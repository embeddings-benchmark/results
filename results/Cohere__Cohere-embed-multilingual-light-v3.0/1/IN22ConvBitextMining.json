{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "task_name": "IN22ConvBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.852983,
        "recall": 0.888889,
        "f1": 0.864094,
        "accuracy": 0.888889,
        "main_score": 0.864094,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.083039,
        "recall": 0.115103,
        "f1": 0.089592,
        "accuracy": 0.115103,
        "main_score": 0.089592,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.475142,
        "recall": 0.557552,
        "f1": 0.49777,
        "accuracy": 0.557552,
        "main_score": 0.49777,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.623996,
        "recall": 0.684631,
        "f1": 0.640188,
        "accuracy": 0.684631,
        "main_score": 0.640188,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.426395,
        "recall": 0.506321,
        "f1": 0.447394,
        "accuracy": 0.506321,
        "main_score": 0.447394,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.801049,
        "recall": 0.844311,
        "f1": 0.813882,
        "accuracy": 0.844311,
        "main_score": 0.813882,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.816115,
        "recall": 0.858949,
        "f1": 0.828624,
        "accuracy": 0.858949,
        "main_score": 0.828624,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.6587,
        "recall": 0.723886,
        "f1": 0.677327,
        "accuracy": 0.723886,
        "main_score": 0.677327,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.394215,
        "recall": 0.474385,
        "f1": 0.415681,
        "accuracy": 0.474385,
        "main_score": 0.415681,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.790829,
        "recall": 0.835662,
        "f1": 0.804005,
        "accuracy": 0.835662,
        "main_score": 0.804005,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.776925,
        "recall": 0.824351,
        "f1": 0.791256,
        "accuracy": 0.824351,
        "main_score": 0.791256,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.820758,
        "recall": 0.854291,
        "f1": 0.830739,
        "accuracy": 0.854291,
        "main_score": 0.830739,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000115,
        "recall": 0.003992,
        "f1": 0.000222,
        "accuracy": 0.003992,
        "main_score": 0.000222,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.830162,
        "recall": 0.866933,
        "f1": 0.841251,
        "accuracy": 0.866933,
        "main_score": 0.841251,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.817742,
        "recall": 0.862941,
        "f1": 0.831603,
        "accuracy": 0.862941,
        "main_score": 0.831603,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.800383,
        "recall": 0.842315,
        "f1": 0.812856,
        "accuracy": 0.842315,
        "main_score": 0.812856,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.666152,
        "recall": 0.728543,
        "f1": 0.684588,
        "accuracy": 0.728543,
        "main_score": 0.684588,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00065,
        "recall": 0.005323,
        "f1": 0.000987,
        "accuracy": 0.005323,
        "main_score": 0.000987,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.359948,
        "recall": 0.43513,
        "f1": 0.379261,
        "accuracy": 0.43513,
        "main_score": 0.379261,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.665842,
        "recall": 0.729874,
        "f1": 0.684693,
        "accuracy": 0.729874,
        "main_score": 0.684693,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.77851,
        "recall": 0.827013,
        "f1": 0.792995,
        "accuracy": 0.827013,
        "main_score": 0.792995,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.832541,
        "recall": 0.87159,
        "f1": 0.844535,
        "accuracy": 0.87159,
        "main_score": 0.844535,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.847069,
        "recall": 0.883566,
        "f1": 0.857843,
        "accuracy": 0.883566,
        "main_score": 0.857843,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.085129,
        "recall": 0.123752,
        "f1": 0.094021,
        "accuracy": 0.123752,
        "main_score": 0.094021,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.523487,
        "recall": 0.606121,
        "f1": 0.546188,
        "accuracy": 0.606121,
        "main_score": 0.546188,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.827402,
        "recall": 0.866933,
        "f1": 0.838863,
        "accuracy": 0.866933,
        "main_score": 0.838863,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.465496,
        "recall": 0.550233,
        "f1": 0.488199,
        "accuracy": 0.550233,
        "main_score": 0.488199,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.865892,
        "recall": 0.894212,
        "f1": 0.874385,
        "accuracy": 0.894212,
        "main_score": 0.874385,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.887691,
        "recall": 0.917498,
        "f1": 0.896962,
        "accuracy": 0.917498,
        "main_score": 0.896962,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.733969,
        "recall": 0.793081,
        "f1": 0.751173,
        "accuracy": 0.793081,
        "main_score": 0.751173,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.425603,
        "recall": 0.513639,
        "f1": 0.449368,
        "accuracy": 0.513639,
        "main_score": 0.449368,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.836389,
        "recall": 0.872921,
        "f1": 0.847551,
        "accuracy": 0.872921,
        "main_score": 0.847551,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.859869,
        "recall": 0.893546,
        "f1": 0.870171,
        "accuracy": 0.893546,
        "main_score": 0.870171,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.887636,
        "recall": 0.914172,
        "f1": 0.895675,
        "accuracy": 0.914172,
        "main_score": 0.895675,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 7.8e-05,
        "recall": 0.002661,
        "f1": 0.000146,
        "accuracy": 0.002661,
        "main_score": 0.000146,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.895065,
        "recall": 0.922156,
        "f1": 0.90346,
        "accuracy": 0.922156,
        "main_score": 0.90346,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.878654,
        "recall": 0.908184,
        "f1": 0.887669,
        "accuracy": 0.908184,
        "main_score": 0.887669,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.850011,
        "recall": 0.886228,
        "f1": 0.861081,
        "accuracy": 0.886228,
        "main_score": 0.861081,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.724637,
        "recall": 0.783766,
        "f1": 0.742204,
        "accuracy": 0.783766,
        "main_score": 0.742204,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000763,
        "recall": 0.005988,
        "f1": 0.000853,
        "accuracy": 0.005988,
        "main_score": 0.000853,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.391485,
        "recall": 0.47505,
        "f1": 0.413361,
        "accuracy": 0.47505,
        "main_score": 0.413361,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.774773,
        "recall": 0.821025,
        "f1": 0.788781,
        "accuracy": 0.821025,
        "main_score": 0.788781,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.857086,
        "recall": 0.890885,
        "f1": 0.867687,
        "accuracy": 0.890885,
        "main_score": 0.867687,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.888212,
        "recall": 0.916168,
        "f1": 0.896784,
        "accuracy": 0.916168,
        "main_score": 0.896784,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.080894,
        "recall": 0.106454,
        "f1": 0.085689,
        "accuracy": 0.106454,
        "main_score": 0.085689,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.072827,
        "recall": 0.102462,
        "f1": 0.078779,
        "accuracy": 0.102462,
        "main_score": 0.078779,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.106961,
        "recall": 0.133733,
        "f1": 0.112555,
        "accuracy": 0.133733,
        "main_score": 0.112555,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.053982,
        "recall": 0.067864,
        "f1": 0.056184,
        "accuracy": 0.067864,
        "main_score": 0.056184,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.087649,
        "recall": 0.113772,
        "f1": 0.093009,
        "accuracy": 0.113772,
        "main_score": 0.093009,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.066121,
        "recall": 0.083167,
        "f1": 0.06899,
        "accuracy": 0.083167,
        "main_score": 0.06899,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.105135,
        "recall": 0.136394,
        "f1": 0.11149,
        "accuracy": 0.136394,
        "main_score": 0.11149,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.065611,
        "recall": 0.083167,
        "f1": 0.068835,
        "accuracy": 0.083167,
        "main_score": 0.068835,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.073015,
        "recall": 0.095808,
        "f1": 0.077441,
        "accuracy": 0.095808,
        "main_score": 0.077441,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.084692,
        "recall": 0.116434,
        "f1": 0.091174,
        "accuracy": 0.116434,
        "main_score": 0.091174,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.072972,
        "recall": 0.100466,
        "f1": 0.077651,
        "accuracy": 0.100466,
        "main_score": 0.077651,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.080057,
        "recall": 0.110446,
        "f1": 0.085873,
        "accuracy": 0.110446,
        "main_score": 0.085873,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000283,
        "recall": 0.002661,
        "f1": 0.000451,
        "accuracy": 0.002661,
        "main_score": 0.000451,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.084101,
        "recall": 0.115768,
        "f1": 0.090324,
        "accuracy": 0.115768,
        "main_score": 0.090324,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.083878,
        "recall": 0.11843,
        "f1": 0.090084,
        "accuracy": 0.11843,
        "main_score": 0.090084,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.067019,
        "recall": 0.089155,
        "f1": 0.070985,
        "accuracy": 0.089155,
        "main_score": 0.070985,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.075453,
        "recall": 0.110446,
        "f1": 0.082057,
        "accuracy": 0.110446,
        "main_score": 0.082057,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 4.3e-05,
        "recall": 0.002661,
        "f1": 8.5e-05,
        "accuracy": 0.002661,
        "main_score": 8.5e-05,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.100042,
        "recall": 0.124418,
        "f1": 0.10521,
        "accuracy": 0.124418,
        "main_score": 0.10521,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.062325,
        "recall": 0.087824,
        "f1": 0.066983,
        "accuracy": 0.087824,
        "main_score": 0.066983,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.073056,
        "recall": 0.101131,
        "f1": 0.077833,
        "accuracy": 0.101131,
        "main_score": 0.077833,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.09034,
        "recall": 0.113107,
        "f1": 0.094263,
        "accuracy": 0.113107,
        "main_score": 0.094263,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.507249,
        "recall": 0.576846,
        "f1": 0.526108,
        "accuracy": 0.576846,
        "main_score": 0.526108,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.559199,
        "recall": 0.626747,
        "f1": 0.576525,
        "accuracy": 0.626747,
        "main_score": 0.576525,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.098351,
        "recall": 0.135729,
        "f1": 0.106311,
        "accuracy": 0.135729,
        "main_score": 0.106311,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.390675,
        "recall": 0.440452,
        "f1": 0.401304,
        "accuracy": 0.440452,
        "main_score": 0.401304,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.355662,
        "recall": 0.421158,
        "f1": 0.371977,
        "accuracy": 0.421158,
        "main_score": 0.371977,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.524523,
        "recall": 0.588822,
        "f1": 0.541368,
        "accuracy": 0.588822,
        "main_score": 0.541368,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.608895,
        "recall": 0.67332,
        "f1": 0.625952,
        "accuracy": 0.67332,
        "main_score": 0.625952,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.425738,
        "recall": 0.484365,
        "f1": 0.440682,
        "accuracy": 0.484365,
        "main_score": 0.440682,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.305821,
        "recall": 0.381903,
        "f1": 0.325454,
        "accuracy": 0.381903,
        "main_score": 0.325454,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.585513,
        "recall": 0.664005,
        "f1": 0.607102,
        "accuracy": 0.664005,
        "main_score": 0.607102,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.494156,
        "recall": 0.568862,
        "f1": 0.513496,
        "accuracy": 0.568862,
        "main_score": 0.513496,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.568032,
        "recall": 0.638057,
        "f1": 0.587353,
        "accuracy": 0.638057,
        "main_score": 0.587353,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000178,
        "recall": 0.003992,
        "f1": 0.000321,
        "accuracy": 0.003992,
        "main_score": 0.000321,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.565142,
        "recall": 0.634065,
        "f1": 0.583555,
        "accuracy": 0.634065,
        "main_score": 0.583555,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.524439,
        "recall": 0.598137,
        "f1": 0.54395,
        "accuracy": 0.598137,
        "main_score": 0.54395,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.553056,
        "recall": 0.622089,
        "f1": 0.571189,
        "accuracy": 0.622089,
        "main_score": 0.571189,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.410146,
        "recall": 0.493014,
        "f1": 0.43242,
        "accuracy": 0.493014,
        "main_score": 0.43242,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 9.7e-05,
        "recall": 0.003327,
        "f1": 0.000185,
        "accuracy": 0.003327,
        "main_score": 0.000185,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.386125,
        "recall": 0.452428,
        "f1": 0.403509,
        "accuracy": 0.452428,
        "main_score": 0.403509,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.412757,
        "recall": 0.490353,
        "f1": 0.433762,
        "accuracy": 0.490353,
        "main_score": 0.433762,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.485477,
        "recall": 0.556886,
        "f1": 0.504505,
        "accuracy": 0.556886,
        "main_score": 0.504505,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.577606,
        "recall": 0.648703,
        "f1": 0.597283,
        "accuracy": 0.648703,
        "main_score": 0.597283,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.794978,
        "recall": 0.844977,
        "f1": 0.809903,
        "accuracy": 0.844977,
        "main_score": 0.809903,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.902495,
        "recall": 0.926148,
        "f1": 0.909625,
        "accuracy": 0.926148,
        "main_score": 0.909625,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.098438,
        "recall": 0.147039,
        "f1": 0.10878,
        "accuracy": 0.147039,
        "main_score": 0.10878,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.534795,
        "recall": 0.632735,
        "f1": 0.562003,
        "accuracy": 0.632735,
        "main_score": 0.562003,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.426924,
        "recall": 0.528277,
        "f1": 0.453673,
        "accuracy": 0.528277,
        "main_score": 0.453673,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.875982,
        "recall": 0.906853,
        "f1": 0.885076,
        "accuracy": 0.906853,
        "main_score": 0.885076,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.906542,
        "recall": 0.93147,
        "f1": 0.914016,
        "accuracy": 0.93147,
        "main_score": 0.914016,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.718169,
        "recall": 0.784431,
        "f1": 0.737693,
        "accuracy": 0.784431,
        "main_score": 0.737693,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.382283,
        "recall": 0.483699,
        "f1": 0.408655,
        "accuracy": 0.483699,
        "main_score": 0.408655,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.849878,
        "recall": 0.887558,
        "f1": 0.86132,
        "accuracy": 0.887558,
        "main_score": 0.86132,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.862719,
        "recall": 0.897538,
        "f1": 0.87333,
        "accuracy": 0.897538,
        "main_score": 0.87333,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.884597,
        "recall": 0.914172,
        "f1": 0.893404,
        "accuracy": 0.914172,
        "main_score": 0.893404,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000116,
        "recall": 0.003327,
        "f1": 0.000214,
        "accuracy": 0.003327,
        "main_score": 0.000214,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.882823,
        "recall": 0.914172,
        "f1": 0.892349,
        "accuracy": 0.914172,
        "main_score": 0.892349,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.862087,
        "recall": 0.897538,
        "f1": 0.872888,
        "accuracy": 0.897538,
        "main_score": 0.872888,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.852435,
        "recall": 0.890885,
        "f1": 0.863918,
        "accuracy": 0.890885,
        "main_score": 0.863918,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.664102,
        "recall": 0.735862,
        "f1": 0.684915,
        "accuracy": 0.735862,
        "main_score": 0.684915,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000466,
        "recall": 0.006653,
        "f1": 0.000805,
        "accuracy": 0.006653,
        "main_score": 0.000805,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.403031,
        "recall": 0.500333,
        "f1": 0.428788,
        "accuracy": 0.500333,
        "main_score": 0.428788,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.774493,
        "recall": 0.823686,
        "f1": 0.78918,
        "accuracy": 0.823686,
        "main_score": 0.78918,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.849191,
        "recall": 0.886228,
        "f1": 0.860371,
        "accuracy": 0.886228,
        "main_score": 0.860371,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.917177,
        "recall": 0.938789,
        "f1": 0.923832,
        "accuracy": 0.938789,
        "main_score": 0.923832,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.444275,
        "recall": 0.513639,
        "f1": 0.462093,
        "accuracy": 0.513639,
        "main_score": 0.462093,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.49186,
        "recall": 0.557552,
        "f1": 0.508386,
        "accuracy": 0.557552,
        "main_score": 0.508386,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.088773,
        "recall": 0.125083,
        "f1": 0.096567,
        "accuracy": 0.125083,
        "main_score": 0.096567,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.35899,
        "recall": 0.429142,
        "f1": 0.37772,
        "accuracy": 0.429142,
        "main_score": 0.37772,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.301524,
        "recall": 0.343979,
        "f1": 0.311528,
        "accuracy": 0.343979,
        "main_score": 0.311528,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.452682,
        "recall": 0.508982,
        "f1": 0.466419,
        "accuracy": 0.508982,
        "main_score": 0.466419,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.470377,
        "recall": 0.541583,
        "f1": 0.488233,
        "accuracy": 0.541583,
        "main_score": 0.488233,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.38883,
        "recall": 0.447771,
        "f1": 0.403536,
        "accuracy": 0.447771,
        "main_score": 0.403536,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.255948,
        "recall": 0.321357,
        "f1": 0.273005,
        "accuracy": 0.321357,
        "main_score": 0.273005,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.478205,
        "recall": 0.549568,
        "f1": 0.496742,
        "accuracy": 0.549568,
        "main_score": 0.496742,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.432211,
        "recall": 0.512309,
        "f1": 0.452848,
        "accuracy": 0.512309,
        "main_score": 0.452848,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.536339,
        "recall": 0.608117,
        "f1": 0.554871,
        "accuracy": 0.608117,
        "main_score": 0.554871,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00042,
        "recall": 0.003992,
        "f1": 0.000613,
        "accuracy": 0.003992,
        "main_score": 0.000613,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.46694,
        "recall": 0.545576,
        "f1": 0.486829,
        "accuracy": 0.545576,
        "main_score": 0.486829,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.464942,
        "recall": 0.532269,
        "f1": 0.482294,
        "accuracy": 0.532269,
        "main_score": 0.482294,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.44104,
        "recall": 0.506986,
        "f1": 0.457267,
        "accuracy": 0.506986,
        "main_score": 0.457267,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.39348,
        "recall": 0.462409,
        "f1": 0.411397,
        "accuracy": 0.462409,
        "main_score": 0.411397,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.005323,
        "f1": 0.000755,
        "accuracy": 0.005323,
        "main_score": 0.000755,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.295526,
        "recall": 0.355955,
        "f1": 0.311734,
        "accuracy": 0.355955,
        "main_score": 0.311734,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.378083,
        "recall": 0.447106,
        "f1": 0.395746,
        "accuracy": 0.447106,
        "main_score": 0.395746,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.424473,
        "recall": 0.491018,
        "f1": 0.441062,
        "accuracy": 0.491018,
        "main_score": 0.441062,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.474886,
        "recall": 0.544245,
        "f1": 0.492444,
        "accuracy": 0.544245,
        "main_score": 0.492444,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.836334,
        "recall": 0.875582,
        "f1": 0.848172,
        "accuracy": 0.875582,
        "main_score": 0.848172,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.898392,
        "recall": 0.924817,
        "f1": 0.906653,
        "accuracy": 0.924817,
        "main_score": 0.906653,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.087104,
        "recall": 0.125749,
        "f1": 0.094412,
        "accuracy": 0.125749,
        "main_score": 0.094412,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.525651,
        "recall": 0.618097,
        "f1": 0.552285,
        "accuracy": 0.618097,
        "main_score": 0.552285,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.828651,
        "recall": 0.867598,
        "f1": 0.839715,
        "accuracy": 0.867598,
        "main_score": 0.839715,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.499213,
        "recall": 0.587492,
        "f1": 0.522798,
        "accuracy": 0.587492,
        "main_score": 0.522798,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.896469,
        "recall": 0.923486,
        "f1": 0.905068,
        "accuracy": 0.923486,
        "main_score": 0.905068,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.726355,
        "recall": 0.787092,
        "f1": 0.744216,
        "accuracy": 0.787092,
        "main_score": 0.744216,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.445003,
        "recall": 0.539587,
        "f1": 0.470896,
        "accuracy": 0.539587,
        "main_score": 0.470896,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.870725,
        "recall": 0.902196,
        "f1": 0.880297,
        "accuracy": 0.902196,
        "main_score": 0.880297,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.857474,
        "recall": 0.892881,
        "f1": 0.86864,
        "accuracy": 0.892881,
        "main_score": 0.86864,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.904513,
        "recall": 0.928144,
        "f1": 0.911887,
        "accuracy": 0.928144,
        "main_score": 0.911887,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 5.8e-05,
        "recall": 0.003327,
        "f1": 0.000113,
        "accuracy": 0.003327,
        "main_score": 0.000113,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.895564,
        "recall": 0.920825,
        "f1": 0.903371,
        "accuracy": 0.920825,
        "main_score": 0.903371,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.877711,
        "recall": 0.909514,
        "f1": 0.887891,
        "accuracy": 0.909514,
        "main_score": 0.887891,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.87037,
        "recall": 0.904192,
        "f1": 0.880686,
        "accuracy": 0.904192,
        "main_score": 0.880686,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.702284,
        "recall": 0.771124,
        "f1": 0.722826,
        "accuracy": 0.771124,
        "main_score": 0.722826,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000743,
        "recall": 0.003992,
        "f1": 0.000816,
        "accuracy": 0.003992,
        "main_score": 0.000816,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.434263,
        "recall": 0.518297,
        "f1": 0.456263,
        "accuracy": 0.518297,
        "main_score": 0.456263,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.756943,
        "recall": 0.810379,
        "f1": 0.773165,
        "accuracy": 0.810379,
        "main_score": 0.773165,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.83975,
        "recall": 0.878909,
        "f1": 0.851798,
        "accuracy": 0.878909,
        "main_score": 0.851798,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.897039,
        "recall": 0.92149,
        "f1": 0.904759,
        "accuracy": 0.92149,
        "main_score": 0.904759,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.820975,
        "recall": 0.864937,
        "f1": 0.833928,
        "accuracy": 0.864937,
        "main_score": 0.833928,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.908317,
        "recall": 0.932801,
        "f1": 0.915924,
        "accuracy": 0.932801,
        "main_score": 0.915924,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.135534,
        "recall": 0.186959,
        "f1": 0.147462,
        "accuracy": 0.186959,
        "main_score": 0.147462,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.620272,
        "recall": 0.694611,
        "f1": 0.641036,
        "accuracy": 0.694611,
        "main_score": 0.641036,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.869451,
        "recall": 0.902196,
        "f1": 0.879112,
        "accuracy": 0.902196,
        "main_score": 0.879112,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.490068,
        "recall": 0.578177,
        "f1": 0.514258,
        "accuracy": 0.578177,
        "main_score": 0.514258,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.876742,
        "recall": 0.904192,
        "f1": 0.884908,
        "accuracy": 0.904192,
        "main_score": 0.884908,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.763296,
        "recall": 0.813041,
        "f1": 0.777819,
        "accuracy": 0.813041,
        "main_score": 0.777819,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.465804,
        "recall": 0.557552,
        "f1": 0.491301,
        "accuracy": 0.557552,
        "main_score": 0.491301,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.862874,
        "recall": 0.898204,
        "f1": 0.873764,
        "accuracy": 0.898204,
        "main_score": 0.873764,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.873353,
        "recall": 0.90153,
        "f1": 0.881925,
        "accuracy": 0.90153,
        "main_score": 0.881925,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.888445,
        "recall": 0.915502,
        "f1": 0.896718,
        "accuracy": 0.915502,
        "main_score": 0.896718,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000104,
        "recall": 0.003327,
        "f1": 0.000193,
        "accuracy": 0.003327,
        "main_score": 0.000193,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.875749,
        "recall": 0.905522,
        "f1": 0.884631,
        "accuracy": 0.905522,
        "main_score": 0.884631,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.882723,
        "recall": 0.912841,
        "f1": 0.891972,
        "accuracy": 0.912841,
        "main_score": 0.891972,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.873187,
        "recall": 0.903526,
        "f1": 0.882413,
        "accuracy": 0.903526,
        "main_score": 0.882413,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.707143,
        "recall": 0.771124,
        "f1": 0.725947,
        "accuracy": 0.771124,
        "main_score": 0.725947,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000525,
        "recall": 0.005988,
        "f1": 0.000792,
        "accuracy": 0.005988,
        "main_score": 0.000792,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.48443,
        "recall": 0.565536,
        "f1": 0.505951,
        "accuracy": 0.565536,
        "main_score": 0.505951,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.788479,
        "recall": 0.833001,
        "f1": 0.802262,
        "accuracy": 0.833001,
        "main_score": 0.802262,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.855201,
        "recall": 0.889554,
        "f1": 0.865859,
        "accuracy": 0.889554,
        "main_score": 0.865859,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.911677,
        "recall": 0.933466,
        "f1": 0.918141,
        "accuracy": 0.933466,
        "main_score": 0.918141,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.676503,
        "recall": 0.735862,
        "f1": 0.694281,
        "accuracy": 0.735862,
        "main_score": 0.694281,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.766024,
        "recall": 0.817033,
        "f1": 0.781741,
        "accuracy": 0.817033,
        "main_score": 0.781741,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.084999,
        "recall": 0.124418,
        "f1": 0.093844,
        "accuracy": 0.124418,
        "main_score": 0.093844,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.456169,
        "recall": 0.530273,
        "f1": 0.476974,
        "accuracy": 0.530273,
        "main_score": 0.476974,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.620315,
        "recall": 0.673985,
        "f1": 0.633755,
        "accuracy": 0.673985,
        "main_score": 0.633755,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.419632,
        "recall": 0.496341,
        "f1": 0.440728,
        "accuracy": 0.496341,
        "main_score": 0.440728,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.712117,
        "recall": 0.759814,
        "f1": 0.726225,
        "accuracy": 0.759814,
        "main_score": 0.726225,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.765098,
        "recall": 0.814371,
        "f1": 0.779443,
        "accuracy": 0.814371,
        "main_score": 0.779443,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.352812,
        "recall": 0.429142,
        "f1": 0.37327,
        "accuracy": 0.429142,
        "main_score": 0.37327,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.706509,
        "recall": 0.765802,
        "f1": 0.723832,
        "accuracy": 0.765802,
        "main_score": 0.723832,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.748054,
        "recall": 0.804391,
        "f1": 0.765265,
        "accuracy": 0.804391,
        "main_score": 0.765265,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.749967,
        "recall": 0.799734,
        "f1": 0.76496,
        "accuracy": 0.799734,
        "main_score": 0.76496,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 6.4e-05,
        "recall": 0.002661,
        "f1": 0.000124,
        "accuracy": 0.002661,
        "main_score": 0.000124,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.752994,
        "recall": 0.803726,
        "f1": 0.767969,
        "accuracy": 0.803726,
        "main_score": 0.767969,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.735269,
        "recall": 0.794411,
        "f1": 0.753118,
        "accuracy": 0.794411,
        "main_score": 0.753118,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.684127,
        "recall": 0.745842,
        "f1": 0.701877,
        "accuracy": 0.745842,
        "main_score": 0.701877,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.57642,
        "recall": 0.655356,
        "f1": 0.600255,
        "accuracy": 0.655356,
        "main_score": 0.600255,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000776,
        "recall": 0.004657,
        "f1": 0.000875,
        "accuracy": 0.004657,
        "main_score": 0.000875,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.356803,
        "recall": 0.43646,
        "f1": 0.378284,
        "accuracy": 0.43646,
        "main_score": 0.378284,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.69643,
        "recall": 0.761144,
        "f1": 0.715925,
        "accuracy": 0.761144,
        "main_score": 0.715925,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.76823,
        "recall": 0.820359,
        "f1": 0.783608,
        "accuracy": 0.820359,
        "main_score": 0.783608,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.756727,
        "recall": 0.807718,
        "f1": 0.771859,
        "accuracy": 0.807718,
        "main_score": 0.771859,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.393616,
        "recall": 0.471723,
        "f1": 0.414006,
        "accuracy": 0.471723,
        "main_score": 0.414006,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.443407,
        "recall": 0.520958,
        "f1": 0.463755,
        "accuracy": 0.520958,
        "main_score": 0.463755,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.068114,
        "recall": 0.09847,
        "f1": 0.074433,
        "accuracy": 0.09847,
        "main_score": 0.074433,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.287763,
        "recall": 0.353293,
        "f1": 0.304968,
        "accuracy": 0.353293,
        "main_score": 0.304968,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.243068,
        "recall": 0.284098,
        "f1": 0.250922,
        "accuracy": 0.284098,
        "main_score": 0.250922,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.258928,
        "recall": 0.314704,
        "f1": 0.273769,
        "accuracy": 0.314704,
        "main_score": 0.273769,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.418776,
        "recall": 0.483699,
        "f1": 0.435587,
        "accuracy": 0.483699,
        "main_score": 0.435587,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.414911,
        "recall": 0.488357,
        "f1": 0.434525,
        "accuracy": 0.488357,
        "main_score": 0.434525,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.352834,
        "recall": 0.409182,
        "f1": 0.367795,
        "accuracy": 0.409182,
        "main_score": 0.367795,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.41925,
        "recall": 0.502329,
        "f1": 0.442006,
        "accuracy": 0.502329,
        "main_score": 0.442006,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.381441,
        "recall": 0.459747,
        "f1": 0.401872,
        "accuracy": 0.459747,
        "main_score": 0.401872,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.427732,
        "recall": 0.506321,
        "f1": 0.447686,
        "accuracy": 0.506321,
        "main_score": 0.447686,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000447,
        "recall": 0.004657,
        "f1": 0.000665,
        "accuracy": 0.004657,
        "main_score": 0.000665,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.446918,
        "recall": 0.525615,
        "f1": 0.467842,
        "accuracy": 0.525615,
        "main_score": 0.467842,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.414141,
        "recall": 0.486361,
        "f1": 0.43216,
        "accuracy": 0.486361,
        "main_score": 0.43216,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.430421,
        "recall": 0.501663,
        "f1": 0.448514,
        "accuracy": 0.501663,
        "main_score": 0.448514,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.35657,
        "recall": 0.438456,
        "f1": 0.378756,
        "accuracy": 0.438456,
        "main_score": 0.378756,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000576,
        "recall": 0.005323,
        "f1": 0.000875,
        "accuracy": 0.005323,
        "main_score": 0.000875,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.244209,
        "recall": 0.302063,
        "f1": 0.259185,
        "accuracy": 0.302063,
        "main_score": 0.259185,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.340323,
        "recall": 0.405855,
        "f1": 0.35755,
        "accuracy": 0.405855,
        "main_score": 0.35755,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.386282,
        "recall": 0.455755,
        "f1": 0.403511,
        "accuracy": 0.455755,
        "main_score": 0.403511,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.501369,
        "recall": 0.576181,
        "f1": 0.521377,
        "accuracy": 0.576181,
        "main_score": 0.521377,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.787104,
        "recall": 0.834331,
        "f1": 0.801242,
        "accuracy": 0.834331,
        "main_score": 0.801242,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.845077,
        "recall": 0.88157,
        "f1": 0.85642,
        "accuracy": 0.88157,
        "main_score": 0.85642,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.088765,
        "recall": 0.124418,
        "f1": 0.096315,
        "accuracy": 0.124418,
        "main_score": 0.096315,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.547246,
        "recall": 0.634731,
        "f1": 0.571874,
        "accuracy": 0.634731,
        "main_score": 0.571874,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.724806,
        "recall": 0.778443,
        "f1": 0.739233,
        "accuracy": 0.778443,
        "main_score": 0.739233,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.469794,
        "recall": 0.557552,
        "f1": 0.493709,
        "accuracy": 0.557552,
        "main_score": 0.493709,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.841273,
        "recall": 0.878909,
        "f1": 0.852419,
        "accuracy": 0.878909,
        "main_score": 0.852419,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.851375,
        "recall": 0.888889,
        "f1": 0.86301,
        "accuracy": 0.888889,
        "main_score": 0.86301,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.669291,
        "recall": 0.734531,
        "f1": 0.688264,
        "accuracy": 0.734531,
        "main_score": 0.688264,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.407321,
        "recall": 0.490353,
        "f1": 0.429684,
        "accuracy": 0.490353,
        "main_score": 0.429684,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.77896,
        "recall": 0.832335,
        "f1": 0.795389,
        "accuracy": 0.832335,
        "main_score": 0.795389,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.851065,
        "recall": 0.887558,
        "f1": 0.862409,
        "accuracy": 0.887558,
        "main_score": 0.862409,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000451,
        "recall": 0.004657,
        "f1": 0.000669,
        "accuracy": 0.004657,
        "main_score": 0.000669,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.873293,
        "recall": 0.904192,
        "f1": 0.882757,
        "accuracy": 0.904192,
        "main_score": 0.882757,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.828106,
        "recall": 0.87159,
        "f1": 0.841506,
        "accuracy": 0.87159,
        "main_score": 0.841506,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.828278,
        "recall": 0.868263,
        "f1": 0.840279,
        "accuracy": 0.868263,
        "main_score": 0.840279,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.69959,
        "recall": 0.767132,
        "f1": 0.719812,
        "accuracy": 0.767132,
        "main_score": 0.719812,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000868,
        "recall": 0.005988,
        "f1": 0.001036,
        "accuracy": 0.005988,
        "main_score": 0.001036,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.39262,
        "recall": 0.477046,
        "f1": 0.414708,
        "accuracy": 0.477046,
        "main_score": 0.414708,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.697699,
        "recall": 0.762475,
        "f1": 0.716925,
        "accuracy": 0.762475,
        "main_score": 0.716925,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.783261,
        "recall": 0.832335,
        "f1": 0.798187,
        "accuracy": 0.832335,
        "main_score": 0.798187,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.862686,
        "recall": 0.9002,
        "f1": 0.874274,
        "accuracy": 0.9002,
        "main_score": 0.874274,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.78371,
        "recall": 0.830339,
        "f1": 0.798118,
        "accuracy": 0.830339,
        "main_score": 0.798118,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.876297,
        "recall": 0.904857,
        "f1": 0.8852,
        "accuracy": 0.904857,
        "main_score": 0.8852,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.09011,
        "recall": 0.126414,
        "f1": 0.097925,
        "accuracy": 0.126414,
        "main_score": 0.097925,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.485999,
        "recall": 0.576181,
        "f1": 0.510857,
        "accuracy": 0.576181,
        "main_score": 0.510857,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.797595,
        "recall": 0.836993,
        "f1": 0.808707,
        "accuracy": 0.836993,
        "main_score": 0.808707,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.445875,
        "recall": 0.526281,
        "f1": 0.467578,
        "accuracy": 0.526281,
        "main_score": 0.467578,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.826786,
        "recall": 0.864937,
        "f1": 0.838014,
        "accuracy": 0.864937,
        "main_score": 0.838014,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.853395,
        "recall": 0.888224,
        "f1": 0.86373,
        "accuracy": 0.888224,
        "main_score": 0.86373,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.727341,
        "recall": 0.783766,
        "f1": 0.743379,
        "accuracy": 0.783766,
        "main_score": 0.743379,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.395373,
        "recall": 0.479042,
        "f1": 0.417977,
        "accuracy": 0.479042,
        "main_score": 0.417977,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.792127,
        "recall": 0.838323,
        "f1": 0.806055,
        "accuracy": 0.838323,
        "main_score": 0.806055,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.855977,
        "recall": 0.886893,
        "f1": 0.865558,
        "accuracy": 0.886893,
        "main_score": 0.865558,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000188,
        "recall": 0.003327,
        "f1": 0.000337,
        "accuracy": 0.003327,
        "main_score": 0.000337,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.853537,
        "recall": 0.888889,
        "f1": 0.864582,
        "accuracy": 0.888889,
        "main_score": 0.864582,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.850887,
        "recall": 0.888224,
        "f1": 0.862187,
        "accuracy": 0.888224,
        "main_score": 0.862187,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.802789,
        "recall": 0.848303,
        "f1": 0.816326,
        "accuracy": 0.848303,
        "main_score": 0.816326,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.678312,
        "recall": 0.744511,
        "f1": 0.697474,
        "accuracy": 0.744511,
        "main_score": 0.697474,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000383,
        "recall": 0.004657,
        "f1": 0.000621,
        "accuracy": 0.004657,
        "main_score": 0.000621,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.392666,
        "recall": 0.469727,
        "f1": 0.413122,
        "accuracy": 0.469727,
        "main_score": 0.413122,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.782895,
        "recall": 0.829009,
        "f1": 0.797087,
        "accuracy": 0.829009,
        "main_score": 0.797087,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.845387,
        "recall": 0.882236,
        "f1": 0.856611,
        "accuracy": 0.882236,
        "main_score": 0.856611,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.853837,
        "recall": 0.89022,
        "f1": 0.864826,
        "accuracy": 0.89022,
        "main_score": 0.864826,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.820637,
        "recall": 0.862941,
        "f1": 0.833501,
        "accuracy": 0.862941,
        "main_score": 0.833501,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.89257,
        "recall": 0.918829,
        "f1": 0.900732,
        "accuracy": 0.918829,
        "main_score": 0.900732,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.092448,
        "recall": 0.130406,
        "f1": 0.100954,
        "accuracy": 0.130406,
        "main_score": 0.100954,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.546636,
        "recall": 0.628743,
        "f1": 0.569513,
        "accuracy": 0.628743,
        "main_score": 0.569513,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.817461,
        "recall": 0.860945,
        "f1": 0.830162,
        "accuracy": 0.860945,
        "main_score": 0.830162,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.547511,
        "recall": 0.631404,
        "f1": 0.570344,
        "accuracy": 0.631404,
        "main_score": 0.570344,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.881337,
        "recall": 0.908849,
        "f1": 0.8899,
        "accuracy": 0.908849,
        "main_score": 0.8899,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.892293,
        "recall": 0.918829,
        "f1": 0.900421,
        "accuracy": 0.918829,
        "main_score": 0.900421,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.723851,
        "recall": 0.780439,
        "f1": 0.740356,
        "accuracy": 0.780439,
        "main_score": 0.740356,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.428924,
        "recall": 0.516966,
        "f1": 0.452488,
        "accuracy": 0.516966,
        "main_score": 0.452488,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.836538,
        "recall": 0.874251,
        "f1": 0.847971,
        "accuracy": 0.874251,
        "main_score": 0.847971,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.843724,
        "recall": 0.882901,
        "f1": 0.8556,
        "accuracy": 0.882901,
        "main_score": 0.8556,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 4.8e-05,
        "recall": 0.002661,
        "f1": 9.4e-05,
        "accuracy": 0.002661,
        "main_score": 9.4e-05,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.87475,
        "recall": 0.905522,
        "f1": 0.884048,
        "accuracy": 0.905522,
        "main_score": 0.884048,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.856753,
        "recall": 0.892216,
        "f1": 0.867776,
        "accuracy": 0.892216,
        "main_score": 0.867776,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.857674,
        "recall": 0.893546,
        "f1": 0.868796,
        "accuracy": 0.893546,
        "main_score": 0.868796,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.726448,
        "recall": 0.786427,
        "f1": 0.744966,
        "accuracy": 0.786427,
        "main_score": 0.744966,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000395,
        "recall": 0.005988,
        "f1": 0.000657,
        "accuracy": 0.005988,
        "main_score": 0.000657,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.421872,
        "recall": 0.504325,
        "f1": 0.444057,
        "accuracy": 0.504325,
        "main_score": 0.444057,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.756908,
        "recall": 0.809714,
        "f1": 0.772813,
        "accuracy": 0.809714,
        "main_score": 0.772813,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.841805,
        "recall": 0.878909,
        "f1": 0.853404,
        "accuracy": 0.878909,
        "main_score": 0.853404,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.886083,
        "recall": 0.914172,
        "f1": 0.894921,
        "accuracy": 0.914172,
        "main_score": 0.894921,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.002661,
        "f1": 3e-05,
        "accuracy": 0.002661,
        "main_score": 3e-05,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 2.2e-05,
        "recall": 0.002661,
        "f1": 4.3e-05,
        "accuracy": 0.002661,
        "main_score": 4.3e-05,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 4.9e-05,
        "recall": 0.003327,
        "f1": 9.5e-05,
        "accuracy": 0.003327,
        "main_score": 9.5e-05,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.001996,
        "f1": 2.9e-05,
        "accuracy": 0.001996,
        "main_score": 2.9e-05,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.2e-05,
        "recall": 0.001331,
        "f1": 2.3e-05,
        "accuracy": 0.001331,
        "main_score": 2.3e-05,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.000665,
        "f1": 6e-06,
        "accuracy": 0.000665,
        "main_score": 6e-06,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001996,
        "f1": 1.2e-05,
        "accuracy": 0.001996,
        "main_score": 1.2e-05,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000112,
        "recall": 0.003327,
        "f1": 0.0002,
        "accuracy": 0.003327,
        "main_score": 0.0002,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.6e-05,
        "recall": 0.002661,
        "f1": 3.2e-05,
        "accuracy": 0.002661,
        "main_score": 3.2e-05,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000668,
        "recall": 0.001996,
        "f1": 0.000672,
        "accuracy": 0.001996,
        "main_score": 0.000672,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.000668,
        "recall": 0.001331,
        "f1": 0.000671,
        "accuracy": 0.001331,
        "main_score": 0.000671,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.002661,
        "f1": 3.1e-05,
        "accuracy": 0.002661,
        "main_score": 3.1e-05,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000679,
        "recall": 0.003327,
        "f1": 0.000693,
        "accuracy": 0.003327,
        "main_score": 0.000693,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.3e-05,
        "recall": 0.001331,
        "f1": 2.5e-05,
        "accuracy": 0.001331,
        "main_score": 2.5e-05,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.001996,
        "f1": 3.3e-05,
        "accuracy": 0.001996,
        "main_score": 3.3e-05,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 1.6e-05,
        "recall": 0.001996,
        "f1": 3.1e-05,
        "accuracy": 0.001996,
        "main_score": 3.1e-05,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 7.3e-05,
        "recall": 0.003327,
        "f1": 0.000136,
        "accuracy": 0.003327,
        "main_score": 0.000136,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.009258,
        "recall": 0.018629,
        "f1": 0.010482,
        "accuracy": 0.018629,
        "main_score": 0.010482,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001996,
        "f1": 1.3e-05,
        "accuracy": 0.001996,
        "main_score": 1.3e-05,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 2.8e-05,
        "recall": 0.002661,
        "f1": 5.4e-05,
        "accuracy": 0.002661,
        "main_score": 5.4e-05,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.001996,
        "f1": 2.1e-05,
        "accuracy": 0.001996,
        "main_score": 2.1e-05,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 2.4e-05,
        "recall": 0.002661,
        "f1": 4.7e-05,
        "accuracy": 0.002661,
        "main_score": 4.7e-05,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.82595,
        "recall": 0.866933,
        "f1": 0.83819,
        "accuracy": 0.866933,
        "main_score": 0.83819,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.889798,
        "recall": 0.916833,
        "f1": 0.898181,
        "accuracy": 0.916833,
        "main_score": 0.898181,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.092638,
        "recall": 0.133067,
        "f1": 0.10185,
        "accuracy": 0.133067,
        "main_score": 0.10185,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.575421,
        "recall": 0.652695,
        "f1": 0.596857,
        "accuracy": 0.652695,
        "main_score": 0.596857,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.793642,
        "recall": 0.840985,
        "f1": 0.806999,
        "accuracy": 0.840985,
        "main_score": 0.806999,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.486367,
        "recall": 0.568862,
        "f1": 0.508705,
        "accuracy": 0.568862,
        "main_score": 0.508705,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.865791,
        "recall": 0.898869,
        "f1": 0.875915,
        "accuracy": 0.898869,
        "main_score": 0.875915,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.872499,
        "recall": 0.905522,
        "f1": 0.882524,
        "accuracy": 0.905522,
        "main_score": 0.882524,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.712965,
        "recall": 0.772455,
        "f1": 0.730179,
        "accuracy": 0.772455,
        "main_score": 0.730179,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.433183,
        "recall": 0.516301,
        "f1": 0.455606,
        "accuracy": 0.516301,
        "main_score": 0.455606,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.859747,
        "recall": 0.894877,
        "f1": 0.870475,
        "accuracy": 0.894877,
        "main_score": 0.870475,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.835518,
        "recall": 0.876248,
        "f1": 0.847961,
        "accuracy": 0.876248,
        "main_score": 0.847961,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.878266,
        "recall": 0.906188,
        "f1": 0.886871,
        "accuracy": 0.906188,
        "main_score": 0.886871,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000106,
        "recall": 0.003992,
        "f1": 0.000201,
        "accuracy": 0.003992,
        "main_score": 0.000201,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.86823,
        "recall": 0.900865,
        "f1": 0.878465,
        "accuracy": 0.900865,
        "main_score": 0.878465,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.837758,
        "recall": 0.876913,
        "f1": 0.8499,
        "accuracy": 0.876913,
        "main_score": 0.8499,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.740664,
        "recall": 0.797073,
        "f1": 0.757807,
        "accuracy": 0.797073,
        "main_score": 0.757807,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000766,
        "recall": 0.004657,
        "f1": 0.000857,
        "accuracy": 0.004657,
        "main_score": 0.000857,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.411201,
        "recall": 0.488357,
        "f1": 0.431638,
        "accuracy": 0.488357,
        "main_score": 0.431638,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.721657,
        "recall": 0.782435,
        "f1": 0.740012,
        "accuracy": 0.782435,
        "main_score": 0.740012,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.844334,
        "recall": 0.880905,
        "f1": 0.855293,
        "accuracy": 0.880905,
        "main_score": 0.855293,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.893125,
        "recall": 0.922821,
        "f1": 0.902395,
        "accuracy": 0.922821,
        "main_score": 0.902395,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.837713,
        "recall": 0.877578,
        "f1": 0.849913,
        "accuracy": 0.877578,
        "main_score": 0.849913,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.892404,
        "recall": 0.920825,
        "f1": 0.901464,
        "accuracy": 0.920825,
        "main_score": 0.901464,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.0929,
        "recall": 0.129075,
        "f1": 0.100662,
        "accuracy": 0.129075,
        "main_score": 0.100662,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.543419,
        "recall": 0.620093,
        "f1": 0.565068,
        "accuracy": 0.620093,
        "main_score": 0.565068,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.807697,
        "recall": 0.849634,
        "f1": 0.819444,
        "accuracy": 0.849634,
        "main_score": 0.819444,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.467258,
        "recall": 0.550898,
        "f1": 0.490057,
        "accuracy": 0.550898,
        "main_score": 0.490057,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.872555,
        "recall": 0.902196,
        "f1": 0.881459,
        "accuracy": 0.902196,
        "main_score": 0.881459,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.884342,
        "recall": 0.914172,
        "f1": 0.893768,
        "accuracy": 0.914172,
        "main_score": 0.893768,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.722209,
        "recall": 0.7831,
        "f1": 0.739977,
        "accuracy": 0.7831,
        "main_score": 0.739977,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.433157,
        "recall": 0.520293,
        "f1": 0.456494,
        "accuracy": 0.520293,
        "main_score": 0.456494,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.851153,
        "recall": 0.884897,
        "f1": 0.861236,
        "accuracy": 0.884897,
        "main_score": 0.861236,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.854735,
        "recall": 0.890885,
        "f1": 0.866134,
        "accuracy": 0.890885,
        "main_score": 0.866134,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.887026,
        "recall": 0.914837,
        "f1": 0.895609,
        "accuracy": 0.914837,
        "main_score": 0.895609,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 9e-05,
        "recall": 0.003327,
        "f1": 0.000173,
        "accuracy": 0.003327,
        "main_score": 0.000173,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.869372,
        "recall": 0.904192,
        "f1": 0.880195,
        "accuracy": 0.904192,
        "main_score": 0.880195,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.831415,
        "recall": 0.873586,
        "f1": 0.8442,
        "accuracy": 0.873586,
        "main_score": 0.8442,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.703576,
        "recall": 0.765802,
        "f1": 0.721988,
        "accuracy": 0.765802,
        "main_score": 0.721988,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00075,
        "recall": 0.004657,
        "f1": 0.000829,
        "accuracy": 0.004657,
        "main_score": 0.000829,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.394845,
        "recall": 0.477046,
        "f1": 0.416483,
        "accuracy": 0.477046,
        "main_score": 0.416483,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.764881,
        "recall": 0.817033,
        "f1": 0.780731,
        "accuracy": 0.817033,
        "main_score": 0.780731,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.853094,
        "recall": 0.890885,
        "f1": 0.865026,
        "accuracy": 0.890885,
        "main_score": 0.865026,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.886749,
        "recall": 0.916833,
        "f1": 0.896252,
        "accuracy": 0.916833,
        "main_score": 0.896252,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.812697,
        "recall": 0.858949,
        "f1": 0.827003,
        "accuracy": 0.858949,
        "main_score": 0.827003,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.868053,
        "recall": 0.90153,
        "f1": 0.878377,
        "accuracy": 0.90153,
        "main_score": 0.878377,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.089827,
        "recall": 0.129075,
        "f1": 0.098203,
        "accuracy": 0.129075,
        "main_score": 0.098203,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.577715,
        "recall": 0.656021,
        "f1": 0.6,
        "accuracy": 0.656021,
        "main_score": 0.6,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.779354,
        "recall": 0.824351,
        "f1": 0.791374,
        "accuracy": 0.824351,
        "main_score": 0.791374,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.46462,
        "recall": 0.545576,
        "f1": 0.485673,
        "accuracy": 0.545576,
        "main_score": 0.485673,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.865924,
        "recall": 0.896873,
        "f1": 0.875297,
        "accuracy": 0.896873,
        "main_score": 0.875297,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.891927,
        "recall": 0.920825,
        "f1": 0.900554,
        "accuracy": 0.920825,
        "main_score": 0.900554,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.694206,
        "recall": 0.754491,
        "f1": 0.711169,
        "accuracy": 0.754491,
        "main_score": 0.711169,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.462123,
        "recall": 0.550898,
        "f1": 0.486314,
        "accuracy": 0.550898,
        "main_score": 0.486314,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.842537,
        "recall": 0.880905,
        "f1": 0.854326,
        "accuracy": 0.880905,
        "main_score": 0.854326,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.818774,
        "recall": 0.862941,
        "f1": 0.832326,
        "accuracy": 0.862941,
        "main_score": 0.832326,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.860896,
        "recall": 0.894212,
        "f1": 0.871059,
        "accuracy": 0.894212,
        "main_score": 0.871059,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000401,
        "recall": 0.005323,
        "f1": 0.000699,
        "accuracy": 0.005323,
        "main_score": 0.000699,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.863906,
        "recall": 0.898204,
        "f1": 0.874362,
        "accuracy": 0.898204,
        "main_score": 0.874362,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.848215,
        "recall": 0.886893,
        "f1": 0.860235,
        "accuracy": 0.886893,
        "main_score": 0.860235,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.679516,
        "recall": 0.750499,
        "f1": 0.700592,
        "accuracy": 0.750499,
        "main_score": 0.700592,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000418,
        "recall": 0.004657,
        "f1": 0.000607,
        "accuracy": 0.004657,
        "main_score": 0.000607,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.415108,
        "recall": 0.497006,
        "f1": 0.436978,
        "accuracy": 0.497006,
        "main_score": 0.436978,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.726326,
        "recall": 0.780439,
        "f1": 0.742785,
        "accuracy": 0.780439,
        "main_score": 0.742785,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.807197,
        "recall": 0.852295,
        "f1": 0.820714,
        "accuracy": 0.852295,
        "main_score": 0.820714,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.895953,
        "recall": 0.92149,
        "f1": 0.903748,
        "accuracy": 0.92149,
        "main_score": 0.903748,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.612272,
        "recall": 0.678643,
        "f1": 0.630537,
        "accuracy": 0.678643,
        "main_score": 0.630537,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.673321,
        "recall": 0.736527,
        "f1": 0.691052,
        "accuracy": 0.736527,
        "main_score": 0.691052,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.067482,
        "recall": 0.093812,
        "f1": 0.072802,
        "accuracy": 0.093812,
        "main_score": 0.072802,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.369047,
        "recall": 0.444444,
        "f1": 0.388547,
        "accuracy": 0.444444,
        "main_score": 0.388547,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.409975,
        "recall": 0.469062,
        "f1": 0.423228,
        "accuracy": 0.469062,
        "main_score": 0.423228,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.331249,
        "recall": 0.402528,
        "f1": 0.349382,
        "accuracy": 0.402528,
        "main_score": 0.349382,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.614119,
        "recall": 0.671324,
        "f1": 0.630217,
        "accuracy": 0.671324,
        "main_score": 0.630217,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.618347,
        "recall": 0.681969,
        "f1": 0.635483,
        "accuracy": 0.681969,
        "main_score": 0.635483,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.488553,
        "recall": 0.555556,
        "f1": 0.506358,
        "accuracy": 0.555556,
        "main_score": 0.506358,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.284852,
        "recall": 0.355289,
        "f1": 0.302942,
        "accuracy": 0.355289,
        "main_score": 0.302942,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.6629,
        "recall": 0.723886,
        "f1": 0.680033,
        "accuracy": 0.723886,
        "main_score": 0.680033,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.596689,
        "recall": 0.666667,
        "f1": 0.616633,
        "accuracy": 0.666667,
        "main_score": 0.616633,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.678965,
        "recall": 0.739188,
        "f1": 0.696186,
        "accuracy": 0.739188,
        "main_score": 0.696186,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000123,
        "recall": 0.005323,
        "f1": 0.000237,
        "accuracy": 0.005323,
        "main_score": 0.000237,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.694368,
        "recall": 0.755156,
        "f1": 0.712169,
        "accuracy": 0.755156,
        "main_score": 0.712169,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.620695,
        "recall": 0.69328,
        "f1": 0.640894,
        "accuracy": 0.69328,
        "main_score": 0.640894,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.595845,
        "recall": 0.660679,
        "f1": 0.61326,
        "accuracy": 0.660679,
        "main_score": 0.61326,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000145,
        "recall": 0.004657,
        "f1": 0.000272,
        "accuracy": 0.004657,
        "main_score": 0.000272,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.271273,
        "recall": 0.332668,
        "f1": 0.286413,
        "accuracy": 0.332668,
        "main_score": 0.286413,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.509159,
        "recall": 0.584165,
        "f1": 0.529864,
        "accuracy": 0.584165,
        "main_score": 0.529864,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.606223,
        "recall": 0.675981,
        "f1": 0.625733,
        "accuracy": 0.675981,
        "main_score": 0.625733,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.645855,
        "recall": 0.71324,
        "f1": 0.664657,
        "accuracy": 0.71324,
        "main_score": 0.664657,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.2e-05,
        "recall": 0.001996,
        "f1": 2.3e-05,
        "accuracy": 0.001996,
        "main_score": 2.3e-05,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.001996,
        "f1": 3.5e-05,
        "accuracy": 0.001996,
        "main_score": 3.5e-05,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 2.1e-05,
        "recall": 0.002661,
        "f1": 4.2e-05,
        "accuracy": 0.002661,
        "main_score": 4.2e-05,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.001996,
        "f1": 2.9e-05,
        "accuracy": 0.001996,
        "main_score": 2.9e-05,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001339,
        "recall": 0.001996,
        "f1": 0.001347,
        "accuracy": 0.001996,
        "main_score": 0.001347,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.001331,
        "f1": 3e-05,
        "accuracy": 0.001331,
        "main_score": 3e-05,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.001996,
        "f1": 3e-05,
        "accuracy": 0.001996,
        "main_score": 3e-05,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000191,
        "recall": 0.003327,
        "f1": 0.000314,
        "accuracy": 0.003327,
        "main_score": 0.000314,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.002661,
        "f1": 3e-05,
        "accuracy": 0.002661,
        "main_score": 3e-05,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000676,
        "recall": 0.002661,
        "f1": 0.000687,
        "accuracy": 0.002661,
        "main_score": 0.000687,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.000676,
        "recall": 0.001996,
        "f1": 0.000687,
        "accuracy": 0.001996,
        "main_score": 0.000687,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.002661,
        "f1": 3e-05,
        "accuracy": 0.002661,
        "main_score": 3e-05,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000679,
        "recall": 0.003327,
        "f1": 0.000692,
        "accuracy": 0.003327,
        "main_score": 0.000692,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.008244,
        "recall": 0.021291,
        "f1": 0.010257,
        "accuracy": 0.021291,
        "main_score": 0.010257,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 1.3e-05,
        "recall": 0.000665,
        "f1": 2.5e-05,
        "accuracy": 0.000665,
        "main_score": 2.5e-05,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.001996,
        "f1": 3.4e-05,
        "accuracy": 0.001996,
        "main_score": 3.4e-05,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.001996,
        "f1": 2.9e-05,
        "accuracy": 0.001996,
        "main_score": 2.9e-05,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 5.6e-05,
        "recall": 0.003327,
        "f1": 0.000107,
        "accuracy": 0.003327,
        "main_score": 0.000107,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.002661,
        "f1": 2.9e-05,
        "accuracy": 0.002661,
        "main_score": 2.9e-05,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.000122,
        "recall": 0.003327,
        "f1": 0.000219,
        "accuracy": 0.003327,
        "main_score": 0.000219,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.001996,
        "f1": 2.2e-05,
        "accuracy": 0.001996,
        "main_score": 2.2e-05,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.001996,
        "f1": 2.1e-05,
        "accuracy": 0.001996,
        "main_score": 2.1e-05,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.373891,
        "recall": 0.445775,
        "f1": 0.393187,
        "accuracy": 0.445775,
        "main_score": 0.393187,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.410626,
        "recall": 0.491683,
        "f1": 0.431395,
        "accuracy": 0.491683,
        "main_score": 0.431395,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.105611,
        "recall": 0.144378,
        "f1": 0.113872,
        "accuracy": 0.144378,
        "main_score": 0.113872,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.403892,
        "recall": 0.47505,
        "f1": 0.422856,
        "accuracy": 0.47505,
        "main_score": 0.422856,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.291993,
        "recall": 0.334664,
        "f1": 0.301029,
        "accuracy": 0.334664,
        "main_score": 0.301029,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.32177,
        "recall": 0.387891,
        "f1": 0.338981,
        "accuracy": 0.387891,
        "main_score": 0.338981,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.389732,
        "recall": 0.449767,
        "f1": 0.404643,
        "accuracy": 0.449767,
        "main_score": 0.404643,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.476254,
        "recall": 0.548237,
        "f1": 0.494467,
        "accuracy": 0.548237,
        "main_score": 0.494467,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.346461,
        "recall": 0.404524,
        "f1": 0.361191,
        "accuracy": 0.404524,
        "main_score": 0.361191,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.26546,
        "recall": 0.329341,
        "f1": 0.28103,
        "accuracy": 0.329341,
        "main_score": 0.28103,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.422289,
        "recall": 0.497671,
        "f1": 0.441473,
        "accuracy": 0.497671,
        "main_score": 0.441473,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.388424,
        "recall": 0.467731,
        "f1": 0.408184,
        "accuracy": 0.467731,
        "main_score": 0.408184,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.427808,
        "recall": 0.502994,
        "f1": 0.446708,
        "accuracy": 0.502994,
        "main_score": 0.446708,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000448,
        "recall": 0.003992,
        "f1": 0.000662,
        "accuracy": 0.003992,
        "main_score": 0.000662,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.41039,
        "recall": 0.479042,
        "f1": 0.427374,
        "accuracy": 0.479042,
        "main_score": 0.427374,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.397084,
        "recall": 0.471058,
        "f1": 0.416325,
        "accuracy": 0.471058,
        "main_score": 0.416325,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.404448,
        "recall": 0.472389,
        "f1": 0.421352,
        "accuracy": 0.472389,
        "main_score": 0.421352,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.310659,
        "recall": 0.39521,
        "f1": 0.331971,
        "accuracy": 0.39521,
        "main_score": 0.331971,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001034,
        "recall": 0.004657,
        "f1": 0.001266,
        "accuracy": 0.004657,
        "main_score": 0.001266,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.334058,
        "recall": 0.410512,
        "f1": 0.353844,
        "accuracy": 0.410512,
        "main_score": 0.353844,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.373709,
        "recall": 0.441783,
        "f1": 0.390233,
        "accuracy": 0.441783,
        "main_score": 0.390233,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.429913,
        "recall": 0.500998,
        "f1": 0.447492,
        "accuracy": 0.500998,
        "main_score": 0.447492,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.674052,
        "recall": 0.744511,
        "f1": 0.695001,
        "accuracy": 0.744511,
        "main_score": 0.695001,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.777035,
        "recall": 0.827013,
        "f1": 0.792536,
        "accuracy": 0.827013,
        "main_score": 0.792536,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.076343,
        "recall": 0.106454,
        "f1": 0.082766,
        "accuracy": 0.106454,
        "main_score": 0.082766,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.405785,
        "recall": 0.49501,
        "f1": 0.430458,
        "accuracy": 0.49501,
        "main_score": 0.430458,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.671868,
        "recall": 0.732535,
        "f1": 0.688463,
        "accuracy": 0.732535,
        "main_score": 0.688463,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.373152,
        "recall": 0.457086,
        "f1": 0.395897,
        "accuracy": 0.457086,
        "main_score": 0.395897,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.726453,
        "recall": 0.781104,
        "f1": 0.742744,
        "accuracy": 0.781104,
        "main_score": 0.742744,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.769267,
        "recall": 0.821025,
        "f1": 0.784891,
        "accuracy": 0.821025,
        "main_score": 0.784891,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.683378,
        "recall": 0.747838,
        "f1": 0.70212,
        "accuracy": 0.747838,
        "main_score": 0.70212,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.345987,
        "recall": 0.430472,
        "f1": 0.368827,
        "accuracy": 0.430472,
        "main_score": 0.368827,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.704365,
        "recall": 0.765802,
        "f1": 0.722326,
        "accuracy": 0.765802,
        "main_score": 0.722326,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.7617,
        "recall": 0.815702,
        "f1": 0.778402,
        "accuracy": 0.815702,
        "main_score": 0.778402,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.753765,
        "recall": 0.807053,
        "f1": 0.770248,
        "accuracy": 0.807053,
        "main_score": 0.770248,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.0001,
        "recall": 0.003327,
        "f1": 0.000189,
        "accuracy": 0.003327,
        "main_score": 0.000189,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.720311,
        "recall": 0.781104,
        "f1": 0.738602,
        "accuracy": 0.781104,
        "main_score": 0.738602,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.75845,
        "recall": 0.812375,
        "f1": 0.774658,
        "accuracy": 0.812375,
        "main_score": 0.774658,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.705723,
        "recall": 0.769128,
        "f1": 0.724475,
        "accuracy": 0.769128,
        "main_score": 0.724475,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.571458,
        "recall": 0.65336,
        "f1": 0.595442,
        "accuracy": 0.65336,
        "main_score": 0.595442,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000442,
        "recall": 0.005323,
        "f1": 0.000652,
        "accuracy": 0.005323,
        "main_score": 0.000652,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.313385,
        "recall": 0.39654,
        "f1": 0.334364,
        "accuracy": 0.39654,
        "main_score": 0.334364,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.772,
        "recall": 0.825682,
        "f1": 0.788357,
        "accuracy": 0.825682,
        "main_score": 0.788357,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.753443,
        "recall": 0.806387,
        "f1": 0.769464,
        "accuracy": 0.806387,
        "main_score": 0.769464,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.772067,
        "recall": 0.822355,
        "f1": 0.787219,
        "accuracy": 0.822355,
        "main_score": 0.787219,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.866401,
        "recall": 0.898204,
        "f1": 0.876225,
        "accuracy": 0.898204,
        "main_score": 0.876225,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.077586,
        "recall": 0.112442,
        "f1": 0.085193,
        "accuracy": 0.112442,
        "main_score": 0.085193,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.4754,
        "recall": 0.558882,
        "f1": 0.498043,
        "accuracy": 0.558882,
        "main_score": 0.498043,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.75548,
        "recall": 0.803061,
        "f1": 0.768418,
        "accuracy": 0.803061,
        "main_score": 0.768418,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.437959,
        "recall": 0.516966,
        "f1": 0.458519,
        "accuracy": 0.516966,
        "main_score": 0.458519,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.817388,
        "recall": 0.852961,
        "f1": 0.827805,
        "accuracy": 0.852961,
        "main_score": 0.827805,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.841606,
        "recall": 0.875582,
        "f1": 0.851941,
        "accuracy": 0.875582,
        "main_score": 0.851941,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.731295,
        "recall": 0.786427,
        "f1": 0.746902,
        "accuracy": 0.786427,
        "main_score": 0.746902,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.386972,
        "recall": 0.465735,
        "f1": 0.407201,
        "accuracy": 0.465735,
        "main_score": 0.407201,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.778138,
        "recall": 0.825682,
        "f1": 0.792145,
        "accuracy": 0.825682,
        "main_score": 0.792145,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.832651,
        "recall": 0.867598,
        "f1": 0.843129,
        "accuracy": 0.867598,
        "main_score": 0.843129,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.839344,
        "recall": 0.87159,
        "f1": 0.84939,
        "accuracy": 0.87159,
        "main_score": 0.84939,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 7.2e-05,
        "recall": 0.001996,
        "f1": 0.000133,
        "accuracy": 0.001996,
        "main_score": 0.000133,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.832579,
        "recall": 0.870259,
        "f1": 0.84388,
        "accuracy": 0.870259,
        "main_score": 0.84388,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.822512,
        "recall": 0.865602,
        "f1": 0.83544,
        "accuracy": 0.865602,
        "main_score": 0.83544,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.780151,
        "recall": 0.83167,
        "f1": 0.795368,
        "accuracy": 0.83167,
        "main_score": 0.795368,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.674503,
        "recall": 0.739854,
        "f1": 0.694103,
        "accuracy": 0.739854,
        "main_score": 0.694103,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000325,
        "recall": 0.005323,
        "f1": 0.00053,
        "accuracy": 0.005323,
        "main_score": 0.00053,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.376805,
        "recall": 0.451763,
        "f1": 0.396781,
        "accuracy": 0.451763,
        "main_score": 0.396781,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.769372,
        "recall": 0.819029,
        "f1": 0.784466,
        "accuracy": 0.819029,
        "main_score": 0.784466,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.843191,
        "recall": 0.878909,
        "f1": 0.853905,
        "accuracy": 0.878909,
        "main_score": 0.853905,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.848749,
        "recall": 0.882236,
        "f1": 0.85822,
        "accuracy": 0.882236,
        "main_score": 0.85822,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.909459,
        "recall": 0.93147,
        "f1": 0.916168,
        "accuracy": 0.93147,
        "main_score": 0.916168,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.094369,
        "recall": 0.130406,
        "f1": 0.101763,
        "accuracy": 0.130406,
        "main_score": 0.101763,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.572467,
        "recall": 0.655356,
        "f1": 0.595617,
        "accuracy": 0.655356,
        "main_score": 0.595617,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.859609,
        "recall": 0.896208,
        "f1": 0.870664,
        "accuracy": 0.896208,
        "main_score": 0.870664,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.465566,
        "recall": 0.550233,
        "f1": 0.487979,
        "accuracy": 0.550233,
        "main_score": 0.487979,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.883965,
        "recall": 0.912176,
        "f1": 0.892371,
        "accuracy": 0.912176,
        "main_score": 0.892371,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.915735,
        "recall": 0.936793,
        "f1": 0.9222,
        "accuracy": 0.936793,
        "main_score": 0.9222,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.719707,
        "recall": 0.776447,
        "f1": 0.735558,
        "accuracy": 0.776447,
        "main_score": 0.735558,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.501449,
        "recall": 0.578177,
        "f1": 0.522047,
        "accuracy": 0.578177,
        "main_score": 0.522047,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.866068,
        "recall": 0.9002,
        "f1": 0.876593,
        "accuracy": 0.9002,
        "main_score": 0.876593,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.844921,
        "recall": 0.883566,
        "f1": 0.85662,
        "accuracy": 0.883566,
        "main_score": 0.85662,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.887835,
        "recall": 0.914837,
        "f1": 0.89623,
        "accuracy": 0.914837,
        "main_score": 0.89623,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 5e-05,
        "recall": 0.002661,
        "f1": 9.6e-05,
        "accuracy": 0.002661,
        "main_score": 9.6e-05,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.88742,
        "recall": 0.915502,
        "f1": 0.895819,
        "accuracy": 0.915502,
        "main_score": 0.895819,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.878321,
        "recall": 0.909514,
        "f1": 0.887549,
        "accuracy": 0.909514,
        "main_score": 0.887549,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.873775,
        "recall": 0.904857,
        "f1": 0.883367,
        "accuracy": 0.904857,
        "main_score": 0.883367,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.720681,
        "recall": 0.78177,
        "f1": 0.738929,
        "accuracy": 0.78177,
        "main_score": 0.738929,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000112,
        "recall": 0.003327,
        "f1": 0.00021,
        "accuracy": 0.003327,
        "main_score": 0.00021,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.426503,
        "recall": 0.508982,
        "f1": 0.447953,
        "accuracy": 0.508982,
        "main_score": 0.447953,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.764926,
        "recall": 0.813041,
        "f1": 0.779175,
        "accuracy": 0.813041,
        "main_score": 0.779175,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.864538,
        "recall": 0.896873,
        "f1": 0.874264,
        "accuracy": 0.896873,
        "main_score": 0.874264,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 925.8284032344818,
  "kg_co2_emissions": null
}