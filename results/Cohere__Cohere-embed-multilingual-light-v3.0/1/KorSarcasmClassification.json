{
  "dataset_revision": "3d96e36e10a88d5b7a3f617cf8362d997504494b",
  "task_name": "KorSarcasmClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.555322,
        "f1": 0.550984,
        "f1_weighted": 0.551014,
        "ap": 0.531285,
        "ap_weighted": 0.531285,
        "scores_per_experiment": [
          {
            "accuracy": 0.605957,
            "f1": 0.603972,
            "f1_weighted": 0.604027,
            "ap": 0.564975,
            "ap_weighted": 0.564975
          },
          {
            "accuracy": 0.527344,
            "f1": 0.526964,
            "f1_weighted": 0.526991,
            "ap": 0.513458,
            "ap_weighted": 0.513458
          },
          {
            "accuracy": 0.563965,
            "f1": 0.550769,
            "f1_weighted": 0.55092,
            "ap": 0.536994,
            "ap_weighted": 0.536994
          },
          {
            "accuracy": 0.532227,
            "f1": 0.532065,
            "f1_weighted": 0.532082,
            "ap": 0.516196,
            "ap_weighted": 0.516196
          },
          {
            "accuracy": 0.522949,
            "f1": 0.507651,
            "f1_weighted": 0.507821,
            "ap": 0.511115,
            "ap_weighted": 0.511115
          },
          {
            "accuracy": 0.602539,
            "f1": 0.601627,
            "f1_weighted": 0.601664,
            "ap": 0.561851,
            "ap_weighted": 0.561851
          },
          {
            "accuracy": 0.588379,
            "f1": 0.586419,
            "f1_weighted": 0.586363,
            "ap": 0.550169,
            "ap_weighted": 0.550169
          },
          {
            "accuracy": 0.57666,
            "f1": 0.567814,
            "f1_weighted": 0.567693,
            "ap": 0.542099,
            "ap_weighted": 0.542099
          },
          {
            "accuracy": 0.497559,
            "f1": 0.497443,
            "f1_weighted": 0.497429,
            "ap": 0.497824,
            "ap_weighted": 0.497824
          },
          {
            "accuracy": 0.535645,
            "f1": 0.535117,
            "f1_weighted": 0.535147,
            "ap": 0.518171,
            "ap_weighted": 0.518171
          }
        ],
        "main_score": 0.555322,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ]
      }
    ]
  },
  "evaluation_time": 142.98700213432312,
  "kg_co2_emissions": null
}