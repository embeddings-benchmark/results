{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.913037,
        "f1": 0.912839,
        "f1_weighted": 0.912848,
        "ap": 0.870138,
        "ap_weighted": 0.870138,
        "scores_per_experiment": [
          {
            "accuracy": 0.935059,
            "f1": 0.935027,
            "f1_weighted": 0.935031,
            "ap": 0.900201,
            "ap_weighted": 0.900201
          },
          {
            "accuracy": 0.915527,
            "f1": 0.915503,
            "f1_weighted": 0.915507,
            "ap": 0.876111,
            "ap_weighted": 0.876111
          },
          {
            "accuracy": 0.929199,
            "f1": 0.929196,
            "f1_weighted": 0.929198,
            "ap": 0.897943,
            "ap_weighted": 0.897943
          },
          {
            "accuracy": 0.881836,
            "f1": 0.881795,
            "f1_weighted": 0.881789,
            "ap": 0.843895,
            "ap_weighted": 0.843895
          },
          {
            "accuracy": 0.921387,
            "f1": 0.921334,
            "f1_weighted": 0.92134,
            "ap": 0.880871,
            "ap_weighted": 0.880871
          },
          {
            "accuracy": 0.920898,
            "f1": 0.920855,
            "f1_weighted": 0.92086,
            "ap": 0.881032,
            "ap_weighted": 0.881032
          },
          {
            "accuracy": 0.900391,
            "f1": 0.900092,
            "f1_weighted": 0.900108,
            "ap": 0.845936,
            "ap_weighted": 0.845936
          },
          {
            "accuracy": 0.927734,
            "f1": 0.927569,
            "f1_weighted": 0.927579,
            "ap": 0.882093,
            "ap_weighted": 0.882093
          },
          {
            "accuracy": 0.926758,
            "f1": 0.92674,
            "f1_weighted": 0.926743,
            "ap": 0.891378,
            "ap_weighted": 0.891378
          },
          {
            "accuracy": 0.871582,
            "f1": 0.870282,
            "f1_weighted": 0.87032,
            "ap": 0.80192,
            "ap_weighted": 0.80192
          }
        ],
        "main_score": 0.913037,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.911768,
        "f1": 0.911562,
        "f1_weighted": 0.911567,
        "ap": 0.869471,
        "ap_weighted": 0.869471,
        "scores_per_experiment": [
          {
            "accuracy": 0.930664,
            "f1": 0.930651,
            "f1_weighted": 0.930653,
            "ap": 0.896802,
            "ap_weighted": 0.896802
          },
          {
            "accuracy": 0.913086,
            "f1": 0.913065,
            "f1_weighted": 0.913067,
            "ap": 0.872942,
            "ap_weighted": 0.872942
          },
          {
            "accuracy": 0.930664,
            "f1": 0.930662,
            "f1_weighted": 0.930663,
            "ap": 0.899973,
            "ap_weighted": 0.899973
          },
          {
            "accuracy": 0.881348,
            "f1": 0.881188,
            "f1_weighted": 0.88118,
            "ap": 0.848692,
            "ap_weighted": 0.848692
          },
          {
            "accuracy": 0.92041,
            "f1": 0.920384,
            "f1_weighted": 0.920387,
            "ap": 0.881708,
            "ap_weighted": 0.881708
          },
          {
            "accuracy": 0.923828,
            "f1": 0.923814,
            "f1_weighted": 0.923816,
            "ap": 0.887699,
            "ap_weighted": 0.887699
          },
          {
            "accuracy": 0.899414,
            "f1": 0.899056,
            "f1_weighted": 0.899068,
            "ap": 0.843064,
            "ap_weighted": 0.843064
          },
          {
            "accuracy": 0.923828,
            "f1": 0.923674,
            "f1_weighted": 0.923681,
            "ap": 0.877577,
            "ap_weighted": 0.877577
          },
          {
            "accuracy": 0.920898,
            "f1": 0.920874,
            "f1_weighted": 0.920877,
            "ap": 0.882511,
            "ap_weighted": 0.882511
          },
          {
            "accuracy": 0.873535,
            "f1": 0.872255,
            "f1_weighted": 0.87228,
            "ap": 0.803744,
            "ap_weighted": 0.803744
          }
        ],
        "main_score": 0.911768,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 32.55742001533508,
  "kg_co2_emissions": null
}