{
  "dataset_revision": "e6b647fcb6299a2f686f742f4d4c023e553ea67e",
  "evaluation_time": 98.64934349060059,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.89",
  "scores": {
    "devtest": [
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "ace_Arab-rus_Cyrl",
        "languages": [
          "ace-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010003857200684078,
        "hf_subset": "bam_Latn-rus_Cyrl",
        "languages": [
          "bam-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0010003857200684078,
        "precision": 0.0009942890208998203,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 1.9547819831654174e-06,
        "hf_subset": "dzo_Tibt-rus_Cyrl",
        "languages": [
          "dzo-Tibt",
          "rus-Cyrl"
        ],
        "main_score": 1.9547819831654174e-06,
        "precision": 9.78358705435761e-07,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0032959395559648834,
        "hf_subset": "hin_Deva-rus_Cyrl",
        "languages": [
          "hin-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0032959395559648834,
        "precision": 0.003163122444275604,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.007781489340050396,
        "hf_subset": "khm_Khmr-rus_Cyrl",
        "languages": [
          "khm-Khmr",
          "rus-Cyrl"
        ],
        "main_score": 0.007781489340050396,
        "precision": 0.007127158116917888,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0032490539272945506,
        "hf_subset": "mag_Deva-rus_Cyrl",
        "languages": [
          "mag-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0032490539272945506,
        "precision": 0.0031302689405456204,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.002068996136489714,
        "hf_subset": "pap_Latn-rus_Cyrl",
        "languages": [
          "pap-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002068996136489714,
        "precision": 0.0016088214703444334,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.002571949991957664,
        "hf_subset": "sot_Latn-rus_Cyrl",
        "languages": [
          "sot-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002571949991957664,
        "precision": 0.0023287677499634024,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009902247841497396,
        "hf_subset": "tur_Latn-rus_Cyrl",
        "languages": [
          "tur-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0009902247841497396,
        "precision": 0.000989184636680509,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0011306362009686818,
        "hf_subset": "ace_Latn-rus_Cyrl",
        "languages": [
          "ace-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0011306362009686818,
        "precision": 0.0010631657199501147,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001978360514166141,
        "hf_subset": "ban_Latn-rus_Cyrl",
        "languages": [
          "ban-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001978360514166141,
        "precision": 0.0019773236410186076,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 1.9509225912934225e-06,
        "hf_subset": "ell_Grek-rus_Cyrl",
        "languages": [
          "ell-Grek",
          "rus-Cyrl"
        ],
        "main_score": 1.9509225912934225e-06,
        "precision": 9.76425190207627e-07,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0019785587904865435,
        "hf_subset": "hne_Deva-rus_Cyrl",
        "languages": [
          "hne-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0019785587904865435,
        "precision": 0.0019774229977596036,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0021176317323878136,
        "hf_subset": "kik_Latn-rus_Cyrl",
        "languages": [
          "kik-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0021176317323878136,
        "precision": 0.002049511986152787,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0042020266604665575,
        "hf_subset": "mai_Deva-rus_Cyrl",
        "languages": [
          "mai-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0042020266604665575,
        "precision": 0.004094944799132583,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0011072095471072454,
        "hf_subset": "pbt_Arab-rus_Cyrl",
        "languages": [
          "pbt-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0011072095471072454,
        "precision": 0.0010513108038770135,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0018362297643755964,
        "hf_subset": "spa_Latn-rus_Cyrl",
        "languages": [
          "spa-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0018362297643755964,
        "precision": 0.0015858719455757043,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.003825644641226783,
        "hf_subset": "twi_Latn-rus_Cyrl",
        "languages": [
          "twi-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003825644641226783,
        "precision": 0.003495857036870036,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0016728348840825212,
        "hf_subset": "acm_Arab-rus_Cyrl",
        "languages": [
          "acm-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0016728348840825212,
        "precision": 0.0014952597290331477,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.010646494767720418,
        "hf_subset": "bel_Cyrl-rus_Cyrl",
        "languages": [
          "bel-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.010646494767720418,
        "precision": 0.00980571641592875,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.2549407114624506,
        "f1": 0.21670041718227534,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.21670041718227534,
        "precision": 0.20736762287409055,
        "recall": 0.2549407114624506
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0018859638219769473,
        "hf_subset": "hrv_Latn-rus_Cyrl",
        "languages": [
          "hrv-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0018859638219769473,
        "precision": 0.0015244665820113388,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010189392611938393,
        "hf_subset": "kin_Latn-rus_Cyrl",
        "languages": [
          "kin-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0010189392611938393,
        "precision": 0.0010037525547526775,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.003158580889352081,
        "hf_subset": "mal_Mlym-rus_Cyrl",
        "languages": [
          "mal-Mlym",
          "rus-Cyrl"
        ],
        "main_score": 0.003158580889352081,
        "precision": 0.0030676013590088427,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0013363448146056843,
        "hf_subset": "pes_Arab-rus_Cyrl",
        "languages": [
          "pes-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0013363448146056843,
        "precision": 0.0009057971014492754,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.003960661100466554,
        "hf_subset": "srd_Latn-rus_Cyrl",
        "languages": [
          "srd-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003960661100466554,
        "precision": 0.0033650336923351913,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.006213269219979395,
        "hf_subset": "tzm_Tfng-rus_Cyrl",
        "languages": [
          "tzm-Tfng",
          "rus-Cyrl"
        ],
        "main_score": 0.006213269219979395,
        "precision": 0.006094589790241964,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0019960146837780927,
        "hf_subset": "acq_Arab-rus_Cyrl",
        "languages": [
          "acq-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0019960146837780927,
        "precision": 0.00198620756036456,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001022390340810556,
        "hf_subset": "bem_Latn-rus_Cyrl",
        "languages": [
          "bem-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001022390340810556,
        "precision": 0.001005529017489994,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0028794203460841892,
        "hf_subset": "epo_Latn-rus_Cyrl",
        "languages": [
          "epo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0028794203460841892,
        "precision": 0.0024743020566269334,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.002992321112993886,
        "hf_subset": "hun_Latn-rus_Cyrl",
        "languages": [
          "hun-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002992321112993886,
        "precision": 0.0029784712240548614,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009900951428705338,
        "hf_subset": "kir_Cyrl-rus_Cyrl",
        "languages": [
          "kir-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.0009900951428705338,
        "precision": 0.0009891196834817012,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0032375226528150065,
        "hf_subset": "mar_Deva-rus_Cyrl",
        "languages": [
          "mar-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0032375226528150065,
        "precision": 0.003113363041066048,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001978286899656002,
        "hf_subset": "plt_Latn-rus_Cyrl",
        "languages": [
          "plt-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001978286899656002,
        "precision": 0.001977286757690673,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.042490118577075096,
        "f1": 0.034705515613505565,
        "hf_subset": "srp_Cyrl-rus_Cyrl",
        "languages": [
          "srp-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.034705515613505565,
        "precision": 0.033631854543165064,
        "recall": 0.042490118577075096
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0048789657570609025,
        "hf_subset": "uig_Arab-rus_Cyrl",
        "languages": [
          "uig-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0048789657570609025,
        "precision": 0.004590006669543248,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009936472634789215,
        "hf_subset": "aeb_Arab-rus_Cyrl",
        "languages": [
          "aeb-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0009936472634789215,
        "precision": 0.0009909024664914877,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001978937315966788,
        "hf_subset": "ben_Beng-rus_Cyrl",
        "languages": [
          "ben-Beng",
          "rus-Cyrl"
        ],
        "main_score": 0.001978937315966788,
        "precision": 0.0019776127332228315,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0021275306170572632,
        "hf_subset": "est_Latn-rus_Cyrl",
        "languages": [
          "est-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0021275306170572632,
        "precision": 0.0017422288031683894,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.003748290875491738,
        "hf_subset": "hye_Armn-rus_Cyrl",
        "languages": [
          "hye-Armn",
          "rus-Cyrl"
        ],
        "main_score": 0.003748290875491738,
        "precision": 0.0034518236414628647,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0019933053300991567,
        "hf_subset": "kmb_Latn-rus_Cyrl",
        "languages": [
          "kmb-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0019933053300991567,
        "precision": 0.001984849070285652,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 3.5673006949101753e-06,
        "hf_subset": "min_Arab-rus_Cyrl",
        "languages": [
          "min-Arab",
          "rus-Cyrl"
        ],
        "main_score": 3.5673006949101753e-06,
        "precision": 1.7868757549550065e-06,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0013100404801878222,
        "hf_subset": "pol_Latn-rus_Cyrl",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0013100404801878222,
        "precision": 0.0011620154110272688,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010427031208256263,
        "hf_subset": "ssw_Latn-rus_Cyrl",
        "languages": [
          "ssw-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0010427031208256263,
        "precision": 0.0010161271621421236,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.17687747035573123,
        "f1": 0.1453446297279587,
        "hf_subset": "ukr_Cyrl-rus_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.1453446297279587,
        "precision": 0.13842799149533636,
        "recall": 0.17687747035573123
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.004949548955994391,
        "hf_subset": "afr_Latn-rus_Cyrl",
        "languages": [
          "afr-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.004949548955994391,
        "precision": 0.004298168790605958,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0050840705188531276,
        "hf_subset": "bho_Deva-rus_Cyrl",
        "languages": [
          "bho-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0050840705188531276,
        "precision": 0.005015318765765533,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.003903522974417044,
        "hf_subset": "eus_Latn-rus_Cyrl",
        "languages": [
          "eus-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003903522974417044,
        "precision": 0.0035659624970283844,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0012830238660022472,
        "hf_subset": "ibo_Latn-rus_Cyrl",
        "languages": [
          "ibo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0012830238660022472,
        "precision": 0.0011591337997987614,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0021768730979927417,
        "hf_subset": "kmr_Latn-rus_Cyrl",
        "languages": [
          "kmr-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0021768730979927417,
        "precision": 0.002085652054237126,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.001583035425242197,
        "hf_subset": "min_Latn-rus_Cyrl",
        "languages": [
          "min-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001583035425242197,
        "precision": 0.0013191803800932003,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.004024495738835267,
        "hf_subset": "por_Latn-rus_Cyrl",
        "languages": [
          "por-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.004024495738835267,
        "precision": 0.00333182691938218,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.002088257097604684,
        "hf_subset": "sun_Latn-rus_Cyrl",
        "languages": [
          "sun-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002088257097604684,
        "precision": 0.002035501266967536,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.002021162395418909,
        "hf_subset": "umb_Latn-rus_Cyrl",
        "languages": [
          "umb-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002021162395418909,
        "precision": 0.001998996589468842,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0011066949237474365,
        "hf_subset": "ajp_Arab-rus_Cyrl",
        "languages": [
          "ajp-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0011066949237474365,
        "precision": 0.0010498799167465204,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "bjn_Arab-rus_Cyrl",
        "languages": [
          "bjn-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0022042559987224017,
        "hf_subset": "ewe_Latn-rus_Cyrl",
        "languages": [
          "ewe-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0022042559987224017,
        "precision": 0.002104003421927056,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.003446400382049003,
        "hf_subset": "ilo_Latn-rus_Cyrl",
        "languages": [
          "ilo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003446400382049003,
        "precision": 0.0032399212180487186,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.002966751918158568,
        "hf_subset": "knc_Arab-rus_Cyrl",
        "languages": [
          "knc-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.002966751918158568,
        "precision": 0.002965590767096375,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.05533596837944664,
        "f1": 0.045640397310556045,
        "hf_subset": "mkd_Cyrl-rus_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.045640397310556045,
        "precision": 0.04394640479826707,
        "recall": 0.05533596837944664
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0019825985932389596,
        "hf_subset": "prs_Arab-rus_Cyrl",
        "languages": [
          "prs-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0019825985932389596,
        "precision": 0.0019794517077125775,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0013793303148625488,
        "hf_subset": "swe_Latn-rus_Cyrl",
        "languages": [
          "swe-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0013793303148625488,
        "precision": 0.0011982679940380197,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0016698510350874622,
        "hf_subset": "urd_Arab-rus_Cyrl",
        "languages": [
          "urd-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0016698510350874622,
        "precision": 0.0014937437894257108,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.005609675073856027,
        "hf_subset": "aka_Latn-rus_Cyrl",
        "languages": [
          "aka-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.005609675073856027,
        "precision": 0.005055621623716252,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0021759420830932304,
        "hf_subset": "bjn_Latn-rus_Cyrl",
        "languages": [
          "bjn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0021759420830932304,
        "precision": 0.0020870937355141296,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0009738003351938853,
        "hf_subset": "fao_Latn-rus_Cyrl",
        "languages": [
          "fao-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0009738003351938853,
        "precision": 0.0006194359804874179,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0027030680691635233,
        "hf_subset": "ind_Latn-rus_Cyrl",
        "languages": [
          "ind-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0027030680691635233,
        "precision": 0.002422022684310019,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0019840652329526005,
        "hf_subset": "knc_Latn-rus_Cyrl",
        "languages": [
          "knc-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0019840652329526005,
        "precision": 0.0019801902857410677,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.00212471786712968,
        "hf_subset": "mlt_Latn-rus_Cyrl",
        "languages": [
          "mlt-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.00212471786712968,
        "precision": 0.001694767807356674,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.000990478326278511,
        "hf_subset": "quy_Latn-rus_Cyrl",
        "languages": [
          "quy-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.000990478326278511,
        "precision": 0.0009893116916528286,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 8.208165839702958e-05,
        "hf_subset": "swh_Latn-rus_Cyrl",
        "languages": [
          "swh-Latn",
          "rus-Cyrl"
        ],
        "main_score": 8.208165839702958e-05,
        "precision": 4.245861014282231e-05,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 1.9762845849802374e-06,
        "hf_subset": "uzn_Latn-rus_Cyrl",
        "languages": [
          "uzn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 1.9762845849802374e-06,
        "precision": 9.891314239140326e-07,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0036633143556076943,
        "hf_subset": "als_Latn-rus_Cyrl",
        "languages": [
          "als-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0036633143556076943,
        "precision": 0.003380120510862968,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009901527549366906,
        "hf_subset": "bod_Tibt-rus_Cyrl",
        "languages": [
          "bod-Tibt",
          "rus-Cyrl"
        ],
        "main_score": 0.0009901527549366906,
        "precision": 0.0009891485473704548,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0018393750743426968,
        "hf_subset": "fij_Latn-rus_Cyrl",
        "languages": [
          "fij-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0018393750743426968,
        "precision": 0.0015291268852643224,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0013639561667594209,
        "hf_subset": "isl_Latn-rus_Cyrl",
        "languages": [
          "isl-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0013639561667594209,
        "precision": 0.001190100552589396,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010053723911080947,
        "hf_subset": "kon_Latn-rus_Cyrl",
        "languages": [
          "kon-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0010053723911080947,
        "precision": 0.0009968070166650577,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.004389470769652772,
        "hf_subset": "mni_Beng-rus_Cyrl",
        "languages": [
          "mni-Beng",
          "rus-Cyrl"
        ],
        "main_score": 0.004389470769652772,
        "precision": 0.00420088306428933,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.004605149554982795,
        "hf_subset": "ron_Latn-rus_Cyrl",
        "languages": [
          "ron-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.004605149554982795,
        "precision": 0.004009735281313714,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.000745899852610346,
        "hf_subset": "szl_Latn-rus_Cyrl",
        "languages": [
          "szl-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.000745899852610346,
        "precision": 0.00041358980699794163,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.00329188740029684,
        "hf_subset": "vec_Latn-rus_Cyrl",
        "languages": [
          "vec-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.00329188740029684,
        "precision": 0.0027750183538562895,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.003455626759634659,
        "hf_subset": "amh_Ethi-rus_Cyrl",
        "languages": [
          "amh-Ethi",
          "rus-Cyrl"
        ],
        "main_score": 0.003455626759634659,
        "precision": 0.00324455318178206,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0017454654768244348,
        "hf_subset": "bos_Latn-rus_Cyrl",
        "languages": [
          "bos-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0017454654768244348,
        "precision": 0.0014262285480335453,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0011956279957654765,
        "hf_subset": "fin_Latn-rus_Cyrl",
        "languages": [
          "fin-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0011956279957654765,
        "precision": 0.0011010146660163608,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.007309698052021969,
        "hf_subset": "ita_Latn-rus_Cyrl",
        "languages": [
          "ita-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.007309698052021969,
        "precision": 0.006628638646026246,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.005084131539018035,
        "hf_subset": "kor_Hang-rus_Cyrl",
        "languages": [
          "kor-Hang",
          "rus-Cyrl"
        ],
        "main_score": 0.005084131539018035,
        "precision": 0.005016618312235936,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.00313212073156569,
        "hf_subset": "mos_Latn-rus_Cyrl",
        "languages": [
          "mos-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.00313212073156569,
        "precision": 0.00280124051714284,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009902719094997956,
        "hf_subset": "run_Latn-rus_Cyrl",
        "languages": [
          "run-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0009902719094997956,
        "precision": 0.000989208249655696,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.00642750120339799,
        "hf_subset": "tam_Taml-rus_Cyrl",
        "languages": [
          "tam-Taml",
          "rus-Cyrl"
        ],
        "main_score": 0.00642750120339799,
        "precision": 0.005920903603822217,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010009255897969573,
        "hf_subset": "vie_Latn-rus_Cyrl",
        "languages": [
          "vie-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0010009255897969573,
        "precision": 0.000994562246173071,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0016532789323813165,
        "hf_subset": "apc_Arab-rus_Cyrl",
        "languages": [
          "apc-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0016532789323813165,
        "precision": 0.0014854113102319097,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0032707362269947513,
        "hf_subset": "bug_Latn-rus_Cyrl",
        "languages": [
          "bug-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0032707362269947513,
        "precision": 0.003141228364405749,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0004982849726522667,
        "hf_subset": "fon_Latn-rus_Cyrl",
        "languages": [
          "fon-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0004982849726522667,
        "precision": 0.00033149217931826625,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0025080444664685314,
        "hf_subset": "jav_Latn-rus_Cyrl",
        "languages": [
          "jav-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0025080444664685314,
        "precision": 0.0022820405497925907,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.022395647338439104,
        "hf_subset": "lao_Laoo-rus_Cyrl",
        "languages": [
          "lao-Laoo",
          "rus-Cyrl"
        ],
        "main_score": 0.022395647338439104,
        "precision": 0.021473710955349088,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0004969229277529673,
        "hf_subset": "mri_Latn-rus_Cyrl",
        "languages": [
          "mri-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0004969229277529673,
        "precision": 0.00033080871545309844,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "rus_Cyrl-ace_Arab",
        "languages": [
          "rus-Cyrl",
          "ace-Arab"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.004031714441255738,
        "hf_subset": "rus_Cyrl-bam_Latn",
        "languages": [
          "rus-Cyrl",
          "bam-Latn"
        ],
        "main_score": 0.004031714441255738,
        "precision": 0.003281578119850706,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 2.8273026966813123e-06,
        "hf_subset": "rus_Cyrl-dzo_Tibt",
        "languages": [
          "rus-Cyrl",
          "dzo-Tibt"
        ],
        "main_score": 2.8273026966813123e-06,
        "precision": 1.4156766368053274e-06,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0007318005394286946,
        "hf_subset": "rus_Cyrl-hin_Deva",
        "languages": [
          "rus-Cyrl",
          "hin-Deva"
        ],
        "main_score": 0.0007318005394286946,
        "precision": 0.0004391849478516808,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.01196364144410595,
        "hf_subset": "rus_Cyrl-khm_Khmr",
        "languages": [
          "rus-Cyrl",
          "khm-Khmr"
        ],
        "main_score": 0.01196364144410595,
        "precision": 0.010113205367978282,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0015379118080702245,
        "hf_subset": "rus_Cyrl-mag_Deva",
        "languages": [
          "rus-Cyrl",
          "mag-Deva"
        ],
        "main_score": 0.0015379118080702245,
        "precision": 0.0013178948340727917,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.004267272945647515,
        "hf_subset": "rus_Cyrl-pap_Latn",
        "languages": [
          "rus-Cyrl",
          "pap-Latn"
        ],
        "main_score": 0.004267272945647515,
        "precision": 0.0031153132548243537,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0029320265538294553,
        "hf_subset": "rus_Cyrl-sot_Latn",
        "languages": [
          "rus-Cyrl",
          "sot-Latn"
        ],
        "main_score": 0.0029320265538294553,
        "precision": 0.002028724666323524,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0020822676071939215,
        "hf_subset": "rus_Cyrl-tur_Latn",
        "languages": [
          "rus-Cyrl",
          "tur-Latn"
        ],
        "main_score": 0.0020822676071939215,
        "precision": 0.001341102397871964,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.0020923107509884086,
        "hf_subset": "rus_Cyrl-ace_Latn",
        "languages": [
          "rus-Cyrl",
          "ace-Latn"
        ],
        "main_score": 0.0020923107509884086,
        "precision": 0.0013651498561563975,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.006100216489498593,
        "hf_subset": "rus_Cyrl-ban_Latn",
        "languages": [
          "rus-Cyrl",
          "ban-Latn"
        ],
        "main_score": 0.006100216489498593,
        "precision": 0.004997318794653999,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 1.0085269562339556e-05,
        "hf_subset": "rus_Cyrl-ell_Grek",
        "languages": [
          "rus-Cyrl",
          "ell-Grek"
        ],
        "main_score": 1.0085269562339556e-05,
        "precision": 5.057711392481998e-06,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0025865408603098733,
        "hf_subset": "rus_Cyrl-hne_Deva",
        "languages": [
          "rus-Cyrl",
          "hne-Deva"
        ],
        "main_score": 0.0025865408603098733,
        "precision": 0.002084387914221797,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.006519583497960042,
        "hf_subset": "rus_Cyrl-kik_Latn",
        "languages": [
          "rus-Cyrl",
          "kik-Latn"
        ],
        "main_score": 0.006519583497960042,
        "precision": 0.005297789374940733,
        "recall": 0.019762845849802372
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0008654011602526536,
        "hf_subset": "rus_Cyrl-mai_Deva",
        "languages": [
          "rus-Cyrl",
          "mai-Deva"
        ],
        "main_score": 0.0008654011602526536,
        "precision": 0.0006083807184722388,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0003230910497802418,
        "hf_subset": "rus_Cyrl-pbt_Arab",
        "languages": [
          "rus-Cyrl",
          "pbt-Arab"
        ],
        "main_score": 0.0003230910497802418,
        "precision": 0.00017451852241604136,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0031684075871221433,
        "hf_subset": "rus_Cyrl-spa_Latn",
        "languages": [
          "rus-Cyrl",
          "spa-Latn"
        ],
        "main_score": 0.0031684075871221433,
        "precision": 0.0026991980992188223,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.0031759897953116244,
        "hf_subset": "rus_Cyrl-twi_Latn",
        "languages": [
          "rus-Cyrl",
          "twi-Latn"
        ],
        "main_score": 0.0031759897953116244,
        "precision": 0.002696601092674694,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.00046176647238815313,
        "hf_subset": "rus_Cyrl-acm_Arab",
        "languages": [
          "rus-Cyrl",
          "acm-Arab"
        ],
        "main_score": 0.00046176647238815313,
        "precision": 0.0002671578968221832,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.07312252964426877,
        "f1": 0.041174479811211306,
        "hf_subset": "rus_Cyrl-bel_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bel-Cyrl"
        ],
        "main_score": 0.041174479811211306,
        "precision": 0.03519206168066963,
        "recall": 0.07312252964426877
      },
      {
        "accuracy": 0.3359683794466403,
        "f1": 0.27234586888737083,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.27234586888737083,
        "precision": 0.2551508685874411,
        "recall": 0.3359683794466403
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.002146996116028798,
        "hf_subset": "rus_Cyrl-hrv_Latn",
        "languages": [
          "rus-Cyrl",
          "hrv-Latn"
        ],
        "main_score": 0.002146996116028798,
        "precision": 0.0016412900005083242,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.001339423200003568,
        "hf_subset": "rus_Cyrl-kin_Latn",
        "languages": [
          "rus-Cyrl",
          "kin-Latn"
        ],
        "main_score": 0.001339423200003568,
        "precision": 0.0008825877496344092,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.002307629846742994,
        "hf_subset": "rus_Cyrl-mal_Mlym",
        "languages": [
          "rus-Cyrl",
          "mal-Mlym"
        ],
        "main_score": 0.002307629846742994,
        "precision": 0.0019772678111419193,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.00033766861674165856,
        "hf_subset": "rus_Cyrl-pes_Arab",
        "languages": [
          "rus-Cyrl",
          "pes-Arab"
        ],
        "main_score": 0.00033766861674165856,
        "precision": 0.00020178131701638244,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0020727392176068202,
        "hf_subset": "rus_Cyrl-srd_Latn",
        "languages": [
          "rus-Cyrl",
          "srd-Latn"
        ],
        "main_score": 0.0020727392176068202,
        "precision": 0.0016650506366585826,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.00031152855649336456,
        "hf_subset": "rus_Cyrl-tzm_Tfng",
        "languages": [
          "rus-Cyrl",
          "tzm-Tfng"
        ],
        "main_score": 0.00031152855649336456,
        "precision": 0.000179383012386422,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0004954745036375336,
        "hf_subset": "rus_Cyrl-acq_Arab",
        "languages": [
          "rus-Cyrl",
          "acq-Arab"
        ],
        "main_score": 0.0004954745036375336,
        "precision": 0.00029848840184593746,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0030976717878779497,
        "hf_subset": "rus_Cyrl-bem_Latn",
        "languages": [
          "rus-Cyrl",
          "bem-Latn"
        ],
        "main_score": 0.0030976717878779497,
        "precision": 0.0027284758427280863,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.0066955182260385986,
        "hf_subset": "rus_Cyrl-epo_Latn",
        "languages": [
          "rus-Cyrl",
          "epo-Latn"
        ],
        "main_score": 0.0066955182260385986,
        "precision": 0.005667787496176013,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.005273296208027774,
        "hf_subset": "rus_Cyrl-hun_Latn",
        "languages": [
          "rus-Cyrl",
          "hun-Latn"
        ],
        "main_score": 0.005273296208027774,
        "precision": 0.004698964946036326,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.0266798418972332,
        "f1": 0.010610302285761418,
        "hf_subset": "rus_Cyrl-kir_Cyrl",
        "languages": [
          "rus-Cyrl",
          "kir-Cyrl"
        ],
        "main_score": 0.010610302285761418,
        "precision": 0.008931155716032669,
        "recall": 0.0266798418972332
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0009185524915563121,
        "hf_subset": "rus_Cyrl-mar_Deva",
        "languages": [
          "rus-Cyrl",
          "mar-Deva"
        ],
        "main_score": 0.0009185524915563121,
        "precision": 0.0006380646530467958,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.004040329162230828,
        "hf_subset": "rus_Cyrl-plt_Latn",
        "languages": [
          "rus-Cyrl",
          "plt-Latn"
        ],
        "main_score": 0.004040329162230828,
        "precision": 0.0033920283804803135,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.10573122529644269,
        "f1": 0.06400439160277145,
        "hf_subset": "rus_Cyrl-srp_Cyrl",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ],
        "main_score": 0.06400439160277145,
        "precision": 0.057496202953024524,
        "recall": 0.10573122529644269
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0020923921429904066,
        "hf_subset": "rus_Cyrl-uig_Arab",
        "languages": [
          "rus-Cyrl",
          "uig-Arab"
        ],
        "main_score": 0.0020923921429904066,
        "precision": 0.0020363935416525003,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0013564966362744517,
        "hf_subset": "rus_Cyrl-aeb_Arab",
        "languages": [
          "rus-Cyrl",
          "aeb-Arab"
        ],
        "main_score": 0.0013564966362744517,
        "precision": 0.0011919399438832788,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.00234465291507508,
        "hf_subset": "rus_Cyrl-ben_Beng",
        "languages": [
          "rus-Cyrl",
          "ben-Beng"
        ],
        "main_score": 0.00234465291507508,
        "precision": 0.0019961250773530914,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.004956172455067296,
        "hf_subset": "rus_Cyrl-est_Latn",
        "languages": [
          "rus-Cyrl",
          "est-Latn"
        ],
        "main_score": 0.004956172455067296,
        "precision": 0.004309793798665032,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.003821484212716847,
        "hf_subset": "rus_Cyrl-hye_Armn",
        "languages": [
          "rus-Cyrl",
          "hye-Armn"
        ],
        "main_score": 0.003821484212716847,
        "precision": 0.003247655914468908,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.002421568755031488,
        "hf_subset": "rus_Cyrl-kmb_Latn",
        "languages": [
          "rus-Cyrl",
          "kmb-Latn"
        ],
        "main_score": 0.002421568755031488,
        "precision": 0.0020360654557601667,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 9.0655256191754e-06,
        "hf_subset": "rus_Cyrl-min_Arab",
        "languages": [
          "rus-Cyrl",
          "min-Arab"
        ],
        "main_score": 9.0655256191754e-06,
        "precision": 4.553651117465984e-06,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0009674169839082845,
        "hf_subset": "rus_Cyrl-pol_Latn",
        "languages": [
          "rus-Cyrl",
          "pol-Latn"
        ],
        "main_score": 0.0009674169839082845,
        "precision": 0.0006720761006428557,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0009839685065546162,
        "hf_subset": "rus_Cyrl-ssw_Latn",
        "languages": [
          "rus-Cyrl",
          "ssw-Latn"
        ],
        "main_score": 0.0009839685065546162,
        "precision": 0.0006685910514624758,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.1274703557312253,
        "f1": 0.09235615007707697,
        "hf_subset": "rus_Cyrl-ukr_Cyrl",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ],
        "main_score": 0.09235615007707697,
        "precision": 0.08616723504231691,
        "recall": 0.1274703557312253
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.005348763366810779,
        "hf_subset": "rus_Cyrl-afr_Latn",
        "languages": [
          "rus-Cyrl",
          "afr-Latn"
        ],
        "main_score": 0.005348763366810779,
        "precision": 0.003864071869868529,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 2.8528096036627413e-05,
        "hf_subset": "rus_Cyrl-bho_Deva",
        "languages": [
          "rus-Cyrl",
          "bho-Deva"
        ],
        "main_score": 2.8528096036627413e-05,
        "precision": 1.4373688300344515e-05,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.002434581017423788,
        "hf_subset": "rus_Cyrl-eus_Latn",
        "languages": [
          "rus-Cyrl",
          "eus-Latn"
        ],
        "main_score": 0.002434581017423788,
        "precision": 0.0019214749401915176,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.002384925625901465,
        "hf_subset": "rus_Cyrl-ibo_Latn",
        "languages": [
          "rus-Cyrl",
          "ibo-Latn"
        ],
        "main_score": 0.002384925625901465,
        "precision": 0.0022064046579205786,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.004309201066511751,
        "hf_subset": "rus_Cyrl-kmr_Latn",
        "languages": [
          "rus-Cyrl",
          "kmr-Latn"
        ],
        "main_score": 0.004309201066511751,
        "precision": 0.0037834229961583904,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.005759806144275142,
        "hf_subset": "rus_Cyrl-min_Latn",
        "languages": [
          "rus-Cyrl",
          "min-Latn"
        ],
        "main_score": 0.005759806144275142,
        "precision": 0.005121184767027719,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.006686028156019835,
        "hf_subset": "rus_Cyrl-por_Latn",
        "languages": [
          "rus-Cyrl",
          "por-Latn"
        ],
        "main_score": 0.006686028156019835,
        "precision": 0.005607050397379703,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.0037525135095706997,
        "hf_subset": "rus_Cyrl-sun_Latn",
        "languages": [
          "rus-Cyrl",
          "sun-Latn"
        ],
        "main_score": 0.0037525135095706997,
        "precision": 0.0030467470984686185,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.002177370654667483,
        "hf_subset": "rus_Cyrl-umb_Latn",
        "languages": [
          "rus-Cyrl",
          "umb-Latn"
        ],
        "main_score": 0.002177370654667483,
        "precision": 0.0015125576781666436,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0014315326168143536,
        "hf_subset": "rus_Cyrl-ajp_Arab",
        "languages": [
          "rus-Cyrl",
          "ajp-Arab"
        ],
        "main_score": 0.0014315326168143536,
        "precision": 0.0012594532876863674,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 4.796807245097662e-06,
        "hf_subset": "rus_Cyrl-bjn_Arab",
        "languages": [
          "rus-Cyrl",
          "bjn-Arab"
        ],
        "main_score": 4.796807245097662e-06,
        "precision": 2.404239154477174e-06,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.0044380489801771165,
        "hf_subset": "rus_Cyrl-ewe_Latn",
        "languages": [
          "rus-Cyrl",
          "ewe-Latn"
        ],
        "main_score": 0.0044380489801771165,
        "precision": 0.0035574354470656764,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.00332752309958332,
        "hf_subset": "rus_Cyrl-ilo_Latn",
        "languages": [
          "rus-Cyrl",
          "ilo-Latn"
        ],
        "main_score": 0.00332752309958332,
        "precision": 0.002400187631024771,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0017027828035334057,
        "hf_subset": "rus_Cyrl-knc_Arab",
        "languages": [
          "rus-Cyrl",
          "knc-Arab"
        ],
        "main_score": 0.0017027828035334057,
        "precision": 0.00138495732369313,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.10869565217391304,
        "f1": 0.0660939047358626,
        "hf_subset": "rus_Cyrl-mkd_Cyrl",
        "languages": [
          "rus-Cyrl",
          "mkd-Cyrl"
        ],
        "main_score": 0.0660939047358626,
        "precision": 0.05807062761684588,
        "recall": 0.10869565217391304
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0009962283907337629,
        "hf_subset": "rus_Cyrl-prs_Arab",
        "languages": [
          "rus-Cyrl",
          "prs-Arab"
        ],
        "main_score": 0.0009962283907337629,
        "precision": 0.0009921937915301049,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.007068821027340283,
        "hf_subset": "rus_Cyrl-swe_Latn",
        "languages": [
          "rus-Cyrl",
          "swe-Latn"
        ],
        "main_score": 0.007068821027340283,
        "precision": 0.005618593631746137,
        "recall": 0.019762845849802372
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0002696792746898244,
        "hf_subset": "rus_Cyrl-urd_Arab",
        "languages": [
          "rus-Cyrl",
          "urd-Arab"
        ],
        "main_score": 0.0002696792746898244,
        "precision": 0.00014392629492706108,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.006915556892514685,
        "hf_subset": "rus_Cyrl-aka_Latn",
        "languages": [
          "rus-Cyrl",
          "aka-Latn"
        ],
        "main_score": 0.006915556892514685,
        "precision": 0.006207224245310786,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.004004317537700187,
        "hf_subset": "rus_Cyrl-bjn_Latn",
        "languages": [
          "rus-Cyrl",
          "bjn-Latn"
        ],
        "main_score": 0.004004317537700187,
        "precision": 0.003258923143426663,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.003365950582304042,
        "hf_subset": "rus_Cyrl-fao_Latn",
        "languages": [
          "rus-Cyrl",
          "fao-Latn"
        ],
        "main_score": 0.003365950582304042,
        "precision": 0.0028997987026237776,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.005342219566655696,
        "hf_subset": "rus_Cyrl-ind_Latn",
        "languages": [
          "rus-Cyrl",
          "ind-Latn"
        ],
        "main_score": 0.005342219566655696,
        "precision": 0.004602263607907796,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.0037426629807286458,
        "hf_subset": "rus_Cyrl-knc_Latn",
        "languages": [
          "rus-Cyrl",
          "knc-Latn"
        ],
        "main_score": 0.0037426629807286458,
        "precision": 0.002848584171965203,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.0035115095423254683,
        "hf_subset": "rus_Cyrl-mlt_Latn",
        "languages": [
          "rus-Cyrl",
          "mlt-Latn"
        ],
        "main_score": 0.0035115095423254683,
        "precision": 0.0023479601339090527,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.00032191060533429323,
        "hf_subset": "rus_Cyrl-quy_Latn",
        "languages": [
          "rus-Cyrl",
          "quy-Latn"
        ],
        "main_score": 0.00032191060533429323,
        "precision": 0.0001697674543520843,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0022805907584282138,
        "hf_subset": "rus_Cyrl-swh_Latn",
        "languages": [
          "rus-Cyrl",
          "swh-Latn"
        ],
        "main_score": 0.0022805907584282138,
        "precision": 0.0015790437602580378,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.0038265051771905058,
        "hf_subset": "rus_Cyrl-uzn_Latn",
        "languages": [
          "rus-Cyrl",
          "uzn-Latn"
        ],
        "main_score": 0.0038265051771905058,
        "precision": 0.0032571763867000306,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.005367977638527831,
        "hf_subset": "rus_Cyrl-als_Latn",
        "languages": [
          "rus-Cyrl",
          "als-Latn"
        ],
        "main_score": 0.005367977638527831,
        "precision": 0.004608379839852324,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0016085477571407313,
        "hf_subset": "rus_Cyrl-bod_Tibt",
        "languages": [
          "rus-Cyrl",
          "bod-Tibt"
        ],
        "main_score": 0.0016085477571407313,
        "precision": 0.0013390053561583167,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.003954798536124802,
        "hf_subset": "rus_Cyrl-fij_Latn",
        "languages": [
          "rus-Cyrl",
          "fij-Latn"
        ],
        "main_score": 0.003954798536124802,
        "precision": 0.0036380288948793106,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0011120668235292737,
        "hf_subset": "rus_Cyrl-isl_Latn",
        "languages": [
          "rus-Cyrl",
          "isl-Latn"
        ],
        "main_score": 0.0011120668235292737,
        "precision": 0.0010517306671706896,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.002872345036553706,
        "hf_subset": "rus_Cyrl-kon_Latn",
        "languages": [
          "rus-Cyrl",
          "kon-Latn"
        ],
        "main_score": 0.002872345036553706,
        "precision": 0.0022120134587574,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0009901067900895024,
        "hf_subset": "rus_Cyrl-mni_Beng",
        "languages": [
          "rus-Cyrl",
          "mni-Beng"
        ],
        "main_score": 0.0009901067900895024,
        "precision": 0.0006926828309047647,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.013900418343200039,
        "hf_subset": "rus_Cyrl-ron_Latn",
        "languages": [
          "rus-Cyrl",
          "ron-Latn"
        ],
        "main_score": 0.013900418343200039,
        "precision": 0.011965557254399977,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.003069742356461289,
        "hf_subset": "rus_Cyrl-szl_Latn",
        "languages": [
          "rus-Cyrl",
          "szl-Latn"
        ],
        "main_score": 0.003069742356461289,
        "precision": 0.002450202788574392,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.003706437301278482,
        "hf_subset": "rus_Cyrl-vec_Latn",
        "languages": [
          "rus-Cyrl",
          "vec-Latn"
        ],
        "main_score": 0.003706437301278482,
        "precision": 0.002978583414565683,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.00226868937640661,
        "hf_subset": "rus_Cyrl-amh_Ethi",
        "languages": [
          "rus-Cyrl",
          "amh-Ethi"
        ],
        "main_score": 0.00226868937640661,
        "precision": 0.0018362121360017572,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0017403154590681846,
        "hf_subset": "rus_Cyrl-bos_Latn",
        "languages": [
          "rus-Cyrl",
          "bos-Latn"
        ],
        "main_score": 0.0017403154590681846,
        "precision": 0.0015301429935682578,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0030270705843473346,
        "hf_subset": "rus_Cyrl-fin_Latn",
        "languages": [
          "rus-Cyrl",
          "fin-Latn"
        ],
        "main_score": 0.0030270705843473346,
        "precision": 0.002636636497695099,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.029644268774703556,
        "f1": 0.014851296763661167,
        "hf_subset": "rus_Cyrl-ita_Latn",
        "languages": [
          "rus-Cyrl",
          "ita-Latn"
        ],
        "main_score": 0.014851296763661167,
        "precision": 0.013405291304139338,
        "recall": 0.029644268774703556
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.00030618237287460343,
        "hf_subset": "rus_Cyrl-kor_Hang",
        "languages": [
          "rus-Cyrl",
          "kor-Hang"
        ],
        "main_score": 0.00030618237287460343,
        "precision": 0.00017156877788063155,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.0047412011270436824,
        "hf_subset": "rus_Cyrl-mos_Latn",
        "languages": [
          "rus-Cyrl",
          "mos-Latn"
        ],
        "main_score": 0.0047412011270436824,
        "precision": 0.0038203295007305797,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0008141165607626183,
        "hf_subset": "rus_Cyrl-run_Latn",
        "languages": [
          "rus-Cyrl",
          "run-Latn"
        ],
        "main_score": 0.0008141165607626183,
        "precision": 0.0004603742647220908,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.00013872670508970696,
        "hf_subset": "rus_Cyrl-tam_Taml",
        "languages": [
          "rus-Cyrl",
          "tam-Taml"
        ],
        "main_score": 0.00013872670508970696,
        "precision": 7.198411179360297e-05,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.004474730547765365,
        "hf_subset": "rus_Cyrl-vie_Latn",
        "languages": [
          "rus-Cyrl",
          "vie-Latn"
        ],
        "main_score": 0.004474730547765365,
        "precision": 0.0036062565704846725,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0019896395050220937,
        "hf_subset": "rus_Cyrl-apc_Arab",
        "languages": [
          "rus-Cyrl",
          "apc-Arab"
        ],
        "main_score": 0.0019896395050220937,
        "precision": 0.0016678388402046147,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0036639041787783207,
        "hf_subset": "rus_Cyrl-bug_Latn",
        "languages": [
          "rus-Cyrl",
          "bug-Latn"
        ],
        "main_score": 0.0036639041787783207,
        "precision": 0.0031496843974778027,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0027336631863858546,
        "hf_subset": "rus_Cyrl-fon_Latn",
        "languages": [
          "rus-Cyrl",
          "fon-Latn"
        ],
        "main_score": 0.0027336631863858546,
        "precision": 0.002394987781193943,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.0045410591474755145,
        "hf_subset": "rus_Cyrl-jav_Latn",
        "languages": [
          "rus-Cyrl",
          "jav-Latn"
        ],
        "main_score": 0.0045410591474755145,
        "precision": 0.004268106862268788,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.029644268774703556,
        "f1": 0.014580173810097219,
        "hf_subset": "rus_Cyrl-lao_Laoo",
        "languages": [
          "rus-Cyrl",
          "lao-Laoo"
        ],
        "main_score": 0.014580173810097219,
        "precision": 0.013233952660177288,
        "recall": 0.029644268774703556
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0007498506509542742,
        "hf_subset": "rus_Cyrl-mri_Latn",
        "languages": [
          "rus-Cyrl",
          "mri-Latn"
        ],
        "main_score": 0.0007498506509542742,
        "precision": 0.00046864998378212355,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.005738967944338362,
        "hf_subset": "rus_Cyrl-taq_Latn",
        "languages": [
          "rus-Cyrl",
          "taq-Latn"
        ],
        "main_score": 0.005738967944338362,
        "precision": 0.004384385292932299,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.004492914405014123,
        "hf_subset": "rus_Cyrl-war_Latn",
        "languages": [
          "rus-Cyrl",
          "war-Latn"
        ],
        "main_score": 0.004492914405014123,
        "precision": 0.003545745222495567,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.00045317830153022114,
        "hf_subset": "rus_Cyrl-arb_Arab",
        "languages": [
          "rus-Cyrl",
          "arb-Arab"
        ],
        "main_score": 0.00045317830153022114,
        "precision": 0.00027628719087806,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.18280632411067194,
        "f1": 0.12233131446464403,
        "hf_subset": "rus_Cyrl-bul_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bul-Cyrl"
        ],
        "main_score": 0.12233131446464403,
        "precision": 0.10989600463623453,
        "recall": 0.18280632411067194
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.00614234707113174,
        "hf_subset": "rus_Cyrl-fra_Latn",
        "languages": [
          "rus-Cyrl",
          "fra-Latn"
        ],
        "main_score": 0.00614234707113174,
        "precision": 0.004934044424497594,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.000990424376306493,
        "hf_subset": "rus_Cyrl-jpn_Jpan",
        "languages": [
          "rus-Cyrl",
          "jpn-Jpan"
        ],
        "main_score": 0.000990424376306493,
        "precision": 0.0006928419657748635,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.00964678536529882,
        "hf_subset": "rus_Cyrl-lij_Latn",
        "languages": [
          "rus-Cyrl",
          "lij-Latn"
        ],
        "main_score": 0.00964678536529882,
        "precision": 0.008286669928293954,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0006863410633254027,
        "hf_subset": "rus_Cyrl-mya_Mymr",
        "languages": [
          "rus-Cyrl",
          "mya-Mymr"
        ],
        "main_score": 0.0006863410633254027,
        "precision": 0.0005080229388529782,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0026071329481045795,
        "hf_subset": "rus_Cyrl-sag_Latn",
        "languages": [
          "rus-Cyrl",
          "sag-Latn"
        ],
        "main_score": 0.0026071329481045795,
        "precision": 0.0023317094095658304,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0007907118280880216,
        "hf_subset": "rus_Cyrl-taq_Tfng",
        "languages": [
          "rus-Cyrl",
          "taq-Tfng"
        ],
        "main_score": 0.0007907118280880216,
        "precision": 0.0004893137335755268,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0036450511930990583,
        "hf_subset": "rus_Cyrl-wol_Latn",
        "languages": [
          "rus-Cyrl",
          "wol-Latn"
        ],
        "main_score": 0.0036450511930990583,
        "precision": 0.0031504836557878246,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0024274368939478045,
        "hf_subset": "rus_Cyrl-arb_Latn",
        "languages": [
          "rus-Cyrl",
          "arb-Latn"
        ],
        "main_score": 0.0024274368939478045,
        "precision": 0.002219805934925987,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.006970328345009588,
        "hf_subset": "rus_Cyrl-cat_Latn",
        "languages": [
          "rus-Cyrl",
          "cat-Latn"
        ],
        "main_score": 0.006970328345009588,
        "precision": 0.006218764103514673,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.00737479447675687,
        "hf_subset": "rus_Cyrl-fur_Latn",
        "languages": [
          "rus-Cyrl",
          "fur-Latn"
        ],
        "main_score": 0.00737479447675687,
        "precision": 0.006112368564671258,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0016782918287900365,
        "hf_subset": "rus_Cyrl-kab_Latn",
        "languages": [
          "rus-Cyrl",
          "kab-Latn"
        ],
        "main_score": 0.0016782918287900365,
        "precision": 0.0011058195804001343,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.004871980349189086,
        "hf_subset": "rus_Cyrl-lim_Latn",
        "languages": [
          "rus-Cyrl",
          "lim-Latn"
        ],
        "main_score": 0.004871980349189086,
        "precision": 0.004102659975492769,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.004292986332282928,
        "hf_subset": "rus_Cyrl-nld_Latn",
        "languages": [
          "rus-Cyrl",
          "nld-Latn"
        ],
        "main_score": 0.004292986332282928,
        "precision": 0.0035212212778981886,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0006484598168856151,
        "hf_subset": "rus_Cyrl-san_Deva",
        "languages": [
          "rus-Cyrl",
          "san-Deva"
        ],
        "main_score": 0.0006484598168856151,
        "precision": 0.00040968981782443754,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.00982326440605317,
        "hf_subset": "rus_Cyrl-tat_Cyrl",
        "languages": [
          "rus-Cyrl",
          "tat-Cyrl"
        ],
        "main_score": 0.00982326440605317,
        "precision": 0.008746862914319746,
        "recall": 0.022727272727272728
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.004838801232309548,
        "hf_subset": "rus_Cyrl-xho_Latn",
        "languages": [
          "rus-Cyrl",
          "xho-Latn"
        ],
        "main_score": 0.004838801232309548,
        "precision": 0.0039200237941214204,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 3.194546903550858e-05,
        "hf_subset": "rus_Cyrl-ars_Arab",
        "languages": [
          "rus-Cyrl",
          "ars-Arab"
        ],
        "main_score": 3.194546903550858e-05,
        "precision": 1.60979163691468e-05,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.003577493073951487,
        "hf_subset": "rus_Cyrl-ceb_Latn",
        "languages": [
          "rus-Cyrl",
          "ceb-Latn"
        ],
        "main_score": 0.003577493073951487,
        "precision": 0.002575378331648951,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.004777331183896062,
        "hf_subset": "rus_Cyrl-fuv_Latn",
        "languages": [
          "rus-Cyrl",
          "fuv-Latn"
        ],
        "main_score": 0.004777331183896062,
        "precision": 0.004056067617808936,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.001185593464231778,
        "hf_subset": "rus_Cyrl-kac_Latn",
        "languages": [
          "rus-Cyrl",
          "kac-Latn"
        ],
        "main_score": 0.001185593464231778,
        "precision": 0.0008096033024905409,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.001842428610781688,
        "hf_subset": "rus_Cyrl-lin_Latn",
        "languages": [
          "rus-Cyrl",
          "lin-Latn"
        ],
        "main_score": 0.001842428610781688,
        "precision": 0.0011815254848404045,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.006907111097567668,
        "hf_subset": "rus_Cyrl-nno_Latn",
        "languages": [
          "rus-Cyrl",
          "nno-Latn"
        ],
        "main_score": 0.006907111097567668,
        "precision": 0.005298095675480793,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0003015143454295192,
        "hf_subset": "rus_Cyrl-sat_Olck",
        "languages": [
          "rus-Cyrl",
          "sat-Olck"
        ],
        "main_score": 0.0003015143454295192,
        "precision": 0.0001743170524796518,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0036396991332561584,
        "hf_subset": "rus_Cyrl-tel_Telu",
        "languages": [
          "rus-Cyrl",
          "tel-Telu"
        ],
        "main_score": 0.0036396991332561584,
        "precision": 0.00315272175369963,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 2.7268154256489357e-05,
        "hf_subset": "rus_Cyrl-ydd_Hebr",
        "languages": [
          "rus-Cyrl",
          "ydd-Hebr"
        ],
        "main_score": 2.7268154256489357e-05,
        "precision": 1.3785390759824891e-05,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.000507749088968465,
        "hf_subset": "rus_Cyrl-ary_Arab",
        "languages": [
          "rus-Cyrl",
          "ary-Arab"
        ],
        "main_score": 0.000507749088968465,
        "precision": 0.00033625174569205317,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.002301873201225391,
        "hf_subset": "rus_Cyrl-ces_Latn",
        "languages": [
          "rus-Cyrl",
          "ces-Latn"
        ],
        "main_score": 0.002301873201225391,
        "precision": 0.001788249279070987,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0031986604709557686,
        "hf_subset": "rus_Cyrl-gaz_Latn",
        "languages": [
          "rus-Cyrl",
          "gaz-Latn"
        ],
        "main_score": 0.0031986604709557686,
        "precision": 0.0028348406128939,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.002761403146769039,
        "hf_subset": "rus_Cyrl-kam_Latn",
        "languages": [
          "rus-Cyrl",
          "kam-Latn"
        ],
        "main_score": 0.002761403146769039,
        "precision": 0.0022307007369302555,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.003926270401058334,
        "hf_subset": "rus_Cyrl-lit_Latn",
        "languages": [
          "rus-Cyrl",
          "lit-Latn"
        ],
        "main_score": 0.003926270401058334,
        "precision": 0.0035369050381269295,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.003507640539503931,
        "hf_subset": "rus_Cyrl-nob_Latn",
        "languages": [
          "rus-Cyrl",
          "nob-Latn"
        ],
        "main_score": 0.003507640539503931,
        "precision": 0.002405394973012864,
        "recall": 0.019762845849802372
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.00470713854362403,
        "hf_subset": "rus_Cyrl-scn_Latn",
        "languages": [
          "rus-Cyrl",
          "scn-Latn"
        ],
        "main_score": 0.00470713854362403,
        "precision": 0.003506397648837736,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.012707463515876198,
        "hf_subset": "rus_Cyrl-tgk_Cyrl",
        "languages": [
          "rus-Cyrl",
          "tgk-Cyrl"
        ],
        "main_score": 0.012707463515876198,
        "precision": 0.01060129714404153,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.0015557144397115496,
        "hf_subset": "rus_Cyrl-yor_Latn",
        "languages": [
          "rus-Cyrl",
          "yor-Latn"
        ],
        "main_score": 0.0015557144397115496,
        "precision": 0.0012902583057813292,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.000288701279787966,
        "hf_subset": "rus_Cyrl-arz_Arab",
        "languages": [
          "rus-Cyrl",
          "arz-Arab"
        ],
        "main_score": 0.000288701279787966,
        "precision": 0.0001505696423221806,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.001584805068206572,
        "hf_subset": "rus_Cyrl-cjk_Latn",
        "languages": [
          "rus-Cyrl",
          "cjk-Latn"
        ],
        "main_score": 0.001584805068206572,
        "precision": 0.0013189294590190046,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.0028016844891103456,
        "hf_subset": "rus_Cyrl-gla_Latn",
        "languages": [
          "rus-Cyrl",
          "gla-Latn"
        ],
        "main_score": 0.0028016844891103456,
        "precision": 0.0020465927571462314,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0007731217783168552,
        "hf_subset": "rus_Cyrl-kan_Knda",
        "languages": [
          "rus-Cyrl",
          "kan-Knda"
        ],
        "main_score": 0.0007731217783168552,
        "precision": 0.00046945483813047475,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.0034590368363553144,
        "hf_subset": "rus_Cyrl-lmo_Latn",
        "languages": [
          "rus-Cyrl",
          "lmo-Latn"
        ],
        "main_score": 0.0034590368363553144,
        "precision": 0.0025427986076864695,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.000446850852169458,
        "hf_subset": "rus_Cyrl-npi_Deva",
        "languages": [
          "rus-Cyrl",
          "npi-Deva"
        ],
        "main_score": 0.000446850852169458,
        "precision": 0.0002576611398033436,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.012255403291426981,
        "hf_subset": "rus_Cyrl-shn_Mymr",
        "languages": [
          "rus-Cyrl",
          "shn-Mymr"
        ],
        "main_score": 0.012255403291426981,
        "precision": 0.010265249826450332,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.00416206142671692,
        "hf_subset": "rus_Cyrl-tgl_Latn",
        "languages": [
          "rus-Cyrl",
          "tgl-Latn"
        ],
        "main_score": 0.00416206142671692,
        "precision": 0.003317423802232512,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.001337269537344301,
        "hf_subset": "rus_Cyrl-yue_Hant",
        "languages": [
          "rus-Cyrl",
          "yue-Hant"
        ],
        "main_score": 0.001337269537344301,
        "precision": 0.0011791289190883347,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 5.4621885007466486e-05,
        "hf_subset": "rus_Cyrl-asm_Beng",
        "languages": [
          "rus-Cyrl",
          "asm-Beng"
        ],
        "main_score": 5.4621885007466486e-05,
        "precision": 2.7810762519931985e-05,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0007104769717567092,
        "hf_subset": "rus_Cyrl-ckb_Arab",
        "languages": [
          "rus-Cyrl",
          "ckb-Arab"
        ],
        "main_score": 0.0007104769717567092,
        "precision": 0.0005205082115576012,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.00537611726928165,
        "hf_subset": "rus_Cyrl-gle_Latn",
        "languages": [
          "rus-Cyrl",
          "gle-Latn"
        ],
        "main_score": 0.00537611726928165,
        "precision": 0.004201057616993432,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0002964686447323825,
        "hf_subset": "rus_Cyrl-kas_Arab",
        "languages": [
          "rus-Cyrl",
          "kas-Arab"
        ],
        "main_score": 0.0002964686447323825,
        "precision": 0.0001660420630774536,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.004730072512940886,
        "hf_subset": "rus_Cyrl-ltg_Latn",
        "languages": [
          "rus-Cyrl",
          "ltg-Latn"
        ],
        "main_score": 0.004730072512940886,
        "precision": 0.004109080054957847,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.001963632701830179,
        "hf_subset": "rus_Cyrl-nso_Latn",
        "languages": [
          "rus-Cyrl",
          "nso-Latn"
        ],
        "main_score": 0.001963632701830179,
        "precision": 0.0012640492660468473,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0010272849720546222,
        "hf_subset": "rus_Cyrl-sin_Sinh",
        "languages": [
          "rus-Cyrl",
          "sin-Sinh"
        ],
        "main_score": 0.0010272849720546222,
        "precision": 0.001007936794929968,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.009830617936067473,
        "hf_subset": "rus_Cyrl-tha_Thai",
        "languages": [
          "rus-Cyrl",
          "tha-Thai"
        ],
        "main_score": 0.009830617936067473,
        "precision": 0.008527002977306092,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.00011846096591418386,
        "hf_subset": "rus_Cyrl-zho_Hans",
        "languages": [
          "rus-Cyrl",
          "zho-Hans"
        ],
        "main_score": 0.00011846096591418386,
        "precision": 6.164840375140392e-05,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.0054397820682950074,
        "hf_subset": "rus_Cyrl-ast_Latn",
        "languages": [
          "rus-Cyrl",
          "ast-Latn"
        ],
        "main_score": 0.0054397820682950074,
        "precision": 0.004240529831228229,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.003733887010938109,
        "hf_subset": "rus_Cyrl-crh_Latn",
        "languages": [
          "rus-Cyrl",
          "crh-Latn"
        ],
        "main_score": 0.003733887010938109,
        "precision": 0.0026983748131627332,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.0052152685194065415,
        "hf_subset": "rus_Cyrl-glg_Latn",
        "languages": [
          "rus-Cyrl",
          "glg-Latn"
        ],
        "main_score": 0.0052152685194065415,
        "precision": 0.004664341327687463,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0023445395816609747,
        "hf_subset": "rus_Cyrl-kas_Deva",
        "languages": [
          "rus-Cyrl",
          "kas-Deva"
        ],
        "main_score": 0.0023445395816609747,
        "precision": 0.0018435895384853027,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.003046419091066629,
        "hf_subset": "rus_Cyrl-ltz_Latn",
        "languages": [
          "rus-Cyrl",
          "ltz-Latn"
        ],
        "main_score": 0.003046419091066629,
        "precision": 0.0025969083964566416,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0040561654764700835,
        "hf_subset": "rus_Cyrl-nus_Latn",
        "languages": [
          "rus-Cyrl",
          "nus-Latn"
        ],
        "main_score": 0.0040561654764700835,
        "precision": 0.0037246959372377593,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0032039348893934793,
        "hf_subset": "rus_Cyrl-slk_Latn",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ],
        "main_score": 0.0032039348893934793,
        "precision": 0.002528281138440753,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.00028414363214938134,
        "hf_subset": "rus_Cyrl-tir_Ethi",
        "languages": [
          "rus-Cyrl",
          "tir-Ethi"
        ],
        "main_score": 0.00028414363214938134,
        "precision": 0.00015108148405136275,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 9.236718624919435e-06,
        "hf_subset": "rus_Cyrl-zho_Hant",
        "languages": [
          "rus-Cyrl",
          "zho-Hant"
        ],
        "main_score": 9.236718624919435e-06,
        "precision": 4.629606098739989e-06,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0012707912403370188,
        "hf_subset": "rus_Cyrl-awa_Deva",
        "languages": [
          "rus-Cyrl",
          "awa-Deva"
        ],
        "main_score": 0.0012707912403370188,
        "precision": 0.0008605416118917603,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.006967012481985381,
        "hf_subset": "rus_Cyrl-cym_Latn",
        "languages": [
          "rus-Cyrl",
          "cym-Latn"
        ],
        "main_score": 0.006967012481985381,
        "precision": 0.0058705971371840375,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.004197621206654916,
        "hf_subset": "rus_Cyrl-grn_Latn",
        "languages": [
          "rus-Cyrl",
          "grn-Latn"
        ],
        "main_score": 0.004197621206654916,
        "precision": 0.0037594658711503776,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0020887627906108156,
        "hf_subset": "rus_Cyrl-kat_Geor",
        "languages": [
          "rus-Cyrl",
          "kat-Geor"
        ],
        "main_score": 0.0020887627906108156,
        "precision": 0.0017379659073078668,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.002611268526014466,
        "hf_subset": "rus_Cyrl-lua_Latn",
        "languages": [
          "rus-Cyrl",
          "lua-Latn"
        ],
        "main_score": 0.002611268526014466,
        "precision": 0.002333803553779478,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.002082308958005621,
        "hf_subset": "rus_Cyrl-nya_Latn",
        "languages": [
          "rus-Cyrl",
          "nya-Latn"
        ],
        "main_score": 0.002082308958005621,
        "precision": 0.0013603385528787348,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.003303489888997324,
        "hf_subset": "rus_Cyrl-slv_Latn",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ],
        "main_score": 0.003303489888997324,
        "precision": 0.00280527263141372,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.03162055335968379,
        "f1": 0.010220475296568781,
        "hf_subset": "rus_Cyrl-tpi_Latn",
        "languages": [
          "rus-Cyrl",
          "tpi-Latn"
        ],
        "main_score": 0.010220475296568781,
        "precision": 0.007873465719508142,
        "recall": 0.03162055335968379
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.003081292722055755,
        "hf_subset": "rus_Cyrl-zsm_Latn",
        "languages": [
          "rus-Cyrl",
          "zsm-Latn"
        ],
        "main_score": 0.003081292722055755,
        "precision": 0.002341355164391657,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0018982951138171967,
        "hf_subset": "rus_Cyrl-ayr_Latn",
        "languages": [
          "rus-Cyrl",
          "ayr-Latn"
        ],
        "main_score": 0.0018982951138171967,
        "precision": 0.0012426211962285624,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.005905864654493297,
        "hf_subset": "rus_Cyrl-dan_Latn",
        "languages": [
          "rus-Cyrl",
          "dan-Latn"
        ],
        "main_score": 0.005905864654493297,
        "precision": 0.00455232570860377,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.001086830983965884,
        "hf_subset": "rus_Cyrl-guj_Gujr",
        "languages": [
          "rus-Cyrl",
          "guj-Gujr"
        ],
        "main_score": 0.001086830983965884,
        "precision": 0.0010385731235533608,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.025691699604743084,
        "f1": 0.009422396367550063,
        "hf_subset": "rus_Cyrl-kaz_Cyrl",
        "languages": [
          "rus-Cyrl",
          "kaz-Cyrl"
        ],
        "main_score": 0.009422396367550063,
        "precision": 0.007904126809292226,
        "recall": 0.025691699604743084
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0018032578037579065,
        "hf_subset": "rus_Cyrl-lug_Latn",
        "languages": [
          "rus-Cyrl",
          "lug-Latn"
        ],
        "main_score": 0.0018032578037579065,
        "precision": 0.0011823077202385592,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.010155571211920329,
        "hf_subset": "rus_Cyrl-oci_Latn",
        "languages": [
          "rus-Cyrl",
          "oci-Latn"
        ],
        "main_score": 0.010155571211920329,
        "precision": 0.008461132847222493,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0016240832459833477,
        "hf_subset": "rus_Cyrl-smo_Latn",
        "languages": [
          "rus-Cyrl",
          "smo-Latn"
        ],
        "main_score": 0.0016240832459833477,
        "precision": 0.0013622267521902973,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0018682721818341578,
        "hf_subset": "rus_Cyrl-tsn_Latn",
        "languages": [
          "rus-Cyrl",
          "tsn-Latn"
        ],
        "main_score": 0.0018682721818341578,
        "precision": 0.0015004693526983015,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0034757877844167184,
        "hf_subset": "rus_Cyrl-zul_Latn",
        "languages": [
          "rus-Cyrl",
          "zul-Latn"
        ],
        "main_score": 0.0034757877844167184,
        "precision": 0.0032462376228671384,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 5.952465022818677e-05,
        "hf_subset": "rus_Cyrl-azb_Arab",
        "languages": [
          "rus-Cyrl",
          "azb-Arab"
        ],
        "main_score": 5.952465022818677e-05,
        "precision": 3.0050982592679424e-05,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0013288312216104086,
        "hf_subset": "rus_Cyrl-deu_Latn",
        "languages": [
          "rus-Cyrl",
          "deu-Latn"
        ],
        "main_score": 0.0013288312216104086,
        "precision": 0.0009170142957046659,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.003736964740482084,
        "hf_subset": "rus_Cyrl-hat_Latn",
        "languages": [
          "rus-Cyrl",
          "hat-Latn"
        ],
        "main_score": 0.003736964740482084,
        "precision": 0.003118741183140561,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.004553772565966636,
        "hf_subset": "rus_Cyrl-kbp_Latn",
        "languages": [
          "rus-Cyrl",
          "kbp-Latn"
        ],
        "main_score": 0.004553772565966636,
        "precision": 0.003921892381390881,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.0030876245889186844,
        "hf_subset": "rus_Cyrl-luo_Latn",
        "languages": [
          "rus-Cyrl",
          "luo-Latn"
        ],
        "main_score": 0.0030876245889186844,
        "precision": 0.00261757591365109,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0006875788418350952,
        "hf_subset": "rus_Cyrl-ory_Orya",
        "languages": [
          "rus-Cyrl",
          "ory-Orya"
        ],
        "main_score": 0.0006875788418350952,
        "precision": 0.0004309799926951075,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0016005467653299919,
        "hf_subset": "rus_Cyrl-sna_Latn",
        "languages": [
          "rus-Cyrl",
          "sna-Latn"
        ],
        "main_score": 0.0016005467653299919,
        "precision": 0.0011382381758586009,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0008250172228244609,
        "hf_subset": "rus_Cyrl-tso_Latn",
        "languages": [
          "rus-Cyrl",
          "tso-Latn"
        ],
        "main_score": 0.0008250172228244609,
        "precision": 0.0004896133895616004,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0017259688454094556,
        "hf_subset": "rus_Cyrl-azj_Latn",
        "languages": [
          "rus-Cyrl",
          "azj-Latn"
        ],
        "main_score": 0.0017259688454094556,
        "precision": 0.001453182958703667,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.005786650720874571,
        "hf_subset": "rus_Cyrl-dik_Latn",
        "languages": [
          "rus-Cyrl",
          "dik-Latn"
        ],
        "main_score": 0.005786650720874571,
        "precision": 0.004573672142225272,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.0031020331378258863,
        "hf_subset": "rus_Cyrl-hau_Latn",
        "languages": [
          "rus-Cyrl",
          "hau-Latn"
        ],
        "main_score": 0.0031020331378258863,
        "precision": 0.002602084520588846,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.00598707345371314,
        "hf_subset": "rus_Cyrl-kea_Latn",
        "languages": [
          "rus-Cyrl",
          "kea-Latn"
        ],
        "main_score": 0.00598707345371314,
        "precision": 0.005182221975570556,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.005653847459048438,
        "hf_subset": "rus_Cyrl-lus_Latn",
        "languages": [
          "rus-Cyrl",
          "lus-Latn"
        ],
        "main_score": 0.005653847459048438,
        "precision": 0.004621022445527474,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.043478260869565216,
        "f1": 0.016979838060095696,
        "hf_subset": "rus_Cyrl-pag_Latn",
        "languages": [
          "rus-Cyrl",
          "pag-Latn"
        ],
        "main_score": 0.016979838060095696,
        "precision": 0.013627268989096868,
        "recall": 0.043478260869565216
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0001338038318189547,
        "hf_subset": "rus_Cyrl-snd_Arab",
        "languages": [
          "rus-Cyrl",
          "snd-Arab"
        ],
        "main_score": 0.0001338038318189547,
        "precision": 6.886637321419929e-05,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.0047689043226918975,
        "hf_subset": "rus_Cyrl-tuk_Latn",
        "languages": [
          "rus-Cyrl",
          "tuk-Latn"
        ],
        "main_score": 0.0047689043226918975,
        "precision": 0.0037366564608311186,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.014116522789450095,
        "hf_subset": "rus_Cyrl-bak_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bak-Cyrl"
        ],
        "main_score": 0.014116522789450095,
        "precision": 0.012714278910332768,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.002774289829625798,
        "hf_subset": "rus_Cyrl-dyu_Latn",
        "languages": [
          "rus-Cyrl",
          "dyu-Latn"
        ],
        "main_score": 0.002774289829625798,
        "precision": 0.0022606335641238095,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.00010341149098016793,
        "hf_subset": "rus_Cyrl-heb_Hebr",
        "languages": [
          "rus-Cyrl",
          "heb-Hebr"
        ],
        "main_score": 0.00010341149098016793,
        "precision": 5.275743380372168e-05,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.005861497335541934,
        "hf_subset": "rus_Cyrl-khk_Cyrl",
        "languages": [
          "rus-Cyrl",
          "khk-Cyrl"
        ],
        "main_score": 0.005861497335541934,
        "precision": 0.00496141878319996,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0031462433822661614,
        "hf_subset": "rus_Cyrl-lvs_Latn",
        "languages": [
          "rus-Cyrl",
          "lvs-Latn"
        ],
        "main_score": 0.0031462433822661614,
        "precision": 0.002776286848070012,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0017153017408541714,
        "hf_subset": "rus_Cyrl-pan_Guru",
        "languages": [
          "rus-Cyrl",
          "pan-Guru"
        ],
        "main_score": 0.0017153017408541714,
        "precision": 0.0014478242269527009,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.002206871015648852,
        "hf_subset": "rus_Cyrl-som_Latn",
        "languages": [
          "rus-Cyrl",
          "som-Latn"
        ],
        "main_score": 0.002206871015648852,
        "precision": 0.0016957870343571714,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.002279159210534941,
        "hf_subset": "rus_Cyrl-tum_Latn",
        "languages": [
          "rus-Cyrl",
          "tum-Latn"
        ],
        "main_score": 0.002279159210534941,
        "precision": 0.0018840753453277707,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009903653347679365,
        "hf_subset": "taq_Latn-rus_Cyrl",
        "languages": [
          "taq-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0009903653347679365,
        "precision": 0.0009892550653420218,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001978353992922625,
        "hf_subset": "war_Latn-rus_Cyrl",
        "languages": [
          "war-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001978353992922625,
        "precision": 0.0019773203735467884,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0017344428204099681,
        "hf_subset": "arb_Arab-rus_Cyrl",
        "languages": [
          "arb-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0017344428204099681,
        "precision": 0.0015272501710906256,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.1600790513833992,
        "f1": 0.1376831211633318,
        "hf_subset": "bul_Cyrl-rus_Cyrl",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.1376831211633318,
        "precision": 0.13230709125187187,
        "recall": 0.1600790513833992
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0032607472313037197,
        "hf_subset": "fra_Latn-rus_Cyrl",
        "languages": [
          "fra-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0032607472313037197,
        "precision": 0.0024802518640886636,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0005073048035546831,
        "hf_subset": "jpn_Jpan-rus_Cyrl",
        "languages": [
          "jpn-Jpan",
          "rus-Cyrl"
        ],
        "main_score": 0.0005073048035546831,
        "precision": 0.0003360244938166199,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.002494593445416962,
        "hf_subset": "lij_Latn-rus_Cyrl",
        "languages": [
          "lij-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002494593445416962,
        "precision": 0.0018727253242575687,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 2.9437569038691448e-05,
        "hf_subset": "mya_Mymr-rus_Cyrl",
        "languages": [
          "mya-Mymr",
          "rus-Cyrl"
        ],
        "main_score": 2.9437569038691448e-05,
        "precision": 1.4891245677809727e-05,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 1.670064429120894e-05,
        "hf_subset": "sag_Latn-rus_Cyrl",
        "languages": [
          "sag-Latn",
          "rus-Cyrl"
        ],
        "main_score": 1.670064429120894e-05,
        "precision": 8.403397674717716e-06,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0011680348636870376,
        "hf_subset": "taq_Tfng-rus_Cyrl",
        "languages": [
          "taq-Tfng",
          "rus-Cyrl"
        ],
        "main_score": 0.0011680348636870376,
        "precision": 0.0010856334277604615,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0030106211382508715,
        "hf_subset": "wol_Latn-rus_Cyrl",
        "languages": [
          "wol-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0030106211382508715,
        "precision": 0.0029880243826726862,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009901527549366906,
        "hf_subset": "arb_Latn-rus_Cyrl",
        "languages": [
          "arb-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0009901527549366906,
        "precision": 0.0009891485473704548,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0025013690716520344,
        "hf_subset": "cat_Latn-rus_Cyrl",
        "languages": [
          "cat-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0025013690716520344,
        "precision": 0.002015912280743861,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0038635733926481405,
        "hf_subset": "fur_Latn-rus_Cyrl",
        "languages": [
          "fur-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0038635733926481405,
        "precision": 0.0035298499044362154,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0019784659145442333,
        "hf_subset": "kab_Latn-rus_Cyrl",
        "languages": [
          "kab-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0019784659145442333,
        "precision": 0.0019773764549166906,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0034021568297754067,
        "hf_subset": "lim_Latn-rus_Cyrl",
        "languages": [
          "lim-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0034021568297754067,
        "precision": 0.0031984975501762923,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.006830186165630901,
        "hf_subset": "nld_Latn-rus_Cyrl",
        "languages": [
          "nld-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.006830186165630901,
        "precision": 0.006175636723458141,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.002899379775020502,
        "hf_subset": "san_Deva-rus_Cyrl",
        "languages": [
          "san-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.002899379775020502,
        "precision": 0.002614566650624969,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.003625150952554778,
        "hf_subset": "tat_Cyrl-rus_Cyrl",
        "languages": [
          "tat-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.003625150952554778,
        "precision": 0.003459480272515107,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.001563068788909815,
        "hf_subset": "xho_Latn-rus_Cyrl",
        "languages": [
          "xho-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001563068788909815,
        "precision": 0.0013590187827752648,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0016661656854344601,
        "hf_subset": "ars_Arab-rus_Cyrl",
        "languages": [
          "ars-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0016661656854344601,
        "precision": 0.0014918953360730485,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0029664434943938046,
        "hf_subset": "ceb_Latn-rus_Cyrl",
        "languages": [
          "ceb-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0029664434943938046,
        "precision": 0.0029654362158692224,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 1.5706528338167654e-05,
        "hf_subset": "fuv_Latn-rus_Cyrl",
        "languages": [
          "fuv-Latn",
          "rus-Cyrl"
        ],
        "main_score": 1.5706528338167654e-05,
        "precision": 7.89958549321442e-06,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 5.582724816328353e-06,
        "hf_subset": "kac_Latn-rus_Cyrl",
        "languages": [
          "kac-Latn",
          "rus-Cyrl"
        ],
        "main_score": 5.582724816328353e-06,
        "precision": 2.7992699503969367e-06,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0014584979518883932,
        "hf_subset": "lin_Latn-rus_Cyrl",
        "languages": [
          "lin-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0014584979518883932,
        "precision": 0.0012583172816914324,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.004034013404383057,
        "hf_subset": "nno_Latn-rus_Cyrl",
        "languages": [
          "nno-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.004034013404383057,
        "precision": 0.003620787923842632,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 2.1024304095534438e-06,
        "hf_subset": "sat_Olck-rus_Cyrl",
        "languages": [
          "sat-Olck",
          "rus-Cyrl"
        ],
        "main_score": 2.1024304095534438e-06,
        "precision": 1.0523347097871338e-06,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.008701910786596056,
        "hf_subset": "tel_Telu-rus_Cyrl",
        "languages": [
          "tel-Telu",
          "rus-Cyrl"
        ],
        "main_score": 0.008701910786596056,
        "precision": 0.00816395115101148,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0029644268774703555,
        "hf_subset": "ydd_Hebr-rus_Cyrl",
        "languages": [
          "ydd-Hebr",
          "rus-Cyrl"
        ],
        "main_score": 0.0029644268774703555,
        "precision": 0.0029644268774703555,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.003956561664071546,
        "hf_subset": "ary_Arab-rus_Cyrl",
        "languages": [
          "ary-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.003956561664071546,
        "precision": 0.003954569458001952,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.004432929222607981,
        "hf_subset": "ces_Latn-rus_Cyrl",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.004432929222607981,
        "precision": 0.003884144025707088,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 1.1895384318989732e-05,
        "hf_subset": "gaz_Latn-rus_Cyrl",
        "languages": [
          "gaz-Latn",
          "rus-Cyrl"
        ],
        "main_score": 1.1895384318989732e-05,
        "precision": 5.971459938427777e-06,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0027305747056196234,
        "hf_subset": "kam_Latn-rus_Cyrl",
        "languages": [
          "kam-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0027305747056196234,
        "precision": 0.002520084583828709,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0023942912796713184,
        "hf_subset": "lit_Latn-rus_Cyrl",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0023942912796713184,
        "precision": 0.002219220044286941,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0028695234601637106,
        "hf_subset": "nob_Latn-rus_Cyrl",
        "languages": [
          "nob-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0028695234601637106,
        "precision": 0.002483948101977968,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0035526620715733478,
        "hf_subset": "scn_Latn-rus_Cyrl",
        "languages": [
          "scn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0035526620715733478,
        "precision": 0.0033418995517718406,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001978245184766924,
        "hf_subset": "tgk_Cyrl-rus_Cyrl",
        "languages": [
          "tgk-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.001978245184766924,
        "precision": 0.0019772658583590754,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.002637541422126402,
        "hf_subset": "yor_Latn-rus_Cyrl",
        "languages": [
          "yor-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002637541422126402,
        "precision": 0.002471604962947787,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009931582432134187,
        "hf_subset": "arz_Arab-rus_Cyrl",
        "languages": [
          "arz-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0009931582432134187,
        "precision": 0.0009906566494684648,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010046350423194475,
        "hf_subset": "cjk_Latn-rus_Cyrl",
        "languages": [
          "cjk-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0010046350423194475,
        "precision": 0.0009964402789398698,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0019782510373036006,
        "hf_subset": "gla_Latn-rus_Cyrl",
        "languages": [
          "gla-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0019782510373036006,
        "precision": 0.0019772687904508444,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.008567279079982703,
        "hf_subset": "kan_Knda-rus_Cyrl",
        "languages": [
          "kan-Knda",
          "rus-Cyrl"
        ],
        "main_score": 0.008567279079982703,
        "precision": 0.008276817146407123,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.003466609602225038,
        "hf_subset": "lmo_Latn-rus_Cyrl",
        "languages": [
          "lmo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003466609602225038,
        "precision": 0.002992287147404386,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.00616233501584532,
        "hf_subset": "npi_Deva-rus_Cyrl",
        "languages": [
          "npi-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.00616233501584532,
        "precision": 0.006059351921611785,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.008037708457421319,
        "hf_subset": "shn_Mymr-rus_Cyrl",
        "languages": [
          "shn-Mymr",
          "rus-Cyrl"
        ],
        "main_score": 0.008037708457421319,
        "precision": 0.00728080985720658,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.002637166590329494,
        "hf_subset": "tgl_Latn-rus_Cyrl",
        "languages": [
          "tgl-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002637166590329494,
        "precision": 0.0024714171085534276,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.002678963548528766,
        "hf_subset": "yue_Hant-rus_Cyrl",
        "languages": [
          "yue-Hant",
          "rus-Cyrl"
        ],
        "main_score": 0.002678963548528766,
        "precision": 0.0024928135106000717,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.002010207520824305,
        "hf_subset": "asm_Beng-rus_Cyrl",
        "languages": [
          "asm-Beng",
          "rus-Cyrl"
        ],
        "main_score": 0.002010207520824305,
        "precision": 0.0019935006850976943,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0042092746370767905,
        "hf_subset": "ckb_Arab-rus_Cyrl",
        "languages": [
          "ckb-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0042092746370767905,
        "precision": 0.004098579903966242,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.002007293198445865,
        "hf_subset": "gle_Latn-rus_Cyrl",
        "languages": [
          "gle-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002007293198445865,
        "precision": 0.001992000912174236,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 0.0009881422924901185,
        "hf_subset": "kas_Arab-rus_Cyrl",
        "languages": [
          "kas-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0009881422924901185,
        "precision": 0.0009881422924901185,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.002026097800069897,
        "hf_subset": "ltg_Latn-rus_Cyrl",
        "languages": [
          "ltg-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002026097800069897,
        "precision": 0.0020013949836530584,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0021690433149249315,
        "hf_subset": "nso_Latn-rus_Cyrl",
        "languages": [
          "nso-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0021690433149249315,
        "precision": 0.002076485727702743,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.006128642087302102,
        "hf_subset": "sin_Sinh-rus_Cyrl",
        "languages": [
          "sin-Sinh",
          "rus-Cyrl"
        ],
        "main_score": 0.006128642087302102,
        "precision": 0.006039728461477106,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.01116041866057909,
        "hf_subset": "tha_Thai-rus_Cyrl",
        "languages": [
          "tha-Thai",
          "rus-Cyrl"
        ],
        "main_score": 0.01116041866057909,
        "precision": 0.01009615702461839,
        "recall": 0.019762845849802372
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0024601663928207427,
        "hf_subset": "zho_Hans-rus_Cyrl",
        "languages": [
          "zho-Hans",
          "rus-Cyrl"
        ],
        "main_score": 0.0024601663928207427,
        "precision": 0.0022688256683942444,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.006127579503841198,
        "hf_subset": "ast_Latn-rus_Cyrl",
        "languages": [
          "ast-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.006127579503841198,
        "precision": 0.00536023863461785,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001978324094355862,
        "hf_subset": "crh_Latn-rus_Cyrl",
        "languages": [
          "crh-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001978324094355862,
        "precision": 0.0019773053931336363,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.006126664234804203,
        "hf_subset": "glg_Latn-rus_Cyrl",
        "languages": [
          "glg-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.006126664234804203,
        "precision": 0.005733963484468399,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.00576047133016417,
        "hf_subset": "kas_Deva-rus_Cyrl",
        "languages": [
          "kas-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.00576047133016417,
        "precision": 0.005419375071127216,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0029145045068978137,
        "hf_subset": "ltz_Latn-rus_Cyrl",
        "languages": [
          "ltz-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0029145045068978137,
        "precision": 0.00261464276275497,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0006775334889491725,
        "hf_subset": "nus_Latn-rus_Cyrl",
        "languages": [
          "nus-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0006775334889491725,
        "precision": 0.0005035036594256984,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0033328676306424217,
        "hf_subset": "slk_Latn-rus_Cyrl",
        "languages": [
          "slk-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0033328676306424217,
        "precision": 0.0031619831881549844,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.003362347250780393,
        "hf_subset": "tir_Ethi-rus_Cyrl",
        "languages": [
          "tir-Ethi",
          "rus-Cyrl"
        ],
        "main_score": 0.003362347250780393,
        "precision": 0.0031853475789402562,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001978926676671387,
        "hf_subset": "zho_Hant-rus_Cyrl",
        "languages": [
          "zho-Hant",
          "rus-Cyrl"
        ],
        "main_score": 0.001978926676671387,
        "precision": 0.0019776073992941465,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.004174454351400762,
        "hf_subset": "awa_Deva-rus_Cyrl",
        "languages": [
          "awa-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.004174454351400762,
        "precision": 0.004077237296792391,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0019783714747215043,
        "hf_subset": "cym_Latn-rus_Cyrl",
        "languages": [
          "cym-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0019783714747215043,
        "precision": 0.0019773291328581332,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0023131403520894327,
        "hf_subset": "grn_Latn-rus_Cyrl",
        "languages": [
          "grn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0023131403520894327,
        "precision": 0.002157190845355847,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0034717781082856513,
        "hf_subset": "kat_Geor-rus_Cyrl",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ],
        "main_score": 0.0034717781082856513,
        "precision": 0.0032420379815318646,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010134919915891904,
        "hf_subset": "lua_Latn-rus_Cyrl",
        "languages": [
          "lua-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0010134919915891904,
        "precision": 0.0010009537411802666,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010662897619419358,
        "hf_subset": "nya_Latn-rus_Cyrl",
        "languages": [
          "nya-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0010662897619419358,
        "precision": 0.0010287374022551888,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.005866581762344841,
        "hf_subset": "slv_Latn-rus_Cyrl",
        "languages": [
          "slv-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.005866581762344841,
        "precision": 0.005576369535871639,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.005338024867048077,
        "hf_subset": "tpi_Latn-rus_Cyrl",
        "languages": [
          "tpi-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.005338024867048077,
        "precision": 0.004694705204216074,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0011698546152320774,
        "hf_subset": "zsm_Latn-rus_Cyrl",
        "languages": [
          "zsm-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0011698546152320774,
        "precision": 0.001087982630038705,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009901548022507908,
        "hf_subset": "ayr_Latn-rus_Cyrl",
        "languages": [
          "ayr-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0009901548022507908,
        "precision": 0.0009891495731144714,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.006947746925977387,
        "hf_subset": "dan_Latn-rus_Cyrl",
        "languages": [
          "dan-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.006947746925977387,
        "precision": 0.006544063758698266,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0029666854884246186,
        "hf_subset": "guj_Gujr-rus_Cyrl",
        "languages": [
          "guj-Gujr",
          "rus-Cyrl"
        ],
        "main_score": 0.0029666854884246186,
        "precision": 0.002965557475059017,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0016488644206035508,
        "hf_subset": "kaz_Cyrl-rus_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.0016488644206035508,
        "precision": 0.0014831947121140162,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009903653347679365,
        "hf_subset": "lug_Latn-rus_Cyrl",
        "languages": [
          "lug-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0009903653347679365,
        "precision": 0.0009892550653420218,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.0053103129386413,
        "hf_subset": "oci_Latn-rus_Cyrl",
        "languages": [
          "oci-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0053103129386413,
        "precision": 0.004882924545885011,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0006744953142072453,
        "hf_subset": "smo_Latn-rus_Cyrl",
        "languages": [
          "smo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0006744953142072453,
        "precision": 0.00039406060316551027,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.001203682199416317,
        "hf_subset": "tsn_Latn-rus_Cyrl",
        "languages": [
          "tsn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001203682199416317,
        "precision": 0.0011021695575090355,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.00020853816381651163,
        "hf_subset": "zul_Latn-rus_Cyrl",
        "languages": [
          "zul-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.00020853816381651163,
        "precision": 0.00011004232086321638,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0012351778656126482,
        "hf_subset": "azb_Arab-rus_Cyrl",
        "languages": [
          "azb-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0012351778656126482,
        "precision": 0.001129305477131564,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.004748792368775813,
        "hf_subset": "deu_Latn-rus_Cyrl",
        "languages": [
          "deu-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.004748792368775813,
        "precision": 0.004447834774769048,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.002957732578819657,
        "hf_subset": "hat_Latn-rus_Cyrl",
        "languages": [
          "hat-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002957732578819657,
        "precision": 0.0026426316182914136,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0013840510571819884,
        "hf_subset": "kbp_Latn-rus_Cyrl",
        "languages": [
          "kbp-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0013840510571819884,
        "precision": 0.0012062508650979653,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0019996180346256672,
        "hf_subset": "luo_Latn-rus_Cyrl",
        "languages": [
          "luo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0019996180346256672,
        "precision": 0.0019880635861209404,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.004230658892299847,
        "hf_subset": "ory_Orya-rus_Cyrl",
        "languages": [
          "ory-Orya",
          "rus-Cyrl"
        ],
        "main_score": 0.004230658892299847,
        "precision": 0.0041020671834625325,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010103601502467288,
        "hf_subset": "sna_Latn-rus_Cyrl",
        "languages": [
          "sna-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0010103601502467288,
        "precision": 0.0009993525604698988,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.00206840306889714,
        "hf_subset": "tso_Latn-rus_Cyrl",
        "languages": [
          "tso-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.00206840306889714,
        "precision": 0.0020244839883108816,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001978439748104534,
        "hf_subset": "azj_Latn-rus_Cyrl",
        "languages": [
          "azj-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001978439748104534,
        "precision": 0.001977363342941471,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.002820450658352359,
        "hf_subset": "dik_Latn-rus_Cyrl",
        "languages": [
          "dik-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002820450658352359,
        "precision": 0.002570622459979551,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009902788163657728,
        "hf_subset": "hau_Latn-rus_Cyrl",
        "languages": [
          "hau-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0009902788163657728,
        "precision": 0.000989211710555584,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0034571690875621177,
        "hf_subset": "kea_Latn-rus_Cyrl",
        "languages": [
          "kea-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0034571690875621177,
        "precision": 0.0032269533935620947,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0013195233446949694,
        "hf_subset": "lus_Latn-rus_Cyrl",
        "languages": [
          "lus-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0013195233446949694,
        "precision": 0.0011867719083260247,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0031994780885033405,
        "hf_subset": "pag_Latn-rus_Cyrl",
        "languages": [
          "pag-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0031994780885033405,
        "precision": 0.0028361350743881454,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001979839053658259,
        "hf_subset": "snd_Arab-rus_Cyrl",
        "languages": [
          "snd-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.001979839053658259,
        "precision": 0.0019780650215432826,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0014862562087829476,
        "hf_subset": "tuk_Latn-rus_Cyrl",
        "languages": [
          "tuk-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0014862562087829476,
        "precision": 0.0012886132083500886,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.004942677914773957,
        "hf_subset": "bak_Cyrl-rus_Cyrl",
        "languages": [
          "bak-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.004942677914773957,
        "precision": 0.0049416956679212,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0011727116219333253,
        "hf_subset": "dyu_Latn-rus_Cyrl",
        "languages": [
          "dyu-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0011727116219333253,
        "precision": 0.001087992407204238,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.003486368703760008,
        "hf_subset": "heb_Hebr-rus_Cyrl",
        "languages": [
          "heb-Hebr",
          "rus-Cyrl"
        ],
        "main_score": 0.003486368703760008,
        "precision": 0.0032769918868317035,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 1.9509225912934225e-06,
        "hf_subset": "khk_Cyrl-rus_Cyrl",
        "languages": [
          "khk-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 1.9509225912934225e-06,
        "precision": 9.76425190207627e-07,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0018211669300449574,
        "hf_subset": "lvs_Latn-rus_Cyrl",
        "languages": [
          "lvs-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0018211669300449574,
        "precision": 0.0015768442759306494,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.004284255983814606,
        "hf_subset": "pan_Guru-rus_Cyrl",
        "languages": [
          "pan-Guru",
          "rus-Cyrl"
        ],
        "main_score": 0.004284255983814606,
        "precision": 0.004134098722172676,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 2.6491750468903984e-06,
        "hf_subset": "som_Latn-rus_Cyrl",
        "languages": [
          "som-Latn",
          "rus-Cyrl"
        ],
        "main_score": 2.6491750468903984e-06,
        "precision": 1.3263654932753268e-06,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 1.3235865709552164e-05,
        "hf_subset": "tum_Latn-rus_Cyrl",
        "languages": [
          "tum-Latn",
          "rus-Cyrl"
        ],
        "main_score": 1.3235865709552164e-05,
        "precision": 6.6483762135936055e-06,
        "recall": 0.001976284584980237
      }
    ]
  },
  "task_name": "FloresBitextMining"
}