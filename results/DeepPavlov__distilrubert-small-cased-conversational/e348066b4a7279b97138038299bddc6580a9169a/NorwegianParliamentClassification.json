{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.528167,
        "f1": 0.5219,
        "f1_weighted": 0.5219,
        "ap": 0.515287,
        "ap_weighted": 0.515287,
        "scores_per_experiment": [
          {
            "accuracy": 0.530833,
            "f1": 0.530778,
            "f1_weighted": 0.530778,
            "ap": 0.516388,
            "ap_weighted": 0.516388
          },
          {
            "accuracy": 0.501667,
            "f1": 0.474677,
            "f1_weighted": 0.474677,
            "ap": 0.500838,
            "ap_weighted": 0.500838
          },
          {
            "accuracy": 0.534167,
            "f1": 0.534128,
            "f1_weighted": 0.534128,
            "ap": 0.518272,
            "ap_weighted": 0.518272
          },
          {
            "accuracy": 0.535,
            "f1": 0.531481,
            "f1_weighted": 0.531481,
            "ap": 0.518544,
            "ap_weighted": 0.518544
          },
          {
            "accuracy": 0.568333,
            "f1": 0.565999,
            "f1_weighted": 0.565999,
            "ap": 0.539639,
            "ap_weighted": 0.539639
          },
          {
            "accuracy": 0.549167,
            "f1": 0.545554,
            "f1_weighted": 0.545554,
            "ap": 0.526635,
            "ap_weighted": 0.526635
          },
          {
            "accuracy": 0.500833,
            "f1": 0.500825,
            "f1_weighted": 0.500825,
            "ap": 0.500417,
            "ap_weighted": 0.500417
          },
          {
            "accuracy": 0.524167,
            "f1": 0.52396,
            "f1_weighted": 0.52396,
            "ap": 0.512693,
            "ap_weighted": 0.512693
          },
          {
            "accuracy": 0.5225,
            "f1": 0.507266,
            "f1_weighted": 0.507266,
            "ap": 0.511625,
            "ap_weighted": 0.511625
          },
          {
            "accuracy": 0.515,
            "f1": 0.504338,
            "f1_weighted": 0.504338,
            "ap": 0.507818,
            "ap_weighted": 0.507818
          }
        ],
        "main_score": 0.528167,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.537,
        "f1": 0.530687,
        "f1_weighted": 0.530687,
        "ap": 0.520971,
        "ap_weighted": 0.520971,
        "scores_per_experiment": [
          {
            "accuracy": 0.5475,
            "f1": 0.547158,
            "f1_weighted": 0.547158,
            "ap": 0.526138,
            "ap_weighted": 0.526138
          },
          {
            "accuracy": 0.478333,
            "f1": 0.449196,
            "f1_weighted": 0.449196,
            "ap": 0.490036,
            "ap_weighted": 0.490036
          },
          {
            "accuracy": 0.544167,
            "f1": 0.544141,
            "f1_weighted": 0.544141,
            "ap": 0.524064,
            "ap_weighted": 0.524064
          },
          {
            "accuracy": 0.568333,
            "f1": 0.564119,
            "f1_weighted": 0.564119,
            "ap": 0.538069,
            "ap_weighted": 0.538069
          },
          {
            "accuracy": 0.594167,
            "f1": 0.591271,
            "f1_weighted": 0.591271,
            "ap": 0.557745,
            "ap_weighted": 0.557745
          },
          {
            "accuracy": 0.551667,
            "f1": 0.549352,
            "f1_weighted": 0.549352,
            "ap": 0.528168,
            "ap_weighted": 0.528168
          },
          {
            "accuracy": 0.5225,
            "f1": 0.522473,
            "f1_weighted": 0.522473,
            "ap": 0.511749,
            "ap_weighted": 0.511749
          },
          {
            "accuracy": 0.525,
            "f1": 0.524979,
            "f1_weighted": 0.524979,
            "ap": 0.513133,
            "ap_weighted": 0.513133
          },
          {
            "accuracy": 0.543333,
            "f1": 0.530286,
            "f1_weighted": 0.530286,
            "ap": 0.523075,
            "ap_weighted": 0.523075
          },
          {
            "accuracy": 0.495,
            "f1": 0.483898,
            "f1_weighted": 0.483898,
            "ap": 0.497535,
            "ap_weighted": 0.497535
          }
        ],
        "main_score": 0.537,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.223998785018921,
  "kg_co2_emissions": 0.0005068073503117692
}