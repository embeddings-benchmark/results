{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001514,
        "recall": 0.004012,
        "f1": 0.00169,
        "accuracy": 0.004012,
        "main_score": 0.00169,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001005,
        "accuracy": 0.002006,
        "main_score": 0.001005,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002008,
        "accuracy": 0.003009,
        "main_score": 0.002008,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001005,
        "accuracy": 0.002006,
        "main_score": 0.001005,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001191,
        "recall": 0.008024,
        "f1": 0.001785,
        "accuracy": 0.008024,
        "main_score": 0.001785,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004013,
        "recall": 0.005015,
        "f1": 0.004014,
        "accuracy": 0.005015,
        "main_score": 0.004014,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002091,
        "recall": 0.004012,
        "f1": 0.002162,
        "accuracy": 0.004012,
        "main_score": 0.002162,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.00301,
        "recall": 0.004012,
        "f1": 0.003011,
        "accuracy": 0.004012,
        "main_score": 0.003011,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 2.6e-05,
        "recall": 0.002006,
        "f1": 5e-05,
        "accuracy": 0.002006,
        "main_score": 5e-05,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001506,
        "recall": 0.003009,
        "f1": 0.001674,
        "accuracy": 0.003009,
        "main_score": 0.001674,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004013,
        "recall": 0.005015,
        "f1": 0.004014,
        "accuracy": 0.005015,
        "main_score": 0.004014,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 2.7e-05,
        "recall": 0.002006,
        "f1": 5.4e-05,
        "accuracy": 0.002006,
        "main_score": 5.4e-05,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.007022,
        "recall": 0.008024,
        "f1": 0.007023,
        "accuracy": 0.008024,
        "main_score": 0.007023,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002341,
        "recall": 0.005015,
        "f1": 0.002844,
        "accuracy": 0.005015,
        "main_score": 0.002844,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001042,
        "recall": 0.003009,
        "f1": 0.001078,
        "accuracy": 0.003009,
        "main_score": 0.001078,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.002006,
        "f1": 8e-06,
        "accuracy": 0.002006,
        "main_score": 8e-06,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 2.7e-05,
        "recall": 0.002006,
        "f1": 5.2e-05,
        "accuracy": 0.002006,
        "main_score": 5.2e-05,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.001568,
        "recall": 0.004012,
        "f1": 0.001792,
        "accuracy": 0.004012,
        "main_score": 0.001792,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.000581,
        "recall": 0.004012,
        "f1": 0.00082,
        "accuracy": 0.004012,
        "main_score": 0.00082,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001258,
        "recall": 0.006018,
        "f1": 0.001867,
        "accuracy": 0.006018,
        "main_score": 0.001867,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.002028,
        "recall": 0.004012,
        "f1": 0.002048,
        "accuracy": 0.004012,
        "main_score": 0.002048,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001435,
        "recall": 0.005015,
        "f1": 0.001685,
        "accuracy": 0.005015,
        "main_score": 0.001685,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.003036,
        "recall": 0.005015,
        "f1": 0.003061,
        "accuracy": 0.005015,
        "main_score": 0.003061,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001005,
        "accuracy": 0.002006,
        "main_score": 0.001005,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.00302,
        "recall": 0.005015,
        "f1": 0.003031,
        "accuracy": 0.005015,
        "main_score": 0.003031,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001765,
        "recall": 0.005015,
        "f1": 0.002093,
        "accuracy": 0.005015,
        "main_score": 0.002093,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.003027,
        "recall": 0.005015,
        "f1": 0.003044,
        "accuracy": 0.005015,
        "main_score": 0.003044,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001601,
        "recall": 0.005015,
        "f1": 0.001849,
        "accuracy": 0.005015,
        "main_score": 0.001849,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000536,
        "recall": 0.003009,
        "f1": 0.000735,
        "accuracy": 0.003009,
        "main_score": 0.000735,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000444,
        "recall": 0.005015,
        "f1": 0.000752,
        "accuracy": 0.005015,
        "main_score": 0.000752,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002008,
        "accuracy": 0.003009,
        "main_score": 0.002008,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002512,
        "recall": 0.005015,
        "f1": 0.002683,
        "accuracy": 0.005015,
        "main_score": 0.002683,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 5.1e-05,
        "recall": 0.002006,
        "f1": 9.8e-05,
        "accuracy": 0.002006,
        "main_score": 9.8e-05,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.001027,
        "recall": 0.003009,
        "f1": 0.00105,
        "accuracy": 0.003009,
        "main_score": 0.00105,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.9e-05,
        "recall": 0.004012,
        "f1": 3.8e-05,
        "accuracy": 0.004012,
        "main_score": 3.8e-05,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002008,
        "accuracy": 0.003009,
        "main_score": 0.002008,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.004013,
        "recall": 0.005015,
        "f1": 0.004014,
        "accuracy": 0.005015,
        "main_score": 0.004014,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001012,
        "recall": 0.003009,
        "f1": 0.001021,
        "accuracy": 0.003009,
        "main_score": 0.001021,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.00104,
        "recall": 0.003009,
        "f1": 0.001074,
        "accuracy": 0.003009,
        "main_score": 0.001074,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001008,
        "recall": 0.003009,
        "f1": 0.001012,
        "accuracy": 0.003009,
        "main_score": 0.001012,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002008,
        "accuracy": 0.003009,
        "main_score": 0.002008,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.001023,
        "recall": 0.003009,
        "f1": 0.001042,
        "accuracy": 0.003009,
        "main_score": 0.001042,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001012,
        "recall": 0.004012,
        "f1": 0.001021,
        "accuracy": 0.004012,
        "main_score": 0.001021,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.003035,
        "recall": 0.005015,
        "f1": 0.003059,
        "accuracy": 0.005015,
        "main_score": 0.003059,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001032,
        "recall": 0.004012,
        "f1": 0.00106,
        "accuracy": 0.004012,
        "main_score": 0.00106,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001005,
        "accuracy": 0.002006,
        "main_score": 0.001005,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 6.8e-05,
        "recall": 0.003009,
        "f1": 0.000131,
        "accuracy": 0.003009,
        "main_score": 0.000131,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.001029,
        "recall": 0.003009,
        "f1": 0.001054,
        "accuracy": 0.003009,
        "main_score": 0.001054,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002008,
        "accuracy": 0.003009,
        "main_score": 0.002008,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.8e-05,
        "recall": 0.003009,
        "f1": 3.7e-05,
        "accuracy": 0.003009,
        "main_score": 3.7e-05,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.002032,
        "recall": 0.003953,
        "f1": 0.002082,
        "accuracy": 0.003953,
        "main_score": 0.002082,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.6e-05,
        "recall": 0.002964,
        "f1": 3.2e-05,
        "accuracy": 0.002964,
        "main_score": 3.2e-05,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.003468,
        "recall": 0.005929,
        "f1": 0.003641,
        "accuracy": 0.005929,
        "main_score": 0.003641,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.001976,
        "f1": 2.1e-05,
        "accuracy": 0.001976,
        "main_score": 2.1e-05,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.003962,
        "recall": 0.005929,
        "f1": 0.003972,
        "accuracy": 0.005929,
        "main_score": 0.003972,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001603,
        "recall": 0.005929,
        "f1": 0.001866,
        "accuracy": 0.005929,
        "main_score": 0.001866,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.006393,
        "recall": 0.009881,
        "f1": 0.006665,
        "accuracy": 0.009881,
        "main_score": 0.006665,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001607,
        "recall": 0.003953,
        "f1": 0.001869,
        "accuracy": 0.003953,
        "main_score": 0.001869,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.00449,
        "recall": 0.007905,
        "f1": 0.004797,
        "accuracy": 0.007905,
        "main_score": 0.004797,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001977,
        "recall": 0.002964,
        "f1": 0.001978,
        "accuracy": 0.002964,
        "main_score": 0.001978,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.003295,
        "recall": 0.004941,
        "f1": 0.003461,
        "accuracy": 0.004941,
        "main_score": 0.003461,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005447,
        "recall": 0.008893,
        "f1": 0.005754,
        "accuracy": 0.008893,
        "main_score": 0.005754,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00131,
        "recall": 0.004941,
        "f1": 0.001868,
        "accuracy": 0.004941,
        "main_score": 0.001868,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009432,
        "recall": 0.012846,
        "f1": 0.00974,
        "accuracy": 0.012846,
        "main_score": 0.00974,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002383,
        "recall": 0.004941,
        "f1": 0.002614,
        "accuracy": 0.004941,
        "main_score": 0.002614,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002471,
        "recall": 0.003953,
        "f1": 0.002637,
        "accuracy": 0.003953,
        "main_score": 0.002637,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000204,
        "recall": 0.002964,
        "f1": 0.000342,
        "accuracy": 0.002964,
        "main_score": 0.000342,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001977,
        "recall": 0.002964,
        "f1": 0.001978,
        "accuracy": 0.002964,
        "main_score": 0.001978,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 8.3e-05,
        "recall": 0.001976,
        "f1": 0.000154,
        "accuracy": 0.001976,
        "main_score": 0.000154,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.003796,
        "recall": 0.006917,
        "f1": 0.004134,
        "accuracy": 0.006917,
        "main_score": 0.004134,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000742,
        "recall": 0.002964,
        "f1": 0.001056,
        "accuracy": 0.002964,
        "main_score": 0.001056,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.004328,
        "recall": 0.006917,
        "f1": 0.004535,
        "accuracy": 0.006917,
        "main_score": 0.004535,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001611,
        "recall": 0.006917,
        "f1": 0.001883,
        "accuracy": 0.006917,
        "main_score": 0.001883,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.006463,
        "recall": 0.008893,
        "f1": 0.006666,
        "accuracy": 0.008893,
        "main_score": 0.006666,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001533,
        "recall": 0.003953,
        "f1": 0.001743,
        "accuracy": 0.003953,
        "main_score": 0.001743,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.005318,
        "recall": 0.007905,
        "f1": 0.005527,
        "accuracy": 0.007905,
        "main_score": 0.005527,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001607,
        "recall": 0.003953,
        "f1": 0.001868,
        "accuracy": 0.003953,
        "main_score": 0.001868,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001528,
        "recall": 0.005929,
        "f1": 0.001837,
        "accuracy": 0.005929,
        "main_score": 0.001837,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.004989,
        "recall": 0.006917,
        "f1": 0.005033,
        "accuracy": 0.006917,
        "main_score": 0.005033,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002971,
        "recall": 0.005929,
        "f1": 0.003308,
        "accuracy": 0.005929,
        "main_score": 0.003308,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.004006,
        "recall": 0.005929,
        "f1": 0.004053,
        "accuracy": 0.005929,
        "main_score": 0.004053,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.002964,
        "f1": 0.000674,
        "accuracy": 0.002964,
        "main_score": 0.000674,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.002043,
        "recall": 0.003953,
        "f1": 0.002102,
        "accuracy": 0.003953,
        "main_score": 0.002102,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000248,
        "recall": 0.001976,
        "f1": 0.000397,
        "accuracy": 0.001976,
        "main_score": 0.000397,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0012,
        "recall": 0.006917,
        "f1": 0.001364,
        "accuracy": 0.006917,
        "main_score": 0.001364,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.004324,
        "recall": 0.006917,
        "f1": 0.004528,
        "accuracy": 0.006917,
        "main_score": 0.004528,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001483,
        "recall": 0.002964,
        "f1": 0.001649,
        "accuracy": 0.002964,
        "main_score": 0.001649,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.004497,
        "recall": 0.006917,
        "f1": 0.004707,
        "accuracy": 0.006917,
        "main_score": 0.004707,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000664,
        "recall": 0.003953,
        "f1": 0.000951,
        "accuracy": 0.003953,
        "main_score": 0.000951,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.006269,
        "recall": 0.008893,
        "f1": 0.006445,
        "accuracy": 0.008893,
        "main_score": 0.006445,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001888,
        "recall": 0.005929,
        "f1": 0.002431,
        "accuracy": 0.005929,
        "main_score": 0.002431,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.00302,
        "recall": 0.004941,
        "f1": 0.00307,
        "accuracy": 0.004941,
        "main_score": 0.00307,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.004335,
        "recall": 0.006917,
        "f1": 0.004547,
        "accuracy": 0.006917,
        "main_score": 0.004547,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.002964,
        "f1": 0.001319,
        "accuracy": 0.002964,
        "main_score": 0.001319,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.004506,
        "recall": 0.006917,
        "f1": 0.004723,
        "accuracy": 0.006917,
        "main_score": 0.004723,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000185,
        "recall": 0.002964,
        "f1": 0.000323,
        "accuracy": 0.002964,
        "main_score": 0.000323,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.007474,
        "recall": 0.009881,
        "f1": 0.007694,
        "accuracy": 0.009881,
        "main_score": 0.007694,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000636,
        "recall": 0.002964,
        "f1": 0.000908,
        "accuracy": 0.002964,
        "main_score": 0.000908,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.004003,
        "recall": 0.005929,
        "f1": 0.004049,
        "accuracy": 0.005929,
        "main_score": 0.004049,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.004503,
        "recall": 0.006917,
        "f1": 0.004717,
        "accuracy": 0.006917,
        "main_score": 0.004717,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001976,
        "f1": 1e-05,
        "accuracy": 0.001976,
        "main_score": 1e-05,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001041,
        "recall": 0.002964,
        "f1": 0.001089,
        "accuracy": 0.002964,
        "main_score": 0.001089,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 39.56427240371704,
  "kg_co2_emissions": 0.0016064014276690765
}