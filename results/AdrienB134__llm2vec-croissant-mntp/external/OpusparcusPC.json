{
    "dataset_revision": "9e9b1f8ef51616073f47f306f7f47dd91663f86a",
    "task_name": "OpusparcusPC",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "fra-Latn",
                "languages": [
                    "None"
                ],
                "cos_sim_accuracy": 0.7343324250681199,
                "cos_sim_ap": 0.8603577758642086,
                "cos_sim_f1": 0.821602478972997,
                "cos_sim_precision": 0.7412140575079872,
                "cos_sim_recall": 0.9215491559086395,
                "dot_accuracy": 0.6886920980926431,
                "dot_ap": 0.7551070462676912,
                "dot_f1": 0.8147547628698824,
                "dot_precision": 0.6883561643835617,
                "dot_recall": 0.9980139026812312,
                "euclidean_accuracy": 0.7384196185286104,
                "euclidean_ap": 0.8627910998502644,
                "euclidean_f1": 0.825531914893617,
                "euclidean_precision": 0.7222635889798957,
                "euclidean_recall": 0.9632571996027806,
                "manhattan_accuracy": 0.7391008174386919,
                "manhattan_ap": 0.8643527306280204,
                "manhattan_f1": 0.8257349808265871,
                "manhattan_precision": 0.7231343283582089,
                "manhattan_recall": 0.9622641509433962,
                "max_accuracy": 0.7391008174386919,
                "max_ap": 0.8643527306280204,
                "max_f1": 0.8257349808265871,
                "main_score": 0.8643527306280204
            }
        ]
    }
}