{
  "dataset_revision": "3047317d2586abb183293f92b1b7d66d1c9ec81a",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "2.3.2",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.714167,
            "f1": 0.711517,
            "f1_weighted": 0.711517,
            "precision": 0.722334,
            "precision_weighted": 0.722334,
            "recall": 0.714167,
            "recall_weighted": 0.714167,
            "ap": 0.663826,
            "ap_weighted": 0.663826
          },
          {
            "accuracy": 0.6675,
            "f1": 0.650723,
            "f1_weighted": 0.650723,
            "precision": 0.707337,
            "precision_weighted": 0.707337,
            "recall": 0.6675,
            "recall_weighted": 0.6675,
            "ap": 0.603256,
            "ap_weighted": 0.603256
          },
          {
            "accuracy": 0.656667,
            "f1": 0.62394,
            "f1_weighted": 0.62394,
            "precision": 0.740323,
            "precision_weighted": 0.740323,
            "recall": 0.656667,
            "recall_weighted": 0.656667,
            "ap": 0.638198,
            "ap_weighted": 0.638198
          },
          {
            "accuracy": 0.730833,
            "f1": 0.730697,
            "f1_weighted": 0.730697,
            "precision": 0.731302,
            "precision_weighted": 0.731302,
            "recall": 0.730833,
            "recall_weighted": 0.730833,
            "ap": 0.666406,
            "ap_weighted": 0.666406
          },
          {
            "accuracy": 0.734167,
            "f1": 0.731251,
            "f1_weighted": 0.731251,
            "precision": 0.744791,
            "precision_weighted": 0.744791,
            "recall": 0.734167,
            "recall_weighted": 0.734167,
            "ap": 0.686347,
            "ap_weighted": 0.686347
          },
          {
            "accuracy": 0.6625,
            "f1": 0.629324,
            "f1_weighted": 0.629324,
            "precision": 0.753116,
            "precision_weighted": 0.753116,
            "recall": 0.6625,
            "recall_weighted": 0.6625,
            "ap": 0.597771,
            "ap_weighted": 0.597771
          },
          {
            "accuracy": 0.6925,
            "f1": 0.689846,
            "f1_weighted": 0.689846,
            "precision": 0.699322,
            "precision_weighted": 0.699322,
            "recall": 0.6925,
            "recall_weighted": 0.6925,
            "ap": 0.641718,
            "ap_weighted": 0.641718
          },
          {
            "accuracy": 0.724167,
            "f1": 0.723355,
            "f1_weighted": 0.723355,
            "precision": 0.726829,
            "precision_weighted": 0.726829,
            "recall": 0.724167,
            "recall_weighted": 0.724167,
            "ap": 0.668439,
            "ap_weighted": 0.668439
          },
          {
            "accuracy": 0.706667,
            "f1": 0.703291,
            "f1_weighted": 0.703291,
            "precision": 0.716521,
            "precision_weighted": 0.716521,
            "recall": 0.706667,
            "recall_weighted": 0.706667,
            "ap": 0.638535,
            "ap_weighted": 0.638535
          },
          {
            "accuracy": 0.724167,
            "f1": 0.719964,
            "f1_weighted": 0.719964,
            "precision": 0.738482,
            "precision_weighted": 0.738482,
            "recall": 0.724167,
            "recall_weighted": 0.724167,
            "ap": 0.678641,
            "ap_weighted": 0.678641
          }
        ],
        "accuracy": 0.701333,
        "f1": 0.691391,
        "f1_weighted": 0.691391,
        "precision": 0.728036,
        "precision_weighted": 0.728036,
        "recall": 0.701333,
        "recall_weighted": 0.701333,
        "ap": 0.648314,
        "ap_weighted": 0.648314,
        "main_score": 0.701333,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.698333,
            "f1": 0.695586,
            "f1_weighted": 0.695586,
            "precision": 0.705761,
            "precision_weighted": 0.705761,
            "recall": 0.698333,
            "recall_weighted": 0.698333,
            "ap": 0.64773,
            "ap_weighted": 0.64773
          },
          {
            "accuracy": 0.670833,
            "f1": 0.650566,
            "f1_weighted": 0.650566,
            "precision": 0.72244,
            "precision_weighted": 0.72244,
            "recall": 0.670833,
            "recall_weighted": 0.670833,
            "ap": 0.605113,
            "ap_weighted": 0.605113
          },
          {
            "accuracy": 0.661667,
            "f1": 0.630209,
            "f1_weighted": 0.630209,
            "precision": 0.745053,
            "precision_weighted": 0.745053,
            "recall": 0.661667,
            "recall_weighted": 0.661667,
            "ap": 0.64356,
            "ap_weighted": 0.64356
          },
          {
            "accuracy": 0.744167,
            "f1": 0.743504,
            "f1_weighted": 0.743504,
            "precision": 0.746717,
            "precision_weighted": 0.746717,
            "recall": 0.744167,
            "recall_weighted": 0.744167,
            "ap": 0.676199,
            "ap_weighted": 0.676199
          },
          {
            "accuracy": 0.729167,
            "f1": 0.726196,
            "f1_weighted": 0.726196,
            "precision": 0.739564,
            "precision_weighted": 0.739564,
            "recall": 0.729167,
            "recall_weighted": 0.729167,
            "ap": 0.680921,
            "ap_weighted": 0.680921
          },
          {
            "accuracy": 0.634167,
            "f1": 0.592673,
            "f1_weighted": 0.592673,
            "precision": 0.72643,
            "precision_weighted": 0.72643,
            "recall": 0.634167,
            "recall_weighted": 0.634167,
            "ap": 0.578071,
            "ap_weighted": 0.578071
          },
          {
            "accuracy": 0.688333,
            "f1": 0.687875,
            "f1_weighted": 0.687875,
            "precision": 0.689447,
            "precision_weighted": 0.689447,
            "recall": 0.688333,
            "recall_weighted": 0.688333,
            "ap": 0.632581,
            "ap_weighted": 0.632581
          },
          {
            "accuracy": 0.740833,
            "f1": 0.740468,
            "f1_weighted": 0.740468,
            "precision": 0.742196,
            "precision_weighted": 0.742196,
            "recall": 0.740833,
            "recall_weighted": 0.740833,
            "ap": 0.68312,
            "ap_weighted": 0.68312
          },
          {
            "accuracy": 0.71,
            "f1": 0.703917,
            "f1_weighted": 0.703917,
            "precision": 0.728802,
            "precision_weighted": 0.728802,
            "recall": 0.71,
            "recall_weighted": 0.71,
            "ap": 0.639275,
            "ap_weighted": 0.639275
          },
          {
            "accuracy": 0.724167,
            "f1": 0.720193,
            "f1_weighted": 0.720193,
            "precision": 0.737667,
            "precision_weighted": 0.737667,
            "recall": 0.724167,
            "recall_weighted": 0.724167,
            "ap": 0.678058,
            "ap_weighted": 0.678058
          }
        ],
        "accuracy": 0.700167,
        "f1": 0.689119,
        "f1_weighted": 0.689119,
        "precision": 0.728408,
        "precision_weighted": 0.728408,
        "recall": 0.700167,
        "recall_weighted": 0.700167,
        "ap": 0.646463,
        "ap_weighted": 0.646463,
        "main_score": 0.700167,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 2472.8158373832703,
  "kg_co2_emissions": null
}