{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8545627943017226,
      "accuracy_threshold": 0.9559576511383057,
      "ap": 0.7225550061847533,
      "f1": 0.660611487783037,
      "f1_threshold": 0.943821907043457,
      "precision": 0.6411720884032779,
      "recall": 0.6812664907651715
    },
    "dot": {
      "accuracy": 0.8545627943017226,
      "accuracy_threshold": 0.9559576511383057,
      "ap": 0.7225574305366214,
      "f1": 0.660611487783037,
      "f1_threshold": 0.9438218474388123,
      "precision": 0.6411720884032779,
      "recall": 0.6812664907651715
    },
    "euclidean": {
      "accuracy": 0.8545627943017226,
      "accuracy_threshold": 0.2967907786369324,
      "ap": 0.7225570844466731,
      "f1": 0.660611487783037,
      "f1_threshold": 0.3351958990097046,
      "precision": 0.6411720884032779,
      "recall": 0.6812664907651715
    },
    "evaluation_time": 15.29,
    "manhattan": {
      "accuracy": 0.8532514752339513,
      "accuracy_threshold": 13.81479549407959,
      "ap": 0.7152919143472247,
      "f1": 0.6560288251190322,
      "f1_threshold": 15.416821479797363,
      "precision": 0.6402913840743532,
      "recall": 0.6725593667546174
    },
    "max": {
      "accuracy": 0.8545627943017226,
      "ap": 0.7225574305366214,
      "f1": 0.660611487783037
    }
  }
}