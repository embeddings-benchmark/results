{
  "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
  "task_name": "MassiveScenarioClassification",
  "mteb_version": "2.3.0",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.695032,
            "f1": 0.686281,
            "f1_weighted": 0.690244,
            "precision": 0.671497,
            "precision_weighted": 0.743202,
            "recall": 0.762013,
            "recall_weighted": 0.695032,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.683227,
            "f1": 0.672508,
            "f1_weighted": 0.680332,
            "precision": 0.656582,
            "precision_weighted": 0.733227,
            "recall": 0.754687,
            "recall_weighted": 0.683227,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.704378,
            "f1": 0.687704,
            "f1_weighted": 0.703501,
            "precision": 0.67364,
            "precision_weighted": 0.754018,
            "recall": 0.764459,
            "recall_weighted": 0.704378,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.672405,
            "f1": 0.654088,
            "f1_weighted": 0.670439,
            "precision": 0.650613,
            "precision_weighted": 0.733047,
            "recall": 0.733369,
            "recall_weighted": 0.672405,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.673881,
            "f1": 0.664022,
            "f1_weighted": 0.664175,
            "precision": 0.66182,
            "precision_weighted": 0.737526,
            "recall": 0.746534,
            "recall_weighted": 0.673881,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.643876,
            "f1": 0.636487,
            "f1_weighted": 0.633462,
            "precision": 0.625271,
            "precision_weighted": 0.696329,
            "recall": 0.71569,
            "recall_weighted": 0.643876,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.657157,
            "f1": 0.643071,
            "f1_weighted": 0.652547,
            "precision": 0.63693,
            "precision_weighted": 0.720854,
            "recall": 0.72505,
            "recall_weighted": 0.657157,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.685686,
            "f1": 0.681536,
            "f1_weighted": 0.686511,
            "precision": 0.669084,
            "precision_weighted": 0.737633,
            "recall": 0.743951,
            "recall_weighted": 0.685686,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.707329,
            "f1": 0.693745,
            "f1_weighted": 0.705855,
            "precision": 0.677236,
            "precision_weighted": 0.747248,
            "recall": 0.760727,
            "recall_weighted": 0.707329,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.680767,
            "f1": 0.673873,
            "f1_weighted": 0.677392,
            "precision": 0.670971,
            "precision_weighted": 0.749191,
            "recall": 0.75718,
            "recall_weighted": 0.680767,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.680374,
        "f1": 0.669332,
        "f1_weighted": 0.676446,
        "precision": 0.659364,
        "precision_weighted": 0.735227,
        "recall": 0.746366,
        "recall_weighted": 0.680374,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.680374,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.702421,
            "f1": 0.695473,
            "f1_weighted": 0.698194,
            "precision": 0.678369,
            "precision_weighted": 0.738885,
            "recall": 0.762375,
            "recall_weighted": 0.702421,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.696369,
            "f1": 0.68728,
            "f1_weighted": 0.691155,
            "precision": 0.669317,
            "precision_weighted": 0.739479,
            "recall": 0.765055,
            "recall_weighted": 0.696369,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.707465,
            "f1": 0.689596,
            "f1_weighted": 0.7039,
            "precision": 0.675321,
            "precision_weighted": 0.754505,
            "recall": 0.765009,
            "recall_weighted": 0.707465,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.706792,
            "f1": 0.694885,
            "f1_weighted": 0.707192,
            "precision": 0.685981,
            "precision_weighted": 0.757518,
            "recall": 0.760653,
            "recall_weighted": 0.706792,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.685609,
            "f1": 0.674037,
            "f1_weighted": 0.673677,
            "precision": 0.678927,
            "precision_weighted": 0.753563,
            "recall": 0.754446,
            "recall_weighted": 0.685609,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.664089,
            "f1": 0.651819,
            "f1_weighted": 0.653903,
            "precision": 0.649607,
            "precision_weighted": 0.723439,
            "recall": 0.726061,
            "recall_weighted": 0.664089,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.680901,
            "f1": 0.667779,
            "f1_weighted": 0.674797,
            "precision": 0.657849,
            "precision_weighted": 0.736664,
            "recall": 0.746461,
            "recall_weighted": 0.680901,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.703093,
            "f1": 0.703851,
            "f1_weighted": 0.704089,
            "precision": 0.691043,
            "precision_weighted": 0.757619,
            "recall": 0.765606,
            "recall_weighted": 0.703093,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.717216,
            "f1": 0.709634,
            "f1_weighted": 0.713919,
            "precision": 0.695059,
            "precision_weighted": 0.757984,
            "recall": 0.773332,
            "recall_weighted": 0.717216,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.6846,
            "f1": 0.678948,
            "f1_weighted": 0.682592,
            "precision": 0.674436,
            "precision_weighted": 0.747233,
            "recall": 0.75143,
            "recall_weighted": 0.6846,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.694855,
        "f1": 0.68533,
        "f1_weighted": 0.690342,
        "precision": 0.675591,
        "precision_weighted": 0.746689,
        "recall": 0.757043,
        "recall_weighted": 0.694855,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.694855,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 22.51996922492981,
  "kg_co2_emissions": null
}