{
    "dataset_revision": "072a486a144adf7f4479a4a0dddb2152e161e1ea",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.4785474108944183,
                "f1": 0.4650175016795915,
                "main_score": 0.4785474108944183
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.3329858776059179,
                "f1": 0.3180302760125908,
                "main_score": 0.3329858776059179
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.5924680564895763,
                "f1": 0.5703769180684687,
                "main_score": 0.5924680564895763
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.4523537323470073,
                "f1": 0.44811263984286126,
                "main_score": 0.4523537323470073
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.6159045057162071,
                "f1": 0.592474421499771,
                "main_score": 0.6159045057162071
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.44922663080026903,
                "f1": 0.44076183379991657,
                "main_score": 0.44922663080026903
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.5123066577000672,
                "f1": 0.5020719330417618,
                "main_score": 0.5123066577000672
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.560995292535306,
                "f1": 0.5329421532133969,
                "main_score": 0.560995292535306
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.4612642905178211,
                "f1": 0.44441530267639634,
                "main_score": 0.4612642905178211
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6967047747141897,
                "f1": 0.6838493366054783,
                "main_score": 0.6967047747141897
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.663483523873571,
                "f1": 0.6513046416817833,
                "main_score": 0.663483523873571
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.5120040349697378,
                "f1": 0.4902889836601541,
                "main_score": 0.5120040349697378
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.4533288500336248,
                "f1": 0.42918931019709833,
                "main_score": 0.4533288500336248
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.6695359784801613,
                "f1": 0.6498788914810563,
                "main_score": 0.6695359784801613
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.4318090114324143,
                "f1": 0.4131250407417542,
                "main_score": 0.4318090114324143
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.6354068594485541,
                "f1": 0.6194829361488948,
                "main_score": 0.6354068594485541
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.44734364492266304,
                "f1": 0.4323001702247849,
                "main_score": 0.44734364492266304
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.381271015467384,
                "f1": 0.3694700198241727,
                "main_score": 0.381271015467384
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.6405514458641561,
                "f1": 0.6235033731674541,
                "main_score": 0.6405514458641561
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.4435104236718225,
                "f1": 0.4313370397574502,
                "main_score": 0.4435104236718225
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.6077000672494955,
                "f1": 0.5971546868957779,
                "main_score": 0.6077000672494955
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.6122057834566241,
                "f1": 0.5944763930628705,
                "main_score": 0.6122057834566241
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.509448554135844,
                "f1": 0.48524338247875215,
                "main_score": 0.509448554135844
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.33839946200403503,
                "f1": 0.3351899999730554,
                "main_score": 0.33839946200403503
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.3734028244788165,
                "f1": 0.356156599064704,
                "main_score": 0.3734028244788165
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.5354404841963685,
                "f1": 0.5129299915455352,
                "main_score": 0.5354404841963685
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.5335574983187625,
                "f1": 0.5146393656519295,
                "main_score": 0.5335574983187625
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.46503026227303296,
                "f1": 0.46049497734375516,
                "main_score": 0.46503026227303296
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.5826832548755883,
                "f1": 0.5610849656896157,
                "main_score": 0.5826832548755883
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.4027572293207801,
                "f1": 0.40200972385492245,
                "main_score": 0.4027572293207801
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.5964694014794889,
                "f1": 0.5839584148789065,
                "main_score": 0.5964694014794889
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.37417619367854743,
                "f1": 0.3504551731363685,
                "main_score": 0.37417619367854743
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.494082044384667,
                "f1": 0.4839369057638714,
                "main_score": 0.494082044384667
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.5209482178883659,
                "f1": 0.49915180317126984,
                "main_score": 0.5209482178883659
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.5047747141896436,
                "f1": 0.48429495257184707,
                "main_score": 0.5047747141896436
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.6669468728984532,
                "f1": 0.6540306868707009,
                "main_score": 0.6669468728984532
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.5052790854068594,
                "f1": 0.49780400354514,
                "main_score": 0.5052790854068594
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.5831540013449898,
                "f1": 0.5614414292668514,
                "main_score": 0.5831540013449898
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.47740416946872893,
                "f1": 0.4616767322761359,
                "main_score": 0.47740416946872893
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.4894418291862811,
                "f1": 0.48445352284756327,
                "main_score": 0.4894418291862811
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.5078681909885676,
                "f1": 0.4964882295494536,
                "main_score": 0.5078681909885676
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.4981170141223942,
                "f1": 0.48213234514449377,
                "main_score": 0.4981170141223942
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.5639542703429725,
                "f1": 0.5403198108523379,
                "main_score": 0.5639542703429725
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.5471082716879623,
                "f1": 0.525131441134746,
                "main_score": 0.5471082716879623
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.444250168123739,
                "f1": 0.4396016300057656,
                "main_score": 0.444250168123739
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.5020511096166779,
                "f1": 0.4886669996798709,
                "main_score": 0.5020511096166779
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.46563550773369206,
                "f1": 0.4518252022585022,
                "main_score": 0.46563550773369206
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.5674848688634835,
                "f1": 0.5429884570375382,
                "main_score": 0.5674848688634835
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.6452589105581709,
                "f1": 0.6297947342861603,
                "main_score": 0.6452589105581709
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.6706792199058508,
                "f1": 0.6536025601634017,
                "main_score": 0.6706792199058508
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.6289172831203765,
                "f1": 0.6269803707054342,
                "main_score": 0.6289172831203765
            }
        ]
    }
}