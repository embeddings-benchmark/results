{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.550132,
        "recall": 0.594784,
        "f1": 0.560776,
        "accuracy": 0.594784,
        "main_score": 0.560776,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.48606,
        "recall": 0.54664,
        "f1": 0.501009,
        "accuracy": 0.54664,
        "main_score": 0.501009,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.472775,
        "recall": 0.500502,
        "f1": 0.479944,
        "accuracy": 0.500502,
        "main_score": 0.479944,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.623624,
        "recall": 0.688064,
        "f1": 0.640158,
        "accuracy": 0.688064,
        "main_score": 0.640158,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.13444,
        "recall": 0.140421,
        "f1": 0.135604,
        "accuracy": 0.140421,
        "main_score": 0.135604,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.808415,
        "recall": 0.843531,
        "f1": 0.81788,
        "accuracy": 0.843531,
        "main_score": 0.81788,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.405048,
        "recall": 0.441324,
        "f1": 0.414016,
        "accuracy": 0.441324,
        "main_score": 0.414016,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.532101,
        "recall": 0.60682,
        "f1": 0.551562,
        "accuracy": 0.60682,
        "main_score": 0.551562,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.396462,
        "recall": 0.441324,
        "f1": 0.406419,
        "accuracy": 0.441324,
        "main_score": 0.406419,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.408583,
        "recall": 0.469408,
        "f1": 0.422493,
        "accuracy": 0.469408,
        "main_score": 0.422493,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.120229,
        "recall": 0.127382,
        "f1": 0.121933,
        "accuracy": 0.127382,
        "main_score": 0.121933,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.655309,
        "recall": 0.709127,
        "f1": 0.670319,
        "accuracy": 0.709127,
        "main_score": 0.670319,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.614107,
        "recall": 0.671013,
        "f1": 0.628663,
        "accuracy": 0.671013,
        "main_score": 0.628663,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.517413,
        "recall": 0.594784,
        "f1": 0.537001,
        "accuracy": 0.594784,
        "main_score": 0.537001,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.618524,
        "recall": 0.664995,
        "f1": 0.63111,
        "accuracy": 0.664995,
        "main_score": 0.63111,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.437609,
        "recall": 0.513541,
        "f1": 0.456527,
        "accuracy": 0.513541,
        "main_score": 0.456527,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.346814,
        "recall": 0.381143,
        "f1": 0.353937,
        "accuracy": 0.381143,
        "main_score": 0.353937,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.603252,
        "recall": 0.67001,
        "f1": 0.620916,
        "accuracy": 0.67001,
        "main_score": 0.620916,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.329517,
        "recall": 0.366098,
        "f1": 0.337121,
        "accuracy": 0.366098,
        "main_score": 0.337121,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.334683,
        "recall": 0.41324,
        "f1": 0.352857,
        "accuracy": 0.41324,
        "main_score": 0.352857,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.050444,
        "recall": 0.055165,
        "f1": 0.051303,
        "accuracy": 0.055165,
        "main_score": 0.051303,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.559891,
        "recall": 0.61986,
        "f1": 0.575219,
        "accuracy": 0.61986,
        "main_score": 0.575219,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.10242,
        "recall": 0.107322,
        "f1": 0.103188,
        "accuracy": 0.107322,
        "main_score": 0.103188,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.715028,
        "recall": 0.768305,
        "f1": 0.729509,
        "accuracy": 0.768305,
        "main_score": 0.729509,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.417583,
        "recall": 0.459378,
        "f1": 0.427794,
        "accuracy": 0.459378,
        "main_score": 0.427794,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.468686,
        "recall": 0.540622,
        "f1": 0.487115,
        "accuracy": 0.540622,
        "main_score": 0.487115,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.346276,
        "recall": 0.374122,
        "f1": 0.3534,
        "accuracy": 0.374122,
        "main_score": 0.3534,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.642427,
        "recall": 0.698094,
        "f1": 0.657054,
        "accuracy": 0.698094,
        "main_score": 0.657054,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.026403,
        "recall": 0.032096,
        "f1": 0.027082,
        "accuracy": 0.032096,
        "main_score": 0.027082,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.094918,
        "recall": 0.1334,
        "f1": 0.101712,
        "accuracy": 0.1334,
        "main_score": 0.101712,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.016564,
        "recall": 0.02006,
        "f1": 0.01708,
        "accuracy": 0.02006,
        "main_score": 0.01708,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.36342,
        "recall": 0.449348,
        "f1": 0.384698,
        "accuracy": 0.449348,
        "main_score": 0.384698,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.055391,
        "recall": 0.059178,
        "f1": 0.055882,
        "accuracy": 0.059178,
        "main_score": 0.055882,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.678135,
        "recall": 0.734203,
        "f1": 0.69312,
        "accuracy": 0.734203,
        "main_score": 0.69312,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.058395,
        "recall": 0.06319,
        "f1": 0.059216,
        "accuracy": 0.06319,
        "main_score": 0.059216,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.638832,
        "recall": 0.702106,
        "f1": 0.655347,
        "accuracy": 0.702106,
        "main_score": 0.655347,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.009028,
        "recall": 0.01003,
        "f1": 0.00903,
        "accuracy": 0.01003,
        "main_score": 0.00903,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007633,
        "recall": 0.024072,
        "f1": 0.009621,
        "accuracy": 0.024072,
        "main_score": 0.009621,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.00301,
        "recall": 0.004012,
        "f1": 0.003011,
        "accuracy": 0.004012,
        "main_score": 0.003011,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.055188,
        "recall": 0.100301,
        "f1": 0.064241,
        "accuracy": 0.100301,
        "main_score": 0.064241,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.042986,
        "recall": 0.047141,
        "f1": 0.043677,
        "accuracy": 0.047141,
        "main_score": 0.043677,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.601146,
        "recall": 0.65998,
        "f1": 0.616277,
        "accuracy": 0.65998,
        "main_score": 0.616277,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.018573,
        "recall": 0.021063,
        "f1": 0.018757,
        "accuracy": 0.021063,
        "main_score": 0.018757,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.344021,
        "recall": 0.425276,
        "f1": 0.363635,
        "accuracy": 0.425276,
        "main_score": 0.363635,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.036633,
        "recall": 0.04012,
        "f1": 0.037156,
        "accuracy": 0.04012,
        "main_score": 0.037156,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.630907,
        "recall": 0.69007,
        "f1": 0.646106,
        "accuracy": 0.69007,
        "main_score": 0.646106,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.047167,
        "recall": 0.05015,
        "f1": 0.047526,
        "accuracy": 0.05015,
        "main_score": 0.047526,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.587937,
        "recall": 0.650953,
        "f1": 0.604494,
        "accuracy": 0.650953,
        "main_score": 0.604494,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.058364,
        "recall": 0.062187,
        "f1": 0.058839,
        "accuracy": 0.062187,
        "main_score": 0.058839,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.643378,
        "recall": 0.705115,
        "f1": 0.660228,
        "accuracy": 0.705115,
        "main_score": 0.660228,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.020232,
        "recall": 0.03009,
        "f1": 0.020868,
        "accuracy": 0.03009,
        "main_score": 0.020868,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.035429,
        "recall": 0.065196,
        "f1": 0.039099,
        "accuracy": 0.065196,
        "main_score": 0.039099,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.064387,
        "recall": 0.069208,
        "f1": 0.065202,
        "accuracy": 0.069208,
        "main_score": 0.065202,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.643554,
        "recall": 0.709127,
        "f1": 0.661945,
        "accuracy": 0.709127,
        "main_score": 0.661945,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.045837,
        "recall": 0.05015,
        "f1": 0.046536,
        "accuracy": 0.05015,
        "main_score": 0.046536,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.654443,
        "recall": 0.718154,
        "f1": 0.671902,
        "accuracy": 0.718154,
        "main_score": 0.671902,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 3e-06,
        "accuracy": 0.001003,
        "main_score": 3e-06,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002508,
        "recall": 0.013039,
        "f1": 0.002933,
        "accuracy": 0.013039,
        "main_score": 0.002933,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.578768,
        "recall": 0.635375,
        "f1": 0.591673,
        "accuracy": 0.635375,
        "main_score": 0.591673,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.463198,
        "recall": 0.537549,
        "f1": 0.480355,
        "accuracy": 0.537549,
        "main_score": 0.480355,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.488791,
        "recall": 0.532609,
        "f1": 0.499844,
        "accuracy": 0.532609,
        "main_score": 0.499844,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.644604,
        "recall": 0.718379,
        "f1": 0.66513,
        "accuracy": 0.718379,
        "main_score": 0.66513,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.21869,
        "recall": 0.23419,
        "f1": 0.221657,
        "accuracy": 0.23419,
        "main_score": 0.221657,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.796308,
        "recall": 0.84585,
        "f1": 0.81054,
        "accuracy": 0.84585,
        "main_score": 0.81054,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.432063,
        "recall": 0.480237,
        "f1": 0.443527,
        "accuracy": 0.480237,
        "main_score": 0.443527,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.542807,
        "recall": 0.616601,
        "f1": 0.561839,
        "accuracy": 0.616601,
        "main_score": 0.561839,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.405291,
        "recall": 0.458498,
        "f1": 0.416384,
        "accuracy": 0.458498,
        "main_score": 0.416384,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.444912,
        "recall": 0.519763,
        "f1": 0.462781,
        "accuracy": 0.519763,
        "main_score": 0.462781,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.155286,
        "recall": 0.170949,
        "f1": 0.15853,
        "accuracy": 0.170949,
        "main_score": 0.15853,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.641399,
        "recall": 0.708498,
        "f1": 0.659531,
        "accuracy": 0.708498,
        "main_score": 0.659531,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.61725,
        "recall": 0.68083,
        "f1": 0.633415,
        "accuracy": 0.68083,
        "main_score": 0.633415,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.501244,
        "recall": 0.58498,
        "f1": 0.522849,
        "accuracy": 0.58498,
        "main_score": 0.522849,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.614183,
        "recall": 0.681818,
        "f1": 0.632508,
        "accuracy": 0.681818,
        "main_score": 0.632508,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.445893,
        "recall": 0.516798,
        "f1": 0.462895,
        "accuracy": 0.516798,
        "main_score": 0.462895,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.35687,
        "recall": 0.408103,
        "f1": 0.367666,
        "accuracy": 0.408103,
        "main_score": 0.367666,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.636987,
        "recall": 0.70751,
        "f1": 0.655712,
        "accuracy": 0.70751,
        "main_score": 0.655712,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.353736,
        "recall": 0.40415,
        "f1": 0.363632,
        "accuracy": 0.40415,
        "main_score": 0.363632,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.308841,
        "recall": 0.384387,
        "f1": 0.325635,
        "accuracy": 0.384387,
        "main_score": 0.325635,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.081748,
        "recall": 0.090909,
        "f1": 0.083507,
        "accuracy": 0.090909,
        "main_score": 0.083507,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.575069,
        "recall": 0.641304,
        "f1": 0.593064,
        "accuracy": 0.641304,
        "main_score": 0.593064,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.156777,
        "recall": 0.170949,
        "f1": 0.159379,
        "accuracy": 0.170949,
        "main_score": 0.159379,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.709585,
        "recall": 0.770751,
        "f1": 0.726768,
        "accuracy": 0.770751,
        "main_score": 0.726768,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.410813,
        "recall": 0.465415,
        "f1": 0.4226,
        "accuracy": 0.465415,
        "main_score": 0.4226,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.46337,
        "recall": 0.539526,
        "f1": 0.48186,
        "accuracy": 0.539526,
        "main_score": 0.48186,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.358087,
        "recall": 0.396245,
        "f1": 0.366851,
        "accuracy": 0.396245,
        "main_score": 0.366851,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.615291,
        "recall": 0.679842,
        "f1": 0.632124,
        "accuracy": 0.679842,
        "main_score": 0.632124,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.027389,
        "recall": 0.035573,
        "f1": 0.028207,
        "accuracy": 0.035573,
        "main_score": 0.028207,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.093251,
        "recall": 0.126482,
        "f1": 0.099954,
        "accuracy": 0.126482,
        "main_score": 0.099954,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.032949,
        "recall": 0.037549,
        "f1": 0.033783,
        "accuracy": 0.037549,
        "main_score": 0.033783,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.326818,
        "recall": 0.414032,
        "f1": 0.347568,
        "accuracy": 0.414032,
        "main_score": 0.347568,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.10615,
        "recall": 0.118577,
        "f1": 0.10866,
        "accuracy": 0.118577,
        "main_score": 0.10866,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.678824,
        "recall": 0.738142,
        "f1": 0.69442,
        "accuracy": 0.738142,
        "main_score": 0.69442,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.08673,
        "recall": 0.096838,
        "f1": 0.088551,
        "accuracy": 0.096838,
        "main_score": 0.088551,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.622408,
        "recall": 0.69664,
        "f1": 0.641999,
        "accuracy": 0.69664,
        "main_score": 0.641999,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.001978,
        "recall": 0.002964,
        "f1": 0.001979,
        "accuracy": 0.002964,
        "main_score": 0.001979,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007734,
        "recall": 0.025692,
        "f1": 0.009949,
        "accuracy": 0.025692,
        "main_score": 0.009949,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.010212,
        "recall": 0.011858,
        "f1": 0.010378,
        "accuracy": 0.011858,
        "main_score": 0.010378,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.056089,
        "recall": 0.102767,
        "f1": 0.064632,
        "accuracy": 0.102767,
        "main_score": 0.064632,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.088314,
        "recall": 0.098814,
        "f1": 0.09033,
        "accuracy": 0.098814,
        "main_score": 0.09033,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.579209,
        "recall": 0.652174,
        "f1": 0.598294,
        "accuracy": 0.652174,
        "main_score": 0.598294,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.042276,
        "recall": 0.045455,
        "f1": 0.04262,
        "accuracy": 0.045455,
        "main_score": 0.04262,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.306689,
        "recall": 0.393281,
        "f1": 0.327439,
        "accuracy": 0.393281,
        "main_score": 0.327439,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.079013,
        "recall": 0.089921,
        "f1": 0.081228,
        "accuracy": 0.089921,
        "main_score": 0.081228,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.629778,
        "recall": 0.695652,
        "f1": 0.64758,
        "accuracy": 0.695652,
        "main_score": 0.64758,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.092547,
        "recall": 0.104743,
        "f1": 0.095043,
        "accuracy": 0.104743,
        "main_score": 0.095043,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.569418,
        "recall": 0.641304,
        "f1": 0.587881,
        "accuracy": 0.641304,
        "main_score": 0.587881,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.093576,
        "recall": 0.103755,
        "f1": 0.095715,
        "accuracy": 0.103755,
        "main_score": 0.095715,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.618068,
        "recall": 0.694664,
        "f1": 0.63924,
        "accuracy": 0.694664,
        "main_score": 0.63924,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.027709,
        "recall": 0.037549,
        "f1": 0.029071,
        "accuracy": 0.037549,
        "main_score": 0.029071,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.040695,
        "recall": 0.074111,
        "f1": 0.045326,
        "accuracy": 0.074111,
        "main_score": 0.045326,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.106806,
        "recall": 0.119565,
        "f1": 0.109434,
        "accuracy": 0.119565,
        "main_score": 0.109434,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.636406,
        "recall": 0.702569,
        "f1": 0.654259,
        "accuracy": 0.702569,
        "main_score": 0.654259,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.108083,
        "recall": 0.120553,
        "f1": 0.110557,
        "accuracy": 0.120553,
        "main_score": 0.110557,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.623892,
        "recall": 0.69664,
        "f1": 0.643584,
        "accuracy": 0.69664,
        "main_score": 0.643584,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.001977,
        "recall": 0.002964,
        "f1": 0.001978,
        "accuracy": 0.002964,
        "main_score": 0.001978,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003268,
        "recall": 0.017787,
        "f1": 0.004242,
        "accuracy": 0.017787,
        "main_score": 0.004242,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 3275.5127363204956,
  "kg_co2_emissions": 0.3074707160761766
}