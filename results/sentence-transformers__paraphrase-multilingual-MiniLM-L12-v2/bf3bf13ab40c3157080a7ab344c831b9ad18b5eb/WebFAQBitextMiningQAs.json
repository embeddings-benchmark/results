{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQAs",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 0.990695,
        "recall": 0.993432,
        "f1": 0.991516,
        "accuracy": 0.993432,
        "main_score": 0.991516,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.857356,
        "recall": 0.884458,
        "f1": 0.864642,
        "accuracy": 0.884458,
        "main_score": 0.864642,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.963994,
        "recall": 0.973029,
        "f1": 0.966822,
        "accuracy": 0.973029,
        "main_score": 0.966822,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.987094,
        "recall": 0.99115,
        "f1": 0.988446,
        "accuracy": 0.99115,
        "main_score": 0.988446,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.972962,
        "recall": 0.978588,
        "f1": 0.974653,
        "accuracy": 0.978588,
        "main_score": 0.974653,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.976671,
        "recall": 0.984127,
        "f1": 0.979076,
        "accuracy": 0.984127,
        "main_score": 0.979076,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.973069,
        "recall": 0.979761,
        "f1": 0.974992,
        "accuracy": 0.979761,
        "main_score": 0.974992,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.990712,
        "recall": 0.993808,
        "f1": 0.991744,
        "accuracy": 0.993808,
        "main_score": 0.991744,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.823826,
        "recall": 0.852747,
        "f1": 0.832381,
        "accuracy": 0.852747,
        "main_score": 0.832381,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.471849,
        "recall": 0.571429,
        "f1": 0.497153,
        "accuracy": 0.571429,
        "main_score": 0.497153,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.895191,
        "recall": 0.919714,
        "f1": 0.902453,
        "accuracy": 0.919714,
        "main_score": 0.902453,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.970663,
        "recall": 0.976431,
        "f1": 0.97226,
        "accuracy": 0.976431,
        "main_score": 0.97226,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.987324,
        "recall": 0.991549,
        "f1": 0.988732,
        "accuracy": 0.991549,
        "main_score": 0.988732,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.994396,
        "recall": 0.996264,
        "f1": 0.995019,
        "accuracy": 0.996264,
        "main_score": 0.995019,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.967508,
        "recall": 0.9737,
        "f1": 0.96929,
        "accuracy": 0.9737,
        "main_score": 0.96929,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.98173,
        "recall": 0.98645,
        "f1": 0.983175,
        "accuracy": 0.98645,
        "main_score": 0.983175,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.975592,
        "recall": 0.980936,
        "f1": 0.97714,
        "accuracy": 0.980936,
        "main_score": 0.97714,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.961205,
        "recall": 0.968085,
        "f1": 0.962939,
        "accuracy": 0.968085,
        "main_score": 0.962939,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.950169,
        "recall": 0.962838,
        "f1": 0.953491,
        "accuracy": 0.962838,
        "main_score": 0.953491,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.964937,
        "recall": 0.972067,
        "f1": 0.966824,
        "accuracy": 0.972067,
        "main_score": 0.966824,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.993143,
        "recall": 0.995429,
        "f1": 0.993905,
        "accuracy": 0.995429,
        "main_score": 0.993905,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.986527,
        "recall": 0.991018,
        "f1": 0.988024,
        "accuracy": 0.991018,
        "main_score": 0.988024,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.984655,
        "recall": 0.988417,
        "f1": 0.985892,
        "accuracy": 0.988417,
        "main_score": 0.985892,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.976562,
        "recall": 0.983209,
        "f1": 0.978576,
        "accuracy": 0.983209,
        "main_score": 0.978576,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.995296,
        "recall": 0.996864,
        "f1": 0.995819,
        "accuracy": 0.996864,
        "main_score": 0.995819,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.980231,
        "recall": 0.984672,
        "f1": 0.981366,
        "accuracy": 0.984672,
        "main_score": 0.981366,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.940608,
        "recall": 0.955801,
        "f1": 0.94508,
        "accuracy": 0.955801,
        "main_score": 0.94508,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.966148,
        "recall": 0.975875,
        "f1": 0.969261,
        "accuracy": 0.975875,
        "main_score": 0.969261,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.980831,
        "recall": 0.98722,
        "f1": 0.982961,
        "accuracy": 0.98722,
        "main_score": 0.982961,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.971374,
        "recall": 0.980916,
        "f1": 0.974555,
        "accuracy": 0.980916,
        "main_score": 0.974555,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.98382,
        "recall": 0.98869,
        "f1": 0.985391,
        "accuracy": 0.98869,
        "main_score": 0.985391,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.989309,
        "recall": 0.992639,
        "f1": 0.990361,
        "accuracy": 0.992639,
        "main_score": 0.990361,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.982177,
        "recall": 0.98796,
        "f1": 0.984065,
        "accuracy": 0.98796,
        "main_score": 0.984065,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.994297,
        "recall": 0.996198,
        "f1": 0.99493,
        "accuracy": 0.996198,
        "main_score": 0.99493,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.990213,
        "recall": 0.993092,
        "f1": 0.991077,
        "accuracy": 0.993092,
        "main_score": 0.991077,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.988629,
        "recall": 0.992203,
        "f1": 0.989766,
        "accuracy": 0.992203,
        "main_score": 0.989766,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.989074,
        "recall": 0.992716,
        "f1": 0.990288,
        "accuracy": 0.992716,
        "main_score": 0.990288,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.989523,
        "recall": 0.993015,
        "f1": 0.990687,
        "accuracy": 0.993015,
        "main_score": 0.990687,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.981878,
        "recall": 0.98682,
        "f1": 0.983526,
        "accuracy": 0.98682,
        "main_score": 0.983526,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.985915,
        "recall": 0.99061,
        "f1": 0.98748,
        "accuracy": 0.99061,
        "main_score": 0.98748,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.972361,
        "recall": 0.979856,
        "f1": 0.974784,
        "accuracy": 0.979856,
        "main_score": 0.974784,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.987139,
        "recall": 0.990094,
        "f1": 0.988095,
        "accuracy": 0.990094,
        "main_score": 0.988095,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.969211,
        "recall": 0.976122,
        "f1": 0.971225,
        "accuracy": 0.976122,
        "main_score": 0.971225,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.889623,
        "recall": 0.914634,
        "f1": 0.896816,
        "accuracy": 0.914634,
        "main_score": 0.896816,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.977229,
        "recall": 0.983122,
        "f1": 0.979044,
        "accuracy": 0.983122,
        "main_score": 0.979044,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.971391,
        "recall": 0.977831,
        "f1": 0.973344,
        "accuracy": 0.977831,
        "main_score": 0.973344,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.927072,
        "recall": 0.939781,
        "f1": 0.930444,
        "accuracy": 0.939781,
        "main_score": 0.930444,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.823443,
        "recall": 0.857143,
        "f1": 0.833595,
        "accuracy": 0.857143,
        "main_score": 0.833595,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.988374,
        "recall": 0.991345,
        "f1": 0.989289,
        "accuracy": 0.991345,
        "main_score": 0.989289,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.982989,
        "recall": 0.988086,
        "f1": 0.984564,
        "accuracy": 0.988086,
        "main_score": 0.984564,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.856506,
        "recall": 0.896613,
        "f1": 0.868899,
        "accuracy": 0.896613,
        "main_score": 0.868899,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.983404,
        "recall": 0.988347,
        "f1": 0.984993,
        "accuracy": 0.988347,
        "main_score": 0.984993,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.86331,
        "recall": 0.8998,
        "f1": 0.874527,
        "accuracy": 0.8998,
        "main_score": 0.874527,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.971123,
        "recall": 0.979536,
        "f1": 0.973852,
        "accuracy": 0.979536,
        "main_score": 0.973852,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.985099,
        "recall": 0.990066,
        "f1": 0.986755,
        "accuracy": 0.990066,
        "main_score": 0.986755,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.98495,
        "recall": 0.989967,
        "f1": 0.986622,
        "accuracy": 0.989967,
        "main_score": 0.986622,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.996411,
        "recall": 0.997608,
        "f1": 0.99681,
        "accuracy": 0.997608,
        "main_score": 0.99681,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.995946,
        "recall": 0.997297,
        "f1": 0.996396,
        "accuracy": 0.997297,
        "main_score": 0.996396,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.996035,
        "recall": 0.997356,
        "f1": 0.996475,
        "accuracy": 0.997356,
        "main_score": 0.996475,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.963573,
        "recall": 0.969564,
        "f1": 0.965273,
        "accuracy": 0.969564,
        "main_score": 0.965273,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.93965,
        "recall": 0.943977,
        "f1": 0.9409,
        "accuracy": 0.943977,
        "main_score": 0.9409,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.450267,
        "recall": 0.574924,
        "f1": 0.48243,
        "accuracy": 0.574924,
        "main_score": 0.48243,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.922514,
        "recall": 0.931378,
        "f1": 0.925135,
        "accuracy": 0.931378,
        "main_score": 0.925135,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.943003,
        "recall": 0.947304,
        "f1": 0.944272,
        "accuracy": 0.947304,
        "main_score": 0.944272,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.928788,
        "recall": 0.932002,
        "f1": 0.929372,
        "accuracy": 0.932002,
        "main_score": 0.929372,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.921867,
        "recall": 0.9267,
        "f1": 0.923324,
        "accuracy": 0.9267,
        "main_score": 0.923324,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.908595,
        "recall": 0.915692,
        "f1": 0.910353,
        "accuracy": 0.915692,
        "main_score": 0.910353,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.929293,
        "recall": 0.933072,
        "f1": 0.930461,
        "accuracy": 0.933072,
        "main_score": 0.930461,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.947908,
        "recall": 0.950094,
        "f1": 0.948534,
        "accuracy": 0.950094,
        "main_score": 0.948534,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.971812,
        "recall": 0.98056,
        "f1": 0.97464,
        "accuracy": 0.98056,
        "main_score": 0.97464,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.400854,
        "recall": 0.530612,
        "f1": 0.434942,
        "accuracy": 0.530612,
        "main_score": 0.434942,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.972137,
        "recall": 0.980891,
        "f1": 0.974978,
        "accuracy": 0.980891,
        "main_score": 0.974978,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.979658,
        "recall": 0.985997,
        "f1": 0.981707,
        "accuracy": 0.985997,
        "main_score": 0.981707,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.985579,
        "recall": 0.989939,
        "f1": 0.986945,
        "accuracy": 0.989939,
        "main_score": 0.986945,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.977246,
        "recall": 0.984363,
        "f1": 0.979551,
        "accuracy": 0.984363,
        "main_score": 0.979551,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.988512,
        "recall": 0.992218,
        "f1": 0.989717,
        "accuracy": 0.992218,
        "main_score": 0.989717,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.976299,
        "recall": 0.983434,
        "f1": 0.978583,
        "accuracy": 0.983434,
        "main_score": 0.978583,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.988883,
        "recall": 0.99255,
        "f1": 0.990096,
        "accuracy": 0.99255,
        "main_score": 0.990096,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.481039,
        "recall": 0.59366,
        "f1": 0.511829,
        "accuracy": 0.59366,
        "main_score": 0.511829,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.976225,
        "recall": 0.983652,
        "f1": 0.978655,
        "accuracy": 0.983652,
        "main_score": 0.978655,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.977205,
        "recall": 0.984405,
        "f1": 0.97954,
        "accuracy": 0.984405,
        "main_score": 0.97954,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.958451,
        "recall": 0.969116,
        "f1": 0.961561,
        "accuracy": 0.969116,
        "main_score": 0.961561,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.978942,
        "recall": 0.98545,
        "f1": 0.981047,
        "accuracy": 0.98545,
        "main_score": 0.981047,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.987506,
        "recall": 0.991502,
        "f1": 0.988821,
        "accuracy": 0.991502,
        "main_score": 0.988821,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.980732,
        "recall": 0.986873,
        "f1": 0.982738,
        "accuracy": 0.986873,
        "main_score": 0.982738,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.985351,
        "recall": 0.989812,
        "f1": 0.986773,
        "accuracy": 0.989812,
        "main_score": 0.986773,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.568198,
        "recall": 0.64133,
        "f1": 0.586768,
        "accuracy": 0.64133,
        "main_score": 0.586768,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.613916,
        "recall": 0.697749,
        "f1": 0.636998,
        "accuracy": 0.697749,
        "main_score": 0.636998,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.53957,
        "recall": 0.618768,
        "f1": 0.559224,
        "accuracy": 0.618768,
        "main_score": 0.559224,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.554234,
        "recall": 0.636612,
        "f1": 0.574854,
        "accuracy": 0.636612,
        "main_score": 0.574854,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.591249,
        "recall": 0.673077,
        "f1": 0.613545,
        "accuracy": 0.673077,
        "main_score": 0.613545,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.978566,
        "recall": 0.985153,
        "f1": 0.980648,
        "accuracy": 0.985153,
        "main_score": 0.980648,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.947991,
        "recall": 0.961447,
        "f1": 0.951895,
        "accuracy": 0.961447,
        "main_score": 0.951895,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.981417,
        "recall": 0.987184,
        "f1": 0.983278,
        "accuracy": 0.987184,
        "main_score": 0.983278,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.984474,
        "recall": 0.98869,
        "f1": 0.985799,
        "accuracy": 0.98869,
        "main_score": 0.985799,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.976057,
        "recall": 0.983005,
        "f1": 0.978242,
        "accuracy": 0.983005,
        "main_score": 0.978242,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.982184,
        "recall": 0.987344,
        "f1": 0.983822,
        "accuracy": 0.987344,
        "main_score": 0.983822,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.963626,
        "recall": 0.972973,
        "f1": 0.966311,
        "accuracy": 0.972973,
        "main_score": 0.966311,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.978469,
        "recall": 0.984902,
        "f1": 0.980558,
        "accuracy": 0.984902,
        "main_score": 0.980558,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.984208,
        "recall": 0.988573,
        "f1": 0.985509,
        "accuracy": 0.988573,
        "main_score": 0.985509,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.98199,
        "recall": 0.987546,
        "f1": 0.983775,
        "accuracy": 0.987546,
        "main_score": 0.983775,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.991719,
        "recall": 0.994282,
        "f1": 0.992541,
        "accuracy": 0.994282,
        "main_score": 0.992541,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.970678,
        "recall": 0.978053,
        "f1": 0.972864,
        "accuracy": 0.978053,
        "main_score": 0.972864,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.984714,
        "recall": 0.988669,
        "f1": 0.985883,
        "accuracy": 0.988669,
        "main_score": 0.985883,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.979671,
        "recall": 0.985786,
        "f1": 0.981649,
        "accuracy": 0.985786,
        "main_score": 0.981649,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.981684,
        "recall": 0.984518,
        "f1": 0.982536,
        "accuracy": 0.984518,
        "main_score": 0.982536,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.978944,
        "recall": 0.985129,
        "f1": 0.980855,
        "accuracy": 0.985129,
        "main_score": 0.980855,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.986874,
        "recall": 0.99086,
        "f1": 0.988143,
        "accuracy": 0.99086,
        "main_score": 0.988143,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.985512,
        "recall": 0.989847,
        "f1": 0.986875,
        "accuracy": 0.989847,
        "main_score": 0.986875,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.984889,
        "recall": 0.989926,
        "f1": 0.986568,
        "accuracy": 0.989926,
        "main_score": 0.986568,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.98468,
        "recall": 0.989322,
        "f1": 0.986227,
        "accuracy": 0.989322,
        "main_score": 0.986227,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.985599,
        "recall": 0.989967,
        "f1": 0.987032,
        "accuracy": 0.989967,
        "main_score": 0.987032,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.42754,
        "recall": 0.501704,
        "f1": 0.445645,
        "accuracy": 0.501704,
        "main_score": 0.445645,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.378893,
        "recall": 0.431095,
        "f1": 0.392835,
        "accuracy": 0.431095,
        "main_score": 0.392835,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.553886,
        "recall": 0.616803,
        "f1": 0.570588,
        "accuracy": 0.616803,
        "main_score": 0.570588,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.968835,
        "recall": 0.978862,
        "f1": 0.972087,
        "accuracy": 0.978862,
        "main_score": 0.972087,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.946789,
        "recall": 0.963303,
        "f1": 0.951988,
        "accuracy": 0.963303,
        "main_score": 0.951988,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.933333,
        "recall": 0.955556,
        "f1": 0.940741,
        "accuracy": 0.955556,
        "main_score": 0.940741,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.764239,
        "recall": 0.815534,
        "f1": 0.779415,
        "accuracy": 0.815534,
        "main_score": 0.779415,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.872509,
        "recall": 0.904639,
        "f1": 0.881787,
        "accuracy": 0.904639,
        "main_score": 0.881787,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.930882,
        "recall": 0.95,
        "f1": 0.936667,
        "accuracy": 0.95,
        "main_score": 0.936667,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.994304,
        "recall": 0.996203,
        "f1": 0.994937,
        "accuracy": 0.996203,
        "main_score": 0.994937,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.991098,
        "recall": 0.994065,
        "f1": 0.992087,
        "accuracy": 0.994065,
        "main_score": 0.992087,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.984976,
        "recall": 0.989624,
        "f1": 0.986489,
        "accuracy": 0.989624,
        "main_score": 0.986489,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.933898,
        "recall": 0.951562,
        "f1": 0.939445,
        "accuracy": 0.951562,
        "main_score": 0.939445,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.800613,
        "recall": 0.84743,
        "f1": 0.813812,
        "accuracy": 0.84743,
        "main_score": 0.813812,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.40388,
        "recall": 0.484272,
        "f1": 0.423647,
        "accuracy": 0.484272,
        "main_score": 0.423647,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.982099,
        "recall": 0.985935,
        "f1": 0.983212,
        "accuracy": 0.985935,
        "main_score": 0.983212,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.977865,
        "recall": 0.985243,
        "f1": 0.980324,
        "accuracy": 0.985243,
        "main_score": 0.980324,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.987779,
        "recall": 0.991523,
        "f1": 0.988962,
        "accuracy": 0.991523,
        "main_score": 0.988962,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.959555,
        "recall": 0.963874,
        "f1": 0.960713,
        "accuracy": 0.963874,
        "main_score": 0.960713,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.972891,
        "recall": 0.981177,
        "f1": 0.975536,
        "accuracy": 0.981177,
        "main_score": 0.975536,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.982101,
        "recall": 0.98638,
        "f1": 0.983435,
        "accuracy": 0.98638,
        "main_score": 0.983435,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.99404,
        "recall": 0.996026,
        "f1": 0.994702,
        "accuracy": 0.996026,
        "main_score": 0.994702,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 0.973621,
        "recall": 0.982014,
        "f1": 0.976319,
        "accuracy": 0.982014,
        "main_score": 0.976319,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.989423,
        "recall": 0.992739,
        "f1": 0.990483,
        "accuracy": 0.992739,
        "main_score": 0.990483,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.967251,
        "recall": 0.97729,
        "f1": 0.970453,
        "accuracy": 0.97729,
        "main_score": 0.970453,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.918084,
        "recall": 0.936508,
        "f1": 0.923545,
        "accuracy": 0.936508,
        "main_score": 0.923545,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.967365,
        "recall": 0.977467,
        "f1": 0.970587,
        "accuracy": 0.977467,
        "main_score": 0.970587,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.987376,
        "recall": 0.990847,
        "f1": 0.988436,
        "accuracy": 0.990847,
        "main_score": 0.988436,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.977242,
        "recall": 0.983497,
        "f1": 0.979092,
        "accuracy": 0.983497,
        "main_score": 0.979092,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.530866,
        "recall": 0.650838,
        "f1": 0.565736,
        "accuracy": 0.650838,
        "main_score": 0.565736,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.955174,
        "recall": 0.969076,
        "f1": 0.959626,
        "accuracy": 0.969076,
        "main_score": 0.959626,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.991069,
        "recall": 0.993696,
        "f1": 0.991901,
        "accuracy": 0.993696,
        "main_score": 0.991901,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.824663,
        "recall": 0.878613,
        "f1": 0.841522,
        "accuracy": 0.878613,
        "main_score": 0.841522,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.97902,
        "recall": 0.985927,
        "f1": 0.9813,
        "accuracy": 0.985927,
        "main_score": 0.9813,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.981928,
        "recall": 0.987952,
        "f1": 0.983936,
        "accuracy": 0.987952,
        "main_score": 0.983936,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.997468,
        "recall": 0.998312,
        "f1": 0.99775,
        "accuracy": 0.998312,
        "main_score": 0.99775,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.973214,
        "recall": 0.982143,
        "f1": 0.97619,
        "accuracy": 0.982143,
        "main_score": 0.97619,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.96162,
        "recall": 0.974414,
        "f1": 0.965885,
        "accuracy": 0.974414,
        "main_score": 0.965885,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.979304,
        "recall": 0.985845,
        "f1": 0.981436,
        "accuracy": 0.985845,
        "main_score": 0.981436,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.96471,
        "recall": 0.973368,
        "f1": 0.967056,
        "accuracy": 0.973368,
        "main_score": 0.967056,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.98684,
        "recall": 0.990827,
        "f1": 0.988095,
        "accuracy": 0.990827,
        "main_score": 0.988095,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.978602,
        "recall": 0.98533,
        "f1": 0.980759,
        "accuracy": 0.98533,
        "main_score": 0.980759,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.994077,
        "recall": 0.996051,
        "f1": 0.994735,
        "accuracy": 0.996051,
        "main_score": 0.994735,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.985331,
        "recall": 0.98953,
        "f1": 0.986677,
        "accuracy": 0.98953,
        "main_score": 0.986677,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.991772,
        "recall": 0.994515,
        "f1": 0.992686,
        "accuracy": 0.994515,
        "main_score": 0.992686,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.97954,
        "recall": 0.986207,
        "f1": 0.981724,
        "accuracy": 0.986207,
        "main_score": 0.981724,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.973486,
        "recall": 0.981437,
        "f1": 0.976048,
        "accuracy": 0.981437,
        "main_score": 0.976048,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.988449,
        "recall": 0.990099,
        "f1": 0.988999,
        "accuracy": 0.990099,
        "main_score": 0.988999,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.990647,
        "recall": 0.993672,
        "f1": 0.991646,
        "accuracy": 0.993672,
        "main_score": 0.991646,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.489423,
        "recall": 0.6098,
        "f1": 0.522342,
        "accuracy": 0.6098,
        "main_score": 0.522342,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.934521,
        "recall": 0.948403,
        "f1": 0.938575,
        "accuracy": 0.948403,
        "main_score": 0.938575,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.987046,
        "recall": 0.991316,
        "f1": 0.988457,
        "accuracy": 0.991316,
        "main_score": 0.988457,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.983951,
        "recall": 0.988883,
        "f1": 0.98553,
        "accuracy": 0.988883,
        "main_score": 0.98553,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.937189,
        "recall": 0.955224,
        "f1": 0.942786,
        "accuracy": 0.955224,
        "main_score": 0.942786,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.991693,
        "recall": 0.994462,
        "f1": 0.992616,
        "accuracy": 0.994462,
        "main_score": 0.992616,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.990926,
        "recall": 0.993547,
        "f1": 0.991766,
        "accuracy": 0.993547,
        "main_score": 0.991766,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 4797.130652427673,
  "kg_co2_emissions": null
}