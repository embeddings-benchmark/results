{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.14311,
        "recall": 0.186523,
        "f1": 0.154692,
        "accuracy": 0.186523,
        "main_score": 0.154692,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.095089,
        "recall": 0.160156,
        "f1": 0.111263,
        "accuracy": 0.160156,
        "main_score": 0.111263,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.060034,
        "recall": 0.103516,
        "f1": 0.069984,
        "accuracy": 0.103516,
        "main_score": 0.069984,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.0006,
        "recall": 0.003906,
        "f1": 0.000863,
        "accuracy": 0.003906,
        "main_score": 0.000863,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.076002,
        "recall": 0.12793,
        "f1": 0.088081,
        "accuracy": 0.12793,
        "main_score": 0.088081,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.125145,
        "recall": 0.175781,
        "f1": 0.137968,
        "accuracy": 0.175781,
        "main_score": 0.137968,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.081048,
        "recall": 0.131836,
        "f1": 0.093461,
        "accuracy": 0.131836,
        "main_score": 0.093461,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.135171,
        "recall": 0.174805,
        "f1": 0.145813,
        "accuracy": 0.174805,
        "main_score": 0.145813,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.017626,
        "recall": 0.044922,
        "f1": 0.022501,
        "accuracy": 0.044922,
        "main_score": 0.022501,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.142182,
        "recall": 0.201172,
        "f1": 0.157999,
        "accuracy": 0.201172,
        "main_score": 0.157999,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.034746,
        "recall": 0.0625,
        "f1": 0.041168,
        "accuracy": 0.0625,
        "main_score": 0.041168,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.129957,
        "recall": 0.168945,
        "f1": 0.139523,
        "accuracy": 0.168945,
        "main_score": 0.139523,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.130311,
        "recall": 0.178711,
        "f1": 0.14249,
        "accuracy": 0.178711,
        "main_score": 0.14249,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.122544,
        "recall": 0.174805,
        "f1": 0.136139,
        "accuracy": 0.174805,
        "main_score": 0.136139,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.125933,
        "recall": 0.173828,
        "f1": 0.137588,
        "accuracy": 0.173828,
        "main_score": 0.137588,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.035711,
        "recall": 0.070312,
        "f1": 0.04189,
        "accuracy": 0.070312,
        "main_score": 0.04189,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.07865,
        "recall": 0.107422,
        "f1": 0.085052,
        "accuracy": 0.107422,
        "main_score": 0.085052,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.095974,
        "recall": 0.136719,
        "f1": 0.105618,
        "accuracy": 0.136719,
        "main_score": 0.105618,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.067634,
        "recall": 0.113281,
        "f1": 0.078238,
        "accuracy": 0.113281,
        "main_score": 0.078238,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.043768,
        "recall": 0.078125,
        "f1": 0.050866,
        "accuracy": 0.078125,
        "main_score": 0.050866,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.055664,
        "recall": 0.094727,
        "f1": 0.063565,
        "accuracy": 0.094727,
        "main_score": 0.063565,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.021331,
        "recall": 0.050781,
        "f1": 0.02619,
        "accuracy": 0.050781,
        "main_score": 0.02619,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.140002,
        "recall": 0.188477,
        "f1": 0.152277,
        "accuracy": 0.188477,
        "main_score": 0.152277,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.062882,
        "recall": 0.112305,
        "f1": 0.073915,
        "accuracy": 0.112305,
        "main_score": 0.073915,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.042543,
        "recall": 0.081055,
        "f1": 0.049855,
        "accuracy": 0.081055,
        "main_score": 0.049855,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002904,
        "recall": 0.006836,
        "f1": 0.003349,
        "accuracy": 0.006836,
        "main_score": 0.003349,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.055467,
        "recall": 0.09082,
        "f1": 0.064153,
        "accuracy": 0.09082,
        "main_score": 0.064153,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.093177,
        "recall": 0.135742,
        "f1": 0.103513,
        "accuracy": 0.135742,
        "main_score": 0.103513,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.05678,
        "recall": 0.091797,
        "f1": 0.06515,
        "accuracy": 0.091797,
        "main_score": 0.06515,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.120118,
        "recall": 0.155273,
        "f1": 0.128927,
        "accuracy": 0.155273,
        "main_score": 0.128927,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.014899,
        "recall": 0.039062,
        "f1": 0.019605,
        "accuracy": 0.039062,
        "main_score": 0.019605,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.114419,
        "recall": 0.161133,
        "f1": 0.126101,
        "accuracy": 0.161133,
        "main_score": 0.126101,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.031678,
        "recall": 0.0625,
        "f1": 0.038174,
        "accuracy": 0.0625,
        "main_score": 0.038174,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.116247,
        "recall": 0.149414,
        "f1": 0.124612,
        "accuracy": 0.149414,
        "main_score": 0.124612,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.122789,
        "recall": 0.163086,
        "f1": 0.133059,
        "accuracy": 0.163086,
        "main_score": 0.133059,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.136075,
        "recall": 0.18457,
        "f1": 0.149499,
        "accuracy": 0.18457,
        "main_score": 0.149499,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.086101,
        "recall": 0.12207,
        "f1": 0.094552,
        "accuracy": 0.12207,
        "main_score": 0.094552,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.029141,
        "recall": 0.063477,
        "f1": 0.035036,
        "accuracy": 0.063477,
        "main_score": 0.035036,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.067734,
        "recall": 0.09668,
        "f1": 0.074485,
        "accuracy": 0.09668,
        "main_score": 0.074485,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.163723,
        "recall": 0.211914,
        "f1": 0.1761,
        "accuracy": 0.211914,
        "main_score": 0.1761,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.043809,
        "recall": 0.078125,
        "f1": 0.051543,
        "accuracy": 0.078125,
        "main_score": 0.051543,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.041339,
        "recall": 0.074219,
        "f1": 0.049075,
        "accuracy": 0.074219,
        "main_score": 0.049075,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.047864,
        "recall": 0.080078,
        "f1": 0.05559,
        "accuracy": 0.080078,
        "main_score": 0.05559,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.014899,
        "recall": 0.03418,
        "f1": 0.01789,
        "accuracy": 0.03418,
        "main_score": 0.01789,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.145828,
        "recall": 0.206055,
        "f1": 0.16172,
        "accuracy": 0.206055,
        "main_score": 0.16172,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.107151,
        "recall": 0.155273,
        "f1": 0.118828,
        "accuracy": 0.155273,
        "main_score": 0.118828,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.333308,
        "recall": 0.369141,
        "f1": 0.342198,
        "accuracy": 0.369141,
        "main_score": 0.342198,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.105933,
        "recall": 0.131836,
        "f1": 0.112229,
        "accuracy": 0.131836,
        "main_score": 0.112229,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.367815,
        "recall": 0.408203,
        "f1": 0.378953,
        "accuracy": 0.408203,
        "main_score": 0.378953,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.1485,
        "recall": 0.22168,
        "f1": 0.166236,
        "accuracy": 0.22168,
        "main_score": 0.166236,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.350628,
        "recall": 0.384766,
        "f1": 0.360057,
        "accuracy": 0.384766,
        "main_score": 0.360057,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.11015,
        "recall": 0.157227,
        "f1": 0.12165,
        "accuracy": 0.157227,
        "main_score": 0.12165,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.285522,
        "recall": 0.311523,
        "f1": 0.291648,
        "accuracy": 0.311523,
        "main_score": 0.291648,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.096565,
        "recall": 0.151367,
        "f1": 0.109365,
        "accuracy": 0.151367,
        "main_score": 0.109365,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.293783,
        "recall": 0.321289,
        "f1": 0.302018,
        "accuracy": 0.321289,
        "main_score": 0.302018,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.093577,
        "recall": 0.138672,
        "f1": 0.105314,
        "accuracy": 0.138672,
        "main_score": 0.105314,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.090474,
        "recall": 0.139648,
        "f1": 0.102099,
        "accuracy": 0.139648,
        "main_score": 0.102099,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.10207,
        "recall": 0.150391,
        "f1": 0.114546,
        "accuracy": 0.150391,
        "main_score": 0.114546,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.094454,
        "recall": 0.139648,
        "f1": 0.106038,
        "accuracy": 0.139648,
        "main_score": 0.106038,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.307726,
        "recall": 0.342773,
        "f1": 0.315613,
        "accuracy": 0.342773,
        "main_score": 0.315613,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.065304,
        "recall": 0.091797,
        "f1": 0.071204,
        "accuracy": 0.091797,
        "main_score": 0.071204,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.064666,
        "recall": 0.102539,
        "f1": 0.073225,
        "accuracy": 0.102539,
        "main_score": 0.073225,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.346637,
        "recall": 0.379883,
        "f1": 0.355512,
        "accuracy": 0.379883,
        "main_score": 0.355512,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.325299,
        "recall": 0.353516,
        "f1": 0.33285,
        "accuracy": 0.353516,
        "main_score": 0.33285,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.344309,
        "recall": 0.378906,
        "f1": 0.353676,
        "accuracy": 0.378906,
        "main_score": 0.353676,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.297245,
        "recall": 0.321289,
        "f1": 0.302736,
        "accuracy": 0.321289,
        "main_score": 0.302736,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.081794,
        "recall": 0.114258,
        "f1": 0.089799,
        "accuracy": 0.114258,
        "main_score": 0.089799,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.067909,
        "recall": 0.099609,
        "f1": 0.075439,
        "accuracy": 0.099609,
        "main_score": 0.075439,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.342274,
        "recall": 0.370117,
        "f1": 0.349475,
        "accuracy": 0.370117,
        "main_score": 0.349475,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.109129,
        "recall": 0.134766,
        "f1": 0.114938,
        "accuracy": 0.134766,
        "main_score": 0.114938,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.3241,
        "recall": 0.360352,
        "f1": 0.332975,
        "accuracy": 0.360352,
        "main_score": 0.332975,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.13178,
        "recall": 0.198242,
        "f1": 0.146862,
        "accuracy": 0.198242,
        "main_score": 0.146862,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.377139,
        "recall": 0.421875,
        "f1": 0.38943,
        "accuracy": 0.421875,
        "main_score": 0.38943,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.05965,
        "recall": 0.094727,
        "f1": 0.067263,
        "accuracy": 0.094727,
        "main_score": 0.067263,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.290509,
        "recall": 0.319336,
        "f1": 0.297069,
        "accuracy": 0.319336,
        "main_score": 0.297069,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.099117,
        "recall": 0.141602,
        "f1": 0.109211,
        "accuracy": 0.141602,
        "main_score": 0.109211,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.277799,
        "recall": 0.301758,
        "f1": 0.283667,
        "accuracy": 0.301758,
        "main_score": 0.283667,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.072327,
        "recall": 0.104492,
        "f1": 0.080488,
        "accuracy": 0.104492,
        "main_score": 0.080488,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.064736,
        "recall": 0.09668,
        "f1": 0.071943,
        "accuracy": 0.09668,
        "main_score": 0.071943,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.079706,
        "recall": 0.112305,
        "f1": 0.086868,
        "accuracy": 0.112305,
        "main_score": 0.086868,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.089646,
        "recall": 0.125,
        "f1": 0.098128,
        "accuracy": 0.125,
        "main_score": 0.098128,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.31802,
        "recall": 0.371094,
        "f1": 0.329913,
        "accuracy": 0.371094,
        "main_score": 0.329913,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.034932,
        "recall": 0.056641,
        "f1": 0.039973,
        "accuracy": 0.056641,
        "main_score": 0.039973,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.085871,
        "recall": 0.128906,
        "f1": 0.096382,
        "accuracy": 0.128906,
        "main_score": 0.096382,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.373826,
        "recall": 0.416992,
        "f1": 0.385345,
        "accuracy": 0.416992,
        "main_score": 0.385345,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.31718,
        "recall": 0.337891,
        "f1": 0.322797,
        "accuracy": 0.337891,
        "main_score": 0.322797,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.322766,
        "recall": 0.34375,
        "f1": 0.327755,
        "accuracy": 0.34375,
        "main_score": 0.327755,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.300787,
        "recall": 0.325195,
        "f1": 0.306451,
        "accuracy": 0.325195,
        "main_score": 0.306451,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.002213,
        "recall": 0.008789,
        "f1": 0.002901,
        "accuracy": 0.008789,
        "main_score": 0.002901,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.00157,
        "recall": 0.007812,
        "f1": 0.002057,
        "accuracy": 0.007812,
        "main_score": 0.002057,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.178399,
        "recall": 0.231445,
        "f1": 0.190039,
        "accuracy": 0.231445,
        "main_score": 0.190039,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.175584,
        "recall": 0.228516,
        "f1": 0.186847,
        "accuracy": 0.228516,
        "main_score": 0.186847,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.155176,
        "recall": 0.21582,
        "f1": 0.168863,
        "accuracy": 0.21582,
        "main_score": 0.168863,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.033538,
        "recall": 0.079102,
        "f1": 0.042242,
        "accuracy": 0.079102,
        "main_score": 0.042242,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.170976,
        "recall": 0.225586,
        "f1": 0.183139,
        "accuracy": 0.225586,
        "main_score": 0.183139,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00241,
        "recall": 0.007812,
        "f1": 0.002786,
        "accuracy": 0.007812,
        "main_score": 0.002786,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.169257,
        "recall": 0.224609,
        "f1": 0.18226,
        "accuracy": 0.224609,
        "main_score": 0.18226,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.00236,
        "recall": 0.011719,
        "f1": 0.003048,
        "accuracy": 0.011719,
        "main_score": 0.003048,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.153648,
        "recall": 0.203125,
        "f1": 0.164493,
        "accuracy": 0.203125,
        "main_score": 0.164493,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000607,
        "recall": 0.003906,
        "f1": 0.000878,
        "accuracy": 0.003906,
        "main_score": 0.000878,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000917,
        "recall": 0.005859,
        "f1": 0.001414,
        "accuracy": 0.005859,
        "main_score": 0.001414,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.000572,
        "recall": 0.005859,
        "f1": 0.00099,
        "accuracy": 0.005859,
        "main_score": 0.00099,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.002099,
        "recall": 0.006836,
        "f1": 0.002765,
        "accuracy": 0.006836,
        "main_score": 0.002765,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.170881,
        "recall": 0.232422,
        "f1": 0.182862,
        "accuracy": 0.232422,
        "main_score": 0.182862,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001882,
        "recall": 0.007812,
        "f1": 0.002748,
        "accuracy": 0.007812,
        "main_score": 0.002748,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001958,
        "recall": 0.008789,
        "f1": 0.002501,
        "accuracy": 0.008789,
        "main_score": 0.002501,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.176746,
        "recall": 0.230469,
        "f1": 0.188822,
        "accuracy": 0.230469,
        "main_score": 0.188822,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.158059,
        "recall": 0.219727,
        "f1": 0.171107,
        "accuracy": 0.219727,
        "main_score": 0.171107,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.15166,
        "recall": 0.211914,
        "f1": 0.164266,
        "accuracy": 0.211914,
        "main_score": 0.164266,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.156907,
        "recall": 0.211914,
        "f1": 0.169375,
        "accuracy": 0.211914,
        "main_score": 0.169375,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.102305,
        "recall": 0.147461,
        "f1": 0.113722,
        "accuracy": 0.147461,
        "main_score": 0.113722,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.076969,
        "recall": 0.124023,
        "f1": 0.088266,
        "accuracy": 0.124023,
        "main_score": 0.088266,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.349314,
        "recall": 0.392578,
        "f1": 0.360714,
        "accuracy": 0.392578,
        "main_score": 0.360714,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.312539,
        "recall": 0.351562,
        "f1": 0.321855,
        "accuracy": 0.351562,
        "main_score": 0.321855,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.085826,
        "recall": 0.114258,
        "f1": 0.091832,
        "accuracy": 0.114258,
        "main_score": 0.091832,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.139961,
        "recall": 0.214844,
        "f1": 0.157536,
        "accuracy": 0.214844,
        "main_score": 0.157536,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.339707,
        "recall": 0.382812,
        "f1": 0.351439,
        "accuracy": 0.382812,
        "main_score": 0.351439,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.122348,
        "recall": 0.171875,
        "f1": 0.135118,
        "accuracy": 0.171875,
        "main_score": 0.135118,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.255386,
        "recall": 0.286133,
        "f1": 0.263213,
        "accuracy": 0.286133,
        "main_score": 0.263213,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.091285,
        "recall": 0.135742,
        "f1": 0.101604,
        "accuracy": 0.135742,
        "main_score": 0.101604,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.300119,
        "recall": 0.337891,
        "f1": 0.310482,
        "accuracy": 0.337891,
        "main_score": 0.310482,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.104004,
        "recall": 0.147461,
        "f1": 0.114732,
        "accuracy": 0.147461,
        "main_score": 0.114732,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.077201,
        "recall": 0.116211,
        "f1": 0.086234,
        "accuracy": 0.116211,
        "main_score": 0.086234,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.092908,
        "recall": 0.136719,
        "f1": 0.103317,
        "accuracy": 0.136719,
        "main_score": 0.103317,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.08961,
        "recall": 0.137695,
        "f1": 0.10132,
        "accuracy": 0.137695,
        "main_score": 0.10132,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.287131,
        "recall": 0.329102,
        "f1": 0.296898,
        "accuracy": 0.329102,
        "main_score": 0.296898,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.054286,
        "recall": 0.083984,
        "f1": 0.060798,
        "accuracy": 0.083984,
        "main_score": 0.060798,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.065878,
        "recall": 0.110352,
        "f1": 0.075948,
        "accuracy": 0.110352,
        "main_score": 0.075948,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.330493,
        "recall": 0.366211,
        "f1": 0.339531,
        "accuracy": 0.366211,
        "main_score": 0.339531,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.33732,
        "recall": 0.375977,
        "f1": 0.347166,
        "accuracy": 0.375977,
        "main_score": 0.347166,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.342981,
        "recall": 0.378906,
        "f1": 0.351955,
        "accuracy": 0.378906,
        "main_score": 0.351955,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.278508,
        "recall": 0.304688,
        "f1": 0.284129,
        "accuracy": 0.304688,
        "main_score": 0.284129,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.119737,
        "recall": 0.170898,
        "f1": 0.132717,
        "accuracy": 0.170898,
        "main_score": 0.132717,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.097943,
        "recall": 0.142578,
        "f1": 0.108728,
        "accuracy": 0.142578,
        "main_score": 0.108728,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.161943,
        "recall": 0.214844,
        "f1": 0.173729,
        "accuracy": 0.214844,
        "main_score": 0.173729,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.140671,
        "recall": 0.186523,
        "f1": 0.150573,
        "accuracy": 0.186523,
        "main_score": 0.150573,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.029078,
        "recall": 0.036133,
        "f1": 0.03052,
        "accuracy": 0.036133,
        "main_score": 0.03052,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.165609,
        "recall": 0.21582,
        "f1": 0.17825,
        "accuracy": 0.21582,
        "main_score": 0.17825,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.154979,
        "recall": 0.206055,
        "f1": 0.166965,
        "accuracy": 0.206055,
        "main_score": 0.166965,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.122692,
        "recall": 0.170898,
        "f1": 0.134962,
        "accuracy": 0.170898,
        "main_score": 0.134962,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.100569,
        "recall": 0.125,
        "f1": 0.104732,
        "accuracy": 0.125,
        "main_score": 0.104732,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.117357,
        "recall": 0.171875,
        "f1": 0.131278,
        "accuracy": 0.171875,
        "main_score": 0.131278,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.112229,
        "recall": 0.140625,
        "f1": 0.118546,
        "accuracy": 0.140625,
        "main_score": 0.118546,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.124316,
        "recall": 0.173828,
        "f1": 0.136745,
        "accuracy": 0.173828,
        "main_score": 0.136745,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.090375,
        "recall": 0.131836,
        "f1": 0.100432,
        "accuracy": 0.131836,
        "main_score": 0.100432,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.092442,
        "recall": 0.139648,
        "f1": 0.102473,
        "accuracy": 0.139648,
        "main_score": 0.102473,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.090437,
        "recall": 0.133789,
        "f1": 0.100233,
        "accuracy": 0.133789,
        "main_score": 0.100233,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.109399,
        "recall": 0.141602,
        "f1": 0.115653,
        "accuracy": 0.141602,
        "main_score": 0.115653,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.05279,
        "recall": 0.080078,
        "f1": 0.058169,
        "accuracy": 0.080078,
        "main_score": 0.058169,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.080127,
        "recall": 0.119141,
        "f1": 0.089787,
        "accuracy": 0.119141,
        "main_score": 0.089787,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.150786,
        "recall": 0.1875,
        "f1": 0.159024,
        "accuracy": 0.1875,
        "main_score": 0.159024,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.132652,
        "recall": 0.166992,
        "f1": 0.140615,
        "accuracy": 0.166992,
        "main_score": 0.140615,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.14461,
        "recall": 0.179688,
        "f1": 0.15252,
        "accuracy": 0.179688,
        "main_score": 0.15252,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.099069,
        "recall": 0.118164,
        "f1": 0.102217,
        "accuracy": 0.118164,
        "main_score": 0.102217,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.11284,
        "recall": 0.151367,
        "f1": 0.122897,
        "accuracy": 0.151367,
        "main_score": 0.122897,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.087249,
        "recall": 0.120117,
        "f1": 0.095698,
        "accuracy": 0.120117,
        "main_score": 0.095698,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.338119,
        "recall": 0.37793,
        "f1": 0.348739,
        "accuracy": 0.37793,
        "main_score": 0.348739,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.360347,
        "recall": 0.411133,
        "f1": 0.373374,
        "accuracy": 0.411133,
        "main_score": 0.373374,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.094874,
        "recall": 0.120117,
        "f1": 0.100666,
        "accuracy": 0.120117,
        "main_score": 0.100666,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.349046,
        "recall": 0.384766,
        "f1": 0.359295,
        "accuracy": 0.384766,
        "main_score": 0.359295,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.14012,
        "recall": 0.206055,
        "f1": 0.155822,
        "accuracy": 0.206055,
        "main_score": 0.155822,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.074971,
        "recall": 0.113281,
        "f1": 0.083977,
        "accuracy": 0.113281,
        "main_score": 0.083977,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.283429,
        "recall": 0.314453,
        "f1": 0.291035,
        "accuracy": 0.314453,
        "main_score": 0.291035,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.110657,
        "recall": 0.15918,
        "f1": 0.122774,
        "accuracy": 0.15918,
        "main_score": 0.122774,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.281039,
        "recall": 0.308594,
        "f1": 0.288155,
        "accuracy": 0.308594,
        "main_score": 0.288155,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.082002,
        "recall": 0.118164,
        "f1": 0.091036,
        "accuracy": 0.118164,
        "main_score": 0.091036,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.087049,
        "recall": 0.123047,
        "f1": 0.095591,
        "accuracy": 0.123047,
        "main_score": 0.095591,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.078231,
        "recall": 0.116211,
        "f1": 0.08712,
        "accuracy": 0.116211,
        "main_score": 0.08712,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.09647,
        "recall": 0.136719,
        "f1": 0.105892,
        "accuracy": 0.136719,
        "main_score": 0.105892,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.314106,
        "recall": 0.359375,
        "f1": 0.324222,
        "accuracy": 0.359375,
        "main_score": 0.324222,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.043159,
        "recall": 0.06543,
        "f1": 0.047891,
        "accuracy": 0.06543,
        "main_score": 0.047891,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.073363,
        "recall": 0.106445,
        "f1": 0.081449,
        "accuracy": 0.106445,
        "main_score": 0.081449,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.409302,
        "recall": 0.451172,
        "f1": 0.420922,
        "accuracy": 0.451172,
        "main_score": 0.420922,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.299558,
        "recall": 0.330078,
        "f1": 0.307323,
        "accuracy": 0.330078,
        "main_score": 0.307323,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.329158,
        "recall": 0.359375,
        "f1": 0.336306,
        "accuracy": 0.359375,
        "main_score": 0.336306,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.306459,
        "recall": 0.335938,
        "f1": 0.312627,
        "accuracy": 0.335938,
        "main_score": 0.312627,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.128661,
        "recall": 0.177734,
        "f1": 0.140665,
        "accuracy": 0.177734,
        "main_score": 0.140665,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.133537,
        "recall": 0.185547,
        "f1": 0.146271,
        "accuracy": 0.185547,
        "main_score": 0.146271,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.07207,
        "recall": 0.129883,
        "f1": 0.085068,
        "accuracy": 0.129883,
        "main_score": 0.085068,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.035621,
        "recall": 0.075195,
        "f1": 0.043072,
        "accuracy": 0.075195,
        "main_score": 0.043072,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001363,
        "recall": 0.004883,
        "f1": 0.001581,
        "accuracy": 0.004883,
        "main_score": 0.001581,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.081187,
        "recall": 0.139648,
        "f1": 0.095924,
        "accuracy": 0.139648,
        "main_score": 0.095924,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.10399,
        "recall": 0.160156,
        "f1": 0.11848,
        "accuracy": 0.160156,
        "main_score": 0.11848,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.056047,
        "recall": 0.097656,
        "f1": 0.065755,
        "accuracy": 0.097656,
        "main_score": 0.065755,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016183,
        "recall": 0.036133,
        "f1": 0.019737,
        "accuracy": 0.036133,
        "main_score": 0.019737,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.101601,
        "recall": 0.147461,
        "f1": 0.112567,
        "accuracy": 0.147461,
        "main_score": 0.112567,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.053833,
        "recall": 0.103516,
        "f1": 0.064923,
        "accuracy": 0.103516,
        "main_score": 0.064923,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.137642,
        "recall": 0.186523,
        "f1": 0.150823,
        "accuracy": 0.186523,
        "main_score": 0.150823,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.098918,
        "recall": 0.151367,
        "f1": 0.111968,
        "accuracy": 0.151367,
        "main_score": 0.111968,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.110507,
        "recall": 0.162109,
        "f1": 0.122091,
        "accuracy": 0.162109,
        "main_score": 0.122091,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.12938,
        "recall": 0.172852,
        "f1": 0.139883,
        "accuracy": 0.172852,
        "main_score": 0.139883,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.022025,
        "recall": 0.057617,
        "f1": 0.028015,
        "accuracy": 0.057617,
        "main_score": 0.028015,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.084764,
        "recall": 0.125,
        "f1": 0.093593,
        "accuracy": 0.125,
        "main_score": 0.093593,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.070944,
        "recall": 0.110352,
        "f1": 0.080688,
        "accuracy": 0.110352,
        "main_score": 0.080688,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.047255,
        "recall": 0.081055,
        "f1": 0.054638,
        "accuracy": 0.081055,
        "main_score": 0.054638,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.061913,
        "recall": 0.107422,
        "f1": 0.073404,
        "accuracy": 0.107422,
        "main_score": 0.073404,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.078764,
        "recall": 0.124023,
        "f1": 0.089885,
        "accuracy": 0.124023,
        "main_score": 0.089885,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.011147,
        "recall": 0.03125,
        "f1": 0.013954,
        "accuracy": 0.03125,
        "main_score": 0.013954,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.028616,
        "recall": 0.048828,
        "f1": 0.031594,
        "accuracy": 0.048828,
        "main_score": 0.031594,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.032224,
        "recall": 0.055664,
        "f1": 0.036422,
        "accuracy": 0.055664,
        "main_score": 0.036422,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.274265,
        "recall": 0.292969,
        "f1": 0.278156,
        "accuracy": 0.292969,
        "main_score": 0.278156,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.271232,
        "recall": 0.294922,
        "f1": 0.276348,
        "accuracy": 0.294922,
        "main_score": 0.276348,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.104309,
        "recall": 0.133789,
        "f1": 0.111429,
        "accuracy": 0.133789,
        "main_score": 0.111429,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.2568,
        "recall": 0.275391,
        "f1": 0.261076,
        "accuracy": 0.275391,
        "main_score": 0.261076,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.059552,
        "recall": 0.112305,
        "f1": 0.070301,
        "accuracy": 0.112305,
        "main_score": 0.070301,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.271278,
        "recall": 0.294922,
        "f1": 0.276169,
        "accuracy": 0.294922,
        "main_score": 0.276169,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.024525,
        "recall": 0.040039,
        "f1": 0.027776,
        "accuracy": 0.040039,
        "main_score": 0.027776,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.028219,
        "recall": 0.053711,
        "f1": 0.033563,
        "accuracy": 0.053711,
        "main_score": 0.033563,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.254716,
        "recall": 0.273438,
        "f1": 0.259622,
        "accuracy": 0.273438,
        "main_score": 0.259622,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.023787,
        "recall": 0.041992,
        "f1": 0.027016,
        "accuracy": 0.041992,
        "main_score": 0.027016,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.022701,
        "recall": 0.039062,
        "f1": 0.025515,
        "accuracy": 0.039062,
        "main_score": 0.025515,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.030121,
        "recall": 0.052734,
        "f1": 0.03423,
        "accuracy": 0.052734,
        "main_score": 0.03423,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.024181,
        "recall": 0.041992,
        "f1": 0.027786,
        "accuracy": 0.041992,
        "main_score": 0.027786,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.258668,
        "recall": 0.279297,
        "f1": 0.262854,
        "accuracy": 0.279297,
        "main_score": 0.262854,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.0128,
        "recall": 0.027344,
        "f1": 0.015199,
        "accuracy": 0.027344,
        "main_score": 0.015199,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.024708,
        "recall": 0.045898,
        "f1": 0.028894,
        "accuracy": 0.045898,
        "main_score": 0.028894,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.258338,
        "recall": 0.27832,
        "f1": 0.262926,
        "accuracy": 0.27832,
        "main_score": 0.262926,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.26549,
        "recall": 0.285156,
        "f1": 0.269758,
        "accuracy": 0.285156,
        "main_score": 0.269758,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.260689,
        "recall": 0.280273,
        "f1": 0.265258,
        "accuracy": 0.280273,
        "main_score": 0.265258,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.331944,
        "recall": 0.363281,
        "f1": 0.340015,
        "accuracy": 0.363281,
        "main_score": 0.340015,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.130601,
        "recall": 0.174805,
        "f1": 0.141552,
        "accuracy": 0.174805,
        "main_score": 0.141552,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.124192,
        "recall": 0.169922,
        "f1": 0.136106,
        "accuracy": 0.169922,
        "main_score": 0.136106,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.06328,
        "recall": 0.105469,
        "f1": 0.071957,
        "accuracy": 0.105469,
        "main_score": 0.071957,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.05847,
        "recall": 0.099609,
        "f1": 0.0672,
        "accuracy": 0.099609,
        "main_score": 0.0672,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001599,
        "recall": 0.004883,
        "f1": 0.001879,
        "accuracy": 0.004883,
        "main_score": 0.001879,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.056293,
        "recall": 0.095703,
        "f1": 0.065604,
        "accuracy": 0.095703,
        "main_score": 0.065604,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.110261,
        "recall": 0.163086,
        "f1": 0.123409,
        "accuracy": 0.163086,
        "main_score": 0.123409,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.080795,
        "recall": 0.12793,
        "f1": 0.093297,
        "accuracy": 0.12793,
        "main_score": 0.093297,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.098682,
        "recall": 0.137695,
        "f1": 0.108288,
        "accuracy": 0.137695,
        "main_score": 0.108288,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.020275,
        "recall": 0.039062,
        "f1": 0.023768,
        "accuracy": 0.039062,
        "main_score": 0.023768,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.032612,
        "recall": 0.056641,
        "f1": 0.037757,
        "accuracy": 0.056641,
        "main_score": 0.037757,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.11329,
        "recall": 0.143555,
        "f1": 0.120368,
        "accuracy": 0.143555,
        "main_score": 0.120368,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.119174,
        "recall": 0.161133,
        "f1": 0.12944,
        "accuracy": 0.161133,
        "main_score": 0.12944,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.142591,
        "recall": 0.19043,
        "f1": 0.154897,
        "accuracy": 0.19043,
        "main_score": 0.154897,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.10719,
        "recall": 0.145508,
        "f1": 0.115761,
        "accuracy": 0.145508,
        "main_score": 0.115761,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.032677,
        "recall": 0.066406,
        "f1": 0.039004,
        "accuracy": 0.066406,
        "main_score": 0.039004,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.049917,
        "recall": 0.073242,
        "f1": 0.054416,
        "accuracy": 0.073242,
        "main_score": 0.054416,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.083787,
        "recall": 0.120117,
        "f1": 0.092554,
        "accuracy": 0.120117,
        "main_score": 0.092554,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.054717,
        "recall": 0.091797,
        "f1": 0.063427,
        "accuracy": 0.091797,
        "main_score": 0.063427,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.036889,
        "recall": 0.067383,
        "f1": 0.043756,
        "accuracy": 0.067383,
        "main_score": 0.043756,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.047354,
        "recall": 0.082031,
        "f1": 0.054394,
        "accuracy": 0.082031,
        "main_score": 0.054394,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.023461,
        "recall": 0.046875,
        "f1": 0.027034,
        "accuracy": 0.046875,
        "main_score": 0.027034,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.053174,
        "recall": 0.076172,
        "f1": 0.058097,
        "accuracy": 0.076172,
        "main_score": 0.058097,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.05429,
        "recall": 0.084961,
        "f1": 0.061047,
        "accuracy": 0.084961,
        "main_score": 0.061047,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.299529,
        "recall": 0.327148,
        "f1": 0.306881,
        "accuracy": 0.327148,
        "main_score": 0.306881,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.277556,
        "recall": 0.303711,
        "f1": 0.283992,
        "accuracy": 0.303711,
        "main_score": 0.283992,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.09122,
        "recall": 0.119141,
        "f1": 0.097597,
        "accuracy": 0.119141,
        "main_score": 0.097597,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.302129,
        "recall": 0.332031,
        "f1": 0.310148,
        "accuracy": 0.332031,
        "main_score": 0.310148,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.083907,
        "recall": 0.143555,
        "f1": 0.09708,
        "accuracy": 0.143555,
        "main_score": 0.09708,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.293072,
        "recall": 0.322266,
        "f1": 0.301043,
        "accuracy": 0.322266,
        "main_score": 0.301043,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.075708,
        "recall": 0.107422,
        "f1": 0.083496,
        "accuracy": 0.107422,
        "main_score": 0.083496,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.261333,
        "recall": 0.282227,
        "f1": 0.266697,
        "accuracy": 0.282227,
        "main_score": 0.266697,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.045003,
        "recall": 0.079102,
        "f1": 0.052727,
        "accuracy": 0.079102,
        "main_score": 0.052727,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.063828,
        "recall": 0.09375,
        "f1": 0.070594,
        "accuracy": 0.09375,
        "main_score": 0.070594,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.055354,
        "recall": 0.086914,
        "f1": 0.061948,
        "accuracy": 0.086914,
        "main_score": 0.061948,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.050428,
        "recall": 0.081055,
        "f1": 0.057596,
        "accuracy": 0.081055,
        "main_score": 0.057596,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.047379,
        "recall": 0.071289,
        "f1": 0.052754,
        "accuracy": 0.071289,
        "main_score": 0.052754,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.263012,
        "recall": 0.286133,
        "f1": 0.269132,
        "accuracy": 0.286133,
        "main_score": 0.269132,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.030851,
        "recall": 0.055664,
        "f1": 0.035825,
        "accuracy": 0.055664,
        "main_score": 0.035825,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.026583,
        "recall": 0.048828,
        "f1": 0.031491,
        "accuracy": 0.048828,
        "main_score": 0.031491,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.26562,
        "recall": 0.290039,
        "f1": 0.271564,
        "accuracy": 0.290039,
        "main_score": 0.271564,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.303205,
        "recall": 0.333984,
        "f1": 0.310922,
        "accuracy": 0.333984,
        "main_score": 0.310922,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.287466,
        "recall": 0.318359,
        "f1": 0.295743,
        "accuracy": 0.318359,
        "main_score": 0.295743,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.264765,
        "recall": 0.28418,
        "f1": 0.269534,
        "accuracy": 0.28418,
        "main_score": 0.269534,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.11455,
        "recall": 0.15625,
        "f1": 0.124782,
        "accuracy": 0.15625,
        "main_score": 0.124782,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.101997,
        "recall": 0.149414,
        "f1": 0.113259,
        "accuracy": 0.149414,
        "main_score": 0.113259,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.051801,
        "recall": 0.102539,
        "f1": 0.062569,
        "accuracy": 0.102539,
        "main_score": 0.062569,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.041708,
        "recall": 0.086914,
        "f1": 0.050257,
        "accuracy": 0.086914,
        "main_score": 0.050257,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000593,
        "recall": 0.003906,
        "f1": 0.00085,
        "accuracy": 0.003906,
        "main_score": 0.00085,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.070854,
        "recall": 0.131836,
        "f1": 0.084699,
        "accuracy": 0.131836,
        "main_score": 0.084699,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.108239,
        "recall": 0.165039,
        "f1": 0.121861,
        "accuracy": 0.165039,
        "main_score": 0.121861,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.050097,
        "recall": 0.091797,
        "f1": 0.059122,
        "accuracy": 0.091797,
        "main_score": 0.059122,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.143532,
        "recall": 0.191406,
        "f1": 0.156017,
        "accuracy": 0.191406,
        "main_score": 0.156017,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.014278,
        "recall": 0.033203,
        "f1": 0.017223,
        "accuracy": 0.033203,
        "main_score": 0.017223,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.100831,
        "recall": 0.143555,
        "f1": 0.111387,
        "accuracy": 0.143555,
        "main_score": 0.111387,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.036445,
        "recall": 0.077148,
        "f1": 0.045098,
        "accuracy": 0.077148,
        "main_score": 0.045098,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.092943,
        "recall": 0.134766,
        "f1": 0.102603,
        "accuracy": 0.134766,
        "main_score": 0.102603,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.091715,
        "recall": 0.148438,
        "f1": 0.104806,
        "accuracy": 0.148438,
        "main_score": 0.104806,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.109533,
        "recall": 0.15332,
        "f1": 0.119748,
        "accuracy": 0.15332,
        "main_score": 0.119748,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.024343,
        "recall": 0.063477,
        "f1": 0.030084,
        "accuracy": 0.063477,
        "main_score": 0.030084,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.06896,
        "recall": 0.094727,
        "f1": 0.074346,
        "accuracy": 0.094727,
        "main_score": 0.074346,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.071856,
        "recall": 0.119141,
        "f1": 0.082729,
        "accuracy": 0.119141,
        "main_score": 0.082729,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.041293,
        "recall": 0.079102,
        "f1": 0.049395,
        "accuracy": 0.079102,
        "main_score": 0.049395,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.046176,
        "recall": 0.083984,
        "f1": 0.054478,
        "accuracy": 0.083984,
        "main_score": 0.054478,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.062156,
        "recall": 0.106445,
        "f1": 0.072752,
        "accuracy": 0.106445,
        "main_score": 0.072752,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.013926,
        "recall": 0.037109,
        "f1": 0.017032,
        "accuracy": 0.037109,
        "main_score": 0.017032,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.131367,
        "recall": 0.177734,
        "f1": 0.143142,
        "accuracy": 0.177734,
        "main_score": 0.143142,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.120419,
        "recall": 0.166992,
        "f1": 0.132802,
        "accuracy": 0.166992,
        "main_score": 0.132802,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.0609,
        "recall": 0.106445,
        "f1": 0.071116,
        "accuracy": 0.106445,
        "main_score": 0.071116,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.043316,
        "recall": 0.078125,
        "f1": 0.051328,
        "accuracy": 0.078125,
        "main_score": 0.051328,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001691,
        "recall": 0.004883,
        "f1": 0.002072,
        "accuracy": 0.004883,
        "main_score": 0.002072,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.061603,
        "recall": 0.105469,
        "f1": 0.071826,
        "accuracy": 0.105469,
        "main_score": 0.071826,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.095074,
        "recall": 0.144531,
        "f1": 0.106556,
        "accuracy": 0.144531,
        "main_score": 0.106556,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.053916,
        "recall": 0.102539,
        "f1": 0.066005,
        "accuracy": 0.102539,
        "main_score": 0.066005,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.099145,
        "recall": 0.147461,
        "f1": 0.110447,
        "accuracy": 0.147461,
        "main_score": 0.110447,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.015426,
        "recall": 0.035156,
        "f1": 0.019123,
        "accuracy": 0.035156,
        "main_score": 0.019123,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.1161,
        "recall": 0.15625,
        "f1": 0.126892,
        "accuracy": 0.15625,
        "main_score": 0.126892,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.032807,
        "recall": 0.063477,
        "f1": 0.039319,
        "accuracy": 0.063477,
        "main_score": 0.039319,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.099799,
        "recall": 0.140625,
        "f1": 0.110493,
        "accuracy": 0.140625,
        "main_score": 0.110493,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.126199,
        "recall": 0.174805,
        "f1": 0.139071,
        "accuracy": 0.174805,
        "main_score": 0.139071,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.090227,
        "recall": 0.129883,
        "f1": 0.099616,
        "accuracy": 0.129883,
        "main_score": 0.099616,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.022961,
        "recall": 0.058594,
        "f1": 0.029522,
        "accuracy": 0.058594,
        "main_score": 0.029522,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.056534,
        "recall": 0.087891,
        "f1": 0.063469,
        "accuracy": 0.087891,
        "main_score": 0.063469,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.073554,
        "recall": 0.112305,
        "f1": 0.08357,
        "accuracy": 0.112305,
        "main_score": 0.08357,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.04953,
        "recall": 0.09082,
        "f1": 0.05942,
        "accuracy": 0.09082,
        "main_score": 0.05942,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.039984,
        "recall": 0.072266,
        "f1": 0.047064,
        "accuracy": 0.072266,
        "main_score": 0.047064,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.052136,
        "recall": 0.092773,
        "f1": 0.061617,
        "accuracy": 0.092773,
        "main_score": 0.061617,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.013028,
        "recall": 0.035156,
        "f1": 0.016015,
        "accuracy": 0.035156,
        "main_score": 0.016015,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.125197,
        "recall": 0.173828,
        "f1": 0.137601,
        "accuracy": 0.173828,
        "main_score": 0.137601,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.131349,
        "recall": 0.173828,
        "f1": 0.142629,
        "accuracy": 0.173828,
        "main_score": 0.142629,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.055581,
        "recall": 0.103516,
        "f1": 0.066492,
        "accuracy": 0.103516,
        "main_score": 0.066492,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.048654,
        "recall": 0.088867,
        "f1": 0.056931,
        "accuracy": 0.088867,
        "main_score": 0.056931,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001728,
        "recall": 0.005859,
        "f1": 0.002145,
        "accuracy": 0.005859,
        "main_score": 0.002145,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.054546,
        "recall": 0.098633,
        "f1": 0.064392,
        "accuracy": 0.098633,
        "main_score": 0.064392,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.097065,
        "recall": 0.137695,
        "f1": 0.10656,
        "accuracy": 0.137695,
        "main_score": 0.10656,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.052935,
        "recall": 0.088867,
        "f1": 0.061312,
        "accuracy": 0.088867,
        "main_score": 0.061312,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.11324,
        "recall": 0.157227,
        "f1": 0.12358,
        "accuracy": 0.157227,
        "main_score": 0.12358,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.017261,
        "recall": 0.039062,
        "f1": 0.020751,
        "accuracy": 0.039062,
        "main_score": 0.020751,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.138023,
        "recall": 0.186523,
        "f1": 0.150098,
        "accuracy": 0.186523,
        "main_score": 0.150098,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.034172,
        "recall": 0.060547,
        "f1": 0.039499,
        "accuracy": 0.060547,
        "main_score": 0.039499,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.108478,
        "recall": 0.138672,
        "f1": 0.115676,
        "accuracy": 0.138672,
        "main_score": 0.115676,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.137084,
        "recall": 0.175781,
        "f1": 0.147363,
        "accuracy": 0.175781,
        "main_score": 0.147363,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.108656,
        "recall": 0.150391,
        "f1": 0.118721,
        "accuracy": 0.150391,
        "main_score": 0.118721,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.02526,
        "recall": 0.056641,
        "f1": 0.030873,
        "accuracy": 0.056641,
        "main_score": 0.030873,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.063375,
        "recall": 0.095703,
        "f1": 0.070703,
        "accuracy": 0.095703,
        "main_score": 0.070703,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.075353,
        "recall": 0.115234,
        "f1": 0.086037,
        "accuracy": 0.115234,
        "main_score": 0.086037,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.041638,
        "recall": 0.070312,
        "f1": 0.047545,
        "accuracy": 0.070312,
        "main_score": 0.047545,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.060262,
        "recall": 0.095703,
        "f1": 0.067984,
        "accuracy": 0.095703,
        "main_score": 0.067984,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.064059,
        "recall": 0.102539,
        "f1": 0.072806,
        "accuracy": 0.102539,
        "main_score": 0.072806,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.01761,
        "recall": 0.038086,
        "f1": 0.020633,
        "accuracy": 0.038086,
        "main_score": 0.020633,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.126585,
        "recall": 0.176758,
        "f1": 0.138619,
        "accuracy": 0.176758,
        "main_score": 0.138619,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.10133,
        "recall": 0.149414,
        "f1": 0.113743,
        "accuracy": 0.149414,
        "main_score": 0.113743,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.074166,
        "recall": 0.126953,
        "f1": 0.085696,
        "accuracy": 0.126953,
        "main_score": 0.085696,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.049794,
        "recall": 0.098633,
        "f1": 0.060116,
        "accuracy": 0.098633,
        "main_score": 0.060116,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002022,
        "recall": 0.004883,
        "f1": 0.002086,
        "accuracy": 0.004883,
        "main_score": 0.002086,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.060716,
        "recall": 0.115234,
        "f1": 0.072363,
        "accuracy": 0.115234,
        "main_score": 0.072363,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.093079,
        "recall": 0.15332,
        "f1": 0.107177,
        "accuracy": 0.15332,
        "main_score": 0.107177,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.07472,
        "recall": 0.130859,
        "f1": 0.087809,
        "accuracy": 0.130859,
        "main_score": 0.087809,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.125943,
        "recall": 0.172852,
        "f1": 0.137505,
        "accuracy": 0.172852,
        "main_score": 0.137505,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.013282,
        "recall": 0.03418,
        "f1": 0.016395,
        "accuracy": 0.03418,
        "main_score": 0.016395,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.115281,
        "recall": 0.169922,
        "f1": 0.128488,
        "accuracy": 0.169922,
        "main_score": 0.128488,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.026583,
        "recall": 0.061523,
        "f1": 0.033498,
        "accuracy": 0.061523,
        "main_score": 0.033498,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.11466,
        "recall": 0.162109,
        "f1": 0.126211,
        "accuracy": 0.162109,
        "main_score": 0.126211,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.096093,
        "recall": 0.136719,
        "f1": 0.105748,
        "accuracy": 0.136719,
        "main_score": 0.105748,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.105664,
        "recall": 0.15625,
        "f1": 0.117872,
        "accuracy": 0.15625,
        "main_score": 0.117872,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.028338,
        "recall": 0.073242,
        "f1": 0.036037,
        "accuracy": 0.073242,
        "main_score": 0.036037,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.062332,
        "recall": 0.094727,
        "f1": 0.069595,
        "accuracy": 0.094727,
        "main_score": 0.069595,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.070053,
        "recall": 0.121094,
        "f1": 0.082015,
        "accuracy": 0.121094,
        "main_score": 0.082015,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.069646,
        "recall": 0.125,
        "f1": 0.082034,
        "accuracy": 0.125,
        "main_score": 0.082034,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.036793,
        "recall": 0.079102,
        "f1": 0.045335,
        "accuracy": 0.079102,
        "main_score": 0.045335,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.056303,
        "recall": 0.097656,
        "f1": 0.064917,
        "accuracy": 0.097656,
        "main_score": 0.064917,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.012625,
        "recall": 0.042969,
        "f1": 0.016252,
        "accuracy": 0.042969,
        "main_score": 0.016252,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.082538,
        "recall": 0.118164,
        "f1": 0.091946,
        "accuracy": 0.118164,
        "main_score": 0.091946,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.063999,
        "recall": 0.09375,
        "f1": 0.071755,
        "accuracy": 0.09375,
        "main_score": 0.071755,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.333057,
        "recall": 0.366211,
        "f1": 0.342612,
        "accuracy": 0.366211,
        "main_score": 0.342612,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.353372,
        "recall": 0.391602,
        "f1": 0.363033,
        "accuracy": 0.391602,
        "main_score": 0.363033,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.109638,
        "recall": 0.134766,
        "f1": 0.115157,
        "accuracy": 0.134766,
        "main_score": 0.115157,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.322802,
        "recall": 0.355469,
        "f1": 0.331638,
        "accuracy": 0.355469,
        "main_score": 0.331638,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.115999,
        "recall": 0.176758,
        "f1": 0.129692,
        "accuracy": 0.176758,
        "main_score": 0.129692,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.357054,
        "recall": 0.394531,
        "f1": 0.367082,
        "accuracy": 0.394531,
        "main_score": 0.367082,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.052647,
        "recall": 0.086914,
        "f1": 0.060217,
        "accuracy": 0.086914,
        "main_score": 0.060217,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.273355,
        "recall": 0.302734,
        "f1": 0.281143,
        "accuracy": 0.302734,
        "main_score": 0.281143,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.086046,
        "recall": 0.130859,
        "f1": 0.096827,
        "accuracy": 0.130859,
        "main_score": 0.096827,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.271468,
        "recall": 0.298828,
        "f1": 0.278725,
        "accuracy": 0.298828,
        "main_score": 0.278725,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.071684,
        "recall": 0.102539,
        "f1": 0.079039,
        "accuracy": 0.102539,
        "main_score": 0.079039,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.063832,
        "recall": 0.09082,
        "f1": 0.069779,
        "accuracy": 0.09082,
        "main_score": 0.069779,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.064303,
        "recall": 0.097656,
        "f1": 0.072561,
        "accuracy": 0.097656,
        "main_score": 0.072561,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.086639,
        "recall": 0.120117,
        "f1": 0.094857,
        "accuracy": 0.120117,
        "main_score": 0.094857,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.028151,
        "recall": 0.052734,
        "f1": 0.032989,
        "accuracy": 0.052734,
        "main_score": 0.032989,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.061873,
        "recall": 0.095703,
        "f1": 0.070037,
        "accuracy": 0.095703,
        "main_score": 0.070037,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.343676,
        "recall": 0.381836,
        "f1": 0.353566,
        "accuracy": 0.381836,
        "main_score": 0.353566,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.302585,
        "recall": 0.330078,
        "f1": 0.30912,
        "accuracy": 0.330078,
        "main_score": 0.30912,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.304556,
        "recall": 0.333008,
        "f1": 0.312411,
        "accuracy": 0.333008,
        "main_score": 0.312411,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.288589,
        "recall": 0.311523,
        "f1": 0.294165,
        "accuracy": 0.311523,
        "main_score": 0.294165,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.073337,
        "recall": 0.108398,
        "f1": 0.081987,
        "accuracy": 0.108398,
        "main_score": 0.081987,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.067489,
        "recall": 0.102539,
        "f1": 0.075187,
        "accuracy": 0.102539,
        "main_score": 0.075187,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.034726,
        "recall": 0.074219,
        "f1": 0.042779,
        "accuracy": 0.074219,
        "main_score": 0.042779,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.016161,
        "recall": 0.035156,
        "f1": 0.019454,
        "accuracy": 0.035156,
        "main_score": 0.019454,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00141,
        "recall": 0.004883,
        "f1": 0.00167,
        "accuracy": 0.004883,
        "main_score": 0.00167,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.039851,
        "recall": 0.080078,
        "f1": 0.047543,
        "accuracy": 0.080078,
        "main_score": 0.047543,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.056049,
        "recall": 0.095703,
        "f1": 0.064656,
        "accuracy": 0.095703,
        "main_score": 0.064656,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.0278,
        "recall": 0.0625,
        "f1": 0.034704,
        "accuracy": 0.0625,
        "main_score": 0.034704,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.084538,
        "recall": 0.12207,
        "f1": 0.092716,
        "accuracy": 0.12207,
        "main_score": 0.092716,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.007351,
        "recall": 0.019531,
        "f1": 0.009085,
        "accuracy": 0.019531,
        "main_score": 0.009085,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.042441,
        "recall": 0.074219,
        "f1": 0.048474,
        "accuracy": 0.074219,
        "main_score": 0.048474,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.023915,
        "recall": 0.049805,
        "f1": 0.028508,
        "accuracy": 0.049805,
        "main_score": 0.028508,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.065376,
        "recall": 0.097656,
        "f1": 0.072231,
        "accuracy": 0.097656,
        "main_score": 0.072231,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.051853,
        "recall": 0.086914,
        "f1": 0.059628,
        "accuracy": 0.086914,
        "main_score": 0.059628,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.067344,
        "recall": 0.107422,
        "f1": 0.076399,
        "accuracy": 0.107422,
        "main_score": 0.076399,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.056495,
        "recall": 0.088867,
        "f1": 0.063349,
        "accuracy": 0.088867,
        "main_score": 0.063349,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.017242,
        "recall": 0.032227,
        "f1": 0.019283,
        "accuracy": 0.032227,
        "main_score": 0.019283,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.037666,
        "recall": 0.066406,
        "f1": 0.043376,
        "accuracy": 0.066406,
        "main_score": 0.043376,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.029181,
        "recall": 0.053711,
        "f1": 0.034369,
        "accuracy": 0.053711,
        "main_score": 0.034369,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.028533,
        "recall": 0.054688,
        "f1": 0.033084,
        "accuracy": 0.054688,
        "main_score": 0.033084,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.036025,
        "recall": 0.070312,
        "f1": 0.042372,
        "accuracy": 0.070312,
        "main_score": 0.042372,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.008625,
        "recall": 0.019531,
        "f1": 0.010386,
        "accuracy": 0.019531,
        "main_score": 0.010386,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.082008,
        "recall": 0.12793,
        "f1": 0.092605,
        "accuracy": 0.12793,
        "main_score": 0.092605,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.134456,
        "recall": 0.183594,
        "f1": 0.146763,
        "accuracy": 0.183594,
        "main_score": 0.146763,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.032993,
        "recall": 0.069336,
        "f1": 0.039529,
        "accuracy": 0.069336,
        "main_score": 0.039529,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.053539,
        "recall": 0.098633,
        "f1": 0.062832,
        "accuracy": 0.098633,
        "main_score": 0.062832,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003477,
        "recall": 0.005859,
        "f1": 0.003693,
        "accuracy": 0.005859,
        "main_score": 0.003693,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.047395,
        "recall": 0.081055,
        "f1": 0.054719,
        "accuracy": 0.081055,
        "main_score": 0.054719,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.072337,
        "recall": 0.117188,
        "f1": 0.082115,
        "accuracy": 0.117188,
        "main_score": 0.082115,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.047312,
        "recall": 0.091797,
        "f1": 0.057324,
        "accuracy": 0.091797,
        "main_score": 0.057324,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.063328,
        "recall": 0.097656,
        "f1": 0.071052,
        "accuracy": 0.097656,
        "main_score": 0.071052,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.014549,
        "recall": 0.035156,
        "f1": 0.017747,
        "accuracy": 0.035156,
        "main_score": 0.017747,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.083546,
        "recall": 0.120117,
        "f1": 0.092993,
        "accuracy": 0.120117,
        "main_score": 0.092993,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.015901,
        "recall": 0.035156,
        "f1": 0.019494,
        "accuracy": 0.035156,
        "main_score": 0.019494,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.070307,
        "recall": 0.102539,
        "f1": 0.077483,
        "accuracy": 0.102539,
        "main_score": 0.077483,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.071108,
        "recall": 0.110352,
        "f1": 0.080877,
        "accuracy": 0.110352,
        "main_score": 0.080877,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.085371,
        "recall": 0.120117,
        "f1": 0.094449,
        "accuracy": 0.120117,
        "main_score": 0.094449,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.063112,
        "recall": 0.097656,
        "f1": 0.07111,
        "accuracy": 0.097656,
        "main_score": 0.07111,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.020282,
        "recall": 0.055664,
        "f1": 0.025659,
        "accuracy": 0.055664,
        "main_score": 0.025659,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.03462,
        "recall": 0.055664,
        "f1": 0.038715,
        "accuracy": 0.055664,
        "main_score": 0.038715,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.040716,
        "recall": 0.076172,
        "f1": 0.048423,
        "accuracy": 0.076172,
        "main_score": 0.048423,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.042041,
        "recall": 0.072266,
        "f1": 0.048234,
        "accuracy": 0.072266,
        "main_score": 0.048234,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.0386,
        "recall": 0.069336,
        "f1": 0.045261,
        "accuracy": 0.069336,
        "main_score": 0.045261,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.010647,
        "recall": 0.02832,
        "f1": 0.013524,
        "accuracy": 0.02832,
        "main_score": 0.013524,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.100803,
        "recall": 0.140625,
        "f1": 0.110648,
        "accuracy": 0.140625,
        "main_score": 0.110648,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.070857,
        "recall": 0.103516,
        "f1": 0.078568,
        "accuracy": 0.103516,
        "main_score": 0.078568,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.350366,
        "recall": 0.384766,
        "f1": 0.359825,
        "accuracy": 0.384766,
        "main_score": 0.359825,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.359588,
        "recall": 0.407227,
        "f1": 0.371472,
        "accuracy": 0.407227,
        "main_score": 0.371472,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.102525,
        "recall": 0.129883,
        "f1": 0.108591,
        "accuracy": 0.129883,
        "main_score": 0.108591,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.342342,
        "recall": 0.374023,
        "f1": 0.350984,
        "accuracy": 0.374023,
        "main_score": 0.350984,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.143697,
        "recall": 0.207031,
        "f1": 0.158757,
        "accuracy": 0.207031,
        "main_score": 0.158757,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.421484,
        "recall": 0.46875,
        "f1": 0.434199,
        "accuracy": 0.46875,
        "main_score": 0.434199,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.087374,
        "recall": 0.128906,
        "f1": 0.097493,
        "accuracy": 0.128906,
        "main_score": 0.097493,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.287816,
        "recall": 0.3125,
        "f1": 0.2943,
        "accuracy": 0.3125,
        "main_score": 0.2943,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.092074,
        "recall": 0.136719,
        "f1": 0.102533,
        "accuracy": 0.136719,
        "main_score": 0.102533,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.273489,
        "recall": 0.296875,
        "f1": 0.280136,
        "accuracy": 0.296875,
        "main_score": 0.280136,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.078599,
        "recall": 0.116211,
        "f1": 0.087604,
        "accuracy": 0.116211,
        "main_score": 0.087604,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.078078,
        "recall": 0.115234,
        "f1": 0.08699,
        "accuracy": 0.115234,
        "main_score": 0.08699,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.062862,
        "recall": 0.095703,
        "f1": 0.070685,
        "accuracy": 0.095703,
        "main_score": 0.070685,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.089907,
        "recall": 0.137695,
        "f1": 0.102426,
        "accuracy": 0.137695,
        "main_score": 0.102426,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.30938,
        "recall": 0.360352,
        "f1": 0.321204,
        "accuracy": 0.360352,
        "main_score": 0.321204,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.042043,
        "recall": 0.066406,
        "f1": 0.047233,
        "accuracy": 0.066406,
        "main_score": 0.047233,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.064725,
        "recall": 0.099609,
        "f1": 0.072833,
        "accuracy": 0.099609,
        "main_score": 0.072833,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.309959,
        "recall": 0.336914,
        "f1": 0.317371,
        "accuracy": 0.336914,
        "main_score": 0.317371,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.317876,
        "recall": 0.347656,
        "f1": 0.325034,
        "accuracy": 0.347656,
        "main_score": 0.325034,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.299874,
        "recall": 0.328125,
        "f1": 0.305678,
        "accuracy": 0.328125,
        "main_score": 0.305678,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.058715,
        "recall": 0.097656,
        "f1": 0.067979,
        "accuracy": 0.097656,
        "main_score": 0.067979,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.066222,
        "recall": 0.103516,
        "f1": 0.075202,
        "accuracy": 0.103516,
        "main_score": 0.075202,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.326491,
        "recall": 0.356445,
        "f1": 0.334101,
        "accuracy": 0.356445,
        "main_score": 0.334101,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.308409,
        "recall": 0.334961,
        "f1": 0.314663,
        "accuracy": 0.334961,
        "main_score": 0.314663,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.093729,
        "recall": 0.124023,
        "f1": 0.100802,
        "accuracy": 0.124023,
        "main_score": 0.100802,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.336547,
        "recall": 0.371094,
        "f1": 0.345374,
        "accuracy": 0.371094,
        "main_score": 0.345374,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.098846,
        "recall": 0.164062,
        "f1": 0.113585,
        "accuracy": 0.164062,
        "main_score": 0.113585,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.313996,
        "recall": 0.34082,
        "f1": 0.320818,
        "accuracy": 0.34082,
        "main_score": 0.320818,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.095375,
        "recall": 0.142578,
        "f1": 0.107157,
        "accuracy": 0.142578,
        "main_score": 0.107157,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.271679,
        "recall": 0.297852,
        "f1": 0.278071,
        "accuracy": 0.297852,
        "main_score": 0.278071,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.052923,
        "recall": 0.084961,
        "f1": 0.060153,
        "accuracy": 0.084961,
        "main_score": 0.060153,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.308816,
        "recall": 0.337891,
        "f1": 0.31653,
        "accuracy": 0.337891,
        "main_score": 0.31653,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.073208,
        "recall": 0.103516,
        "f1": 0.080591,
        "accuracy": 0.103516,
        "main_score": 0.080591,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.058785,
        "recall": 0.091797,
        "f1": 0.067239,
        "accuracy": 0.091797,
        "main_score": 0.067239,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.075836,
        "recall": 0.111328,
        "f1": 0.084214,
        "accuracy": 0.111328,
        "main_score": 0.084214,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.054655,
        "recall": 0.091797,
        "f1": 0.063094,
        "accuracy": 0.091797,
        "main_score": 0.063094,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.285241,
        "recall": 0.313477,
        "f1": 0.291694,
        "accuracy": 0.313477,
        "main_score": 0.291694,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.032612,
        "recall": 0.06543,
        "f1": 0.039128,
        "accuracy": 0.06543,
        "main_score": 0.039128,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.052481,
        "recall": 0.085938,
        "f1": 0.059825,
        "accuracy": 0.085938,
        "main_score": 0.059825,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.300014,
        "recall": 0.324219,
        "f1": 0.306286,
        "accuracy": 0.324219,
        "main_score": 0.306286,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.350567,
        "recall": 0.385742,
        "f1": 0.359968,
        "accuracy": 0.385742,
        "main_score": 0.359968,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.282117,
        "recall": 0.301758,
        "f1": 0.286868,
        "accuracy": 0.301758,
        "main_score": 0.286868,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.066769,
        "recall": 0.101562,
        "f1": 0.074923,
        "accuracy": 0.101562,
        "main_score": 0.074923,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.07161,
        "recall": 0.113281,
        "f1": 0.082145,
        "accuracy": 0.113281,
        "main_score": 0.082145,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.329446,
        "recall": 0.365234,
        "f1": 0.338804,
        "accuracy": 0.365234,
        "main_score": 0.338804,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.310515,
        "recall": 0.344727,
        "f1": 0.319132,
        "accuracy": 0.344727,
        "main_score": 0.319132,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.093161,
        "recall": 0.121094,
        "f1": 0.099313,
        "accuracy": 0.121094,
        "main_score": 0.099313,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.343956,
        "recall": 0.379883,
        "f1": 0.353892,
        "accuracy": 0.379883,
        "main_score": 0.353892,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.117449,
        "recall": 0.185547,
        "f1": 0.13278,
        "accuracy": 0.185547,
        "main_score": 0.13278,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.32149,
        "recall": 0.354492,
        "f1": 0.330098,
        "accuracy": 0.354492,
        "main_score": 0.330098,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.113949,
        "recall": 0.160156,
        "f1": 0.125819,
        "accuracy": 0.160156,
        "main_score": 0.125819,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.269747,
        "recall": 0.294922,
        "f1": 0.275919,
        "accuracy": 0.294922,
        "main_score": 0.275919,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.075963,
        "recall": 0.118164,
        "f1": 0.084858,
        "accuracy": 0.118164,
        "main_score": 0.084858,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.296147,
        "recall": 0.325195,
        "f1": 0.304283,
        "accuracy": 0.325195,
        "main_score": 0.304283,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.097446,
        "recall": 0.128906,
        "f1": 0.105979,
        "accuracy": 0.128906,
        "main_score": 0.105979,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.071788,
        "recall": 0.111328,
        "f1": 0.081319,
        "accuracy": 0.111328,
        "main_score": 0.081319,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.096002,
        "recall": 0.136719,
        "f1": 0.105416,
        "accuracy": 0.136719,
        "main_score": 0.105416,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.068792,
        "recall": 0.111328,
        "f1": 0.079072,
        "accuracy": 0.111328,
        "main_score": 0.079072,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.279921,
        "recall": 0.314453,
        "f1": 0.287978,
        "accuracy": 0.314453,
        "main_score": 0.287978,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.04645,
        "recall": 0.081055,
        "f1": 0.053241,
        "accuracy": 0.081055,
        "main_score": 0.053241,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.04797,
        "recall": 0.083984,
        "f1": 0.056282,
        "accuracy": 0.083984,
        "main_score": 0.056282,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.30916,
        "recall": 0.337891,
        "f1": 0.315954,
        "accuracy": 0.337891,
        "main_score": 0.315954,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.35373,
        "recall": 0.392578,
        "f1": 0.364434,
        "accuracy": 0.392578,
        "main_score": 0.364434,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.282466,
        "recall": 0.302734,
        "f1": 0.286423,
        "accuracy": 0.302734,
        "main_score": 0.286423,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.026311,
        "recall": 0.044922,
        "f1": 0.030284,
        "accuracy": 0.044922,
        "main_score": 0.030284,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.022908,
        "recall": 0.041016,
        "f1": 0.026019,
        "accuracy": 0.041016,
        "main_score": 0.026019,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.280679,
        "recall": 0.304688,
        "f1": 0.286249,
        "accuracy": 0.304688,
        "main_score": 0.286249,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.274411,
        "recall": 0.302734,
        "f1": 0.280242,
        "accuracy": 0.302734,
        "main_score": 0.280242,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.096935,
        "recall": 0.125,
        "f1": 0.103282,
        "accuracy": 0.125,
        "main_score": 0.103282,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.269685,
        "recall": 0.291016,
        "f1": 0.27454,
        "accuracy": 0.291016,
        "main_score": 0.27454,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.060272,
        "recall": 0.114258,
        "f1": 0.071401,
        "accuracy": 0.114258,
        "main_score": 0.071401,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.292381,
        "recall": 0.318359,
        "f1": 0.298043,
        "accuracy": 0.318359,
        "main_score": 0.298043,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.022845,
        "recall": 0.038086,
        "f1": 0.025831,
        "accuracy": 0.038086,
        "main_score": 0.025831,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.325256,
        "recall": 0.37207,
        "f1": 0.337933,
        "accuracy": 0.37207,
        "main_score": 0.337933,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.029904,
        "recall": 0.048828,
        "f1": 0.033379,
        "accuracy": 0.048828,
        "main_score": 0.033379,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.258887,
        "recall": 0.280273,
        "f1": 0.264363,
        "accuracy": 0.280273,
        "main_score": 0.264363,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.023953,
        "recall": 0.043945,
        "f1": 0.027308,
        "accuracy": 0.043945,
        "main_score": 0.027308,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.027453,
        "recall": 0.045898,
        "f1": 0.030534,
        "accuracy": 0.045898,
        "main_score": 0.030534,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.025647,
        "recall": 0.043945,
        "f1": 0.029117,
        "accuracy": 0.043945,
        "main_score": 0.029117,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.025838,
        "recall": 0.042969,
        "f1": 0.029604,
        "accuracy": 0.042969,
        "main_score": 0.029604,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.267489,
        "recall": 0.291016,
        "f1": 0.272529,
        "accuracy": 0.291016,
        "main_score": 0.272529,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.011849,
        "recall": 0.026367,
        "f1": 0.014627,
        "accuracy": 0.026367,
        "main_score": 0.014627,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.020884,
        "recall": 0.037109,
        "f1": 0.023715,
        "accuracy": 0.037109,
        "main_score": 0.023715,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.273947,
        "recall": 0.301758,
        "f1": 0.279322,
        "accuracy": 0.301758,
        "main_score": 0.279322,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.265921,
        "recall": 0.291016,
        "f1": 0.271578,
        "accuracy": 0.291016,
        "main_score": 0.271578,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.272456,
        "recall": 0.291992,
        "f1": 0.277401,
        "accuracy": 0.291992,
        "main_score": 0.277401,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 46.79803681373596,
  "kg_co2_emissions": 0.002907260252108968
}