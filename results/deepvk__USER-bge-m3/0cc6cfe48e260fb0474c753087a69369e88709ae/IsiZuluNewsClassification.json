{
  "dataset_revision": "55caf0e52693a1ea63b15a4980a73fc137fb862b",
  "task_name": "IsiZuluNewsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.296676,
        "f1": 0.289196,
        "f1_weighted": 0.304742,
        "scores_per_experiment": [
          {
            "accuracy": 0.277926,
            "f1": 0.277655,
            "f1_weighted": 0.292005
          },
          {
            "accuracy": 0.3125,
            "f1": 0.29105,
            "f1_weighted": 0.327098
          },
          {
            "accuracy": 0.292553,
            "f1": 0.299774,
            "f1_weighted": 0.288798
          },
          {
            "accuracy": 0.292553,
            "f1": 0.274429,
            "f1_weighted": 0.290856
          },
          {
            "accuracy": 0.327128,
            "f1": 0.3023,
            "f1_weighted": 0.345841
          },
          {
            "accuracy": 0.267287,
            "f1": 0.262106,
            "f1_weighted": 0.261434
          },
          {
            "accuracy": 0.281915,
            "f1": 0.284238,
            "f1_weighted": 0.291353
          },
          {
            "accuracy": 0.319149,
            "f1": 0.303246,
            "f1_weighted": 0.325026
          },
          {
            "accuracy": 0.31516,
            "f1": 0.292046,
            "f1_weighted": 0.329138
          },
          {
            "accuracy": 0.280585,
            "f1": 0.305111,
            "f1_weighted": 0.295872
          }
        ],
        "main_score": 0.296676,
        "hf_subset": "default",
        "languages": [
          "zul-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 8.295022010803223,
  "kg_co2_emissions": 0.00028384716404437346
}