{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "task_name": "IN22ConvBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.049448,
        "recall": 0.077179,
        "f1": 0.055226,
        "accuracy": 0.077179,
        "main_score": 0.055226,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.038083,
        "recall": 0.063207,
        "f1": 0.042747,
        "accuracy": 0.063207,
        "main_score": 0.042747,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.029402,
        "recall": 0.045243,
        "f1": 0.033002,
        "accuracy": 0.045243,
        "main_score": 0.033002,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000948,
        "recall": 0.004657,
        "f1": 0.001145,
        "accuracy": 0.004657,
        "main_score": 0.001145,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.037726,
        "recall": 0.063872,
        "f1": 0.042613,
        "accuracy": 0.063872,
        "main_score": 0.042613,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.034026,
        "recall": 0.05988,
        "f1": 0.039428,
        "accuracy": 0.05988,
        "main_score": 0.039428,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.042903,
        "recall": 0.063872,
        "f1": 0.047561,
        "accuracy": 0.063872,
        "main_score": 0.047561,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.026132,
        "recall": 0.039255,
        "f1": 0.028465,
        "accuracy": 0.039255,
        "main_score": 0.028465,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.005408,
        "recall": 0.015303,
        "f1": 0.00653,
        "accuracy": 0.015303,
        "main_score": 0.00653,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.031808,
        "recall": 0.052562,
        "f1": 0.036137,
        "accuracy": 0.052562,
        "main_score": 0.036137,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.011094,
        "recall": 0.025283,
        "f1": 0.013426,
        "accuracy": 0.025283,
        "main_score": 0.013426,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.033207,
        "recall": 0.051896,
        "f1": 0.037226,
        "accuracy": 0.051896,
        "main_score": 0.037226,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.042071,
        "recall": 0.065203,
        "f1": 0.047049,
        "accuracy": 0.065203,
        "main_score": 0.047049,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.046738,
        "recall": 0.077179,
        "f1": 0.053319,
        "accuracy": 0.077179,
        "main_score": 0.053319,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.039173,
        "recall": 0.066534,
        "f1": 0.044509,
        "accuracy": 0.066534,
        "main_score": 0.044509,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.036825,
        "recall": 0.05855,
        "f1": 0.04138,
        "accuracy": 0.05855,
        "main_score": 0.04138,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.035244,
        "recall": 0.055223,
        "f1": 0.03902,
        "accuracy": 0.055223,
        "main_score": 0.03902,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.033526,
        "recall": 0.052562,
        "f1": 0.037179,
        "accuracy": 0.052562,
        "main_score": 0.037179,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.027765,
        "recall": 0.044578,
        "f1": 0.031546,
        "accuracy": 0.044578,
        "main_score": 0.031546,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.011326,
        "recall": 0.025948,
        "f1": 0.013319,
        "accuracy": 0.025948,
        "main_score": 0.013319,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.01775,
        "recall": 0.033932,
        "f1": 0.020665,
        "accuracy": 0.033932,
        "main_score": 0.020665,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.00624,
        "recall": 0.013307,
        "f1": 0.007393,
        "accuracy": 0.013307,
        "main_score": 0.007393,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.042325,
        "recall": 0.075848,
        "f1": 0.049426,
        "accuracy": 0.075848,
        "main_score": 0.049426,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.02334,
        "recall": 0.045243,
        "f1": 0.027545,
        "accuracy": 0.045243,
        "main_score": 0.027545,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.023742,
        "recall": 0.044578,
        "f1": 0.027892,
        "accuracy": 0.044578,
        "main_score": 0.027892,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000965,
        "recall": 0.003992,
        "f1": 0.001166,
        "accuracy": 0.003992,
        "main_score": 0.001166,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028113,
        "recall": 0.050566,
        "f1": 0.031867,
        "accuracy": 0.050566,
        "main_score": 0.031867,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.032203,
        "recall": 0.055223,
        "f1": 0.03726,
        "accuracy": 0.055223,
        "main_score": 0.03726,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.033089,
        "recall": 0.051231,
        "f1": 0.036994,
        "accuracy": 0.051231,
        "main_score": 0.036994,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.020594,
        "recall": 0.036593,
        "f1": 0.023825,
        "accuracy": 0.036593,
        "main_score": 0.023825,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.00711,
        "recall": 0.013972,
        "f1": 0.008064,
        "accuracy": 0.013972,
        "main_score": 0.008064,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.027405,
        "recall": 0.051896,
        "f1": 0.03275,
        "accuracy": 0.051896,
        "main_score": 0.03275,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.010838,
        "recall": 0.025283,
        "f1": 0.012897,
        "accuracy": 0.025283,
        "main_score": 0.012897,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.024762,
        "recall": 0.042582,
        "f1": 0.028203,
        "accuracy": 0.042582,
        "main_score": 0.028203,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.029278,
        "recall": 0.047239,
        "f1": 0.033246,
        "accuracy": 0.047239,
        "main_score": 0.033246,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.040905,
        "recall": 0.067864,
        "f1": 0.046683,
        "accuracy": 0.067864,
        "main_score": 0.046683,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.029127,
        "recall": 0.046574,
        "f1": 0.032141,
        "accuracy": 0.046574,
        "main_score": 0.032141,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.027351,
        "recall": 0.045908,
        "f1": 0.030817,
        "accuracy": 0.045908,
        "main_score": 0.030817,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.021785,
        "recall": 0.03992,
        "f1": 0.025177,
        "accuracy": 0.03992,
        "main_score": 0.025177,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.027585,
        "recall": 0.042582,
        "f1": 0.030371,
        "accuracy": 0.042582,
        "main_score": 0.030371,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.022242,
        "recall": 0.037259,
        "f1": 0.025125,
        "accuracy": 0.037259,
        "main_score": 0.025125,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.008246,
        "recall": 0.020625,
        "f1": 0.010238,
        "accuracy": 0.020625,
        "main_score": 0.010238,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.019505,
        "recall": 0.031936,
        "f1": 0.021692,
        "accuracy": 0.031936,
        "main_score": 0.021692,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006796,
        "recall": 0.013307,
        "f1": 0.0077,
        "accuracy": 0.013307,
        "main_score": 0.0077,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.044953,
        "recall": 0.06986,
        "f1": 0.050275,
        "accuracy": 0.06986,
        "main_score": 0.050275,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.035561,
        "recall": 0.057884,
        "f1": 0.039911,
        "accuracy": 0.057884,
        "main_score": 0.039911,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.055366,
        "recall": 0.072522,
        "f1": 0.058913,
        "accuracy": 0.072522,
        "main_score": 0.058913,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.019221,
        "recall": 0.025283,
        "f1": 0.020255,
        "accuracy": 0.025283,
        "main_score": 0.020255,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.063501,
        "recall": 0.083167,
        "f1": 0.067971,
        "accuracy": 0.083167,
        "main_score": 0.067971,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.043458,
        "recall": 0.066534,
        "f1": 0.048501,
        "accuracy": 0.066534,
        "main_score": 0.048501,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.073529,
        "recall": 0.091151,
        "f1": 0.077563,
        "accuracy": 0.091151,
        "main_score": 0.077563,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.021805,
        "recall": 0.039255,
        "f1": 0.025111,
        "accuracy": 0.039255,
        "main_score": 0.025111,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.030737,
        "recall": 0.040585,
        "f1": 0.032687,
        "accuracy": 0.040585,
        "main_score": 0.032687,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.022615,
        "recall": 0.038589,
        "f1": 0.025666,
        "accuracy": 0.038589,
        "main_score": 0.025666,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.042293,
        "recall": 0.05988,
        "f1": 0.045964,
        "accuracy": 0.05988,
        "main_score": 0.045964,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.027942,
        "recall": 0.044578,
        "f1": 0.03106,
        "accuracy": 0.044578,
        "main_score": 0.03106,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.031156,
        "recall": 0.054558,
        "f1": 0.036694,
        "accuracy": 0.054558,
        "main_score": 0.036694,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.034298,
        "recall": 0.05988,
        "f1": 0.039436,
        "accuracy": 0.05988,
        "main_score": 0.039436,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.03173,
        "recall": 0.0499,
        "f1": 0.035693,
        "accuracy": 0.0499,
        "main_score": 0.035693,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.067827,
        "recall": 0.085828,
        "f1": 0.071221,
        "accuracy": 0.085828,
        "main_score": 0.071221,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.025485,
        "recall": 0.047239,
        "f1": 0.029735,
        "accuracy": 0.047239,
        "main_score": 0.029735,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.022148,
        "recall": 0.033932,
        "f1": 0.024873,
        "accuracy": 0.033932,
        "main_score": 0.024873,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.05953,
        "recall": 0.075183,
        "f1": 0.062893,
        "accuracy": 0.075183,
        "main_score": 0.062893,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.042916,
        "recall": 0.05855,
        "f1": 0.045998,
        "accuracy": 0.05855,
        "main_score": 0.045998,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.05263,
        "recall": 0.067864,
        "f1": 0.056052,
        "accuracy": 0.067864,
        "main_score": 0.056052,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.041171,
        "recall": 0.0499,
        "f1": 0.042678,
        "accuracy": 0.0499,
        "main_score": 0.042678,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.035357,
        "recall": 0.059215,
        "f1": 0.040767,
        "accuracy": 0.059215,
        "main_score": 0.040767,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.029032,
        "recall": 0.0499,
        "f1": 0.0336,
        "accuracy": 0.0499,
        "main_score": 0.0336,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.057535,
        "recall": 0.07851,
        "f1": 0.06217,
        "accuracy": 0.07851,
        "main_score": 0.06217,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.022124,
        "recall": 0.02994,
        "f1": 0.023121,
        "accuracy": 0.02994,
        "main_score": 0.023121,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.059341,
        "recall": 0.083832,
        "f1": 0.063682,
        "accuracy": 0.083832,
        "main_score": 0.063682,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.047096,
        "recall": 0.073187,
        "f1": 0.052821,
        "accuracy": 0.073187,
        "main_score": 0.052821,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.09556,
        "recall": 0.129741,
        "f1": 0.103243,
        "accuracy": 0.129741,
        "main_score": 0.103243,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.017543,
        "recall": 0.029275,
        "f1": 0.019481,
        "accuracy": 0.029275,
        "main_score": 0.019481,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.035739,
        "recall": 0.047904,
        "f1": 0.038056,
        "accuracy": 0.047904,
        "main_score": 0.038056,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.033445,
        "recall": 0.063872,
        "f1": 0.040412,
        "accuracy": 0.063872,
        "main_score": 0.040412,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.041954,
        "recall": 0.055888,
        "f1": 0.04437,
        "accuracy": 0.055888,
        "main_score": 0.04437,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.025676,
        "recall": 0.040585,
        "f1": 0.028277,
        "accuracy": 0.040585,
        "main_score": 0.028277,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.028365,
        "recall": 0.046574,
        "f1": 0.032127,
        "accuracy": 0.046574,
        "main_score": 0.032127,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.033558,
        "recall": 0.05855,
        "f1": 0.039123,
        "accuracy": 0.05855,
        "main_score": 0.039123,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.031085,
        "recall": 0.046574,
        "f1": 0.034826,
        "accuracy": 0.046574,
        "main_score": 0.034826,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.088324,
        "recall": 0.122422,
        "f1": 0.096335,
        "accuracy": 0.122422,
        "main_score": 0.096335,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.017864,
        "recall": 0.033267,
        "f1": 0.020508,
        "accuracy": 0.033267,
        "main_score": 0.020508,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.031932,
        "recall": 0.05988,
        "f1": 0.037459,
        "accuracy": 0.05988,
        "main_score": 0.037459,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.064772,
        "recall": 0.093147,
        "f1": 0.071359,
        "accuracy": 0.093147,
        "main_score": 0.071359,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.04477,
        "recall": 0.05988,
        "f1": 0.047521,
        "accuracy": 0.05988,
        "main_score": 0.047521,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.049393,
        "recall": 0.065868,
        "f1": 0.052582,
        "accuracy": 0.065868,
        "main_score": 0.052582,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.052283,
        "recall": 0.066534,
        "f1": 0.054744,
        "accuracy": 0.066534,
        "main_score": 0.054744,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001435,
        "recall": 0.007984,
        "f1": 0.001879,
        "accuracy": 0.007984,
        "main_score": 0.001879,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.000847,
        "recall": 0.009315,
        "f1": 0.001366,
        "accuracy": 0.009315,
        "main_score": 0.001366,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.018786,
        "recall": 0.043247,
        "f1": 0.021915,
        "accuracy": 0.043247,
        "main_score": 0.021915,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.022506,
        "recall": 0.042582,
        "f1": 0.025455,
        "accuracy": 0.042582,
        "main_score": 0.025455,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.02191,
        "recall": 0.043912,
        "f1": 0.024902,
        "accuracy": 0.043912,
        "main_score": 0.024902,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.00871,
        "recall": 0.025283,
        "f1": 0.010918,
        "accuracy": 0.025283,
        "main_score": 0.010918,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.02259,
        "recall": 0.041916,
        "f1": 0.025055,
        "accuracy": 0.041916,
        "main_score": 0.025055,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001357,
        "recall": 0.007319,
        "f1": 0.001875,
        "accuracy": 0.007319,
        "main_score": 0.001875,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.014302,
        "recall": 0.033932,
        "f1": 0.017228,
        "accuracy": 0.033932,
        "main_score": 0.017228,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.000635,
        "recall": 0.007319,
        "f1": 0.000972,
        "accuracy": 0.007319,
        "main_score": 0.000972,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.016487,
        "recall": 0.035263,
        "f1": 0.018732,
        "accuracy": 0.035263,
        "main_score": 0.018732,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001109,
        "recall": 0.009315,
        "f1": 0.001452,
        "accuracy": 0.009315,
        "main_score": 0.001452,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001639,
        "recall": 0.006653,
        "f1": 0.001866,
        "accuracy": 0.006653,
        "main_score": 0.001866,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.00203,
        "recall": 0.007319,
        "f1": 0.002393,
        "accuracy": 0.007319,
        "main_score": 0.002393,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.001067,
        "recall": 0.006653,
        "f1": 0.001557,
        "accuracy": 0.006653,
        "main_score": 0.001557,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.023967,
        "recall": 0.041916,
        "f1": 0.026284,
        "accuracy": 0.041916,
        "main_score": 0.026284,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001508,
        "recall": 0.006653,
        "f1": 0.001887,
        "accuracy": 0.006653,
        "main_score": 0.001887,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001344,
        "recall": 0.008649,
        "f1": 0.001837,
        "accuracy": 0.008649,
        "main_score": 0.001837,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.023455,
        "recall": 0.040585,
        "f1": 0.025885,
        "accuracy": 0.040585,
        "main_score": 0.025885,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.02203,
        "recall": 0.041251,
        "f1": 0.024709,
        "accuracy": 0.041251,
        "main_score": 0.024709,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.019611,
        "recall": 0.045243,
        "f1": 0.023083,
        "accuracy": 0.045243,
        "main_score": 0.023083,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.021287,
        "recall": 0.037259,
        "f1": 0.023826,
        "accuracy": 0.037259,
        "main_score": 0.023826,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.039748,
        "recall": 0.061876,
        "f1": 0.044335,
        "accuracy": 0.061876,
        "main_score": 0.044335,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.036456,
        "recall": 0.061876,
        "f1": 0.041607,
        "accuracy": 0.061876,
        "main_score": 0.041607,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.063451,
        "recall": 0.085828,
        "f1": 0.068208,
        "accuracy": 0.085828,
        "main_score": 0.068208,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.065125,
        "recall": 0.085163,
        "f1": 0.069006,
        "accuracy": 0.085163,
        "main_score": 0.069006,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.022124,
        "recall": 0.029275,
        "f1": 0.023135,
        "accuracy": 0.029275,
        "main_score": 0.023135,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.049471,
        "recall": 0.07851,
        "f1": 0.055893,
        "accuracy": 0.07851,
        "main_score": 0.055893,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.070109,
        "recall": 0.087824,
        "f1": 0.073646,
        "accuracy": 0.087824,
        "main_score": 0.073646,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.036884,
        "recall": 0.059215,
        "f1": 0.041438,
        "accuracy": 0.059215,
        "main_score": 0.041438,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.034619,
        "recall": 0.045243,
        "f1": 0.036917,
        "accuracy": 0.045243,
        "main_score": 0.036917,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.024387,
        "recall": 0.03992,
        "f1": 0.027832,
        "accuracy": 0.03992,
        "main_score": 0.027832,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.048515,
        "recall": 0.066534,
        "f1": 0.052248,
        "accuracy": 0.066534,
        "main_score": 0.052248,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.036557,
        "recall": 0.061211,
        "f1": 0.041443,
        "accuracy": 0.061211,
        "main_score": 0.041443,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.035143,
        "recall": 0.05988,
        "f1": 0.040237,
        "accuracy": 0.05988,
        "main_score": 0.040237,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.042411,
        "recall": 0.065868,
        "f1": 0.047493,
        "accuracy": 0.065868,
        "main_score": 0.047493,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.027967,
        "recall": 0.042582,
        "f1": 0.030858,
        "accuracy": 0.042582,
        "main_score": 0.030858,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.064049,
        "recall": 0.080506,
        "f1": 0.067423,
        "accuracy": 0.080506,
        "main_score": 0.067423,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.026933,
        "recall": 0.047904,
        "f1": 0.030741,
        "accuracy": 0.047904,
        "main_score": 0.030741,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.027612,
        "recall": 0.043247,
        "f1": 0.030866,
        "accuracy": 0.043247,
        "main_score": 0.030866,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.05658,
        "recall": 0.06853,
        "f1": 0.05904,
        "accuracy": 0.06853,
        "main_score": 0.05904,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.052714,
        "recall": 0.074518,
        "f1": 0.056791,
        "accuracy": 0.074518,
        "main_score": 0.056791,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.070982,
        "recall": 0.090486,
        "f1": 0.0749,
        "accuracy": 0.090486,
        "main_score": 0.0749,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.04192,
        "recall": 0.052562,
        "f1": 0.043827,
        "accuracy": 0.052562,
        "main_score": 0.043827,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.032968,
        "recall": 0.050566,
        "f1": 0.036682,
        "accuracy": 0.050566,
        "main_score": 0.036682,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.031387,
        "recall": 0.053227,
        "f1": 0.035592,
        "accuracy": 0.053227,
        "main_score": 0.035592,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.040105,
        "recall": 0.056554,
        "f1": 0.043278,
        "accuracy": 0.056554,
        "main_score": 0.043278,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.046542,
        "recall": 0.06853,
        "f1": 0.050861,
        "accuracy": 0.06853,
        "main_score": 0.050861,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.011999,
        "recall": 0.016633,
        "f1": 0.012797,
        "accuracy": 0.016633,
        "main_score": 0.012797,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.056215,
        "recall": 0.079175,
        "f1": 0.061352,
        "accuracy": 0.079175,
        "main_score": 0.061352,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.058279,
        "recall": 0.082502,
        "f1": 0.063126,
        "accuracy": 0.082502,
        "main_score": 0.063126,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.021886,
        "recall": 0.037259,
        "f1": 0.02534,
        "accuracy": 0.037259,
        "main_score": 0.02534,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.026131,
        "recall": 0.033932,
        "f1": 0.027379,
        "accuracy": 0.033932,
        "main_score": 0.027379,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.033963,
        "recall": 0.057219,
        "f1": 0.038382,
        "accuracy": 0.057219,
        "main_score": 0.038382,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.030972,
        "recall": 0.03992,
        "f1": 0.032708,
        "accuracy": 0.03992,
        "main_score": 0.032708,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.043549,
        "recall": 0.067199,
        "f1": 0.048916,
        "accuracy": 0.067199,
        "main_score": 0.048916,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.028601,
        "recall": 0.045908,
        "f1": 0.032388,
        "accuracy": 0.045908,
        "main_score": 0.032388,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.031242,
        "recall": 0.053892,
        "f1": 0.03586,
        "accuracy": 0.053892,
        "main_score": 0.03586,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.030363,
        "recall": 0.046574,
        "f1": 0.033528,
        "accuracy": 0.046574,
        "main_score": 0.033528,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.047833,
        "recall": 0.071191,
        "f1": 0.05198,
        "accuracy": 0.071191,
        "main_score": 0.05198,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.017049,
        "recall": 0.031271,
        "f1": 0.019528,
        "accuracy": 0.031271,
        "main_score": 0.019528,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.031441,
        "recall": 0.051896,
        "f1": 0.035213,
        "accuracy": 0.051896,
        "main_score": 0.035213,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.045703,
        "recall": 0.065203,
        "f1": 0.049276,
        "accuracy": 0.065203,
        "main_score": 0.049276,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.02663,
        "recall": 0.036593,
        "f1": 0.028222,
        "accuracy": 0.036593,
        "main_score": 0.028222,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.039998,
        "recall": 0.051231,
        "f1": 0.042361,
        "accuracy": 0.051231,
        "main_score": 0.042361,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.030328,
        "recall": 0.040585,
        "f1": 0.032072,
        "accuracy": 0.040585,
        "main_score": 0.032072,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.042537,
        "recall": 0.067199,
        "f1": 0.047898,
        "accuracy": 0.067199,
        "main_score": 0.047898,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.037097,
        "recall": 0.059215,
        "f1": 0.041821,
        "accuracy": 0.059215,
        "main_score": 0.041821,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.067462,
        "recall": 0.093147,
        "f1": 0.073127,
        "accuracy": 0.093147,
        "main_score": 0.073127,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.082701,
        "recall": 0.11843,
        "f1": 0.090745,
        "accuracy": 0.11843,
        "main_score": 0.090745,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.023498,
        "recall": 0.030605,
        "f1": 0.024501,
        "accuracy": 0.030605,
        "main_score": 0.024501,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.064496,
        "recall": 0.091816,
        "f1": 0.06989,
        "accuracy": 0.091816,
        "main_score": 0.06989,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.050224,
        "recall": 0.077844,
        "f1": 0.056579,
        "accuracy": 0.077844,
        "main_score": 0.056579,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.026903,
        "recall": 0.044578,
        "f1": 0.030212,
        "accuracy": 0.044578,
        "main_score": 0.030212,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.03509,
        "recall": 0.050566,
        "f1": 0.038058,
        "accuracy": 0.050566,
        "main_score": 0.038058,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.035538,
        "recall": 0.067199,
        "f1": 0.042903,
        "accuracy": 0.067199,
        "main_score": 0.042903,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.045124,
        "recall": 0.063207,
        "f1": 0.048206,
        "accuracy": 0.063207,
        "main_score": 0.048206,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.028908,
        "recall": 0.04857,
        "f1": 0.033072,
        "accuracy": 0.04857,
        "main_score": 0.033072,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.034149,
        "recall": 0.05855,
        "f1": 0.039585,
        "accuracy": 0.05855,
        "main_score": 0.039585,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.036456,
        "recall": 0.064538,
        "f1": 0.042616,
        "accuracy": 0.064538,
        "main_score": 0.042616,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.030645,
        "recall": 0.051896,
        "f1": 0.035656,
        "accuracy": 0.051896,
        "main_score": 0.035656,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.087025,
        "recall": 0.125083,
        "f1": 0.095156,
        "accuracy": 0.125083,
        "main_score": 0.095156,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.02538,
        "recall": 0.042582,
        "f1": 0.029037,
        "accuracy": 0.042582,
        "main_score": 0.029037,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.027043,
        "recall": 0.045243,
        "f1": 0.03129,
        "accuracy": 0.045243,
        "main_score": 0.03129,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.083372,
        "recall": 0.112442,
        "f1": 0.089647,
        "accuracy": 0.112442,
        "main_score": 0.089647,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.044,
        "recall": 0.059215,
        "f1": 0.046851,
        "accuracy": 0.059215,
        "main_score": 0.046851,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.05553,
        "recall": 0.070526,
        "f1": 0.058671,
        "accuracy": 0.070526,
        "main_score": 0.058671,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.051611,
        "recall": 0.06853,
        "f1": 0.054893,
        "accuracy": 0.06853,
        "main_score": 0.054893,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.028833,
        "recall": 0.045243,
        "f1": 0.031919,
        "accuracy": 0.045243,
        "main_score": 0.031919,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.025813,
        "recall": 0.041251,
        "f1": 0.028897,
        "accuracy": 0.041251,
        "main_score": 0.028897,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.02177,
        "recall": 0.038589,
        "f1": 0.024654,
        "accuracy": 0.038589,
        "main_score": 0.024654,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.016398,
        "recall": 0.02994,
        "f1": 0.018854,
        "accuracy": 0.02994,
        "main_score": 0.018854,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000733,
        "recall": 0.003992,
        "f1": 0.000793,
        "accuracy": 0.003992,
        "main_score": 0.000793,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.032952,
        "recall": 0.056554,
        "f1": 0.037815,
        "accuracy": 0.056554,
        "main_score": 0.037815,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.024492,
        "recall": 0.042582,
        "f1": 0.028326,
        "accuracy": 0.042582,
        "main_score": 0.028326,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.022002,
        "recall": 0.037259,
        "f1": 0.025116,
        "accuracy": 0.037259,
        "main_score": 0.025116,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004499,
        "recall": 0.011311,
        "f1": 0.005368,
        "accuracy": 0.011311,
        "main_score": 0.005368,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.018061,
        "recall": 0.031936,
        "f1": 0.020565,
        "accuracy": 0.031936,
        "main_score": 0.020565,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.021974,
        "recall": 0.040585,
        "f1": 0.025477,
        "accuracy": 0.040585,
        "main_score": 0.025477,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.029018,
        "recall": 0.045908,
        "f1": 0.032174,
        "accuracy": 0.045908,
        "main_score": 0.032174,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.027585,
        "recall": 0.047904,
        "f1": 0.031302,
        "accuracy": 0.047904,
        "main_score": 0.031302,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.027657,
        "recall": 0.043247,
        "f1": 0.030287,
        "accuracy": 0.043247,
        "main_score": 0.030287,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.018726,
        "recall": 0.035928,
        "f1": 0.021575,
        "accuracy": 0.035928,
        "main_score": 0.021575,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.01492,
        "recall": 0.027279,
        "f1": 0.016916,
        "accuracy": 0.027279,
        "main_score": 0.016916,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.028795,
        "recall": 0.041251,
        "f1": 0.031205,
        "accuracy": 0.041251,
        "main_score": 0.031205,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.014289,
        "recall": 0.026613,
        "f1": 0.016525,
        "accuracy": 0.026613,
        "main_score": 0.016525,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.017321,
        "recall": 0.033932,
        "f1": 0.02001,
        "accuracy": 0.033932,
        "main_score": 0.02001,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.017026,
        "recall": 0.039255,
        "f1": 0.020637,
        "accuracy": 0.039255,
        "main_score": 0.020637,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.032363,
        "recall": 0.055223,
        "f1": 0.03761,
        "accuracy": 0.055223,
        "main_score": 0.03761,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.005901,
        "recall": 0.013307,
        "f1": 0.006832,
        "accuracy": 0.013307,
        "main_score": 0.006832,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.0089,
        "recall": 0.017299,
        "f1": 0.010017,
        "accuracy": 0.017299,
        "main_score": 0.010017,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.007136,
        "recall": 0.015303,
        "f1": 0.008286,
        "accuracy": 0.015303,
        "main_score": 0.008286,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.034517,
        "recall": 0.043247,
        "f1": 0.035796,
        "accuracy": 0.043247,
        "main_score": 0.035796,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.03502,
        "recall": 0.041916,
        "f1": 0.036594,
        "accuracy": 0.041916,
        "main_score": 0.036594,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.021573,
        "recall": 0.025283,
        "f1": 0.022232,
        "accuracy": 0.025283,
        "main_score": 0.022232,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.033823,
        "recall": 0.040585,
        "f1": 0.034787,
        "accuracy": 0.040585,
        "main_score": 0.034787,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.019196,
        "recall": 0.027279,
        "f1": 0.021002,
        "accuracy": 0.027279,
        "main_score": 0.021002,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.03772,
        "recall": 0.047239,
        "f1": 0.039078,
        "accuracy": 0.047239,
        "main_score": 0.039078,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.006762,
        "recall": 0.012641,
        "f1": 0.007512,
        "accuracy": 0.012641,
        "main_score": 0.007512,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.007178,
        "recall": 0.018629,
        "f1": 0.008814,
        "accuracy": 0.018629,
        "main_score": 0.008814,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.029264,
        "recall": 0.035928,
        "f1": 0.030192,
        "accuracy": 0.035928,
        "main_score": 0.030192,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.0078,
        "recall": 0.014637,
        "f1": 0.008842,
        "accuracy": 0.014637,
        "main_score": 0.008842,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.010046,
        "recall": 0.017299,
        "f1": 0.011234,
        "accuracy": 0.017299,
        "main_score": 0.011234,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.008266,
        "recall": 0.017964,
        "f1": 0.009651,
        "accuracy": 0.017964,
        "main_score": 0.009651,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.004321,
        "recall": 0.010645,
        "f1": 0.005437,
        "accuracy": 0.010645,
        "main_score": 0.005437,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.039997,
        "recall": 0.047904,
        "f1": 0.041486,
        "accuracy": 0.047904,
        "main_score": 0.041486,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.003962,
        "recall": 0.00998,
        "f1": 0.004753,
        "accuracy": 0.00998,
        "main_score": 0.004753,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006233,
        "recall": 0.013972,
        "f1": 0.007542,
        "accuracy": 0.013972,
        "main_score": 0.007542,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.038094,
        "recall": 0.043912,
        "f1": 0.039382,
        "accuracy": 0.043912,
        "main_score": 0.039382,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.027773,
        "recall": 0.035263,
        "f1": 0.02871,
        "accuracy": 0.035263,
        "main_score": 0.02871,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.031796,
        "recall": 0.037259,
        "f1": 0.032644,
        "accuracy": 0.037259,
        "main_score": 0.032644,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.051525,
        "recall": 0.059215,
        "f1": 0.053283,
        "accuracy": 0.059215,
        "main_score": 0.053283,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.034366,
        "recall": 0.051231,
        "f1": 0.038101,
        "accuracy": 0.051231,
        "main_score": 0.038101,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.032319,
        "recall": 0.047904,
        "f1": 0.035466,
        "accuracy": 0.047904,
        "main_score": 0.035466,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.018176,
        "recall": 0.025948,
        "f1": 0.019981,
        "accuracy": 0.025948,
        "main_score": 0.019981,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.027321,
        "recall": 0.046574,
        "f1": 0.030799,
        "accuracy": 0.046574,
        "main_score": 0.030799,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000621,
        "recall": 0.003327,
        "f1": 0.000953,
        "accuracy": 0.003327,
        "main_score": 0.000953,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022804,
        "recall": 0.035928,
        "f1": 0.025109,
        "accuracy": 0.035928,
        "main_score": 0.025109,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.02886,
        "recall": 0.044578,
        "f1": 0.031905,
        "accuracy": 0.044578,
        "main_score": 0.031905,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.044484,
        "recall": 0.062542,
        "f1": 0.048427,
        "accuracy": 0.062542,
        "main_score": 0.048427,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.018916,
        "recall": 0.028609,
        "f1": 0.020581,
        "accuracy": 0.028609,
        "main_score": 0.020581,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.005697,
        "recall": 0.015303,
        "f1": 0.007094,
        "accuracy": 0.015303,
        "main_score": 0.007094,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.009115,
        "recall": 0.016633,
        "f1": 0.010385,
        "accuracy": 0.016633,
        "main_score": 0.010385,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.02776,
        "recall": 0.03992,
        "f1": 0.030084,
        "accuracy": 0.03992,
        "main_score": 0.030084,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.022283,
        "recall": 0.031936,
        "f1": 0.024754,
        "accuracy": 0.031936,
        "main_score": 0.024754,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.036912,
        "recall": 0.060546,
        "f1": 0.041603,
        "accuracy": 0.060546,
        "main_score": 0.041603,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.029583,
        "recall": 0.044578,
        "f1": 0.032377,
        "accuracy": 0.044578,
        "main_score": 0.032377,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.034769,
        "recall": 0.056554,
        "f1": 0.039301,
        "accuracy": 0.056554,
        "main_score": 0.039301,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.016931,
        "recall": 0.025948,
        "f1": 0.018627,
        "accuracy": 0.025948,
        "main_score": 0.018627,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.024192,
        "recall": 0.037259,
        "f1": 0.026689,
        "accuracy": 0.037259,
        "main_score": 0.026689,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.026462,
        "recall": 0.040585,
        "f1": 0.029194,
        "accuracy": 0.040585,
        "main_score": 0.029194,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.010958,
        "recall": 0.021291,
        "f1": 0.01244,
        "accuracy": 0.021291,
        "main_score": 0.01244,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.014982,
        "recall": 0.027279,
        "f1": 0.017031,
        "accuracy": 0.027279,
        "main_score": 0.017031,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.009548,
        "recall": 0.017964,
        "f1": 0.011001,
        "accuracy": 0.017964,
        "main_score": 0.011001,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.013485,
        "recall": 0.025948,
        "f1": 0.015729,
        "accuracy": 0.025948,
        "main_score": 0.015729,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.01226,
        "recall": 0.027279,
        "f1": 0.015258,
        "accuracy": 0.027279,
        "main_score": 0.015258,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.043491,
        "recall": 0.059215,
        "f1": 0.046707,
        "accuracy": 0.059215,
        "main_score": 0.046707,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.04057,
        "recall": 0.0499,
        "f1": 0.042346,
        "accuracy": 0.0499,
        "main_score": 0.042346,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.017976,
        "recall": 0.023287,
        "f1": 0.018569,
        "accuracy": 0.023287,
        "main_score": 0.018569,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.051807,
        "recall": 0.066534,
        "f1": 0.055414,
        "accuracy": 0.066534,
        "main_score": 0.055414,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.026858,
        "recall": 0.043247,
        "f1": 0.030301,
        "accuracy": 0.043247,
        "main_score": 0.030301,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.0444,
        "recall": 0.05855,
        "f1": 0.046959,
        "accuracy": 0.05855,
        "main_score": 0.046959,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.032891,
        "recall": 0.051896,
        "f1": 0.036436,
        "accuracy": 0.051896,
        "main_score": 0.036436,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.02944,
        "recall": 0.035928,
        "f1": 0.030663,
        "accuracy": 0.035928,
        "main_score": 0.030663,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.010943,
        "recall": 0.023952,
        "f1": 0.013225,
        "accuracy": 0.023952,
        "main_score": 0.013225,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.017062,
        "recall": 0.030605,
        "f1": 0.019813,
        "accuracy": 0.030605,
        "main_score": 0.019813,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.013827,
        "recall": 0.025948,
        "f1": 0.015815,
        "accuracy": 0.025948,
        "main_score": 0.015815,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.015986,
        "recall": 0.027944,
        "f1": 0.018339,
        "accuracy": 0.027944,
        "main_score": 0.018339,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.018055,
        "recall": 0.033267,
        "f1": 0.020716,
        "accuracy": 0.033267,
        "main_score": 0.020716,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.044105,
        "recall": 0.057219,
        "f1": 0.046742,
        "accuracy": 0.057219,
        "main_score": 0.046742,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.01591,
        "recall": 0.031936,
        "f1": 0.018749,
        "accuracy": 0.031936,
        "main_score": 0.018749,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006769,
        "recall": 0.015968,
        "f1": 0.008319,
        "accuracy": 0.015968,
        "main_score": 0.008319,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.039858,
        "recall": 0.053227,
        "f1": 0.042012,
        "accuracy": 0.053227,
        "main_score": 0.042012,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.044808,
        "recall": 0.061211,
        "f1": 0.048343,
        "accuracy": 0.061211,
        "main_score": 0.048343,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.054949,
        "recall": 0.075848,
        "f1": 0.058627,
        "accuracy": 0.075848,
        "main_score": 0.058627,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.034518,
        "recall": 0.040585,
        "f1": 0.035691,
        "accuracy": 0.040585,
        "main_score": 0.035691,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.03088,
        "recall": 0.053892,
        "f1": 0.035298,
        "accuracy": 0.053892,
        "main_score": 0.035298,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.026714,
        "recall": 0.047904,
        "f1": 0.030808,
        "accuracy": 0.047904,
        "main_score": 0.030808,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.021783,
        "recall": 0.040585,
        "f1": 0.02534,
        "accuracy": 0.040585,
        "main_score": 0.02534,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.020428,
        "recall": 0.038589,
        "f1": 0.023535,
        "accuracy": 0.038589,
        "main_score": 0.023535,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000917,
        "recall": 0.003992,
        "f1": 0.001057,
        "accuracy": 0.003992,
        "main_score": 0.001057,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031432,
        "recall": 0.057884,
        "f1": 0.036216,
        "accuracy": 0.057884,
        "main_score": 0.036216,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.036423,
        "recall": 0.064538,
        "f1": 0.042617,
        "accuracy": 0.064538,
        "main_score": 0.042617,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.031197,
        "recall": 0.051896,
        "f1": 0.035194,
        "accuracy": 0.051896,
        "main_score": 0.035194,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.031069,
        "recall": 0.050566,
        "f1": 0.034831,
        "accuracy": 0.050566,
        "main_score": 0.034831,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006207,
        "recall": 0.012641,
        "f1": 0.007265,
        "accuracy": 0.012641,
        "main_score": 0.007265,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.025416,
        "recall": 0.050566,
        "f1": 0.030071,
        "accuracy": 0.050566,
        "main_score": 0.030071,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.01476,
        "recall": 0.033267,
        "f1": 0.018002,
        "accuracy": 0.033267,
        "main_score": 0.018002,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.023609,
        "recall": 0.041251,
        "f1": 0.026568,
        "accuracy": 0.041251,
        "main_score": 0.026568,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.030931,
        "recall": 0.053892,
        "f1": 0.035602,
        "accuracy": 0.053892,
        "main_score": 0.035602,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.023906,
        "recall": 0.039255,
        "f1": 0.027366,
        "accuracy": 0.039255,
        "main_score": 0.027366,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.027558,
        "recall": 0.051231,
        "f1": 0.031576,
        "accuracy": 0.051231,
        "main_score": 0.031576,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019611,
        "recall": 0.035928,
        "f1": 0.022605,
        "accuracy": 0.035928,
        "main_score": 0.022605,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.020633,
        "recall": 0.033267,
        "f1": 0.023024,
        "accuracy": 0.033267,
        "main_score": 0.023024,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.015991,
        "recall": 0.033267,
        "f1": 0.018962,
        "accuracy": 0.033267,
        "main_score": 0.018962,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.012643,
        "recall": 0.026613,
        "f1": 0.015178,
        "accuracy": 0.026613,
        "main_score": 0.015178,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.02101,
        "recall": 0.038589,
        "f1": 0.024647,
        "accuracy": 0.038589,
        "main_score": 0.024647,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006473,
        "recall": 0.013307,
        "f1": 0.007632,
        "accuracy": 0.013307,
        "main_score": 0.007632,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.037649,
        "recall": 0.063872,
        "f1": 0.042827,
        "accuracy": 0.063872,
        "main_score": 0.042827,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.034089,
        "recall": 0.056554,
        "f1": 0.038919,
        "accuracy": 0.056554,
        "main_score": 0.038919,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.029864,
        "recall": 0.053892,
        "f1": 0.034518,
        "accuracy": 0.053892,
        "main_score": 0.034518,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.0274,
        "recall": 0.03992,
        "f1": 0.030124,
        "accuracy": 0.03992,
        "main_score": 0.030124,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002265,
        "recall": 0.004657,
        "f1": 0.002444,
        "accuracy": 0.004657,
        "main_score": 0.002444,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027007,
        "recall": 0.051231,
        "f1": 0.031388,
        "accuracy": 0.051231,
        "main_score": 0.031388,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.027103,
        "recall": 0.050566,
        "f1": 0.031712,
        "accuracy": 0.050566,
        "main_score": 0.031712,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.035152,
        "recall": 0.051896,
        "f1": 0.0388,
        "accuracy": 0.051896,
        "main_score": 0.0388,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.029011,
        "recall": 0.047239,
        "f1": 0.03247,
        "accuracy": 0.047239,
        "main_score": 0.03247,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.008886,
        "recall": 0.016633,
        "f1": 0.010649,
        "accuracy": 0.016633,
        "main_score": 0.010649,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.024636,
        "recall": 0.045243,
        "f1": 0.028497,
        "accuracy": 0.045243,
        "main_score": 0.028497,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.012595,
        "recall": 0.023952,
        "f1": 0.014824,
        "accuracy": 0.023952,
        "main_score": 0.014824,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.024345,
        "recall": 0.041251,
        "f1": 0.027661,
        "accuracy": 0.041251,
        "main_score": 0.027661,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.034752,
        "recall": 0.057884,
        "f1": 0.039838,
        "accuracy": 0.057884,
        "main_score": 0.039838,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.03061,
        "recall": 0.054558,
        "f1": 0.035542,
        "accuracy": 0.054558,
        "main_score": 0.035542,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.032437,
        "recall": 0.04857,
        "f1": 0.035816,
        "accuracy": 0.04857,
        "main_score": 0.035816,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.026892,
        "recall": 0.042582,
        "f1": 0.030084,
        "accuracy": 0.042582,
        "main_score": 0.030084,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.02583,
        "recall": 0.039255,
        "f1": 0.028824,
        "accuracy": 0.039255,
        "main_score": 0.028824,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.020771,
        "recall": 0.035263,
        "f1": 0.023749,
        "accuracy": 0.035263,
        "main_score": 0.023749,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.012289,
        "recall": 0.028609,
        "f1": 0.014382,
        "accuracy": 0.028609,
        "main_score": 0.014382,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.018605,
        "recall": 0.033267,
        "f1": 0.021331,
        "accuracy": 0.033267,
        "main_score": 0.021331,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006896,
        "recall": 0.016633,
        "f1": 0.008571,
        "accuracy": 0.016633,
        "main_score": 0.008571,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.042124,
        "recall": 0.063207,
        "f1": 0.046281,
        "accuracy": 0.063207,
        "main_score": 0.046281,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.040507,
        "recall": 0.061876,
        "f1": 0.045272,
        "accuracy": 0.061876,
        "main_score": 0.045272,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.02869,
        "recall": 0.050566,
        "f1": 0.033181,
        "accuracy": 0.050566,
        "main_score": 0.033181,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.027942,
        "recall": 0.044578,
        "f1": 0.031572,
        "accuracy": 0.044578,
        "main_score": 0.031572,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000476,
        "recall": 0.003327,
        "f1": 0.000685,
        "accuracy": 0.003327,
        "main_score": 0.000685,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027486,
        "recall": 0.04857,
        "f1": 0.031699,
        "accuracy": 0.04857,
        "main_score": 0.031699,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.033709,
        "recall": 0.057219,
        "f1": 0.038744,
        "accuracy": 0.057219,
        "main_score": 0.038744,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.03231,
        "recall": 0.04857,
        "f1": 0.035742,
        "accuracy": 0.04857,
        "main_score": 0.035742,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.02677,
        "recall": 0.043247,
        "f1": 0.029805,
        "accuracy": 0.043247,
        "main_score": 0.029805,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.008081,
        "recall": 0.015303,
        "f1": 0.009276,
        "accuracy": 0.015303,
        "main_score": 0.009276,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.029988,
        "recall": 0.051231,
        "f1": 0.034816,
        "accuracy": 0.051231,
        "main_score": 0.034816,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.01375,
        "recall": 0.022621,
        "f1": 0.015244,
        "accuracy": 0.022621,
        "main_score": 0.015244,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.029011,
        "recall": 0.044578,
        "f1": 0.031822,
        "accuracy": 0.044578,
        "main_score": 0.031822,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.035606,
        "recall": 0.052562,
        "f1": 0.039241,
        "accuracy": 0.052562,
        "main_score": 0.039241,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.035461,
        "recall": 0.051896,
        "f1": 0.038917,
        "accuracy": 0.051896,
        "main_score": 0.038917,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.03203,
        "recall": 0.050566,
        "f1": 0.036246,
        "accuracy": 0.050566,
        "main_score": 0.036246,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.023125,
        "recall": 0.041251,
        "f1": 0.026241,
        "accuracy": 0.041251,
        "main_score": 0.026241,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.025799,
        "recall": 0.040585,
        "f1": 0.028444,
        "accuracy": 0.040585,
        "main_score": 0.028444,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.021516,
        "recall": 0.037259,
        "f1": 0.02448,
        "accuracy": 0.037259,
        "main_score": 0.02448,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.013287,
        "recall": 0.027944,
        "f1": 0.015578,
        "accuracy": 0.027944,
        "main_score": 0.015578,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.018958,
        "recall": 0.032601,
        "f1": 0.021053,
        "accuracy": 0.032601,
        "main_score": 0.021053,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.008147,
        "recall": 0.015968,
        "f1": 0.009609,
        "accuracy": 0.015968,
        "main_score": 0.009609,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.043936,
        "recall": 0.071856,
        "f1": 0.048993,
        "accuracy": 0.071856,
        "main_score": 0.048993,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.031767,
        "recall": 0.059215,
        "f1": 0.037322,
        "accuracy": 0.059215,
        "main_score": 0.037322,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.028352,
        "recall": 0.049235,
        "f1": 0.03195,
        "accuracy": 0.049235,
        "main_score": 0.03195,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.023976,
        "recall": 0.042582,
        "f1": 0.028065,
        "accuracy": 0.042582,
        "main_score": 0.028065,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001495,
        "recall": 0.004657,
        "f1": 0.001613,
        "accuracy": 0.004657,
        "main_score": 0.001613,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026124,
        "recall": 0.0499,
        "f1": 0.030243,
        "accuracy": 0.0499,
        "main_score": 0.030243,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.031227,
        "recall": 0.056554,
        "f1": 0.036336,
        "accuracy": 0.056554,
        "main_score": 0.036336,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.034799,
        "recall": 0.052562,
        "f1": 0.038525,
        "accuracy": 0.052562,
        "main_score": 0.038525,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.02231,
        "recall": 0.043912,
        "f1": 0.026304,
        "accuracy": 0.043912,
        "main_score": 0.026304,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006416,
        "recall": 0.014637,
        "f1": 0.00767,
        "accuracy": 0.014637,
        "main_score": 0.00767,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.02836,
        "recall": 0.049235,
        "f1": 0.032537,
        "accuracy": 0.049235,
        "main_score": 0.032537,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.014866,
        "recall": 0.029275,
        "f1": 0.017262,
        "accuracy": 0.029275,
        "main_score": 0.017262,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.030004,
        "recall": 0.049235,
        "f1": 0.033957,
        "accuracy": 0.049235,
        "main_score": 0.033957,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.031137,
        "recall": 0.05988,
        "f1": 0.037194,
        "accuracy": 0.05988,
        "main_score": 0.037194,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.03827,
        "recall": 0.071191,
        "f1": 0.045603,
        "accuracy": 0.071191,
        "main_score": 0.045603,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.025611,
        "recall": 0.050566,
        "f1": 0.030599,
        "accuracy": 0.050566,
        "main_score": 0.030599,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.026993,
        "recall": 0.047904,
        "f1": 0.031026,
        "accuracy": 0.047904,
        "main_score": 0.031026,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.030037,
        "recall": 0.055888,
        "f1": 0.035975,
        "accuracy": 0.055888,
        "main_score": 0.035975,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.021053,
        "recall": 0.037924,
        "f1": 0.024112,
        "accuracy": 0.037924,
        "main_score": 0.024112,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.011746,
        "recall": 0.028609,
        "f1": 0.013811,
        "accuracy": 0.028609,
        "main_score": 0.013811,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.014443,
        "recall": 0.035263,
        "f1": 0.018164,
        "accuracy": 0.035263,
        "main_score": 0.018164,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.005449,
        "recall": 0.014637,
        "f1": 0.006719,
        "accuracy": 0.014637,
        "main_score": 0.006719,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.030486,
        "recall": 0.053227,
        "f1": 0.035651,
        "accuracy": 0.053227,
        "main_score": 0.035651,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.030965,
        "recall": 0.047904,
        "f1": 0.034647,
        "accuracy": 0.047904,
        "main_score": 0.034647,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.062587,
        "recall": 0.085163,
        "f1": 0.067942,
        "accuracy": 0.085163,
        "main_score": 0.067942,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.084706,
        "recall": 0.112442,
        "f1": 0.091304,
        "accuracy": 0.112442,
        "main_score": 0.091304,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.022094,
        "recall": 0.028609,
        "f1": 0.023291,
        "accuracy": 0.028609,
        "main_score": 0.023291,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.065791,
        "recall": 0.090486,
        "f1": 0.071076,
        "accuracy": 0.090486,
        "main_score": 0.071076,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.0466,
        "recall": 0.073187,
        "f1": 0.052536,
        "accuracy": 0.073187,
        "main_score": 0.052536,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.087596,
        "recall": 0.121091,
        "f1": 0.095341,
        "accuracy": 0.121091,
        "main_score": 0.095341,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016531,
        "recall": 0.031271,
        "f1": 0.019118,
        "accuracy": 0.031271,
        "main_score": 0.019118,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.037156,
        "recall": 0.053227,
        "f1": 0.040369,
        "accuracy": 0.053227,
        "main_score": 0.040369,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.034146,
        "recall": 0.05988,
        "f1": 0.040066,
        "accuracy": 0.05988,
        "main_score": 0.040066,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.042455,
        "recall": 0.056554,
        "f1": 0.045309,
        "accuracy": 0.056554,
        "main_score": 0.045309,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.030178,
        "recall": 0.046574,
        "f1": 0.033431,
        "accuracy": 0.046574,
        "main_score": 0.033431,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.031773,
        "recall": 0.054558,
        "f1": 0.036676,
        "accuracy": 0.054558,
        "main_score": 0.036676,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.031964,
        "recall": 0.05855,
        "f1": 0.037658,
        "accuracy": 0.05855,
        "main_score": 0.037658,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.027812,
        "recall": 0.044578,
        "f1": 0.031299,
        "accuracy": 0.044578,
        "main_score": 0.031299,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.01569,
        "recall": 0.02994,
        "f1": 0.018365,
        "accuracy": 0.02994,
        "main_score": 0.018365,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.03412,
        "recall": 0.060546,
        "f1": 0.039573,
        "accuracy": 0.060546,
        "main_score": 0.039573,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.067464,
        "recall": 0.091816,
        "f1": 0.072791,
        "accuracy": 0.091816,
        "main_score": 0.072791,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.044313,
        "recall": 0.057219,
        "f1": 0.046715,
        "accuracy": 0.057219,
        "main_score": 0.046715,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.056017,
        "recall": 0.073852,
        "f1": 0.059516,
        "accuracy": 0.073852,
        "main_score": 0.059516,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.04545,
        "recall": 0.062542,
        "f1": 0.048772,
        "accuracy": 0.062542,
        "main_score": 0.048772,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.029659,
        "recall": 0.050566,
        "f1": 0.032765,
        "accuracy": 0.050566,
        "main_score": 0.032765,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.023231,
        "recall": 0.041916,
        "f1": 0.026624,
        "accuracy": 0.041916,
        "main_score": 0.026624,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.019296,
        "recall": 0.036593,
        "f1": 0.022555,
        "accuracy": 0.036593,
        "main_score": 0.022555,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.012816,
        "recall": 0.024617,
        "f1": 0.014691,
        "accuracy": 0.024617,
        "main_score": 0.014691,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001413,
        "recall": 0.003327,
        "f1": 0.001483,
        "accuracy": 0.003327,
        "main_score": 0.001483,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023779,
        "recall": 0.043247,
        "f1": 0.027156,
        "accuracy": 0.043247,
        "main_score": 0.027156,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.019303,
        "recall": 0.037924,
        "f1": 0.022554,
        "accuracy": 0.037924,
        "main_score": 0.022554,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.021118,
        "recall": 0.037924,
        "f1": 0.02425,
        "accuracy": 0.037924,
        "main_score": 0.02425,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.024585,
        "recall": 0.041251,
        "f1": 0.028007,
        "accuracy": 0.041251,
        "main_score": 0.028007,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004044,
        "recall": 0.009315,
        "f1": 0.004698,
        "accuracy": 0.009315,
        "main_score": 0.004698,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.015244,
        "recall": 0.030605,
        "f1": 0.017758,
        "accuracy": 0.030605,
        "main_score": 0.017758,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.013589,
        "recall": 0.026613,
        "f1": 0.01544,
        "accuracy": 0.026613,
        "main_score": 0.01544,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.018226,
        "recall": 0.031936,
        "f1": 0.020012,
        "accuracy": 0.031936,
        "main_score": 0.020012,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.025561,
        "recall": 0.042582,
        "f1": 0.029247,
        "accuracy": 0.042582,
        "main_score": 0.029247,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.026713,
        "recall": 0.046574,
        "f1": 0.029635,
        "accuracy": 0.046574,
        "main_score": 0.029635,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.022323,
        "recall": 0.038589,
        "f1": 0.024876,
        "accuracy": 0.038589,
        "main_score": 0.024876,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.01392,
        "recall": 0.028609,
        "f1": 0.016075,
        "accuracy": 0.028609,
        "main_score": 0.016075,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.012827,
        "recall": 0.021956,
        "f1": 0.01401,
        "accuracy": 0.021956,
        "main_score": 0.01401,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.011928,
        "recall": 0.022621,
        "f1": 0.013615,
        "accuracy": 0.022621,
        "main_score": 0.013615,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.011903,
        "recall": 0.023952,
        "f1": 0.013455,
        "accuracy": 0.023952,
        "main_score": 0.013455,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.017749,
        "recall": 0.031271,
        "f1": 0.020056,
        "accuracy": 0.031271,
        "main_score": 0.020056,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006379,
        "recall": 0.011311,
        "f1": 0.006967,
        "accuracy": 0.011311,
        "main_score": 0.006967,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.027756,
        "recall": 0.046574,
        "f1": 0.031686,
        "accuracy": 0.046574,
        "main_score": 0.031686,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.025286,
        "recall": 0.043247,
        "f1": 0.02886,
        "accuracy": 0.043247,
        "main_score": 0.02886,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.01665,
        "recall": 0.029275,
        "f1": 0.019092,
        "accuracy": 0.029275,
        "main_score": 0.019092,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.025653,
        "recall": 0.044578,
        "f1": 0.029558,
        "accuracy": 0.044578,
        "main_score": 0.029558,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001682,
        "recall": 0.004657,
        "f1": 0.001812,
        "accuracy": 0.004657,
        "main_score": 0.001812,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024932,
        "recall": 0.041916,
        "f1": 0.027806,
        "accuracy": 0.041916,
        "main_score": 0.027806,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.022264,
        "recall": 0.041251,
        "f1": 0.026236,
        "accuracy": 0.041251,
        "main_score": 0.026236,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.026719,
        "recall": 0.045243,
        "f1": 0.030233,
        "accuracy": 0.045243,
        "main_score": 0.030233,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015246,
        "recall": 0.027279,
        "f1": 0.017268,
        "accuracy": 0.027279,
        "main_score": 0.017268,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.00928,
        "recall": 0.016633,
        "f1": 0.010655,
        "accuracy": 0.016633,
        "main_score": 0.010655,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.023216,
        "recall": 0.03992,
        "f1": 0.02694,
        "accuracy": 0.03992,
        "main_score": 0.02694,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.007968,
        "recall": 0.019295,
        "f1": 0.009783,
        "accuracy": 0.019295,
        "main_score": 0.009783,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.021253,
        "recall": 0.035263,
        "f1": 0.023371,
        "accuracy": 0.035263,
        "main_score": 0.023371,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.027252,
        "recall": 0.043912,
        "f1": 0.031187,
        "accuracy": 0.043912,
        "main_score": 0.031187,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.02458,
        "recall": 0.046574,
        "f1": 0.029035,
        "accuracy": 0.046574,
        "main_score": 0.029035,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.03022,
        "recall": 0.047239,
        "f1": 0.033945,
        "accuracy": 0.047239,
        "main_score": 0.033945,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.034758,
        "recall": 0.056554,
        "f1": 0.039748,
        "accuracy": 0.056554,
        "main_score": 0.039748,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.014134,
        "recall": 0.027279,
        "f1": 0.016414,
        "accuracy": 0.027279,
        "main_score": 0.016414,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.014101,
        "recall": 0.027279,
        "f1": 0.016857,
        "accuracy": 0.027279,
        "main_score": 0.016857,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.009386,
        "recall": 0.020625,
        "f1": 0.011213,
        "accuracy": 0.020625,
        "main_score": 0.011213,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.013831,
        "recall": 0.025283,
        "f1": 0.015638,
        "accuracy": 0.025283,
        "main_score": 0.015638,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.005654,
        "recall": 0.013972,
        "f1": 0.006988,
        "accuracy": 0.013972,
        "main_score": 0.006988,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.026091,
        "recall": 0.043912,
        "f1": 0.030005,
        "accuracy": 0.043912,
        "main_score": 0.030005,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.024237,
        "recall": 0.041916,
        "f1": 0.028279,
        "accuracy": 0.041916,
        "main_score": 0.028279,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.059779,
        "recall": 0.077179,
        "f1": 0.063493,
        "accuracy": 0.077179,
        "main_score": 0.063493,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.060544,
        "recall": 0.087159,
        "f1": 0.065706,
        "accuracy": 0.087159,
        "main_score": 0.065706,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.020078,
        "recall": 0.027279,
        "f1": 0.021115,
        "accuracy": 0.027279,
        "main_score": 0.021115,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.05648,
        "recall": 0.073852,
        "f1": 0.059922,
        "accuracy": 0.073852,
        "main_score": 0.059922,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.043474,
        "recall": 0.063872,
        "f1": 0.047994,
        "accuracy": 0.063872,
        "main_score": 0.047994,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.081354,
        "recall": 0.105123,
        "f1": 0.086579,
        "accuracy": 0.105123,
        "main_score": 0.086579,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016598,
        "recall": 0.02994,
        "f1": 0.018922,
        "accuracy": 0.02994,
        "main_score": 0.018922,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.033339,
        "recall": 0.045243,
        "f1": 0.036125,
        "accuracy": 0.045243,
        "main_score": 0.036125,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.020863,
        "recall": 0.043912,
        "f1": 0.025489,
        "accuracy": 0.043912,
        "main_score": 0.025489,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.038127,
        "recall": 0.053227,
        "f1": 0.040818,
        "accuracy": 0.053227,
        "main_score": 0.040818,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.020484,
        "recall": 0.031936,
        "f1": 0.022914,
        "accuracy": 0.031936,
        "main_score": 0.022914,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.02285,
        "recall": 0.040585,
        "f1": 0.027293,
        "accuracy": 0.040585,
        "main_score": 0.027293,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.023192,
        "recall": 0.039255,
        "f1": 0.026816,
        "accuracy": 0.039255,
        "main_score": 0.026816,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.024012,
        "recall": 0.041251,
        "f1": 0.027185,
        "accuracy": 0.041251,
        "main_score": 0.027185,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.071571,
        "recall": 0.097139,
        "f1": 0.077326,
        "accuracy": 0.097139,
        "main_score": 0.077326,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.012319,
        "recall": 0.025283,
        "f1": 0.014711,
        "accuracy": 0.025283,
        "main_score": 0.014711,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.020661,
        "recall": 0.033932,
        "f1": 0.022931,
        "accuracy": 0.033932,
        "main_score": 0.022931,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.03973,
        "recall": 0.051231,
        "f1": 0.041648,
        "accuracy": 0.051231,
        "main_score": 0.041648,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.048687,
        "recall": 0.061211,
        "f1": 0.051455,
        "accuracy": 0.061211,
        "main_score": 0.051455,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.049099,
        "recall": 0.062542,
        "f1": 0.051575,
        "accuracy": 0.062542,
        "main_score": 0.051575,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.014242,
        "recall": 0.025283,
        "f1": 0.015847,
        "accuracy": 0.025283,
        "main_score": 0.015847,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.012754,
        "recall": 0.023287,
        "f1": 0.014618,
        "accuracy": 0.023287,
        "main_score": 0.014618,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.044725,
        "recall": 0.064538,
        "f1": 0.048108,
        "accuracy": 0.064538,
        "main_score": 0.048108,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.042897,
        "recall": 0.055223,
        "f1": 0.045234,
        "accuracy": 0.055223,
        "main_score": 0.045234,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.017222,
        "recall": 0.023287,
        "f1": 0.01807,
        "accuracy": 0.023287,
        "main_score": 0.01807,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.053053,
        "recall": 0.071191,
        "f1": 0.056405,
        "accuracy": 0.071191,
        "main_score": 0.056405,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.021364,
        "recall": 0.036593,
        "f1": 0.024553,
        "accuracy": 0.036593,
        "main_score": 0.024553,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.045125,
        "recall": 0.055888,
        "f1": 0.047472,
        "accuracy": 0.055888,
        "main_score": 0.047472,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.017004,
        "recall": 0.033932,
        "f1": 0.020253,
        "accuracy": 0.033932,
        "main_score": 0.020253,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.028767,
        "recall": 0.036593,
        "f1": 0.030534,
        "accuracy": 0.036593,
        "main_score": 0.030534,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.00955,
        "recall": 0.018629,
        "f1": 0.011421,
        "accuracy": 0.018629,
        "main_score": 0.011421,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.040318,
        "recall": 0.054558,
        "f1": 0.04323,
        "accuracy": 0.054558,
        "main_score": 0.04323,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.013876,
        "recall": 0.025948,
        "f1": 0.016334,
        "accuracy": 0.025948,
        "main_score": 0.016334,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.013794,
        "recall": 0.025283,
        "f1": 0.015649,
        "accuracy": 0.025283,
        "main_score": 0.015649,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.015903,
        "recall": 0.02994,
        "f1": 0.018186,
        "accuracy": 0.02994,
        "main_score": 0.018186,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.011366,
        "recall": 0.021291,
        "f1": 0.013213,
        "accuracy": 0.021291,
        "main_score": 0.013213,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.045671,
        "recall": 0.057219,
        "f1": 0.04814,
        "accuracy": 0.057219,
        "main_score": 0.04814,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.012964,
        "recall": 0.026613,
        "f1": 0.01495,
        "accuracy": 0.026613,
        "main_score": 0.01495,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.010762,
        "recall": 0.019295,
        "f1": 0.012078,
        "accuracy": 0.019295,
        "main_score": 0.012078,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.040976,
        "recall": 0.04857,
        "f1": 0.042405,
        "accuracy": 0.04857,
        "main_score": 0.042405,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.05848,
        "recall": 0.073187,
        "f1": 0.062006,
        "accuracy": 0.073187,
        "main_score": 0.062006,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.036399,
        "recall": 0.043247,
        "f1": 0.037689,
        "accuracy": 0.043247,
        "main_score": 0.037689,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.019424,
        "recall": 0.036593,
        "f1": 0.022497,
        "accuracy": 0.036593,
        "main_score": 0.022497,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.023142,
        "recall": 0.041916,
        "f1": 0.026382,
        "accuracy": 0.041916,
        "main_score": 0.026382,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.051988,
        "recall": 0.073187,
        "f1": 0.055804,
        "accuracy": 0.073187,
        "main_score": 0.055804,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.049998,
        "recall": 0.065203,
        "f1": 0.052621,
        "accuracy": 0.065203,
        "main_score": 0.052621,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.0175,
        "recall": 0.023287,
        "f1": 0.018258,
        "accuracy": 0.023287,
        "main_score": 0.018258,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.069158,
        "recall": 0.091816,
        "f1": 0.073874,
        "accuracy": 0.091816,
        "main_score": 0.073874,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.035173,
        "recall": 0.054558,
        "f1": 0.039799,
        "accuracy": 0.054558,
        "main_score": 0.039799,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.055648,
        "recall": 0.070526,
        "f1": 0.058466,
        "accuracy": 0.070526,
        "main_score": 0.058466,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.031528,
        "recall": 0.05855,
        "f1": 0.0371,
        "accuracy": 0.05855,
        "main_score": 0.0371,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.030702,
        "recall": 0.039255,
        "f1": 0.032278,
        "accuracy": 0.039255,
        "main_score": 0.032278,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.01246,
        "recall": 0.027944,
        "f1": 0.015597,
        "accuracy": 0.027944,
        "main_score": 0.015597,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.050607,
        "recall": 0.071191,
        "f1": 0.05473,
        "accuracy": 0.071191,
        "main_score": 0.05473,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.018605,
        "recall": 0.037259,
        "f1": 0.021885,
        "accuracy": 0.037259,
        "main_score": 0.021885,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.017772,
        "recall": 0.033267,
        "f1": 0.020365,
        "accuracy": 0.033267,
        "main_score": 0.020365,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.024698,
        "recall": 0.040585,
        "f1": 0.02776,
        "accuracy": 0.040585,
        "main_score": 0.02776,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.01949,
        "recall": 0.035263,
        "f1": 0.021877,
        "accuracy": 0.035263,
        "main_score": 0.021877,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.051934,
        "recall": 0.067199,
        "f1": 0.054966,
        "accuracy": 0.067199,
        "main_score": 0.054966,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019801,
        "recall": 0.03992,
        "f1": 0.023129,
        "accuracy": 0.03992,
        "main_score": 0.023129,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.015881,
        "recall": 0.027944,
        "f1": 0.017984,
        "accuracy": 0.027944,
        "main_score": 0.017984,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.04697,
        "recall": 0.063207,
        "f1": 0.049973,
        "accuracy": 0.063207,
        "main_score": 0.049973,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.060318,
        "recall": 0.07984,
        "f1": 0.064473,
        "accuracy": 0.07984,
        "main_score": 0.064473,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.039776,
        "recall": 0.049235,
        "f1": 0.041237,
        "accuracy": 0.049235,
        "main_score": 0.041237,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.007309,
        "recall": 0.011976,
        "f1": 0.008228,
        "accuracy": 0.011976,
        "main_score": 0.008228,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.009093,
        "recall": 0.015303,
        "f1": 0.010063,
        "accuracy": 0.015303,
        "main_score": 0.010063,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.035995,
        "recall": 0.046574,
        "f1": 0.038088,
        "accuracy": 0.046574,
        "main_score": 0.038088,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.044992,
        "recall": 0.060546,
        "f1": 0.047922,
        "accuracy": 0.060546,
        "main_score": 0.047922,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.020571,
        "recall": 0.026613,
        "f1": 0.021872,
        "accuracy": 0.026613,
        "main_score": 0.021872,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.041804,
        "recall": 0.050566,
        "f1": 0.043081,
        "accuracy": 0.050566,
        "main_score": 0.043081,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.021924,
        "recall": 0.035928,
        "f1": 0.024808,
        "accuracy": 0.035928,
        "main_score": 0.024808,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.047569,
        "recall": 0.065868,
        "f1": 0.050685,
        "accuracy": 0.065868,
        "main_score": 0.050685,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.006149,
        "recall": 0.010645,
        "f1": 0.006864,
        "accuracy": 0.010645,
        "main_score": 0.006864,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.046417,
        "recall": 0.064538,
        "f1": 0.050618,
        "accuracy": 0.064538,
        "main_score": 0.050618,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.007418,
        "recall": 0.017299,
        "f1": 0.009186,
        "accuracy": 0.017299,
        "main_score": 0.009186,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.033064,
        "recall": 0.043247,
        "f1": 0.034804,
        "accuracy": 0.043247,
        "main_score": 0.034804,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.005923,
        "recall": 0.013972,
        "f1": 0.007143,
        "accuracy": 0.013972,
        "main_score": 0.007143,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.008592,
        "recall": 0.014637,
        "f1": 0.009571,
        "accuracy": 0.014637,
        "main_score": 0.009571,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.009355,
        "recall": 0.016633,
        "f1": 0.01047,
        "accuracy": 0.016633,
        "main_score": 0.01047,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.00469,
        "recall": 0.009315,
        "f1": 0.005353,
        "accuracy": 0.009315,
        "main_score": 0.005353,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.046887,
        "recall": 0.057884,
        "f1": 0.049349,
        "accuracy": 0.057884,
        "main_score": 0.049349,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.00395,
        "recall": 0.008649,
        "f1": 0.004589,
        "accuracy": 0.008649,
        "main_score": 0.004589,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006669,
        "recall": 0.013307,
        "f1": 0.007435,
        "accuracy": 0.013307,
        "main_score": 0.007435,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.043503,
        "recall": 0.059215,
        "f1": 0.046106,
        "accuracy": 0.059215,
        "main_score": 0.046106,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.033298,
        "recall": 0.03992,
        "f1": 0.034461,
        "accuracy": 0.03992,
        "main_score": 0.034461,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.037305,
        "recall": 0.045243,
        "f1": 0.038777,
        "accuracy": 0.045243,
        "main_score": 0.038777,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 48.214428663253784,
  "kg_co2_emissions": 0.0023180192332428033
}