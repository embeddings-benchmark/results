{
  "dataset_revision": "3d96e36e10a88d5b7a3f617cf8362d997504494b",
  "task_name": "KorSarcasmClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.52168,
        "f1": 0.518068,
        "f1_weighted": 0.518095,
        "ap": 0.511315,
        "ap_weighted": 0.511315,
        "scores_per_experiment": [
          {
            "accuracy": 0.573242,
            "f1": 0.564387,
            "f1_weighted": 0.564508,
            "ap": 0.542948,
            "ap_weighted": 0.542948
          },
          {
            "accuracy": 0.537109,
            "f1": 0.531999,
            "f1_weighted": 0.532095,
            "ap": 0.519198,
            "ap_weighted": 0.519198
          },
          {
            "accuracy": 0.534668,
            "f1": 0.530051,
            "f1_weighted": 0.530142,
            "ap": 0.517743,
            "ap_weighted": 0.517743
          },
          {
            "accuracy": 0.51416,
            "f1": 0.511644,
            "f1_weighted": 0.511576,
            "ap": 0.506353,
            "ap_weighted": 0.506353
          },
          {
            "accuracy": 0.490234,
            "f1": 0.481487,
            "f1_weighted": 0.481619,
            "ap": 0.49415,
            "ap_weighted": 0.49415
          },
          {
            "accuracy": 0.540039,
            "f1": 0.539912,
            "f1_weighted": 0.539897,
            "ap": 0.520615,
            "ap_weighted": 0.520615
          },
          {
            "accuracy": 0.538574,
            "f1": 0.53808,
            "f1_weighted": 0.53805,
            "ap": 0.519745,
            "ap_weighted": 0.519745
          },
          {
            "accuracy": 0.520508,
            "f1": 0.520198,
            "f1_weighted": 0.520175,
            "ap": 0.509705,
            "ap_weighted": 0.509705
          },
          {
            "accuracy": 0.48291,
            "f1": 0.47928,
            "f1_weighted": 0.479195,
            "ap": 0.490807,
            "ap_weighted": 0.490807
          },
          {
            "accuracy": 0.485352,
            "f1": 0.483637,
            "f1_weighted": 0.483695,
            "ap": 0.49189,
            "ap_weighted": 0.49189
          }
        ],
        "main_score": 0.52168,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ]
      }
    ]
  },
  "evaluation_time": 9.277616500854492,
  "kg_co2_emissions": 0.0003377454653929089
}