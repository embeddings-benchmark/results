{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.120438,
        "mrr": 0.102416,
        "nAUC_map_max": -0.144623,
        "nAUC_map_std": 0.021027,
        "nAUC_map_diff1": 0.005553,
        "nAUC_mrr_max": -0.140606,
        "nAUC_mrr_std": 0.021002,
        "nAUC_mrr_diff1": 0.018651,
        "main_score": 0.102416,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.105596,
        "mrr": 0.088014,
        "nAUC_map_max": -0.038784,
        "nAUC_map_std": 0.029476,
        "nAUC_map_diff1": 0.08478,
        "nAUC_mrr_max": -0.038069,
        "nAUC_mrr_std": 0.015083,
        "nAUC_mrr_diff1": 0.097756,
        "main_score": 0.088014,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.073652,
        "mrr": 0.054578,
        "nAUC_map_max": -0.201988,
        "nAUC_map_std": 0.274587,
        "nAUC_map_diff1": 0.033217,
        "nAUC_mrr_max": -0.194339,
        "nAUC_mrr_std": 0.235847,
        "nAUC_mrr_diff1": 0.021493,
        "main_score": 0.054578,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.125121,
        "mrr": 0.10656,
        "nAUC_map_max": -0.080561,
        "nAUC_map_std": -0.004595,
        "nAUC_map_diff1": 0.124394,
        "nAUC_mrr_max": -0.072454,
        "nAUC_mrr_std": -0.007431,
        "nAUC_mrr_diff1": 0.120292,
        "main_score": 0.10656,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.107904,
        "mrr": 0.089645,
        "nAUC_map_max": -0.063459,
        "nAUC_map_std": 0.075029,
        "nAUC_map_diff1": 0.132659,
        "nAUC_mrr_max": -0.057847,
        "nAUC_mrr_std": 0.054314,
        "nAUC_mrr_diff1": 0.128792,
        "main_score": 0.089645,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.081681,
        "mrr": 0.063169,
        "nAUC_map_max": -0.022209,
        "nAUC_map_std": 0.013057,
        "nAUC_map_diff1": 0.151598,
        "nAUC_mrr_max": -0.034077,
        "nAUC_mrr_std": 0.004307,
        "nAUC_mrr_diff1": 0.143185,
        "main_score": 0.063169,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 24490.47180891037,
  "kg_co2_emissions": 2.3132985266338135
}