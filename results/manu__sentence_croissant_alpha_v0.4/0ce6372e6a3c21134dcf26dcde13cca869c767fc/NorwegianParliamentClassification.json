{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.53825,
        "f1": 0.535451,
        "f1_weighted": 0.535451,
        "ap": 0.521823,
        "ap_weighted": 0.521823,
        "scores_per_experiment": [
          {
            "accuracy": 0.530833,
            "f1": 0.521567,
            "f1_weighted": 0.521567,
            "ap": 0.516734,
            "ap_weighted": 0.516734
          },
          {
            "accuracy": 0.516667,
            "f1": 0.515016,
            "f1_weighted": 0.515016,
            "ap": 0.508582,
            "ap_weighted": 0.508582
          },
          {
            "accuracy": 0.585,
            "f1": 0.576904,
            "f1_weighted": 0.576904,
            "ap": 0.552488,
            "ap_weighted": 0.552488
          },
          {
            "accuracy": 0.545,
            "f1": 0.544786,
            "f1_weighted": 0.544786,
            "ap": 0.524617,
            "ap_weighted": 0.524617
          },
          {
            "accuracy": 0.555,
            "f1": 0.554995,
            "f1_weighted": 0.554995,
            "ap": 0.530505,
            "ap_weighted": 0.530505
          },
          {
            "accuracy": 0.483333,
            "f1": 0.483282,
            "f1_weighted": 0.483282,
            "ap": 0.491939,
            "ap_weighted": 0.491939
          },
          {
            "accuracy": 0.5175,
            "f1": 0.517459,
            "f1_weighted": 0.517459,
            "ap": 0.509051,
            "ap_weighted": 0.509051
          },
          {
            "accuracy": 0.5225,
            "f1": 0.520314,
            "f1_weighted": 0.520314,
            "ap": 0.511696,
            "ap_weighted": 0.511696
          },
          {
            "accuracy": 0.576667,
            "f1": 0.573338,
            "f1_weighted": 0.573338,
            "ap": 0.545472,
            "ap_weighted": 0.545472
          },
          {
            "accuracy": 0.55,
            "f1": 0.546853,
            "f1_weighted": 0.546853,
            "ap": 0.527143,
            "ap_weighted": 0.527143
          }
        ],
        "main_score": 0.53825,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.542083,
        "f1": 0.539354,
        "f1_weighted": 0.539354,
        "ap": 0.524595,
        "ap_weighted": 0.524595,
        "scores_per_experiment": [
          {
            "accuracy": 0.513333,
            "f1": 0.505184,
            "f1_weighted": 0.505184,
            "ap": 0.506906,
            "ap_weighted": 0.506906
          },
          {
            "accuracy": 0.510833,
            "f1": 0.509016,
            "f1_weighted": 0.509016,
            "ap": 0.505521,
            "ap_weighted": 0.505521
          },
          {
            "accuracy": 0.608333,
            "f1": 0.599723,
            "f1_weighted": 0.599723,
            "ap": 0.570774,
            "ap_weighted": 0.570774
          },
          {
            "accuracy": 0.571667,
            "f1": 0.571523,
            "f1_weighted": 0.571523,
            "ap": 0.541165,
            "ap_weighted": 0.541165
          },
          {
            "accuracy": 0.556667,
            "f1": 0.556588,
            "f1_weighted": 0.556588,
            "ap": 0.531632,
            "ap_weighted": 0.531632
          },
          {
            "accuracy": 0.481667,
            "f1": 0.481644,
            "f1_weighted": 0.481644,
            "ap": 0.491165,
            "ap_weighted": 0.491165
          },
          {
            "accuracy": 0.531667,
            "f1": 0.531146,
            "f1_weighted": 0.531146,
            "ap": 0.516773,
            "ap_weighted": 0.516773
          },
          {
            "accuracy": 0.531667,
            "f1": 0.528392,
            "f1_weighted": 0.528392,
            "ap": 0.516693,
            "ap_weighted": 0.516693
          },
          {
            "accuracy": 0.575,
            "f1": 0.573288,
            "f1_weighted": 0.573288,
            "ap": 0.543941,
            "ap_weighted": 0.543941
          },
          {
            "accuracy": 0.54,
            "f1": 0.537037,
            "f1_weighted": 0.537037,
            "ap": 0.521379,
            "ap_weighted": 0.521379
          }
        ],
        "main_score": 0.542083,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 127.54426646232605,
  "kg_co2_emissions": 0.010724820556243526
}