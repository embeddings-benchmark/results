{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.865723,
        "f1": 0.865253,
        "f1_weighted": 0.865268,
        "ap": 0.813199,
        "ap_weighted": 0.813199,
        "scores_per_experiment": [
          {
            "accuracy": 0.865234,
            "f1": 0.864872,
            "f1_weighted": 0.864893,
            "ap": 0.804761,
            "ap_weighted": 0.804761
          },
          {
            "accuracy": 0.839355,
            "f1": 0.839009,
            "f1_weighted": 0.839031,
            "ap": 0.776355,
            "ap_weighted": 0.776355
          },
          {
            "accuracy": 0.912109,
            "f1": 0.912085,
            "f1_weighted": 0.912081,
            "ap": 0.883277,
            "ap_weighted": 0.883277
          },
          {
            "accuracy": 0.839844,
            "f1": 0.839574,
            "f1_weighted": 0.839593,
            "ap": 0.777971,
            "ap_weighted": 0.777971
          },
          {
            "accuracy": 0.874512,
            "f1": 0.8744,
            "f1_weighted": 0.874389,
            "ap": 0.838012,
            "ap_weighted": 0.838012
          },
          {
            "accuracy": 0.883301,
            "f1": 0.883217,
            "f1_weighted": 0.883207,
            "ap": 0.84851,
            "ap_weighted": 0.84851
          },
          {
            "accuracy": 0.858398,
            "f1": 0.85786,
            "f1_weighted": 0.857886,
            "ap": 0.794804,
            "ap_weighted": 0.794804
          },
          {
            "accuracy": 0.897461,
            "f1": 0.897442,
            "f1_weighted": 0.897438,
            "ap": 0.862685,
            "ap_weighted": 0.862685
          },
          {
            "accuracy": 0.85498,
            "f1": 0.854188,
            "f1_weighted": 0.854219,
            "ap": 0.788495,
            "ap_weighted": 0.788495
          },
          {
            "accuracy": 0.832031,
            "f1": 0.829886,
            "f1_weighted": 0.829942,
            "ap": 0.757119,
            "ap_weighted": 0.757119
          }
        ],
        "main_score": 0.865723,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.855322,
        "f1": 0.854931,
        "f1_weighted": 0.854938,
        "ap": 0.802606,
        "ap_weighted": 0.802606,
        "scores_per_experiment": [
          {
            "accuracy": 0.857422,
            "f1": 0.857108,
            "f1_weighted": 0.857121,
            "ap": 0.796365,
            "ap_weighted": 0.796365
          },
          {
            "accuracy": 0.815918,
            "f1": 0.81563,
            "f1_weighted": 0.815644,
            "ap": 0.751329,
            "ap_weighted": 0.751329
          },
          {
            "accuracy": 0.896484,
            "f1": 0.896445,
            "f1_weighted": 0.896441,
            "ap": 0.862876,
            "ap_weighted": 0.862876
          },
          {
            "accuracy": 0.823242,
            "f1": 0.823069,
            "f1_weighted": 0.82308,
            "ap": 0.76086,
            "ap_weighted": 0.76086
          },
          {
            "accuracy": 0.867188,
            "f1": 0.866907,
            "f1_weighted": 0.866895,
            "ap": 0.833174,
            "ap_weighted": 0.833174
          },
          {
            "accuracy": 0.873047,
            "f1": 0.872853,
            "f1_weighted": 0.872843,
            "ap": 0.838586,
            "ap_weighted": 0.838586
          },
          {
            "accuracy": 0.85498,
            "f1": 0.854489,
            "f1_weighted": 0.854506,
            "ap": 0.791209,
            "ap_weighted": 0.791209
          },
          {
            "accuracy": 0.888184,
            "f1": 0.888125,
            "f1_weighted": 0.88812,
            "ap": 0.853081,
            "ap_weighted": 0.853081
          },
          {
            "accuracy": 0.837891,
            "f1": 0.837369,
            "f1_weighted": 0.837387,
            "ap": 0.772334,
            "ap_weighted": 0.772334
          },
          {
            "accuracy": 0.838867,
            "f1": 0.837316,
            "f1_weighted": 0.837347,
            "ap": 0.766246,
            "ap_weighted": 0.766246
          }
        ],
        "main_score": 0.855322,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 17.621687412261963,
  "kg_co2_emissions": 0.000628527579855085
}