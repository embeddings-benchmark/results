{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.92632,
        "recall": 0.944835,
        "f1": 0.931695,
        "accuracy": 0.944835,
        "main_score": 0.931695,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.918589,
        "recall": 0.944835,
        "f1": 0.927115,
        "accuracy": 0.944835,
        "main_score": 0.927115,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.987964,
        "recall": 0.991976,
        "f1": 0.989301,
        "accuracy": 0.991976,
        "main_score": 0.989301,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.987964,
        "recall": 0.991976,
        "f1": 0.989301,
        "accuracy": 0.991976,
        "main_score": 0.989301,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.993982,
        "recall": 0.995988,
        "f1": 0.994651,
        "accuracy": 0.995988,
        "main_score": 0.994651,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.998495,
        "recall": 0.998997,
        "f1": 0.998663,
        "accuracy": 0.998997,
        "main_score": 0.998663,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.914577,
        "recall": 0.940822,
        "f1": 0.922935,
        "accuracy": 0.940822,
        "main_score": 0.922935,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.937813,
        "recall": 0.957874,
        "f1": 0.944333,
        "accuracy": 0.957874,
        "main_score": 0.944333,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.95127,
        "recall": 0.965898,
        "f1": 0.955934,
        "accuracy": 0.965898,
        "main_score": 0.955934,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.956035,
        "recall": 0.96991,
        "f1": 0.960548,
        "accuracy": 0.96991,
        "main_score": 0.960548,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.998495,
        "recall": 0.998997,
        "f1": 0.998663,
        "accuracy": 0.998997,
        "main_score": 0.998663,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.986794,
        "recall": 0.990973,
        "f1": 0.988131,
        "accuracy": 0.990973,
        "main_score": 0.988131,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.958375,
        "recall": 0.970913,
        "f1": 0.962387,
        "accuracy": 0.970913,
        "main_score": 0.962387,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.959378,
        "recall": 0.972919,
        "f1": 0.963892,
        "accuracy": 0.972919,
        "main_score": 0.963892,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.884898,
        "recall": 0.912738,
        "f1": 0.892648,
        "accuracy": 0.912738,
        "main_score": 0.892648,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.894266,
        "recall": 0.92678,
        "f1": 0.904614,
        "accuracy": 0.92678,
        "main_score": 0.904614,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.983785,
        "recall": 0.988967,
        "f1": 0.985456,
        "accuracy": 0.988967,
        "main_score": 0.985456,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.98228,
        "recall": 0.987964,
        "f1": 0.984119,
        "accuracy": 0.987964,
        "main_score": 0.984119,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.507378,
        "recall": 0.583751,
        "f1": 0.526618,
        "accuracy": 0.583751,
        "main_score": 0.526618,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.583189,
        "recall": 0.667001,
        "f1": 0.60649,
        "accuracy": 0.667001,
        "main_score": 0.60649,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.908893,
        "recall": 0.93681,
        "f1": 0.91772,
        "accuracy": 0.93681,
        "main_score": 0.91772,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.913825,
        "recall": 0.940822,
        "f1": 0.922501,
        "accuracy": 0.940822,
        "main_score": 0.922501,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.982447,
        "recall": 0.987964,
        "f1": 0.984286,
        "accuracy": 0.987964,
        "main_score": 0.984286,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.983952,
        "recall": 0.988967,
        "f1": 0.985624,
        "accuracy": 0.988967,
        "main_score": 0.985624,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.717561,
        "recall": 0.758275,
        "f1": 0.727846,
        "accuracy": 0.758275,
        "main_score": 0.727846,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.788114,
        "recall": 0.849549,
        "f1": 0.807422,
        "accuracy": 0.849549,
        "main_score": 0.807422,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.87429,
        "recall": 0.907723,
        "f1": 0.884057,
        "accuracy": 0.907723,
        "main_score": 0.884057,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.908977,
        "recall": 0.93681,
        "f1": 0.917653,
        "accuracy": 0.93681,
        "main_score": 0.917653,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.812994,
        "recall": 0.857573,
        "f1": 0.825805,
        "accuracy": 0.857573,
        "main_score": 0.825805,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.836844,
        "recall": 0.885657,
        "f1": 0.852391,
        "accuracy": 0.885657,
        "main_score": 0.852391,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.835272,
        "recall": 0.880642,
        "f1": 0.849047,
        "accuracy": 0.880642,
        "main_score": 0.849047,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.817686,
        "recall": 0.8666,
        "f1": 0.832416,
        "accuracy": 0.8666,
        "main_score": 0.832416,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.975426,
        "recall": 0.982949,
        "f1": 0.977934,
        "accuracy": 0.982949,
        "main_score": 0.977934,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.980776,
        "recall": 0.985958,
        "f1": 0.982447,
        "accuracy": 0.985958,
        "main_score": 0.982447,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.968322,
        "recall": 0.977934,
        "f1": 0.971314,
        "accuracy": 0.977934,
        "main_score": 0.971314,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.977349,
        "recall": 0.983952,
        "f1": 0.979338,
        "accuracy": 0.983952,
        "main_score": 0.979338,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.089233,
        "recall": 0.108325,
        "f1": 0.09396,
        "accuracy": 0.108325,
        "main_score": 0.09396,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.094883,
        "recall": 0.149448,
        "f1": 0.107057,
        "accuracy": 0.149448,
        "main_score": 0.107057,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.120354,
        "recall": 0.155466,
        "f1": 0.126846,
        "accuracy": 0.155466,
        "main_score": 0.126846,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.14183,
        "recall": 0.209629,
        "f1": 0.158129,
        "accuracy": 0.209629,
        "main_score": 0.158129,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.938148,
        "recall": 0.956871,
        "f1": 0.944118,
        "accuracy": 0.956871,
        "main_score": 0.944118,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.925025,
        "recall": 0.947844,
        "f1": 0.932364,
        "accuracy": 0.947844,
        "main_score": 0.932364,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.688695,
        "recall": 0.746239,
        "f1": 0.703682,
        "accuracy": 0.746239,
        "main_score": 0.703682,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.698577,
        "recall": 0.777332,
        "f1": 0.722083,
        "accuracy": 0.777332,
        "main_score": 0.722083,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.906737,
        "recall": 0.932798,
        "f1": 0.914477,
        "accuracy": 0.932798,
        "main_score": 0.914477,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.937145,
        "recall": 0.956871,
        "f1": 0.943664,
        "accuracy": 0.956871,
        "main_score": 0.943664,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.91232,
        "recall": 0.937813,
        "f1": 0.920079,
        "accuracy": 0.937813,
        "main_score": 0.920079,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.917001,
        "recall": 0.942828,
        "f1": 0.925295,
        "accuracy": 0.942828,
        "main_score": 0.925295,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.948763,
        "recall": 0.964895,
        "f1": 0.953928,
        "accuracy": 0.964895,
        "main_score": 0.953928,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.952524,
        "recall": 0.967904,
        "f1": 0.957539,
        "accuracy": 0.967904,
        "main_score": 0.957539,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.085854,
        "recall": 0.105316,
        "f1": 0.089503,
        "accuracy": 0.105316,
        "main_score": 0.089503,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.08393,
        "recall": 0.128385,
        "f1": 0.093431,
        "accuracy": 0.128385,
        "main_score": 0.093431,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.954697,
        "recall": 0.968907,
        "f1": 0.959378,
        "accuracy": 0.968907,
        "main_score": 0.959378,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.949348,
        "recall": 0.965898,
        "f1": 0.954865,
        "accuracy": 0.965898,
        "main_score": 0.954865,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.938933,
        "recall": 0.956871,
        "f1": 0.9444,
        "accuracy": 0.956871,
        "main_score": 0.9444,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.947676,
        "recall": 0.964895,
        "f1": 0.95336,
        "accuracy": 0.964895,
        "main_score": 0.95336,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.006525,
        "recall": 0.009027,
        "f1": 0.006698,
        "accuracy": 0.009027,
        "main_score": 0.006698,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001685,
        "recall": 0.014042,
        "f1": 0.002859,
        "accuracy": 0.014042,
        "main_score": 0.002859,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.915876,
        "recall": 0.939723,
        "f1": 0.923043,
        "accuracy": 0.939723,
        "main_score": 0.923043,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.922596,
        "recall": 0.947628,
        "f1": 0.93083,
        "accuracy": 0.947628,
        "main_score": 0.93083,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.992589,
        "recall": 0.995059,
        "f1": 0.993412,
        "accuracy": 0.995059,
        "main_score": 0.993412,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.989625,
        "recall": 0.993083,
        "f1": 0.990777,
        "accuracy": 0.993083,
        "main_score": 0.990777,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.997036,
        "recall": 0.998024,
        "f1": 0.997365,
        "accuracy": 0.998024,
        "main_score": 0.997365,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.947134,
        "recall": 0.963439,
        "f1": 0.952404,
        "accuracy": 0.963439,
        "main_score": 0.952404,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.94697,
        "recall": 0.964427,
        "f1": 0.952734,
        "accuracy": 0.964427,
        "main_score": 0.952734,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.95779,
        "recall": 0.970356,
        "f1": 0.961693,
        "accuracy": 0.970356,
        "main_score": 0.961693,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.952404,
        "recall": 0.967391,
        "f1": 0.957181,
        "accuracy": 0.967391,
        "main_score": 0.957181,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.994071,
        "recall": 0.996047,
        "f1": 0.99473,
        "accuracy": 0.996047,
        "main_score": 0.99473,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.982213,
        "recall": 0.988142,
        "f1": 0.98419,
        "accuracy": 0.988142,
        "main_score": 0.98419,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.954628,
        "recall": 0.968379,
        "f1": 0.958893,
        "accuracy": 0.968379,
        "main_score": 0.958893,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.957675,
        "recall": 0.971344,
        "f1": 0.962121,
        "accuracy": 0.971344,
        "main_score": 0.962121,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.886677,
        "recall": 0.91502,
        "f1": 0.894661,
        "accuracy": 0.91502,
        "main_score": 0.894661,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.893116,
        "recall": 0.925889,
        "f1": 0.903458,
        "accuracy": 0.925889,
        "main_score": 0.903458,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.988142,
        "recall": 0.992095,
        "f1": 0.98946,
        "accuracy": 0.992095,
        "main_score": 0.98946,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.989954,
        "recall": 0.993083,
        "f1": 0.990942,
        "accuracy": 0.993083,
        "main_score": 0.990942,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.461926,
        "recall": 0.534585,
        "f1": 0.479545,
        "accuracy": 0.534585,
        "main_score": 0.479545,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.521405,
        "recall": 0.62253,
        "f1": 0.549744,
        "accuracy": 0.62253,
        "main_score": 0.549744,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.914888,
        "recall": 0.940711,
        "f1": 0.923057,
        "accuracy": 0.940711,
        "main_score": 0.923057,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.920455,
        "recall": 0.944664,
        "f1": 0.928162,
        "accuracy": 0.944664,
        "main_score": 0.928162,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.990119,
        "recall": 0.993083,
        "f1": 0.991107,
        "accuracy": 0.993083,
        "main_score": 0.991107,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.990119,
        "recall": 0.993083,
        "f1": 0.991107,
        "accuracy": 0.993083,
        "main_score": 0.991107,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.730752,
        "recall": 0.777668,
        "f1": 0.74306,
        "accuracy": 0.777668,
        "main_score": 0.74306,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.777866,
        "recall": 0.841897,
        "f1": 0.797826,
        "accuracy": 0.841897,
        "main_score": 0.797826,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.863086,
        "recall": 0.898221,
        "f1": 0.87304,
        "accuracy": 0.898221,
        "main_score": 0.87304,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.870718,
        "recall": 0.911067,
        "f1": 0.883531,
        "accuracy": 0.911067,
        "main_score": 0.883531,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.840942,
        "recall": 0.885375,
        "f1": 0.854348,
        "accuracy": 0.885375,
        "main_score": 0.854348,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.859931,
        "recall": 0.901186,
        "f1": 0.872892,
        "accuracy": 0.901186,
        "main_score": 0.872892,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.838801,
        "recall": 0.882411,
        "f1": 0.851633,
        "accuracy": 0.882411,
        "main_score": 0.851633,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.82337,
        "recall": 0.873518,
        "f1": 0.838801,
        "accuracy": 0.873518,
        "main_score": 0.838801,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.972003,
        "recall": 0.980237,
        "f1": 0.974638,
        "accuracy": 0.980237,
        "main_score": 0.974638,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.966074,
        "recall": 0.976285,
        "f1": 0.969368,
        "accuracy": 0.976285,
        "main_score": 0.969368,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.975132,
        "recall": 0.983202,
        "f1": 0.977767,
        "accuracy": 0.983202,
        "main_score": 0.977767,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.976614,
        "recall": 0.98419,
        "f1": 0.979084,
        "accuracy": 0.98419,
        "main_score": 0.979084,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.077883,
        "recall": 0.091897,
        "f1": 0.08141,
        "accuracy": 0.091897,
        "main_score": 0.08141,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.091418,
        "recall": 0.141304,
        "f1": 0.102502,
        "accuracy": 0.141304,
        "main_score": 0.102502,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.102816,
        "recall": 0.125494,
        "f1": 0.106942,
        "accuracy": 0.125494,
        "main_score": 0.106942,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.1271,
        "recall": 0.199605,
        "f1": 0.144117,
        "accuracy": 0.199605,
        "main_score": 0.144117,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.951005,
        "recall": 0.966403,
        "f1": 0.955929,
        "accuracy": 0.966403,
        "main_score": 0.955929,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.936594,
        "recall": 0.956522,
        "f1": 0.943017,
        "accuracy": 0.956522,
        "main_score": 0.943017,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.68075,
        "recall": 0.735178,
        "f1": 0.695588,
        "accuracy": 0.735178,
        "main_score": 0.695588,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.684686,
        "recall": 0.772727,
        "f1": 0.711825,
        "accuracy": 0.772727,
        "main_score": 0.711825,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.936594,
        "recall": 0.955534,
        "f1": 0.942641,
        "accuracy": 0.955534,
        "main_score": 0.942641,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.951087,
        "recall": 0.966403,
        "f1": 0.956028,
        "accuracy": 0.966403,
        "main_score": 0.956028,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.917582,
        "recall": 0.938735,
        "f1": 0.923487,
        "accuracy": 0.938735,
        "main_score": 0.923487,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.931489,
        "recall": 0.953557,
        "f1": 0.938735,
        "accuracy": 0.953557,
        "main_score": 0.938735,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.931489,
        "recall": 0.952569,
        "f1": 0.938194,
        "accuracy": 0.952569,
        "main_score": 0.938194,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.944499,
        "recall": 0.962451,
        "f1": 0.950428,
        "accuracy": 0.962451,
        "main_score": 0.950428,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.064632,
        "recall": 0.079051,
        "f1": 0.06779,
        "accuracy": 0.079051,
        "main_score": 0.06779,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.077295,
        "recall": 0.117589,
        "f1": 0.085518,
        "accuracy": 0.117589,
        "main_score": 0.085518,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.956933,
        "recall": 0.970356,
        "f1": 0.961199,
        "accuracy": 0.970356,
        "main_score": 0.961199,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.957675,
        "recall": 0.971344,
        "f1": 0.962121,
        "accuracy": 0.971344,
        "main_score": 0.962121,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.954216,
        "recall": 0.968379,
        "f1": 0.958663,
        "accuracy": 0.968379,
        "main_score": 0.958663,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.960474,
        "recall": 0.97332,
        "f1": 0.964756,
        "accuracy": 0.97332,
        "main_score": 0.964756,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.010874,
        "recall": 0.013834,
        "f1": 0.011208,
        "accuracy": 0.013834,
        "main_score": 0.011208,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003421,
        "recall": 0.023715,
        "f1": 0.005686,
        "accuracy": 0.023715,
        "main_score": 0.005686,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 95.04270577430725,
  "kg_co2_emissions": 0.0061152729925564465
}