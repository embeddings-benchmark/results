{
  "dataset_revision": "8f4de158d4162de768ebb4dc0594429d785077da",
  "task_name": "AmbientAcousticContext",
  "mteb_version": "2.4.2",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.44305,
            "f1": 0.393304,
            "f1_weighted": 0.418603,
            "precision": 0.397192,
            "precision_weighted": 0.431341,
            "recall": 0.429239,
            "recall_weighted": 0.44305,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.448842,
            "f1": 0.387104,
            "f1_weighted": 0.417843,
            "precision": 0.388508,
            "precision_weighted": 0.427132,
            "recall": 0.431959,
            "recall_weighted": 0.448842,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.46139,
            "f1": 0.394778,
            "f1_weighted": 0.428249,
            "precision": 0.389921,
            "precision_weighted": 0.429189,
            "recall": 0.43645,
            "recall_weighted": 0.46139,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.44305,
            "f1": 0.390406,
            "f1_weighted": 0.421241,
            "precision": 0.396346,
            "precision_weighted": 0.433094,
            "recall": 0.418938,
            "recall_weighted": 0.44305,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.462355,
            "f1": 0.403732,
            "f1_weighted": 0.435568,
            "precision": 0.42021,
            "precision_weighted": 0.463343,
            "recall": 0.446052,
            "recall_weighted": 0.462355,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.476834,
            "f1": 0.413845,
            "f1_weighted": 0.446107,
            "precision": 0.42409,
            "precision_weighted": 0.462544,
            "recall": 0.446792,
            "recall_weighted": 0.476834,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.472008,
            "f1": 0.408299,
            "f1_weighted": 0.447667,
            "precision": 0.429141,
            "precision_weighted": 0.475005,
            "recall": 0.434202,
            "recall_weighted": 0.472008,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.477799,
            "f1": 0.427748,
            "f1_weighted": 0.452145,
            "precision": 0.425948,
            "precision_weighted": 0.458562,
            "recall": 0.464201,
            "recall_weighted": 0.477799,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.469112,
            "f1": 0.411118,
            "f1_weighted": 0.440735,
            "precision": 0.416169,
            "precision_weighted": 0.452053,
            "recall": 0.442706,
            "recall_weighted": 0.469112,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.452703,
            "f1": 0.396652,
            "f1_weighted": 0.424634,
            "precision": 0.424441,
            "precision_weighted": 0.465225,
            "recall": 0.439269,
            "recall_weighted": 0.452703,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.460714,
        "f1": 0.402699,
        "f1_weighted": 0.433279,
        "precision": 0.411197,
        "precision_weighted": 0.449749,
        "recall": 0.438981,
        "recall_weighted": 0.460714,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.460714,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 145.2199890613556,
  "kg_co2_emissions": null
}