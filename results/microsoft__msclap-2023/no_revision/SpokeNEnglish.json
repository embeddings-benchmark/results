{
  "dataset_revision": "afbff14d927de14412d8124502313ea6d9d140e0",
  "task_name": "SpokeNEnglish",
  "mteb_version": "2.4.2",
  "scores": {
    "train": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.115625,
            "f1": 0.087397,
            "f1_weighted": 0.088562,
            "precision": 0.113398,
            "precision_weighted": 0.122788,
            "recall": 0.129591,
            "recall_weighted": 0.115625,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.135937,
            "f1": 0.115501,
            "f1_weighted": 0.117093,
            "precision": 0.145761,
            "precision_weighted": 0.154418,
            "recall": 0.137113,
            "recall_weighted": 0.135937,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.126562,
            "f1": 0.092383,
            "f1_weighted": 0.093874,
            "precision": 0.100633,
            "precision_weighted": 0.111707,
            "recall": 0.14257,
            "recall_weighted": 0.126562,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.126562,
            "f1": 0.100219,
            "f1_weighted": 0.100733,
            "precision": 0.122455,
            "precision_weighted": 0.125297,
            "recall": 0.126752,
            "recall_weighted": 0.126562,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.151562,
            "f1": 0.119035,
            "f1_weighted": 0.129279,
            "precision": 0.147414,
            "precision_weighted": 0.173005,
            "recall": 0.14918,
            "recall_weighted": 0.151562,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.13125,
        "f1": 0.102907,
        "f1_weighted": 0.105908,
        "precision": 0.125932,
        "precision_weighted": 0.137443,
        "recall": 0.137041,
        "recall_weighted": 0.13125,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.13125,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 205.19756054878235,
  "kg_co2_emissions": null
}