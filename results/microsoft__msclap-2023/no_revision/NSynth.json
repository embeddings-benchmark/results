{
  "dataset_revision": "e32dfe9b65e121e64229a821fe1ff177e8962635",
  "task_name": "NSynth",
  "mteb_version": "2.4.2",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.693205,
            "f1": 0.695018,
            "f1_weighted": 0.69215,
            "precision": 0.692595,
            "precision_weighted": 0.698306,
            "recall": 0.706014,
            "recall_weighted": 0.693205,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.545636,
            "f1": 0.543026,
            "f1_weighted": 0.547174,
            "precision": 0.611711,
            "precision_weighted": 0.648447,
            "recall": 0.559819,
            "recall_weighted": 0.545636,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.563624,
            "f1": 0.561865,
            "f1_weighted": 0.563338,
            "precision": 0.567989,
            "precision_weighted": 0.583976,
            "recall": 0.575853,
            "recall_weighted": 0.563624,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.637908,
            "f1": 0.626034,
            "f1_weighted": 0.642813,
            "precision": 0.629222,
            "precision_weighted": 0.652891,
            "recall": 0.628822,
            "recall_weighted": 0.637908,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.646236,
            "f1": 0.632367,
            "f1_weighted": 0.643206,
            "precision": 0.649869,
            "precision_weighted": 0.657165,
            "recall": 0.633105,
            "recall_weighted": 0.646236,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.692871,
            "f1": 0.688163,
            "f1_weighted": 0.693702,
            "precision": 0.68742,
            "precision_weighted": 0.697886,
            "recall": 0.692904,
            "recall_weighted": 0.692871,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.520653,
            "f1": 0.506726,
            "f1_weighted": 0.480513,
            "precision": 0.542613,
            "precision_weighted": 0.545891,
            "recall": 0.563307,
            "recall_weighted": 0.520653,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.7002,
            "f1": 0.701118,
            "f1_weighted": 0.698794,
            "precision": 0.705378,
            "precision_weighted": 0.718723,
            "recall": 0.721112,
            "recall_weighted": 0.7002,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.654564,
            "f1": 0.649998,
            "f1_weighted": 0.654657,
            "precision": 0.655272,
            "precision_weighted": 0.667871,
            "recall": 0.660043,
            "recall_weighted": 0.654564,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.608927,
            "f1": 0.605179,
            "f1_weighted": 0.613039,
            "precision": 0.616097,
            "precision_weighted": 0.639708,
            "recall": 0.618931,
            "recall_weighted": 0.608927,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.626382,
        "f1": 0.620949,
        "f1_weighted": 0.622939,
        "precision": 0.635817,
        "precision_weighted": 0.651086,
        "recall": 0.635991,
        "recall_weighted": 0.626382,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.626382,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 390.012717962265,
  "kg_co2_emissions": null
}