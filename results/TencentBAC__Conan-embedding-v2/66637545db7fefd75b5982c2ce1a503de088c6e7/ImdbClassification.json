{
  "dataset_revision": "3d86128a09e091d6018b6d26cad27f2739fc2db7",
  "task_name": "ImdbClassification",
  "mteb_version": "1.36.38",
  "scores": {
    "test": [
      {
        "accuracy": 0.961628,
        "f1": 0.961618,
        "f1_weighted": 0.961618,
        "ap": 0.942869,
        "ap_weighted": 0.942869,
        "scores_per_experiment": [
          {
            "accuracy": 0.96092,
            "f1": 0.960905,
            "f1_weighted": 0.960905,
            "ap": 0.951446,
            "ap_weighted": 0.951446
          },
          {
            "accuracy": 0.95856,
            "f1": 0.958542,
            "f1_weighted": 0.958542,
            "ap": 0.948758,
            "ap_weighted": 0.948758
          },
          {
            "accuracy": 0.96012,
            "f1": 0.960104,
            "f1_weighted": 0.960104,
            "ap": 0.933612,
            "ap_weighted": 0.933612
          },
          {
            "accuracy": 0.95772,
            "f1": 0.957694,
            "f1_weighted": 0.957694,
            "ap": 0.928452,
            "ap_weighted": 0.928452
          },
          {
            "accuracy": 0.96236,
            "f1": 0.962356,
            "f1_weighted": 0.962356,
            "ap": 0.949516,
            "ap_weighted": 0.949516
          },
          {
            "accuracy": 0.96116,
            "f1": 0.961149,
            "f1_weighted": 0.961149,
            "ap": 0.936319,
            "ap_weighted": 0.936319
          },
          {
            "accuracy": 0.96432,
            "f1": 0.964318,
            "f1_weighted": 0.964318,
            "ap": 0.944726,
            "ap_weighted": 0.944726
          },
          {
            "accuracy": 0.9634,
            "f1": 0.9634,
            "f1_weighted": 0.9634,
            "ap": 0.947493,
            "ap_weighted": 0.947493
          },
          {
            "accuracy": 0.96468,
            "f1": 0.96468,
            "f1_weighted": 0.96468,
            "ap": 0.94698,
            "ap_weighted": 0.94698
          },
          {
            "accuracy": 0.96304,
            "f1": 0.963036,
            "f1_weighted": 0.963036,
            "ap": 0.941393,
            "ap_weighted": 0.941393
          }
        ],
        "main_score": 0.961628,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 100.5743796825409,
  "kg_co2_emissions": null
}