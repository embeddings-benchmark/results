{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "1.34.21",
  "scores": {
    "test": [
      {
        "accuracy": 0.570821,
        "f1": 0.473434,
        "f1_weighted": 0.639157,
        "ap": 0.891819,
        "ap_weighted": 0.891819,
        "scores_per_experiment": [
          {
            "accuracy": 0.534954,
            "f1": 0.445732,
            "f1_weighted": 0.612686,
            "ap": 0.88329,
            "ap_weighted": 0.88329
          },
          {
            "accuracy": 0.531915,
            "f1": 0.440476,
            "f1_weighted": 0.610291,
            "ap": 0.880555,
            "ap_weighted": 0.880555
          },
          {
            "accuracy": 0.531915,
            "f1": 0.466763,
            "f1_weighted": 0.606697,
            "ap": 0.902621,
            "ap_weighted": 0.902621
          },
          {
            "accuracy": 0.43769,
            "f1": 0.385357,
            "f1_weighted": 0.520005,
            "ap": 0.875602,
            "ap_weighted": 0.875602
          },
          {
            "accuracy": 0.607903,
            "f1": 0.508426,
            "f1_weighted": 0.674444,
            "ap": 0.902721,
            "ap_weighted": 0.902721
          },
          {
            "accuracy": 0.519757,
            "f1": 0.422525,
            "f1_weighted": 0.600423,
            "ap": 0.87216,
            "ap_weighted": 0.87216
          },
          {
            "accuracy": 0.504559,
            "f1": 0.451874,
            "f1_weighted": 0.579455,
            "ap": 0.90408,
            "ap_weighted": 0.90408
          },
          {
            "accuracy": 0.620061,
            "f1": 0.506166,
            "f1_weighted": 0.684217,
            "ap": 0.896853,
            "ap_weighted": 0.896853
          },
          {
            "accuracy": 0.699088,
            "f1": 0.553191,
            "f1_weighted": 0.744875,
            "ap": 0.902437,
            "ap_weighted": 0.902437
          },
          {
            "accuracy": 0.720365,
            "f1": 0.553833,
            "f1_weighted": 0.758477,
            "ap": 0.897872,
            "ap_weighted": 0.897872
          }
        ],
        "main_score": 0.570821,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 3.1838793754577637,
  "kg_co2_emissions": null
}