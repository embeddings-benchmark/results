{
  "dataset_revision": "3e0319203c7162b9c9f8015b594441f979c199bc",
  "task_name": "ToxicChatClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.757045,
        "f1": 0.640412,
        "f1_weighted": 0.792974,
        "ap": 0.263549,
        "ap_weighted": 0.263549,
        "scores_per_experiment": [
          {
            "accuracy": 0.679553,
            "f1": 0.578005,
            "f1_weighted": 0.733084,
            "ap": 0.216334,
            "ap_weighted": 0.216334
          },
          {
            "accuracy": 0.805842,
            "f1": 0.674142,
            "f1_weighted": 0.829334,
            "ap": 0.281853,
            "ap_weighted": 0.281853
          },
          {
            "accuracy": 0.791237,
            "f1": 0.673492,
            "f1_weighted": 0.820379,
            "ap": 0.294615,
            "ap_weighted": 0.294615
          },
          {
            "accuracy": 0.814433,
            "f1": 0.69413,
            "f1_weighted": 0.837834,
            "ap": 0.314345,
            "ap_weighted": 0.314345
          },
          {
            "accuracy": 0.737113,
            "f1": 0.603323,
            "f1_weighted": 0.775905,
            "ap": 0.213096,
            "ap_weighted": 0.213096
          },
          {
            "accuracy": 0.737973,
            "f1": 0.626951,
            "f1_weighted": 0.779409,
            "ap": 0.253538,
            "ap_weighted": 0.253538
          },
          {
            "accuracy": 0.828179,
            "f1": 0.694487,
            "f1_weighted": 0.845889,
            "ap": 0.301956,
            "ap_weighted": 0.301956
          },
          {
            "accuracy": 0.678694,
            "f1": 0.591407,
            "f1_weighted": 0.732883,
            "ap": 0.243723,
            "ap_weighted": 0.243723
          },
          {
            "accuracy": 0.736254,
            "f1": 0.616207,
            "f1_weighted": 0.777008,
            "ap": 0.234937,
            "ap_weighted": 0.234937
          },
          {
            "accuracy": 0.761168,
            "f1": 0.651974,
            "f1_weighted": 0.798013,
            "ap": 0.28109,
            "ap_weighted": 0.28109
          }
        ],
        "main_score": 0.757045,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.182259559631348,
  "kg_co2_emissions": 0.000209187717690622
}