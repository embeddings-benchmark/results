{
  "dataset_revision": "f333c1fcfa3ab43f008a327c8bd0140441354d34",
  "task_name": "BrazilianToxicTweetsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.199902,
        "f1": 0.145378,
        "lrap": 0.791168,
        "scores_per_experiment": [
          {
            "accuracy": 0.19873,
            "f1": 0.15394,
            "lrap": 0.81429
          },
          {
            "accuracy": 0.172363,
            "f1": 0.142329,
            "lrap": 0.793254
          },
          {
            "accuracy": 0.141113,
            "f1": 0.146239,
            "lrap": 0.81465
          },
          {
            "accuracy": 0.21875,
            "f1": 0.137901,
            "lrap": 0.833917
          },
          {
            "accuracy": 0.333984,
            "f1": 0.152521,
            "lrap": 0.766154
          },
          {
            "accuracy": 0.158691,
            "f1": 0.173612,
            "lrap": 0.800388
          },
          {
            "accuracy": 0.173828,
            "f1": 0.12778,
            "lrap": 0.7712
          },
          {
            "accuracy": 0.124023,
            "f1": 0.158922,
            "lrap": 0.776469
          },
          {
            "accuracy": 0.212402,
            "f1": 0.109946,
            "lrap": 0.739746
          },
          {
            "accuracy": 0.265137,
            "f1": 0.15059,
            "lrap": 0.801609
          }
        ],
        "main_score": 0.199902,
        "hf_subset": "default",
        "languages": [
          "por-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 5.726306676864624,
  "kg_co2_emissions": 0.00025159118051465727
}