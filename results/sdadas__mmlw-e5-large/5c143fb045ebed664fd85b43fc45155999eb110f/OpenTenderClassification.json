{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.321293,
            "f1": 0.318356,
            "f1_weighted": 0.31833,
            "precision": 0.324548,
            "precision_weighted": 0.324506,
            "recall": 0.321311,
            "recall_weighted": 0.321293,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.335117,
            "f1": 0.336515,
            "f1_weighted": 0.336414,
            "precision": 0.34548,
            "precision_weighted": 0.345361,
            "recall": 0.335193,
            "recall_weighted": 0.335117,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.330212,
            "f1": 0.331264,
            "f1_weighted": 0.331203,
            "precision": 0.340723,
            "precision_weighted": 0.340654,
            "recall": 0.330266,
            "recall_weighted": 0.330212,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.315273,
            "f1": 0.316832,
            "f1_weighted": 0.316812,
            "precision": 0.325039,
            "precision_weighted": 0.325022,
            "recall": 0.315293,
            "recall_weighted": 0.315273,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.305909,
            "f1": 0.302574,
            "f1_weighted": 0.30256,
            "precision": 0.306256,
            "precision_weighted": 0.30626,
            "recall": 0.305932,
            "recall_weighted": 0.305909,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.314604,
            "f1": 0.317739,
            "f1_weighted": 0.317636,
            "precision": 0.328767,
            "precision_weighted": 0.328632,
            "recall": 0.314675,
            "recall_weighted": 0.314604,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.313489,
            "f1": 0.311104,
            "f1_weighted": 0.311054,
            "precision": 0.322452,
            "precision_weighted": 0.322373,
            "recall": 0.313494,
            "recall_weighted": 0.313489,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.313712,
            "f1": 0.313594,
            "f1_weighted": 0.31346,
            "precision": 0.322244,
            "precision_weighted": 0.322096,
            "recall": 0.313843,
            "recall_weighted": 0.313712,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.295206,
            "f1": 0.294988,
            "f1_weighted": 0.294876,
            "precision": 0.306214,
            "precision_weighted": 0.306059,
            "recall": 0.295274,
            "recall_weighted": 0.295206,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.327982,
            "f1": 0.32624,
            "f1_weighted": 0.326178,
            "precision": 0.33501,
            "precision_weighted": 0.33488,
            "recall": 0.327984,
            "recall_weighted": 0.327982,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.31728,
        "f1": 0.316921,
        "f1_weighted": 0.316852,
        "precision": 0.325673,
        "precision_weighted": 0.325584,
        "recall": 0.317327,
        "recall_weighted": 0.31728,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.316921,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 109.18215489387512,
  "kg_co2_emissions": null
}