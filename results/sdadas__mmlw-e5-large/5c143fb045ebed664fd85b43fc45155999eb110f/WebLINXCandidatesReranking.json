{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.125349,
        "mrr": 0.106371,
        "nAUC_map_max": -0.090306,
        "nAUC_map_std": 0.016953,
        "nAUC_map_diff1": 0.183667,
        "nAUC_mrr_max": -0.080073,
        "nAUC_mrr_std": 0.01807,
        "nAUC_mrr_diff1": 0.189389,
        "main_score": 0.106371,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.103629,
        "mrr": 0.084783,
        "nAUC_map_max": 0.092151,
        "nAUC_map_std": 0.162642,
        "nAUC_map_diff1": 0.177448,
        "nAUC_mrr_max": 0.095901,
        "nAUC_mrr_std": 0.157785,
        "nAUC_mrr_diff1": 0.161388,
        "main_score": 0.084783,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.086747,
        "mrr": 0.068997,
        "nAUC_map_max": 0.025202,
        "nAUC_map_std": 0.263861,
        "nAUC_map_diff1": 0.16174,
        "nAUC_mrr_max": -0.005211,
        "nAUC_mrr_std": 0.230927,
        "nAUC_mrr_diff1": 0.138572,
        "main_score": 0.068997,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.112253,
        "mrr": 0.09223,
        "nAUC_map_max": -0.140685,
        "nAUC_map_std": -0.038681,
        "nAUC_map_diff1": 0.067549,
        "nAUC_mrr_max": -0.135137,
        "nAUC_mrr_std": -0.039532,
        "nAUC_mrr_diff1": 0.066505,
        "main_score": 0.09223,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.112722,
        "mrr": 0.093658,
        "nAUC_map_max": 0.01307,
        "nAUC_map_std": 0.144969,
        "nAUC_map_diff1": 0.071826,
        "nAUC_mrr_max": 0.0152,
        "nAUC_mrr_std": 0.128357,
        "nAUC_mrr_diff1": 0.074255,
        "main_score": 0.093658,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.087517,
        "mrr": 0.069647,
        "nAUC_map_max": 0.065881,
        "nAUC_map_std": 0.141806,
        "nAUC_map_diff1": 0.149913,
        "nAUC_mrr_max": 0.064846,
        "nAUC_mrr_std": 0.136219,
        "nAUC_mrr_diff1": 0.148931,
        "main_score": 0.069647,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 5668.1996331214905,
  "kg_co2_emissions": 0.5203412962499213
}