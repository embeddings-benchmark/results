{
  "dataset_revision": "8ccc72e69e65f40c70e117d8b3c08306bb788b60",
  "task_name": "MasakhaNEWSClusteringS2S",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "v_measure": 0.414506,
        "v_measure_std": 0.47821,
        "v_measures": [
          1.0,
          0.045691,
          0.018475,
          0.008363,
          1.0
        ],
        "main_score": 0.414506,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ]
      },
      {
        "v_measure": 0.424333,
        "v_measure_std": 0.31178,
        "v_measures": [
          0.05438,
          0.706952,
          0.635359,
          0.691966,
          0.033008
        ],
        "main_score": 0.424333,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "v_measure": 0.494231,
        "v_measure_std": 0.296409,
        "v_measures": [
          1.0,
          0.095098,
          0.342112,
          0.514929,
          0.519017
        ],
        "main_score": 0.494231,
        "hf_subset": "fra",
        "languages": [
          "fra-Latn"
        ]
      },
      {
        "v_measure": 0.138428,
        "v_measure_std": 0.198253,
        "v_measures": [
          0.031496,
          0.0,
          0.092873,
          0.037376,
          0.530395
        ],
        "main_score": 0.138428,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ]
      },
      {
        "v_measure": 0.382447,
        "v_measure_std": 0.370198,
        "v_measures": [
          0.011961,
          0.545686,
          0.010294,
          1.0,
          0.344293
        ],
        "main_score": 0.382447,
        "hf_subset": "ibo",
        "languages": [
          "ibo-Latn"
        ]
      },
      {
        "v_measure": 0.749457,
        "v_measure_std": 0.209945,
        "v_measures": [
          0.505118,
          0.654101,
          1.0,
          1.0,
          0.588067
        ],
        "main_score": 0.749457,
        "hf_subset": "lin",
        "languages": [
          "lin-Latn"
        ]
      },
      {
        "v_measure": 0.444586,
        "v_measure_std": 0.45588,
        "v_measures": [
          0.043098,
          0.021395,
          1.0,
          1.0,
          0.158436
        ],
        "main_score": 0.444586,
        "hf_subset": "lug",
        "languages": [
          "lug-Latn"
        ]
      },
      {
        "v_measure": 0.248304,
        "v_measure_std": 0.381343,
        "v_measures": [
          0.184751,
          0.01376,
          1.0,
          0.029868,
          0.013143
        ],
        "main_score": 0.248304,
        "hf_subset": "orm",
        "languages": [
          "orm-Ethi"
        ]
      },
      {
        "v_measure": 0.705883,
        "v_measure_std": 0.333449,
        "v_measures": [
          0.053194,
          0.844658,
          0.812762,
          0.818802,
          1.0
        ],
        "main_score": 0.705883,
        "hf_subset": "pcm",
        "languages": [
          "pcm-Latn"
        ]
      },
      {
        "v_measure": 0.546618,
        "v_measure_std": 0.37538,
        "v_measures": [
          0.243363,
          0.146467,
          1.0,
          0.343258,
          1.0
        ],
        "main_score": 0.546618,
        "hf_subset": "run",
        "languages": [
          "run-Latn"
        ]
      },
      {
        "v_measure": 0.469,
        "v_measure_std": 0.443056,
        "v_measures": [
          1.0,
          0.06219,
          0.278224,
          0.004584,
          1.0
        ],
        "main_score": 0.469,
        "hf_subset": "sna",
        "languages": [
          "sna-Latn"
        ]
      },
      {
        "v_measure": 0.298969,
        "v_measure_std": 0.357155,
        "v_measures": [
          0.075888,
          1.0,
          0.039905,
          0.136992,
          0.242058
        ],
        "main_score": 0.298969,
        "hf_subset": "som",
        "languages": [
          "som-Latn"
        ]
      },
      {
        "v_measure": 0.215567,
        "v_measure_std": 0.200067,
        "v_measures": [
          0.04326,
          0.074859,
          0.041554,
          0.488803,
          0.429359
        ],
        "main_score": 0.215567,
        "hf_subset": "swa",
        "languages": [
          "swa-Latn"
        ]
      },
      {
        "v_measure": 0.442051,
        "v_measure_std": 0.455861,
        "v_measures": [
          0.062263,
          1.0,
          0.099168,
          1.0,
          0.048827
        ],
        "main_score": 0.442051,
        "hf_subset": "tir",
        "languages": [
          "tir-Ethi"
        ]
      },
      {
        "v_measure": 0.268828,
        "v_measure_std": 0.368145,
        "v_measures": [
          0.14161,
          0.125625,
          0.028379,
          0.048525,
          1.0
        ],
        "main_score": 0.268828,
        "hf_subset": "xho",
        "languages": [
          "xho-Latn"
        ]
      },
      {
        "v_measure": 0.320175,
        "v_measure_std": 0.343419,
        "v_measures": [
          1.0,
          0.124324,
          0.101428,
          0.132147,
          0.242974
        ],
        "main_score": 0.320175,
        "hf_subset": "yor",
        "languages": [
          "yor-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 8.920313358306885,
  "kg_co2_emissions": 0.0004958300758377707
}