{
  "dataset_revision": "b07c6ce548f6a7ac8d546e1bbe197a0086409190",
  "task_name": "SweRecClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.552441,
        "f1": 0.488097,
        "f1_weighted": 0.575338,
        "scores_per_experiment": [
          {
            "accuracy": 0.577148,
            "f1": 0.498326,
            "f1_weighted": 0.594868
          },
          {
            "accuracy": 0.51123,
            "f1": 0.487096,
            "f1_weighted": 0.564096
          },
          {
            "accuracy": 0.48877,
            "f1": 0.460963,
            "f1_weighted": 0.516651
          },
          {
            "accuracy": 0.519531,
            "f1": 0.468872,
            "f1_weighted": 0.558196
          },
          {
            "accuracy": 0.521973,
            "f1": 0.477954,
            "f1_weighted": 0.555582
          },
          {
            "accuracy": 0.583984,
            "f1": 0.485131,
            "f1_weighted": 0.579931
          },
          {
            "accuracy": 0.569824,
            "f1": 0.507529,
            "f1_weighted": 0.595815
          },
          {
            "accuracy": 0.650879,
            "f1": 0.535357,
            "f1_weighted": 0.645825
          },
          {
            "accuracy": 0.541504,
            "f1": 0.48164,
            "f1_weighted": 0.56248
          },
          {
            "accuracy": 0.55957,
            "f1": 0.478107,
            "f1_weighted": 0.579938
          }
        ],
        "main_score": 0.552441,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 8.45308232307434,
  "kg_co2_emissions": 0.0003073481974617319
}