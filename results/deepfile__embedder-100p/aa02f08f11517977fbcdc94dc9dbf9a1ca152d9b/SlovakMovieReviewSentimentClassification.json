{
  "dataset_revision": "0c47583c9d339b3b6f89e4db76088af5f1ec8d39",
  "task_name": "SlovakMovieReviewSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.556445,
        "f1": 0.545342,
        "f1_weighted": 0.554892,
        "ap": 0.435975,
        "ap_weighted": 0.435975,
        "scores_per_experiment": [
          {
            "accuracy": 0.548828,
            "f1": 0.538799,
            "f1_weighted": 0.55175,
            "ap": 0.42631,
            "ap_weighted": 0.42631
          },
          {
            "accuracy": 0.551758,
            "f1": 0.499458,
            "f1_weighted": 0.530269,
            "ap": 0.40911,
            "ap_weighted": 0.40911
          },
          {
            "accuracy": 0.587402,
            "f1": 0.573247,
            "f1_weighted": 0.588048,
            "ap": 0.447716,
            "ap_weighted": 0.447716
          },
          {
            "accuracy": 0.578613,
            "f1": 0.578601,
            "f1_weighted": 0.579032,
            "ap": 0.46224,
            "ap_weighted": 0.46224
          },
          {
            "accuracy": 0.543945,
            "f1": 0.531637,
            "f1_weighted": 0.546096,
            "ap": 0.421777,
            "ap_weighted": 0.421777
          },
          {
            "accuracy": 0.5625,
            "f1": 0.545508,
            "f1_weighted": 0.562243,
            "ap": 0.42964,
            "ap_weighted": 0.42964
          },
          {
            "accuracy": 0.520508,
            "f1": 0.520471,
            "f1_weighted": 0.521273,
            "ap": 0.424707,
            "ap_weighted": 0.424707
          },
          {
            "accuracy": 0.573242,
            "f1": 0.568707,
            "f1_weighted": 0.577129,
            "ap": 0.44718,
            "ap_weighted": 0.44718
          },
          {
            "accuracy": 0.557617,
            "f1": 0.55759,
            "f1_weighted": 0.556932,
            "ap": 0.449513,
            "ap_weighted": 0.449513
          },
          {
            "accuracy": 0.540039,
            "f1": 0.539405,
            "f1_weighted": 0.53615,
            "ap": 0.441561,
            "ap_weighted": 0.441561
          }
        ],
        "main_score": 0.556445,
        "hf_subset": "default",
        "languages": [
          "svk-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 8.892108678817749,
  "kg_co2_emissions": 0.00032779498765812305
}