{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.246583,
        "recall": 0.287864,
        "f1": 0.254963,
        "accuracy": 0.287864,
        "main_score": 0.254963,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.214531,
        "recall": 0.338014,
        "f1": 0.241944,
        "accuracy": 0.338014,
        "main_score": 0.241944,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.547659,
        "recall": 0.600802,
        "f1": 0.561244,
        "accuracy": 0.600802,
        "main_score": 0.561244,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.512748,
        "recall": 0.631896,
        "f1": 0.54658,
        "accuracy": 0.631896,
        "main_score": 0.54658,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.750227,
        "recall": 0.782347,
        "f1": 0.758661,
        "accuracy": 0.782347,
        "main_score": 0.758661,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.629422,
        "recall": 0.736209,
        "f1": 0.661991,
        "accuracy": 0.736209,
        "main_score": 0.661991,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.148849,
        "recall": 0.170512,
        "f1": 0.152632,
        "accuracy": 0.170512,
        "main_score": 0.152632,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.129518,
        "recall": 0.240722,
        "f1": 0.151508,
        "accuracy": 0.240722,
        "main_score": 0.151508,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.030076,
        "recall": 0.041123,
        "f1": 0.031794,
        "accuracy": 0.041123,
        "main_score": 0.031794,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.049981,
        "recall": 0.104313,
        "f1": 0.058091,
        "accuracy": 0.104313,
        "main_score": 0.058091,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.325664,
        "recall": 0.373119,
        "f1": 0.3371,
        "accuracy": 0.373119,
        "main_score": 0.3371,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.309191,
        "recall": 0.446339,
        "f1": 0.343851,
        "accuracy": 0.446339,
        "main_score": 0.343851,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.044044,
        "recall": 0.054162,
        "f1": 0.045283,
        "accuracy": 0.054162,
        "main_score": 0.045283,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.060496,
        "recall": 0.121364,
        "f1": 0.070506,
        "accuracy": 0.121364,
        "main_score": 0.070506,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.169671,
        "recall": 0.204614,
        "f1": 0.176658,
        "accuracy": 0.204614,
        "main_score": 0.176658,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.121448,
        "recall": 0.23671,
        "f1": 0.144075,
        "accuracy": 0.23671,
        "main_score": 0.144075,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.661254,
        "recall": 0.706118,
        "f1": 0.672723,
        "accuracy": 0.706118,
        "main_score": 0.672723,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.555216,
        "recall": 0.673019,
        "f1": 0.589442,
        "accuracy": 0.673019,
        "main_score": 0.589442,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.086439,
        "recall": 0.114343,
        "f1": 0.090879,
        "accuracy": 0.114343,
        "main_score": 0.090879,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.085491,
        "recall": 0.173521,
        "f1": 0.101687,
        "accuracy": 0.173521,
        "main_score": 0.101687,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.32348,
        "recall": 0.368104,
        "f1": 0.333634,
        "accuracy": 0.368104,
        "main_score": 0.333634,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.25364,
        "recall": 0.394183,
        "f1": 0.287833,
        "accuracy": 0.394183,
        "main_score": 0.287833,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.270701,
        "recall": 0.315948,
        "f1": 0.280255,
        "accuracy": 0.315948,
        "main_score": 0.280255,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.241248,
        "recall": 0.365095,
        "f1": 0.269961,
        "accuracy": 0.365095,
        "main_score": 0.269961,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.253553,
        "recall": 0.308927,
        "f1": 0.266648,
        "accuracy": 0.308927,
        "main_score": 0.266648,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.291523,
        "recall": 0.418255,
        "f1": 0.323267,
        "accuracy": 0.418255,
        "main_score": 0.323267,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.599425,
        "recall": 0.674022,
        "f1": 0.619655,
        "accuracy": 0.674022,
        "main_score": 0.619655,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.590013,
        "recall": 0.69007,
        "f1": 0.61851,
        "accuracy": 0.69007,
        "main_score": 0.61851,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.174967,
        "recall": 0.204614,
        "f1": 0.180439,
        "accuracy": 0.204614,
        "main_score": 0.180439,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.145654,
        "recall": 0.260782,
        "f1": 0.169586,
        "accuracy": 0.260782,
        "main_score": 0.169586,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.12864,
        "recall": 0.159478,
        "f1": 0.135272,
        "accuracy": 0.159478,
        "main_score": 0.135272,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.125096,
        "recall": 0.238716,
        "f1": 0.148176,
        "accuracy": 0.238716,
        "main_score": 0.148176,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.526702,
        "recall": 0.585757,
        "f1": 0.541151,
        "accuracy": 0.585757,
        "main_score": 0.541151,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.457466,
        "recall": 0.583751,
        "f1": 0.491528,
        "accuracy": 0.583751,
        "main_score": 0.491528,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.451411,
        "recall": 0.501505,
        "f1": 0.462478,
        "accuracy": 0.501505,
        "main_score": 0.462478,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.395532,
        "recall": 0.52658,
        "f1": 0.430156,
        "accuracy": 0.52658,
        "main_score": 0.430156,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.016069,
        "recall": 0.021063,
        "f1": 0.017092,
        "accuracy": 0.021063,
        "main_score": 0.017092,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020072,
        "recall": 0.066199,
        "f1": 0.025457,
        "accuracy": 0.066199,
        "main_score": 0.025457,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.03296,
        "recall": 0.041123,
        "f1": 0.034194,
        "accuracy": 0.041123,
        "main_score": 0.034194,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.035196,
        "recall": 0.092277,
        "f1": 0.044222,
        "accuracy": 0.092277,
        "main_score": 0.044222,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.379277,
        "recall": 0.432297,
        "f1": 0.391076,
        "accuracy": 0.432297,
        "main_score": 0.391076,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.32611,
        "recall": 0.45336,
        "f1": 0.357322,
        "accuracy": 0.45336,
        "main_score": 0.357322,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.161083,
        "recall": 0.19659,
        "f1": 0.16905,
        "accuracy": 0.19659,
        "main_score": 0.16905,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.148705,
        "recall": 0.268806,
        "f1": 0.175952,
        "accuracy": 0.268806,
        "main_score": 0.175952,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.379451,
        "recall": 0.432297,
        "f1": 0.391225,
        "accuracy": 0.432297,
        "main_score": 0.391225,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.323053,
        "recall": 0.461384,
        "f1": 0.358758,
        "accuracy": 0.461384,
        "main_score": 0.358758,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.431761,
        "recall": 0.484453,
        "f1": 0.444017,
        "accuracy": 0.484453,
        "main_score": 0.444017,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.366625,
        "recall": 0.496489,
        "f1": 0.398763,
        "accuracy": 0.496489,
        "main_score": 0.398763,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.386161,
        "recall": 0.447342,
        "f1": 0.400137,
        "accuracy": 0.447342,
        "main_score": 0.400137,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.367336,
        "recall": 0.502508,
        "f1": 0.401996,
        "accuracy": 0.502508,
        "main_score": 0.401996,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.030506,
        "recall": 0.04012,
        "f1": 0.032667,
        "accuracy": 0.04012,
        "main_score": 0.032667,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025416,
        "recall": 0.080241,
        "f1": 0.033499,
        "accuracy": 0.080241,
        "main_score": 0.033499,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.517559,
        "recall": 0.560682,
        "f1": 0.527822,
        "accuracy": 0.560682,
        "main_score": 0.527822,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.43581,
        "recall": 0.567703,
        "f1": 0.471104,
        "accuracy": 0.567703,
        "main_score": 0.471104,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.490884,
        "recall": 0.539619,
        "f1": 0.502378,
        "accuracy": 0.539619,
        "main_score": 0.502378,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.406418,
        "recall": 0.534604,
        "f1": 0.439561,
        "accuracy": 0.534604,
        "main_score": 0.439561,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.002556,
        "recall": 0.005015,
        "f1": 0.002768,
        "accuracy": 0.005015,
        "main_score": 0.002768,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001099,
        "recall": 0.017051,
        "f1": 0.001921,
        "accuracy": 0.017051,
        "main_score": 0.001921,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.242284,
        "recall": 0.273715,
        "f1": 0.25013,
        "accuracy": 0.273715,
        "main_score": 0.25013,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.209028,
        "recall": 0.335968,
        "f1": 0.237251,
        "accuracy": 0.335968,
        "main_score": 0.237251,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.541413,
        "recall": 0.601779,
        "f1": 0.556064,
        "accuracy": 0.601779,
        "main_score": 0.556064,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.511137,
        "recall": 0.635375,
        "f1": 0.546765,
        "accuracy": 0.635375,
        "main_score": 0.546765,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.732142,
        "recall": 0.768775,
        "f1": 0.741723,
        "accuracy": 0.768775,
        "main_score": 0.741723,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.621245,
        "recall": 0.728261,
        "f1": 0.653261,
        "accuracy": 0.728261,
        "main_score": 0.653261,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.128911,
        "recall": 0.151186,
        "f1": 0.132687,
        "accuracy": 0.151186,
        "main_score": 0.132687,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.122504,
        "recall": 0.240119,
        "f1": 0.146318,
        "accuracy": 0.240119,
        "main_score": 0.146318,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.021428,
        "recall": 0.027668,
        "f1": 0.022763,
        "accuracy": 0.027668,
        "main_score": 0.022763,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.043402,
        "recall": 0.087945,
        "f1": 0.048733,
        "accuracy": 0.087945,
        "main_score": 0.048733,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.340067,
        "recall": 0.379447,
        "f1": 0.348777,
        "accuracy": 0.379447,
        "main_score": 0.348777,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.298326,
        "recall": 0.439723,
        "f1": 0.333244,
        "accuracy": 0.439723,
        "main_score": 0.333244,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.040388,
        "recall": 0.046443,
        "f1": 0.041483,
        "accuracy": 0.046443,
        "main_score": 0.041483,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.048117,
        "recall": 0.104743,
        "f1": 0.056281,
        "accuracy": 0.104743,
        "main_score": 0.056281,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.142961,
        "recall": 0.164032,
        "f1": 0.148186,
        "accuracy": 0.164032,
        "main_score": 0.148186,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.116128,
        "recall": 0.227273,
        "f1": 0.13747,
        "accuracy": 0.227273,
        "main_score": 0.13747,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.608897,
        "recall": 0.655138,
        "f1": 0.62047,
        "accuracy": 0.655138,
        "main_score": 0.62047,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.515522,
        "recall": 0.640316,
        "f1": 0.550732,
        "accuracy": 0.640316,
        "main_score": 0.550732,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.065126,
        "recall": 0.094862,
        "f1": 0.069785,
        "accuracy": 0.094862,
        "main_score": 0.069785,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.078246,
        "recall": 0.166008,
        "f1": 0.094425,
        "accuracy": 0.166008,
        "main_score": 0.094425,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.295315,
        "recall": 0.339921,
        "f1": 0.306486,
        "accuracy": 0.339921,
        "main_score": 0.306486,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.2649,
        "recall": 0.401186,
        "f1": 0.297314,
        "accuracy": 0.401186,
        "main_score": 0.297314,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.287777,
        "recall": 0.33004,
        "f1": 0.297511,
        "accuracy": 0.33004,
        "main_score": 0.297511,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.246014,
        "recall": 0.375494,
        "f1": 0.276059,
        "accuracy": 0.375494,
        "main_score": 0.276059,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.216747,
        "recall": 0.281621,
        "f1": 0.22996,
        "accuracy": 0.281621,
        "main_score": 0.22996,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.27165,
        "recall": 0.389328,
        "f1": 0.300432,
        "accuracy": 0.389328,
        "main_score": 0.300432,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.571189,
        "recall": 0.643281,
        "f1": 0.590637,
        "accuracy": 0.643281,
        "main_score": 0.590637,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.570985,
        "recall": 0.674901,
        "f1": 0.600365,
        "accuracy": 0.674901,
        "main_score": 0.600365,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.146944,
        "recall": 0.171937,
        "f1": 0.152468,
        "accuracy": 0.171937,
        "main_score": 0.152468,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.13753,
        "recall": 0.245059,
        "f1": 0.159339,
        "accuracy": 0.245059,
        "main_score": 0.159339,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.124051,
        "recall": 0.150198,
        "f1": 0.128642,
        "accuracy": 0.150198,
        "main_score": 0.128642,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.109434,
        "recall": 0.22332,
        "f1": 0.132292,
        "accuracy": 0.22332,
        "main_score": 0.132292,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.513328,
        "recall": 0.570158,
        "f1": 0.528523,
        "accuracy": 0.570158,
        "main_score": 0.528523,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.433618,
        "recall": 0.570158,
        "f1": 0.471573,
        "accuracy": 0.570158,
        "main_score": 0.471573,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.400376,
        "recall": 0.447628,
        "f1": 0.412124,
        "accuracy": 0.447628,
        "main_score": 0.412124,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.333965,
        "recall": 0.479249,
        "f1": 0.371414,
        "accuracy": 0.479249,
        "main_score": 0.371414,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.021839,
        "recall": 0.028656,
        "f1": 0.023388,
        "accuracy": 0.028656,
        "main_score": 0.023388,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01546,
        "recall": 0.057312,
        "f1": 0.019801,
        "accuracy": 0.057312,
        "main_score": 0.019801,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.030198,
        "recall": 0.044466,
        "f1": 0.032868,
        "accuracy": 0.044466,
        "main_score": 0.032868,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.029952,
        "recall": 0.094862,
        "f1": 0.040255,
        "accuracy": 0.094862,
        "main_score": 0.040255,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.373667,
        "recall": 0.421937,
        "f1": 0.385069,
        "accuracy": 0.421937,
        "main_score": 0.385069,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.326672,
        "recall": 0.469368,
        "f1": 0.363479,
        "accuracy": 0.469368,
        "main_score": 0.363479,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.161048,
        "recall": 0.197628,
        "f1": 0.168163,
        "accuracy": 0.197628,
        "main_score": 0.168163,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.15437,
        "recall": 0.271739,
        "f1": 0.178484,
        "accuracy": 0.271739,
        "main_score": 0.178484,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.366343,
        "recall": 0.416996,
        "f1": 0.37875,
        "accuracy": 0.416996,
        "main_score": 0.37875,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.323213,
        "recall": 0.464427,
        "f1": 0.359639,
        "accuracy": 0.464427,
        "main_score": 0.359639,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.421596,
        "recall": 0.469368,
        "f1": 0.432898,
        "accuracy": 0.469368,
        "main_score": 0.432898,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.349515,
        "recall": 0.495059,
        "f1": 0.387565,
        "accuracy": 0.495059,
        "main_score": 0.387565,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.381878,
        "recall": 0.432806,
        "f1": 0.394467,
        "accuracy": 0.432806,
        "main_score": 0.394467,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.368634,
        "recall": 0.500988,
        "f1": 0.403382,
        "accuracy": 0.500988,
        "main_score": 0.403382,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.023953,
        "recall": 0.036561,
        "f1": 0.026191,
        "accuracy": 0.036561,
        "main_score": 0.026191,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.029176,
        "recall": 0.081028,
        "f1": 0.036889,
        "accuracy": 0.081028,
        "main_score": 0.036889,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.507657,
        "recall": 0.5583,
        "f1": 0.520518,
        "accuracy": 0.5583,
        "main_score": 0.520518,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.435507,
        "recall": 0.568182,
        "f1": 0.471599,
        "accuracy": 0.568182,
        "main_score": 0.471599,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.508914,
        "recall": 0.560277,
        "f1": 0.52195,
        "accuracy": 0.560277,
        "main_score": 0.52195,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.417495,
        "recall": 0.551383,
        "f1": 0.453266,
        "accuracy": 0.551383,
        "main_score": 0.453266,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.00939,
        "recall": 0.011858,
        "f1": 0.009886,
        "accuracy": 0.011858,
        "main_score": 0.009886,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002729,
        "recall": 0.023715,
        "f1": 0.004335,
        "accuracy": 0.023715,
        "main_score": 0.004335,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 103.76058626174927,
  "kg_co2_emissions": 0.006465801177286454
}