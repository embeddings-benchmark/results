{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.149566,
        "mrr": 0.133366,
        "nAUC_map_max": -0.049904,
        "nAUC_map_std": 0.017833,
        "nAUC_map_diff1": 0.170031,
        "nAUC_mrr_max": -0.053788,
        "nAUC_mrr_std": 0.013054,
        "nAUC_mrr_diff1": 0.170975,
        "main_score": 0.133366,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.12122,
        "mrr": 0.106275,
        "nAUC_map_max": -0.063053,
        "nAUC_map_std": 0.064487,
        "nAUC_map_diff1": 0.149574,
        "nAUC_mrr_max": -0.044052,
        "nAUC_mrr_std": 0.047513,
        "nAUC_mrr_diff1": 0.162204,
        "main_score": 0.106275,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.099222,
        "mrr": 0.082658,
        "nAUC_map_max": -0.110116,
        "nAUC_map_std": 0.145779,
        "nAUC_map_diff1": 0.016884,
        "nAUC_mrr_max": -0.122903,
        "nAUC_mrr_std": 0.111941,
        "nAUC_mrr_diff1": 0.005797,
        "main_score": 0.082658,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.10642,
        "mrr": 0.087428,
        "nAUC_map_max": -0.116918,
        "nAUC_map_std": -0.073798,
        "nAUC_map_diff1": 0.057727,
        "nAUC_mrr_max": -0.129856,
        "nAUC_mrr_std": -0.095312,
        "nAUC_mrr_diff1": 0.051611,
        "main_score": 0.087428,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.114069,
        "mrr": 0.095829,
        "nAUC_map_max": -0.045639,
        "nAUC_map_std": 0.091512,
        "nAUC_map_diff1": 0.094098,
        "nAUC_mrr_max": -0.043439,
        "nAUC_mrr_std": 0.073808,
        "nAUC_mrr_diff1": 0.099607,
        "main_score": 0.095829,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.110165,
        "mrr": 0.093928,
        "nAUC_map_max": -0.014589,
        "nAUC_map_std": 0.166508,
        "nAUC_map_diff1": 0.084527,
        "nAUC_mrr_max": -0.014265,
        "nAUC_mrr_std": 0.168847,
        "nAUC_mrr_diff1": 0.083009,
        "main_score": 0.093928,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 1885.5920627117157,
  "kg_co2_emissions": 0.1551549384172426
}