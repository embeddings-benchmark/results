{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.37222595830531285,
                "f1": 0.34630136809477785,
                "main_score": 0.37222595830531285
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.03194351042367182,
                "f1": 0.012612010214639442,
                "main_score": 0.03194351042367182
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.1426361802286483,
                "f1": 0.1370260406613821,
                "main_score": 0.1426361802286483
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.3721923335574983,
                "f1": 0.3633553913878251,
                "main_score": 0.3721923335574983
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.10756556825823807,
                "f1": 0.09676431920229374,
                "main_score": 0.10756556825823807
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.3249831876260928,
                "f1": 0.3081889578269187,
                "main_score": 0.3249831876260928
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.4099529253530598,
                "f1": 0.3768768183180129,
                "main_score": 0.4099529253530598
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.4278076664425016,
                "f1": 0.37821948306671355,
                "main_score": 0.4278076664425016
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.3349024882313383,
                "f1": 0.2971809045584527,
                "main_score": 0.3349024882313383
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.738836583725622,
                "f1": 0.7216381047416814,
                "main_score": 0.738836583725622
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.4445191661062542,
                "f1": 0.4346583297093683,
                "main_score": 0.4445191661062542
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.26738399462004037,
                "f1": 0.2411896530001951,
                "main_score": 0.26738399462004037
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.38096839273705446,
                "f1": 0.3534443269387154,
                "main_score": 0.38096839273705446
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.4689307330195024,
                "f1": 0.43471640925142924,
                "main_score": 0.4689307330195024
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.2519838601210491,
                "f1": 0.22446286736401916,
                "main_score": 0.2519838601210491
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.13940820443846672,
                "f1": 0.13257747189396213,
                "main_score": 0.13940820443846672
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.3471082716879624,
                "f1": 0.32036974696095993,
                "main_score": 0.3471082716879624
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.06711499663752522,
                "f1": 0.054394410190965914,
                "main_score": 0.06711499663752522
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.3856758574310693,
                "f1": 0.3683183505458304,
                "main_score": 0.3856758574310693
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.3222595830531271,
                "f1": 0.3010972675771159,
                "main_score": 0.3222595830531271
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.45796906523201075,
                "f1": 0.4437143784350453,
                "main_score": 0.45796906523201075
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.29189643577673163,
                "f1": 0.2543718135312703,
                "main_score": 0.29189643577673163
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.34219905850706117,
                "f1": 0.32333592263041394,
                "main_score": 0.34219905850706117
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.08890383322125084,
                "f1": 0.07294310113130201,
                "main_score": 0.08890383322125084
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.04616677874915938,
                "f1": 0.015028537477535886,
                "main_score": 0.04616677874915938
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.031708137188971086,
                "f1": 0.01577141181582638,
                "main_score": 0.031708137188971086
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.15026899798251514,
                "f1": 0.14077395255366182,
                "main_score": 0.15026899798251514
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.360995292535306,
                "f1": 0.350877269083235,
                "main_score": 0.360995292535306
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.029959650302622726,
                "f1": 0.008064424547273696,
                "main_score": 0.029959650302622726
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.23301950235373234,
                "f1": 0.22477376205075852,
                "main_score": 0.23301950235373234
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.3613315400134499,
                "f1": 0.3299623898888715,
                "main_score": 0.3613315400134499
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.03813046402151983,
                "f1": 0.011769597223141248,
                "main_score": 0.03813046402151983
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.3966711499663752,
                "f1": 0.35921474753569216,
                "main_score": 0.3966711499663752
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.41079354404841967,
                "f1": 0.37577399618522006,
                "main_score": 0.41079354404841967
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.38211163416274374,
                "f1": 0.3489419275422068,
                "main_score": 0.38211163416274374
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.45198386012104913,
                "f1": 0.4271660225307043,
                "main_score": 0.45198386012104913
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.39485541358439813,
                "f1": 0.3747402102847154,
                "main_score": 0.39485541358439813
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.31819098856758576,
                "f1": 0.30120158288509724,
                "main_score": 0.31819098856758576
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.3544720914593141,
                "f1": 0.33745300635363035,
                "main_score": 0.3544720914593141
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.3689307330195024,
                "f1": 0.34469716196961053,
                "main_score": 0.3689307330195024
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.3883322125084062,
                "f1": 0.3605077034488826,
                "main_score": 0.3883322125084062
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.3753530598520511,
                "f1": 0.3521395700670493,
                "main_score": 0.3753530598520511
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.07905178211163418,
                "f1": 0.061635133263252456,
                "main_score": 0.07905178211163418
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.028480161398789516,
                "f1": 0.010163931337986962,
                "main_score": 0.028480161398789516
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.10501008742434433,
                "f1": 0.06858549418430471,
                "main_score": 0.10501008742434433
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.39465366509751176,
                "f1": 0.34962925973285747,
                "main_score": 0.39465366509751176
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.3750168123739071,
                "f1": 0.35031097269820466,
                "main_score": 0.3750168123739071
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.1610961667787492,
                "f1": 0.1588460972619252,
                "main_score": 0.1610961667787492
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.3611297915265636,
                "f1": 0.34599187163214734,
                "main_score": 0.3611297915265636
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.1885003362474781,
                "f1": 0.1509584388649328,
                "main_score": 0.1885003362474781
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.17219233355749833,
                "f1": 0.14538046039008337,
                "main_score": 0.17219233355749833
            }
        ]
    }
}