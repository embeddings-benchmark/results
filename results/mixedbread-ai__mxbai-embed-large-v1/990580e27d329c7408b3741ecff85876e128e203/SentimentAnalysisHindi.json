{
  "dataset_revision": "1beac1b941da76a9c51e3e5b39d230fde9a80983",
  "evaluation_time": 12.67518949508667,
  "kg_co2_emissions": 0.0005336227100781816,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.38818359375,
        "f1": 0.37057799220328025,
        "f1_weighted": 0.4016023419818633,
        "hf_subset": "default",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.37057799220328025,
        "scores_per_experiment": [
          {
            "accuracy": 0.4423828125,
            "f1": 0.4126073023380565,
            "f1_weighted": 0.45734558856406415
          },
          {
            "accuracy": 0.35400390625,
            "f1": 0.3476171321963258,
            "f1_weighted": 0.36641160622805047
          },
          {
            "accuracy": 0.41357421875,
            "f1": 0.38778024003588624,
            "f1_weighted": 0.4198227489687724
          },
          {
            "accuracy": 0.38427734375,
            "f1": 0.37738439243753913,
            "f1_weighted": 0.3971209838029622
          },
          {
            "accuracy": 0.3515625,
            "f1": 0.3285410027812465,
            "f1_weighted": 0.3514698243931121
          },
          {
            "accuracy": 0.3505859375,
            "f1": 0.3434026650465814,
            "f1_weighted": 0.3648631087681536
          },
          {
            "accuracy": 0.396484375,
            "f1": 0.3803123568459091,
            "f1_weighted": 0.4141933497510473
          },
          {
            "accuracy": 0.40234375,
            "f1": 0.3835181063677891,
            "f1_weighted": 0.42305850305597337
          },
          {
            "accuracy": 0.37451171875,
            "f1": 0.3630018366542515,
            "f1_weighted": 0.39166049256375246
          },
          {
            "accuracy": 0.412109375,
            "f1": 0.38161488732921806,
            "f1_weighted": 0.4300772137227452
          }
        ]
      }
    ]
  },
  "task_name": "SentimentAnalysisHindi"
}