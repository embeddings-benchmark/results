{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "task_name": "EmotionClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.51715,
        "f1": 0.47393,
        "f1_weighted": 0.535112,
        "scores_per_experiment": [
          {
            "accuracy": 0.5385,
            "f1": 0.485507,
            "f1_weighted": 0.558399
          },
          {
            "accuracy": 0.5385,
            "f1": 0.486311,
            "f1_weighted": 0.547503
          },
          {
            "accuracy": 0.5265,
            "f1": 0.477543,
            "f1_weighted": 0.547006
          },
          {
            "accuracy": 0.489,
            "f1": 0.460835,
            "f1_weighted": 0.51034
          },
          {
            "accuracy": 0.5265,
            "f1": 0.491109,
            "f1_weighted": 0.543741
          },
          {
            "accuracy": 0.535,
            "f1": 0.493117,
            "f1_weighted": 0.548327
          },
          {
            "accuracy": 0.5285,
            "f1": 0.478709,
            "f1_weighted": 0.550057
          },
          {
            "accuracy": 0.4795,
            "f1": 0.443373,
            "f1_weighted": 0.496708
          },
          {
            "accuracy": 0.5135,
            "f1": 0.46646,
            "f1_weighted": 0.527638
          },
          {
            "accuracy": 0.496,
            "f1": 0.456331,
            "f1_weighted": 0.521397
          }
        ],
        "main_score": 0.51715,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.50995,
        "f1": 0.456152,
        "f1_weighted": 0.533028,
        "scores_per_experiment": [
          {
            "accuracy": 0.527,
            "f1": 0.464356,
            "f1_weighted": 0.551433
          },
          {
            "accuracy": 0.5185,
            "f1": 0.454116,
            "f1_weighted": 0.535161
          },
          {
            "accuracy": 0.515,
            "f1": 0.457464,
            "f1_weighted": 0.539605
          },
          {
            "accuracy": 0.4975,
            "f1": 0.454612,
            "f1_weighted": 0.524227
          },
          {
            "accuracy": 0.5145,
            "f1": 0.468039,
            "f1_weighted": 0.53979
          },
          {
            "accuracy": 0.5015,
            "f1": 0.444877,
            "f1_weighted": 0.521836
          },
          {
            "accuracy": 0.5105,
            "f1": 0.453926,
            "f1_weighted": 0.537096
          },
          {
            "accuracy": 0.4935,
            "f1": 0.44755,
            "f1_weighted": 0.512587
          },
          {
            "accuracy": 0.519,
            "f1": 0.464642,
            "f1_weighted": 0.537304
          },
          {
            "accuracy": 0.5025,
            "f1": 0.451941,
            "f1_weighted": 0.53124
          }
        ],
        "main_score": 0.50995,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 18.56363606452942,
  "kg_co2_emissions": 0.0007548718977373466
}