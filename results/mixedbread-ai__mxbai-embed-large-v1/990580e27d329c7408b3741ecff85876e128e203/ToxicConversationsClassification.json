{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 14.738448858261108,
  "kg_co2_emissions": 0.0006293261610237188,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.67314453125,
        "ap": 0.12573236884420225,
        "ap_weighted": 0.12573236884420225,
        "f1": 0.5159381810827472,
        "f1_weighted": 0.7442600799622603,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.67314453125,
        "scores_per_experiment": [
          {
            "accuracy": 0.67578125,
            "ap": 0.12773933149005484,
            "ap_weighted": 0.12773933149005484,
            "f1": 0.5202846955002702,
            "f1_weighted": 0.7501955530967832
          },
          {
            "accuracy": 0.75537109375,
            "ap": 0.13802651963508483,
            "ap_weighted": 0.13802651963508483,
            "f1": 0.5639136283366378,
            "f1_weighted": 0.8071506735633411
          },
          {
            "accuracy": 0.7158203125,
            "ap": 0.13585672260802467,
            "ap_weighted": 0.13585672260802467,
            "f1": 0.5445006970430699,
            "f1_weighted": 0.7796559653931874
          },
          {
            "accuracy": 0.7509765625,
            "ap": 0.14427449407267115,
            "ap_weighted": 0.14427449407267115,
            "f1": 0.5664993226551917,
            "f1_weighted": 0.804552287844151
          },
          {
            "accuracy": 0.51611328125,
            "ap": 0.1082349242599445,
            "ap_weighted": 0.1082349242599445,
            "f1": 0.42769082748424475,
            "f1_weighted": 0.617057672567676
          },
          {
            "accuracy": 0.50634765625,
            "ap": 0.10432962526953324,
            "ap_weighted": 0.10432962526953324,
            "f1": 0.4197963752405339,
            "f1_weighted": 0.6084365882118606
          },
          {
            "accuracy": 0.76416015625,
            "ap": 0.11620068578231893,
            "ap_weighted": 0.11620068578231893,
            "f1": 0.5487461902604788,
            "f1_weighted": 0.8112010859254503
          },
          {
            "accuracy": 0.6494140625,
            "ap": 0.11475039732084995,
            "ap_weighted": 0.11475039732084995,
            "f1": 0.49829405567110485,
            "f1_weighted": 0.7300831052912251
          },
          {
            "accuracy": 0.6728515625,
            "ap": 0.11847407991544949,
            "ap_weighted": 0.11847407991544949,
            "f1": 0.5119174994877865,
            "f1_weighted": 0.7478446462846029
          },
          {
            "accuracy": 0.724609375,
            "ap": 0.14943690808809074,
            "ap_weighted": 0.14943690808809074,
            "f1": 0.5577385191481541,
            "f1_weighted": 0.7864232214443245
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}