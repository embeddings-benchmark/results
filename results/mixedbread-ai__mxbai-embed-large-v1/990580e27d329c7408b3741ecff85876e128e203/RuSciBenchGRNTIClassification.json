{
  "dataset_revision": "673a610d6d3dd91a547a0d57ae1b56f37ebbf6a1",
  "evaluation_time": 112.62466406822205,
  "kg_co2_emissions": null,
  "mteb_version": "1.19.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.221435546875,
        "f1": 0.2207432959131881,
        "f1_weighted": 0.22083963517991118,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.221435546875,
        "scores_per_experiment": [
          {
            "accuracy": 0.2451171875,
            "f1": 0.24550183227605404,
            "f1_weighted": 0.24550336555482338
          },
          {
            "accuracy": 0.212890625,
            "f1": 0.2130583198397948,
            "f1_weighted": 0.21319096159719245
          },
          {
            "accuracy": 0.1943359375,
            "f1": 0.19556101463999373,
            "f1_weighted": 0.19556204842922884
          },
          {
            "accuracy": 0.23681640625,
            "f1": 0.2350295740515891,
            "f1_weighted": 0.2351405587495632
          },
          {
            "accuracy": 0.2060546875,
            "f1": 0.20617887407242483,
            "f1_weighted": 0.20624223676400769
          },
          {
            "accuracy": 0.21044921875,
            "f1": 0.20932198184004627,
            "f1_weighted": 0.20944552011235196
          },
          {
            "accuracy": 0.23583984375,
            "f1": 0.2356888865875344,
            "f1_weighted": 0.23589040484944676
          },
          {
            "accuracy": 0.21240234375,
            "f1": 0.20933046580206968,
            "f1_weighted": 0.20945798666161244
          },
          {
            "accuracy": 0.22119140625,
            "f1": 0.21860146631982819,
            "f1_weighted": 0.21870592834801594
          },
          {
            "accuracy": 0.2392578125,
            "f1": 0.23916054370254564,
            "f1_weighted": 0.23925734073286906
          }
        ]
      }
    ]
  },
  "task_name": "RuSciBenchGRNTIClassification"
}