{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 81.75109648704529,
  "kg_co2_emissions": 0.004580179292526561,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.033203125,
        "f1": 0.025990513392857142,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.025990513392857142,
        "precision": 0.023990885416666666,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00322265625,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.00322265625,
        "precision": 0.002766927083333333,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.005533854166666666,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.005533854166666666,
        "precision": 0.00537109375,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.071182396606575e-06,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 2.071182396606575e-06,
        "precision": 1.0366905520169851e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0034191528150467106,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.0034191528150467106,
        "precision": 0.003210730168356002,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.8828125e-05,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 4.8828125e-05,
        "precision": 2.5040064102564102e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0013671875,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.0013671875,
        "precision": 0.001220703125,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001523170273364228,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.001523170273364228,
        "precision": 0.0013317700135479934,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0036690848214285714,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.0036690848214285714,
        "precision": 0.003099468954248366,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0029296875,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0029296875,
        "precision": 0.00263671875,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00048828125,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.00048828125,
        "precision": 0.0003255208333333333,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0037307518115942025,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0037307518115942025,
        "precision": 0.0032182173295454545,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0007068452380952381,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0007068452380952381,
        "precision": 0.0005170036764705882,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0038973721590909085,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0038973721590909085,
        "precision": 0.003504422010281385,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0018891490120456467,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0018891490120456467,
        "precision": 0.0015428617538803925,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.50758111933798e-05,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 6.50758111933798e-05,
        "precision": 3.321192286036036e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008219401041666667,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.0008219401041666667,
        "precision": 0.0005784254807692308,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 4.953577898550725e-05,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 4.953577898550725e-05,
        "precision": 2.5118244498959262e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0019055405592469546,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0019055405592469546,
        "precision": 0.0016130426286676287,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.650297619047619e-05,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 4.650297619047619e-05,
        "precision": 2.381859756097561e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016012573868299188,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.0016012573868299188,
        "precision": 0.001373942173052987,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.017614135175715712,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.017614135175715712,
        "precision": 0.01518259843455156,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006172651615359948,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.006172651615359948,
        "precision": 0.005726220141882184,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.010491267814447668,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.010491267814447668,
        "precision": 0.00934235030922039,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.143935236004391e-06,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 2.143935236004391e-06,
        "precision": 1.0731456043956044e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008102485120471362,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.008102485120471362,
        "precision": 0.00768225522232796,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0015468187638427464,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0015468187638427464,
        "precision": 0.001302193072709085,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.012761262175324676,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.012761262175324676,
        "precision": 0.011745876736111112,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0022195542659715324,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0022195542659715324,
        "precision": 0.002097850608592796,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0078101566682085835,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.0078101566682085835,
        "precision": 0.0068895000845484635,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01139000972985348,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.01139000972985348,
        "precision": 0.010561541323260072,
        "recall": 0.015625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009957107843137254,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0009957107843137254,
        "precision": 0.0009862314356435644,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008335110276325976,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.008335110276325976,
        "precision": 0.007213202698037257,
        "recall": 0.015625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000732421875,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.000732421875,
        "precision": 0.0005307404891304348,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01410113324175824,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.01410113324175824,
        "precision": 0.012986801609848483,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0076450892857142854,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.0076450892857142854,
        "precision": 0.006829677483974359,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.5431315104166665e-06,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 2.5431315104166665e-06,
        "precision": 1.2732235984354628e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0027452256944444442,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0027452256944444442,
        "precision": 0.0024445976307189542,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001984126984126984,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.001984126984126984,
        "precision": 0.0016620342548076923,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.001220703125,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.001220703125,
        "precision": 0.0011160714285714285,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.006813006722085386,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.006813006722085386,
        "precision": 0.006441269126912692,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002308477728724223,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.002308477728724223,
        "precision": 0.0021514332371298035,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003888788910795651,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.003888788910795651,
        "precision": 0.0034752125676135934,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.2841796875,
        "f1": 0.26611936240842493,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.26611936240842493,
        "precision": 0.2599706608495671,
        "recall": 0.2841796875
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.02820919557419314,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.02820919557419314,
        "precision": 0.026280218169788795,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.2666015625,
        "f1": 0.246475047210039,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.246475047210039,
        "precision": 0.2396243811527015,
        "recall": 0.2666015625
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.022815015474460538,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.022815015474460538,
        "precision": 0.019074647466532382,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.2734375,
        "f1": 0.2488375586721175,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2488375586721175,
        "precision": 0.23992664536262034,
        "recall": 0.2734375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.276369463869464e-06,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 2.276369463869464e-06,
        "precision": 1.1395128354725787e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.15799716638717667,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.15799716638717667,
        "precision": 0.15249653986329703,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.043972330837565216,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.043972330837565216,
        "precision": 0.038723254284777714,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.11899195035241397,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11899195035241397,
        "precision": 0.1106676299233042,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02715975849749979,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.02715975849749979,
        "precision": 0.024141327660013867,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001231449287652646,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001231449287652646,
        "precision": 0.0011214608757540467,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.032630865047857234,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.032630865047857234,
        "precision": 0.0281729809903638,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0028537555790462766,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0028537555790462766,
        "precision": 0.002579922703138997,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1181640625,
        "f1": 0.10959136891754077,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.10959136891754077,
        "precision": 0.10771608142786675,
        "recall": 0.1181640625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03545847526316276,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.03545847526316276,
        "precision": 0.03189393608705132,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0002244971264367816,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0002244971264367816,
        "precision": 0.0001258263221153846,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.2685546875,
        "f1": 0.2494660760410682,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2494660760410682,
        "precision": 0.24336049163255044,
        "recall": 0.2685546875
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.13088495163690475,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.13088495163690475,
        "precision": 0.12109972228858097,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.15125558035714284,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.15125558035714284,
        "precision": 0.14386393229166666,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.17227427681361007,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.17227427681361007,
        "precision": 0.16649517759972118,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00019531249999999998,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.00019531249999999998,
        "precision": 0.00010384261877828055,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005827484147796647,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.005827484147796647,
        "precision": 0.0051411809948313176,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.2890625,
        "f1": 0.26372684390262513,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.26372684390262513,
        "precision": 0.254378600457702,
        "recall": 0.2890625
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.029823822096858882,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.029823822096858882,
        "precision": 0.02794302322351956,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.3193359375,
        "f1": 0.2924228295347744,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2924228295347744,
        "precision": 0.2828962405866703,
        "recall": 0.3193359375
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.02110530809786644,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.02110530809786644,
        "precision": 0.017267712182119352,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.41796875,
        "f1": 0.377814812140984,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.377814812140984,
        "precision": 0.3633867272050866,
        "recall": 0.41796875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.6429296346414075e-06,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 2.6429296346414075e-06,
        "precision": 1.3232554200542005e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.16885128659386617,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.16885128659386617,
        "precision": 0.16210493353611588,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.2041015625,
        "f1": 0.1598243607520951,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.1598243607520951,
        "precision": 0.14667728504445257,
        "recall": 0.2041015625
      },
      {
        "accuracy": 0.146484375,
        "f1": 0.12194177350427352,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.12194177350427352,
        "precision": 0.11351798488787493,
        "recall": 0.146484375
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.06910119945044904,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06910119945044904,
        "precision": 0.06285729786706348,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0001445427558910162,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0001445427558910162,
        "precision": 7.76436096203538e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.09801663701307543,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.09801663701307543,
        "precision": 0.08869818332708959,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011484925176056338,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0011484925176056338,
        "precision": 0.0010699473359777015,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.1286875598579923,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1286875598579923,
        "precision": 0.126227562401649,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.04286512155080312,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.04286512155080312,
        "precision": 0.03752491840099776,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00048828125,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00048828125,
        "precision": 0.0003255208333333333,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.3427734375,
        "f1": 0.3128014942956349,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.3128014942956349,
        "precision": 0.3026264149969143,
        "recall": 0.3427734375
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.13679998929022366,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.13679998929022366,
        "precision": 0.12864806453673638,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.1632531067767118,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1632531067767118,
        "precision": 0.15521286789956368,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.2138671875,
        "f1": 0.19212255624026459,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.19212255624026459,
        "precision": 0.1856878681189234,
        "recall": 0.2138671875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001065340909090909,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.001065340909090909,
        "precision": 0.0007300967261904762,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003737828351449275,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.003737828351449275,
        "precision": 0.003155913044008587,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.09196942365260802,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.09196942365260802,
        "precision": 0.0833116901150201,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.10881311562083856,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.10881311562083856,
        "precision": 0.1000240030152933,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.10773242689026377,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.10773242689026377,
        "precision": 0.09777370479665953,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.00952095332280281,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.00952095332280281,
        "precision": 0.006643724411581838,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.11532853778369727,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.11532853778369727,
        "precision": 0.10685232832352846,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014553885412860795,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.0014553885412860795,
        "precision": 0.0009192264441287878,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.08448824314676129,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.08448824314676129,
        "precision": 0.07542664624918785,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0070343040856216624,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.0070343040856216624,
        "precision": 0.006321924603174603,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.0633037725579097,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.0633037725579097,
        "precision": 0.0528800088882566,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004927542544730044,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.004927542544730044,
        "precision": 0.003913424534223045,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0011849677321087923,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0011849677321087923,
        "precision": 0.0006504039327227343,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004818949238788587,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.004818949238788587,
        "precision": 0.004191468253968254,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00047956194196428575,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.00047956194196428575,
        "precision": 0.00025859154985919097,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.10319225793383102,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.10319225793383102,
        "precision": 0.09284489822631675,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0049803544449079475,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.0049803544449079475,
        "precision": 0.004551643941319879,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00012428977272727271,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.00012428977272727271,
        "precision": 6.362139168432203e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1435546875,
        "f1": 0.10676427627684484,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.10676427627684484,
        "precision": 0.09889840903623298,
        "recall": 0.1435546875
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.08141190258833175,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.08141190258833175,
        "precision": 0.07175175512655885,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.09098696622737472,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.09098696622737472,
        "precision": 0.07638325995062278,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.125,
        "f1": 0.08589010736296766,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.08589010736296766,
        "precision": 0.0759750764656889,
        "recall": 0.125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0037933885005482456,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0037933885005482456,
        "precision": 0.003529762151053735,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.00259914320845749,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00259914320845749,
        "precision": 0.0020067481612483485,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.265625,
        "f1": 0.23139953172912156,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.23139953172912156,
        "precision": 0.22035194847972805,
        "recall": 0.265625
      },
      {
        "accuracy": 0.2958984375,
        "f1": 0.2654991049861974,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2654991049861974,
        "precision": 0.2551317551805833,
        "recall": 0.2958984375
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.02437140522022284,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.02437140522022284,
        "precision": 0.02322141254104797,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.026070776675086435,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.026070776675086435,
        "precision": 0.021757721048594247,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.3095703125,
        "f1": 0.27199772612370265,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.27199772612370265,
        "precision": 0.25952172912750626,
        "recall": 0.3095703125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.456858407079646e-06,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 3.456858407079646e-06,
        "precision": 1.731493794326241e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.185546875,
        "f1": 0.15952383271979648,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.15952383271979648,
        "precision": 0.15119443492745788,
        "recall": 0.185546875
      },
      {
        "accuracy": 0.09375,
        "f1": 0.06295586420606036,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.06295586420606036,
        "precision": 0.055397812445290615,
        "recall": 0.09375
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.1239262907269539,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1239262907269539,
        "precision": 0.11432910675698138,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.2421875,
        "f1": 0.18687996031746032,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.18687996031746032,
        "precision": 0.16924257925234487,
        "recall": 0.2421875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001196116213336223,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001196116213336223,
        "precision": 0.0010999043782552083,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.04976209956610224,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.04976209956610224,
        "precision": 0.04641836854296643,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0015380318515666959,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0015380318515666959,
        "precision": 0.001297848951370321,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.15912729599493175,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.15912729599493175,
        "precision": 0.15575471891389858,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.050306500313480496,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.050306500313480496,
        "precision": 0.046346765023522835,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.6041666666666666e-06,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 2.6041666666666666e-06,
        "precision": 1.3038217623497997e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.2744140625,
        "f1": 0.239376880427834,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.239376880427834,
        "precision": 0.22890469127169888,
        "recall": 0.2744140625
      },
      {
        "accuracy": 0.166015625,
        "f1": 0.13607982358239348,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.13607982358239348,
        "precision": 0.125470455109127,
        "recall": 0.166015625
      },
      {
        "accuracy": 0.1875,
        "f1": 0.16022591322888338,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.16022591322888338,
        "precision": 0.1518024755968435,
        "recall": 0.1875
      },
      {
        "accuracy": 0.205078125,
        "f1": 0.18021963192031176,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.18021963192031176,
        "precision": 0.17253705255754823,
        "recall": 0.205078125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.127587145969499e-06,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 2.127587145969499e-06,
        "precision": 1.064953653217012e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008161025839222614,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.0008161025839222614,
        "precision": 0.0005782112658126072,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.026462414533427306,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.026462414533427306,
        "precision": 0.026122515750144196,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.03058060662745412,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.03058060662745412,
        "precision": 0.02988409728573033,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.013349336036895674,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.013349336036895674,
        "precision": 0.012371284881498471,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.024658203125,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.024658203125,
        "precision": 0.024553571428571428,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.028799361807174306,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.028799361807174306,
        "precision": 0.02859865202536537,
        "recall": 0.03125
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.08602663070436507,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.08602663070436507,
        "precision": 0.0785981677827381,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.021964798850574712,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.021964798850574712,
        "precision": 0.02128678234382566,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0003757821781382186,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.0003757821781382186,
        "precision": 0.00022065112311143658,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.05545331946699134,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.05545331946699134,
        "precision": 0.05254293774801587,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011589537860036004,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.0011589537860036004,
        "precision": 0.0010766419820099256,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.012585409112217998,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.012585409112217998,
        "precision": 0.011403266636367858,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009856868103568217,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.0009856868103568217,
        "precision": 0.000981135542674731,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0051020869129122775,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.0051020869129122775,
        "precision": 0.004644808314487773,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.04766920758773367,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.04766920758773367,
        "precision": 0.04613619565400445,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006686878933089321,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.0006686878933089321,
        "precision": 0.0004971466651763151,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.009665937585522715,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.009665937585522715,
        "precision": 0.008607894655257936,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.027306637047847984,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.027306637047847984,
        "precision": 0.026534665609903384,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.02557401294640331,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.02557401294640331,
        "precision": 0.025184538820974055,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.09375,
        "f1": 0.07301974826388889,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.07301974826388889,
        "precision": 0.06707361006934404,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.022170799365942028,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.022170799365942028,
        "precision": 0.02199051589947461,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003941977896341464,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.003941977896341464,
        "precision": 0.003547273938150651,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008480418197215072,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.008480418197215072,
        "precision": 0.007891618707048395,
        "recall": 0.015625
      },
      {
        "accuracy": 0.279296875,
        "f1": 0.25735832093253963,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.25735832093253963,
        "precision": 0.2489181219362745,
        "recall": 0.279296875
      },
      {
        "accuracy": 0.4375,
        "f1": 0.3973818824404762,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3973818824404762,
        "precision": 0.38185221354166665,
        "recall": 0.4375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019635566130703667,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.019635566130703667,
        "precision": 0.01789919439151952,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.326171875,
        "f1": 0.3008304873295108,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3008304873295108,
        "precision": 0.29249057962436864,
        "recall": 0.326171875
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.0220822671228146,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0220822671228146,
        "precision": 0.018207872655714927,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.727828212290503e-06,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 2.727828212290503e-06,
        "precision": 1.3658216783216783e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1875,
        "f1": 0.16785601978361375,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.16785601978361375,
        "precision": 0.1610748951569264,
        "recall": 0.1875
      },
      {
        "accuracy": 0.26171875,
        "f1": 0.21351145057199744,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.21351145057199744,
        "precision": 0.19660407788825757,
        "recall": 0.26171875
      },
      {
        "accuracy": 0.140625,
        "f1": 0.11718765301222613,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11718765301222613,
        "precision": 0.10980238631739186,
        "recall": 0.140625
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.09154884207565098,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09154884207565098,
        "precision": 0.08345670036343865,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006630811427086693,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0006630811427086693,
        "precision": 0.0004943206628915934,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.13291684986020924,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.13291684986020924,
        "precision": 0.12187306237599208,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0002517917556980057,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0002517917556980057,
        "precision": 0.0001396157070778279,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.1191763176992936,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1191763176992936,
        "precision": 0.11647497821283487,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.06726106102061435,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.06726106102061435,
        "precision": 0.062022076231060604,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.0911312849162012e-05,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 1.0911312849162012e-05,
        "precision": 5.486306179775281e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.359375,
        "f1": 0.32995721726190474,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.32995721726190474,
        "precision": 0.31896391369047616,
        "recall": 0.359375
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.13081817960593925,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.13081817960593925,
        "precision": 0.12256928049164378,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.14181835306951168,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.14181835306951168,
        "precision": 0.13332691912972086,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.2041015625,
        "f1": 0.18095901688315336,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.18095901688315336,
        "precision": 0.1745002839888366,
        "recall": 0.2041015625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1486523652365235e-06,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 2.1486523652365235e-06,
        "precision": 1.0755093612334803e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006533585409252669,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0006533585409252669,
        "precision": 0.0004894410629453682,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0011971432715676136,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0011971432715676136,
        "precision": 0.0010936754639796948,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001654836678778211,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.001654836678778211,
        "precision": 0.0010679587339743589,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011419132681255524,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0011419132681255524,
        "precision": 0.0008150989790836653,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.044451871657754e-05,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 1.044451871657754e-05,
        "precision": 5.250336021505377e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.07715916895604395,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.07715916895604395,
        "precision": 0.06655762942512532,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003114226889683351,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0003114226889683351,
        "precision": 0.00016924291409809702,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004912271398944193,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0004912271398944193,
        "precision": 0.00032699600327291034,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00041706309360021304,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.00041706309360021304,
        "precision": 0.0002574968279018108,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.04939553176857864,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.04939553176857864,
        "precision": 0.042136346726190474,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.5710059370298733e-05,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 2.5710059370298733e-05,
        "precision": 1.2972982169593032e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010451124916357524,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.010451124916357524,
        "precision": 0.008500583988023372,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016821831783244755,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.0016821831783244755,
        "precision": 0.0014928304183567745,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006098157541518767,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.006098157541518767,
        "precision": 0.004830503971143723,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012263600688082552,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.012263600688082552,
        "precision": 0.010569438442588112,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0016536137452860958,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0016536137452860958,
        "precision": 0.0011226899442616958,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.01441521484030675,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.01441521484030675,
        "precision": 0.012631688836710179,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0024513711734693877,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.0024513711734693877,
        "precision": 0.001958133012820513,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0002495810846100279,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.0002495810846100279,
        "precision": 0.00014223675678371906,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.07305225156787656,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.07305225156787656,
        "precision": 0.06363464822937479,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 3.708032589676291e-05,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 3.708032589676291e-05,
        "precision": 1.8662315472751355e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0018730644707207207,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0018730644707207207,
        "precision": 0.0015551017992424241,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.005888787499459857,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.005888787499459857,
        "precision": 0.005573033436254458,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.1716292388167388,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.1716292388167388,
        "precision": 0.16500831886574074,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.2041015625,
        "f1": 0.18164409805536047,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.18164409805536047,
        "precision": 0.17537640651631647,
        "recall": 0.2041015625
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.030262046403997378,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.030262046403997378,
        "precision": 0.02954229720308399,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.17367508503386955,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.17367508503386955,
        "precision": 0.16767292580409357,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.01723029451998481,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.01723029451998481,
        "precision": 0.01487814873874199,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.16805097571699135,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.16805097571699135,
        "precision": 0.16039598507988723,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006579431684334511,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0006579431684334511,
        "precision": 0.0004917442375886524,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004840959821428572,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.004840959821428572,
        "precision": 0.0039186963848039215,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.09531842915507628,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.09531842915507628,
        "precision": 0.08922122583887868,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.005403645833333333,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.005403645833333333,
        "precision": 0.004991319444444444,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008026415322732287,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.008026415322732287,
        "precision": 0.007635573081313664,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006899675844988344,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0006899675844988344,
        "precision": 0.0005079992285602168,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.15234996358915903,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.15234996358915903,
        "precision": 0.1487632293583322,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005235770121471046,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.005235770121471046,
        "precision": 0.004777356282716988,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 7.599708171206226e-06,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 7.599708171206226e-06,
        "precision": 3.814697265625e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.17628409083321855,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.17628409083321855,
        "precision": 0.16917695545014882,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.134765625,
        "f1": 0.11126509347729477,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.11126509347729477,
        "precision": 0.10345126787643082,
        "recall": 0.134765625
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.12872577024690995,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.12872577024690995,
        "precision": 0.1208191829313706,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.3759765625,
        "f1": 0.3498400227159993,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.3498400227159993,
        "precision": 0.3412646842090201,
        "recall": 0.3759765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009462553879310345,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0009462553879310345,
        "precision": 0.0006045386904761904,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005411998600187938,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.005411998600187938,
        "precision": 0.004884789206557793,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.045125008455086574,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.045125008455086574,
        "precision": 0.039593772113303366,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.1875,
        "f1": 0.14892190600198413,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.14892190600198413,
        "precision": 0.1353062220982143,
        "recall": 0.1875
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.3441267512374447e-05,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 1.3441267512374447e-05,
        "precision": 6.7529242083096514e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0947265625,
        "f1": 0.06645995567698232,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.06645995567698232,
        "precision": 0.05875189182562229,
        "recall": 0.0947265625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001957007952286282,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.001957007952286282,
        "precision": 0.001662101593625498,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.23046875,
        "f1": 0.1881983413721695,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.1881983413721695,
        "precision": 0.17387456835699022,
        "recall": 0.23046875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.5972406914893616e-06,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 2.5972406914893616e-06,
        "precision": 1.3003495339547271e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0032585470085470082,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0032585470085470082,
        "precision": 0.003126672196061644,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004278087577041257,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.004278087577041257,
        "precision": 0.004124955728135468,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.10413975130772006,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.10413975130772006,
        "precision": 0.09590932342397188,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0016276041666666665,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0016276041666666665,
        "precision": 0.00146484375,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.234375,
        "f1": 0.1928673594200938,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.1928673594200938,
        "precision": 0.17823935504599564,
        "recall": 0.234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010202869486106232,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0010202869486106232,
        "precision": 0.000998608445037307,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 6.711769759450172e-06,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 6.711769759450172e-06,
        "precision": 3.367456896551724e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06618347378580054,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.06618347378580054,
        "precision": 0.05958951259244227,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.07375625495742683,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.07375625495742683,
        "precision": 0.0670723157051282,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004098767031363736,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.004098767031363736,
        "precision": 0.003758496577196782,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0029651988636363634,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0029651988636363634,
        "precision": 0.002947771990740741,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.00446194946428463,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.00446194946428463,
        "precision": 0.00402678546189507,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.0052618069815196e-06,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 2.0052618069815196e-06,
        "precision": 1.0036613566289826e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.10353266810106773,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.10353266810106773,
        "precision": 0.09924358617500742,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.1220703125,
        "f1": 0.106787954883658,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.106787954883658,
        "precision": 0.10183333974753696,
        "recall": 0.1220703125
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.05396485575937692,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.05396485575937692,
        "precision": 0.04927983192648468,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.1162109375,
        "f1": 0.10392984111657302,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.10392984111657302,
        "precision": 0.09967117500783207,
        "recall": 0.1162109375
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.047137622577075704,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.047137622577075704,
        "precision": 0.03986065831897452,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.08654203094417606,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.08654203094417606,
        "precision": 0.08129201229687498,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.0478641456582633,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.0478641456582633,
        "precision": 0.044013263483478324,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.08593092054955138,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.08593092054955138,
        "precision": 0.08042904661864746,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0018641725155971478,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.0018641725155971478,
        "precision": 0.001496707579876918,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004999274499022483,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.0004999274499022483,
        "precision": 0.00033136135105637994,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.009365751982968986,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.009365751982968986,
        "precision": 0.00823098354775088,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0030837613673091614,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.0030837613673091614,
        "precision": 0.0026588261172524564,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.14951975187929922,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.14951975187929922,
        "precision": 0.14295139824293582,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006644161888690089,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0006644161888690089,
        "precision": 0.0003985950187517203,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007076719576719577,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.007076719576719577,
        "precision": 0.0063777483739441525,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.109375,
        "f1": 0.09584175197557471,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.09584175197557471,
        "precision": 0.09132367198773447,
        "recall": 0.109375
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.11457061992038099,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.11457061992038099,
        "precision": 0.1111773943928753,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.205078125,
        "f1": 0.18007760277406415,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.18007760277406415,
        "precision": 0.17038671099950395,
        "recall": 0.205078125
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.0826492173573975,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.0826492173573975,
        "precision": 0.07801164899553571,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0018948478660081054,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0018948478660081054,
        "precision": 0.0015050410594699113,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004727066408696592,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.004727066408696592,
        "precision": 0.0038759314441658803,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.026529275629586936,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.026529275629586936,
        "precision": 0.02356939383646245,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.04368697316364933,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.04368697316364933,
        "precision": 0.037782813089916295,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00013308152444091925,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00013308152444091925,
        "precision": 7.06296097550113e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2158203125,
        "f1": 0.1673332093253968,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.1673332093253968,
        "precision": 0.15129355778769843,
        "recall": 0.2158203125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001972501240079365,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.001972501240079365,
        "precision": 0.0019628616325457694,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06326455805022828,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.06326455805022828,
        "precision": 0.05507331240204809,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006543353007307476,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0006543353007307476,
        "precision": 0.0004899308488175675,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002544202302631579,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.002544202302631579,
        "precision": 0.0023328993055555555,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.126953125,
        "f1": 0.0904010919344937,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.0904010919344937,
        "precision": 0.08136487129407051,
        "recall": 0.126953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017918442234848484,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0017918442234848484,
        "precision": 0.0015512687562904037,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019559638444767444,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0019559638444767444,
        "precision": 0.0019545464883551677,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.06897233163922474,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.06897233163922474,
        "precision": 0.06129126523815748,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002683839597902098,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.002683839597902098,
        "precision": 0.002482129301619433,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.8923579415791874e-05,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 5.8923579415791874e-05,
        "precision": 3.0284926470588236e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.06791912002410497,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.06791912002410497,
        "precision": 0.06213015448240751,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009790473918575063,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0009790473918575063,
        "precision": 0.0009778065286624204,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03585571211604176,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.03585571211604176,
        "precision": 0.03339781449362041,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0034924882680025084,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0034924882680025084,
        "precision": 0.00291977662937084,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00202531533446712,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.00202531533446712,
        "precision": 0.0016087269776052717,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007928894203084671,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.007928894203084671,
        "precision": 0.007222209301221507,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0006510416666666666,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.00048828125,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011190318302387267,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0011190318302387267,
        "precision": 0.0010505022321428573,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009765625,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0009765625,
        "precision": 0.00068359375,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0014875545058139535,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0014875545058139535,
        "precision": 0.0013135723039215685,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.833613119834711e-05,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 3.833613119834711e-05,
        "precision": 1.9362877155172412e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.018084368170153728,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.018084368170153728,
        "precision": 0.016863564495400434,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00027901785714285713,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.00027901785714285713,
        "precision": 0.00016276041666666666,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.019875372023809523,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.019875372023809523,
        "precision": 0.01785481770833333,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.7901785714285713e-05,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 2.7901785714285713e-05,
        "precision": 1.4153079710144928e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.010402264322247827,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.010402264322247827,
        "precision": 0.009130740153123679,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.001035748106060606,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.001035748106060606,
        "precision": 0.001007080078125,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.001953125,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.001953125,
        "precision": 0.001953125,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004497931985294117,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.004497931985294117,
        "precision": 0.0040071614583333335,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.008698776533018867,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.008698776533018867,
        "precision": 0.007572058475378788,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.04558454241071428,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.04558454241071428,
        "precision": 0.039619760664682535,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.001953125,
        "f1": 8.23525432900433e-05,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 8.23525432900433e-05,
        "precision": 4.280846099963847e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00022386695906432747,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.00022386695906432747,
        "precision": 0.00012550891285211267,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.00856950209159515,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.00856950209159515,
        "precision": 0.007438393684126803,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015404068026897567,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0015404068026897567,
        "precision": 0.0013406220067049808,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010813090619660477,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.010813090619660477,
        "precision": 0.009775330987842164,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03631959945436508,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.03631959945436508,
        "precision": 0.033074685801630435,
        "recall": 0.046875
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.08724888392857141,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.08724888392857141,
        "precision": 0.07942630828373015,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.3690668948926721e-05,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 1.3690668948926721e-05,
        "precision": 6.879046189453911e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.04299696773559365,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.04299696773559365,
        "precision": 0.03960468242694805,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0024064704900839053,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0024064704900839053,
        "precision": 0.0022017518495986927,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.11693781478937729,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.11693781478937729,
        "precision": 0.10743505084325397,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.797219162995594e-05,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 6.797219162995594e-05,
        "precision": 3.5110690289046654e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005359387828407225,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.005359387828407225,
        "precision": 0.004854980702042523,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.2197265625,
        "f1": 0.1848491623393967,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.1848491623393967,
        "precision": 0.17226678757440475,
        "recall": 0.2197265625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006931314872808576,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0006931314872808576,
        "precision": 0.0005095115494878191,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.09691723315746753,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09691723315746753,
        "precision": 0.08867126603245465,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0024496822033898305,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0024496822033898305,
        "precision": 0.002282801418439716,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019919820062171208,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0019919820062171208,
        "precision": 0.0019727553547033566,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00032433546335200746,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.00032433546335200746,
        "precision": 0.00018573707673580136,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.0737594274215368,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.0737594274215368,
        "precision": 0.06852940150669642,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.05194414768748409,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.05194414768748409,
        "precision": 0.04823999649439102,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004027573672413625,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.004027573672413625,
        "precision": 0.003643822540306915,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00761645644556495,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.00761645644556495,
        "precision": 0.007065367808539746,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.9191350276015972e-05,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 2.9191350276015972e-05,
        "precision": 1.4787800879350176e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0014183407738095238,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.0014183407738095238,
        "precision": 0.0009765625,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000994964262508122,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.000994964262508122,
        "precision": 0.0006768120659722222,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00014221783980582523,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.00014221783980582523,
        "precision": 7.647652911324786e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00097886843270366,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.00097886843270366,
        "precision": 0.0009777168291962175,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00027901785714285713,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.00027901785714285713,
        "precision": 0.00016276041666666666,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.01132633831718741,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.01132633831718741,
        "precision": 0.00958489512315637,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004836309523809524,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.0004836309523809524,
        "precision": 0.00029296875,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.024469656328623586,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.024469656328623586,
        "precision": 0.023011546084537645,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.52147622242099e-05,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 2.52147622242099e-05,
        "precision": 1.274258098618138e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.325432318449768e-05,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 3.325432318449768e-05,
        "precision": 1.6852322567783093e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006513589607291427,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.006513589607291427,
        "precision": 0.005667170328363723,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015492614777734576,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0015492614777734576,
        "precision": 0.0011175925539608366,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0072785061991647495,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.0072785061991647495,
        "precision": 0.006688902537150605,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0011937052952677952,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.0011937052952677952,
        "precision": 0.0007990348991375892,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.00266934820597967,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.00266934820597967,
        "precision": 0.0020835802735028617,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.000919353903609677,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.000919353903609677,
        "precision": 0.0006310780132024203,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006086179476913716,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.006086179476913716,
        "precision": 0.005684037010272319,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0011067708333333333,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.0011067708333333333,
        "precision": 0.0010463169642857143,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001589483701205804,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.001589483701205804,
        "precision": 0.0013388447377873564,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.008176888967583508,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.008176888967583508,
        "precision": 0.007010027258440344,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.5365259740259742e-05,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 2.5365259740259742e-05,
        "precision": 1.2849506578947368e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 9.773744413843276e-06,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 9.773744413843276e-06,
        "precision": 4.901223965677519e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0013020833333333333,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.0009765625,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.17096026358801716,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.17096026358801716,
        "precision": 0.16225579975579973,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.2099609375,
        "f1": 0.18787156789799253,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.18787156789799253,
        "precision": 0.18010029846455627,
        "recall": 0.2099609375
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.08927021353821538,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.08927021353821538,
        "precision": 0.08267021877861722,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.205078125,
        "f1": 0.18532794388314536,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.18532794388314536,
        "precision": 0.17801321399954212,
        "recall": 0.205078125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.04298682300262034,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.04298682300262034,
        "precision": 0.03570119609066463,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.16876220274657772,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.16876220274657772,
        "precision": 0.16109908447933768,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.020054459564957612,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.020054459564957612,
        "precision": 0.01766398833839091,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.1505425347222222,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.1505425347222222,
        "precision": 0.1411888485863095,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0010583410024350391,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.0010583410024350391,
        "precision": 0.000709795426907322,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.15760315245272186,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.15760315245272186,
        "precision": 0.14642868022564137,
        "recall": 0.189453125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012817654722862616,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.0012817654722862616,
        "precision": 0.0011420468729368852,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.010509856896575647,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.010509856896575647,
        "precision": 0.009146640349097176,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0016276041666666665,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.0016276041666666665,
        "precision": 0.00146484375,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.008652627910911042,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.008652627910911042,
        "precision": 0.008076329385080645,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017949695858457018,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0017949695858457018,
        "precision": 0.0015528650778847894,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.009360390871235854,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.009360390871235854,
        "precision": 0.0081683935989314,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.201171875,
        "f1": 0.17822562369933273,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.17822562369933273,
        "precision": 0.17035355220725792,
        "recall": 0.201171875
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.1379763404066976,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.1379763404066976,
        "precision": 0.13173660694412648,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.20684911334325395,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.20684911334325395,
        "precision": 0.1973935081845238,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.171875,
        "f1": 0.14999767485119048,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.14999767485119048,
        "precision": 0.142454514461537,
        "recall": 0.171875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.003323321937596302,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.003323321937596302,
        "precision": 0.0031753351658950616,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003843537454532885,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.003843537454532885,
        "precision": 0.003452669834505772,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04470647433652948,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.04470647433652948,
        "precision": 0.04057220855316558,
        "recall": 0.0625
      },
      {
        "accuracy": 0.072265625,
        "f1": 0.0545372812950938,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.0545372812950938,
        "precision": 0.0498644575017507,
        "recall": 0.072265625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.4691845764854616e-06,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 2.4691845764854616e-06,
        "precision": 1.2361550632911393e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.051601727312919565,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.051601727312919565,
        "precision": 0.047209736681380086,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010430592691622104,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0010430592691622104,
        "precision": 0.0010103376240744287,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.06144517916978855,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.06144517916978855,
        "precision": 0.053297539719012604,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.245923913043478e-05,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 4.245923913043478e-05,
        "precision": 2.170138888888889e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0017621050824175824,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0017621050824175824,
        "precision": 0.0015367492330081813,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08940359228445166,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.08940359228445166,
        "precision": 0.08156040736607142,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003009626714323456,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.003009626714323456,
        "precision": 0.0029700312580618056,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.067170519367785,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.067170519367785,
        "precision": 0.06032205099587912,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000988491505531282,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.000988491505531282,
        "precision": 0.0009825453314112277,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.08098493303571427,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.08098493303571427,
        "precision": 0.07196082811445681,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009151121386054422,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0009151121386054422,
        "precision": 0.0006378578332106038,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.27938657286327e-05,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 3.27938657286327e-05,
        "precision": 1.6572158607298648e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.8142956054140264e-05,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 1.8142956054140264e-05,
        "precision": 9.11384686085973e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04722816246253746,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.04722816246253746,
        "precision": 0.0431414880315186,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0035886811344785483,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0035886811344785483,
        "precision": 0.0033174876540962924,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0039884032680787326,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0039884032680787326,
        "precision": 0.0033154529865371506,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.263366623476166e-05,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 2.263366623476166e-05,
        "precision": 1.1413242910158414e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026167674731182797,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0026167674731182797,
        "precision": 0.002447747564935065,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010716711956521739,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0010716711956521739,
        "precision": 0.001025818941885965,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.002055921052631579,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.002055921052631579,
        "precision": 0.002007378472222222,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0020208769437799045,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0020208769437799045,
        "precision": 0.0019879446155699337,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.651676014957265e-05,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 3.651676014957265e-05,
        "precision": 1.847209464516568e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.01380482648642322,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.01380482648642322,
        "precision": 0.012566477672292546,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.000390625,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.000390625,
        "precision": 0.000244140625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.011353238711349925,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.011353238711349925,
        "precision": 0.010153713474025975,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004013564560439561,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0004013564560439561,
        "precision": 0.0002495359979281768,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.007405598958333334,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.007405598958333334,
        "precision": 0.006649925595238096,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012023269489247312,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0012023269489247312,
        "precision": 0.0010978929924242424,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.04449482266865079,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.04449482266865079,
        "precision": 0.03958026836444805,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0035807291666666665,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0035807291666666665,
        "precision": 0.00341796875,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004886546964627151,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.004886546964627151,
        "precision": 0.004591714559386973,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.009458826752931502,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.009458826752931502,
        "precision": 0.008668271019345239,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0016276041666666665,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0016276041666666665,
        "precision": 0.00146484375,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0033696301300125313,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0033696301300125313,
        "precision": 0.003172278025793651,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00047200520833333334,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.00047200520833333334,
        "precision": 0.00028659986413043475,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006652780211253504,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.006652780211253504,
        "precision": 0.005865474875376791,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.763719512195122e-05,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 4.763719512195122e-05,
        "precision": 2.44140625e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0025993971306471305,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0025993971306471305,
        "precision": 0.0023193359375,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0038596394810416195,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0038596394810416195,
        "precision": 0.0034873699014307483,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.287109375,
        "f1": 0.26252867683531744,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.26252867683531744,
        "precision": 0.2540345207093254,
        "recall": 0.287109375
      },
      {
        "accuracy": 0.3544921875,
        "f1": 0.3211581495761183,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3211581495761183,
        "precision": 0.31008432980346196,
        "recall": 0.3544921875
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.024589998759920635,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.024589998759920635,
        "precision": 0.022742854600251265,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.3203125,
        "f1": 0.2974613954838564,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2974613954838564,
        "precision": 0.2906959874977453,
        "recall": 0.3203125
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.024094063435403604,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.024094063435403604,
        "precision": 0.020565908908722716,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.3544921875,
        "f1": 0.32244836677568756,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.32244836677568756,
        "precision": 0.31139801360748626,
        "recall": 0.3544921875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00012206024334181642,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.00012206024334181642,
        "precision": 6.425343316623156e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.185546875,
        "f1": 0.16915485141627098,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.16915485141627098,
        "precision": 0.16321803108912483,
        "recall": 0.185546875
      },
      {
        "accuracy": 0.1181640625,
        "f1": 0.0884305760109988,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.0884305760109988,
        "precision": 0.07985554863972832,
        "recall": 0.1181640625
      },
      {
        "accuracy": 0.1435546875,
        "f1": 0.11605094951765234,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11605094951765234,
        "precision": 0.1072032951138251,
        "recall": 0.1435546875
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.06258155671254458,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06258155671254458,
        "precision": 0.05673216897070224,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006551022176022176,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0006551022176022176,
        "precision": 0.0004903157552083333,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.05806364573839902,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.05806364573839902,
        "precision": 0.05180158507795227,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002228255772281248,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.002228255772281248,
        "precision": 0.0020983898913586414,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.12886915158670403,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.12886915158670403,
        "precision": 0.12608519410277222,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03797990708041542,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.03797990708041542,
        "precision": 0.03233470017064674,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.13010931776556775,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.13010931776556775,
        "precision": 0.12096409527352606,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.1767578125,
        "f1": 0.15715111884181865,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.15715111884181865,
        "precision": 0.14986579354493323,
        "recall": 0.1767578125
      },
      {
        "accuracy": 0.2158203125,
        "f1": 0.1971554288399039,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.1971554288399039,
        "precision": 0.19105538684708379,
        "recall": 0.2158203125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00098046875,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.00098046875,
        "precision": 0.0009785195390781562,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012817741935201965,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0012817741935201965,
        "precision": 0.0011400741185897435,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.130859375,
        "f1": 0.11708116319444443,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.11708116319444443,
        "precision": 0.11281579890240492,
        "recall": 0.130859375
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.12460937499999998,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.12460937499999998,
        "precision": 0.11848958333333333,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.030195811459559182,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.030195811459559182,
        "precision": 0.028453591295043518,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.13193824404761906,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.13193824404761906,
        "precision": 0.12715928819444444,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.027853648630812633,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.027853648630812633,
        "precision": 0.023345720290945008,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.11280347931844098,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.11280347931844098,
        "precision": 0.1071692224958803,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0027542806131052623,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.0027542806131052623,
        "precision": 0.0024226663229862493,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.109375,
        "f1": 0.09382433081724297,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.09382433081724297,
        "precision": 0.08891482831496961,
        "recall": 0.109375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0023052098293028086,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.0023052098293028086,
        "precision": 0.0018428755058516268,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.13498082246512466,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.13498082246512466,
        "precision": 0.12978423158082358,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004394391295515223,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.004394391295515223,
        "precision": 0.00417224202904967,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0021726111990154713,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0021726111990154713,
        "precision": 0.0020764330342997466,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026079371782496783,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.0026079371782496783,
        "precision": 0.002443295152321083,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010374523344494047,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.0010374523344494047,
        "precision": 0.001007834698011058,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.1522114691268739,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.1522114691268739,
        "precision": 0.14795943123097505,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0016454899725362655,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.0016454899725362655,
        "precision": 0.0013688734964312703,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002452672095885138,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.002452672095885138,
        "precision": 0.002239305938631754,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.11553859190577942,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.11553859190577942,
        "precision": 0.11167991042721646,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.1767578125,
        "f1": 0.16104333337086935,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.16104333337086935,
        "precision": 0.15627397913068142,
        "recall": 0.1767578125
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.09623608206200787,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.09623608206200787,
        "precision": 0.09217728158286341,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.997060327198364e-06,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 1.997060327198364e-06,
        "precision": 9.995522006141249e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0005556303879310345,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.0005556303879310345,
        "precision": 0.00036039806547619044,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.1267076851061226,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.1267076851061226,
        "precision": 0.12074047326005394,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.13337820825561847,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.13337820825561847,
        "precision": 0.1272712607453031,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.0793384320815786,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.0793384320815786,
        "precision": 0.07399467467717034,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.1484375,
        "f1": 0.13374391586061507,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.13374391586061507,
        "precision": 0.12841054728446016,
        "recall": 0.1484375
      },
      {
        "accuracy": 0.109375,
        "f1": 0.06876817110330438,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.06876817110330438,
        "precision": 0.05925525794479723,
        "recall": 0.109375
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.11791064916381296,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.11791064916381296,
        "precision": 0.11290169010039183,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07590836572281884,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.07590836572281884,
        "precision": 0.06900531719257305,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.11296182062679734,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.11296182062679734,
        "precision": 0.1060857019574306,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00019243242719950434,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.00019243242719950434,
        "precision": 0.00010379375177297663,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.20703125,
        "f1": 0.18084774925595237,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.18084774925595237,
        "precision": 0.1701753162202381,
        "recall": 0.20703125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010504541221084344,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.0010504541221084344,
        "precision": 0.0010145147984179576,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.008005180714812307,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.008005180714812307,
        "precision": 0.006865414413159518,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0010323660714285714,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.0010323660714285714,
        "precision": 0.0010052849264705881,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0050648057566743,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.0050648057566743,
        "precision": 0.0038363463240370784,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.2109375,
        "f1": 0.19429175967261902,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.19429175967261902,
        "precision": 0.188598814479285,
        "recall": 0.2109375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005114219019861831,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.0005114219019861831,
        "precision": 0.00033716120709242165,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006107658617424242,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.006107658617424242,
        "precision": 0.005288826832374898,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.12949978915061336,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.12949978915061336,
        "precision": 0.12269384171134419,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.142578125,
        "f1": 0.12729195953896172,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.12729195953896172,
        "precision": 0.12268495942043409,
        "recall": 0.142578125
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.1114780174119826,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.1114780174119826,
        "precision": 0.10619208657131834,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002150964374048706,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.002150964374048706,
        "precision": 0.0018080721094859873,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004184960392867613,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.004184960392867613,
        "precision": 0.0034668545330423413,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.2060546875,
        "f1": 0.185791015625,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.185791015625,
        "precision": 0.17839644630809595,
        "recall": 0.2060546875
      },
      {
        "accuracy": 0.224609375,
        "f1": 0.20258941266811212,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.20258941266811212,
        "precision": 0.19669657483301745,
        "recall": 0.224609375
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.02962476901073309,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.02962476901073309,
        "precision": 0.028809781782238444,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.1923828125,
        "f1": 0.17039996136675822,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.17039996136675822,
        "precision": 0.16288440412579228,
        "recall": 0.1923828125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015151404304010746,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.015151404304010746,
        "precision": 0.012837473002954063,
        "recall": 0.03125
      },
      {
        "accuracy": 0.2021484375,
        "f1": 0.17550709174192386,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.17550709174192386,
        "precision": 0.16678102712338772,
        "recall": 0.2021484375
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.369265005525625e-05,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 1.369265005525625e-05,
        "precision": 6.871938760723395e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.3798828125,
        "f1": 0.34602096579635644,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.34602096579635644,
        "precision": 0.33374139694940474,
        "recall": 0.3798828125
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.010417755340992985,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.010417755340992985,
        "precision": 0.009508886055190957,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.09591463873072903,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.09591463873072903,
        "precision": 0.08817989251139224,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.009868479320233055,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.009868479320233055,
        "precision": 0.00897581908079955,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008972348409060594,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.008972348409060594,
        "precision": 0.00800408891541477,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 5.4832874459210744e-05,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 5.4832874459210744e-05,
        "precision": 2.772669789027435e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.13890100784632034,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.13890100784632034,
        "precision": 0.13435013879349816,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0030478978816699605,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.0030478978816699605,
        "precision": 0.002266006958857986,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.208984375,
        "f1": 0.18321290471681095,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.18321290471681095,
        "precision": 0.1754990024268715,
        "recall": 0.208984375
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.10466781734496122,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.10466781734496122,
        "precision": 0.09610210891071927,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.12929703330800404,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.12929703330800404,
        "precision": 0.12161166757185828,
        "recall": 0.15234375
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}