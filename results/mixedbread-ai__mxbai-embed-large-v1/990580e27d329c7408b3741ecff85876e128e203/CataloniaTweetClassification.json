{
  "dataset_revision": "cf24d44e517efa534f048e5fc5981f399ed25bee",
  "evaluation_time": 43.45293712615967,
  "kg_co2_emissions": 0.002136730897058392,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.4866071428571429,
        "f1": 0.5027169110022249,
        "f1_weighted": 0.48089972412327786,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.4866071428571429,
        "scores_per_experiment": [
          {
            "accuracy": 0.5143849206349206,
            "f1": 0.5326655602229158,
            "f1_weighted": 0.5133209405606058
          },
          {
            "accuracy": 0.5342261904761905,
            "f1": 0.550641706358371,
            "f1_weighted": 0.5356542439619209
          },
          {
            "accuracy": 0.3898809523809524,
            "f1": 0.38259721023228543,
            "f1_weighted": 0.37112303948059033
          },
          {
            "accuracy": 0.4905753968253968,
            "f1": 0.518511584820476,
            "f1_weighted": 0.4932191767761238
          },
          {
            "accuracy": 0.46279761904761907,
            "f1": 0.4869181881750364,
            "f1_weighted": 0.45299419944924296
          },
          {
            "accuracy": 0.5446428571428571,
            "f1": 0.5616645754614136,
            "f1_weighted": 0.5361527528630703
          },
          {
            "accuracy": 0.47023809523809523,
            "f1": 0.48264774400482713,
            "f1_weighted": 0.4648332025780371
          },
          {
            "accuracy": 0.47966269841269843,
            "f1": 0.49061647868237923,
            "f1_weighted": 0.4658026565616722
          },
          {
            "accuracy": 0.4791666666666667,
            "f1": 0.49279343238934165,
            "f1_weighted": 0.4784567450427274
          },
          {
            "accuracy": 0.5004960317460317,
            "f1": 0.5281126296752019,
            "f1_weighted": 0.4974402839587884
          }
        ]
      },
      {
        "accuracy": 0.4824378109452736,
        "f1": 0.47416113106630187,
        "f1_weighted": 0.4798227357633726,
        "hf_subset": "catalan",
        "languages": [
          "cat-Latn"
        ],
        "main_score": 0.4824378109452736,
        "scores_per_experiment": [
          {
            "accuracy": 0.4691542288557214,
            "f1": 0.46298359863042493,
            "f1_weighted": 0.46983494754601884
          },
          {
            "accuracy": 0.4014925373134328,
            "f1": 0.39372490068097177,
            "f1_weighted": 0.3961618340383669
          },
          {
            "accuracy": 0.5358208955223881,
            "f1": 0.5267878559435287,
            "f1_weighted": 0.5352837890525443
          },
          {
            "accuracy": 0.5283582089552239,
            "f1": 0.511403561126537,
            "f1_weighted": 0.5252948237085525
          },
          {
            "accuracy": 0.4711442786069652,
            "f1": 0.45272185100455076,
            "f1_weighted": 0.46600395698905295
          },
          {
            "accuracy": 0.48955223880597015,
            "f1": 0.4874327469748572,
            "f1_weighted": 0.4914479603054342
          },
          {
            "accuracy": 0.4691542288557214,
            "f1": 0.4617918098538334,
            "f1_weighted": 0.46560099089230156
          },
          {
            "accuracy": 0.4407960199004975,
            "f1": 0.4430159001145997,
            "f1_weighted": 0.4390013568555722
          },
          {
            "accuracy": 0.5199004975124378,
            "f1": 0.5117538614627847,
            "f1_weighted": 0.5135016817426218
          },
          {
            "accuracy": 0.49900497512437814,
            "f1": 0.489995224870931,
            "f1_weighted": 0.4960960165032606
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.4868982630272953,
        "f1": 0.49993825519990576,
        "f1_weighted": 0.48307798332918317,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.4868982630272953,
        "scores_per_experiment": [
          {
            "accuracy": 0.5186104218362283,
            "f1": 0.5310692313578643,
            "f1_weighted": 0.5175291149109353
          },
          {
            "accuracy": 0.5389578163771712,
            "f1": 0.5513078820678339,
            "f1_weighted": 0.5411209137221822
          },
          {
            "accuracy": 0.40148883374689825,
            "f1": 0.3956685426645743,
            "f1_weighted": 0.38974328814322773
          },
          {
            "accuracy": 0.5012406947890818,
            "f1": 0.5215990491996227,
            "f1_weighted": 0.5033813829582152
          },
          {
            "accuracy": 0.4645161290322581,
            "f1": 0.4847953710587653,
            "f1_weighted": 0.4573208372263111
          },
          {
            "accuracy": 0.5200992555831265,
            "f1": 0.5387473803327846,
            "f1_weighted": 0.5117127283111716
          },
          {
            "accuracy": 0.47444168734491315,
            "f1": 0.4835905395464923,
            "f1_weighted": 0.4714032538622489
          },
          {
            "accuracy": 0.48883374689826303,
            "f1": 0.495871029288477,
            "f1_weighted": 0.47851799297807157
          },
          {
            "accuracy": 0.45707196029776676,
            "f1": 0.4680495411571089,
            "f1_weighted": 0.4576134670339831
          },
          {
            "accuracy": 0.5037220843672456,
            "f1": 0.5286839853255351,
            "f1_weighted": 0.5024368541454852
          }
        ]
      },
      {
        "accuracy": 0.4761691542288558,
        "f1": 0.46715379742280205,
        "f1_weighted": 0.4736790601034067,
        "hf_subset": "catalan",
        "languages": [
          "cat-Latn"
        ],
        "main_score": 0.4761691542288558,
        "scores_per_experiment": [
          {
            "accuracy": 0.4651741293532338,
            "f1": 0.4618959861818139,
            "f1_weighted": 0.46455679619414997
          },
          {
            "accuracy": 0.39303482587064675,
            "f1": 0.39052282464961485,
            "f1_weighted": 0.3870846870216602
          },
          {
            "accuracy": 0.5358208955223881,
            "f1": 0.5239280936480953,
            "f1_weighted": 0.5358557172225761
          },
          {
            "accuracy": 0.5194029850746269,
            "f1": 0.4991962446798992,
            "f1_weighted": 0.5173721065866957
          },
          {
            "accuracy": 0.4592039800995025,
            "f1": 0.43956011407859047,
            "f1_weighted": 0.45424948056418435
          },
          {
            "accuracy": 0.46318407960199004,
            "f1": 0.4615719555928484,
            "f1_weighted": 0.4650044781937625
          },
          {
            "accuracy": 0.48009950248756217,
            "f1": 0.4719568996730004,
            "f1_weighted": 0.47523904287099733
          },
          {
            "accuracy": 0.44527363184079605,
            "f1": 0.4455162736366094,
            "f1_weighted": 0.4441700749462891
          },
          {
            "accuracy": 0.49701492537313435,
            "f1": 0.4839247409460687,
            "f1_weighted": 0.4928869137669986
          },
          {
            "accuracy": 0.5034825870646766,
            "f1": 0.4934648411414797,
            "f1_weighted": 0.5003713036667535
          }
        ]
      }
    ]
  },
  "task_name": "CataloniaTweetClassification"
}