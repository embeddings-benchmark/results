{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 13.402210712432861,
  "kg_co2_emissions": 0.00039866001383169464,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.5432692307692307,
        "f1": 0.4230624610052217,
        "f1_weighted": 0.5864470721121351,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5432692307692307,
        "scores_per_experiment": [
          {
            "accuracy": 0.5192307692307693,
            "f1": 0.4094520176943215,
            "f1_weighted": 0.555614197123631
          },
          {
            "accuracy": 0.5961538461538461,
            "f1": 0.46953144894321364,
            "f1_weighted": 0.6328734990499696
          },
          {
            "accuracy": 0.625,
            "f1": 0.5020531400966184,
            "f1_weighted": 0.7020299145299145
          },
          {
            "accuracy": 0.5769230769230769,
            "f1": 0.4574938574938575,
            "f1_weighted": 0.6446371196371197
          },
          {
            "accuracy": 0.6057692307692307,
            "f1": 0.4404358448928122,
            "f1_weighted": 0.6602968280143564
          },
          {
            "accuracy": 0.4807692307692308,
            "f1": 0.38507190701339633,
            "f1_weighted": 0.5034475965327029
          },
          {
            "accuracy": 0.47115384615384615,
            "f1": 0.39175683623836505,
            "f1_weighted": 0.5067953936496971
          },
          {
            "accuracy": 0.5865384615384616,
            "f1": 0.3793010752688172,
            "f1_weighted": 0.6186827956989247
          },
          {
            "accuracy": 0.5,
            "f1": 0.41355191750178055,
            "f1_weighted": 0.542071009181816
          },
          {
            "accuracy": 0.47115384615384615,
            "f1": 0.38197656490903487,
            "f1_weighted": 0.4980223677032188
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5304761904761905,
        "f1": 0.40487069408724813,
        "f1_weighted": 0.5796430215906773,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5304761904761905,
        "scores_per_experiment": [
          {
            "accuracy": 0.5523809523809524,
            "f1": 0.4300599347468115,
            "f1_weighted": 0.6073238643641515
          },
          {
            "accuracy": 0.5333333333333333,
            "f1": 0.43214285714285716,
            "f1_weighted": 0.6053061224489796
          },
          {
            "accuracy": 0.5523809523809524,
            "f1": 0.4223891376570851,
            "f1_weighted": 0.6225090966619206
          },
          {
            "accuracy": 0.49523809523809526,
            "f1": 0.38356040511212924,
            "f1_weighted": 0.5740615706132947
          },
          {
            "accuracy": 0.6190476190476191,
            "f1": 0.4263478818998716,
            "f1_weighted": 0.6475029036004646
          },
          {
            "accuracy": 0.4380952380952381,
            "f1": 0.34333880229696473,
            "f1_weighted": 0.46917676471737174
          },
          {
            "accuracy": 0.5428571428571428,
            "f1": 0.4380108632600327,
            "f1_weighted": 0.5882814402985262
          },
          {
            "accuracy": 0.6,
            "f1": 0.40970927318295736,
            "f1_weighted": 0.6257745315670128
          },
          {
            "accuracy": 0.4380952380952381,
            "f1": 0.3516535327002088,
            "f1_weighted": 0.4801611356470924
          },
          {
            "accuracy": 0.5333333333333333,
            "f1": 0.4114942528735632,
            "f1_weighted": 0.5763327859879583
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}