{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.619099,
        "f1": 0.597902,
        "f1_weighted": 0.634041,
        "ap": 0.759537,
        "ap_weighted": 0.759537,
        "scores_per_experiment": [
          {
            "accuracy": 0.628755,
            "f1": 0.610456,
            "f1_weighted": 0.643793,
            "ap": 0.768117,
            "ap_weighted": 0.768117
          },
          {
            "accuracy": 0.618026,
            "f1": 0.588919,
            "f1_weighted": 0.63211,
            "ap": 0.74809,
            "ap_weighted": 0.74809
          },
          {
            "accuracy": 0.667382,
            "f1": 0.650298,
            "f1_weighted": 0.680817,
            "ap": 0.793559,
            "ap_weighted": 0.793559
          },
          {
            "accuracy": 0.648069,
            "f1": 0.621251,
            "f1_weighted": 0.661045,
            "ap": 0.767124,
            "ap_weighted": 0.767124
          },
          {
            "accuracy": 0.607296,
            "f1": 0.593781,
            "f1_weighted": 0.623038,
            "ap": 0.763515,
            "ap_weighted": 0.763515
          },
          {
            "accuracy": 0.594421,
            "f1": 0.576052,
            "f1_weighted": 0.610896,
            "ap": 0.748225,
            "ap_weighted": 0.748225
          },
          {
            "accuracy": 0.603004,
            "f1": 0.579125,
            "f1_weighted": 0.618709,
            "ap": 0.745884,
            "ap_weighted": 0.745884
          },
          {
            "accuracy": 0.564378,
            "f1": 0.547886,
            "f1_weighted": 0.581981,
            "ap": 0.734137,
            "ap_weighted": 0.734137
          },
          {
            "accuracy": 0.590129,
            "f1": 0.558351,
            "f1_weighted": 0.605128,
            "ap": 0.730936,
            "ap_weighted": 0.730936
          },
          {
            "accuracy": 0.669528,
            "f1": 0.652898,
            "f1_weighted": 0.682897,
            "ap": 0.795783,
            "ap_weighted": 0.795783
          }
        ],
        "main_score": 0.619099,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.602463,
        "f1": 0.582252,
        "f1_weighted": 0.617758,
        "ap": 0.749388,
        "ap_weighted": 0.749388,
        "scores_per_experiment": [
          {
            "accuracy": 0.594218,
            "f1": 0.580145,
            "f1_weighted": 0.610267,
            "ap": 0.752822,
            "ap_weighted": 0.752822
          },
          {
            "accuracy": 0.589936,
            "f1": 0.559635,
            "f1_weighted": 0.604901,
            "ap": 0.730485,
            "ap_weighted": 0.730485
          },
          {
            "accuracy": 0.649893,
            "f1": 0.627082,
            "f1_weighted": 0.663224,
            "ap": 0.771777,
            "ap_weighted": 0.771777
          },
          {
            "accuracy": 0.652034,
            "f1": 0.622561,
            "f1_weighted": 0.663891,
            "ap": 0.764349,
            "ap_weighted": 0.764349
          },
          {
            "accuracy": 0.571734,
            "f1": 0.552838,
            "f1_weighted": 0.588859,
            "ap": 0.733166,
            "ap_weighted": 0.733166
          },
          {
            "accuracy": 0.600642,
            "f1": 0.58963,
            "f1_weighted": 0.615973,
            "ap": 0.76239,
            "ap_weighted": 0.76239
          },
          {
            "accuracy": 0.579229,
            "f1": 0.560461,
            "f1_weighted": 0.596052,
            "ap": 0.737408,
            "ap_weighted": 0.737408
          },
          {
            "accuracy": 0.561028,
            "f1": 0.547412,
            "f1_weighted": 0.578174,
            "ap": 0.73452,
            "ap_weighted": 0.73452
          },
          {
            "accuracy": 0.587794,
            "f1": 0.562399,
            "f1_weighted": 0.603709,
            "ap": 0.734264,
            "ap_weighted": 0.734264
          },
          {
            "accuracy": 0.638116,
            "f1": 0.620358,
            "f1_weighted": 0.652533,
            "ap": 0.772697,
            "ap_weighted": 0.772697
          }
        ],
        "main_score": 0.602463,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 55.7720685005188,
  "kg_co2_emissions": null
}