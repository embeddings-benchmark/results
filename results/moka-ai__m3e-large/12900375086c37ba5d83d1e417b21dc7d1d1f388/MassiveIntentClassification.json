{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "task_name": "MassiveIntentClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.380915,
        "f1": 0.36168,
        "f1_weighted": 0.38476,
        "scores_per_experiment": [
          {
            "accuracy": 0.381702,
            "f1": 0.360846,
            "f1_weighted": 0.387442
          },
          {
            "accuracy": 0.359567,
            "f1": 0.338803,
            "f1_weighted": 0.364556
          },
          {
            "accuracy": 0.372848,
            "f1": 0.361145,
            "f1_weighted": 0.382007
          },
          {
            "accuracy": 0.373832,
            "f1": 0.354962,
            "f1_weighted": 0.380195
          },
          {
            "accuracy": 0.411215,
            "f1": 0.386075,
            "f1_weighted": 0.415344
          },
          {
            "accuracy": 0.387605,
            "f1": 0.360761,
            "f1_weighted": 0.390933
          },
          {
            "accuracy": 0.368421,
            "f1": 0.345901,
            "f1_weighted": 0.365894
          },
          {
            "accuracy": 0.392523,
            "f1": 0.375932,
            "f1_weighted": 0.39861
          },
          {
            "accuracy": 0.379242,
            "f1": 0.373356,
            "f1_weighted": 0.376704
          },
          {
            "accuracy": 0.382194,
            "f1": 0.359016,
            "f1_weighted": 0.385917
          }
        ],
        "main_score": 0.380915,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.38961,
        "f1": 0.360854,
        "f1_weighted": 0.394381,
        "scores_per_experiment": [
          {
            "accuracy": 0.393073,
            "f1": 0.371915,
            "f1_weighted": 0.398982
          },
          {
            "accuracy": 0.38534,
            "f1": 0.345654,
            "f1_weighted": 0.394805
          },
          {
            "accuracy": 0.398453,
            "f1": 0.367911,
            "f1_weighted": 0.404955
          },
          {
            "accuracy": 0.378615,
            "f1": 0.351838,
            "f1_weighted": 0.384492
          },
          {
            "accuracy": 0.396436,
            "f1": 0.355591,
            "f1_weighted": 0.397662
          },
          {
            "accuracy": 0.393746,
            "f1": 0.369422,
            "f1_weighted": 0.399236
          },
          {
            "accuracy": 0.378278,
            "f1": 0.354002,
            "f1_weighted": 0.377364
          },
          {
            "accuracy": 0.394418,
            "f1": 0.366858,
            "f1_weighted": 0.401051
          },
          {
            "accuracy": 0.385676,
            "f1": 0.359622,
            "f1_weighted": 0.387479
          },
          {
            "accuracy": 0.392065,
            "f1": 0.36573,
            "f1_weighted": 0.397784
          }
        ],
        "main_score": 0.38961,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 50.65376377105713,
  "kg_co2_emissions": null
}