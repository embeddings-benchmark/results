{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "2.1.10",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.544073,
            "f1": 0.458169,
            "f1_weighted": 0.620141,
            "precision": 0.527015,
            "precision_weighted": 0.80791,
            "recall": 0.56178,
            "recall_weighted": 0.544073,
            "ap": 0.141154,
            "ap_weighted": 0.141154
          },
          {
            "accuracy": 0.556231,
            "f1": 0.459807,
            "f1_weighted": 0.631151,
            "precision": 0.521048,
            "precision_weighted": 0.801379,
            "recall": 0.547807,
            "recall_weighted": 0.556231,
            "ap": 0.136978,
            "ap_weighted": 0.136978
          },
          {
            "accuracy": 0.598784,
            "f1": 0.488071,
            "f1_weighted": 0.666804,
            "precision": 0.532512,
            "precision_weighted": 0.809955,
            "recall": 0.572112,
            "recall_weighted": 0.598784,
            "ap": 0.145194,
            "ap_weighted": 0.145194
          },
          {
            "accuracy": 0.440729,
            "f1": 0.387486,
            "f1_weighted": 0.523065,
            "precision": 0.501233,
            "precision_weighted": 0.783202,
            "recall": 0.502752,
            "recall_weighted": 0.440729,
            "ap": 0.125226,
            "ap_weighted": 0.125226
          },
          {
            "accuracy": 0.6231,
            "f1": 0.519097,
            "f1_weighted": 0.686998,
            "precision": 0.557637,
            "precision_weighted": 0.831697,
            "recall": 0.627837,
            "recall_weighted": 0.6231,
            "ap": 0.167725,
            "ap_weighted": 0.167725
          },
          {
            "accuracy": 0.489362,
            "f1": 0.418287,
            "f1_weighted": 0.570943,
            "precision": 0.508782,
            "precision_weighted": 0.790943,
            "recall": 0.520071,
            "recall_weighted": 0.489362,
            "ap": 0.129292,
            "ap_weighted": 0.129292
          },
          {
            "accuracy": 0.486322,
            "f1": 0.407498,
            "f1_weighted": 0.569745,
            "precision": 0.494306,
            "precision_weighted": 0.776036,
            "recall": 0.486958,
            "recall_weighted": 0.486322,
            "ap": 0.121902,
            "ap_weighted": 0.121902
          },
          {
            "accuracy": 0.550152,
            "f1": 0.459074,
            "f1_weighted": 0.625713,
            "precision": 0.524027,
            "precision_weighted": 0.804586,
            "recall": 0.554793,
            "recall_weighted": 0.550152,
            "ap": 0.139041,
            "ap_weighted": 0.139041
          },
          {
            "accuracy": 0.680851,
            "f1": 0.530925,
            "f1_weighted": 0.73002,
            "precision": 0.544679,
            "precision_weighted": 0.813755,
            "recall": 0.58761,
            "recall_weighted": 0.680851,
            "ap": 0.153192,
            "ap_weighted": 0.153192
          },
          {
            "accuracy": 0.765957,
            "f1": 0.619767,
            "f1_weighted": 0.796772,
            "precision": 0.608163,
            "precision_weighted": 0.850245,
            "recall": 0.688516,
            "recall_weighted": 0.765957,
            "ap": 0.218919,
            "ap_weighted": 0.218919
          }
        ],
        "accuracy": 0.573556,
        "f1": 0.474818,
        "f1_weighted": 0.642135,
        "precision": 0.53194,
        "precision_weighted": 0.806971,
        "recall": 0.565024,
        "recall_weighted": 0.573556,
        "ap": 0.147862,
        "ap_weighted": 0.147862,
        "main_score": 0.573556,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 23.500797748565674,
  "kg_co2_emissions": null
}