{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "task_name": "PoemSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.524762,
        "f1": 0.382732,
        "f1_weighted": 0.576164,
        "scores_per_experiment": [
          {
            "accuracy": 0.580952,
            "f1": 0.431716,
            "f1_weighted": 0.631589
          },
          {
            "accuracy": 0.542857,
            "f1": 0.408654,
            "f1_weighted": 0.588462
          },
          {
            "accuracy": 0.542857,
            "f1": 0.387149,
            "f1_weighted": 0.583743
          },
          {
            "accuracy": 0.533333,
            "f1": 0.415758,
            "f1_weighted": 0.597102
          },
          {
            "accuracy": 0.552381,
            "f1": 0.396351,
            "f1_weighted": 0.601849
          },
          {
            "accuracy": 0.561905,
            "f1": 0.40148,
            "f1_weighted": 0.606317
          },
          {
            "accuracy": 0.52381,
            "f1": 0.408622,
            "f1_weighted": 0.588574
          },
          {
            "accuracy": 0.419048,
            "f1": 0.298674,
            "f1_weighted": 0.465737
          },
          {
            "accuracy": 0.466667,
            "f1": 0.294354,
            "f1_weighted": 0.52158
          },
          {
            "accuracy": 0.52381,
            "f1": 0.384562,
            "f1_weighted": 0.576688
          }
        ],
        "main_score": 0.524762,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.488462,
        "f1": 0.363677,
        "f1_weighted": 0.548314,
        "scores_per_experiment": [
          {
            "accuracy": 0.548077,
            "f1": 0.390235,
            "f1_weighted": 0.619822
          },
          {
            "accuracy": 0.471154,
            "f1": 0.367174,
            "f1_weighted": 0.518704
          },
          {
            "accuracy": 0.605769,
            "f1": 0.460633,
            "f1_weighted": 0.666698
          },
          {
            "accuracy": 0.596154,
            "f1": 0.44765,
            "f1_weighted": 0.658983
          },
          {
            "accuracy": 0.442308,
            "f1": 0.310699,
            "f1_weighted": 0.506746
          },
          {
            "accuracy": 0.423077,
            "f1": 0.304201,
            "f1_weighted": 0.47673
          },
          {
            "accuracy": 0.451923,
            "f1": 0.366726,
            "f1_weighted": 0.512216
          },
          {
            "accuracy": 0.432692,
            "f1": 0.302486,
            "f1_weighted": 0.507331
          },
          {
            "accuracy": 0.432692,
            "f1": 0.313264,
            "f1_weighted": 0.488159
          },
          {
            "accuracy": 0.480769,
            "f1": 0.373703,
            "f1_weighted": 0.527748
          }
        ],
        "main_score": 0.488462,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 13.431625604629517,
  "kg_co2_emissions": 0.0003722924079009299
}