{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.001005,
        "recall": 0.002006,
        "f1": 0.001008,
        "accuracy": 0.002006,
        "main_score": 0.001008,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006727,
        "recall": 0.024072,
        "f1": 0.008742,
        "accuracy": 0.024072,
        "main_score": 0.008742,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.015846,
        "recall": 0.02006,
        "f1": 0.016543,
        "accuracy": 0.02006,
        "main_score": 0.016543,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018859,
        "recall": 0.055165,
        "f1": 0.022886,
        "accuracy": 0.055165,
        "main_score": 0.022886,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002009,
        "accuracy": 0.003009,
        "main_score": 0.002009,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011145,
        "recall": 0.028084,
        "f1": 0.013625,
        "accuracy": 0.028084,
        "main_score": 0.013625,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.021776,
        "recall": 0.027081,
        "f1": 0.022538,
        "accuracy": 0.027081,
        "main_score": 0.022538,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025688,
        "recall": 0.068205,
        "f1": 0.030979,
        "accuracy": 0.068205,
        "main_score": 0.030979,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.013921,
        "recall": 0.021063,
        "f1": 0.015139,
        "accuracy": 0.021063,
        "main_score": 0.015139,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023015,
        "recall": 0.069208,
        "f1": 0.029261,
        "accuracy": 0.069208,
        "main_score": 0.029261,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002009,
        "accuracy": 0.003009,
        "main_score": 0.002009,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011859,
        "recall": 0.031093,
        "f1": 0.014489,
        "accuracy": 0.031093,
        "main_score": 0.014489,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.017753,
        "recall": 0.019057,
        "f1": 0.018054,
        "accuracy": 0.019057,
        "main_score": 0.018054,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014183,
        "recall": 0.042126,
        "f1": 0.017958,
        "accuracy": 0.042126,
        "main_score": 0.017958,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.063237,
        "recall": 0.071214,
        "f1": 0.064754,
        "accuracy": 0.071214,
        "main_score": 0.064754,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.036918,
        "recall": 0.106319,
        "f1": 0.047031,
        "accuracy": 0.106319,
        "main_score": 0.047031,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.009154,
        "recall": 0.011033,
        "f1": 0.009253,
        "accuracy": 0.011033,
        "main_score": 0.009253,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00896,
        "recall": 0.029087,
        "f1": 0.011173,
        "accuracy": 0.029087,
        "main_score": 0.011173,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.005015,
        "recall": 0.005015,
        "f1": 0.005015,
        "accuracy": 0.005015,
        "main_score": 0.005015,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012167,
        "recall": 0.028084,
        "f1": 0.014286,
        "accuracy": 0.028084,
        "main_score": 0.014286,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.007022,
        "recall": 0.008024,
        "f1": 0.007024,
        "accuracy": 0.008024,
        "main_score": 0.007024,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017487,
        "recall": 0.039117,
        "f1": 0.020922,
        "accuracy": 0.039117,
        "main_score": 0.020922,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.014044,
        "recall": 0.015045,
        "f1": 0.014045,
        "accuracy": 0.015045,
        "main_score": 0.014045,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016424,
        "recall": 0.05015,
        "f1": 0.021435,
        "accuracy": 0.05015,
        "main_score": 0.021435,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.030559,
        "recall": 0.04012,
        "f1": 0.032652,
        "accuracy": 0.04012,
        "main_score": 0.032652,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.032108,
        "recall": 0.080241,
        "f1": 0.039522,
        "accuracy": 0.080241,
        "main_score": 0.039522,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.024528,
        "recall": 0.032096,
        "f1": 0.025923,
        "accuracy": 0.032096,
        "main_score": 0.025923,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.03438,
        "recall": 0.076229,
        "f1": 0.040792,
        "accuracy": 0.076229,
        "main_score": 0.040792,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.070748,
        "recall": 0.074223,
        "f1": 0.071385,
        "accuracy": 0.074223,
        "main_score": 0.071385,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.059661,
        "recall": 0.142427,
        "f1": 0.074302,
        "accuracy": 0.142427,
        "main_score": 0.074302,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.017554,
        "recall": 0.019057,
        "f1": 0.017723,
        "accuracy": 0.019057,
        "main_score": 0.017723,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017337,
        "recall": 0.038114,
        "f1": 0.020224,
        "accuracy": 0.038114,
        "main_score": 0.020224,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.004013,
        "recall": 0.005015,
        "f1": 0.004015,
        "accuracy": 0.005015,
        "main_score": 0.004015,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004703,
        "recall": 0.017051,
        "f1": 0.006189,
        "accuracy": 0.017051,
        "main_score": 0.006189,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.00602,
        "recall": 0.007021,
        "f1": 0.006021,
        "accuracy": 0.007021,
        "main_score": 0.006021,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009846,
        "recall": 0.028084,
        "f1": 0.012165,
        "accuracy": 0.028084,
        "main_score": 0.012165,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.003589,
        "recall": 0.006018,
        "f1": 0.003824,
        "accuracy": 0.006018,
        "main_score": 0.003824,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00488,
        "recall": 0.018054,
        "f1": 0.006417,
        "accuracy": 0.018054,
        "main_score": 0.006417,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002009,
        "accuracy": 0.003009,
        "main_score": 0.002009,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009306,
        "recall": 0.022066,
        "f1": 0.010832,
        "accuracy": 0.022066,
        "main_score": 0.010832,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.004013,
        "recall": 0.005015,
        "f1": 0.004015,
        "accuracy": 0.005015,
        "main_score": 0.004015,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009104,
        "recall": 0.026078,
        "f1": 0.011187,
        "accuracy": 0.026078,
        "main_score": 0.011187,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.005016,
        "recall": 0.006018,
        "f1": 0.005018,
        "accuracy": 0.006018,
        "main_score": 0.005018,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017449,
        "recall": 0.043129,
        "f1": 0.020434,
        "accuracy": 0.043129,
        "main_score": 0.020434,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 3e-06,
        "accuracy": 0.001003,
        "main_score": 3e-06,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006201,
        "recall": 0.02006,
        "f1": 0.007978,
        "accuracy": 0.02006,
        "main_score": 0.007978,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.00301,
        "recall": 0.004012,
        "f1": 0.003011,
        "accuracy": 0.004012,
        "main_score": 0.003011,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012974,
        "recall": 0.037111,
        "f1": 0.015722,
        "accuracy": 0.037111,
        "main_score": 0.015722,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.005016,
        "recall": 0.006018,
        "f1": 0.005018,
        "accuracy": 0.006018,
        "main_score": 0.005018,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012319,
        "recall": 0.033099,
        "f1": 0.014735,
        "accuracy": 0.033099,
        "main_score": 0.014735,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.001003,
        "recall": 0.001003,
        "f1": 0.001003,
        "accuracy": 0.001003,
        "main_score": 0.001003,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009178,
        "recall": 0.032096,
        "f1": 0.011581,
        "accuracy": 0.032096,
        "main_score": 0.011581,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001006,
        "accuracy": 0.002006,
        "main_score": 0.001006,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00544,
        "recall": 0.026078,
        "f1": 0.007658,
        "accuracy": 0.026078,
        "main_score": 0.007658,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002009,
        "accuracy": 0.003009,
        "main_score": 0.002009,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009561,
        "recall": 0.026078,
        "f1": 0.011457,
        "accuracy": 0.026078,
        "main_score": 0.011457,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.006521,
        "recall": 0.008024,
        "f1": 0.006689,
        "accuracy": 0.008024,
        "main_score": 0.006689,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003391,
        "recall": 0.018054,
        "f1": 0.004645,
        "accuracy": 0.018054,
        "main_score": 0.004645,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.000988,
        "recall": 0.000988,
        "f1": 0.000988,
        "accuracy": 0.000988,
        "main_score": 0.000988,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011313,
        "recall": 0.027668,
        "f1": 0.013174,
        "accuracy": 0.027668,
        "main_score": 0.013174,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.02207,
        "recall": 0.027668,
        "f1": 0.023388,
        "accuracy": 0.027668,
        "main_score": 0.023388,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017588,
        "recall": 0.063241,
        "f1": 0.023235,
        "accuracy": 0.063241,
        "main_score": 0.023235,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.003953,
        "recall": 0.003953,
        "f1": 0.003953,
        "accuracy": 0.003953,
        "main_score": 0.003953,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016246,
        "recall": 0.035573,
        "f1": 0.018556,
        "accuracy": 0.035573,
        "main_score": 0.018556,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.027998,
        "recall": 0.035573,
        "f1": 0.029943,
        "accuracy": 0.035573,
        "main_score": 0.029943,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025227,
        "recall": 0.068182,
        "f1": 0.030858,
        "accuracy": 0.068182,
        "main_score": 0.030858,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.021823,
        "recall": 0.02668,
        "f1": 0.02296,
        "accuracy": 0.02668,
        "main_score": 0.02296,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018171,
        "recall": 0.056324,
        "f1": 0.022821,
        "accuracy": 0.056324,
        "main_score": 0.022821,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000329,
        "recall": 0.000988,
        "f1": 0.000494,
        "accuracy": 0.000988,
        "main_score": 0.000494,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012995,
        "recall": 0.027668,
        "f1": 0.014982,
        "accuracy": 0.027668,
        "main_score": 0.014982,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.011391,
        "recall": 0.014822,
        "f1": 0.011911,
        "accuracy": 0.014822,
        "main_score": 0.011911,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006972,
        "recall": 0.029644,
        "f1": 0.009208,
        "accuracy": 0.029644,
        "main_score": 0.009208,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.078147,
        "recall": 0.086957,
        "f1": 0.080437,
        "accuracy": 0.086957,
        "main_score": 0.080437,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.043441,
        "recall": 0.115613,
        "f1": 0.05466,
        "accuracy": 0.115613,
        "main_score": 0.05466,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002505,
        "recall": 0.004941,
        "f1": 0.002802,
        "accuracy": 0.004941,
        "main_score": 0.002802,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006515,
        "recall": 0.024704,
        "f1": 0.008607,
        "accuracy": 0.024704,
        "main_score": 0.008607,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.005765,
        "recall": 0.007905,
        "f1": 0.006096,
        "accuracy": 0.007905,
        "main_score": 0.006096,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008852,
        "recall": 0.021739,
        "f1": 0.010689,
        "accuracy": 0.021739,
        "main_score": 0.010689,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.005435,
        "recall": 0.005929,
        "f1": 0.005599,
        "accuracy": 0.005929,
        "main_score": 0.005599,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018272,
        "recall": 0.036561,
        "f1": 0.021296,
        "accuracy": 0.036561,
        "main_score": 0.021296,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.014526,
        "recall": 0.016798,
        "f1": 0.01494,
        "accuracy": 0.016798,
        "main_score": 0.01494,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019929,
        "recall": 0.048419,
        "f1": 0.023518,
        "accuracy": 0.048419,
        "main_score": 0.023518,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.033302,
        "recall": 0.040514,
        "f1": 0.035081,
        "accuracy": 0.040514,
        "main_score": 0.035081,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.035932,
        "recall": 0.073123,
        "f1": 0.041656,
        "accuracy": 0.073123,
        "main_score": 0.041656,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.031457,
        "recall": 0.038538,
        "f1": 0.033434,
        "accuracy": 0.038538,
        "main_score": 0.033434,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.037904,
        "recall": 0.081028,
        "f1": 0.04453,
        "accuracy": 0.081028,
        "main_score": 0.04453,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.05756,
        "recall": 0.060277,
        "f1": 0.058039,
        "accuracy": 0.060277,
        "main_score": 0.058039,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.051411,
        "recall": 0.108696,
        "f1": 0.061041,
        "accuracy": 0.108696,
        "main_score": 0.061041,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.022238,
        "recall": 0.024704,
        "f1": 0.022407,
        "accuracy": 0.024704,
        "main_score": 0.022407,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013556,
        "recall": 0.041502,
        "f1": 0.016626,
        "accuracy": 0.041502,
        "main_score": 0.016626,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006423,
        "recall": 0.006917,
        "f1": 0.006588,
        "accuracy": 0.006917,
        "main_score": 0.006588,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014529,
        "recall": 0.033597,
        "f1": 0.017248,
        "accuracy": 0.033597,
        "main_score": 0.017248,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.002306,
        "recall": 0.002964,
        "f1": 0.00247,
        "accuracy": 0.002964,
        "main_score": 0.00247,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009033,
        "recall": 0.023715,
        "f1": 0.010925,
        "accuracy": 0.023715,
        "main_score": 0.010925,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.00132,
        "recall": 0.002964,
        "f1": 0.001486,
        "accuracy": 0.002964,
        "main_score": 0.001486,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005298,
        "recall": 0.016798,
        "f1": 0.006507,
        "accuracy": 0.016798,
        "main_score": 0.006507,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.003462,
        "recall": 0.004941,
        "f1": 0.003629,
        "accuracy": 0.004941,
        "main_score": 0.003629,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009493,
        "recall": 0.027668,
        "f1": 0.011348,
        "accuracy": 0.027668,
        "main_score": 0.011348,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.003294,
        "recall": 0.003953,
        "f1": 0.003458,
        "accuracy": 0.003953,
        "main_score": 0.003458,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016021,
        "recall": 0.033597,
        "f1": 0.017703,
        "accuracy": 0.033597,
        "main_score": 0.017703,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.008399,
        "recall": 0.009881,
        "f1": 0.008893,
        "accuracy": 0.009881,
        "main_score": 0.008893,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021624,
        "recall": 0.054348,
        "f1": 0.02513,
        "accuracy": 0.054348,
        "main_score": 0.02513,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006863,
        "recall": 0.019763,
        "f1": 0.008354,
        "accuracy": 0.019763,
        "main_score": 0.008354,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.006258,
        "recall": 0.006917,
        "f1": 0.006423,
        "accuracy": 0.006917,
        "main_score": 0.006423,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018709,
        "recall": 0.043478,
        "f1": 0.021723,
        "accuracy": 0.043478,
        "main_score": 0.021723,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.00527,
        "recall": 0.005929,
        "f1": 0.005435,
        "accuracy": 0.005929,
        "main_score": 0.005435,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014198,
        "recall": 0.038538,
        "f1": 0.016439,
        "accuracy": 0.038538,
        "main_score": 0.016439,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.002472,
        "recall": 0.003953,
        "f1": 0.002637,
        "accuracy": 0.003953,
        "main_score": 0.002637,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009712,
        "recall": 0.022727,
        "f1": 0.011496,
        "accuracy": 0.022727,
        "main_score": 0.011496,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.003294,
        "recall": 0.003953,
        "f1": 0.003458,
        "accuracy": 0.003953,
        "main_score": 0.003458,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013341,
        "recall": 0.028656,
        "f1": 0.01515,
        "accuracy": 0.028656,
        "main_score": 0.01515,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.004776,
        "recall": 0.005929,
        "f1": 0.005105,
        "accuracy": 0.005929,
        "main_score": 0.005105,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016353,
        "recall": 0.041502,
        "f1": 0.019345,
        "accuracy": 0.041502,
        "main_score": 0.019345,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.010871,
        "recall": 0.012846,
        "f1": 0.011201,
        "accuracy": 0.012846,
        "main_score": 0.011201,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007583,
        "recall": 0.021739,
        "f1": 0.008676,
        "accuracy": 0.021739,
        "main_score": 0.008676,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 52.88905692100525,
  "kg_co2_emissions": 0.0019002347679105088
}