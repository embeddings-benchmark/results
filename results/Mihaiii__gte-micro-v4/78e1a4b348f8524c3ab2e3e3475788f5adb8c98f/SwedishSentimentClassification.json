{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.723291,
        "f1": 0.721734,
        "f1_weighted": 0.721721,
        "ap": 0.665496,
        "ap_weighted": 0.665496,
        "scores_per_experiment": [
          {
            "accuracy": 0.724609,
            "f1": 0.720027,
            "f1_weighted": 0.720132,
            "ap": 0.653599,
            "ap_weighted": 0.653599
          },
          {
            "accuracy": 0.717285,
            "f1": 0.713642,
            "f1_weighted": 0.713547,
            "ap": 0.671482,
            "ap_weighted": 0.671482
          },
          {
            "accuracy": 0.691895,
            "f1": 0.691503,
            "f1_weighted": 0.69147,
            "ap": 0.637171,
            "ap_weighted": 0.637171
          },
          {
            "accuracy": 0.708496,
            "f1": 0.705774,
            "f1_weighted": 0.705691,
            "ap": 0.659868,
            "ap_weighted": 0.659868
          },
          {
            "accuracy": 0.726562,
            "f1": 0.726558,
            "f1_weighted": 0.726555,
            "ap": 0.666498,
            "ap_weighted": 0.666498
          },
          {
            "accuracy": 0.722168,
            "f1": 0.720955,
            "f1_weighted": 0.721009,
            "ap": 0.655975,
            "ap_weighted": 0.655975
          },
          {
            "accuracy": 0.736816,
            "f1": 0.736583,
            "f1_weighted": 0.736606,
            "ap": 0.672715,
            "ap_weighted": 0.672715
          },
          {
            "accuracy": 0.754395,
            "f1": 0.754286,
            "f1_weighted": 0.754301,
            "ap": 0.690707,
            "ap_weighted": 0.690707
          },
          {
            "accuracy": 0.718262,
            "f1": 0.717068,
            "f1_weighted": 0.717015,
            "ap": 0.665564,
            "ap_weighted": 0.665564
          },
          {
            "accuracy": 0.732422,
            "f1": 0.73094,
            "f1_weighted": 0.730881,
            "ap": 0.681377,
            "ap_weighted": 0.681377
          }
        ],
        "main_score": 0.723291,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.72251,
        "f1": 0.720977,
        "f1_weighted": 0.720971,
        "ap": 0.664194,
        "ap_weighted": 0.664194,
        "scores_per_experiment": [
          {
            "accuracy": 0.708496,
            "f1": 0.702657,
            "f1_weighted": 0.702738,
            "ap": 0.63894,
            "ap_weighted": 0.63894
          },
          {
            "accuracy": 0.724121,
            "f1": 0.721161,
            "f1_weighted": 0.721105,
            "ap": 0.676553,
            "ap_weighted": 0.676553
          },
          {
            "accuracy": 0.683594,
            "f1": 0.683157,
            "f1_weighted": 0.683134,
            "ap": 0.629255,
            "ap_weighted": 0.629255
          },
          {
            "accuracy": 0.719238,
            "f1": 0.716452,
            "f1_weighted": 0.716398,
            "ap": 0.67078,
            "ap_weighted": 0.67078
          },
          {
            "accuracy": 0.737793,
            "f1": 0.73779,
            "f1_weighted": 0.737792,
            "ap": 0.676029,
            "ap_weighted": 0.676029
          },
          {
            "accuracy": 0.723145,
            "f1": 0.722329,
            "f1_weighted": 0.722358,
            "ap": 0.65737,
            "ap_weighted": 0.65737
          },
          {
            "accuracy": 0.726562,
            "f1": 0.726205,
            "f1_weighted": 0.726224,
            "ap": 0.662059,
            "ap_weighted": 0.662059
          },
          {
            "accuracy": 0.76416,
            "f1": 0.764002,
            "f1_weighted": 0.764014,
            "ap": 0.699348,
            "ap_weighted": 0.699348
          },
          {
            "accuracy": 0.693848,
            "f1": 0.692845,
            "f1_weighted": 0.692811,
            "ap": 0.640442,
            "ap_weighted": 0.640442
          },
          {
            "accuracy": 0.744141,
            "f1": 0.743168,
            "f1_weighted": 0.743138,
            "ap": 0.691163,
            "ap_weighted": 0.691163
          }
        ],
        "main_score": 0.72251,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 14.729902029037476,
  "kg_co2_emissions": 0.0004310299942129573
}