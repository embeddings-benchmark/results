{
  "dataset_revision": "cec3923e16519efe51d535497e711932b8f1dc44",
  "task_name": "PunjabiNewsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.596815,
        "f1": 0.511177,
        "f1_weighted": 0.642604,
        "ap": 0.197613,
        "ap_weighted": 0.197613,
        "scores_per_experiment": [
          {
            "accuracy": 0.707006,
            "f1": 0.558773,
            "f1_weighted": 0.729811,
            "ap": 0.198065,
            "ap_weighted": 0.198065
          },
          {
            "accuracy": 0.56051,
            "f1": 0.485344,
            "f1_weighted": 0.616884,
            "ap": 0.182609,
            "ap_weighted": 0.182609
          },
          {
            "accuracy": 0.656051,
            "f1": 0.56118,
            "f1_weighted": 0.697638,
            "ap": 0.219268,
            "ap_weighted": 0.219268
          },
          {
            "accuracy": 0.675159,
            "f1": 0.535907,
            "f1_weighted": 0.705924,
            "ap": 0.187381,
            "ap_weighted": 0.187381
          },
          {
            "accuracy": 0.566879,
            "f1": 0.511172,
            "f1_weighted": 0.621535,
            "ap": 0.210719,
            "ap_weighted": 0.210719
          },
          {
            "accuracy": 0.541401,
            "f1": 0.491909,
            "f1_weighted": 0.597963,
            "ap": 0.202925,
            "ap_weighted": 0.202925
          },
          {
            "accuracy": 0.547771,
            "f1": 0.492048,
            "f1_weighted": 0.604565,
            "ap": 0.198026,
            "ap_weighted": 0.198026
          },
          {
            "accuracy": 0.694268,
            "f1": 0.549498,
            "f1_weighted": 0.720294,
            "ap": 0.193486,
            "ap_weighted": 0.193486
          },
          {
            "accuracy": 0.535032,
            "f1": 0.467252,
            "f1_weighted": 0.594339,
            "ap": 0.176946,
            "ap_weighted": 0.176946
          },
          {
            "accuracy": 0.484076,
            "f1": 0.45869,
            "f1_weighted": 0.53709,
            "ap": 0.206708,
            "ap_weighted": 0.206708
          }
        ],
        "main_score": 0.596815,
        "hf_subset": "default",
        "languages": [
          "pan-Guru"
        ]
      }
    ]
  },
  "evaluation_time": 7.669050931930542,
  "kg_co2_emissions": 0.00022094715693371267
}