{
  "dataset_revision": "264a18480c529d9e922483839b4b9758e690b762",
  "evaluation_time": 2319.388787984848,
  "kg_co2_emissions": 0.1356055708898182,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.109375,
        "f1": 0.09008556547619047,
        "hf_subset": "eng_Latn-aai_Latn",
        "languages": [
          "eng-Latn",
          "aai-Latn"
        ],
        "main_score": 0.09008556547619047,
        "precision": 0.08458891369047619,
        "recall": 0.109375
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07491303066037736,
        "hf_subset": "aai_Latn-eng_Latn",
        "languages": [
          "aai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07491303066037736,
        "precision": 0.0673206381911739,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.015625,
        "hf_subset": "eng_Latn-aak_Arab",
        "languages": [
          "eng-Latn",
          "aak-Arab"
        ],
        "main_score": 0.015625,
        "precision": 0.015625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "aak_Arab-eng_Latn",
        "languages": [
          "aak-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.021528991841491842,
        "hf_subset": "eng_Latn-aau_Latn",
        "languages": [
          "eng-Latn",
          "aau-Latn"
        ],
        "main_score": 0.021528991841491842,
        "precision": 0.014560222763347763,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00911261047979798,
        "hf_subset": "aau_Latn-eng_Latn",
        "languages": [
          "aau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00911261047979798,
        "precision": 0.008523011818910256,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014929173870675393,
        "hf_subset": "eng_Latn-aaz_Latn",
        "languages": [
          "eng-Latn",
          "aaz-Latn"
        ],
        "main_score": 0.014929173870675393,
        "precision": 0.012081473214285713,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019397670981144133,
        "hf_subset": "aaz_Latn-eng_Latn",
        "languages": [
          "aaz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019397670981144133,
        "precision": 0.01825556024774775,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03142209353146853,
        "hf_subset": "eng_Latn-abt_Latn",
        "languages": [
          "eng-Latn",
          "abt-Latn"
        ],
        "main_score": 0.03142209353146853,
        "precision": 0.028206638558201054,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018451558371575583,
        "hf_subset": "abt_Latn-eng_Latn",
        "languages": [
          "abt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018451558371575583,
        "precision": 0.01729313344038208,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04011346726190476,
        "hf_subset": "eng_Latn-abx_Latn",
        "languages": [
          "eng-Latn",
          "abx-Latn"
        ],
        "main_score": 0.04011346726190476,
        "precision": 0.03408668154761905,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.051897321428571425,
        "hf_subset": "abx_Latn-eng_Latn",
        "languages": [
          "abx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.051897321428571425,
        "precision": 0.04474614270050126,
        "recall": 0.078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00018601190476190475,
        "hf_subset": "eng_Latn-aby_Latn",
        "languages": [
          "eng-Latn",
          "aby-Latn"
        ],
        "main_score": 0.00018601190476190475,
        "precision": 9.527439024390244e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0001240079365079365,
        "hf_subset": "aby_Latn-eng_Latn",
        "languages": [
          "aby-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001240079365079365,
        "precision": 6.300403225806451e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.011103053678439372,
        "hf_subset": "eng_Latn-acf_Latn",
        "languages": [
          "eng-Latn",
          "acf-Latn"
        ],
        "main_score": 0.011103053678439372,
        "precision": 0.007283211580086581,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01711309523809524,
        "hf_subset": "acf_Latn-eng_Latn",
        "languages": [
          "acf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01711309523809524,
        "precision": 0.015720274390243903,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.018694410059458235,
        "hf_subset": "eng_Latn-acr_Latn",
        "languages": [
          "eng-Latn",
          "acr-Latn"
        ],
        "main_score": 0.018694410059458235,
        "precision": 0.013338236541875523,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.027257745821002745,
        "hf_subset": "acr_Latn-eng_Latn",
        "languages": [
          "acr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027257745821002745,
        "precision": 0.025651914449797513,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.031901041666666664,
        "hf_subset": "eng_Latn-acu_Latn",
        "languages": [
          "eng-Latn",
          "acu-Latn"
        ],
        "main_score": 0.031901041666666664,
        "precision": 0.028525904605263157,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01183197463768116,
        "hf_subset": "acu_Latn-eng_Latn",
        "languages": [
          "acu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01183197463768116,
        "precision": 0.011776194852941176,
        "recall": 0.015625
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.10737900656328964,
        "hf_subset": "eng_Latn-adz_Latn",
        "languages": [
          "eng-Latn",
          "adz-Latn"
        ],
        "main_score": 0.10737900656328964,
        "precision": 0.09748186383928573,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.109375,
        "f1": 0.08245907738095237,
        "hf_subset": "adz_Latn-eng_Latn",
        "languages": [
          "adz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08245907738095237,
        "precision": 0.0744837194055944,
        "recall": 0.109375
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06265231847049164,
        "hf_subset": "eng_Latn-aer_Latn",
        "languages": [
          "eng-Latn",
          "aer-Latn"
        ],
        "main_score": 0.06265231847049164,
        "precision": 0.0574800037202381,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04778365952206481,
        "hf_subset": "aer_Latn-eng_Latn",
        "languages": [
          "aer-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04778365952206481,
        "precision": 0.04505306976010101,
        "recall": 0.0625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009905133928571428,
        "hf_subset": "eng_Latn-aey_Latn",
        "languages": [
          "eng-Latn",
          "aey-Latn"
        ],
        "main_score": 0.009905133928571428,
        "precision": 0.00798233695652174,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010335219034797017,
        "hf_subset": "aey_Latn-eng_Latn",
        "languages": [
          "aey-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010335219034797017,
        "precision": 0.009228515625,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012539628623188404,
        "hf_subset": "eng_Latn-agd_Latn",
        "languages": [
          "eng-Latn",
          "agd-Latn"
        ],
        "main_score": 0.012539628623188404,
        "precision": 0.009635416666666667,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "agd_Latn-eng_Latn",
        "languages": [
          "agd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011458405218684823,
        "hf_subset": "eng_Latn-agg_Latn",
        "languages": [
          "eng-Latn",
          "agg-Latn"
        ],
        "main_score": 0.011458405218684823,
        "precision": 0.00909908234126984,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007903343023255814,
        "hf_subset": "agg_Latn-eng_Latn",
        "languages": [
          "agg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007903343023255814,
        "precision": 0.007858455882352941,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011997767857142856,
        "hf_subset": "eng_Latn-agm_Latn",
        "languages": [
          "eng-Latn",
          "agm-Latn"
        ],
        "main_score": 0.011997767857142856,
        "precision": 0.010416666666666668,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "agm_Latn-eng_Latn",
        "languages": [
          "agm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.078125,
        "f1": 0.04817708333333333,
        "hf_subset": "eng_Latn-agn_Latn",
        "languages": [
          "eng-Latn",
          "agn-Latn"
        ],
        "main_score": 0.04817708333333333,
        "precision": 0.04153127499764728,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.02731300052072111,
        "hf_subset": "agn_Latn-eng_Latn",
        "languages": [
          "agn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02731300052072111,
        "precision": 0.02306961860902578,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020780066287878787,
        "hf_subset": "eng_Latn-agr_Latn",
        "languages": [
          "eng-Latn",
          "agr-Latn"
        ],
        "main_score": 0.020780066287878787,
        "precision": 0.01795839966695945,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008113819808027924,
        "hf_subset": "agr_Latn-eng_Latn",
        "languages": [
          "agr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008113819808027924,
        "precision": 0.006856496710526316,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01693346609477124,
        "hf_subset": "eng_Latn-agt_Latn",
        "languages": [
          "eng-Latn",
          "agt-Latn"
        ],
        "main_score": 0.01693346609477124,
        "precision": 0.013734827536425017,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01629389129389129,
        "hf_subset": "agt_Latn-eng_Latn",
        "languages": [
          "agt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01629389129389129,
        "precision": 0.014787244496855347,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.024294133771929825,
        "hf_subset": "eng_Latn-agu_Latn",
        "languages": [
          "eng-Latn",
          "agu-Latn"
        ],
        "main_score": 0.024294133771929825,
        "precision": 0.021720157657657658,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0072265625,
        "hf_subset": "agu_Latn-eng_Latn",
        "languages": [
          "agu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0072265625,
        "precision": 0.005241158963585435,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018909143518518516,
        "hf_subset": "eng_Latn-aia_Latn",
        "languages": [
          "eng-Latn",
          "aia-Latn"
        ],
        "main_score": 0.018909143518518516,
        "precision": 0.01793395748987854,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007949561403508772,
        "hf_subset": "aia_Latn-eng_Latn",
        "languages": [
          "aia-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007949561403508772,
        "precision": 0.007882254464285714,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020025712025316454,
        "hf_subset": "eng_Latn-aii_Syrc",
        "languages": [
          "eng-Latn",
          "aii-Syrc"
        ],
        "main_score": 0.0020025712025316454,
        "precision": 0.001326963906581741,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0008336828859060403,
        "hf_subset": "aii_Syrc-eng_Latn",
        "languages": [
          "aii-Syrc",
          "eng-Latn"
        ],
        "main_score": 0.0008336828859060403,
        "precision": 0.00046042135885885884,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03165890548029557,
        "hf_subset": "eng_Latn-aka_Latn",
        "languages": [
          "eng-Latn",
          "aka-Latn"
        ],
        "main_score": 0.03165890548029557,
        "precision": 0.02999441964285714,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "aka_Latn-eng_Latn",
        "languages": [
          "aka-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018938948934837094,
        "hf_subset": "eng_Latn-ake_Latn",
        "languages": [
          "eng-Latn",
          "ake-Latn"
        ],
        "main_score": 0.018938948934837094,
        "precision": 0.016956676136363636,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005604619565217391,
        "hf_subset": "ake_Latn-eng_Latn",
        "languages": [
          "ake-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005604619565217391,
        "precision": 0.00029239766081871346,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02786627435064935,
        "hf_subset": "eng_Latn-alp_Latn",
        "languages": [
          "eng-Latn",
          "alp-Latn"
        ],
        "main_score": 0.02786627435064935,
        "precision": 0.02603691881035631,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004494432471264367,
        "hf_subset": "alp_Latn-eng_Latn",
        "languages": [
          "alp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004494432471264367,
        "precision": 0.0030473602484472045,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.03843283901204159,
        "hf_subset": "eng_Latn-alq_Latn",
        "languages": [
          "eng-Latn",
          "alq-Latn"
        ],
        "main_score": 0.03843283901204159,
        "precision": 0.033156748276233564,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022980220734126984,
        "hf_subset": "alq_Latn-eng_Latn",
        "languages": [
          "alq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022980220734126984,
        "precision": 0.020471715784215784,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011160714285714284,
        "hf_subset": "eng_Latn-als_Latn",
        "languages": [
          "eng-Latn",
          "als-Latn"
        ],
        "main_score": 0.011160714285714284,
        "precision": 0.009161646586345381,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008060515873015872,
        "hf_subset": "als_Latn-eng_Latn",
        "languages": [
          "als-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008060515873015872,
        "precision": 0.0063495710784313725,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.07182192084535835,
        "hf_subset": "eng_Latn-aly_Latn",
        "languages": [
          "eng-Latn",
          "aly-Latn"
        ],
        "main_score": 0.07182192084535835,
        "precision": 0.06777073476292225,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.05674715909090909,
        "hf_subset": "aly_Latn-eng_Latn",
        "languages": [
          "aly-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05674715909090909,
        "precision": 0.05469796316964286,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005859375,
        "hf_subset": "eng_Latn-ame_Latn",
        "languages": [
          "eng-Latn",
          "ame-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005208333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00501104797979798,
        "hf_subset": "ame_Latn-eng_Latn",
        "languages": [
          "ame-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00501104797979798,
        "precision": 0.0045166015625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020182291666666664,
        "hf_subset": "eng_Latn-amf_Latn",
        "languages": [
          "eng-Latn",
          "amf-Latn"
        ],
        "main_score": 0.020182291666666664,
        "precision": 0.017361111111111112,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002662907268170426,
        "hf_subset": "amf_Latn-eng_Latn",
        "languages": [
          "amf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002662907268170426,
        "precision": 0.001982717803030303,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020810081845238096,
        "hf_subset": "eng_Latn-amk_Latn",
        "languages": [
          "eng-Latn",
          "amk-Latn"
        ],
        "main_score": 0.020810081845238096,
        "precision": 0.017745535714285714,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005831312859195402,
        "hf_subset": "amk_Latn-eng_Latn",
        "languages": [
          "amk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005831312859195402,
        "precision": 0.005016447368421053,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006265782828282828,
        "hf_subset": "eng_Latn-amm_Latn",
        "languages": [
          "eng-Latn",
          "amm-Latn"
        ],
        "main_score": 0.006265782828282828,
        "precision": 0.005219184027777778,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.0690104166666664e-05,
        "hf_subset": "amm_Latn-eng_Latn",
        "languages": [
          "amm-Latn",
          "eng-Latn"
        ],
        "main_score": 4.0690104166666664e-05,
        "precision": 2.0451570680628273e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02342653588366241,
        "hf_subset": "eng_Latn-amn_Latn",
        "languages": [
          "eng-Latn",
          "amn-Latn"
        ],
        "main_score": 0.02342653588366241,
        "precision": 0.018464964110644258,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01903692305573915,
        "hf_subset": "amn_Latn-eng_Latn",
        "languages": [
          "amn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01903692305573915,
        "precision": 0.016890092329545456,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.026171875,
        "hf_subset": "eng_Latn-amo_Latn",
        "languages": [
          "eng-Latn",
          "amo-Latn"
        ],
        "main_score": 0.026171875,
        "precision": 0.020584643504140784,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017637310606060604,
        "hf_subset": "amo_Latn-eng_Latn",
        "languages": [
          "amo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017637310606060604,
        "precision": 0.016015625,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.030386117788461536,
        "hf_subset": "eng_Latn-amp_Latn",
        "languages": [
          "eng-Latn",
          "amp-Latn"
        ],
        "main_score": 0.030386117788461536,
        "precision": 0.027112926136363635,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008112980769230768,
        "hf_subset": "amp_Latn-eng_Latn",
        "languages": [
          "amp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008112980769230768,
        "precision": 0.00796875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02353515625,
        "hf_subset": "eng_Latn-amr_Latn",
        "languages": [
          "eng-Latn",
          "amr-Latn"
        ],
        "main_score": 0.02353515625,
        "precision": 0.020827414772727273,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010696663533834586,
        "hf_subset": "amr_Latn-eng_Latn",
        "languages": [
          "amr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010696663533834586,
        "precision": 0.009545678490990991,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.030772569444444446,
        "hf_subset": "eng_Latn-amu_Latn",
        "languages": [
          "eng-Latn",
          "amu-Latn"
        ],
        "main_score": 0.030772569444444446,
        "precision": 0.026844982784780577,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02765151515151515,
        "hf_subset": "amu_Latn-eng_Latn",
        "languages": [
          "amu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02765151515151515,
        "precision": 0.02396237080103359,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.14378638174019606,
        "hf_subset": "eng_Latn-amx_Latn",
        "languages": [
          "eng-Latn",
          "amx-Latn"
        ],
        "main_score": 0.14378638174019606,
        "precision": 0.13103841145833334,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.13323510599415203,
        "hf_subset": "amx_Latn-eng_Latn",
        "languages": [
          "amx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.13323510599415203,
        "precision": 0.12298968890765766,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.06306306306306306,
        "f1": 0.0545045045045045,
        "hf_subset": "eng_Latn-anh_Latn",
        "languages": [
          "eng-Latn",
          "anh-Latn"
        ],
        "main_score": 0.0545045045045045,
        "precision": 0.054285054285054285,
        "recall": 0.06306306306306306
      },
      {
        "accuracy": 0.04504504504504504,
        "f1": 0.028875028875028873,
        "hf_subset": "anh_Latn-eng_Latn",
        "languages": [
          "anh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028875028875028873,
        "precision": 0.025702172760996293,
        "recall": 0.04504504504504504
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.0178242700636289,
        "hf_subset": "eng_Latn-anv_Latn",
        "languages": [
          "eng-Latn",
          "anv-Latn"
        ],
        "main_score": 0.0178242700636289,
        "precision": 0.014621435771889398,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00674715909090909,
        "hf_subset": "anv_Latn-eng_Latn",
        "languages": [
          "anv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00674715909090909,
        "precision": 0.0059814453125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-aoi_Latn",
        "languages": [
          "eng-Latn",
          "aoi-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0019345238095238096,
        "hf_subset": "aoi_Latn-eng_Latn",
        "languages": [
          "aoi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0019345238095238096,
        "precision": 0.001171875,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.02682482955504897,
        "hf_subset": "eng_Latn-aoj_Latn",
        "languages": [
          "eng-Latn",
          "aoj-Latn"
        ],
        "main_score": 0.02682482955504897,
        "precision": 0.023737426994050636,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.01842813581094831,
        "hf_subset": "aoj_Latn-eng_Latn",
        "languages": [
          "aoj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01842813581094831,
        "precision": 0.01567166686135016,
        "recall": 0.046875
      },
      {
        "accuracy": 0.109375,
        "f1": 0.08823784722222222,
        "hf_subset": "eng_Latn-aom_Latn",
        "languages": [
          "eng-Latn",
          "aom-Latn"
        ],
        "main_score": 0.08823784722222222,
        "precision": 0.08178168402777777,
        "recall": 0.109375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05879481504207573,
        "hf_subset": "aom_Latn-eng_Latn",
        "languages": [
          "aom-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05879481504207573,
        "precision": 0.05447892176071055,
        "recall": 0.078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.008917485870610871,
        "hf_subset": "eng_Latn-aon_Latn",
        "languages": [
          "eng-Latn",
          "aon-Latn"
        ],
        "main_score": 0.008917485870610871,
        "precision": 0.006766862333268583,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004146493544600939,
        "hf_subset": "aon_Latn-eng_Latn",
        "languages": [
          "aon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004146493544600939,
        "precision": 0.004028261198547215,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012276785714285714,
        "hf_subset": "eng_Latn-apb_Latn",
        "languages": [
          "eng-Latn",
          "apb-Latn"
        ],
        "main_score": 0.012276785714285714,
        "precision": 0.010066105769230768,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "apb_Latn-eng_Latn",
        "languages": [
          "apb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03606189919149478,
        "hf_subset": "eng_Latn-ape_Latn",
        "languages": [
          "eng-Latn",
          "ape-Latn"
        ],
        "main_score": 0.03606189919149478,
        "precision": 0.03207711884469697,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010056053848741909,
        "hf_subset": "ape_Latn-eng_Latn",
        "languages": [
          "ape-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010056053848741909,
        "precision": 0.0078113709573141045,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004339952175543886,
        "hf_subset": "eng_Latn-apn_Latn",
        "languages": [
          "eng-Latn",
          "apn-Latn"
        ],
        "main_score": 0.004339952175543886,
        "precision": 0.004129464285714286,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.167431192660551e-05,
        "hf_subset": "apn_Latn-eng_Latn",
        "languages": [
          "apn-Latn",
          "eng-Latn"
        ],
        "main_score": 7.167431192660551e-05,
        "precision": 3.616898148148148e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024049789186507936,
        "hf_subset": "eng_Latn-apr_Latn",
        "languages": [
          "eng-Latn",
          "apr-Latn"
        ],
        "main_score": 0.024049789186507936,
        "precision": 0.020580428685897434,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009474863967051467,
        "hf_subset": "apr_Latn-eng_Latn",
        "languages": [
          "apr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009474863967051467,
        "precision": 0.0087255248394802,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0024157072368421054,
        "hf_subset": "eng_Latn-apu_Latn",
        "languages": [
          "eng-Latn",
          "apu-Latn"
        ],
        "main_score": 0.0024157072368421054,
        "precision": 0.0014090401785714286,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.793478260869565e-05,
        "hf_subset": "apu_Latn-eng_Latn",
        "languages": [
          "apu-Latn",
          "eng-Latn"
        ],
        "main_score": 6.793478260869565e-05,
        "precision": 3.426535087719298e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.10560234036796537,
        "hf_subset": "eng_Latn-apw_Latn",
        "languages": [
          "eng-Latn",
          "apw-Latn"
        ],
        "main_score": 0.10560234036796537,
        "precision": 0.09468005952380953,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.08411458333333333,
        "hf_subset": "apw_Latn-eng_Latn",
        "languages": [
          "apw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08411458333333333,
        "precision": 0.07934027777777777,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026785714285714286,
        "hf_subset": "eng_Latn-apz_Latn",
        "languages": [
          "eng-Latn",
          "apz-Latn"
        ],
        "main_score": 0.0026785714285714286,
        "precision": 0.0016276041666666665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003976004464285714,
        "hf_subset": "apz_Latn-eng_Latn",
        "languages": [
          "apz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003976004464285714,
        "precision": 0.003941441441441441,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002501539408866995,
        "hf_subset": "eng_Latn-arb_Arab",
        "languages": [
          "eng-Latn",
          "arb-Arab"
        ],
        "main_score": 0.002501539408866995,
        "precision": 0.001441592261904762,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00043402777777777775,
        "hf_subset": "arb_Arab-eng_Latn",
        "languages": [
          "arb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.00043402777777777775,
        "precision": 0.00022977941176470588,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07933913559941519,
        "hf_subset": "eng_Latn-are_Latn",
        "languages": [
          "eng-Latn",
          "are-Latn"
        ],
        "main_score": 0.07933913559941519,
        "precision": 0.07171533978174603,
        "recall": 0.109375
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.08054969031531531,
        "hf_subset": "are_Latn-eng_Latn",
        "languages": [
          "are-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08054969031531531,
        "precision": 0.07608506944444444,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.026041666666666664,
        "hf_subset": "eng_Latn-arl_Latn",
        "languages": [
          "eng-Latn",
          "arl-Latn"
        ],
        "main_score": 0.026041666666666664,
        "precision": 0.025390625,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007904411764705882,
        "hf_subset": "arl_Latn-eng_Latn",
        "languages": [
          "arl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007904411764705882,
        "precision": 0.007859002976190476,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014248197960618846,
        "hf_subset": "eng_Latn-arn_Latn",
        "languages": [
          "eng-Latn",
          "arn-Latn"
        ],
        "main_score": 0.014248197960618846,
        "precision": 0.012061798878205129,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011644345238095238,
        "hf_subset": "arn_Latn-eng_Latn",
        "languages": [
          "arn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011644345238095238,
        "precision": 0.010025748800419855,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.1827956989247312,
        "f1": 0.12050969622127117,
        "hf_subset": "eng_Latn-arp_Latn",
        "languages": [
          "eng-Latn",
          "arp-Latn"
        ],
        "main_score": 0.12050969622127117,
        "precision": 0.10649641577060932,
        "recall": 0.1827956989247312
      },
      {
        "accuracy": 0.15053763440860216,
        "f1": 0.12493599590373783,
        "hf_subset": "arp_Latn-eng_Latn",
        "languages": [
          "arp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12493599590373783,
        "precision": 0.1164874551971326,
        "recall": 0.15053763440860216
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00033967391304347825,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.00033967391304347825,
        "precision": 0.0001775568181818182,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0001240079365079365,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0001240079365079365,
        "precision": 6.300403225806451e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004477415966386554,
        "hf_subset": "eng_Latn-aso_Latn",
        "languages": [
          "eng-Latn",
          "aso-Latn"
        ],
        "main_score": 0.004477415966386554,
        "precision": 0.00420700294384058,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016571969696969695,
        "hf_subset": "aso_Latn-eng_Latn",
        "languages": [
          "aso-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0016571969696969695,
        "precision": 0.0009672619047619048,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002436755952380953,
        "hf_subset": "eng_Latn-ata_Latn",
        "languages": [
          "eng-Latn",
          "ata-Latn"
        ],
        "main_score": 0.002436755952380953,
        "precision": 0.0014576535307898259,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003982099514563107,
        "hf_subset": "ata_Latn-eng_Latn",
        "languages": [
          "ata-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003982099514563107,
        "precision": 0.003944546568627451,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020941840277777776,
        "hf_subset": "eng_Latn-atb_Latn",
        "languages": [
          "eng-Latn",
          "atb-Latn"
        ],
        "main_score": 0.020941840277777776,
        "precision": 0.01691313244047619,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02427535662890036,
        "hf_subset": "atb_Latn-eng_Latn",
        "languages": [
          "atb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02427535662890036,
        "precision": 0.023880450099469496,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020089285714285716,
        "hf_subset": "eng_Latn-atd_Latn",
        "languages": [
          "eng-Latn",
          "atd-Latn"
        ],
        "main_score": 0.020089285714285716,
        "precision": 0.017424791430995477,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011979166666666666,
        "hf_subset": "atd_Latn-eng_Latn",
        "languages": [
          "atd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011979166666666666,
        "precision": 0.0107421875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0018880208333333333,
        "hf_subset": "eng_Latn-atg_Latn",
        "languages": [
          "eng-Latn",
          "atg-Latn"
        ],
        "main_score": 0.0018880208333333333,
        "precision": 0.001146399456521739,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013881340579710145,
        "hf_subset": "atg_Latn-eng_Latn",
        "languages": [
          "atg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013881340579710145,
        "precision": 0.012956574675324677,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013526895133053222,
        "hf_subset": "eng_Latn-att_Latn",
        "languages": [
          "eng-Latn",
          "att-Latn"
        ],
        "main_score": 0.013526895133053222,
        "precision": 0.01147615947420635,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.022224195075757576,
        "hf_subset": "att_Latn-eng_Latn",
        "languages": [
          "att-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022224195075757576,
        "precision": 0.021529274425287355,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00033967391304347825,
        "hf_subset": "eng_Latn-auc_Latn",
        "languages": [
          "eng-Latn",
          "auc-Latn"
        ],
        "main_score": 0.00033967391304347825,
        "precision": 0.0001775568181818182,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00030614459325396825,
        "hf_subset": "auc_Latn-eng_Latn",
        "languages": [
          "auc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00030614459325396825,
        "precision": 0.00015725806451612903,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06509271036666184,
        "hf_subset": "eng_Latn-aui_Latn",
        "languages": [
          "eng-Latn",
          "aui-Latn"
        ],
        "main_score": 0.06509271036666184,
        "precision": 0.05825596838197645,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.078125,
        "f1": 0.057861485687659954,
        "hf_subset": "aui_Latn-eng_Latn",
        "languages": [
          "aui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.057861485687659954,
        "precision": 0.053578095369785084,
        "recall": 0.078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013020833333333333,
        "hf_subset": "eng_Latn-auy_Latn",
        "languages": [
          "eng-Latn",
          "auy-Latn"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.00078125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006510416666666666,
        "hf_subset": "auy_Latn-eng_Latn",
        "languages": [
          "auy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.0003551136363636364,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00859375,
        "hf_subset": "eng_Latn-avt_Latn",
        "languages": [
          "eng-Latn",
          "avt-Latn"
        ],
        "main_score": 0.00859375,
        "precision": 0.007114955357142857,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01243656517094017,
        "hf_subset": "avt_Latn-eng_Latn",
        "languages": [
          "avt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01243656517094017,
        "precision": 0.01110138290229885,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-awb_Latn",
        "languages": [
          "eng-Latn",
          "awb-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.102272727272727e-05,
        "hf_subset": "awb_Latn-eng_Latn",
        "languages": [
          "awb-Latn",
          "eng-Latn"
        ],
        "main_score": 7.102272727272727e-05,
        "precision": 3.5837155963302754e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.050505050505050504,
        "f1": 0.029124579124579126,
        "hf_subset": "eng_Latn-awk_Latn",
        "languages": [
          "eng-Latn",
          "awk-Latn"
        ],
        "main_score": 0.029124579124579126,
        "precision": 0.026413200326243804,
        "recall": 0.050505050505050504
      },
      {
        "accuracy": 0.020202020202020204,
        "f1": 0.020202020202020204,
        "hf_subset": "awk_Latn-eng_Latn",
        "languages": [
          "awk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020202020202020204,
        "precision": 0.020202020202020204,
        "recall": 0.020202020202020204
      },
      {
        "accuracy": 0.1875,
        "f1": 0.13471365108543418,
        "hf_subset": "eng_Latn-awx_Latn",
        "languages": [
          "eng-Latn",
          "awx-Latn"
        ],
        "main_score": 0.13471365108543418,
        "precision": 0.12046812461514778,
        "recall": 0.1875
      },
      {
        "accuracy": 0.140625,
        "f1": 0.11941105769230768,
        "hf_subset": "awx_Latn-eng_Latn",
        "languages": [
          "awx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11941105769230768,
        "precision": 0.11400741880490059,
        "recall": 0.140625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04239211309523809,
        "hf_subset": "eng_Latn-azb_Arab",
        "languages": [
          "eng-Latn",
          "azb-Arab"
        ],
        "main_score": 0.04239211309523809,
        "precision": 0.037077146199388844,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015684185606060608,
        "hf_subset": "azb_Arab-eng_Latn",
        "languages": [
          "azb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.015684185606060608,
        "precision": 0.013411458333333334,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.030056788340336135,
        "hf_subset": "eng_Latn-azg_Latn",
        "languages": [
          "eng-Latn",
          "azg-Latn"
        ],
        "main_score": 0.030056788340336135,
        "precision": 0.02443728146853147,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0187900641025641,
        "hf_subset": "azg_Latn-eng_Latn",
        "languages": [
          "azg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0187900641025641,
        "precision": 0.0167578125,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019401041666666667,
        "hf_subset": "eng_Latn-azz_Latn",
        "languages": [
          "eng-Latn",
          "azz-Latn"
        ],
        "main_score": 0.019401041666666667,
        "precision": 0.015266927083333333,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0075068229467900515,
        "hf_subset": "azz_Latn-eng_Latn",
        "languages": [
          "azz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0075068229467900515,
        "precision": 0.006137424045138888,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02554253472222222,
        "hf_subset": "eng_Latn-bao_Latn",
        "languages": [
          "eng-Latn",
          "bao-Latn"
        ],
        "main_score": 0.02554253472222222,
        "precision": 0.021163504464285714,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019302095473970472,
        "hf_subset": "bao_Latn-eng_Latn",
        "languages": [
          "bao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019302095473970472,
        "precision": 0.017146769807060754,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004557291666666667,
        "hf_subset": "eng_Latn-bba_Latn",
        "languages": [
          "eng-Latn",
          "bba-Latn"
        ],
        "main_score": 0.004557291666666667,
        "precision": 0.004261363636363636,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010235942725752508,
        "hf_subset": "bba_Latn-eng_Latn",
        "languages": [
          "bba-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010235942725752508,
        "precision": 0.008185763888888888,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "eng_Latn-bbb_Latn",
        "languages": [
          "eng-Latn",
          "bbb-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005013020833333333,
        "hf_subset": "bbb_Latn-eng_Latn",
        "languages": [
          "bbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005013020833333333,
        "precision": 0.004510114734299517,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01617136437908497,
        "hf_subset": "eng_Latn-bbr_Latn",
        "languages": [
          "eng-Latn",
          "bbr-Latn"
        ],
        "main_score": 0.01617136437908497,
        "precision": 0.013511439732142859,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.015625,
        "hf_subset": "bbr_Latn-eng_Latn",
        "languages": [
          "bbr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015625,
        "precision": 0.015625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018138371239183933,
        "hf_subset": "eng_Latn-bch_Latn",
        "languages": [
          "eng-Latn",
          "bch-Latn"
        ],
        "main_score": 0.018138371239183933,
        "precision": 0.015869140625,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.012319711538461538,
        "hf_subset": "bch_Latn-eng_Latn",
        "languages": [
          "bch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012319711538461538,
        "precision": 0.012044270833333334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012830946180555556,
        "hf_subset": "eng_Latn-bco_Latn",
        "languages": [
          "eng-Latn",
          "bco-Latn"
        ],
        "main_score": 0.012830946180555556,
        "precision": 0.010844944076420891,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.010416666666666666,
        "hf_subset": "bco_Latn-eng_Latn",
        "languages": [
          "bco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.009765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007413474462365591,
        "hf_subset": "eng_Latn-bdd_Latn",
        "languages": [
          "eng-Latn",
          "bdd-Latn"
        ],
        "main_score": 0.007413474462365591,
        "precision": 0.005338541666666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003253956330128205,
        "hf_subset": "bdd_Latn-eng_Latn",
        "languages": [
          "bdd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003253956330128205,
        "precision": 0.0023032134433962266,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.18666666666666668,
        "f1": 0.12440659340659342,
        "hf_subset": "eng_Latn-bea_Latn",
        "languages": [
          "eng-Latn",
          "bea-Latn"
        ],
        "main_score": 0.12440659340659342,
        "precision": 0.10784126984126985,
        "recall": 0.18666666666666668
      },
      {
        "accuracy": 0.17333333333333334,
        "f1": 0.14644444444444446,
        "hf_subset": "bea_Latn-eng_Latn",
        "languages": [
          "bea-Latn",
          "eng-Latn"
        ],
        "main_score": 0.14644444444444446,
        "precision": 0.13822222222222222,
        "recall": 0.17333333333333334
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0040625,
        "hf_subset": "eng_Latn-bef_Latn",
        "languages": [
          "eng-Latn",
          "bef-Latn"
        ],
        "main_score": 0.0040625,
        "precision": 0.003985969387755102,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "bef_Latn-eng_Latn",
        "languages": [
          "bef-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.06340476472312409,
        "hf_subset": "eng_Latn-bel_Cyrl",
        "languages": [
          "eng-Latn",
          "bel-Cyrl"
        ],
        "main_score": 0.06340476472312409,
        "precision": 0.048737119175627244,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02593625992063492,
        "hf_subset": "bel_Cyrl-eng_Latn",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.02593625992063492,
        "precision": 0.02248069037389497,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007300967261904761,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.007300967261904761,
        "precision": 0.005279356060606061,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026478119180633145,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0026478119180633145,
        "precision": 0.001975070224719101,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018332506613756613,
        "hf_subset": "eng_Latn-beo_Latn",
        "languages": [
          "eng-Latn",
          "beo-Latn"
        ],
        "main_score": 0.018332506613756613,
        "precision": 0.016426282051282052,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005859375,
        "hf_subset": "beo_Latn-eng_Latn",
        "languages": [
          "beo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005208333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.04037388392857143,
        "hf_subset": "eng_Latn-beu_Latn",
        "languages": [
          "eng-Latn",
          "beu-Latn"
        ],
        "main_score": 0.04037388392857143,
        "precision": 0.03220486111111111,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.01978985821759259,
        "hf_subset": "beu_Latn-eng_Latn",
        "languages": [
          "beu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01978985821759259,
        "precision": 0.017222737210494284,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.030719389117826616,
        "hf_subset": "eng_Latn-bgs_Latn",
        "languages": [
          "eng-Latn",
          "bgs-Latn"
        ],
        "main_score": 0.030719389117826616,
        "precision": 0.02806454613095238,
        "recall": 0.046875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.028118322649572647,
        "hf_subset": "bgs_Latn-eng_Latn",
        "languages": [
          "bgs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028118322649572647,
        "precision": 0.023156725683694535,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.025525629866726563,
        "hf_subset": "eng_Latn-bgt_Latn",
        "languages": [
          "eng-Latn",
          "bgt-Latn"
        ],
        "main_score": 0.025525629866726563,
        "precision": 0.02209060813090418,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022899138621794872,
        "hf_subset": "bgt_Latn-eng_Latn",
        "languages": [
          "bgt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022899138621794872,
        "precision": 0.02059092420212766,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.07744505704926201,
        "hf_subset": "eng_Latn-bhg_Latn",
        "languages": [
          "eng-Latn",
          "bhg-Latn"
        ],
        "main_score": 0.07744505704926201,
        "precision": 0.0701401139672939,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.109375,
        "f1": 0.08023178700828157,
        "hf_subset": "bhg_Latn-eng_Latn",
        "languages": [
          "bhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08023178700828157,
        "precision": 0.07218276515151516,
        "recall": 0.109375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006156517094017094,
        "hf_subset": "eng_Latn-bhl_Latn",
        "languages": [
          "eng-Latn",
          "bhl-Latn"
        ],
        "main_score": 0.006156517094017094,
        "precision": 0.005252223782771535,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005572916666666667,
        "hf_subset": "bhl_Latn-eng_Latn",
        "languages": [
          "bhl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005572916666666667,
        "precision": 0.0049355996621621625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "eng_Latn-big_Latn",
        "languages": [
          "eng-Latn",
          "big-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "big_Latn-eng_Latn",
        "languages": [
          "big-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010701100680720246,
        "hf_subset": "eng_Latn-bjk_Latn",
        "languages": [
          "eng-Latn",
          "bjk-Latn"
        ],
        "main_score": 0.010701100680720246,
        "precision": 0.008376818313341751,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.014322916666666666,
        "hf_subset": "bjk_Latn-eng_Latn",
        "languages": [
          "bjk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014322916666666666,
        "precision": 0.013671875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017170730744949493,
        "hf_subset": "eng_Latn-bjp_Latn",
        "languages": [
          "eng-Latn",
          "bjp-Latn"
        ],
        "main_score": 0.017170730744949493,
        "precision": 0.013292100694444444,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0208953373015873,
        "hf_subset": "bjp_Latn-eng_Latn",
        "languages": [
          "bjp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0208953373015873,
        "precision": 0.01882957175925926,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00501104797979798,
        "hf_subset": "eng_Latn-bjr_Latn",
        "languages": [
          "eng-Latn",
          "bjr-Latn"
        ],
        "main_score": 0.00501104797979798,
        "precision": 0.0032145182291666665,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003551136363636364,
        "hf_subset": "bjr_Latn-eng_Latn",
        "languages": [
          "bjr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003551136363636364,
        "precision": 0.00018601190476190475,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0125,
        "hf_subset": "eng_Latn-bjv_Latn",
        "languages": [
          "eng-Latn",
          "bjv-Latn"
        ],
        "main_score": 0.0125,
        "precision": 0.012152777777777778,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0033675401978973405,
        "hf_subset": "bjv_Latn-eng_Latn",
        "languages": [
          "bjv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0033675401978973405,
        "precision": 0.0023705051369863014,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02546502976190476,
        "hf_subset": "eng_Latn-bjz_Latn",
        "languages": [
          "eng-Latn",
          "bjz-Latn"
        ],
        "main_score": 0.02546502976190476,
        "precision": 0.020551215277777778,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010006889244739414,
        "hf_subset": "bjz_Latn-eng_Latn",
        "languages": [
          "bjz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010006889244739414,
        "precision": 0.008279562678896697,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.047205539686008435,
        "hf_subset": "eng_Latn-bkd_Latn",
        "languages": [
          "eng-Latn",
          "bkd-Latn"
        ],
        "main_score": 0.047205539686008435,
        "precision": 0.03862955040961945,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03602430555555555,
        "hf_subset": "bkd_Latn-eng_Latn",
        "languages": [
          "bkd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03602430555555555,
        "precision": 0.03245132688492064,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00020032051282051281,
        "hf_subset": "eng_Latn-bki_Latn",
        "languages": [
          "eng-Latn",
          "bki-Latn"
        ],
        "main_score": 0.00020032051282051281,
        "precision": 0.00010279605263157894,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "bki_Latn-eng_Latn",
        "languages": [
          "bki-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01740451388888889,
        "hf_subset": "eng_Latn-bkq_Latn",
        "languages": [
          "eng-Latn",
          "bkq-Latn"
        ],
        "main_score": 0.01740451388888889,
        "precision": 0.014760044642857142,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01996805726600985,
        "hf_subset": "bkq_Latn-eng_Latn",
        "languages": [
          "bkq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01996805726600985,
        "precision": 0.018343635531135532,
        "recall": 0.03125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.051201923076923075,
        "hf_subset": "eng_Latn-bkx_Latn",
        "languages": [
          "eng-Latn",
          "bkx-Latn"
        ],
        "main_score": 0.051201923076923075,
        "precision": 0.042051091269841266,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.03281926406926407,
        "hf_subset": "bkx_Latn-eng_Latn",
        "languages": [
          "bkx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03281926406926407,
        "precision": 0.025003829656862743,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02630208333333333,
        "hf_subset": "eng_Latn-blw_Latn",
        "languages": [
          "eng-Latn",
          "blw-Latn"
        ],
        "main_score": 0.02630208333333333,
        "precision": 0.023111979166666664,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013401442307692307,
        "hf_subset": "blw_Latn-eng_Latn",
        "languages": [
          "blw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013401442307692307,
        "precision": 0.01275634765625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.03638082837301587,
        "hf_subset": "eng_Latn-blz_Latn",
        "languages": [
          "eng-Latn",
          "blz-Latn"
        ],
        "main_score": 0.03638082837301587,
        "precision": 0.029286728896103897,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.029296875,
        "hf_subset": "blz_Latn-eng_Latn",
        "languages": [
          "blz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029296875,
        "precision": 0.027473958333333333,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.017898379946077313,
        "hf_subset": "eng_Latn-bmh_Latn",
        "languages": [
          "eng-Latn",
          "bmh-Latn"
        ],
        "main_score": 0.017898379946077313,
        "precision": 0.014400183150183151,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012648809523809524,
        "hf_subset": "bmh_Latn-eng_Latn",
        "languages": [
          "bmh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012648809523809524,
        "precision": 0.011212384259259259,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.08661417322834646,
        "f1": 0.0686558916977483,
        "hf_subset": "eng_Latn-bmk_Latn",
        "languages": [
          "eng-Latn",
          "bmk-Latn"
        ],
        "main_score": 0.0686558916977483,
        "precision": 0.06477974037029155,
        "recall": 0.08661417322834646
      },
      {
        "accuracy": 0.10236220472440945,
        "f1": 0.08433945756780402,
        "hf_subset": "bmk_Latn-eng_Latn",
        "languages": [
          "bmk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08433945756780402,
        "precision": 0.08023144834168457,
        "recall": 0.10236220472440945
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02535008394383394,
        "hf_subset": "eng_Latn-bmr_Latn",
        "languages": [
          "eng-Latn",
          "bmr-Latn"
        ],
        "main_score": 0.02535008394383394,
        "precision": 0.021071920955882353,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007243575783972125,
        "hf_subset": "bmr_Latn-eng_Latn",
        "languages": [
          "bmr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007243575783972125,
        "precision": 0.005941737150450211,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.009941533310099487,
        "hf_subset": "eng_Latn-bmu_Latn",
        "languages": [
          "eng-Latn",
          "bmu-Latn"
        ],
        "main_score": 0.009941533310099487,
        "precision": 0.007539563301282051,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018858562446717818,
        "hf_subset": "bmu_Latn-eng_Latn",
        "languages": [
          "bmu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018858562446717818,
        "precision": 0.017909071180555555,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02179315476190476,
        "hf_subset": "eng_Latn-bnp_Latn",
        "languages": [
          "eng-Latn",
          "bnp-Latn"
        ],
        "main_score": 0.02179315476190476,
        "precision": 0.017537906209781212,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0178849377394636,
        "hf_subset": "bnp_Latn-eng_Latn",
        "languages": [
          "bnp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0178849377394636,
        "precision": 0.016158702761627907,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01789772727272727,
        "hf_subset": "eng_Latn-boa_Latn",
        "languages": [
          "eng-Latn",
          "boa-Latn"
        ],
        "main_score": 0.01789772727272727,
        "precision": 0.014518229166666665,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011375762195121951,
        "hf_subset": "boa_Latn-eng_Latn",
        "languages": [
          "boa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011375762195121951,
        "precision": 0.008943235557259713,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03333875868055555,
        "hf_subset": "eng_Latn-boj_Latn",
        "languages": [
          "eng-Latn",
          "boj-Latn"
        ],
        "main_score": 0.03333875868055555,
        "precision": 0.026953575028801843,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017104640151515152,
        "hf_subset": "boj_Latn-eng_Latn",
        "languages": [
          "boj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017104640151515152,
        "precision": 0.013997902931549275,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.026189072327044025,
        "hf_subset": "eng_Latn-bon_Latn",
        "languages": [
          "eng-Latn",
          "bon-Latn"
        ],
        "main_score": 0.026189072327044025,
        "precision": 0.022991786858974357,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005592757936507936,
        "hf_subset": "bon_Latn-eng_Latn",
        "languages": [
          "bon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005592757936507936,
        "precision": 0.0049458165322580645,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01188858695652174,
        "hf_subset": "eng_Latn-box_Latn",
        "languages": [
          "eng-Latn",
          "box-Latn"
        ],
        "main_score": 0.01188858695652174,
        "precision": 0.010633680555555556,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005208333333333333,
        "hf_subset": "box_Latn-eng_Latn",
        "languages": [
          "box-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.0046875,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01658803436147186,
        "hf_subset": "eng_Latn-bpr_Latn",
        "languages": [
          "eng-Latn",
          "bpr-Latn"
        ],
        "main_score": 0.01658803436147186,
        "precision": 0.013749562324929972,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011523437499999999,
        "hf_subset": "bpr_Latn-eng_Latn",
        "languages": [
          "bpr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011523437499999999,
        "precision": 0.010389868341404358,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013069309163059163,
        "hf_subset": "eng_Latn-bps_Latn",
        "languages": [
          "eng-Latn",
          "bps-Latn"
        ],
        "main_score": 0.013069309163059163,
        "precision": 0.010086118913144967,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008928571428571428,
        "hf_subset": "bps_Latn-eng_Latn",
        "languages": [
          "bps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008928571428571428,
        "precision": 0.008463541666666668,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01848958333333333,
        "hf_subset": "eng_Latn-bqc_Latn",
        "languages": [
          "eng-Latn",
          "bqc-Latn"
        ],
        "main_score": 0.01848958333333333,
        "precision": 0.0173828125,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00805769751082251,
        "hf_subset": "bqc_Latn-eng_Latn",
        "languages": [
          "bqc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00805769751082251,
        "precision": 0.006475482723577236,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008277529761904762,
        "hf_subset": "eng_Latn-bqp_Latn",
        "languages": [
          "eng-Latn",
          "bqp-Latn"
        ],
        "main_score": 0.008277529761904762,
        "precision": 0.006865530303030302,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00769442287784679,
        "hf_subset": "bqp_Latn-eng_Latn",
        "languages": [
          "bqp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00769442287784679,
        "precision": 0.00654468201754386,
        "recall": 0.015625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.05697882846320346,
        "hf_subset": "eng_Latn-bre_Latn",
        "languages": [
          "eng-Latn",
          "bre-Latn"
        ],
        "main_score": 0.05697882846320346,
        "precision": 0.04663008432539682,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04787126289736078,
        "hf_subset": "bre_Latn-eng_Latn",
        "languages": [
          "bre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04787126289736078,
        "precision": 0.04129593460648148,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02372931784022137,
        "hf_subset": "eng_Latn-bsj_Latn",
        "languages": [
          "eng-Latn",
          "bsj-Latn"
        ],
        "main_score": 0.02372931784022137,
        "precision": 0.019292534722222223,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.022135416666666664,
        "hf_subset": "bsj_Latn-eng_Latn",
        "languages": [
          "bsj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022135416666666664,
        "precision": 0.021484375,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0192122113997114,
        "hf_subset": "eng_Latn-bsn_Latn",
        "languages": [
          "eng-Latn",
          "bsn-Latn"
        ],
        "main_score": 0.0192122113997114,
        "precision": 0.016599180640243905,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "bsn_Latn-eng_Latn",
        "languages": [
          "bsn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.09375,
        "f1": 0.06907403812974465,
        "hf_subset": "eng_Latn-bsp_Latn",
        "languages": [
          "eng-Latn",
          "bsp-Latn"
        ],
        "main_score": 0.06907403812974465,
        "precision": 0.06341322586726998,
        "recall": 0.09375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04466256179378531,
        "hf_subset": "bsp_Latn-eng_Latn",
        "languages": [
          "bsp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04466256179378531,
        "precision": 0.0417372557997558,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01813243039424442,
        "hf_subset": "eng_Latn-bss_Latn",
        "languages": [
          "eng-Latn",
          "bss-Latn"
        ],
        "main_score": 0.01813243039424442,
        "precision": 0.014896334134615385,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019275323275862066,
        "hf_subset": "bss_Latn-eng_Latn",
        "languages": [
          "bss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019275323275862066,
        "precision": 0.01797217653508772,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025137138188608774,
        "hf_subset": "eng_Latn-buk_Latn",
        "languages": [
          "eng-Latn",
          "buk-Latn"
        ],
        "main_score": 0.025137138188608774,
        "precision": 0.021110026041666667,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.015190972222222222,
        "hf_subset": "buk_Latn-eng_Latn",
        "languages": [
          "buk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015190972222222222,
        "precision": 0.01416015625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014973958333333334,
        "hf_subset": "eng_Latn-bus_Latn",
        "languages": [
          "eng-Latn",
          "bus-Latn"
        ],
        "main_score": 0.014973958333333334,
        "precision": 0.013802083333333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009585457052139036,
        "hf_subset": "bus_Latn-eng_Latn",
        "languages": [
          "bus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009585457052139036,
        "precision": 0.008765984530472637,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025208786439255188,
        "hf_subset": "eng_Latn-bvd_Latn",
        "languages": [
          "eng-Latn",
          "bvd-Latn"
        ],
        "main_score": 0.025208786439255188,
        "precision": 0.02190755208333333,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010416666666666666,
        "hf_subset": "bvd_Latn-eng_Latn",
        "languages": [
          "bvd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.008463541666666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03334748641304348,
        "hf_subset": "eng_Latn-bvr_Latn",
        "languages": [
          "eng-Latn",
          "bvr-Latn"
        ],
        "main_score": 0.03334748641304348,
        "precision": 0.027211286976911976,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.042346938775510205,
        "hf_subset": "bvr_Latn-eng_Latn",
        "languages": [
          "bvr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.042346938775510205,
        "precision": 0.04109700520833333,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.028580729166666666,
        "hf_subset": "eng_Latn-bxh_Latn",
        "languages": [
          "eng-Latn",
          "bxh-Latn"
        ],
        "main_score": 0.028580729166666666,
        "precision": 0.02529451884920635,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.024494949494949497,
        "hf_subset": "bxh_Latn-eng_Latn",
        "languages": [
          "bxh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024494949494949497,
        "precision": 0.02279730902777778,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004058051323676324,
        "hf_subset": "eng_Latn-byr_Latn",
        "languages": [
          "eng-Latn",
          "byr-Latn"
        ],
        "main_score": 0.004058051323676324,
        "precision": 0.002369488856589147,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0019982839595375722,
        "hf_subset": "byr_Latn-eng_Latn",
        "languages": [
          "byr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0019982839595375722,
        "precision": 0.0013247940891472868,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017049153645833332,
        "hf_subset": "eng_Latn-byx_Latn",
        "languages": [
          "eng-Latn",
          "byx-Latn"
        ],
        "main_score": 0.017049153645833332,
        "precision": 0.014515128968253969,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009375,
        "hf_subset": "byx_Latn-eng_Latn",
        "languages": [
          "byx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009375,
        "precision": 0.0087890625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.037353515625,
        "hf_subset": "eng_Latn-bzd_Latn",
        "languages": [
          "eng-Latn",
          "bzd-Latn"
        ],
        "main_score": 0.037353515625,
        "precision": 0.03451128766977929,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021794286062378168,
        "hf_subset": "bzd_Latn-eng_Latn",
        "languages": [
          "bzd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021794286062378168,
        "precision": 0.020875066773504272,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02096020299145299,
        "hf_subset": "eng_Latn-bzh_Latn",
        "languages": [
          "eng-Latn",
          "bzh-Latn"
        ],
        "main_score": 0.02096020299145299,
        "precision": 0.01776578490497076,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015559895833333332,
        "hf_subset": "bzh_Latn-eng_Latn",
        "languages": [
          "bzh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015559895833333332,
        "precision": 0.013253348214285714,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.1484375,
        "f1": 0.08794420878399206,
        "hf_subset": "eng_Latn-bzj_Latn",
        "languages": [
          "eng-Latn",
          "bzj-Latn"
        ],
        "main_score": 0.08794420878399206,
        "precision": 0.0741138599537037,
        "recall": 0.1484375
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.09941638764880951,
        "hf_subset": "bzj_Latn-eng_Latn",
        "languages": [
          "bzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09941638764880951,
        "precision": 0.093467760884065,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.041162288232600736,
        "hf_subset": "eng_Latn-caa_Latn",
        "languages": [
          "eng-Latn",
          "caa-Latn"
        ],
        "main_score": 0.041162288232600736,
        "precision": 0.03596032873376623,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.027733947386425838,
        "hf_subset": "caa_Latn-eng_Latn",
        "languages": [
          "caa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027733947386425838,
        "precision": 0.02346994962879583,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.02989598299808429,
        "hf_subset": "eng_Latn-cab_Latn",
        "languages": [
          "eng-Latn",
          "cab-Latn"
        ],
        "main_score": 0.02989598299808429,
        "precision": 0.025301045582706762,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016974720528455285,
        "hf_subset": "cab_Latn-eng_Latn",
        "languages": [
          "cab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016974720528455285,
        "precision": 0.01564896472392638,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03721609698172198,
        "hf_subset": "eng_Latn-cac_Latn",
        "languages": [
          "eng-Latn",
          "cac-Latn"
        ],
        "main_score": 0.03721609698172198,
        "precision": 0.033882090132090134,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010657387955182073,
        "hf_subset": "cac_Latn-eng_Latn",
        "languages": [
          "cac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010657387955182073,
        "precision": 0.009584780092592593,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.109375,
        "f1": 0.08490048363095237,
        "hf_subset": "eng_Latn-caf_Latn",
        "languages": [
          "eng-Latn",
          "caf-Latn"
        ],
        "main_score": 0.08490048363095237,
        "precision": 0.07932002892940393,
        "recall": 0.109375
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.07903645833333334,
        "hf_subset": "caf_Latn-eng_Latn",
        "languages": [
          "caf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07903645833333334,
        "precision": 0.07454427083333333,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.03982790532078216,
        "hf_subset": "eng_Latn-cak_Latn",
        "languages": [
          "eng-Latn",
          "cak-Latn"
        ],
        "main_score": 0.03982790532078216,
        "precision": 0.03374168032420369,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05999348958333334,
        "hf_subset": "cak_Latn-eng_Latn",
        "languages": [
          "cak-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05999348958333334,
        "precision": 0.05358072916666667,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01829157855576441,
        "hf_subset": "eng_Latn-cao_Latn",
        "languages": [
          "eng-Latn",
          "cao-Latn"
        ],
        "main_score": 0.01829157855576441,
        "precision": 0.013758680555555555,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.030524130817099565,
        "hf_subset": "cao_Latn-eng_Latn",
        "languages": [
          "cao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030524130817099565,
        "precision": 0.026973010540268686,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.021518238705738706,
        "hf_subset": "eng_Latn-cap_Latn",
        "languages": [
          "eng-Latn",
          "cap-Latn"
        ],
        "main_score": 0.021518238705738706,
        "precision": 0.019181490603904394,
        "recall": 0.046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00703610248447205,
        "hf_subset": "cap_Latn-eng_Latn",
        "languages": [
          "cap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00703610248447205,
        "precision": 0.0061322062084257205,
        "recall": 0.015625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04353143601190476,
        "hf_subset": "eng_Latn-car_Latn",
        "languages": [
          "eng-Latn",
          "car-Latn"
        ],
        "main_score": 0.04353143601190476,
        "precision": 0.03825954861111111,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03675801917989418,
        "hf_subset": "car_Latn-eng_Latn",
        "languages": [
          "car-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03675801917989418,
        "precision": 0.0350010016025641,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009114583333333334,
        "hf_subset": "eng_Latn-cav_Latn",
        "languages": [
          "eng-Latn",
          "cav-Latn"
        ],
        "main_score": 0.009114583333333334,
        "precision": 0.00859375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008675553359242383,
        "hf_subset": "cav_Latn-eng_Latn",
        "languages": [
          "cav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008675553359242383,
        "precision": 0.00826171875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.033699156746031744,
        "hf_subset": "eng_Latn-cax_Latn",
        "languages": [
          "eng-Latn",
          "cax-Latn"
        ],
        "main_score": 0.033699156746031744,
        "precision": 0.029538690476190475,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014987915090374105,
        "hf_subset": "cax_Latn-eng_Latn",
        "languages": [
          "cax-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014987915090374105,
        "precision": 0.01272759555785124,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025832463667285095,
        "hf_subset": "eng_Latn-cbc_Latn",
        "languages": [
          "eng-Latn",
          "cbc-Latn"
        ],
        "main_score": 0.025832463667285095,
        "precision": 0.024024394914215687,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013485863095238096,
        "hf_subset": "cbc_Latn-eng_Latn",
        "languages": [
          "cbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013485863095238096,
        "precision": 0.01171875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02752706962719298,
        "hf_subset": "eng_Latn-cbi_Latn",
        "languages": [
          "eng-Latn",
          "cbi-Latn"
        ],
        "main_score": 0.02752706962719298,
        "precision": 0.023851517406204906,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "cbi_Latn-eng_Latn",
        "languages": [
          "cbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.3984375,
        "f1": 0.33853574810606063,
        "hf_subset": "eng_Latn-cbk_Latn",
        "languages": [
          "eng-Latn",
          "cbk-Latn"
        ],
        "main_score": 0.33853574810606063,
        "precision": 0.31777512851731604,
        "recall": 0.3984375
      },
      {
        "accuracy": 0.39453125,
        "f1": 0.32491657647907646,
        "hf_subset": "cbk_Latn-eng_Latn",
        "languages": [
          "cbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.32491657647907646,
        "precision": 0.3038835041592395,
        "recall": 0.39453125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024497572739760238,
        "hf_subset": "eng_Latn-cbr_Latn",
        "languages": [
          "eng-Latn",
          "cbr-Latn"
        ],
        "main_score": 0.024497572739760238,
        "precision": 0.021130952380952382,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012009466719077568,
        "hf_subset": "cbr_Latn-eng_Latn",
        "languages": [
          "cbr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012009466719077568,
        "precision": 0.009640066964285713,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021721117424242424,
        "hf_subset": "eng_Latn-cbs_Latn",
        "languages": [
          "eng-Latn",
          "cbs-Latn"
        ],
        "main_score": 0.021721117424242424,
        "precision": 0.019783528645833333,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019856770833333336,
        "hf_subset": "cbs_Latn-eng_Latn",
        "languages": [
          "cbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019856770833333336,
        "precision": 0.01826636904761905,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011138215233042818,
        "hf_subset": "eng_Latn-cbt_Latn",
        "languages": [
          "eng-Latn",
          "cbt-Latn"
        ],
        "main_score": 0.011138215233042818,
        "precision": 0.00972842261904762,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005464045503108002,
        "hf_subset": "cbt_Latn-eng_Latn",
        "languages": [
          "cbt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005464045503108002,
        "precision": 0.00476495150862069,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004665798611111111,
        "hf_subset": "eng_Latn-cbu_Latn",
        "languages": [
          "eng-Latn",
          "cbu-Latn"
        ],
        "main_score": 0.004665798611111111,
        "precision": 0.004305866368286445,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00078125,
        "hf_subset": "cbu_Latn-eng_Latn",
        "languages": [
          "cbu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00078125,
        "precision": 0.00043402777777777775,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01728515625,
        "hf_subset": "eng_Latn-cbv_Latn",
        "languages": [
          "eng-Latn",
          "cbv-Latn"
        ],
        "main_score": 0.01728515625,
        "precision": 0.013972355769230768,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016251098282348282,
        "hf_subset": "cbv_Latn-eng_Latn",
        "languages": [
          "cbv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016251098282348282,
        "precision": 0.014756944444444444,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019928882031522117,
        "hf_subset": "eng_Latn-cco_Latn",
        "languages": [
          "eng-Latn",
          "cco-Latn"
        ],
        "main_score": 0.019928882031522117,
        "precision": 0.018234979538690476,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011173282657657657,
        "hf_subset": "cco_Latn-eng_Latn",
        "languages": [
          "cco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011173282657657657,
        "precision": 0.009949343607305938,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.04349341299019607,
        "hf_subset": "eng_Latn-ceb_Latn",
        "languages": [
          "eng-Latn",
          "ceb-Latn"
        ],
        "main_score": 0.04349341299019607,
        "precision": 0.03495396205357143,
        "recall": 0.078125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07195394163763066,
        "hf_subset": "ceb_Latn-eng_Latn",
        "languages": [
          "ceb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07195394163763066,
        "precision": 0.06381293402777777,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.032247121710526315,
        "hf_subset": "eng_Latn-cek_Latn",
        "languages": [
          "eng-Latn",
          "cek-Latn"
        ],
        "main_score": 0.032247121710526315,
        "precision": 0.028444320436507936,
        "recall": 0.046875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03617037259615384,
        "hf_subset": "cek_Latn-eng_Latn",
        "languages": [
          "cek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03617037259615384,
        "precision": 0.03469111608809257,
        "recall": 0.046875
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.05654285304946477,
        "hf_subset": "eng_Latn-ces_Latn",
        "languages": [
          "eng-Latn",
          "ces-Latn"
        ],
        "main_score": 0.05654285304946477,
        "precision": 0.047805498537920404,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.08434110000431333,
        "hf_subset": "ces_Latn-eng_Latn",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08434110000431333,
        "precision": 0.07541988899410774,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.046502976190476185,
        "hf_subset": "eng_Latn-cgc_Latn",
        "languages": [
          "eng-Latn",
          "cgc-Latn"
        ],
        "main_score": 0.046502976190476185,
        "precision": 0.04296875,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.034592013888888884,
        "hf_subset": "cgc_Latn-eng_Latn",
        "languages": [
          "cgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.034592013888888884,
        "precision": 0.03136160714285714,
        "recall": 0.046875
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.13652471283245737,
        "hf_subset": "eng_Latn-cha_Latn",
        "languages": [
          "eng-Latn",
          "cha-Latn"
        ],
        "main_score": 0.13652471283245737,
        "precision": 0.12058324513517528,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.1875,
        "f1": 0.13721311240842493,
        "hf_subset": "cha_Latn-eng_Latn",
        "languages": [
          "cha-Latn",
          "eng-Latn"
        ],
        "main_score": 0.13721311240842493,
        "precision": 0.12310249412026444,
        "recall": 0.1875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.028625149005583786,
        "hf_subset": "eng_Latn-chd_Latn",
        "languages": [
          "eng-Latn",
          "chd-Latn"
        ],
        "main_score": 0.028625149005583786,
        "precision": 0.025305369543650792,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020612634782396565,
        "hf_subset": "chd_Latn-eng_Latn",
        "languages": [
          "chd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020612634782396565,
        "precision": 0.017903645833333332,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04027512520159579,
        "hf_subset": "eng_Latn-chf_Latn",
        "languages": [
          "eng-Latn",
          "chf-Latn"
        ],
        "main_score": 0.04027512520159579,
        "precision": 0.03558911520337302,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01878987240829346,
        "hf_subset": "chf_Latn-eng_Latn",
        "languages": [
          "chf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01878987240829346,
        "precision": 0.014614502895752893,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019994517543859648,
        "hf_subset": "eng_Latn-chk_Latn",
        "languages": [
          "eng-Latn",
          "chk-Latn"
        ],
        "main_score": 0.019994517543859648,
        "precision": 0.01860260533184191,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.030237268518518517,
        "hf_subset": "chk_Latn-eng_Latn",
        "languages": [
          "chk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030237268518518517,
        "precision": 0.029447115384615384,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03933585180138489,
        "hf_subset": "eng_Latn-chq_Latn",
        "languages": [
          "eng-Latn",
          "chq-Latn"
        ],
        "main_score": 0.03933585180138489,
        "precision": 0.03654221754807692,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01428224362334032,
        "hf_subset": "chq_Latn-eng_Latn",
        "languages": [
          "chq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01428224362334032,
        "precision": 0.013338052640249978,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03728454449961803,
        "hf_subset": "eng_Latn-chz_Latn",
        "languages": [
          "eng-Latn",
          "chz-Latn"
        ],
        "main_score": 0.03728454449961803,
        "precision": 0.03376657196969697,
        "recall": 0.0625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018605912583368384,
        "hf_subset": "chz_Latn-eng_Latn",
        "languages": [
          "chz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018605912583368384,
        "precision": 0.017480468750000002,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009579613095238094,
        "hf_subset": "eng_Latn-cjo_Latn",
        "languages": [
          "eng-Latn",
          "cjo-Latn"
        ],
        "main_score": 0.009579613095238094,
        "precision": 0.0078125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "cjo_Latn-eng_Latn",
        "languages": [
          "cjo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009498530982905984,
        "hf_subset": "eng_Latn-cjv_Latn",
        "languages": [
          "eng-Latn",
          "cjv-Latn"
        ],
        "main_score": 0.009498530982905984,
        "precision": 0.008722913881461675,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "cjv_Latn-eng_Latn",
        "languages": [
          "cjv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003720238095238095,
        "hf_subset": "eng_Latn-ckb_Arab",
        "languages": [
          "eng-Latn",
          "ckb-Arab"
        ],
        "main_score": 0.0003720238095238095,
        "precision": 0.0001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003551136363636364,
        "hf_subset": "ckb_Arab-eng_Latn",
        "languages": [
          "ckb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0003551136363636364,
        "precision": 0.00018601190476190475,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06065376281247991,
        "hf_subset": "eng_Latn-cle_Latn",
        "languages": [
          "eng-Latn",
          "cle-Latn"
        ],
        "main_score": 0.06065376281247991,
        "precision": 0.05233481413398693,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.018746367013536346,
        "hf_subset": "cle_Latn-eng_Latn",
        "languages": [
          "cle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018746367013536346,
        "precision": 0.016277260630129242,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.05604285037878788,
        "hf_subset": "eng_Latn-clu_Latn",
        "languages": [
          "eng-Latn",
          "clu-Latn"
        ],
        "main_score": 0.05604285037878788,
        "precision": 0.04943405343459222,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04627976190476191,
        "hf_subset": "clu_Latn-eng_Latn",
        "languages": [
          "clu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04627976190476191,
        "precision": 0.04381510416666667,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02257220643939394,
        "hf_subset": "eng_Latn-cme_Latn",
        "languages": [
          "eng-Latn",
          "cme-Latn"
        ],
        "main_score": 0.02257220643939394,
        "precision": 0.02010013640873016,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01953125,
        "hf_subset": "cme_Latn-eng_Latn",
        "languages": [
          "cme-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01953125,
        "precision": 0.01953125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.22265625,
        "f1": 0.1674149418290043,
        "hf_subset": "eng_Latn-cmn_Hans",
        "languages": [
          "eng-Latn",
          "cmn-Hans"
        ],
        "main_score": 0.1674149418290043,
        "precision": 0.15421201060318757,
        "recall": 0.22265625
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.12628631693966874,
        "hf_subset": "cmn_Hans-eng_Latn",
        "languages": [
          "cmn-Hans",
          "eng-Latn"
        ],
        "main_score": 0.12628631693966874,
        "precision": 0.11754043662482924,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002864583333333333,
        "hf_subset": "eng_Latn-cni_Latn",
        "languages": [
          "eng-Latn",
          "cni-Latn"
        ],
        "main_score": 0.002864583333333333,
        "precision": 0.002087823275862069,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00022977941176470588,
        "hf_subset": "cni_Latn-eng_Latn",
        "languages": [
          "cni-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00022977941176470588,
        "precision": 0.00011837121212121212,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.021572362449378577,
        "hf_subset": "eng_Latn-cnl_Latn",
        "languages": [
          "eng-Latn",
          "cnl-Latn"
        ],
        "main_score": 0.021572362449378577,
        "precision": 0.019209569898303455,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012898763020833332,
        "hf_subset": "cnl_Latn-eng_Latn",
        "languages": [
          "cnl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012898763020833332,
        "precision": 0.011348576570680629,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020837823275862068,
        "hf_subset": "eng_Latn-cnt_Latn",
        "languages": [
          "eng-Latn",
          "cnt-Latn"
        ],
        "main_score": 0.020837823275862068,
        "precision": 0.018948739035087717,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010843648538961038,
        "hf_subset": "cnt_Latn-eng_Latn",
        "languages": [
          "cnt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010843648538961038,
        "precision": 0.009724017073934837,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013534271467207572,
        "hf_subset": "eng_Latn-cof_Latn",
        "languages": [
          "eng-Latn",
          "cof-Latn"
        ],
        "main_score": 0.013534271467207572,
        "precision": 0.011990017361111112,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00744949494949495,
        "hf_subset": "cof_Latn-eng_Latn",
        "languages": [
          "cof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00744949494949495,
        "precision": 0.0060620504712301584,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02669270833333333,
        "hf_subset": "eng_Latn-con_Latn",
        "languages": [
          "eng-Latn",
          "con-Latn"
        ],
        "main_score": 0.02669270833333333,
        "precision": 0.024739583333333332,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00792910447761194,
        "hf_subset": "con_Latn-eng_Latn",
        "languages": [
          "con-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00792910447761194,
        "precision": 0.007871685606060606,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.0080128205128203e-05,
        "hf_subset": "eng_Latn-cop_Copt",
        "languages": [
          "eng-Latn",
          "cop-Copt"
        ],
        "main_score": 5.0080128205128203e-05,
        "precision": 2.5201612903225806e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.241701244813278e-05,
        "hf_subset": "cop_Copt-eng_Latn",
        "languages": [
          "cop-Copt",
          "eng-Latn"
        ],
        "main_score": 3.241701244813278e-05,
        "precision": 1.6276041666666666e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005208333333333333,
        "hf_subset": "eng_Latn-cot_Latn",
        "languages": [
          "eng-Latn",
          "cot-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.0046875,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0007122800476322604,
        "hf_subset": "cot_Latn-eng_Latn",
        "languages": [
          "cot-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007122800476322604,
        "precision": 0.0003742126015486164,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03608726924752077,
        "hf_subset": "eng_Latn-cpa_Latn",
        "languages": [
          "eng-Latn",
          "cpa-Latn"
        ],
        "main_score": 0.03608726924752077,
        "precision": 0.0331450973731884,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011151952855417528,
        "hf_subset": "cpa_Latn-eng_Latn",
        "languages": [
          "cpa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011151952855417528,
        "precision": 0.009886893926259823,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02830636160714286,
        "hf_subset": "eng_Latn-cpb_Latn",
        "languages": [
          "eng-Latn",
          "cpb-Latn"
        ],
        "main_score": 0.02830636160714286,
        "precision": 0.025227787628053586,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021859780844155845,
        "hf_subset": "cpb_Latn-eng_Latn",
        "languages": [
          "cpb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021859780844155845,
        "precision": 0.019787428987059513,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03283135369532428,
        "hf_subset": "eng_Latn-cpc_Latn",
        "languages": [
          "eng-Latn",
          "cpc-Latn"
        ],
        "main_score": 0.03283135369532428,
        "precision": 0.029866536458333332,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01535535622831222,
        "hf_subset": "cpc_Latn-eng_Latn",
        "languages": [
          "cpc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01535535622831222,
        "precision": 0.014210090211323762,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022677835338680927,
        "hf_subset": "eng_Latn-cpu_Latn",
        "languages": [
          "eng-Latn",
          "cpu-Latn"
        ],
        "main_score": 0.022677835338680927,
        "precision": 0.018391927083333332,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014761965008675534,
        "hf_subset": "cpu_Latn-eng_Latn",
        "languages": [
          "cpu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014761965008675534,
        "precision": 0.013594666499078263,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018229166666666664,
        "hf_subset": "eng_Latn-cpy_Latn",
        "languages": [
          "eng-Latn",
          "cpy-Latn"
        ],
        "main_score": 0.018229166666666664,
        "precision": 0.01640625,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016732034412955465,
        "hf_subset": "cpy_Latn-eng_Latn",
        "languages": [
          "cpy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016732034412955465,
        "precision": 0.015040470157657658,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021679687499999996,
        "hf_subset": "eng_Latn-crn_Latn",
        "languages": [
          "eng-Latn",
          "crn-Latn"
        ],
        "main_score": 0.021679687499999996,
        "precision": 0.01877578059732665,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02185451799248969,
        "hf_subset": "crn_Latn-eng_Latn",
        "languages": [
          "crn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02185451799248969,
        "precision": 0.018562321665884927,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.08117135286131996,
        "hf_subset": "eng_Latn-crx_Latn",
        "languages": [
          "eng-Latn",
          "crx-Latn"
        ],
        "main_score": 0.08117135286131996,
        "precision": 0.07540936710858587,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.085546875,
        "hf_subset": "crx_Latn-eng_Latn",
        "languages": [
          "crx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.085546875,
        "precision": 0.0820608428030303,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.030505952380952377,
        "hf_subset": "eng_Latn-cso_Latn",
        "languages": [
          "eng-Latn",
          "cso-Latn"
        ],
        "main_score": 0.030505952380952377,
        "precision": 0.02810968137254902,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018912096088435373,
        "hf_subset": "cso_Latn-eng_Latn",
        "languages": [
          "cso-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018912096088435373,
        "precision": 0.01694309255464481,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06338617979242979,
        "hf_subset": "eng_Latn-csy_Latn",
        "languages": [
          "eng-Latn",
          "csy-Latn"
        ],
        "main_score": 0.06338617979242979,
        "precision": 0.0553135016025641,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.07404513888888889,
        "hf_subset": "csy_Latn-eng_Latn",
        "languages": [
          "csy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07404513888888889,
        "precision": 0.07047526041666666,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04513113839285714,
        "hf_subset": "eng_Latn-cta_Latn",
        "languages": [
          "eng-Latn",
          "cta-Latn"
        ],
        "main_score": 0.04513113839285714,
        "precision": 0.04092548076923076,
        "recall": 0.0625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01453238224637681,
        "hf_subset": "cta_Latn-eng_Latn",
        "languages": [
          "cta-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01453238224637681,
        "precision": 0.011245265151515152,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.036000100160256406,
        "hf_subset": "eng_Latn-cth_Latn",
        "languages": [
          "eng-Latn",
          "cth-Latn"
        ],
        "main_score": 0.036000100160256406,
        "precision": 0.033176612958401755,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02780330882352941,
        "hf_subset": "cth_Latn-eng_Latn",
        "languages": [
          "cth-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02780330882352941,
        "precision": 0.026416015625,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03873387896825396,
        "hf_subset": "eng_Latn-ctp_Latn",
        "languages": [
          "eng-Latn",
          "ctp-Latn"
        ],
        "main_score": 0.03873387896825396,
        "precision": 0.03503145355148883,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.023344494047619048,
        "hf_subset": "ctp_Latn-eng_Latn",
        "languages": [
          "ctp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023344494047619048,
        "precision": 0.0211338141025641,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.039989347568106764,
        "hf_subset": "eng_Latn-ctu_Latn",
        "languages": [
          "eng-Latn",
          "ctu-Latn"
        ],
        "main_score": 0.039989347568106764,
        "precision": 0.03642555361305361,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.028876869658119655,
        "hf_subset": "ctu_Latn-eng_Latn",
        "languages": [
          "ctu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028876869658119655,
        "precision": 0.025653915634384385,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010505942299006324,
        "hf_subset": "eng_Latn-cub_Latn",
        "languages": [
          "eng-Latn",
          "cub-Latn"
        ],
        "main_score": 0.010505942299006324,
        "precision": 0.009392072770979022,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01829217069892473,
        "hf_subset": "cub_Latn-eng_Latn",
        "languages": [
          "cub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01829217069892473,
        "precision": 0.0176098831300813,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03307291666666666,
        "hf_subset": "eng_Latn-cuc_Latn",
        "languages": [
          "eng-Latn",
          "cuc-Latn"
        ],
        "main_score": 0.03307291666666666,
        "precision": 0.03022693452380952,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019765093537414964,
        "hf_subset": "cuc_Latn-eng_Latn",
        "languages": [
          "cuc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019765093537414964,
        "precision": 0.017333984375,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007165995209059233,
        "hf_subset": "eng_Latn-cui_Latn",
        "languages": [
          "eng-Latn",
          "cui-Latn"
        ],
        "main_score": 0.007165995209059233,
        "precision": 0.0059570312500000005,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0072609031593406596,
        "hf_subset": "cui_Latn-eng_Latn",
        "languages": [
          "cui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0072609031593406596,
        "precision": 0.005897299757281553,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.028852713213321765,
        "hf_subset": "eng_Latn-cuk_Latn",
        "languages": [
          "eng-Latn",
          "cuk-Latn"
        ],
        "main_score": 0.028852713213321765,
        "precision": 0.025798958174574952,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017269433815192744,
        "hf_subset": "cuk_Latn-eng_Latn",
        "languages": [
          "cuk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017269433815192744,
        "precision": 0.014133793647300469,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.033710937499999996,
        "hf_subset": "eng_Latn-cut_Latn",
        "languages": [
          "eng-Latn",
          "cut-Latn"
        ],
        "main_score": 0.033710937499999996,
        "precision": 0.02964564732142857,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013594777960526315,
        "hf_subset": "cut_Latn-eng_Latn",
        "languages": [
          "cut-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013594777960526315,
        "precision": 0.012018875591016548,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05508150703463203,
        "hf_subset": "eng_Latn-cux_Latn",
        "languages": [
          "eng-Latn",
          "cux-Latn"
        ],
        "main_score": 0.05508150703463203,
        "precision": 0.047750946969696964,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04880487351190477,
        "hf_subset": "cux_Latn-eng_Latn",
        "languages": [
          "cux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04880487351190477,
        "precision": 0.04549030867182463,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009319554143772894,
        "hf_subset": "eng_Latn-cwe_Latn",
        "languages": [
          "eng-Latn",
          "cwe-Latn"
        ],
        "main_score": 0.009319554143772894,
        "precision": 0.007499630988529015,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.463286713286713e-05,
        "hf_subset": "cwe_Latn-eng_Latn",
        "languages": [
          "cwe-Latn",
          "eng-Latn"
        ],
        "main_score": 5.463286713286713e-05,
        "precision": 2.750880281690141e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.0341015625,
        "hf_subset": "eng_Latn-cya_Latn",
        "languages": [
          "eng-Latn",
          "cya-Latn"
        ],
        "main_score": 0.0341015625,
        "precision": 0.029171316964285713,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021665877525252522,
        "hf_subset": "cya_Latn-eng_Latn",
        "languages": [
          "cya-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021665877525252522,
        "precision": 0.01857793898809524,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010256185807656396,
        "hf_subset": "eng_Latn-daa_Latn",
        "languages": [
          "eng-Latn",
          "daa-Latn"
        ],
        "main_score": 0.010256185807656396,
        "precision": 0.007955884176587302,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006510416666666666,
        "hf_subset": "daa_Latn-eng_Latn",
        "languages": [
          "daa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006510416666666666,
        "precision": 0.005859375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.0424827483076564,
        "hf_subset": "eng_Latn-dad_Latn",
        "languages": [
          "eng-Latn",
          "dad-Latn"
        ],
        "main_score": 0.0424827483076564,
        "precision": 0.03748837425595238,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025510817307692307,
        "hf_subset": "dad_Latn-eng_Latn",
        "languages": [
          "dad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025510817307692307,
        "precision": 0.02232666015625,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.006827419655033258,
        "hf_subset": "eng_Latn-dah_Latn",
        "languages": [
          "eng-Latn",
          "dah-Latn"
        ],
        "main_score": 0.006827419655033258,
        "precision": 0.004209354014041514,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "dah_Latn-eng_Latn",
        "languages": [
          "dah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.25,
        "f1": 0.19105502836326055,
        "hf_subset": "eng_Latn-dan_Latn",
        "languages": [
          "eng-Latn",
          "dan-Latn"
        ],
        "main_score": 0.19105502836326055,
        "precision": 0.17670312885670614,
        "recall": 0.25
      },
      {
        "accuracy": 0.30078125,
        "f1": 0.24183603540100249,
        "hf_subset": "dan_Latn-eng_Latn",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ],
        "main_score": 0.24183603540100249,
        "precision": 0.22272135416666666,
        "recall": 0.30078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009895833333333333,
        "hf_subset": "eng_Latn-ded_Latn",
        "languages": [
          "eng-Latn",
          "ded-Latn"
        ],
        "main_score": 0.009895833333333333,
        "precision": 0.009027777777777777,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006510416666666666,
        "hf_subset": "ded_Latn-eng_Latn",
        "languages": [
          "ded-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.0003551136363636364,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.66796875,
        "f1": 0.5922619047619048,
        "hf_subset": "eng_Latn-deu_Latn",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.5922619047619048,
        "precision": 0.5630859374999999,
        "recall": 0.66796875
      },
      {
        "accuracy": 0.67578125,
        "f1": 0.6011811755952381,
        "hf_subset": "deu_Latn-eng_Latn",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.6011811755952381,
        "precision": 0.5706752232142858,
        "recall": 0.67578125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03366815476190476,
        "hf_subset": "eng_Latn-dgc_Latn",
        "languages": [
          "eng-Latn",
          "dgc-Latn"
        ],
        "main_score": 0.03366815476190476,
        "precision": 0.030598958333333332,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022837936046511628,
        "hf_subset": "dgc_Latn-eng_Latn",
        "languages": [
          "dgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022837936046511628,
        "precision": 0.02027529761904762,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.054694940476190466,
        "hf_subset": "eng_Latn-dgr_Latn",
        "languages": [
          "eng-Latn",
          "dgr-Latn"
        ],
        "main_score": 0.054694940476190466,
        "precision": 0.05031843466553288,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.047526041666666664,
        "hf_subset": "dgr_Latn-eng_Latn",
        "languages": [
          "dgr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.047526041666666664,
        "precision": 0.04622395833333333,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006158074262693828,
        "hf_subset": "eng_Latn-dgz_Latn",
        "languages": [
          "eng-Latn",
          "dgz-Latn"
        ],
        "main_score": 0.006158074262693828,
        "precision": 0.005125473484848485,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 9.765625e-05,
        "hf_subset": "dgz_Latn-eng_Latn",
        "languages": [
          "dgz-Latn",
          "eng-Latn"
        ],
        "main_score": 9.765625e-05,
        "precision": 4.944620253164557e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014336046918767508,
        "hf_subset": "eng_Latn-dhg_Latn",
        "languages": [
          "eng-Latn",
          "dhg-Latn"
        ],
        "main_score": 0.014336046918767508,
        "precision": 0.012168482730263157,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010026041666666666,
        "hf_subset": "dhg_Latn-eng_Latn",
        "languages": [
          "dhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010026041666666666,
        "precision": 0.007928161248473748,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03213397206192604,
        "hf_subset": "eng_Latn-dif_Latn",
        "languages": [
          "eng-Latn",
          "dif-Latn"
        ],
        "main_score": 0.03213397206192604,
        "precision": 0.025936940834658764,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.028040747549019605,
        "hf_subset": "dif_Latn-eng_Latn",
        "languages": [
          "dif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028040747549019605,
        "precision": 0.02576885254168908,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02224110524891775,
        "hf_subset": "eng_Latn-dik_Latn",
        "languages": [
          "eng-Latn",
          "dik-Latn"
        ],
        "main_score": 0.02224110524891775,
        "precision": 0.01735946345321345,
        "recall": 0.046875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "dik_Latn-eng_Latn",
        "languages": [
          "dik-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.12105263157894737,
        "f1": 0.07772392693445325,
        "hf_subset": "eng_Latn-dji_Latn",
        "languages": [
          "eng-Latn",
          "dji-Latn"
        ],
        "main_score": 0.07772392693445325,
        "precision": 0.06824546282750617,
        "recall": 0.12105263157894737
      },
      {
        "accuracy": 0.04736842105263158,
        "f1": 0.03545934042166217,
        "hf_subset": "dji_Latn-eng_Latn",
        "languages": [
          "dji-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03545934042166217,
        "precision": 0.03440002445137233,
        "recall": 0.04736842105263158
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013319407003229155,
        "hf_subset": "eng_Latn-djk_Latn",
        "languages": [
          "eng-Latn",
          "djk-Latn"
        ],
        "main_score": 0.013319407003229155,
        "precision": 0.00999588519119769,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010225183823529412,
        "hf_subset": "djk_Latn-eng_Latn",
        "languages": [
          "djk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010225183823529412,
        "precision": 0.009358723958333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011160714285714285,
        "hf_subset": "eng_Latn-djr_Latn",
        "languages": [
          "eng-Latn",
          "djr-Latn"
        ],
        "main_score": 0.0011160714285714285,
        "precision": 0.0006510416666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00028935185185185184,
        "hf_subset": "djr_Latn-eng_Latn",
        "languages": [
          "djr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00028935185185185184,
        "precision": 0.00015024038461538462,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0137213693957115,
        "hf_subset": "eng_Latn-dob_Latn",
        "languages": [
          "eng-Latn",
          "dob-Latn"
        ],
        "main_score": 0.0137213693957115,
        "precision": 0.012086004273504272,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002662468905472637,
        "hf_subset": "dob_Latn-eng_Latn",
        "languages": [
          "dob-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002662468905472637,
        "precision": 0.00198249530075188,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-dop_Latn",
        "languages": [
          "eng-Latn",
          "dop-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004175646551724138,
        "hf_subset": "dop_Latn-eng_Latn",
        "languages": [
          "dop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004175646551724138,
        "precision": 0.004045758928571429,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004309275793650794,
        "hf_subset": "eng_Latn-dov_Latn",
        "languages": [
          "eng-Latn",
          "dov-Latn"
        ],
        "main_score": 0.004309275793650794,
        "precision": 0.0026919178967804817,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0120216259057971,
        "hf_subset": "dov_Latn-eng_Latn",
        "languages": [
          "dov-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0120216259057971,
        "precision": 0.009461449795081966,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011266402867965368,
        "hf_subset": "eng_Latn-dwr_Latn",
        "languages": [
          "eng-Latn",
          "dwr-Latn"
        ],
        "main_score": 0.011266402867965368,
        "precision": 0.010227272727272727,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0129585326953748,
        "hf_subset": "dwr_Latn-eng_Latn",
        "languages": [
          "dwr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0129585326953748,
        "precision": 0.011375565245478036,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012109375,
        "hf_subset": "eng_Latn-dww_Latn",
        "languages": [
          "eng-Latn",
          "dww-Latn"
        ],
        "main_score": 0.012109375,
        "precision": 0.00935329861111111,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011393229166666666,
        "hf_subset": "dww_Latn-eng_Latn",
        "languages": [
          "dww-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011393229166666666,
        "precision": 0.010323660714285714,
        "recall": 0.015625
      },
      {
        "accuracy": 0.17293233082706766,
        "f1": 0.1264769065520945,
        "hf_subset": "eng_Latn-dwy_Latn",
        "languages": [
          "eng-Latn",
          "dwy-Latn"
        ],
        "main_score": 0.1264769065520945,
        "precision": 0.11510507036822827,
        "recall": 0.17293233082706766
      },
      {
        "accuracy": 0.12781954887218044,
        "f1": 0.08330794306026504,
        "hf_subset": "dwy_Latn-eng_Latn",
        "languages": [
          "dwy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08330794306026504,
        "precision": 0.0721187584345479,
        "recall": 0.12781954887218044
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03282180059523809,
        "hf_subset": "eng_Latn-ebk_Latn",
        "languages": [
          "eng-Latn",
          "ebk-Latn"
        ],
        "main_score": 0.03282180059523809,
        "precision": 0.028357514880952384,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.028645833333333332,
        "hf_subset": "ebk_Latn-eng_Latn",
        "languages": [
          "ebk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028645833333333332,
        "precision": 0.026041666666666664,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008732938218390805,
        "hf_subset": "eng_Latn-eko_Latn",
        "languages": [
          "eng-Latn",
          "eko-Latn"
        ],
        "main_score": 0.008732938218390805,
        "precision": 0.007135247564935065,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004392660440613027,
        "hf_subset": "eko_Latn-eng_Latn",
        "languages": [
          "eko-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004392660440613027,
        "precision": 0.0026479341736694675,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02357681381118881,
        "hf_subset": "eng_Latn-emi_Latn",
        "languages": [
          "eng-Latn",
          "emi-Latn"
        ],
        "main_score": 0.02357681381118881,
        "precision": 0.018337673611111112,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011429537259615385,
        "hf_subset": "emi_Latn-eng_Latn",
        "languages": [
          "emi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011429537259615385,
        "precision": 0.010011628979548808,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016595643939393938,
        "hf_subset": "eng_Latn-emp_Latn",
        "languages": [
          "eng-Latn",
          "emp-Latn"
        ],
        "main_score": 0.016595643939393938,
        "precision": 0.013736979166666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012050840978593273,
        "hf_subset": "emp_Latn-eng_Latn",
        "languages": [
          "emp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012050840978593273,
        "precision": 0.01077835648148148,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004276398689516129,
        "hf_subset": "eng_Latn-enq_Latn",
        "languages": [
          "eng-Latn",
          "enq-Latn"
        ],
        "main_score": 0.004276398689516129,
        "precision": 0.004096294949762031,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0007207961309523809,
        "hf_subset": "enq_Latn-eng_Latn",
        "languages": [
          "enq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007207961309523809,
        "precision": 0.00039030507780507783,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.26953125,
        "f1": 0.19639089209401708,
        "hf_subset": "eng_Latn-epo_Latn",
        "languages": [
          "eng-Latn",
          "epo-Latn"
        ],
        "main_score": 0.19639089209401708,
        "precision": 0.17882568458740333,
        "recall": 0.26953125
      },
      {
        "accuracy": 0.2421875,
        "f1": 0.18228405708874457,
        "hf_subset": "epo_Latn-eng_Latn",
        "languages": [
          "epo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.18228405708874457,
        "precision": 0.16376488095238093,
        "recall": 0.2421875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013444883461047254,
        "hf_subset": "eng_Latn-eri_Latn",
        "languages": [
          "eng-Latn",
          "eri-Latn"
        ],
        "main_score": 0.013444883461047254,
        "precision": 0.011416687753036437,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0168765943877551,
        "hf_subset": "eri_Latn-eng_Latn",
        "languages": [
          "eri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0168765943877551,
        "precision": 0.015293246809032893,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007965938779357896,
        "hf_subset": "eng_Latn-ese_Latn",
        "languages": [
          "eng-Latn",
          "ese-Latn"
        ],
        "main_score": 0.007965938779357896,
        "precision": 0.006632303414786968,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006094158318815331,
        "hf_subset": "ese_Latn-eng_Latn",
        "languages": [
          "ese-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006094158318815331,
        "precision": 0.0051635526895943565,
        "recall": 0.015625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06991924131191471,
        "hf_subset": "eng_Latn-esk_Latn",
        "languages": [
          "eng-Latn",
          "esk-Latn"
        ],
        "main_score": 0.06991924131191471,
        "precision": 0.06422106014784947,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.05053111293859649,
        "hf_subset": "esk_Latn-eng_Latn",
        "languages": [
          "esk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05053111293859649,
        "precision": 0.04714719907281527,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.000980392156862745,
        "hf_subset": "eng_Latn-etr_Latn",
        "languages": [
          "eng-Latn",
          "etr-Latn"
        ],
        "main_score": 0.000980392156862745,
        "precision": 0.0005231584821428571,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027018229166666666,
        "hf_subset": "etr_Latn-eng_Latn",
        "languages": [
          "etr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027018229166666666,
        "precision": 0.0020025712025316454,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.023567708333333333,
        "hf_subset": "eng_Latn-ewe_Latn",
        "languages": [
          "eng-Latn",
          "ewe-Latn"
        ],
        "main_score": 0.023567708333333333,
        "precision": 0.020876736111111113,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020881721565315314,
        "hf_subset": "ewe_Latn-eng_Latn",
        "languages": [
          "ewe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020881721565315314,
        "precision": 0.019249131944444445,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0071682224025974035,
        "hf_subset": "eng_Latn-faa_Latn",
        "languages": [
          "eng-Latn",
          "faa-Latn"
        ],
        "main_score": 0.0071682224025974035,
        "precision": 0.0045066550925925925,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0015861162173202614,
        "hf_subset": "faa_Latn-eng_Latn",
        "languages": [
          "faa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0015861162173202614,
        "precision": 0.0008670691287878787,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009049479166666666,
        "hf_subset": "eng_Latn-fai_Latn",
        "languages": [
          "eng-Latn",
          "fai-Latn"
        ],
        "main_score": 0.009049479166666666,
        "precision": 0.007393973214285714,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001973684210526316,
        "hf_subset": "fai_Latn-eng_Latn",
        "languages": [
          "fai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001973684210526316,
        "precision": 0.001193576388888889,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.05614769345238095,
        "hf_subset": "eng_Latn-far_Latn",
        "languages": [
          "eng-Latn",
          "far-Latn"
        ],
        "main_score": 0.05614769345238095,
        "precision": 0.04751955943362193,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02292596726190476,
        "hf_subset": "far_Latn-eng_Latn",
        "languages": [
          "far-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02292596726190476,
        "precision": 0.02152157738095238,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.01979659880050505,
        "hf_subset": "eng_Latn-ffm_Latn",
        "languages": [
          "eng-Latn",
          "ffm-Latn"
        ],
        "main_score": 0.01979659880050505,
        "precision": 0.016001566662481707,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.019754464285714285,
        "hf_subset": "ffm_Latn-eng_Latn",
        "languages": [
          "ffm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019754464285714285,
        "precision": 0.019646139705882353,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013671874999999998,
        "hf_subset": "eng_Latn-for_Latn",
        "languages": [
          "eng-Latn",
          "for-Latn"
        ],
        "main_score": 0.013671874999999998,
        "precision": 0.012073863636363636,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0013950892857142857,
        "hf_subset": "for_Latn-eng_Latn",
        "languages": [
          "for-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013950892857142857,
        "precision": 0.0007626110649941586,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.80078125,
        "f1": 0.750390625,
        "hf_subset": "eng_Latn-fra_Latn",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ],
        "main_score": 0.750390625,
        "precision": 0.7286241319444444,
        "recall": 0.80078125
      },
      {
        "accuracy": 0.84375,
        "f1": 0.801953125,
        "hf_subset": "fra_Latn-eng_Latn",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.801953125,
        "precision": 0.7846354166666667,
        "recall": 0.84375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.026808315732206864,
        "hf_subset": "eng_Latn-fue_Latn",
        "languages": [
          "eng-Latn",
          "fue-Latn"
        ],
        "main_score": 0.026808315732206864,
        "precision": 0.02186081063034188,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020490284455128203,
        "hf_subset": "fue_Latn-eng_Latn",
        "languages": [
          "fue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020490284455128203,
        "precision": 0.01779203869047619,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010255821078431373,
        "hf_subset": "eng_Latn-fuf_Latn",
        "languages": [
          "eng-Latn",
          "fuf-Latn"
        ],
        "main_score": 0.010255821078431373,
        "precision": 0.008256392045454544,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003920558608058608,
        "hf_subset": "fuf_Latn-eng_Latn",
        "languages": [
          "fuf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003920558608058608,
        "precision": 0.0027069627192982454,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014077524038461537,
        "hf_subset": "eng_Latn-fuh_Latn",
        "languages": [
          "eng-Latn",
          "fuh-Latn"
        ],
        "main_score": 0.014077524038461537,
        "precision": 0.011864459325396825,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01065340909090909,
        "hf_subset": "fuh_Latn-eng_Latn",
        "languages": [
          "fuh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01065340909090909,
        "precision": 0.0098876953125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013671875,
        "hf_subset": "eng_Latn-gah_Latn",
        "languages": [
          "eng-Latn",
          "gah-Latn"
        ],
        "main_score": 0.013671875,
        "precision": 0.012073863636363636,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.0690104166666664e-05,
        "hf_subset": "gah_Latn-eng_Latn",
        "languages": [
          "gah-Latn",
          "eng-Latn"
        ],
        "main_score": 4.0690104166666664e-05,
        "precision": 2.0451570680628273e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.026171875,
        "hf_subset": "eng_Latn-gai_Latn",
        "languages": [
          "eng-Latn",
          "gai-Latn"
        ],
        "main_score": 0.026171875,
        "precision": 0.02248263888888889,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022960069444444446,
        "hf_subset": "gai_Latn-eng_Latn",
        "languages": [
          "gai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022960069444444446,
        "precision": 0.021703361742424244,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022820147795960487,
        "hf_subset": "eng_Latn-gam_Latn",
        "languages": [
          "eng-Latn",
          "gam-Latn"
        ],
        "main_score": 0.022820147795960487,
        "precision": 0.02018963184232026,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.024889823717948716,
        "hf_subset": "gam_Latn-eng_Latn",
        "languages": [
          "gam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024889823717948716,
        "precision": 0.0235140931372549,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03402157738095238,
        "hf_subset": "eng_Latn-gaw_Latn",
        "languages": [
          "eng-Latn",
          "gaw-Latn"
        ],
        "main_score": 0.03402157738095238,
        "precision": 0.030496834150326797,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015809358465608467,
        "hf_subset": "gaw_Latn-eng_Latn",
        "languages": [
          "gaw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015809358465608467,
        "precision": 0.014514828202736318,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011284722222222222,
        "hf_subset": "eng_Latn-gdn_Latn",
        "languages": [
          "eng-Latn",
          "gdn-Latn"
        ],
        "main_score": 0.011284722222222222,
        "precision": 0.008951822916666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00437942480432639,
        "hf_subset": "gdn_Latn-eng_Latn",
        "languages": [
          "gdn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00437942480432639,
        "precision": 0.004147951218263717,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023207131410256408,
        "hf_subset": "eng_Latn-gdr_Latn",
        "languages": [
          "eng-Latn",
          "gdr-Latn"
        ],
        "main_score": 0.023207131410256408,
        "precision": 0.01953125,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013264973958333332,
        "hf_subset": "gdr_Latn-eng_Latn",
        "languages": [
          "gdr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013264973958333332,
        "precision": 0.011844758064516129,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020957341269841268,
        "hf_subset": "eng_Latn-geb_Latn",
        "languages": [
          "eng-Latn",
          "geb-Latn"
        ],
        "main_score": 0.020957341269841268,
        "precision": 0.01690899884259259,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0075379720853858785,
        "hf_subset": "geb_Latn-eng_Latn",
        "languages": [
          "geb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0075379720853858785,
        "precision": 0.005986570994794679,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01532688216639581,
        "hf_subset": "eng_Latn-gfk_Latn",
        "languages": [
          "eng-Latn",
          "gfk-Latn"
        ],
        "main_score": 0.01532688216639581,
        "precision": 0.012701512896825397,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02793866738505747,
        "hf_subset": "gfk_Latn-eng_Latn",
        "languages": [
          "gfk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02793866738505747,
        "precision": 0.025437127976190476,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0029730902777777776,
        "hf_subset": "eng_Latn-ghs_Latn",
        "languages": [
          "eng-Latn",
          "ghs-Latn"
        ],
        "main_score": 0.0029730902777777776,
        "precision": 0.0017643776260504202,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0001201923076923077,
        "hf_subset": "ghs_Latn-eng_Latn",
        "languages": [
          "ghs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001201923076923077,
        "precision": 6.103515625e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.043010752688172046,
        "f1": 0.02635462787265444,
        "hf_subset": "eng_Latn-glk_Arab",
        "languages": [
          "eng-Latn",
          "glk-Arab"
        ],
        "main_score": 0.02635462787265444,
        "precision": 0.024327956989247314,
        "recall": 0.043010752688172046
      },
      {
        "accuracy": 0.03225806451612903,
        "f1": 0.0066445182724252485,
        "hf_subset": "glk_Arab-eng_Latn",
        "languages": [
          "glk-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0066445182724252485,
        "precision": 0.004238493485805313,
        "recall": 0.03225806451612903
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005428034700722395,
        "hf_subset": "eng_Latn-gmv_Latn",
        "languages": [
          "eng-Latn",
          "gmv-Latn"
        ],
        "main_score": 0.005428034700722395,
        "precision": 0.004722518150252525,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007886904761904762,
        "hf_subset": "gmv_Latn-eng_Latn",
        "languages": [
          "gmv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007886904761904762,
        "precision": 0.006315104166666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01949869791666667,
        "hf_subset": "eng_Latn-gng_Latn",
        "languages": [
          "eng-Latn",
          "gng-Latn"
        ],
        "main_score": 0.01949869791666667,
        "precision": 0.018272569444444445,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009755546955624354,
        "hf_subset": "gng_Latn-eng_Latn",
        "languages": [
          "gng-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009755546955624354,
        "precision": 0.0089291351010101,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001951593137254902,
        "hf_subset": "eng_Latn-gnn_Latn",
        "languages": [
          "eng-Latn",
          "gnn-Latn"
        ],
        "main_score": 0.001951593137254902,
        "precision": 0.0011779986592409242,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005580357142857143,
        "hf_subset": "gnn_Latn-eng_Latn",
        "languages": [
          "gnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005580357142857143,
        "precision": 0.00030048076923076925,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.020992772108843538,
        "hf_subset": "eng_Latn-gnw_Latn",
        "languages": [
          "eng-Latn",
          "gnw-Latn"
        ],
        "main_score": 0.020992772108843538,
        "precision": 0.019612630208333332,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018659420289855073,
        "hf_subset": "gnw_Latn-eng_Latn",
        "languages": [
          "gnw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018659420289855073,
        "precision": 0.016688368055555555,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0162109375,
        "hf_subset": "eng_Latn-gof_Latn",
        "languages": [
          "eng-Latn",
          "gof-Latn"
        ],
        "main_score": 0.0162109375,
        "precision": 0.014555431547619048,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002395833333333333,
        "hf_subset": "gof_Latn-eng_Latn",
        "languages": [
          "gof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002395833333333333,
        "precision": 0.0013780381944444443,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019785748106060604,
        "hf_subset": "eng_Latn-grc_Grek",
        "languages": [
          "eng-Latn",
          "grc-Grek"
        ],
        "main_score": 0.019785748106060604,
        "precision": 0.015922619047619047,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001252547554347826,
        "hf_subset": "grc_Grek-eng_Latn",
        "languages": [
          "grc-Grek",
          "eng-Latn"
        ],
        "main_score": 0.001252547554347826,
        "precision": 0.0006729751559714796,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-gub_Latn",
        "languages": [
          "eng-Latn",
          "gub-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007561383928571428,
        "hf_subset": "gub_Latn-eng_Latn",
        "languages": [
          "gub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007561383928571428,
        "precision": 0.00645497081043956,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013802083333333335,
        "hf_subset": "eng_Latn-guh_Latn",
        "languages": [
          "eng-Latn",
          "guh-Latn"
        ],
        "main_score": 0.013802083333333335,
        "precision": 0.012934027777777779,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013720238095238094,
        "hf_subset": "guh_Latn-eng_Latn",
        "languages": [
          "guh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013720238095238094,
        "precision": 0.012856606606606607,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0140625,
        "hf_subset": "eng_Latn-gui_Latn",
        "languages": [
          "eng-Latn",
          "gui-Latn"
        ],
        "main_score": 0.0140625,
        "precision": 0.013221739236314048,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021510377169700032,
        "hf_subset": "gui_Latn-eng_Latn",
        "languages": [
          "gui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021510377169700032,
        "precision": 0.019227430555555557,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006998539435248296,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.0006998539435248296,
        "precision": 0.0003756009615384615,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030691964285714285,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.0030691964285714285,
        "precision": 0.001953125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.5546875,
        "f1": 0.49017857142857146,
        "hf_subset": "eng_Latn-gul_Latn",
        "languages": [
          "eng-Latn",
          "gul-Latn"
        ],
        "main_score": 0.49017857142857146,
        "precision": 0.4693655303030303,
        "recall": 0.5546875
      },
      {
        "accuracy": 0.5,
        "f1": 0.4358974792568543,
        "hf_subset": "gul_Latn-eng_Latn",
        "languages": [
          "gul-Latn",
          "eng-Latn"
        ],
        "main_score": 0.4358974792568543,
        "precision": 0.4132269965277778,
        "recall": 0.5
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025129731379731377,
        "hf_subset": "eng_Latn-gum_Latn",
        "languages": [
          "eng-Latn",
          "gum-Latn"
        ],
        "main_score": 0.025129731379731377,
        "precision": 0.021110983455882353,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0072071454678362575,
        "hf_subset": "gum_Latn-eng_Latn",
        "languages": [
          "gum-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0072071454678362575,
        "precision": 0.0062374665775401066,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02554563492063492,
        "hf_subset": "eng_Latn-gun_Latn",
        "languages": [
          "eng-Latn",
          "gun-Latn"
        ],
        "main_score": 0.02554563492063492,
        "precision": 0.023412459935897436,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.028249289772727275,
        "hf_subset": "gun_Latn-eng_Latn",
        "languages": [
          "gun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028249289772727275,
        "precision": 0.025037202380952382,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02238343253968254,
        "hf_subset": "eng_Latn-guo_Latn",
        "languages": [
          "eng-Latn",
          "guo-Latn"
        ],
        "main_score": 0.02238343253968254,
        "precision": 0.020412071078431373,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02197176773159636,
        "hf_subset": "guo_Latn-eng_Latn",
        "languages": [
          "guo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02197176773159636,
        "precision": 0.01874813988095238,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.13848214285714283,
        "hf_subset": "eng_Latn-gup_Latn",
        "languages": [
          "eng-Latn",
          "gup-Latn"
        ],
        "main_score": 0.13848214285714283,
        "precision": 0.13129701967592594,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.07012167744252874,
        "hf_subset": "gup_Latn-eng_Latn",
        "languages": [
          "gup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07012167744252874,
        "precision": 0.06632597117794486,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02575678356928357,
        "hf_subset": "eng_Latn-gux_Latn",
        "languages": [
          "eng-Latn",
          "gux-Latn"
        ],
        "main_score": 0.02575678356928357,
        "precision": 0.022253350458773254,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012064830043859649,
        "hf_subset": "gux_Latn-eng_Latn",
        "languages": [
          "gux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012064830043859649,
        "precision": 0.010345362103174603,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013984374999999999,
        "hf_subset": "eng_Latn-gvc_Latn",
        "languages": [
          "eng-Latn",
          "gvc-Latn"
        ],
        "main_score": 0.013984374999999999,
        "precision": 0.01123046875,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014715768148482234,
        "hf_subset": "gvc_Latn-eng_Latn",
        "languages": [
          "gvc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014715768148482234,
        "precision": 0.01228005349099099,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.023654513888888888,
        "hf_subset": "eng_Latn-gvf_Latn",
        "languages": [
          "eng-Latn",
          "gvf-Latn"
        ],
        "main_score": 0.023654513888888888,
        "precision": 0.021321614583333332,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015117005531832296,
        "hf_subset": "gvf_Latn-eng_Latn",
        "languages": [
          "gvf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015117005531832296,
        "precision": 0.013675089191722256,
        "recall": 0.03125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07976158405172415,
        "hf_subset": "eng_Latn-gvn_Latn",
        "languages": [
          "eng-Latn",
          "gvn-Latn"
        ],
        "main_score": 0.07976158405172415,
        "precision": 0.07387462797619049,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07398793502011383,
        "hf_subset": "gvn_Latn-eng_Latn",
        "languages": [
          "gvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07398793502011383,
        "precision": 0.06814969572686798,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017327008928571426,
        "hf_subset": "eng_Latn-gvs_Latn",
        "languages": [
          "eng-Latn",
          "gvs-Latn"
        ],
        "main_score": 0.017327008928571426,
        "precision": 0.015206473214285716,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005859375,
        "hf_subset": "gvs_Latn-eng_Latn",
        "languages": [
          "gvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005208333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.09005815467212526,
        "hf_subset": "eng_Latn-gwi_Latn",
        "languages": [
          "eng-Latn",
          "gwi-Latn"
        ],
        "main_score": 0.09005815467212526,
        "precision": 0.07946940104166667,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.0754209250524109,
        "hf_subset": "gwi_Latn-eng_Latn",
        "languages": [
          "gwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0754209250524109,
        "precision": 0.0704039558531746,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023760357481060607,
        "hf_subset": "eng_Latn-gym_Latn",
        "languages": [
          "eng-Latn",
          "gym-Latn"
        ],
        "main_score": 0.023760357481060607,
        "precision": 0.0220788788377193,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014105902777777778,
        "hf_subset": "gym_Latn-eng_Latn",
        "languages": [
          "gym-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014105902777777778,
        "precision": 0.013250612745098039,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024845969089390144,
        "hf_subset": "eng_Latn-gyr_Latn",
        "languages": [
          "eng-Latn",
          "gyr-Latn"
        ],
        "main_score": 0.024845969089390144,
        "precision": 0.022729272240990993,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0027963333771008404,
        "hf_subset": "gyr_Latn-eng_Latn",
        "languages": [
          "gyr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027963333771008404,
        "precision": 0.0017432547501221895,
        "recall": 0.015625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.0507199789463816,
        "hf_subset": "eng_Latn-hat_Latn",
        "languages": [
          "eng-Latn",
          "hat-Latn"
        ],
        "main_score": 0.0507199789463816,
        "precision": 0.04363256259022032,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06584762063069909,
        "hf_subset": "hat_Latn-eng_Latn",
        "languages": [
          "hat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06584762063069909,
        "precision": 0.059975038402457756,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.03659267526455026,
        "hf_subset": "eng_Latn-hau_Latn",
        "languages": [
          "eng-Latn",
          "hau-Latn"
        ],
        "main_score": 0.03659267526455026,
        "precision": 0.03203939795736671,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.023772321428571427,
        "hf_subset": "hau_Latn-eng_Latn",
        "languages": [
          "hau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023772321428571427,
        "precision": 0.018955348320158105,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02405880052878408,
        "hf_subset": "eng_Latn-haw_Latn",
        "languages": [
          "eng-Latn",
          "haw-Latn"
        ],
        "main_score": 0.02405880052878408,
        "precision": 0.02107376628861004,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.019525472357503605,
        "hf_subset": "haw_Latn-eng_Latn",
        "languages": [
          "haw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019525472357503605,
        "precision": 0.016360703468000677,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005533854166666667,
        "hf_subset": "eng_Latn-hbo_Hebr",
        "languages": [
          "eng-Latn",
          "hbo-Hebr"
        ],
        "main_score": 0.005533854166666667,
        "precision": 0.00481939935064935,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003720238095238095,
        "hf_subset": "hbo_Hebr-eng_Latn",
        "languages": [
          "hbo-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.0003720238095238095,
        "precision": 0.0001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004036458333333334,
        "hf_subset": "eng_Latn-hch_Latn",
        "languages": [
          "eng-Latn",
          "hch-Latn"
        ],
        "main_score": 0.004036458333333334,
        "precision": 0.0027422664141414145,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.151574803149606e-05,
        "hf_subset": "hch_Latn-eng_Latn",
        "languages": [
          "hch-Latn",
          "eng-Latn"
        ],
        "main_score": 6.151574803149606e-05,
        "precision": 3.1001984126984125e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.685141509433962e-05,
        "hf_subset": "eng_Latn-heb_Hebr",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ],
        "main_score": 3.685141509433962e-05,
        "precision": 1.851303317535545e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004270582932692307,
        "hf_subset": "heb_Hebr-eng_Latn",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.004270582932692307,
        "precision": 0.004093293220766129,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017008023648648646,
        "hf_subset": "eng_Latn-heg_Latn",
        "languages": [
          "eng-Latn",
          "heg-Latn"
        ],
        "main_score": 0.017008023648648646,
        "precision": 0.014047952915140414,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.032942708333333334,
        "hf_subset": "heg_Latn-eng_Latn",
        "languages": [
          "heg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.032942708333333334,
        "precision": 0.030056423611111112,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011093239379084966,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.011093239379084966,
        "precision": 0.008900035511363636,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008072916666666666,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.008072916666666666,
        "precision": 0.0068359375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.012782606737524769,
        "hf_subset": "eng_Latn-hix_Latn",
        "languages": [
          "eng-Latn",
          "hix-Latn"
        ],
        "main_score": 0.012782606737524769,
        "precision": 0.010648704594017094,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.0479274611398965e-05,
        "hf_subset": "hix_Latn-eng_Latn",
        "languages": [
          "hix-Latn",
          "eng-Latn"
        ],
        "main_score": 4.0479274611398965e-05,
        "precision": 2.0345052083333332e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014044744318181817,
        "hf_subset": "eng_Latn-hla_Latn",
        "languages": [
          "eng-Latn",
          "hla-Latn"
        ],
        "main_score": 0.014044744318181817,
        "precision": 0.011995604928017718,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012429887820512821,
        "hf_subset": "hla_Latn-eng_Latn",
        "languages": [
          "hla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012429887820512821,
        "precision": 0.010975030637254902,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.03028193218885915,
        "hf_subset": "eng_Latn-hlt_Latn",
        "languages": [
          "eng-Latn",
          "hlt-Latn"
        ],
        "main_score": 0.03028193218885915,
        "precision": 0.025037547259483935,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03582144474637681,
        "hf_subset": "hlt_Latn-eng_Latn",
        "languages": [
          "hlt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03582144474637681,
        "precision": 0.031168831168831165,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03255208333333333,
        "hf_subset": "eng_Latn-hmo_Latn",
        "languages": [
          "eng-Latn",
          "hmo-Latn"
        ],
        "main_score": 0.03255208333333333,
        "precision": 0.029947916666666664,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021157398044161037,
        "hf_subset": "hmo_Latn-eng_Latn",
        "languages": [
          "hmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021157398044161037,
        "precision": 0.020449385683760684,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02072172619047619,
        "hf_subset": "eng_Latn-hns_Latn",
        "languages": [
          "eng-Latn",
          "hns-Latn"
        ],
        "main_score": 0.02072172619047619,
        "precision": 0.01862170649509804,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01333999060150376,
        "hf_subset": "hns_Latn-eng_Latn",
        "languages": [
          "hns-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01333999060150376,
        "precision": 0.011553030303030303,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.125,
        "f1": 0.09232901213369962,
        "hf_subset": "eng_Latn-hop_Latn",
        "languages": [
          "eng-Latn",
          "hop-Latn"
        ],
        "main_score": 0.09232901213369962,
        "precision": 0.08524460565476191,
        "recall": 0.125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.060824002896613195,
        "hf_subset": "hop_Latn-eng_Latn",
        "languages": [
          "hop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.060824002896613195,
        "precision": 0.05761417906221686,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009156275656814448,
        "hf_subset": "eng_Latn-hot_Latn",
        "languages": [
          "eng-Latn",
          "hot-Latn"
        ],
        "main_score": 0.009156275656814448,
        "precision": 0.007530469804318488,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "hot_Latn-eng_Latn",
        "languages": [
          "hot-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.04137752757352941,
        "hf_subset": "eng_Latn-hrv_Latn",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ],
        "main_score": 0.04137752757352941,
        "precision": 0.033212629555659984,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.038470643939393936,
        "hf_subset": "hrv_Latn-eng_Latn",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.038470643939393936,
        "precision": 0.03178111293859649,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023816287878787878,
        "hf_subset": "eng_Latn-hto_Latn",
        "languages": [
          "eng-Latn",
          "hto-Latn"
        ],
        "main_score": 0.023816287878787878,
        "precision": 0.019986979166666665,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014328505622202656,
        "hf_subset": "hto_Latn-eng_Latn",
        "languages": [
          "hto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014328505622202656,
        "precision": 0.012176724137931035,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03180183531746032,
        "hf_subset": "eng_Latn-hub_Latn",
        "languages": [
          "eng-Latn",
          "hub-Latn"
        ],
        "main_score": 0.03180183531746032,
        "precision": 0.02636422821969697,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018431308275058275,
        "hf_subset": "hub_Latn-eng_Latn",
        "languages": [
          "hub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018431308275058275,
        "precision": 0.017680743970714903,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014756944444444444,
        "hf_subset": "eng_Latn-hui_Latn",
        "languages": [
          "eng-Latn",
          "hui-Latn"
        ],
        "main_score": 0.014756944444444444,
        "precision": 0.0134765625,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004263392857142857,
        "hf_subset": "hui_Latn-eng_Latn",
        "languages": [
          "hui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004263392857142857,
        "precision": 0.004090382996632997,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02605581974637681,
        "hf_subset": "eng_Latn-hun_Latn",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ],
        "main_score": 0.02605581974637681,
        "precision": 0.0227052895021645,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03231678272385509,
        "hf_subset": "hun_Latn-eng_Latn",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03231678272385509,
        "precision": 0.02687848176129426,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009013189576228368,
        "hf_subset": "eng_Latn-hus_Latn",
        "languages": [
          "eng-Latn",
          "hus-Latn"
        ],
        "main_score": 0.009013189576228368,
        "precision": 0.007034676535087719,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004543687810945273,
        "hf_subset": "hus_Latn-eng_Latn",
        "languages": [
          "hus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004543687810945273,
        "precision": 0.003123571381922675,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.04161086309523809,
        "hf_subset": "eng_Latn-huu_Latn",
        "languages": [
          "eng-Latn",
          "huu-Latn"
        ],
        "main_score": 0.04161086309523809,
        "precision": 0.039496527777777776,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01376953125,
        "hf_subset": "huu_Latn-eng_Latn",
        "languages": [
          "huu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01376953125,
        "precision": 0.011653645833333334,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.027185921717171716,
        "hf_subset": "eng_Latn-huv_Latn",
        "languages": [
          "eng-Latn",
          "huv-Latn"
        ],
        "main_score": 0.027185921717171716,
        "precision": 0.023537071078431372,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01610714824879227,
        "hf_subset": "huv_Latn-eng_Latn",
        "languages": [
          "huv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01610714824879227,
        "precision": 0.014760899958574979,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.10317460317460317,
        "f1": 0.06217618360475503,
        "hf_subset": "eng_Latn-hvn_Latn",
        "languages": [
          "eng-Latn",
          "hvn-Latn"
        ],
        "main_score": 0.06217618360475503,
        "precision": 0.05220458553791887,
        "recall": 0.10317460317460317
      },
      {
        "accuracy": 0.047619047619047616,
        "f1": 0.02784076593600403,
        "hf_subset": "hvn_Latn-eng_Latn",
        "languages": [
          "hvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02784076593600403,
        "precision": 0.024036281179138322,
        "recall": 0.047619047619047616
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007139136904761905,
        "hf_subset": "eng_Latn-ian_Latn",
        "languages": [
          "eng-Latn",
          "ian-Latn"
        ],
        "main_score": 0.007139136904761905,
        "precision": 0.0059003959180216805,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000390625,
        "hf_subset": "ian_Latn-eng_Latn",
        "languages": [
          "ian-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000390625,
        "precision": 0.00020559210526315788,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021416170634920635,
        "hf_subset": "eng_Latn-ign_Latn",
        "languages": [
          "eng-Latn",
          "ign-Latn"
        ],
        "main_score": 0.021416170634920635,
        "precision": 0.019403014520202023,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0074590773809523805,
        "hf_subset": "ign_Latn-eng_Latn",
        "languages": [
          "ign-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0074590773809523805,
        "precision": 0.006099675447101917,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014750744047619047,
        "hf_subset": "eng_Latn-ikk_Latn",
        "languages": [
          "eng-Latn",
          "ikk-Latn"
        ],
        "main_score": 0.014750744047619047,
        "precision": 0.011105093078898225,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012007968509984639,
        "hf_subset": "ikk_Latn-eng_Latn",
        "languages": [
          "ikk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012007968509984639,
        "precision": 0.01028001945970696,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010593659812409811,
        "hf_subset": "eng_Latn-ikw_Latn",
        "languages": [
          "eng-Latn",
          "ikw-Latn"
        ],
        "main_score": 0.010593659812409811,
        "precision": 0.009362963935574231,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00786389802631579,
        "hf_subset": "ikw_Latn-eng_Latn",
        "languages": [
          "ikw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00786389802631579,
        "precision": 0.007838369205298013,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.06935918898809523,
        "hf_subset": "eng_Latn-ilo_Latn",
        "languages": [
          "eng-Latn",
          "ilo-Latn"
        ],
        "main_score": 0.06935918898809523,
        "precision": 0.06010330815018315,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.05615699404761905,
        "hf_subset": "ilo_Latn-eng_Latn",
        "languages": [
          "ilo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05615699404761905,
        "precision": 0.05205829326923077,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02265625,
        "hf_subset": "eng_Latn-imo_Latn",
        "languages": [
          "eng-Latn",
          "imo-Latn"
        ],
        "main_score": 0.02265625,
        "precision": 0.020244295634920636,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004076086956521739,
        "hf_subset": "imo_Latn-eng_Latn",
        "languages": [
          "imo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004076086956521739,
        "precision": 0.003993055555555555,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003515625,
        "hf_subset": "eng_Latn-inb_Latn",
        "languages": [
          "eng-Latn",
          "inb-Latn"
        ],
        "main_score": 0.003515625,
        "precision": 0.002278645833333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005375267094017094,
        "hf_subset": "inb_Latn-eng_Latn",
        "languages": [
          "inb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005375267094017094,
        "precision": 0.003548177083333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.04734655601399389,
        "hf_subset": "eng_Latn-ind_Latn",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ],
        "main_score": 0.04734655601399389,
        "precision": 0.03991908316356846,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.05585748792270531,
        "hf_subset": "ind_Latn-eng_Latn",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05585748792270531,
        "precision": 0.053377189217032966,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008548677884615384,
        "hf_subset": "eng_Latn-ino_Latn",
        "languages": [
          "eng-Latn",
          "ino-Latn"
        ],
        "main_score": 0.008548677884615384,
        "precision": 0.00681952468487395,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013834635416666665,
        "hf_subset": "ino_Latn-eng_Latn",
        "languages": [
          "ino-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013834635416666665,
        "precision": 0.0008223684210526316,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022860863095238094,
        "hf_subset": "eng_Latn-iou_Latn",
        "languages": [
          "eng-Latn",
          "iou-Latn"
        ],
        "main_score": 0.022860863095238094,
        "precision": 0.020321800595238096,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "iou_Latn-eng_Latn",
        "languages": [
          "iou-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006195813923395445,
        "hf_subset": "eng_Latn-ipi_Latn",
        "languages": [
          "eng-Latn",
          "ipi-Latn"
        ],
        "main_score": 0.006195813923395445,
        "precision": 0.005380667892156863,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.382034632034632e-05,
        "hf_subset": "ipi_Latn-eng_Latn",
        "languages": [
          "ipi-Latn",
          "eng-Latn"
        ],
        "main_score": 3.382034632034632e-05,
        "precision": 1.6983695652173913e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010247395833333332,
        "hf_subset": "eng_Latn-isn_Latn",
        "languages": [
          "eng-Latn",
          "isn-Latn"
        ],
        "main_score": 0.010247395833333332,
        "precision": 0.007929421768707482,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026565995525727067,
        "hf_subset": "isn_Latn-eng_Latn",
        "languages": [
          "isn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026565995525727067,
        "precision": 0.0019795185810810812,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.55859375,
        "f1": 0.47267485119047614,
        "hf_subset": "eng_Latn-ita_Latn",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ],
        "main_score": 0.47267485119047614,
        "precision": 0.44232559974747476,
        "recall": 0.55859375
      },
      {
        "accuracy": 0.578125,
        "f1": 0.5151411739302365,
        "hf_subset": "ita_Latn-eng_Latn",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.5151411739302365,
        "precision": 0.49346168154761905,
        "recall": 0.578125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012344848282348282,
        "hf_subset": "eng_Latn-iws_Latn",
        "languages": [
          "eng-Latn",
          "iws-Latn"
        ],
        "main_score": 0.012344848282348282,
        "precision": 0.009331597222222222,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.102272727272727e-05,
        "hf_subset": "iws_Latn-eng_Latn",
        "languages": [
          "iws-Latn",
          "eng-Latn"
        ],
        "main_score": 7.102272727272727e-05,
        "precision": 3.5837155963302754e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.007652799847840147,
        "hf_subset": "eng_Latn-ixl_Latn",
        "languages": [
          "eng-Latn",
          "ixl-Latn"
        ],
        "main_score": 0.007652799847840147,
        "precision": 0.0045122918169793165,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005326259540897699,
        "hf_subset": "ixl_Latn-eng_Latn",
        "languages": [
          "ixl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005326259540897699,
        "precision": 0.0036754261363636364,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04401041666666666,
        "hf_subset": "eng_Latn-jac_Latn",
        "languages": [
          "eng-Latn",
          "jac-Latn"
        ],
        "main_score": 0.04401041666666666,
        "precision": 0.039952256944444445,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006439048181557846,
        "hf_subset": "jac_Latn-eng_Latn",
        "languages": [
          "jac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006439048181557846,
        "precision": 0.00550963314839696,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019364091790562376,
        "hf_subset": "eng_Latn-jae_Latn",
        "languages": [
          "eng-Latn",
          "jae-Latn"
        ],
        "main_score": 0.019364091790562376,
        "precision": 0.015869140625,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.023697916666666666,
        "hf_subset": "jae_Latn-eng_Latn",
        "languages": [
          "jae-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023697916666666666,
        "precision": 0.0224609375,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.047244094488188976,
        "f1": 0.018085239345081862,
        "hf_subset": "eng_Latn-jao_Latn",
        "languages": [
          "eng-Latn",
          "jao-Latn"
        ],
        "main_score": 0.018085239345081862,
        "precision": 0.011811023622047244,
        "recall": 0.047244094488188976
      },
      {
        "accuracy": 0.06299212598425197,
        "f1": 0.024905588478871934,
        "hf_subset": "jao_Latn-eng_Latn",
        "languages": [
          "jao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024905588478871934,
        "precision": 0.019173526604628968,
        "recall": 0.06299212598425197
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.031510416666666666,
        "hf_subset": "eng_Latn-jic_Latn",
        "languages": [
          "eng-Latn",
          "jic-Latn"
        ],
        "main_score": 0.031510416666666666,
        "precision": 0.027669270833333332,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025990069529860313,
        "hf_subset": "jic_Latn-eng_Latn",
        "languages": [
          "jic-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025990069529860313,
        "precision": 0.024860442745236973,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.016330798846174513,
        "hf_subset": "eng_Latn-jid_Latn",
        "languages": [
          "eng-Latn",
          "jid-Latn"
        ],
        "main_score": 0.016330798846174513,
        "precision": 0.013342916990165632,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016449652777777775,
        "hf_subset": "jid_Latn-eng_Latn",
        "languages": [
          "jid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016449652777777775,
        "precision": 0.015062736742424242,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0040162852112676055,
        "hf_subset": "eng_Latn-jiv_Latn",
        "languages": [
          "eng-Latn",
          "jiv-Latn"
        ],
        "main_score": 0.0040162852112676055,
        "precision": 0.003962053571428571,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0043243676686217005,
        "hf_subset": "jiv_Latn-eng_Latn",
        "languages": [
          "jiv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0043243676686217005,
        "precision": 0.0041240200348432055,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013438091856060607,
        "hf_subset": "eng_Latn-jni_Latn",
        "languages": [
          "eng-Latn",
          "jni-Latn"
        ],
        "main_score": 0.013438091856060607,
        "precision": 0.009233369883040935,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012737940228174604,
        "hf_subset": "jni_Latn-eng_Latn",
        "languages": [
          "jni-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012737940228174604,
        "precision": 0.011256720430107527,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06493284547483766,
        "hf_subset": "eng_Latn-jpn_Jpan",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ],
        "main_score": 0.06493284547483766,
        "precision": 0.05816398499503968,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.02706609496217307,
        "hf_subset": "jpn_Jpan-eng_Latn",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ],
        "main_score": 0.02706609496217307,
        "precision": 0.023471143074013275,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03019649621212121,
        "hf_subset": "eng_Latn-jvn_Latn",
        "languages": [
          "eng-Latn",
          "jvn-Latn"
        ],
        "main_score": 0.03019649621212121,
        "precision": 0.026836509844322343,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015136510616474851,
        "hf_subset": "jvn_Latn-eng_Latn",
        "languages": [
          "jvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015136510616474851,
        "precision": 0.014093811094819159,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0012659143518518518,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.0012659143518518518,
        "precision": 0.0007082760989010989,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005895537948290242,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.005895537948290242,
        "precision": 0.005104993386243387,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018359374999999997,
        "hf_subset": "eng_Latn-kaq_Latn",
        "languages": [
          "eng-Latn",
          "kaq-Latn"
        ],
        "main_score": 0.018359374999999997,
        "precision": 0.016189236111111113,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009195523648648648,
        "hf_subset": "kaq_Latn-eng_Latn",
        "languages": [
          "kaq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009195523648648648,
        "precision": 0.007548983134920635,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.025227864583333332,
        "hf_subset": "eng_Latn-kbc_Latn",
        "languages": [
          "eng-Latn",
          "kbc-Latn"
        ],
        "main_score": 0.025227864583333332,
        "precision": 0.023307291666666667,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014530608127934271,
        "hf_subset": "kbc_Latn-eng_Latn",
        "languages": [
          "kbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014530608127934271,
        "precision": 0.01347175184729064,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04227116648318157,
        "hf_subset": "eng_Latn-kbh_Latn",
        "languages": [
          "eng-Latn",
          "kbh-Latn"
        ],
        "main_score": 0.04227116648318157,
        "precision": 0.03644915899051928,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02026906329600031,
        "hf_subset": "kbh_Latn-eng_Latn",
        "languages": [
          "kbh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02026906329600031,
        "precision": 0.017595653044871797,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.024776785714285716,
        "hf_subset": "eng_Latn-kbm_Latn",
        "languages": [
          "eng-Latn",
          "kbm-Latn"
        ],
        "main_score": 0.024776785714285716,
        "precision": 0.022218883547008544,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002697172619047619,
        "hf_subset": "kbm_Latn-eng_Latn",
        "languages": [
          "kbm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002697172619047619,
        "precision": 0.0020001882530120483,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013918404476516634,
        "hf_subset": "eng_Latn-kbq_Latn",
        "languages": [
          "eng-Latn",
          "kbq-Latn"
        ],
        "main_score": 0.013918404476516634,
        "precision": 0.01167999751984127,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018254697712418298,
        "hf_subset": "kbq_Latn-eng_Latn",
        "languages": [
          "kbq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018254697712418298,
        "precision": 0.016357421875,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015373883928571428,
        "hf_subset": "eng_Latn-kdc_Latn",
        "languages": [
          "eng-Latn",
          "kdc-Latn"
        ],
        "main_score": 0.015373883928571428,
        "precision": 0.01390438988095238,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005254836309523809,
        "hf_subset": "kdc_Latn-eng_Latn",
        "languages": [
          "kdc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005254836309523809,
        "precision": 0.003929640718562874,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "eng_Latn-kde_Latn",
        "languages": [
          "eng-Latn",
          "kde-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006819661458333333,
        "hf_subset": "kde_Latn-eng_Latn",
        "languages": [
          "kde-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006819661458333333,
        "precision": 0.005688630110062893,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018861130189255188,
        "hf_subset": "eng_Latn-kdl_Latn",
        "languages": [
          "eng-Latn",
          "kdl-Latn"
        ],
        "main_score": 0.018861130189255188,
        "precision": 0.016438802083333332,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004978491902834008,
        "hf_subset": "kdl_Latn-eng_Latn",
        "languages": [
          "kdl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004978491902834008,
        "precision": 0.00447906572997416,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.019003739316239318,
        "hf_subset": "eng_Latn-kek_Latn",
        "languages": [
          "eng-Latn",
          "kek-Latn"
        ],
        "main_score": 0.019003739316239318,
        "precision": 0.014916745580808079,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008090945512820514,
        "hf_subset": "kek_Latn-eng_Latn",
        "languages": [
          "kek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008090945512820514,
        "precision": 0.006652669790005316,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014665347673160172,
        "hf_subset": "eng_Latn-ken_Latn",
        "languages": [
          "eng-Latn",
          "ken-Latn"
        ],
        "main_score": 0.014665347673160172,
        "precision": 0.01259659476902174,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008409880050505051,
        "hf_subset": "ken_Latn-eng_Latn",
        "languages": [
          "ken-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008409880050505051,
        "precision": 0.006902675555019304,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020118939786059352,
        "hf_subset": "eng_Latn-kew_Latn",
        "languages": [
          "eng-Latn",
          "kew-Latn"
        ],
        "main_score": 0.020118939786059352,
        "precision": 0.01733441956327986,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008138020833333332,
        "hf_subset": "kew_Latn-eng_Latn",
        "languages": [
          "kew-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008138020833333332,
        "precision": 0.00798233695652174,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013227653349475382,
        "hf_subset": "eng_Latn-kgf_Latn",
        "languages": [
          "eng-Latn",
          "kgf-Latn"
        ],
        "main_score": 0.013227653349475382,
        "precision": 0.0114605783045977,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012699731334841627,
        "hf_subset": "kgf_Latn-eng_Latn",
        "languages": [
          "kgf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012699731334841627,
        "precision": 0.011236810064935064,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020815248842592594,
        "hf_subset": "eng_Latn-kgk_Latn",
        "languages": [
          "eng-Latn",
          "kgk-Latn"
        ],
        "main_score": 0.020815248842592594,
        "precision": 0.015959119496855346,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010004069790667945,
        "hf_subset": "kgk_Latn-eng_Latn",
        "languages": [
          "kgk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010004069790667945,
        "precision": 0.009236251304658317,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.026985563661440188,
        "hf_subset": "eng_Latn-kgp_Latn",
        "languages": [
          "eng-Latn",
          "kgp-Latn"
        ],
        "main_score": 0.026985563661440188,
        "precision": 0.022052348975752506,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.024088541666666664,
        "hf_subset": "kgp_Latn-eng_Latn",
        "languages": [
          "kgp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024088541666666664,
        "precision": 0.020312499999999997,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004142992424242424,
        "hf_subset": "eng_Latn-khs_Latn",
        "languages": [
          "eng-Latn",
          "khs-Latn"
        ],
        "main_score": 0.004142992424242424,
        "precision": 0.0040283203125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "khs_Latn-eng_Latn",
        "languages": [
          "khs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.030483774038461538,
        "hf_subset": "eng_Latn-khz_Latn",
        "languages": [
          "eng-Latn",
          "khz-Latn"
        ],
        "main_score": 0.030483774038461538,
        "precision": 0.027901785714285712,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015926535087719296,
        "hf_subset": "khz_Latn-eng_Latn",
        "languages": [
          "khz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015926535087719296,
        "precision": 0.014539930555555556,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01885068741565452,
        "hf_subset": "eng_Latn-kik_Latn",
        "languages": [
          "eng-Latn",
          "kik-Latn"
        ],
        "main_score": 0.01885068741565452,
        "precision": 0.015190972222222222,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01778927364864865,
        "hf_subset": "kik_Latn-eng_Latn",
        "languages": [
          "kik-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01778927364864865,
        "precision": 0.017035590277777776,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.14457831325301204,
        "f1": 0.10160642570281125,
        "hf_subset": "eng_Latn-kiw_Latn",
        "languages": [
          "eng-Latn",
          "kiw-Latn"
        ],
        "main_score": 0.10160642570281125,
        "precision": 0.09213042646777587,
        "recall": 0.14457831325301204
      },
      {
        "accuracy": 0.03614457831325301,
        "f1": 0.013289521723256663,
        "hf_subset": "kiw_Latn-eng_Latn",
        "languages": [
          "kiw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013289521723256663,
        "precision": 0.009259259259259259,
        "recall": 0.03614457831325301
      },
      {
        "accuracy": 0.046875,
        "f1": 0.027777777777777776,
        "hf_subset": "eng_Latn-kiz_Latn",
        "languages": [
          "eng-Latn",
          "kiz-Latn"
        ],
        "main_score": 0.027777777777777776,
        "precision": 0.023035037878787877,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018229166666666664,
        "hf_subset": "kiz_Latn-eng_Latn",
        "languages": [
          "kiz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018229166666666664,
        "precision": 0.016276041666666668,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.016833882263569765,
        "hf_subset": "eng_Latn-kje_Latn",
        "languages": [
          "eng-Latn",
          "kje-Latn"
        ],
        "main_score": 0.016833882263569765,
        "precision": 0.01340501945970696,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.026116071428571426,
        "hf_subset": "kje_Latn-eng_Latn",
        "languages": [
          "kje-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026116071428571426,
        "precision": 0.025065104166666668,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.007802100585817691,
        "hf_subset": "eng_Latn-kjs_Latn",
        "languages": [
          "eng-Latn",
          "kjs-Latn"
        ],
        "main_score": 0.007802100585817691,
        "precision": 0.004800347222222222,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "kjs_Latn-eng_Latn",
        "languages": [
          "kjs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014914279513888889,
        "hf_subset": "eng_Latn-kkc_Latn",
        "languages": [
          "eng-Latn",
          "kkc-Latn"
        ],
        "main_score": 0.014914279513888889,
        "precision": 0.012767067092293907,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019654947916666665,
        "hf_subset": "kkc_Latn-eng_Latn",
        "languages": [
          "kkc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019654947916666665,
        "precision": 0.018352288832199547,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03642733134920635,
        "hf_subset": "eng_Latn-kkl_Latn",
        "languages": [
          "eng-Latn",
          "kkl-Latn"
        ],
        "main_score": 0.03642733134920635,
        "precision": 0.03251065340909091,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02385157867494824,
        "hf_subset": "kkl_Latn-eng_Latn",
        "languages": [
          "kkl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02385157867494824,
        "precision": 0.021040482954545456,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04529389880952381,
        "hf_subset": "eng_Latn-klt_Latn",
        "languages": [
          "eng-Latn",
          "klt-Latn"
        ],
        "main_score": 0.04529389880952381,
        "precision": 0.03786892361111111,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03821405692959002,
        "hf_subset": "klt_Latn-eng_Latn",
        "languages": [
          "klt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03821405692959002,
        "precision": 0.036937415081521735,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018779592803030303,
        "hf_subset": "eng_Latn-klv_Latn",
        "languages": [
          "eng-Latn",
          "klv-Latn"
        ],
        "main_score": 0.018779592803030303,
        "precision": 0.016369047619047616,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008112980769230768,
        "hf_subset": "klv_Latn-eng_Latn",
        "languages": [
          "klv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008112980769230768,
        "precision": 0.00796875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01531161037784679,
        "hf_subset": "eng_Latn-kmg_Latn",
        "languages": [
          "eng-Latn",
          "kmg-Latn"
        ],
        "main_score": 0.01531161037784679,
        "precision": 0.011798109145970988,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011328125,
        "hf_subset": "kmg_Latn-eng_Latn",
        "languages": [
          "kmg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011328125,
        "precision": 0.010091145833333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.01449761495142929,
        "hf_subset": "eng_Latn-kmh_Latn",
        "languages": [
          "eng-Latn",
          "kmh-Latn"
        ],
        "main_score": 0.01449761495142929,
        "precision": 0.010664576480263158,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003967765748031496,
        "hf_subset": "kmh_Latn-eng_Latn",
        "languages": [
          "kmh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003967765748031496,
        "precision": 0.0027653769841269843,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04849196623093682,
        "hf_subset": "eng_Latn-kmk_Latn",
        "languages": [
          "eng-Latn",
          "kmk-Latn"
        ],
        "main_score": 0.04849196623093682,
        "precision": 0.045804537259615384,
        "recall": 0.0625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03848198784722222,
        "hf_subset": "kmk_Latn-eng_Latn",
        "languages": [
          "kmk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03848198784722222,
        "precision": 0.03384700711754643,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014409722222222221,
        "hf_subset": "eng_Latn-kmo_Latn",
        "languages": [
          "eng-Latn",
          "kmo-Latn"
        ],
        "main_score": 0.014409722222222221,
        "precision": 0.01220703125,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009817476219570635,
        "hf_subset": "kmo_Latn-eng_Latn",
        "languages": [
          "kmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009817476219570635,
        "precision": 0.007912919470324362,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03275669642857142,
        "hf_subset": "eng_Latn-kms_Latn",
        "languages": [
          "eng-Latn",
          "kms-Latn"
        ],
        "main_score": 0.03275669642857142,
        "precision": 0.02953559027777778,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015947390825320512,
        "hf_subset": "kms_Latn-eng_Latn",
        "languages": [
          "kms-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015947390825320512,
        "precision": 0.015789800020885546,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00078125,
        "hf_subset": "eng_Latn-kmu_Latn",
        "languages": [
          "eng-Latn",
          "kmu-Latn"
        ],
        "main_score": 0.00078125,
        "precision": 0.00043402777777777775,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007919520547945206,
        "hf_subset": "kmu_Latn-eng_Latn",
        "languages": [
          "kmu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007919520547945206,
        "precision": 0.007866753472222222,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04600694444444444,
        "hf_subset": "eng_Latn-kne_Latn",
        "languages": [
          "eng-Latn",
          "kne-Latn"
        ],
        "main_score": 0.04600694444444444,
        "precision": 0.03825061274509804,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.047079613095238095,
        "hf_subset": "kne_Latn-eng_Latn",
        "languages": [
          "kne-Latn",
          "eng-Latn"
        ],
        "main_score": 0.047079613095238095,
        "precision": 0.043136160714285714,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0069833431603773585,
        "hf_subset": "eng_Latn-knf_Latn",
        "languages": [
          "eng-Latn",
          "knf-Latn"
        ],
        "main_score": 0.0069833431603773585,
        "precision": 0.00581764155982906,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007889851485148515,
        "hf_subset": "knf_Latn-eng_Latn",
        "languages": [
          "knf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007889851485148515,
        "precision": 0.0078515625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022549132799671592,
        "hf_subset": "eng_Latn-knj_Latn",
        "languages": [
          "eng-Latn",
          "knj-Latn"
        ],
        "main_score": 0.022549132799671592,
        "precision": 0.019303852671451356,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02470238095238095,
        "hf_subset": "knj_Latn-eng_Latn",
        "languages": [
          "knj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02470238095238095,
        "precision": 0.021593442221266017,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.014322916666666666,
        "hf_subset": "eng_Latn-knv_Latn",
        "languages": [
          "eng-Latn",
          "knv-Latn"
        ],
        "main_score": 0.014322916666666666,
        "precision": 0.013671875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0019965277777777776,
        "hf_subset": "knv_Latn-eng_Latn",
        "languages": [
          "knv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0019965277777777776,
        "precision": 0.0013239059590316573,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1484375,
        "f1": 0.11589052007020756,
        "hf_subset": "eng_Latn-kos_Latn",
        "languages": [
          "eng-Latn",
          "kos-Latn"
        ],
        "main_score": 0.11589052007020756,
        "precision": 0.10763268849206349,
        "recall": 0.1484375
      },
      {
        "accuracy": 0.125,
        "f1": 0.10003321490855957,
        "hf_subset": "kos_Latn-eng_Latn",
        "languages": [
          "kos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.10003321490855957,
        "precision": 0.09558647207966764,
        "recall": 0.125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02490327380952381,
        "hf_subset": "eng_Latn-kpf_Latn",
        "languages": [
          "eng-Latn",
          "kpf-Latn"
        ],
        "main_score": 0.02490327380952381,
        "precision": 0.020865885416666667,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "kpf_Latn-eng_Latn",
        "languages": [
          "kpf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.125,
        "f1": 0.08976945465686273,
        "hf_subset": "eng_Latn-kpg_Latn",
        "languages": [
          "eng-Latn",
          "kpg-Latn"
        ],
        "main_score": 0.08976945465686273,
        "precision": 0.08125697544642857,
        "recall": 0.125
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.0920749823093573,
        "hf_subset": "kpg_Latn-eng_Latn",
        "languages": [
          "kpg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0920749823093573,
        "precision": 0.08668410392300195,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021319159010315926,
        "hf_subset": "eng_Latn-kpj_Latn",
        "languages": [
          "eng-Latn",
          "kpj-Latn"
        ],
        "main_score": 0.021319159010315926,
        "precision": 0.018083261281291174,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008146306818181818,
        "hf_subset": "kpj_Latn-eng_Latn",
        "languages": [
          "kpj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008146306818181818,
        "precision": 0.007983062411010915,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04653115981240981,
        "hf_subset": "eng_Latn-kpr_Latn",
        "languages": [
          "eng-Latn",
          "kpr-Latn"
        ],
        "main_score": 0.04653115981240981,
        "precision": 0.0417604015481374,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.055036619358564326,
        "hf_subset": "kpr_Latn-eng_Latn",
        "languages": [
          "kpr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.055036619358564326,
        "precision": 0.05169895208957709,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008783143939393938,
        "hf_subset": "eng_Latn-kpw_Latn",
        "languages": [
          "eng-Latn",
          "kpw-Latn"
        ],
        "main_score": 0.008783143939393938,
        "precision": 0.0072265625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007144815162907268,
        "hf_subset": "kpw_Latn-eng_Latn",
        "languages": [
          "kpw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007144815162907268,
        "precision": 0.0061912785947712415,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01705729166666667,
        "hf_subset": "eng_Latn-kpx_Latn",
        "languages": [
          "eng-Latn",
          "kpx-Latn"
        ],
        "main_score": 0.01705729166666667,
        "precision": 0.015407986111111112,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007866379310344828,
        "hf_subset": "kpx_Latn-eng_Latn",
        "languages": [
          "kpx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007866379310344828,
        "precision": 0.007839626736111112,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.09523809523809523,
        "f1": 0.06278659611992946,
        "hf_subset": "eng_Latn-kqa_Latn",
        "languages": [
          "eng-Latn",
          "kqa-Latn"
        ],
        "main_score": 0.06278659611992946,
        "precision": 0.05357142857142857,
        "recall": 0.09523809523809523
      },
      {
        "accuracy": 0.047619047619047616,
        "f1": 0.036281179138321996,
        "hf_subset": "kqa_Latn-eng_Latn",
        "languages": [
          "kqa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.036281179138321996,
        "precision": 0.03439153439153439,
        "recall": 0.047619047619047616
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07178199404761904,
        "hf_subset": "eng_Latn-kqc_Latn",
        "languages": [
          "eng-Latn",
          "kqc-Latn"
        ],
        "main_score": 0.07178199404761904,
        "precision": 0.0628330328525641,
        "recall": 0.109375
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.07273065476190477,
        "hf_subset": "kqc_Latn-eng_Latn",
        "languages": [
          "kqc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07273065476190477,
        "precision": 0.06871448863636365,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03742897727272727,
        "hf_subset": "eng_Latn-kqf_Latn",
        "languages": [
          "eng-Latn",
          "kqf-Latn"
        ],
        "main_score": 0.03742897727272727,
        "precision": 0.030143229166666664,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.0286910929144385,
        "hf_subset": "kqf_Latn-eng_Latn",
        "languages": [
          "kqf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0286910929144385,
        "precision": 0.025105794270833332,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.08571428571428572,
        "f1": 0.058044733044733045,
        "hf_subset": "eng_Latn-kql_Latn",
        "languages": [
          "eng-Latn",
          "kql-Latn"
        ],
        "main_score": 0.058044733044733045,
        "precision": 0.05321237585943469,
        "recall": 0.08571428571428572
      },
      {
        "accuracy": 0.05,
        "f1": 0.038571428571428576,
        "hf_subset": "kql_Latn-eng_Latn",
        "languages": [
          "kql-Latn",
          "eng-Latn"
        ],
        "main_score": 0.038571428571428576,
        "precision": 0.03596059113300493,
        "recall": 0.05
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023885886591478694,
        "hf_subset": "eng_Latn-kqw_Latn",
        "languages": [
          "eng-Latn",
          "kqw-Latn"
        ],
        "main_score": 0.023885886591478694,
        "precision": 0.020834484600648392,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009375,
        "hf_subset": "kqw_Latn-eng_Latn",
        "languages": [
          "kqw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009375,
        "precision": 0.0087890625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.018407504471383146,
        "hf_subset": "eng_Latn-ksd_Latn",
        "languages": [
          "eng-Latn",
          "ksd-Latn"
        ],
        "main_score": 0.018407504471383146,
        "precision": 0.014033855016036094,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.028362573099415204,
        "hf_subset": "ksd_Latn-eng_Latn",
        "languages": [
          "ksd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028362573099415204,
        "precision": 0.02438151041666667,
        "recall": 0.046875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03895399305555555,
        "hf_subset": "eng_Latn-ksj_Latn",
        "languages": [
          "eng-Latn",
          "ksj-Latn"
        ],
        "main_score": 0.03895399305555555,
        "precision": 0.03659561820652174,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024687161796536794,
        "hf_subset": "ksj_Latn-eng_Latn",
        "languages": [
          "ksj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024687161796536794,
        "precision": 0.02154947916666667,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01171125081130013,
        "hf_subset": "eng_Latn-ksr_Latn",
        "languages": [
          "eng-Latn",
          "ksr-Latn"
        ],
        "main_score": 0.01171125081130013,
        "precision": 0.007830772381553632,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012178655660377359,
        "hf_subset": "ksr_Latn-eng_Latn",
        "languages": [
          "ksr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012178655660377359,
        "precision": 0.01195663060897436,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.04983687137795001,
        "hf_subset": "eng_Latn-ktm_Latn",
        "languages": [
          "eng-Latn",
          "ktm-Latn"
        ],
        "main_score": 0.04983687137795001,
        "precision": 0.04097057456432457,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06524937229849988,
        "hf_subset": "ktm_Latn-eng_Latn",
        "languages": [
          "ktm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06524937229849988,
        "precision": 0.060872654593932166,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018248049693362193,
        "hf_subset": "eng_Latn-kto_Latn",
        "languages": [
          "eng-Latn",
          "kto-Latn"
        ],
        "main_score": 0.018248049693362193,
        "precision": 0.01604894121674491,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010221354166666665,
        "hf_subset": "kto_Latn-eng_Latn",
        "languages": [
          "kto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010221354166666665,
        "precision": 0.00823818108974359,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01474609375,
        "hf_subset": "eng_Latn-kud_Latn",
        "languages": [
          "eng-Latn",
          "kud-Latn"
        ],
        "main_score": 0.01474609375,
        "precision": 0.01351376488095238,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.1555851063829786e-05,
        "hf_subset": "kud_Latn-eng_Latn",
        "languages": [
          "kud-Latn",
          "eng-Latn"
        ],
        "main_score": 4.1555851063829786e-05,
        "precision": 2.088903743315508e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02978980654761905,
        "hf_subset": "eng_Latn-kue_Latn",
        "languages": [
          "eng-Latn",
          "kue-Latn"
        ],
        "main_score": 0.02978980654761905,
        "precision": 0.02601831761988012,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016401624570282658,
        "hf_subset": "kue_Latn-eng_Latn",
        "languages": [
          "kue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016401624570282658,
        "precision": 0.01603100637552854,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010756340579710144,
        "hf_subset": "eng_Latn-kup_Latn",
        "languages": [
          "eng-Latn",
          "kup-Latn"
        ],
        "main_score": 0.010756340579710144,
        "precision": 0.009943181818181818,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004774305555555556,
        "hf_subset": "kup_Latn-eng_Latn",
        "languages": [
          "kup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004774305555555556,
        "precision": 0.0033668154761904764,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019283234126984128,
        "hf_subset": "eng_Latn-kvg_Latn",
        "languages": [
          "eng-Latn",
          "kvg-Latn"
        ],
        "main_score": 0.019283234126984128,
        "precision": 0.015557513973577235,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009301245629370628,
        "hf_subset": "kvg_Latn-eng_Latn",
        "languages": [
          "kvg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009301245629370628,
        "precision": 0.007489120751096491,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01752232142857143,
        "hf_subset": "eng_Latn-kvn_Latn",
        "languages": [
          "eng-Latn",
          "kvn-Latn"
        ],
        "main_score": 0.01752232142857143,
        "precision": 0.013625372023809524,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011826049498746867,
        "hf_subset": "kvn_Latn-eng_Latn",
        "languages": [
          "kvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011826049498746867,
        "precision": 0.010566140518707485,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.015236137902667509,
        "hf_subset": "eng_Latn-kwd_Latn",
        "languages": [
          "eng-Latn",
          "kwd-Latn"
        ],
        "main_score": 0.015236137902667509,
        "precision": 0.012425356761294262,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01112689393939394,
        "hf_subset": "kwd_Latn-eng_Latn",
        "languages": [
          "kwd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01112689393939394,
        "precision": 0.01015625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.078125,
        "f1": 0.058984375,
        "hf_subset": "eng_Latn-kwf_Latn",
        "languages": [
          "eng-Latn",
          "kwf-Latn"
        ],
        "main_score": 0.058984375,
        "precision": 0.05493100649350649,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016536458333333334,
        "hf_subset": "kwf_Latn-eng_Latn",
        "languages": [
          "kwf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016536458333333334,
        "precision": 0.015108656609195402,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020669371240087504,
        "hf_subset": "eng_Latn-kwi_Latn",
        "languages": [
          "eng-Latn",
          "kwi-Latn"
        ],
        "main_score": 0.020669371240087504,
        "precision": 0.018946873439060936,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.023121279761904763,
        "hf_subset": "kwi_Latn-eng_Latn",
        "languages": [
          "kwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023121279761904763,
        "precision": 0.01953125,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009994419642857143,
        "hf_subset": "eng_Latn-kwj_Latn",
        "languages": [
          "eng-Latn",
          "kwj-Latn"
        ],
        "main_score": 0.009994419642857143,
        "precision": 0.009051983173076924,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004906226585914086,
        "hf_subset": "kwj_Latn-eng_Latn",
        "languages": [
          "kwj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004906226585914086,
        "precision": 0.00444449086452763,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0034288194444444444,
        "hf_subset": "eng_Latn-kyc_Latn",
        "languages": [
          "eng-Latn",
          "kyc-Latn"
        ],
        "main_score": 0.0034288194444444444,
        "precision": 0.0021721117424242423,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.301401869158878e-05,
        "hf_subset": "kyc_Latn-eng_Latn",
        "languages": [
          "kyc-Latn",
          "eng-Latn"
        ],
        "main_score": 7.301401869158878e-05,
        "precision": 3.685141509433962e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006324404761904762,
        "hf_subset": "eng_Latn-kyf_Latn",
        "languages": [
          "eng-Latn",
          "kyf-Latn"
        ],
        "main_score": 0.006324404761904762,
        "precision": 0.004557291666666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00028935185185185184,
        "hf_subset": "kyf_Latn-eng_Latn",
        "languages": [
          "kyf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00028935185185185184,
        "precision": 0.00015024038461538462,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004261363636363636,
        "hf_subset": "eng_Latn-kyg_Latn",
        "languages": [
          "eng-Latn",
          "kyg-Latn"
        ],
        "main_score": 0.004261363636363636,
        "precision": 0.004092261904761905,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.000853587962962963,
        "hf_subset": "kyg_Latn-eng_Latn",
        "languages": [
          "kyg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000853587962962963,
        "precision": 0.00047053478712357215,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00824702380952381,
        "hf_subset": "eng_Latn-kyq_Latn",
        "languages": [
          "eng-Latn",
          "kyq-Latn"
        ],
        "main_score": 0.00824702380952381,
        "precision": 0.008039314516129032,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011809593023255814,
        "hf_subset": "kyq_Latn-eng_Latn",
        "languages": [
          "kyq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011809593023255814,
        "precision": 0.011764705882352941,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010424901185770752,
        "hf_subset": "eng_Latn-kyz_Latn",
        "languages": [
          "eng-Latn",
          "kyz-Latn"
        ],
        "main_score": 0.010424901185770752,
        "precision": 0.009357244318181818,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007003837719298245,
        "hf_subset": "kyz_Latn-eng_Latn",
        "languages": [
          "kyz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007003837719298245,
        "precision": 0.006117050438596491,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0030894886363636363,
        "hf_subset": "eng_Latn-kze_Latn",
        "languages": [
          "eng-Latn",
          "kze-Latn"
        ],
        "main_score": 0.0030894886363636363,
        "precision": 0.0019221230158730158,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.792944785276074e-05,
        "hf_subset": "kze_Latn-eng_Latn",
        "languages": [
          "kze-Latn",
          "eng-Latn"
        ],
        "main_score": 4.792944785276074e-05,
        "precision": 2.4112654320987653e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017969297093837534,
        "hf_subset": "eng_Latn-lac_Latn",
        "languages": [
          "eng-Latn",
          "lac-Latn"
        ],
        "main_score": 0.017969297093837534,
        "precision": 0.015920211497542004,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015514837609801201,
        "hf_subset": "lac_Latn-eng_Latn",
        "languages": [
          "lac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015514837609801201,
        "precision": 0.014361213235294117,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.5859375,
        "f1": 0.5027653769841269,
        "hf_subset": "eng_Latn-lat_Latn",
        "languages": [
          "eng-Latn",
          "lat-Latn"
        ],
        "main_score": 0.5027653769841269,
        "precision": 0.47315383184523807,
        "recall": 0.5859375
      },
      {
        "accuracy": 0.50390625,
        "f1": 0.4319541097689075,
        "hf_subset": "lat_Latn-eng_Latn",
        "languages": [
          "lat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.4319541097689075,
        "precision": 0.4059498444264069,
        "recall": 0.50390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.030921677064255186,
        "hf_subset": "eng_Latn-lbb_Latn",
        "languages": [
          "eng-Latn",
          "lbb-Latn"
        ],
        "main_score": 0.030921677064255186,
        "precision": 0.02800335800438597,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018279897186147184,
        "hf_subset": "lbb_Latn-eng_Latn",
        "languages": [
          "lbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018279897186147184,
        "precision": 0.01717936197916667,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.05658967391304348,
        "hf_subset": "eng_Latn-lbk_Latn",
        "languages": [
          "eng-Latn",
          "lbk-Latn"
        ],
        "main_score": 0.05658967391304348,
        "precision": 0.05453953598484848,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.030196340460526314,
        "hf_subset": "lbk_Latn-eng_Latn",
        "languages": [
          "lbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030196340460526314,
        "precision": 0.026874210858585858,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025824652777777776,
        "hf_subset": "eng_Latn-lcm_Latn",
        "languages": [
          "eng-Latn",
          "lcm-Latn"
        ],
        "main_score": 0.025824652777777776,
        "precision": 0.021844362745098038,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0207832532051282,
        "hf_subset": "lcm_Latn-eng_Latn",
        "languages": [
          "lcm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0207832532051282,
        "precision": 0.019205729166666664,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016195718344155844,
        "hf_subset": "eng_Latn-leu_Latn",
        "languages": [
          "eng-Latn",
          "leu-Latn"
        ],
        "main_score": 0.016195718344155844,
        "precision": 0.014295014880952382,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018351236979166664,
        "hf_subset": "leu_Latn-eng_Latn",
        "languages": [
          "leu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018351236979166664,
        "precision": 0.017640128968253968,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.029344767720306517,
        "hf_subset": "eng_Latn-lex_Latn",
        "languages": [
          "eng-Latn",
          "lex-Latn"
        ],
        "main_score": 0.029344767720306517,
        "precision": 0.0274250462246302,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018207830007002802,
        "hf_subset": "lex_Latn-eng_Latn",
        "languages": [
          "lex-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018207830007002802,
        "precision": 0.015975886093073592,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.039322916666666666,
        "hf_subset": "eng_Latn-lgl_Latn",
        "languages": [
          "eng-Latn",
          "lgl-Latn"
        ],
        "main_score": 0.039322916666666666,
        "precision": 0.03583688446969697,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03108723958333333,
        "hf_subset": "lgl_Latn-eng_Latn",
        "languages": [
          "lgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03108723958333333,
        "precision": 0.028906249999999998,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03000485761738906,
        "hf_subset": "eng_Latn-lid_Latn",
        "languages": [
          "eng-Latn",
          "lid-Latn"
        ],
        "main_score": 0.03000485761738906,
        "precision": 0.025520340119949494,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008764022435897436,
        "hf_subset": "lid_Latn-eng_Latn",
        "languages": [
          "lid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008764022435897436,
        "precision": 0.008323863636363636,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016684649403239556,
        "hf_subset": "eng_Latn-lif_Deva",
        "languages": [
          "eng-Latn",
          "lif-Deva"
        ],
        "main_score": 0.016684649403239556,
        "precision": 0.013551037720959596,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006543242296918767,
        "hf_subset": "lif_Deva-eng_Latn",
        "languages": [
          "lif-Deva",
          "eng-Latn"
        ],
        "main_score": 0.006543242296918767,
        "precision": 0.005875857067510548,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011209562072166793,
        "hf_subset": "eng_Latn-lin_Latn",
        "languages": [
          "eng-Latn",
          "lin-Latn"
        ],
        "main_score": 0.011209562072166793,
        "precision": 0.009934129901960782,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006119791666666667,
        "hf_subset": "lin_Latn-eng_Latn",
        "languages": [
          "lin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006119791666666667,
        "precision": 0.004231770833333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008153457903780068,
        "hf_subset": "eng_Latn-lit_Latn",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ],
        "main_score": 0.008153457903780068,
        "precision": 0.005574544270833333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01015625,
        "hf_subset": "lit_Latn-eng_Latn",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01015625,
        "precision": 0.007921006944444444,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.0297687578320802,
        "hf_subset": "eng_Latn-llg_Latn",
        "languages": [
          "eng-Latn",
          "llg-Latn"
        ],
        "main_score": 0.0297687578320802,
        "precision": 0.024939546130952377,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.023487261146496817,
        "hf_subset": "llg_Latn-eng_Latn",
        "languages": [
          "llg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023487261146496817,
        "precision": 0.023462540064102564,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002012310606060606,
        "hf_subset": "eng_Latn-lug_Latn",
        "languages": [
          "eng-Latn",
          "lug-Latn"
        ],
        "main_score": 0.002012310606060606,
        "precision": 0.001103670634920635,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.1062091503267975e-05,
        "hf_subset": "lug_Latn-eng_Latn",
        "languages": [
          "lug-Latn",
          "eng-Latn"
        ],
        "main_score": 5.1062091503267975e-05,
        "precision": 2.5699013157894735e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.023015396062271064,
        "hf_subset": "eng_Latn-luo_Latn",
        "languages": [
          "eng-Latn",
          "luo-Latn"
        ],
        "main_score": 0.023015396062271064,
        "precision": 0.01876219443369453,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.015625,
        "hf_subset": "luo_Latn-eng_Latn",
        "languages": [
          "luo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015625,
        "precision": 0.014453125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005580357142857143,
        "hf_subset": "eng_Latn-lww_Latn",
        "languages": [
          "eng-Latn",
          "lww-Latn"
        ],
        "main_score": 0.0005580357142857143,
        "precision": 0.00030048076923076925,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "lww_Latn-eng_Latn",
        "languages": [
          "lww-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.030536755421865718,
        "hf_subset": "eng_Latn-maa_Latn",
        "languages": [
          "eng-Latn",
          "maa-Latn"
        ],
        "main_score": 0.030536755421865718,
        "precision": 0.026069615425084174,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017919859514687102,
        "hf_subset": "maa_Latn-eng_Latn",
        "languages": [
          "maa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017919859514687102,
        "precision": 0.015801015937917225,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.039713541666666664,
        "hf_subset": "eng_Latn-maj_Latn",
        "languages": [
          "eng-Latn",
          "maj-Latn"
        ],
        "main_score": 0.039713541666666664,
        "precision": 0.03645833333333333,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010894058504311625,
        "hf_subset": "maj_Latn-eng_Latn",
        "languages": [
          "maj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010894058504311625,
        "precision": 0.008713942307692308,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013816550925925927,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.013816550925925927,
        "precision": 0.010845483133218982,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006801975439422472,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.006801975439422472,
        "precision": 0.005704940713022609,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03001302083333333,
        "hf_subset": "eng_Latn-mam_Latn",
        "languages": [
          "eng-Latn",
          "mam-Latn"
        ],
        "main_score": 0.03001302083333333,
        "precision": 0.023453000992063492,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03169986392642642,
        "hf_subset": "mam_Latn-eng_Latn",
        "languages": [
          "mam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03169986392642642,
        "precision": 0.027094388401912486,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.036360889842047925,
        "hf_subset": "eng_Latn-maq_Latn",
        "languages": [
          "eng-Latn",
          "maq-Latn"
        ],
        "main_score": 0.036360889842047925,
        "precision": 0.03341769450167888,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010629189613929684,
        "hf_subset": "maq_Latn-eng_Latn",
        "languages": [
          "maq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010629189613929684,
        "precision": 0.009873499142367067,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004208519345238095,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.004208519345238095,
        "precision": 0.002864583333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0042424045780119725,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0042424045780119725,
        "precision": 0.002562313988095238,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03177083333333333,
        "hf_subset": "eng_Latn-mau_Latn",
        "languages": [
          "eng-Latn",
          "mau-Latn"
        ],
        "main_score": 0.03177083333333333,
        "precision": 0.02578125,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013476562499999999,
        "hf_subset": "mau_Latn-eng_Latn",
        "languages": [
          "mau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013476562499999999,
        "precision": 0.011493389423076922,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004836309523809524,
        "hf_subset": "eng_Latn-mav_Latn",
        "languages": [
          "eng-Latn",
          "mav-Latn"
        ],
        "main_score": 0.004836309523809524,
        "precision": 0.004402043269230769,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00025318287037037036,
        "hf_subset": "mav_Latn-eng_Latn",
        "languages": [
          "mav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00025318287037037036,
        "precision": 0.00012872043582248205,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.056744622564935066,
        "hf_subset": "eng_Latn-maz_Latn",
        "languages": [
          "eng-Latn",
          "maz-Latn"
        ],
        "main_score": 0.056744622564935066,
        "precision": 0.052501860119047616,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02395833333333333,
        "hf_subset": "maz_Latn-eng_Latn",
        "languages": [
          "maz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02395833333333333,
        "precision": 0.02085503472222222,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.140625,
        "f1": 0.09780244666308797,
        "hf_subset": "eng_Latn-mbb_Latn",
        "languages": [
          "eng-Latn",
          "mbb-Latn"
        ],
        "main_score": 0.09780244666308797,
        "precision": 0.08791155133928572,
        "recall": 0.140625
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.0861285092395167,
        "hf_subset": "mbb_Latn-eng_Latn",
        "languages": [
          "mbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0861285092395167,
        "precision": 0.0784567967064218,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03208705357142857,
        "hf_subset": "eng_Latn-mbc_Latn",
        "languages": [
          "eng-Latn",
          "mbc-Latn"
        ],
        "main_score": 0.03208705357142857,
        "precision": 0.030694232723577235,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.020833333333333332,
        "hf_subset": "mbc_Latn-eng_Latn",
        "languages": [
          "mbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020833333333333332,
        "precision": 0.0203125,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019180606869184456,
        "hf_subset": "eng_Latn-mbh_Latn",
        "languages": [
          "eng-Latn",
          "mbh-Latn"
        ],
        "main_score": 0.019180606869184456,
        "precision": 0.015580188041125542,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.028670855255591973,
        "hf_subset": "mbh_Latn-eng_Latn",
        "languages": [
          "mbh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028670855255591973,
        "precision": 0.026927548363095237,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017897727272727273,
        "hf_subset": "eng_Latn-mbj_Latn",
        "languages": [
          "eng-Latn",
          "mbj-Latn"
        ],
        "main_score": 0.017897727272727273,
        "precision": 0.015690104166666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008122519841269842,
        "hf_subset": "mbj_Latn-eng_Latn",
        "languages": [
          "mbj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008122519841269842,
        "precision": 0.00673828125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008282869816586921,
        "hf_subset": "eng_Latn-mbl_Latn",
        "languages": [
          "eng-Latn",
          "mbl-Latn"
        ],
        "main_score": 0.008282869816586921,
        "precision": 0.006597222222222222,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0012383167980110704,
        "hf_subset": "mbl_Latn-eng_Latn",
        "languages": [
          "mbl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0012383167980110704,
        "precision": 0.0006693342090707964,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.030619517543859647,
        "hf_subset": "eng_Latn-mbs_Latn",
        "languages": [
          "eng-Latn",
          "mbs-Latn"
        ],
        "main_score": 0.030619517543859647,
        "precision": 0.028537326388888888,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015104166666666665,
        "hf_subset": "mbs_Latn-eng_Latn",
        "languages": [
          "mbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015104166666666665,
        "precision": 0.012803819444444444,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010230654761904762,
        "hf_subset": "eng_Latn-mbt_Latn",
        "languages": [
          "eng-Latn",
          "mbt-Latn"
        ],
        "main_score": 0.010230654761904762,
        "precision": 0.008167613636363636,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005705330714936247,
        "hf_subset": "mbt_Latn-eng_Latn",
        "languages": [
          "mbt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005705330714936247,
        "precision": 0.005002934272300469,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03374255952380952,
        "hf_subset": "eng_Latn-mca_Latn",
        "languages": [
          "eng-Latn",
          "mca-Latn"
        ],
        "main_score": 0.03374255952380952,
        "precision": 0.02894297542735043,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0254858993902439,
        "hf_subset": "mca_Latn-eng_Latn",
        "languages": [
          "mca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0254858993902439,
        "precision": 0.022834683641975308,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007954545454545454,
        "hf_subset": "eng_Latn-mcb_Latn",
        "languages": [
          "eng-Latn",
          "mcb-Latn"
        ],
        "main_score": 0.007954545454545454,
        "precision": 0.007884837962962963,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009281517094017094,
        "hf_subset": "mcb_Latn-eng_Latn",
        "languages": [
          "mcb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009281517094017094,
        "precision": 0.008626302083333334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007118055555555556,
        "hf_subset": "eng_Latn-mcd_Latn",
        "languages": [
          "eng-Latn",
          "mcd-Latn"
        ],
        "main_score": 0.007118055555555556,
        "precision": 0.005902206688596491,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014931344696969696,
        "hf_subset": "mcd_Latn-eng_Latn",
        "languages": [
          "mcd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014931344696969696,
        "precision": 0.013696289062499999,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0029730902777777776,
        "hf_subset": "eng_Latn-mcf_Latn",
        "languages": [
          "eng-Latn",
          "mcf-Latn"
        ],
        "main_score": 0.0029730902777777776,
        "precision": 0.0017643776260504202,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0037009214743589742,
        "hf_subset": "mcf_Latn-eng_Latn",
        "languages": [
          "mcf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0037009214743589742,
        "precision": 0.002572195870535714,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03551215277777778,
        "hf_subset": "eng_Latn-mco_Latn",
        "languages": [
          "eng-Latn",
          "mco-Latn"
        ],
        "main_score": 0.03551215277777778,
        "precision": 0.033720999053030304,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.030329034687425437,
        "hf_subset": "mco_Latn-eng_Latn",
        "languages": [
          "mco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030329034687425437,
        "precision": 0.02809089781746032,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015367263436249282,
        "hf_subset": "eng_Latn-mcp_Latn",
        "languages": [
          "eng-Latn",
          "mcp-Latn"
        ],
        "main_score": 0.015367263436249282,
        "precision": 0.013123139880952381,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007161458333333333,
        "hf_subset": "mcp_Latn-eng_Latn",
        "languages": [
          "mcp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007161458333333333,
        "precision": 0.005989583333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012596842880559986,
        "hf_subset": "eng_Latn-mcq_Latn",
        "languages": [
          "eng-Latn",
          "mcq-Latn"
        ],
        "main_score": 0.012596842880559986,
        "precision": 0.011004972296760087,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0019899764150943396,
        "hf_subset": "mcq_Latn-eng_Latn",
        "languages": [
          "mcq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0019899764150943396,
        "precision": 0.0013205963665086887,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007161458333333333,
        "hf_subset": "eng_Latn-mcr_Latn",
        "languages": [
          "eng-Latn",
          "mcr-Latn"
        ],
        "main_score": 0.007161458333333333,
        "precision": 0.006214488636363636,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006554184173669467,
        "hf_subset": "mcr_Latn-eng_Latn",
        "languages": [
          "mcr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006554184173669467,
        "precision": 0.005456912878787879,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016826923076923078,
        "hf_subset": "eng_Latn-mdy_Latn",
        "languages": [
          "eng-Latn",
          "mdy-Latn"
        ],
        "main_score": 0.0016826923076923078,
        "precision": 0.00103759765625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mdy_Latn-eng_Latn",
        "languages": [
          "mdy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010836522108843536,
        "hf_subset": "eng_Latn-med_Latn",
        "languages": [
          "eng-Latn",
          "med-Latn"
        ],
        "main_score": 0.010836522108843536,
        "precision": 0.009651692708333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007081020752895752,
        "hf_subset": "med_Latn-eng_Latn",
        "languages": [
          "med-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007081020752895752,
        "precision": 0.005747165577002906,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008418004326047359,
        "hf_subset": "eng_Latn-mee_Latn",
        "languages": [
          "eng-Latn",
          "mee-Latn"
        ],
        "main_score": 0.008418004326047359,
        "precision": 0.005380394345238095,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004245472419140452,
        "hf_subset": "mee_Latn-eng_Latn",
        "languages": [
          "mee-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004245472419140452,
        "precision": 0.0040798611111111105,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02114481209150327,
        "hf_subset": "eng_Latn-mek_Latn",
        "languages": [
          "eng-Latn",
          "mek-Latn"
        ],
        "main_score": 0.02114481209150327,
        "precision": 0.019065708482854864,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017253164443488237,
        "hf_subset": "mek_Latn-eng_Latn",
        "languages": [
          "mek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017253164443488237,
        "precision": 0.01512784090909091,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015086623743563081,
        "hf_subset": "eng_Latn-meq_Latn",
        "languages": [
          "eng-Latn",
          "meq-Latn"
        ],
        "main_score": 0.015086623743563081,
        "precision": 0.0137664740328712,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012080627705627706,
        "hf_subset": "meq_Latn-eng_Latn",
        "languages": [
          "meq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012080627705627706,
        "precision": 0.01079358552631579,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013752003205128205,
        "hf_subset": "eng_Latn-met_Latn",
        "languages": [
          "eng-Latn",
          "met-Latn"
        ],
        "main_score": 0.013752003205128205,
        "precision": 0.008928571428571428,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007899305555555555,
        "hf_subset": "met_Latn-eng_Latn",
        "languages": [
          "met-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007899305555555555,
        "precision": 0.007856390449438201,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.029902925982384823,
        "hf_subset": "eng_Latn-meu_Latn",
        "languages": [
          "eng-Latn",
          "meu-Latn"
        ],
        "main_score": 0.029902925982384823,
        "precision": 0.026599168740242,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022612847222222225,
        "hf_subset": "meu_Latn-eng_Latn",
        "languages": [
          "meu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022612847222222225,
        "precision": 0.019173177083333333,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03958333333333333,
        "hf_subset": "eng_Latn-mgc_Latn",
        "languages": [
          "eng-Latn",
          "mgc-Latn"
        ],
        "main_score": 0.03958333333333333,
        "precision": 0.035926078216374266,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011387310606060606,
        "hf_subset": "mgc_Latn-eng_Latn",
        "languages": [
          "mgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011387310606060606,
        "precision": 0.009960937500000001,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01072831602399024,
        "hf_subset": "eng_Latn-mgh_Latn",
        "languages": [
          "eng-Latn",
          "mgh-Latn"
        ],
        "main_score": 0.01072831602399024,
        "precision": 0.006776999213779641,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0066524621212121215,
        "hf_subset": "mgh_Latn-eng_Latn",
        "languages": [
          "mgh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0066524621212121215,
        "precision": 0.005931712962962963,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.07655502392344497,
        "f1": 0.05058206405659262,
        "hf_subset": "eng_Latn-mgw_Latn",
        "languages": [
          "eng-Latn",
          "mgw-Latn"
        ],
        "main_score": 0.05058206405659262,
        "precision": 0.04550296195033037,
        "recall": 0.07655502392344497
      },
      {
        "accuracy": 0.04784688995215311,
        "f1": 0.0347917385369951,
        "hf_subset": "mgw_Latn-eng_Latn",
        "languages": [
          "mgw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0347917385369951,
        "precision": 0.0328307555357739,
        "recall": 0.04784688995215311
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.027928998427559283,
        "hf_subset": "eng_Latn-mhl_Latn",
        "languages": [
          "eng-Latn",
          "mhl-Latn"
        ],
        "main_score": 0.027928998427559283,
        "precision": 0.021019709967320256,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017764136904761904,
        "hf_subset": "mhl_Latn-eng_Latn",
        "languages": [
          "mhl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017764136904761904,
        "precision": 0.017022357723577235,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04967447916666666,
        "hf_subset": "eng_Latn-mib_Latn",
        "languages": [
          "eng-Latn",
          "mib-Latn"
        ],
        "main_score": 0.04967447916666666,
        "precision": 0.044012107683982685,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03210145449308756,
        "hf_subset": "mib_Latn-eng_Latn",
        "languages": [
          "mib-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03210145449308756,
        "precision": 0.0303374743852459,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018001818783068783,
        "hf_subset": "eng_Latn-mic_Latn",
        "languages": [
          "eng-Latn",
          "mic-Latn"
        ],
        "main_score": 0.018001818783068783,
        "precision": 0.017000786163522012,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "mic_Latn-eng_Latn",
        "languages": [
          "mic-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.05990079365079365,
        "hf_subset": "eng_Latn-mie_Latn",
        "languages": [
          "eng-Latn",
          "mie-Latn"
        ],
        "main_score": 0.05990079365079365,
        "precision": 0.05262440174549549,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04720314407814408,
        "hf_subset": "mie_Latn-eng_Latn",
        "languages": [
          "mie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04720314407814408,
        "precision": 0.04320568371579401,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.050473264281008845,
        "hf_subset": "eng_Latn-mig_Latn",
        "languages": [
          "eng-Latn",
          "mig-Latn"
        ],
        "main_score": 0.050473264281008845,
        "precision": 0.04479251217532468,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03744419642857143,
        "hf_subset": "mig_Latn-eng_Latn",
        "languages": [
          "mig-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03744419642857143,
        "precision": 0.033203125,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.036219618055555555,
        "hf_subset": "eng_Latn-mih_Latn",
        "languages": [
          "eng-Latn",
          "mih-Latn"
        ],
        "main_score": 0.036219618055555555,
        "precision": 0.029506138392857144,
        "recall": 0.0625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03629946670653907,
        "hf_subset": "mih_Latn-eng_Latn",
        "languages": [
          "mih-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03629946670653907,
        "precision": 0.03358909970238095,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.023739064754689752,
        "hf_subset": "eng_Latn-mil_Latn",
        "languages": [
          "eng-Latn",
          "mil-Latn"
        ],
        "main_score": 0.023739064754689752,
        "precision": 0.022363980042486582,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009765625,
        "hf_subset": "mil_Latn-eng_Latn",
        "languages": [
          "mil-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.009114583333333334,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020907738095238094,
        "hf_subset": "eng_Latn-mio_Latn",
        "languages": [
          "eng-Latn",
          "mio-Latn"
        ],
        "main_score": 0.020907738095238094,
        "precision": 0.016731770833333333,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004199857026143791,
        "hf_subset": "mio_Latn-eng_Latn",
        "languages": [
          "mio-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004199857026143791,
        "precision": 0.002835195628937894,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.028339892700501253,
        "hf_subset": "eng_Latn-mir_Latn",
        "languages": [
          "eng-Latn",
          "mir-Latn"
        ],
        "main_score": 0.028339892700501253,
        "precision": 0.02670527670527671,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013418175731387781,
        "hf_subset": "mir_Latn-eng_Latn",
        "languages": [
          "mir-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013418175731387781,
        "precision": 0.01144515214490969,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.03606843928920542,
        "hf_subset": "eng_Latn-mit_Latn",
        "languages": [
          "eng-Latn",
          "mit-Latn"
        ],
        "main_score": 0.03606843928920542,
        "precision": 0.03008343962585034,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020407774390243903,
        "hf_subset": "mit_Latn-eng_Latn",
        "languages": [
          "mit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020407774390243903,
        "precision": 0.018060378086419752,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020250582750582752,
        "hf_subset": "eng_Latn-miz_Latn",
        "languages": [
          "eng-Latn",
          "miz-Latn"
        ],
        "main_score": 0.020250582750582752,
        "precision": 0.016661658653846154,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014114583333333333,
        "hf_subset": "miz_Latn-eng_Latn",
        "languages": [
          "miz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014114583333333333,
        "precision": 0.013249801377118644,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02153707837301587,
        "hf_subset": "eng_Latn-mjc_Latn",
        "languages": [
          "eng-Latn",
          "mjc-Latn"
        ],
        "main_score": 0.02153707837301587,
        "precision": 0.016977051237161533,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014029052450600543,
        "hf_subset": "mjc_Latn-eng_Latn",
        "languages": [
          "mjc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014029052450600543,
        "precision": 0.013204731466450218,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.18359375,
        "f1": 0.11964571886446887,
        "hf_subset": "eng_Latn-mkj_Latn",
        "languages": [
          "eng-Latn",
          "mkj-Latn"
        ],
        "main_score": 0.11964571886446887,
        "precision": 0.10117268490829345,
        "recall": 0.18359375
      },
      {
        "accuracy": 0.171875,
        "f1": 0.1189259831540742,
        "hf_subset": "mkj_Latn-eng_Latn",
        "languages": [
          "mkj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1189259831540742,
        "precision": 0.10425967261904762,
        "recall": 0.171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008463541666666666,
        "hf_subset": "eng_Latn-mkl_Latn",
        "languages": [
          "eng-Latn",
          "mkl-Latn"
        ],
        "main_score": 0.008463541666666666,
        "precision": 0.007161458333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004487271167048054,
        "hf_subset": "mkl_Latn-eng_Latn",
        "languages": [
          "mkl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004487271167048054,
        "precision": 0.004210069444444444,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.035881696428571426,
        "hf_subset": "eng_Latn-mkn_Latn",
        "languages": [
          "eng-Latn",
          "mkn-Latn"
        ],
        "main_score": 0.035881696428571426,
        "precision": 0.0302734375,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02608605587121212,
        "hf_subset": "mkn_Latn-eng_Latn",
        "languages": [
          "mkn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02608605587121212,
        "precision": 0.025412946428571427,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021809895833333332,
        "hf_subset": "eng_Latn-mks_Latn",
        "languages": [
          "eng-Latn",
          "mks-Latn"
        ],
        "main_score": 0.021809895833333332,
        "precision": 0.01878720238095238,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018472098109989718,
        "hf_subset": "mks_Latn-eng_Latn",
        "languages": [
          "mks-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018472098109989718,
        "precision": 0.017394027923669467,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007700892857142857,
        "hf_subset": "eng_Latn-mle_Latn",
        "languages": [
          "eng-Latn",
          "mle-Latn"
        ],
        "main_score": 0.007700892857142857,
        "precision": 0.006184895833333334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005580357142857143,
        "hf_subset": "mle_Latn-eng_Latn",
        "languages": [
          "mle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005580357142857143,
        "precision": 0.00030048076923076925,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.027928998427559283,
        "hf_subset": "eng_Latn-mlh_Latn",
        "languages": [
          "eng-Latn",
          "mlh-Latn"
        ],
        "main_score": 0.027928998427559283,
        "precision": 0.021019709967320256,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017764136904761904,
        "hf_subset": "mlh_Latn-eng_Latn",
        "languages": [
          "mlh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017764136904761904,
        "precision": 0.017022357723577235,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00984909188034188,
        "hf_subset": "eng_Latn-mlp_Latn",
        "languages": [
          "eng-Latn",
          "mlp-Latn"
        ],
        "main_score": 0.00984909188034188,
        "precision": 0.007917596726190477,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003985164141414141,
        "hf_subset": "mlp_Latn-eng_Latn",
        "languages": [
          "mlp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003985164141414141,
        "precision": 0.003946109693877551,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008673878205128206,
        "hf_subset": "eng_Latn-mmo_Latn",
        "languages": [
          "eng-Latn",
          "mmo-Latn"
        ],
        "main_score": 0.008673878205128206,
        "precision": 0.007161458333333334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006611877705627706,
        "hf_subset": "mmo_Latn-eng_Latn",
        "languages": [
          "mmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006611877705627706,
        "precision": 0.005910773026315789,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022751130490956072,
        "hf_subset": "eng_Latn-mmx_Latn",
        "languages": [
          "eng-Latn",
          "mmx-Latn"
        ],
        "main_score": 0.022751130490956072,
        "precision": 0.018161327030812323,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010821906887755101,
        "hf_subset": "mmx_Latn-eng_Latn",
        "languages": [
          "mmx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010821906887755101,
        "precision": 0.00954716996920605,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02636307377518315,
        "hf_subset": "eng_Latn-mna_Latn",
        "languages": [
          "eng-Latn",
          "mna-Latn"
        ],
        "main_score": 0.02636307377518315,
        "precision": 0.02317837460960897,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01743951612903226,
        "hf_subset": "mna_Latn-eng_Latn",
        "languages": [
          "mna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01743951612903226,
        "precision": 0.014778645833333333,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.021701388888888888,
        "hf_subset": "eng_Latn-mop_Latn",
        "languages": [
          "eng-Latn",
          "mop-Latn"
        ],
        "main_score": 0.021701388888888888,
        "precision": 0.02080078125,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016869926083081452,
        "hf_subset": "mop_Latn-eng_Latn",
        "languages": [
          "mop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016869926083081452,
        "precision": 0.01321227058531746,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014973958333333332,
        "hf_subset": "eng_Latn-mox_Latn",
        "languages": [
          "eng-Latn",
          "mox-Latn"
        ],
        "main_score": 0.014973958333333332,
        "precision": 0.014026988636363636,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004673170853269537,
        "hf_subset": "mox_Latn-eng_Latn",
        "languages": [
          "mox-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004673170853269537,
        "precision": 0.004310679464469468,
        "recall": 0.015625
      },
      {
        "accuracy": 0.12048192771084337,
        "f1": 0.07536461636017755,
        "hf_subset": "eng_Latn-mph_Latn",
        "languages": [
          "eng-Latn",
          "mph-Latn"
        ],
        "main_score": 0.07536461636017755,
        "precision": 0.06564352648689999,
        "recall": 0.12048192771084337
      },
      {
        "accuracy": 0.0963855421686747,
        "f1": 0.049489688075610716,
        "hf_subset": "mph_Latn-eng_Latn",
        "languages": [
          "mph-Latn",
          "eng-Latn"
        ],
        "main_score": 0.049489688075610716,
        "precision": 0.04054312488047428,
        "recall": 0.0963855421686747
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00021701388888888888,
        "hf_subset": "eng_Latn-mpj_Latn",
        "languages": [
          "eng-Latn",
          "mpj-Latn"
        ],
        "main_score": 0.00021701388888888888,
        "precision": 0.00011160714285714285,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.314625850340136e-05,
        "hf_subset": "mpj_Latn-eng_Latn",
        "languages": [
          "mpj-Latn",
          "eng-Latn"
        ],
        "main_score": 5.314625850340136e-05,
        "precision": 2.675513698630137e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.024878472222222225,
        "hf_subset": "eng_Latn-mpm_Latn",
        "languages": [
          "eng-Latn",
          "mpm-Latn"
        ],
        "main_score": 0.024878472222222225,
        "precision": 0.02045200892857143,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.023048566017316016,
        "hf_subset": "mpm_Latn-eng_Latn",
        "languages": [
          "mpm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023048566017316016,
        "precision": 0.021970867673992672,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.029755704365079363,
        "hf_subset": "eng_Latn-mpp_Latn",
        "languages": [
          "eng-Latn",
          "mpp-Latn"
        ],
        "main_score": 0.029755704365079363,
        "precision": 0.02765531994047619,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00546875,
        "hf_subset": "mpp_Latn-eng_Latn",
        "languages": [
          "mpp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00546875,
        "precision": 0.0048828125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01513310185185185,
        "hf_subset": "eng_Latn-mps_Latn",
        "languages": [
          "eng-Latn",
          "mps-Latn"
        ],
        "main_score": 0.01513310185185185,
        "precision": 0.012406040497951572,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012260545665634675,
        "hf_subset": "mps_Latn-eng_Latn",
        "languages": [
          "mps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012260545665634675,
        "precision": 0.010702363142730497,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011717976485148515,
        "hf_subset": "eng_Latn-mpt_Latn",
        "languages": [
          "eng-Latn",
          "mpt-Latn"
        ],
        "main_score": 0.011717976485148515,
        "precision": 0.008990885416666667,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003893849206349206,
        "hf_subset": "mpt_Latn-eng_Latn",
        "languages": [
          "mpt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003893849206349206,
        "precision": 0.0026709618506493508,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0196206788003663,
        "hf_subset": "eng_Latn-mpx_Latn",
        "languages": [
          "eng-Latn",
          "mpx-Latn"
        ],
        "main_score": 0.0196206788003663,
        "precision": 0.017872643849206348,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.02072786266568483,
        "hf_subset": "mpx_Latn-eng_Latn",
        "languages": [
          "mpx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02072786266568483,
        "precision": 0.020222981770833336,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.023771255352437418,
        "hf_subset": "eng_Latn-mqb_Latn",
        "languages": [
          "eng-Latn",
          "mqb-Latn"
        ],
        "main_score": 0.023771255352437418,
        "precision": 0.01961822710803689,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.022197420634920632,
        "hf_subset": "mqb_Latn-eng_Latn",
        "languages": [
          "mqb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022197420634920632,
        "precision": 0.021515625,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.018584280303030304,
        "hf_subset": "eng_Latn-mqj_Latn",
        "languages": [
          "eng-Latn",
          "mqj-Latn"
        ],
        "main_score": 0.018584280303030304,
        "precision": 0.013868166510025062,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.013020833333333332,
        "hf_subset": "mqj_Latn-eng_Latn",
        "languages": [
          "mqj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013020833333333332,
        "precision": 0.0125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.09099513767482517,
        "hf_subset": "eng_Latn-msb_Latn",
        "languages": [
          "eng-Latn",
          "msb-Latn"
        ],
        "main_score": 0.09099513767482517,
        "precision": 0.08022242514430014,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.08778401519189764,
        "hf_subset": "msb_Latn-eng_Latn",
        "languages": [
          "msb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08778401519189764,
        "precision": 0.07991695804195804,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.09375,
        "f1": 0.06867350633435192,
        "hf_subset": "eng_Latn-msc_Latn",
        "languages": [
          "eng-Latn",
          "msc-Latn"
        ],
        "main_score": 0.06867350633435192,
        "precision": 0.06310972556089743,
        "recall": 0.09375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.026541355056980055,
        "hf_subset": "msc_Latn-eng_Latn",
        "languages": [
          "msc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026541355056980055,
        "precision": 0.022936698717948716,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.029095323229213318,
        "hf_subset": "eng_Latn-msk_Latn",
        "languages": [
          "eng-Latn",
          "msk-Latn"
        ],
        "main_score": 0.029095323229213318,
        "precision": 0.025960387551759834,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03956910767372724,
        "hf_subset": "msk_Latn-eng_Latn",
        "languages": [
          "msk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03956910767372724,
        "precision": 0.03810073390151515,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.039257812499999996,
        "hf_subset": "eng_Latn-msm_Latn",
        "languages": [
          "eng-Latn",
          "msm-Latn"
        ],
        "main_score": 0.039257812499999996,
        "precision": 0.03324032738095238,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.031055964052287582,
        "hf_subset": "msm_Latn-eng_Latn",
        "languages": [
          "msm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.031055964052287582,
        "precision": 0.02793067226890756,
        "recall": 0.046875
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.047106322496947496,
        "hf_subset": "eng_Latn-msy_Latn",
        "languages": [
          "eng-Latn",
          "msy-Latn"
        ],
        "main_score": 0.047106322496947496,
        "precision": 0.04304236778846153,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02560042878956125,
        "hf_subset": "msy_Latn-eng_Latn",
        "languages": [
          "msy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02560042878956125,
        "precision": 0.022411616161616164,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.024191841976516634,
        "hf_subset": "eng_Latn-mti_Latn",
        "languages": [
          "eng-Latn",
          "mti-Latn"
        ],
        "main_score": 0.024191841976516634,
        "precision": 0.020884627525252525,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017876101762820513,
        "hf_subset": "mti_Latn-eng_Latn",
        "languages": [
          "mti-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017876101762820513,
        "precision": 0.016964775219298244,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01875,
        "hf_subset": "eng_Latn-mto_Latn",
        "languages": [
          "eng-Latn",
          "mto-Latn"
        ],
        "main_score": 0.01875,
        "precision": 0.015234375000000001,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014377578059732665,
        "hf_subset": "mto_Latn-eng_Latn",
        "languages": [
          "mto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014377578059732665,
        "precision": 0.011875354402321197,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003426535087719298,
        "hf_subset": "eng_Latn-mux_Latn",
        "languages": [
          "eng-Latn",
          "mux-Latn"
        ],
        "main_score": 0.003426535087719298,
        "precision": 0.002387152777777778,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005260942760942761,
        "hf_subset": "mux_Latn-eng_Latn",
        "languages": [
          "mux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005260942760942761,
        "precision": 0.0002723106971153846,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010327210455173817,
        "hf_subset": "eng_Latn-muy_Latn",
        "languages": [
          "eng-Latn",
          "muy-Latn"
        ],
        "main_score": 0.010327210455173817,
        "precision": 0.007239074213093109,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006032986111111111,
        "hf_subset": "muy_Latn-eng_Latn",
        "languages": [
          "muy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006032986111111111,
        "precision": 0.005297111742424242,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011840022467320261,
        "hf_subset": "eng_Latn-mva_Latn",
        "languages": [
          "eng-Latn",
          "mva-Latn"
        ],
        "main_score": 0.011840022467320261,
        "precision": 0.009107396509740259,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013054978875291372,
        "hf_subset": "mva_Latn-eng_Latn",
        "languages": [
          "mva-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013054978875291372,
        "precision": 0.01243546195652174,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01737387663398693,
        "hf_subset": "eng_Latn-mvn_Latn",
        "languages": [
          "eng-Latn",
          "mvn-Latn"
        ],
        "main_score": 0.01737387663398693,
        "precision": 0.015414891098484849,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0087890625,
        "hf_subset": "mvn_Latn-eng_Latn",
        "languages": [
          "mvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0087890625,
        "precision": 0.008370535714285714,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.28515625,
        "f1": 0.22171299201875708,
        "hf_subset": "eng_Latn-mwc_Latn",
        "languages": [
          "eng-Latn",
          "mwc-Latn"
        ],
        "main_score": 0.22171299201875708,
        "precision": 0.2029110863095238,
        "recall": 0.28515625
      },
      {
        "accuracy": 0.25,
        "f1": 0.19532283399470898,
        "hf_subset": "mwc_Latn-eng_Latn",
        "languages": [
          "mwc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.19532283399470898,
        "precision": 0.17992120726495725,
        "recall": 0.25
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017144097222222224,
        "hf_subset": "eng_Latn-mwe_Latn",
        "languages": [
          "eng-Latn",
          "mwe-Latn"
        ],
        "main_score": 0.017144097222222224,
        "precision": 0.015462239583333332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004293272397891963,
        "hf_subset": "mwe_Latn-eng_Latn",
        "languages": [
          "mwe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004293272397891963,
        "precision": 0.004107625415742794,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.10961884959846915,
        "hf_subset": "eng_Latn-mwf_Latn",
        "languages": [
          "eng-Latn",
          "mwf-Latn"
        ],
        "main_score": 0.10961884959846915,
        "precision": 0.09893761837121212,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.10127728174603173,
        "hf_subset": "mwf_Latn-eng_Latn",
        "languages": [
          "mwf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.10127728174603173,
        "precision": 0.09242983217592593,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017018378831417623,
        "hf_subset": "eng_Latn-mwp_Latn",
        "languages": [
          "eng-Latn",
          "mwp-Latn"
        ],
        "main_score": 0.017018378831417623,
        "precision": 0.01418781328320802,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004774305555555556,
        "hf_subset": "mwp_Latn-eng_Latn",
        "languages": [
          "mwp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004774305555555556,
        "precision": 0.00439453125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04700520833333333,
        "hf_subset": "eng_Latn-mxb_Latn",
        "languages": [
          "eng-Latn",
          "mxb-Latn"
        ],
        "main_score": 0.04700520833333333,
        "precision": 0.041449652777777776,
        "recall": 0.0625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017680431547619047,
        "hf_subset": "mxb_Latn-eng_Latn",
        "languages": [
          "mxb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017680431547619047,
        "precision": 0.016025641025641024,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.040824142156862746,
        "hf_subset": "eng_Latn-mxp_Latn",
        "languages": [
          "eng-Latn",
          "mxp-Latn"
        ],
        "main_score": 0.040824142156862746,
        "precision": 0.038004557291666664,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.027655098497732428,
        "hf_subset": "mxp_Latn-eng_Latn",
        "languages": [
          "mxp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027655098497732428,
        "precision": 0.02516508556547619,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014906517094017092,
        "hf_subset": "eng_Latn-mxq_Latn",
        "languages": [
          "eng-Latn",
          "mxq-Latn"
        ],
        "main_score": 0.014906517094017092,
        "precision": 0.011635708971088435,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0070030275041050895,
        "hf_subset": "mxq_Latn-eng_Latn",
        "languages": [
          "mxq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0070030275041050895,
        "precision": 0.004810071475368788,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023524305555555555,
        "hf_subset": "eng_Latn-mxt_Latn",
        "languages": [
          "eng-Latn",
          "mxt-Latn"
        ],
        "main_score": 0.023524305555555555,
        "precision": 0.019773065476190475,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019351803221288516,
        "hf_subset": "mxt_Latn-eng_Latn",
        "languages": [
          "mxt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019351803221288516,
        "precision": 0.018170826569264067,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-mya_Latn",
        "languages": [
          "eng-Latn",
          "mya-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mya_Latn-eng_Latn",
        "languages": [
          "mya-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005303607723577236,
        "hf_subset": "eng_Latn-myk_Latn",
        "languages": [
          "eng-Latn",
          "myk-Latn"
        ],
        "main_score": 0.005303607723577236,
        "precision": 0.004735725308641975,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008072916666666666,
        "hf_subset": "myk_Latn-eng_Latn",
        "languages": [
          "myk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008072916666666666,
        "precision": 0.0068359375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02200653698979592,
        "hf_subset": "eng_Latn-myu_Latn",
        "languages": [
          "eng-Latn",
          "myu-Latn"
        ],
        "main_score": 0.02200653698979592,
        "precision": 0.020905174469627592,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03338618469392926,
        "hf_subset": "myu_Latn-eng_Latn",
        "languages": [
          "myu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03338618469392926,
        "precision": 0.031093838850062366,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0033313041125541125,
        "hf_subset": "eng_Latn-myw_Latn",
        "languages": [
          "eng-Latn",
          "myw-Latn"
        ],
        "main_score": 0.0033313041125541125,
        "precision": 0.002334449404761905,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017783717105263157,
        "hf_subset": "myw_Latn-eng_Latn",
        "languages": [
          "myw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017783717105263157,
        "precision": 0.017032657657657657,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011830357142857142,
        "hf_subset": "eng_Latn-myy_Latn",
        "languages": [
          "eng-Latn",
          "myy-Latn"
        ],
        "main_score": 0.011830357142857142,
        "precision": 0.010473278985507246,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "myy_Latn-eng_Latn",
        "languages": [
          "myy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.088,
        "f1": 0.04964444444444444,
        "hf_subset": "eng_Latn-mzz_Latn",
        "languages": [
          "eng-Latn",
          "mzz-Latn"
        ],
        "main_score": 0.04964444444444444,
        "precision": 0.04067619047619048,
        "recall": 0.088
      },
      {
        "accuracy": 0.04,
        "f1": 0.02603174603174603,
        "hf_subset": "mzz_Latn-eng_Latn",
        "languages": [
          "mzz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02603174603174603,
        "precision": 0.025129032258064517,
        "recall": 0.04
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004368072660098522,
        "hf_subset": "eng_Latn-nab_Latn",
        "languages": [
          "eng-Latn",
          "nab-Latn"
        ],
        "main_score": 0.004368072660098522,
        "precision": 0.0029500689475253426,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00010279605263157894,
        "hf_subset": "nab_Latn-eng_Latn",
        "languages": [
          "nab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00010279605263157894,
        "precision": 5.208333333333334e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011555989583333332,
        "hf_subset": "eng_Latn-naf_Latn",
        "languages": [
          "eng-Latn",
          "naf-Latn"
        ],
        "main_score": 0.011555989583333332,
        "precision": 0.010156249999999999,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00546875,
        "hf_subset": "naf_Latn-eng_Latn",
        "languages": [
          "naf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00546875,
        "precision": 0.0048828125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006307555857487923,
        "hf_subset": "eng_Latn-nak_Latn",
        "languages": [
          "eng-Latn",
          "nak-Latn"
        ],
        "main_score": 0.006307555857487923,
        "precision": 0.005264673186468264,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003969766260162602,
        "hf_subset": "nak_Latn-eng_Latn",
        "languages": [
          "nak-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003969766260162602,
        "precision": 0.00393826844262295,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006213299675470728,
        "hf_subset": "eng_Latn-nas_Latn",
        "languages": [
          "eng-Latn",
          "nas-Latn"
        ],
        "main_score": 0.006213299675470728,
        "precision": 0.004044376407657657,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001767113095238095,
        "hf_subset": "nas_Latn-eng_Latn",
        "languages": [
          "nas-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001767113095238095,
        "precision": 0.001006155303030303,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.032155539772727275,
        "hf_subset": "eng_Latn-nbq_Latn",
        "languages": [
          "eng-Latn",
          "nbq-Latn"
        ],
        "main_score": 0.032155539772727275,
        "precision": 0.02777157738095238,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019087683150183152,
        "hf_subset": "nbq_Latn-eng_Latn",
        "languages": [
          "nbq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019087683150183152,
        "precision": 0.01803485576923077,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022043404476516634,
        "hf_subset": "eng_Latn-nca_Latn",
        "languages": [
          "eng-Latn",
          "nca-Latn"
        ],
        "main_score": 0.022043404476516634,
        "precision": 0.01953532920843776,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005834115561118064,
        "hf_subset": "nca_Latn-eng_Latn",
        "languages": [
          "nca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005834115561118064,
        "precision": 0.00501655910326087,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014954880189255188,
        "hf_subset": "eng_Latn-nch_Latn",
        "languages": [
          "eng-Latn",
          "nch-Latn"
        ],
        "main_score": 0.014954880189255188,
        "precision": 0.012532552083333332,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01294642857142857,
        "hf_subset": "nch_Latn-eng_Latn",
        "languages": [
          "nch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01294642857142857,
        "precision": 0.011368574828840395,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011700077449458043,
        "hf_subset": "eng_Latn-ncj_Latn",
        "languages": [
          "eng-Latn",
          "ncj-Latn"
        ],
        "main_score": 0.011700077449458043,
        "precision": 0.009277259199134198,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.02837484780844156,
        "hf_subset": "ncj_Latn-eng_Latn",
        "languages": [
          "ncj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02837484780844156,
        "precision": 0.02329072043725245,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011496812810945273,
        "hf_subset": "eng_Latn-ncl_Latn",
        "languages": [
          "eng-Latn",
          "ncl-Latn"
        ],
        "main_score": 0.011496812810945273,
        "precision": 0.009336529356060606,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011653645833333334,
        "hf_subset": "ncl_Latn-eng_Latn",
        "languages": [
          "ncl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011653645833333334,
        "precision": 0.010091145833333332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012239583333333333,
        "hf_subset": "eng_Latn-ncu_Latn",
        "languages": [
          "eng-Latn",
          "ncu-Latn"
        ],
        "main_score": 0.012239583333333333,
        "precision": 0.008297821969696969,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007437206329463791,
        "hf_subset": "ncu_Latn-eng_Latn",
        "languages": [
          "ncu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007437206329463791,
        "precision": 0.006068800990675991,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02045583858543417,
        "hf_subset": "eng_Latn-ndg_Latn",
        "languages": [
          "eng-Latn",
          "ndg-Latn"
        ],
        "main_score": 0.02045583858543417,
        "precision": 0.014835365372474749,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013990593905472637,
        "hf_subset": "ndg_Latn-eng_Latn",
        "languages": [
          "ndg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013990593905472637,
        "precision": 0.012073641134085213,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012890625,
        "hf_subset": "eng_Latn-ndj_Latn",
        "languages": [
          "eng-Latn",
          "ndj-Latn"
        ],
        "main_score": 0.012890625,
        "precision": 0.0110562865497076,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "ndj_Latn-eng_Latn",
        "languages": [
          "ndj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022921519151138714,
        "hf_subset": "eng_Latn-nfa_Latn",
        "languages": [
          "eng-Latn",
          "nfa-Latn"
        ],
        "main_score": 0.022921519151138714,
        "precision": 0.020088859346671845,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.020221159825870645,
        "hf_subset": "nfa_Latn-eng_Latn",
        "languages": [
          "nfa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020221159825870645,
        "precision": 0.018899739583333332,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0067708333333333336,
        "hf_subset": "eng_Latn-ngp_Latn",
        "languages": [
          "eng-Latn",
          "ngp-Latn"
        ],
        "main_score": 0.0067708333333333336,
        "precision": 0.0048828125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.351626016260163e-05,
        "hf_subset": "ngp_Latn-eng_Latn",
        "languages": [
          "ngp-Latn",
          "eng-Latn"
        ],
        "main_score": 6.351626016260163e-05,
        "precision": 3.201844262295082e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02378855187908497,
        "hf_subset": "eng_Latn-ngu_Latn",
        "languages": [
          "eng-Latn",
          "ngu-Latn"
        ],
        "main_score": 0.02378855187908497,
        "precision": 0.020951915922619045,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0214889118757259,
        "hf_subset": "ngu_Latn-eng_Latn",
        "languages": [
          "ngu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0214889118757259,
        "precision": 0.019628906250000005,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020769751082251084,
        "hf_subset": "eng_Latn-nhe_Latn",
        "languages": [
          "eng-Latn",
          "nhe-Latn"
        ],
        "main_score": 0.020769751082251084,
        "precision": 0.01823901816824291,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017492559523809525,
        "hf_subset": "nhe_Latn-eng_Latn",
        "languages": [
          "nhe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017492559523809525,
        "precision": 0.015636027929017946,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03446749012481771,
        "hf_subset": "eng_Latn-nhg_Latn",
        "languages": [
          "eng-Latn",
          "nhg-Latn"
        ],
        "main_score": 0.03446749012481771,
        "precision": 0.02847842261904762,
        "recall": 0.0625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017469618055555556,
        "hf_subset": "nhg_Latn-eng_Latn",
        "languages": [
          "nhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017469618055555556,
        "precision": 0.01564360119047619,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.043089657738095234,
        "hf_subset": "eng_Latn-nhi_Latn",
        "languages": [
          "eng-Latn",
          "nhi-Latn"
        ],
        "main_score": 0.043089657738095234,
        "precision": 0.03695317970938375,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.025613839285714285,
        "hf_subset": "nhi_Latn-eng_Latn",
        "languages": [
          "nhi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025613839285714285,
        "precision": 0.02111270753512133,
        "recall": 0.046875
      },
      {
        "accuracy": 0.09375,
        "f1": 0.0672009909733124,
        "hf_subset": "eng_Latn-nho_Latn",
        "languages": [
          "eng-Latn",
          "nho-Latn"
        ],
        "main_score": 0.0672009909733124,
        "precision": 0.06091471354166667,
        "recall": 0.09375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.057957323554421764,
        "hf_subset": "nho_Latn-eng_Latn",
        "languages": [
          "nho-Latn",
          "eng-Latn"
        ],
        "main_score": 0.057957323554421764,
        "precision": 0.052486327166175746,
        "recall": 0.078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.027805679563492062,
        "hf_subset": "eng_Latn-nhr_Latn",
        "languages": [
          "eng-Latn",
          "nhr-Latn"
        ],
        "main_score": 0.027805679563492062,
        "precision": 0.022792232789855073,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00946401247645951,
        "hf_subset": "nhr_Latn-eng_Latn",
        "languages": [
          "nhr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00946401247645951,
        "precision": 0.00872324402429467,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0018936011904761906,
        "hf_subset": "eng_Latn-nhu_Latn",
        "languages": [
          "eng-Latn",
          "nhu-Latn"
        ],
        "main_score": 0.0018936011904761906,
        "precision": 0.0010886863425925927,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.014322916666666666,
        "hf_subset": "nhu_Latn-eng_Latn",
        "languages": [
          "nhu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014322916666666666,
        "precision": 0.013671875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008610262286732874,
        "hf_subset": "eng_Latn-nhw_Latn",
        "languages": [
          "eng-Latn",
          "nhw-Latn"
        ],
        "main_score": 0.008610262286732874,
        "precision": 0.006624348958333333,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010922739541160593,
        "hf_subset": "nhw_Latn-eng_Latn",
        "languages": [
          "nhw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010922739541160593,
        "precision": 0.010027449324324325,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03624131944444444,
        "hf_subset": "eng_Latn-nhy_Latn",
        "languages": [
          "eng-Latn",
          "nhy-Latn"
        ],
        "main_score": 0.03624131944444444,
        "precision": 0.031834893048128345,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.030989583333333327,
        "hf_subset": "nhy_Latn-eng_Latn",
        "languages": [
          "nhy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030989583333333327,
        "precision": 0.028851425438596492,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.036012102122015915,
        "hf_subset": "eng_Latn-nif_Latn",
        "languages": [
          "eng-Latn",
          "nif-Latn"
        ],
        "main_score": 0.036012102122015915,
        "precision": 0.03307852372408293,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02825520833333333,
        "hf_subset": "nif_Latn-eng_Latn",
        "languages": [
          "nif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02825520833333333,
        "precision": 0.025716145833333332,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005147058823529412,
        "hf_subset": "eng_Latn-nii_Latn",
        "languages": [
          "eng-Latn",
          "nii-Latn"
        ],
        "main_score": 0.005147058823529412,
        "precision": 0.003452845982142857,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.25e-05,
        "hf_subset": "nii_Latn-eng_Latn",
        "languages": [
          "nii-Latn",
          "eng-Latn"
        ],
        "main_score": 6.25e-05,
        "precision": 3.150201612903226e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012311853532396564,
        "hf_subset": "eng_Latn-nin_Latn",
        "languages": [
          "eng-Latn",
          "nin-Latn"
        ],
        "main_score": 0.012311853532396564,
        "precision": 0.009534801136363636,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0048828125,
        "hf_subset": "nin_Latn-eng_Latn",
        "languages": [
          "nin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0048828125,
        "precision": 0.004464285714285714,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03620294408396451,
        "hf_subset": "eng_Latn-nko_Latn",
        "languages": [
          "eng-Latn",
          "nko-Latn"
        ],
        "main_score": 0.03620294408396451,
        "precision": 0.03346616743237383,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03502604166666666,
        "hf_subset": "nko_Latn-eng_Latn",
        "languages": [
          "nko-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03502604166666666,
        "precision": 0.031208512050653593,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.2890625,
        "f1": 0.21763063325563323,
        "hf_subset": "eng_Latn-nld_Latn",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ],
        "main_score": 0.21763063325563323,
        "precision": 0.19734002976190476,
        "recall": 0.2890625
      },
      {
        "accuracy": 0.3671875,
        "f1": 0.30288890796703294,
        "hf_subset": "nld_Latn-eng_Latn",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.30288890796703294,
        "precision": 0.28071919211525187,
        "recall": 0.3671875
      },
      {
        "accuracy": 0.140625,
        "f1": 0.0959851296336624,
        "hf_subset": "eng_Latn-nlg_Latn",
        "languages": [
          "eng-Latn",
          "nlg-Latn"
        ],
        "main_score": 0.0959851296336624,
        "precision": 0.08540092719780218,
        "recall": 0.140625
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07468950320512821,
        "hf_subset": "nlg_Latn-eng_Latn",
        "languages": [
          "nlg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07468950320512821,
        "precision": 0.06804653679653679,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.22265625,
        "f1": 0.1717796233076564,
        "hf_subset": "eng_Latn-nna_Latn",
        "languages": [
          "eng-Latn",
          "nna-Latn"
        ],
        "main_score": 0.1717796233076564,
        "precision": 0.1571498325892857,
        "recall": 0.22265625
      },
      {
        "accuracy": 0.20703125,
        "f1": 0.16345288103100603,
        "hf_subset": "nna_Latn-eng_Latn",
        "languages": [
          "nna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.16345288103100603,
        "precision": 0.15380780055542284,
        "recall": 0.20703125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007068452380952381,
        "hf_subset": "eng_Latn-nnq_Latn",
        "languages": [
          "eng-Latn",
          "nnq-Latn"
        ],
        "main_score": 0.007068452380952381,
        "precision": 0.006159855769230769,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005267518939393939,
        "hf_subset": "nnq_Latn-eng_Latn",
        "languages": [
          "nnq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005267518939393939,
        "precision": 0.0036458333333333334,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02118884339502546,
        "hf_subset": "eng_Latn-noa_Latn",
        "languages": [
          "eng-Latn",
          "noa-Latn"
        ],
        "main_score": 0.02118884339502546,
        "precision": 0.01679462031024531,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019171626984126985,
        "hf_subset": "noa_Latn-eng_Latn",
        "languages": [
          "noa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019171626984126985,
        "precision": 0.016273082386363637,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01398333077605019,
        "hf_subset": "eng_Latn-nop_Latn",
        "languages": [
          "eng-Latn",
          "nop-Latn"
        ],
        "main_score": 0.01398333077605019,
        "precision": 0.01222934956800446,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004774305555555556,
        "hf_subset": "nop_Latn-eng_Latn",
        "languages": [
          "nop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004774305555555556,
        "precision": 0.00439453125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015835336538461538,
        "hf_subset": "eng_Latn-not_Latn",
        "languages": [
          "eng-Latn",
          "not-Latn"
        ],
        "main_score": 0.015835336538461538,
        "precision": 0.013151041666666665,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "not_Latn-eng_Latn",
        "languages": [
          "not-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.060290287990196076,
        "hf_subset": "eng_Latn-nou_Latn",
        "languages": [
          "eng-Latn",
          "nou-Latn"
        ],
        "main_score": 0.060290287990196076,
        "precision": 0.05399228050595238,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.056830018939393934,
        "hf_subset": "nou_Latn-eng_Latn",
        "languages": [
          "nou-Latn",
          "eng-Latn"
        ],
        "main_score": 0.056830018939393934,
        "precision": 0.05125558035714285,
        "recall": 0.078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01188497340425532,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.01188497340425532,
        "precision": 0.010631793478260869,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0030329831332189822,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0030329831332189822,
        "precision": 0.002176339285714286,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.03539186507936508,
        "hf_subset": "eng_Latn-npl_Latn",
        "languages": [
          "eng-Latn",
          "npl-Latn"
        ],
        "main_score": 0.03539186507936508,
        "precision": 0.027754526289682536,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013758680555555555,
        "hf_subset": "npl_Latn-eng_Latn",
        "languages": [
          "npl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013758680555555555,
        "precision": 0.010647060359231412,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.027793560606060606,
        "hf_subset": "eng_Latn-nsn_Latn",
        "languages": [
          "eng-Latn",
          "nsn-Latn"
        ],
        "main_score": 0.027793560606060606,
        "precision": 0.02523871527777778,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024830838303245218,
        "hf_subset": "nsn_Latn-eng_Latn",
        "languages": [
          "nsn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024830838303245218,
        "precision": 0.02317349418632187,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.027934745718462824,
        "hf_subset": "eng_Latn-nss_Latn",
        "languages": [
          "eng-Latn",
          "nss-Latn"
        ],
        "main_score": 0.027934745718462824,
        "precision": 0.023761750685154216,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03184561965811966,
        "hf_subset": "nss_Latn-eng_Latn",
        "languages": [
          "nss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03184561965811966,
        "precision": 0.028157946654040405,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0035190879875886525,
        "hf_subset": "eng_Latn-ntj_Latn",
        "languages": [
          "eng-Latn",
          "ntj-Latn"
        ],
        "main_score": 0.0035190879875886525,
        "precision": 0.0021031476449275364,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.7063253012048195e-05,
        "hf_subset": "ntj_Latn-eng_Latn",
        "languages": [
          "ntj-Latn",
          "eng-Latn"
        ],
        "main_score": 4.7063253012048195e-05,
        "precision": 2.3674242424242424e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.017578125,
        "hf_subset": "eng_Latn-ntp_Latn",
        "languages": [
          "eng-Latn",
          "ntp-Latn"
        ],
        "main_score": 0.017578125,
        "precision": 0.016927083333333332,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004266624579124578,
        "hf_subset": "ntp_Latn-eng_Latn",
        "languages": [
          "ntp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004266624579124578,
        "precision": 0.0040923275405786875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012586805555555556,
        "hf_subset": "eng_Latn-ntu_Latn",
        "languages": [
          "eng-Latn",
          "ntu-Latn"
        ],
        "main_score": 0.012586805555555556,
        "precision": 0.01078501918859649,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01607666015625,
        "hf_subset": "ntu_Latn-eng_Latn",
        "languages": [
          "ntu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01607666015625,
        "precision": 0.015861349979278905,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03704133821321321,
        "hf_subset": "eng_Latn-nuy_Latn",
        "languages": [
          "eng-Latn",
          "nuy-Latn"
        ],
        "main_score": 0.03704133821321321,
        "precision": 0.032898562357305934,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.032744859307359306,
        "hf_subset": "nuy_Latn-eng_Latn",
        "languages": [
          "nuy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.032744859307359306,
        "precision": 0.03017578125,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008610102694924123,
        "hf_subset": "eng_Latn-nvm_Latn",
        "languages": [
          "eng-Latn",
          "nvm-Latn"
        ],
        "main_score": 0.008610102694924123,
        "precision": 0.007000784588675213,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009375,
        "hf_subset": "nvm_Latn-eng_Latn",
        "languages": [
          "nvm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009375,
        "precision": 0.0087890625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.026562499999999996,
        "hf_subset": "eng_Latn-nwi_Latn",
        "languages": [
          "eng-Latn",
          "nwi-Latn"
        ],
        "main_score": 0.026562499999999996,
        "precision": 0.023141571969696968,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013516813236582258,
        "hf_subset": "nwi_Latn-eng_Latn",
        "languages": [
          "nwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013516813236582258,
        "precision": 0.01269656761506065,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0192775974025974,
        "hf_subset": "eng_Latn-nya_Latn",
        "languages": [
          "eng-Latn",
          "nya-Latn"
        ],
        "main_score": 0.0192775974025974,
        "precision": 0.01698717948717949,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.5687134502923974e-05,
        "hf_subset": "nya_Latn-eng_Latn",
        "languages": [
          "nya-Latn",
          "eng-Latn"
        ],
        "main_score": 4.5687134502923974e-05,
        "precision": 2.2977941176470588e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.16393442622950818,
        "f1": 0.10124012216333181,
        "hf_subset": "eng_Latn-nys_Latn",
        "languages": [
          "eng-Latn",
          "nys-Latn"
        ],
        "main_score": 0.10124012216333181,
        "precision": 0.08508652094717668,
        "recall": 0.16393442622950818
      },
      {
        "accuracy": 0.1557377049180328,
        "f1": 0.11592256714335543,
        "hf_subset": "nys_Latn-eng_Latn",
        "languages": [
          "nys-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11592256714335543,
        "precision": 0.10673556664290805,
        "recall": 0.1557377049180328
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.032885701699834166,
        "hf_subset": "eng_Latn-nyu_Latn",
        "languages": [
          "eng-Latn",
          "nyu-Latn"
        ],
        "main_score": 0.032885701699834166,
        "precision": 0.02738066312799043,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.027834007841089414,
        "hf_subset": "nyu_Latn-eng_Latn",
        "languages": [
          "nyu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027834007841089414,
        "precision": 0.026292445760006902,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03708530287114846,
        "hf_subset": "eng_Latn-obo_Latn",
        "languages": [
          "eng-Latn",
          "obo-Latn"
        ],
        "main_score": 0.03708530287114846,
        "precision": 0.03265125516616059,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.0254915836352657,
        "hf_subset": "obo_Latn-eng_Latn",
        "languages": [
          "obo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0254915836352657,
        "precision": 0.02310130002470356,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.10955950877825876,
        "hf_subset": "eng_Latn-okv_Latn",
        "languages": [
          "eng-Latn",
          "okv-Latn"
        ],
        "main_score": 0.10955950877825876,
        "precision": 0.09476044788544788,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.18359375,
        "f1": 0.1285282782984989,
        "hf_subset": "okv_Latn-eng_Latn",
        "languages": [
          "okv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1285282782984989,
        "precision": 0.11449675279217869,
        "recall": 0.18359375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0009474734042553192,
        "hf_subset": "eng_Latn-omw_Latn",
        "languages": [
          "eng-Latn",
          "omw-Latn"
        ],
        "main_score": 0.0009474734042553192,
        "precision": 0.0005189462560386473,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "omw_Latn-eng_Latn",
        "languages": [
          "omw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019794766865079368,
        "hf_subset": "eng_Latn-ong_Latn",
        "languages": [
          "eng-Latn",
          "ong-Latn"
        ],
        "main_score": 0.019794766865079368,
        "precision": 0.017403839932712217,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018330627705627704,
        "hf_subset": "ong_Latn-eng_Latn",
        "languages": [
          "ong-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018330627705627704,
        "precision": 0.01762952302631579,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024929315476190476,
        "hf_subset": "eng_Latn-ons_Latn",
        "languages": [
          "eng-Latn",
          "ons-Latn"
        ],
        "main_score": 0.024929315476190476,
        "precision": 0.022027335573652537,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.038876488095238096,
        "hf_subset": "ons_Latn-eng_Latn",
        "languages": [
          "ons-Latn",
          "eng-Latn"
        ],
        "main_score": 0.038876488095238096,
        "precision": 0.03485030936716792,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.04839892988445378,
        "hf_subset": "eng_Latn-ood_Latn",
        "languages": [
          "eng-Latn",
          "ood-Latn"
        ],
        "main_score": 0.04839892988445378,
        "precision": 0.04351998378642502,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03555186170212766,
        "hf_subset": "ood_Latn-eng_Latn",
        "languages": [
          "ood-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03555186170212766,
        "precision": 0.03536101310483871,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007998511904761904,
        "hf_subset": "eng_Latn-opm_Latn",
        "languages": [
          "eng-Latn",
          "opm-Latn"
        ],
        "main_score": 0.007998511904761904,
        "precision": 0.006223789231601732,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003125,
        "hf_subset": "opm_Latn-eng_Latn",
        "languages": [
          "opm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003125,
        "precision": 0.00016276041666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002004187091503268,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.002004187091503268,
        "precision": 0.001327782346491228,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004307021103896104,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.004307021103896104,
        "precision": 0.002906750061055895,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02123081140350877,
        "hf_subset": "eng_Latn-ote_Latn",
        "languages": [
          "eng-Latn",
          "ote-Latn"
        ],
        "main_score": 0.02123081140350877,
        "precision": 0.01927548363095238,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01020923520923521,
        "hf_subset": "ote_Latn-eng_Latn",
        "languages": [
          "ote-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01020923520923521,
        "precision": 0.009242691532258065,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.025041852678571428,
        "hf_subset": "eng_Latn-otm_Latn",
        "languages": [
          "eng-Latn",
          "otm-Latn"
        ],
        "main_score": 0.025041852678571428,
        "precision": 0.02239583333333333,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019783266129032258,
        "hf_subset": "otm_Latn-eng_Latn",
        "languages": [
          "otm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019783266129032258,
        "precision": 0.017708333333333333,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04564462915100251,
        "hf_subset": "eng_Latn-otn_Latn",
        "languages": [
          "eng-Latn",
          "otn-Latn"
        ],
        "main_score": 0.04564462915100251,
        "precision": 0.04102389219576719,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03647671395633352,
        "hf_subset": "otn_Latn-eng_Latn",
        "languages": [
          "otn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03647671395633352,
        "precision": 0.03472890261242624,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007798126352813853,
        "hf_subset": "eng_Latn-otq_Latn",
        "languages": [
          "eng-Latn",
          "otq-Latn"
        ],
        "main_score": 0.007798126352813853,
        "precision": 0.006287561824246606,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004616477272727273,
        "hf_subset": "otq_Latn-eng_Latn",
        "languages": [
          "otq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004616477272727273,
        "precision": 0.004296875,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.05172991071428572,
        "hf_subset": "eng_Latn-ots_Latn",
        "languages": [
          "eng-Latn",
          "ots-Latn"
        ],
        "main_score": 0.05172991071428572,
        "precision": 0.04886929256301607,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02975679454474097,
        "hf_subset": "ots_Latn-eng_Latn",
        "languages": [
          "ots-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02975679454474097,
        "precision": 0.028883463541666668,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018303571428571426,
        "hf_subset": "eng_Latn-pab_Latn",
        "languages": [
          "eng-Latn",
          "pab-Latn"
        ],
        "main_score": 0.018303571428571426,
        "precision": 0.015299479166666668,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017852128623188405,
        "hf_subset": "pab_Latn-eng_Latn",
        "languages": [
          "pab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017852128623188405,
        "precision": 0.015894801051051052,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.038221246159754224,
        "hf_subset": "eng_Latn-pad_Latn",
        "languages": [
          "eng-Latn",
          "pad-Latn"
        ],
        "main_score": 0.038221246159754224,
        "precision": 0.03615034640905542,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012282731549364613,
        "hf_subset": "pad_Latn-eng_Latn",
        "languages": [
          "pad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012282731549364613,
        "precision": 0.010897067408501715,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03176942946990117,
        "hf_subset": "eng_Latn-pah_Latn",
        "languages": [
          "eng-Latn",
          "pah-Latn"
        ],
        "main_score": 0.03176942946990117,
        "precision": 0.030348557692307692,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020156337608634705,
        "hf_subset": "pah_Latn-eng_Latn",
        "languages": [
          "pah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020156337608634705,
        "precision": 0.018742421737213404,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009607514880952382,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.009607514880952382,
        "precision": 0.006522578983516483,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.02857840401785714,
        "hf_subset": "eng_Latn-pao_Latn",
        "languages": [
          "eng-Latn",
          "pao-Latn"
        ],
        "main_score": 0.02857840401785714,
        "precision": 0.02420811085755642,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03686899038461538,
        "hf_subset": "pao_Latn-eng_Latn",
        "languages": [
          "pao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03686899038461538,
        "precision": 0.0342562806372549,
        "recall": 0.046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0087890625,
        "hf_subset": "eng_Latn-pes_Arab",
        "languages": [
          "eng-Latn",
          "pes-Arab"
        ],
        "main_score": 0.0087890625,
        "precision": 0.00706845238095238,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0010427846388729328,
        "hf_subset": "pes_Arab-eng_Latn",
        "languages": [
          "pes-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0010427846388729328,
        "precision": 0.0005615234375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012625503836441334,
        "hf_subset": "eng_Latn-pib_Latn",
        "languages": [
          "eng-Latn",
          "pib-Latn"
        ],
        "main_score": 0.012625503836441334,
        "precision": 0.009973284841954023,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "pib_Latn-eng_Latn",
        "languages": [
          "pib-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021704382183908046,
        "hf_subset": "eng_Latn-pio_Latn",
        "languages": [
          "eng-Latn",
          "pio-Latn"
        ],
        "main_score": 0.021704382183908046,
        "precision": 0.01870861595607235,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010511465680512016,
        "hf_subset": "pio_Latn-eng_Latn",
        "languages": [
          "pio-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010511465680512016,
        "precision": 0.008261099965458518,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.019791666666666666,
        "hf_subset": "eng_Latn-pir_Latn",
        "languages": [
          "eng-Latn",
          "pir-Latn"
        ],
        "main_score": 0.019791666666666666,
        "precision": 0.0185546875,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016536458333333334,
        "hf_subset": "pir_Latn-eng_Latn",
        "languages": [
          "pir-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016536458333333334,
        "precision": 0.014710441468253968,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00013020833333333333,
        "hf_subset": "eng_Latn-piu_Latn",
        "languages": [
          "eng-Latn",
          "piu-Latn"
        ],
        "main_score": 0.00013020833333333333,
        "precision": 6.620762711864407e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0011955765168970814,
        "hf_subset": "piu_Latn-eng_Latn",
        "languages": [
          "piu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011955765168970814,
        "precision": 0.0006691358525436641,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014702380952380953,
        "hf_subset": "eng_Latn-pjt_Latn",
        "languages": [
          "eng-Latn",
          "pjt-Latn"
        ],
        "main_score": 0.014702380952380953,
        "precision": 0.013866484093637454,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010905905330882353,
        "hf_subset": "pjt_Latn-eng_Latn",
        "languages": [
          "pjt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010905905330882353,
        "precision": 0.00973292141443321,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.07761346726190477,
        "hf_subset": "eng_Latn-pls_Latn",
        "languages": [
          "eng-Latn",
          "pls-Latn"
        ],
        "main_score": 0.07761346726190477,
        "precision": 0.06593191964285713,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04470796130952381,
        "hf_subset": "pls_Latn-eng_Latn",
        "languages": [
          "pls-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04470796130952381,
        "precision": 0.04025681692211297,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017420014880952378,
        "hf_subset": "eng_Latn-plu_Latn",
        "languages": [
          "eng-Latn",
          "plu-Latn"
        ],
        "main_score": 0.017420014880952378,
        "precision": 0.015506953983516484,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "plu_Latn-eng_Latn",
        "languages": [
          "plu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03216145833333333,
        "hf_subset": "eng_Latn-pma_Latn",
        "languages": [
          "eng-Latn",
          "pma-Latn"
        ],
        "main_score": 0.03216145833333333,
        "precision": 0.029622395833333332,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014459978070175438,
        "hf_subset": "pma_Latn-eng_Latn",
        "languages": [
          "pma-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014459978070175438,
        "precision": 0.013741629464285714,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.05132966440886699,
        "hf_subset": "eng_Latn-poe_Latn",
        "languages": [
          "eng-Latn",
          "poe-Latn"
        ],
        "main_score": 0.05132966440886699,
        "precision": 0.04725388182419432,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02020596590909091,
        "hf_subset": "poe_Latn-eng_Latn",
        "languages": [
          "poe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02020596590909091,
        "precision": 0.018506580972906403,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007161458333333333,
        "hf_subset": "eng_Latn-poh_Latn",
        "languages": [
          "eng-Latn",
          "poh-Latn"
        ],
        "main_score": 0.007161458333333333,
        "precision": 0.005989583333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "poh_Latn-eng_Latn",
        "languages": [
          "poh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04904709690893901,
        "hf_subset": "eng_Latn-poi_Latn",
        "languages": [
          "eng-Latn",
          "poi-Latn"
        ],
        "main_score": 0.04904709690893901,
        "precision": 0.043899809587813615,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025979141656662666,
        "hf_subset": "poi_Latn-eng_Latn",
        "languages": [
          "poi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025979141656662666,
        "precision": 0.023871026089937172,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.06847507390270548,
        "hf_subset": "eng_Latn-pol_Latn",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ],
        "main_score": 0.06847507390270548,
        "precision": 0.06163659474206349,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.043652766504329005,
        "hf_subset": "pol_Latn-eng_Latn",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.043652766504329005,
        "precision": 0.03751890624432458,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.014811400103519667,
        "hf_subset": "eng_Latn-pon_Latn",
        "languages": [
          "eng-Latn",
          "pon-Latn"
        ],
        "main_score": 0.014811400103519667,
        "precision": 0.012218954899875952,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006810242635189669,
        "hf_subset": "pon_Latn-eng_Latn",
        "languages": [
          "pon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006810242635189669,
        "precision": 0.004599600740495136,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.6875,
        "f1": 0.6112723214285715,
        "hf_subset": "eng_Latn-por_Latn",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ],
        "main_score": 0.6112723214285715,
        "precision": 0.5807725694444444,
        "recall": 0.6875
      },
      {
        "accuracy": 0.7265625,
        "f1": 0.658984375,
        "hf_subset": "por_Latn-eng_Latn",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ],
        "main_score": 0.658984375,
        "precision": 0.6307942708333334,
        "recall": 0.7265625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012374571282906931,
        "hf_subset": "eng_Latn-poy_Latn",
        "languages": [
          "eng-Latn",
          "poy-Latn"
        ],
        "main_score": 0.012374571282906931,
        "precision": 0.01094573331381733,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.1062091503267975e-05,
        "hf_subset": "poy_Latn-eng_Latn",
        "languages": [
          "poy-Latn",
          "eng-Latn"
        ],
        "main_score": 5.1062091503267975e-05,
        "precision": 2.5699013157894735e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019725327994762155,
        "hf_subset": "eng_Latn-ppo_Latn",
        "languages": [
          "eng-Latn",
          "ppo-Latn"
        ],
        "main_score": 0.019725327994762155,
        "precision": 0.018424479166666667,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008463541666666666,
        "hf_subset": "ppo_Latn-eng_Latn",
        "languages": [
          "ppo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008463541666666666,
        "precision": 0.007161458333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.032421875,
        "hf_subset": "eng_Latn-prf_Latn",
        "languages": [
          "eng-Latn",
          "prf-Latn"
        ],
        "main_score": 0.032421875,
        "precision": 0.028255208333333334,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.028878348214285712,
        "hf_subset": "prf_Latn-eng_Latn",
        "languages": [
          "prf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028878348214285712,
        "precision": 0.026900183150183152,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.028266175656309032,
        "hf_subset": "eng_Latn-pri_Latn",
        "languages": [
          "eng-Latn",
          "pri-Latn"
        ],
        "main_score": 0.028266175656309032,
        "precision": 0.02587603400735294,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.020399305555555556,
        "hf_subset": "pri_Latn-eng_Latn",
        "languages": [
          "pri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020399305555555556,
        "precision": 0.02001953125,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02612179487179487,
        "hf_subset": "eng_Latn-ptp_Latn",
        "languages": [
          "eng-Latn",
          "ptp-Latn"
        ],
        "main_score": 0.02612179487179487,
        "precision": 0.023676215277777773,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "ptp_Latn-eng_Latn",
        "languages": [
          "ptp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.026344343932748537,
        "hf_subset": "eng_Latn-ptu_Latn",
        "languages": [
          "eng-Latn",
          "ptu-Latn"
        ],
        "main_score": 0.026344343932748537,
        "precision": 0.022631448412698412,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02173859126984127,
        "hf_subset": "ptu_Latn-eng_Latn",
        "languages": [
          "ptu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02173859126984127,
        "precision": 0.019265944558913308,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.022831637311744472,
        "hf_subset": "eng_Latn-pwg_Latn",
        "languages": [
          "eng-Latn",
          "pwg-Latn"
        ],
        "main_score": 0.022831637311744472,
        "precision": 0.019022578983516482,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.028317775974025974,
        "hf_subset": "pwg_Latn-eng_Latn",
        "languages": [
          "pwg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028317775974025974,
        "precision": 0.026380780677655678,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.026787982723577235,
        "hf_subset": "eng_Latn-qub_Latn",
        "languages": [
          "eng-Latn",
          "qub-Latn"
        ],
        "main_score": 0.026787982723577235,
        "precision": 0.02579396394500561,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009921261223344555,
        "hf_subset": "qub_Latn-eng_Latn",
        "languages": [
          "qub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009921261223344555,
        "precision": 0.008251953125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.005997138138107807,
        "hf_subset": "eng_Latn-quc_Latn",
        "languages": [
          "eng-Latn",
          "quc-Latn"
        ],
        "main_score": 0.005997138138107807,
        "precision": 0.003525629276637341,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020508094336219335,
        "hf_subset": "quc_Latn-eng_Latn",
        "languages": [
          "quc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020508094336219335,
        "precision": 0.018638939950980392,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01837439903846154,
        "hf_subset": "eng_Latn-quf_Latn",
        "languages": [
          "eng-Latn",
          "quf-Latn"
        ],
        "main_score": 0.01837439903846154,
        "precision": 0.01481827445652174,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006820436507936508,
        "hf_subset": "quf_Latn-eng_Latn",
        "languages": [
          "quf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006820436507936508,
        "precision": 0.005743677836345381,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03480282738095238,
        "hf_subset": "eng_Latn-quh_Latn",
        "languages": [
          "eng-Latn",
          "quh-Latn"
        ],
        "main_score": 0.03480282738095238,
        "precision": 0.031007946047008548,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01937789222271981,
        "hf_subset": "quh_Latn-eng_Latn",
        "languages": [
          "quh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01937789222271981,
        "precision": 0.016722557704508135,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.04465407062647754,
        "hf_subset": "eng_Latn-qul_Latn",
        "languages": [
          "eng-Latn",
          "qul-Latn"
        ],
        "main_score": 0.04465407062647754,
        "precision": 0.03808788007956806,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02957634870660313,
        "hf_subset": "qul_Latn-eng_Latn",
        "languages": [
          "qul-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02957634870660313,
        "precision": 0.025259782535173157,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006324404761904761,
        "hf_subset": "eng_Latn-qup_Latn",
        "languages": [
          "eng-Latn",
          "qup-Latn"
        ],
        "main_score": 0.006324404761904761,
        "precision": 0.005338541666666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008206561583577712,
        "hf_subset": "qup_Latn-eng_Latn",
        "languages": [
          "qup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008206561583577712,
        "precision": 0.008015046296296296,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011328125,
        "hf_subset": "eng_Latn-qvc_Latn",
        "languages": [
          "eng-Latn",
          "qvc-Latn"
        ],
        "main_score": 0.011328125,
        "precision": 0.008623342803030303,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00546875,
        "hf_subset": "qvc_Latn-eng_Latn",
        "languages": [
          "qvc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00546875,
        "precision": 0.0048828125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.047530578542392565,
        "hf_subset": "eng_Latn-qve_Latn",
        "languages": [
          "eng-Latn",
          "qve-Latn"
        ],
        "main_score": 0.047530578542392565,
        "precision": 0.04189453125,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014325513171515746,
        "hf_subset": "qve_Latn-eng_Latn",
        "languages": [
          "qve-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014325513171515746,
        "precision": 0.011881769177265501,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03644609832569391,
        "hf_subset": "eng_Latn-qvh_Latn",
        "languages": [
          "eng-Latn",
          "qvh-Latn"
        ],
        "main_score": 0.03644609832569391,
        "precision": 0.03243119546830484,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022085336538461536,
        "hf_subset": "qvh_Latn-eng_Latn",
        "languages": [
          "qvh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022085336538461536,
        "precision": 0.01904000946969697,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03298456101190476,
        "hf_subset": "eng_Latn-qvm_Latn",
        "languages": [
          "eng-Latn",
          "qvm-Latn"
        ],
        "main_score": 0.03298456101190476,
        "precision": 0.028695279535864978,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013616071428571429,
        "hf_subset": "qvm_Latn-eng_Latn",
        "languages": [
          "qvm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013616071428571429,
        "precision": 0.011315724206349206,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017513920890937017,
        "hf_subset": "eng_Latn-qvn_Latn",
        "languages": [
          "eng-Latn",
          "qvn-Latn"
        ],
        "main_score": 0.017513920890937017,
        "precision": 0.015513392857142856,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007096354166666666,
        "hf_subset": "qvn_Latn-eng_Latn",
        "languages": [
          "qvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007096354166666666,
        "precision": 0.004789806547619047,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00959201388888889,
        "hf_subset": "eng_Latn-qvs_Latn",
        "languages": [
          "eng-Latn",
          "qvs-Latn"
        ],
        "main_score": 0.00959201388888889,
        "precision": 0.007454427083333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007102272727272727,
        "hf_subset": "qvs_Latn-eng_Latn",
        "languages": [
          "qvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007102272727272727,
        "precision": 0.000390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010757688492063492,
        "hf_subset": "eng_Latn-qvw_Latn",
        "languages": [
          "eng-Latn",
          "qvw-Latn"
        ],
        "main_score": 0.010757688492063492,
        "precision": 0.008047876602564103,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012352029745589991,
        "hf_subset": "qvw_Latn-eng_Latn",
        "languages": [
          "qvw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012352029745589991,
        "precision": 0.012045701694139193,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014864309210526314,
        "hf_subset": "eng_Latn-qvz_Latn",
        "languages": [
          "eng-Latn",
          "qvz-Latn"
        ],
        "main_score": 0.014864309210526314,
        "precision": 0.01171875,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010431045141652537,
        "hf_subset": "qvz_Latn-eng_Latn",
        "languages": [
          "qvz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010431045141652537,
        "precision": 0.008222102920361301,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.027604166666666666,
        "hf_subset": "eng_Latn-qwh_Latn",
        "languages": [
          "eng-Latn",
          "qwh-Latn"
        ],
        "main_score": 0.027604166666666666,
        "precision": 0.02489938446969697,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019050045289855072,
        "hf_subset": "qwh_Latn-eng_Latn",
        "languages": [
          "qwh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019050045289855072,
        "precision": 0.017013888888888887,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020619642145135564,
        "hf_subset": "eng_Latn-qxh_Latn",
        "languages": [
          "eng-Latn",
          "qxh-Latn"
        ],
        "main_score": 0.020619642145135564,
        "precision": 0.01910777608915907,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009384645061728395,
        "hf_subset": "qxh_Latn-eng_Latn",
        "languages": [
          "qxh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009384645061728395,
        "precision": 0.008668167195855616,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.05221354166666667,
        "hf_subset": "eng_Latn-qxn_Latn",
        "languages": [
          "eng-Latn",
          "qxn-Latn"
        ],
        "main_score": 0.05221354166666667,
        "precision": 0.0459680316091954,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01862909226190476,
        "hf_subset": "qxn_Latn-eng_Latn",
        "languages": [
          "qxn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01862909226190476,
        "precision": 0.015987723214285713,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.025204613095238096,
        "hf_subset": "eng_Latn-qxo_Latn",
        "languages": [
          "eng-Latn",
          "qxo-Latn"
        ],
        "main_score": 0.025204613095238096,
        "precision": 0.0234375,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01435391865079365,
        "hf_subset": "qxo_Latn-eng_Latn",
        "languages": [
          "qxo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01435391865079365,
        "precision": 0.013213186553030304,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0230493450767841,
        "hf_subset": "eng_Latn-rai_Latn",
        "languages": [
          "eng-Latn",
          "rai-Latn"
        ],
        "main_score": 0.0230493450767841,
        "precision": 0.02196205104638009,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020255124496981892,
        "hf_subset": "rai_Latn-eng_Latn",
        "languages": [
          "rai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020255124496981892,
        "precision": 0.01990753538257408,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.02158203125,
        "hf_subset": "eng_Latn-reg_Latn",
        "languages": [
          "eng-Latn",
          "reg-Latn"
        ],
        "main_score": 0.02158203125,
        "precision": 0.020768229166666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010788690476190476,
        "hf_subset": "reg_Latn-eng_Latn",
        "languages": [
          "reg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010788690476190476,
        "precision": 0.0099609375,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.025234205898268396,
        "hf_subset": "eng_Latn-rgu_Latn",
        "languages": [
          "eng-Latn",
          "rgu-Latn"
        ],
        "main_score": 0.025234205898268396,
        "precision": 0.019887098861283644,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03194373292349727,
        "hf_subset": "rgu_Latn-eng_Latn",
        "languages": [
          "rgu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03194373292349727,
        "precision": 0.030620421245421244,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005619681558303417,
        "hf_subset": "eng_Latn-rkb_Latn",
        "languages": [
          "eng-Latn",
          "rkb-Latn"
        ],
        "main_score": 0.005619681558303417,
        "precision": 0.0041199757996633,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011160714285714285,
        "hf_subset": "rkb_Latn-eng_Latn",
        "languages": [
          "rkb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011160714285714285,
        "precision": 0.0006510416666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03428442028985507,
        "hf_subset": "eng_Latn-rmc_Latn",
        "languages": [
          "eng-Latn",
          "rmc-Latn"
        ],
        "main_score": 0.03428442028985507,
        "precision": 0.027105034722222223,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.039012419871794865,
        "hf_subset": "rmc_Latn-eng_Latn",
        "languages": [
          "rmc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.039012419871794865,
        "precision": 0.03544625946969697,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.019124422605580692,
        "hf_subset": "eng_Latn-rmy_Latn",
        "languages": [
          "eng-Latn",
          "rmy-Latn"
        ],
        "main_score": 0.019124422605580692,
        "precision": 0.015255301339285715,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02747734036796537,
        "hf_subset": "rmy_Latn-eng_Latn",
        "languages": [
          "rmy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02747734036796537,
        "precision": 0.022080592105263155,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.28515625,
        "f1": 0.20207726609060273,
        "hf_subset": "eng_Latn-ron_Latn",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ],
        "main_score": 0.20207726609060273,
        "precision": 0.17677105880230878,
        "recall": 0.28515625
      },
      {
        "accuracy": 0.234375,
        "f1": 0.18757449278433175,
        "hf_subset": "ron_Latn-eng_Latn",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ],
        "main_score": 0.18757449278433175,
        "precision": 0.1758935065915365,
        "recall": 0.234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.00826875632591093,
        "hf_subset": "eng_Latn-roo_Latn",
        "languages": [
          "eng-Latn",
          "roo-Latn"
        ],
        "main_score": 0.00826875632591093,
        "precision": 0.006526188926091269,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "roo_Latn-eng_Latn",
        "languages": [
          "roo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024702944624819624,
        "hf_subset": "eng_Latn-rop_Latn",
        "languages": [
          "eng-Latn",
          "rop-Latn"
        ],
        "main_score": 0.024702944624819624,
        "precision": 0.020730669070512818,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0275,
        "hf_subset": "rop_Latn-eng_Latn",
        "languages": [
          "rop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0275,
        "precision": 0.0274234693877551,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01829985119047619,
        "hf_subset": "eng_Latn-row_Latn",
        "languages": [
          "eng-Latn",
          "row-Latn"
        ],
        "main_score": 0.01829985119047619,
        "precision": 0.016066539797008547,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.024136178861788617,
        "hf_subset": "row_Latn-eng_Latn",
        "languages": [
          "row-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024136178861788617,
        "precision": 0.022810423057259714,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013268229166666666,
        "hf_subset": "eng_Latn-rro_Latn",
        "languages": [
          "eng-Latn",
          "rro-Latn"
        ],
        "main_score": 0.013268229166666666,
        "precision": 0.010160900297619048,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011800073099415205,
        "hf_subset": "rro_Latn-eng_Latn",
        "languages": [
          "rro-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011800073099415205,
        "precision": 0.01052370730105105,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008203125,
        "hf_subset": "eng_Latn-ruf_Latn",
        "languages": [
          "eng-Latn",
          "ruf-Latn"
        ],
        "main_score": 0.008203125,
        "precision": 0.0068462171052631575,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0008362676056338029,
        "hf_subset": "ruf_Latn-eng_Latn",
        "languages": [
          "ruf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0008362676056338029,
        "precision": 0.0004617316784869976,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01687127976190476,
        "hf_subset": "eng_Latn-rug_Latn",
        "languages": [
          "eng-Latn",
          "rug-Latn"
        ],
        "main_score": 0.01687127976190476,
        "precision": 0.013985974049707603,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004193376068376069,
        "hf_subset": "rug_Latn-eng_Latn",
        "languages": [
          "rug-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004193376068376069,
        "precision": 0.002544202302631579,
        "recall": 0.015625
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.06832568073830408,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.06832568073830408,
        "precision": 0.056786699054621845,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.0416754382517188,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0416754382517188,
        "precision": 0.03689684200893441,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012630208333333334,
        "hf_subset": "eng_Latn-rwo_Latn",
        "languages": [
          "eng-Latn",
          "rwo-Latn"
        ],
        "main_score": 0.012630208333333334,
        "precision": 0.011097301136363636,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00551672149122807,
        "hf_subset": "rwo_Latn-eng_Latn",
        "languages": [
          "rwo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00551672149122807,
        "precision": 0.004063907657657658,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014713541666666666,
        "hf_subset": "eng_Latn-sab_Latn",
        "languages": [
          "eng-Latn",
          "sab-Latn"
        ],
        "main_score": 0.014713541666666666,
        "precision": 0.012705592105263157,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017783717105263157,
        "hf_subset": "sab_Latn-eng_Latn",
        "languages": [
          "sab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017783717105263157,
        "precision": 0.017032657657657657,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0052917179802955665,
        "hf_subset": "eng_Latn-san_Latn",
        "languages": [
          "eng-Latn",
          "san-Latn"
        ],
        "main_score": 0.0052917179802955665,
        "precision": 0.004696800595238096,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0019899764150943396,
        "hf_subset": "san_Latn-eng_Latn",
        "languages": [
          "san-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0019899764150943396,
        "precision": 0.0013205963665086887,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020182291666666664,
        "hf_subset": "eng_Latn-sbe_Latn",
        "languages": [
          "eng-Latn",
          "sbe-Latn"
        ],
        "main_score": 0.020182291666666664,
        "precision": 0.017588404605263157,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "sbe_Latn-eng_Latn",
        "languages": [
          "sbe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019692460317460317,
        "hf_subset": "eng_Latn-sbk_Latn",
        "languages": [
          "eng-Latn",
          "sbk-Latn"
        ],
        "main_score": 0.019692460317460317,
        "precision": 0.016026475694444445,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "sbk_Latn-eng_Latn",
        "languages": [
          "sbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.041806175595238096,
        "hf_subset": "eng_Latn-sbs_Latn",
        "languages": [
          "eng-Latn",
          "sbs-Latn"
        ],
        "main_score": 0.041806175595238096,
        "precision": 0.03962053571428572,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011197916666666667,
        "hf_subset": "sbs_Latn-eng_Latn",
        "languages": [
          "sbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011197916666666667,
        "precision": 0.010199652777777778,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04369419642857143,
        "hf_subset": "eng_Latn-seh_Latn",
        "languages": [
          "eng-Latn",
          "seh-Latn"
        ],
        "main_score": 0.04369419642857143,
        "precision": 0.038031684027777776,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009738286440249603,
        "hf_subset": "seh_Latn-eng_Latn",
        "languages": [
          "seh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009738286440249603,
        "precision": 0.007834777022546419,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024228050595238096,
        "hf_subset": "eng_Latn-sey_Latn",
        "languages": [
          "eng-Latn",
          "sey-Latn"
        ],
        "main_score": 0.024228050595238096,
        "precision": 0.022231804653679653,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008145917565139263,
        "hf_subset": "sey_Latn-eng_Latn",
        "languages": [
          "sey-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008145917565139263,
        "precision": 0.007982894582551595,
        "recall": 0.015625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04066042553331231,
        "hf_subset": "eng_Latn-sgb_Latn",
        "languages": [
          "eng-Latn",
          "sgb-Latn"
        ],
        "main_score": 0.04066042553331231,
        "precision": 0.03645262244152046,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03366268382352941,
        "hf_subset": "sgb_Latn-eng_Latn",
        "languages": [
          "sgb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03366268382352941,
        "precision": 0.028499348958333334,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01512933680902431,
        "hf_subset": "eng_Latn-sgz_Latn",
        "languages": [
          "eng-Latn",
          "sgz-Latn"
        ],
        "main_score": 0.01512933680902431,
        "precision": 0.012425305690898628,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014165088383838384,
        "hf_subset": "sgz_Latn-eng_Latn",
        "languages": [
          "sgz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014165088383838384,
        "precision": 0.012339154411764707,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04395604395604396,
        "f1": 0.013029827315541604,
        "hf_subset": "eng_Latn-shj_Latn",
        "languages": [
          "eng-Latn",
          "shj-Latn"
        ],
        "main_score": 0.013029827315541604,
        "precision": 0.007904376325428958,
        "recall": 0.04395604395604396
      },
      {
        "accuracy": 0.03296703296703297,
        "f1": 0.018792801401497052,
        "hf_subset": "shj_Latn-eng_Latn",
        "languages": [
          "shj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018792801401497052,
        "precision": 0.016727716727716727,
        "recall": 0.03296703296703297
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014518229166666667,
        "hf_subset": "eng_Latn-shp_Latn",
        "languages": [
          "eng-Latn",
          "shp-Latn"
        ],
        "main_score": 0.014518229166666667,
        "precision": 0.012243700592885376,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0203125,
        "hf_subset": "shp_Latn-eng_Latn",
        "languages": [
          "shp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0203125,
        "precision": 0.018663194444444444,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013621411483253586,
        "hf_subset": "eng_Latn-sim_Latn",
        "languages": [
          "eng-Latn",
          "sim-Latn"
        ],
        "main_score": 0.013621411483253586,
        "precision": 0.011588541666666667,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004670516304347825,
        "hf_subset": "sim_Latn-eng_Latn",
        "languages": [
          "sim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004670516304347825,
        "precision": 0.0033126531862745093,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02041617685475444,
        "hf_subset": "eng_Latn-sja_Latn",
        "languages": [
          "eng-Latn",
          "sja-Latn"
        ],
        "main_score": 0.02041617685475444,
        "precision": 0.016631155303030304,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019008282103825137,
        "hf_subset": "sja_Latn-eng_Latn",
        "languages": [
          "sja-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019008282103825137,
        "precision": 0.0169921875,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011173396915584416,
        "hf_subset": "eng_Latn-sll_Latn",
        "languages": [
          "eng-Latn",
          "sll-Latn"
        ],
        "main_score": 0.011173396915584416,
        "precision": 0.008315711152882205,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "sll_Latn-eng_Latn",
        "languages": [
          "sll-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06655505952380952,
        "hf_subset": "eng_Latn-smk_Latn",
        "languages": [
          "eng-Latn",
          "smk-Latn"
        ],
        "main_score": 0.06655505952380952,
        "precision": 0.06015625,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.05680600944081336,
        "hf_subset": "smk_Latn-eng_Latn",
        "languages": [
          "smk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05680600944081336,
        "precision": 0.05400390625,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02751740447052947,
        "hf_subset": "eng_Latn-snc_Latn",
        "languages": [
          "eng-Latn",
          "snc-Latn"
        ],
        "main_score": 0.02751740447052947,
        "precision": 0.023984375000000002,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022211821556579622,
        "hf_subset": "snc_Latn-eng_Latn",
        "languages": [
          "snc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022211821556579622,
        "precision": 0.021123134667503964,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02732514880952381,
        "hf_subset": "eng_Latn-snn_Latn",
        "languages": [
          "eng-Latn",
          "snn-Latn"
        ],
        "main_score": 0.02732514880952381,
        "precision": 0.02591145833333333,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006916538950358852,
        "hf_subset": "snn_Latn-eng_Latn",
        "languages": [
          "snn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006916538950358852,
        "precision": 0.005777049731182796,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.018105326308451308,
        "hf_subset": "eng_Latn-snp_Latn",
        "languages": [
          "eng-Latn",
          "snp-Latn"
        ],
        "main_score": 0.018105326308451308,
        "precision": 0.01328050680175038,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004343312937062937,
        "hf_subset": "snp_Latn-eng_Latn",
        "languages": [
          "snp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004343312937062937,
        "precision": 0.004131116365131579,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.12857142857142856,
        "f1": 0.09595238095238096,
        "hf_subset": "eng_Latn-snx_Latn",
        "languages": [
          "eng-Latn",
          "snx-Latn"
        ],
        "main_score": 0.09595238095238096,
        "precision": 0.09043355380429684,
        "recall": 0.12857142857142856
      },
      {
        "accuracy": 0.10714285714285714,
        "f1": 0.07286010480747322,
        "hf_subset": "snx_Latn-eng_Latn",
        "languages": [
          "snx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07286010480747322,
        "precision": 0.06569444444444444,
        "recall": 0.10714285714285714
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012058911483253588,
        "hf_subset": "eng_Latn-sny_Latn",
        "languages": [
          "eng-Latn",
          "sny-Latn"
        ],
        "main_score": 0.012058911483253588,
        "precision": 0.00842013888888889,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01611519607843137,
        "hf_subset": "sny_Latn-eng_Latn",
        "languages": [
          "sny-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01611519607843137,
        "precision": 0.014766808712121212,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00879794034090909,
        "hf_subset": "eng_Latn-som_Latn",
        "languages": [
          "eng-Latn",
          "som-Latn"
        ],
        "main_score": 0.00879794034090909,
        "precision": 0.007218424479166667,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009375,
        "hf_subset": "som_Latn-eng_Latn",
        "languages": [
          "som-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009375,
        "precision": 0.0087890625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010443853021978021,
        "hf_subset": "eng_Latn-soq_Latn",
        "languages": [
          "eng-Latn",
          "soq-Latn"
        ],
        "main_score": 0.010443853021978021,
        "precision": 0.009476099258814104,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016528057795698922,
        "hf_subset": "soq_Latn-eng_Latn",
        "languages": [
          "soq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016528057795698922,
        "precision": 0.015104166666666665,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "eng_Latn-soy_Latn",
        "languages": [
          "eng-Latn",
          "soy-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006510416666666666,
        "hf_subset": "soy_Latn-eng_Latn",
        "languages": [
          "soy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.0003551136363636364,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.796875,
        "f1": 0.7487072172619047,
        "hf_subset": "eng_Latn-spa_Latn",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ],
        "main_score": 0.7487072172619047,
        "precision": 0.7298549107142858,
        "recall": 0.796875
      },
      {
        "accuracy": 0.8828125,
        "f1": 0.8524739583333333,
        "hf_subset": "spa_Latn-eng_Latn",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.8524739583333333,
        "precision": 0.8388671875,
        "recall": 0.8828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0033854166666666668,
        "hf_subset": "eng_Latn-spl_Latn",
        "languages": [
          "eng-Latn",
          "spl-Latn"
        ],
        "main_score": 0.0033854166666666668,
        "precision": 0.002387152777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0002418154761904762,
        "hf_subset": "spl_Latn-eng_Latn",
        "languages": [
          "spl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0002418154761904762,
        "precision": 0.00012281994595922377,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.050059779912870944,
        "hf_subset": "eng_Latn-spm_Latn",
        "languages": [
          "eng-Latn",
          "spm-Latn"
        ],
        "main_score": 0.050059779912870944,
        "precision": 0.046292215608841863,
        "recall": 0.078125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.053477441623201,
        "hf_subset": "spm_Latn-eng_Latn",
        "languages": [
          "spm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.053477441623201,
        "precision": 0.046666837993421056,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015057342980295565,
        "hf_subset": "eng_Latn-spp_Latn",
        "languages": [
          "eng-Latn",
          "spp-Latn"
        ],
        "main_score": 0.015057342980295565,
        "precision": 0.01381138392857143,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "spp_Latn-eng_Latn",
        "languages": [
          "spp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013095238095238096,
        "hf_subset": "eng_Latn-sps_Latn",
        "languages": [
          "eng-Latn",
          "sps-Latn"
        ],
        "main_score": 0.013095238095238096,
        "precision": 0.012504489942528734,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013671875,
        "hf_subset": "sps_Latn-eng_Latn",
        "languages": [
          "sps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013671875,
        "precision": 0.011848958333333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005998883928571428,
        "hf_subset": "eng_Latn-spy_Latn",
        "languages": [
          "eng-Latn",
          "spy-Latn"
        ],
        "main_score": 0.005998883928571428,
        "precision": 0.005115327380952381,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0006429984945609946,
        "hf_subset": "spy_Latn-eng_Latn",
        "languages": [
          "spy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006429984945609946,
        "precision": 0.0003357139933020622,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022346565315315314,
        "hf_subset": "eng_Latn-sri_Latn",
        "languages": [
          "eng-Latn",
          "sri-Latn"
        ],
        "main_score": 0.022346565315315314,
        "precision": 0.02029079861111111,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015043138041733546,
        "hf_subset": "sri_Latn-eng_Latn",
        "languages": [
          "sri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015043138041733546,
        "precision": 0.014054305069930072,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01381561147186147,
        "hf_subset": "eng_Latn-srm_Latn",
        "languages": [
          "eng-Latn",
          "srm-Latn"
        ],
        "main_score": 0.01381561147186147,
        "precision": 0.01214130108173077,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.010416666666666666,
        "hf_subset": "srm_Latn-eng_Latn",
        "languages": [
          "srm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.009765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.044471441387559804,
        "hf_subset": "eng_Latn-srn_Latn",
        "languages": [
          "eng-Latn",
          "srn-Latn"
        ],
        "main_score": 0.044471441387559804,
        "precision": 0.038973847517730496,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.057457729468599034,
        "hf_subset": "srn_Latn-eng_Latn",
        "languages": [
          "srn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.057457729468599034,
        "precision": 0.054376775568181816,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.04383476224296536,
        "hf_subset": "eng_Latn-srp_Latn",
        "languages": [
          "eng-Latn",
          "srp-Latn"
        ],
        "main_score": 0.04383476224296536,
        "precision": 0.03716038464759617,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.038508621369949494,
        "hf_subset": "srp_Latn-eng_Latn",
        "languages": [
          "srp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.038508621369949494,
        "precision": 0.03310915989532421,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.031510416666666666,
        "hf_subset": "eng_Latn-srq_Latn",
        "languages": [
          "eng-Latn",
          "srq-Latn"
        ],
        "main_score": 0.031510416666666666,
        "precision": 0.02774610183747412,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.024182668172690762,
        "hf_subset": "srq_Latn-eng_Latn",
        "languages": [
          "srq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024182668172690762,
        "precision": 0.022834095528455285,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02201404600301659,
        "hf_subset": "eng_Latn-ssd_Latn",
        "languages": [
          "eng-Latn",
          "ssd-Latn"
        ],
        "main_score": 0.02201404600301659,
        "precision": 0.018108723958333333,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.027097800925925924,
        "hf_subset": "ssd_Latn-eng_Latn",
        "languages": [
          "ssd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027097800925925924,
        "precision": 0.025789848663522012,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01890500992063492,
        "hf_subset": "eng_Latn-ssg_Latn",
        "languages": [
          "eng-Latn",
          "ssg-Latn"
        ],
        "main_score": 0.01890500992063492,
        "precision": 0.015227936126373626,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015733506944444444,
        "hf_subset": "ssg_Latn-eng_Latn",
        "languages": [
          "ssg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015733506944444444,
        "precision": 0.014508142605633802,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013785314078282828,
        "hf_subset": "eng_Latn-ssx_Latn",
        "languages": [
          "eng-Latn",
          "ssx-Latn"
        ],
        "main_score": 0.013785314078282828,
        "precision": 0.012858072916666668,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004557291666666667,
        "hf_subset": "ssx_Latn-eng_Latn",
        "languages": [
          "ssx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004557291666666667,
        "precision": 0.004261363636363636,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009592378618113913,
        "hf_subset": "eng_Latn-stp_Latn",
        "languages": [
          "eng-Latn",
          "stp-Latn"
        ],
        "main_score": 0.009592378618113913,
        "precision": 0.0073720495320407295,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007355097409220726,
        "hf_subset": "stp_Latn-eng_Latn",
        "languages": [
          "stp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007355097409220726,
        "precision": 0.0060876225490196076,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.007509244227994228,
        "hf_subset": "eng_Latn-sua_Latn",
        "languages": [
          "eng-Latn",
          "sua-Latn"
        ],
        "main_score": 0.007509244227994228,
        "precision": 0.004336939102564103,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008765665253327608,
        "hf_subset": "sua_Latn-eng_Latn",
        "languages": [
          "sua-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008765665253327608,
        "precision": 0.008333552443054336,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014046223958333335,
        "hf_subset": "eng_Latn-sue_Latn",
        "languages": [
          "eng-Latn",
          "sue-Latn"
        ],
        "main_score": 0.014046223958333335,
        "precision": 0.013060035842293908,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004341083024118738,
        "hf_subset": "sue_Latn-eng_Latn",
        "languages": [
          "sue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004341083024118738,
        "precision": 0.004132532523318606,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00950915404040404,
        "hf_subset": "eng_Latn-sus_Arab",
        "languages": [
          "eng-Latn",
          "sus-Arab"
        ],
        "main_score": 0.00950915404040404,
        "precision": 0.007740582606589147,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020013503086419755,
        "hf_subset": "sus_Arab-eng_Latn",
        "languages": [
          "sus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0020013503086419755,
        "precision": 0.0013263457556935818,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006996893477457501,
        "hf_subset": "eng_Latn-suz_Latn",
        "languages": [
          "eng-Latn",
          "suz-Latn"
        ],
        "main_score": 0.006996893477457501,
        "precision": 0.004646809895833333,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 8.680555555555556e-05,
        "hf_subset": "suz_Latn-eng_Latn",
        "languages": [
          "suz-Latn",
          "eng-Latn"
        ],
        "main_score": 8.680555555555556e-05,
        "precision": 4.3890449438202246e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.1393045973124098,
        "hf_subset": "eng_Latn-swe_Latn",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ],
        "main_score": 0.1393045973124098,
        "precision": 0.12431891025641026,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.1730719584235209,
        "hf_subset": "swe_Latn-eng_Latn",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1730719584235209,
        "precision": 0.15161297931763285,
        "recall": 0.23828125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02364938446969697,
        "hf_subset": "eng_Latn-swh_Latn",
        "languages": [
          "eng-Latn",
          "swh-Latn"
        ],
        "main_score": 0.02364938446969697,
        "precision": 0.02107767791875522,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025200617283950618,
        "hf_subset": "swh_Latn-eng_Latn",
        "languages": [
          "swh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025200617283950618,
        "precision": 0.023213594453828826,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03221912202380952,
        "hf_subset": "eng_Latn-swp_Latn",
        "languages": [
          "eng-Latn",
          "swp-Latn"
        ],
        "main_score": 0.03221912202380952,
        "precision": 0.02710821870978121,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01582255747126437,
        "hf_subset": "swp_Latn-eng_Latn",
        "languages": [
          "swp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01582255747126437,
        "precision": 0.01348882850241546,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014192708333333333,
        "hf_subset": "eng_Latn-sxb_Latn",
        "languages": [
          "eng-Latn",
          "sxb-Latn"
        ],
        "main_score": 0.014192708333333333,
        "precision": 0.011811755952380952,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006559862869198312,
        "hf_subset": "sxb_Latn-eng_Latn",
        "languages": [
          "sxb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006559862869198312,
        "precision": 0.005884255573248408,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011067708333333332,
        "hf_subset": "eng_Latn-tac_Latn",
        "languages": [
          "eng-Latn",
          "tac-Latn"
        ],
        "main_score": 0.011067708333333332,
        "precision": 0.009114583333333334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "tac_Latn-eng_Latn",
        "languages": [
          "tac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0013495460332350576,
        "hf_subset": "eng_Latn-taj_Deva",
        "languages": [
          "eng-Latn",
          "taj-Deva"
        ],
        "main_score": 0.0013495460332350576,
        "precision": 0.0007236578525641026,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00162353515625,
        "hf_subset": "taj_Deva-eng_Latn",
        "languages": [
          "taj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00162353515625,
        "precision": 0.001007320374015748,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004524941770186335,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.004524941770186335,
        "precision": 0.004228482744107744,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007102272727272727,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.0007102272727272727,
        "precision": 0.000390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017892539474161542,
        "hf_subset": "eng_Latn-tav_Latn",
        "languages": [
          "eng-Latn",
          "tav-Latn"
        ],
        "main_score": 0.017892539474161542,
        "precision": 0.016131615921442688,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.022754314170843774,
        "hf_subset": "tav_Latn-eng_Latn",
        "languages": [
          "tav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022754314170843774,
        "precision": 0.018343840672469705,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02039175724637681,
        "hf_subset": "eng_Latn-taw_Latn",
        "languages": [
          "eng-Latn",
          "taw-Latn"
        ],
        "main_score": 0.02039175724637681,
        "precision": 0.017755681818181816,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "taw_Latn-eng_Latn",
        "languages": [
          "taw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.015921798406862746,
        "hf_subset": "eng_Latn-tbc_Latn",
        "languages": [
          "eng-Latn",
          "tbc-Latn"
        ],
        "main_score": 0.015921798406862746,
        "precision": 0.012821439225361195,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02198660714285714,
        "hf_subset": "tbc_Latn-eng_Latn",
        "languages": [
          "tbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02198660714285714,
        "precision": 0.02109289896514161,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03139293546365915,
        "hf_subset": "eng_Latn-tbf_Latn",
        "languages": [
          "eng-Latn",
          "tbf-Latn"
        ],
        "main_score": 0.03139293546365915,
        "precision": 0.027834047750737462,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019661458333333333,
        "hf_subset": "tbf_Latn-eng_Latn",
        "languages": [
          "tbf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019661458333333333,
        "precision": 0.017361111111111112,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015950520833333336,
        "hf_subset": "eng_Latn-tbg_Latn",
        "languages": [
          "eng-Latn",
          "tbg-Latn"
        ],
        "main_score": 0.015950520833333336,
        "precision": 0.014360119047619047,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003950639204545455,
        "hf_subset": "tbg_Latn-eng_Latn",
        "languages": [
          "tbg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003950639204545455,
        "precision": 0.003928571428571429,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016257957175925923,
        "hf_subset": "eng_Latn-tbo_Latn",
        "languages": [
          "eng-Latn",
          "tbo-Latn"
        ],
        "main_score": 0.016257957175925923,
        "precision": 0.014787244496855347,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.016927083333333332,
        "hf_subset": "tbo_Latn-eng_Latn",
        "languages": [
          "tbo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016927083333333332,
        "precision": 0.01640625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005042613636363637,
        "hf_subset": "eng_Latn-tbz_Latn",
        "languages": [
          "eng-Latn",
          "tbz-Latn"
        ],
        "main_score": 0.005042613636363637,
        "precision": 0.004526289682539682,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "tbz_Latn-eng_Latn",
        "languages": [
          "tbz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009114583333333332,
        "hf_subset": "eng_Latn-tca_Latn",
        "languages": [
          "eng-Latn",
          "tca-Latn"
        ],
        "main_score": 0.009114583333333332,
        "precision": 0.00859375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0042990846951602765,
        "hf_subset": "tca_Latn-eng_Latn",
        "languages": [
          "tca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0042990846951602765,
        "precision": 0.004107762896825396,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.062189347872207076,
        "hf_subset": "eng_Latn-tcs_Latn",
        "languages": [
          "eng-Latn",
          "tcs-Latn"
        ],
        "main_score": 0.062189347872207076,
        "precision": 0.05590401785714286,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.041793818161005664,
        "hf_subset": "tcs_Latn-eng_Latn",
        "languages": [
          "tcs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.041793818161005664,
        "precision": 0.03688716231684981,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.04628690679523327,
        "hf_subset": "eng_Latn-tcz_Latn",
        "languages": [
          "eng-Latn",
          "tcz-Latn"
        ],
        "main_score": 0.04628690679523327,
        "precision": 0.037377823089768655,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.05250355113636363,
        "hf_subset": "tcz_Latn-eng_Latn",
        "languages": [
          "tcz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05250355113636363,
        "precision": 0.048463255494505496,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03194114912864912,
        "hf_subset": "eng_Latn-tdt_Latn",
        "languages": [
          "eng-Latn",
          "tdt-Latn"
        ],
        "main_score": 0.03194114912864912,
        "precision": 0.028903290719696967,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.0358250070861678,
        "hf_subset": "tdt_Latn-eng_Latn",
        "languages": [
          "tdt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0358250070861678,
        "precision": 0.03327594770189003,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015705128205128205,
        "hf_subset": "eng_Latn-tee_Latn",
        "languages": [
          "eng-Latn",
          "tee-Latn"
        ],
        "main_score": 0.015705128205128205,
        "precision": 0.014431423611111112,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.012369791666666666,
        "hf_subset": "tee_Latn-eng_Latn",
        "languages": [
          "tee-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012369791666666666,
        "precision": 0.011067708333333334,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004317434210526315,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.004317434210526315,
        "precision": 0.002951388888888889,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004079861111111111,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.004079861111111111,
        "precision": 0.0026929450757575755,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00798191391941392,
        "hf_subset": "eng_Latn-ter_Latn",
        "languages": [
          "eng-Latn",
          "ter-Latn"
        ],
        "main_score": 0.00798191391941392,
        "precision": 0.00664813701923077,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002516574782199782,
        "hf_subset": "ter_Latn-eng_Latn",
        "languages": [
          "ter-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002516574782199782,
        "precision": 0.0015943088850837138,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024313713972431074,
        "hf_subset": "eng_Latn-tet_Latn",
        "languages": [
          "eng-Latn",
          "tet-Latn"
        ],
        "main_score": 0.024313713972431074,
        "precision": 0.02131076388888889,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017117632113821137,
        "hf_subset": "tet_Latn-eng_Latn",
        "languages": [
          "tet-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017117632113821137,
        "precision": 0.01650390625,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.140625,
        "f1": 0.10324618957431457,
        "hf_subset": "eng_Latn-tew_Latn",
        "languages": [
          "eng-Latn",
          "tew-Latn"
        ],
        "main_score": 0.10324618957431457,
        "precision": 0.09257708054812834,
        "recall": 0.140625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.0849445017027542,
        "hf_subset": "tew_Latn-eng_Latn",
        "languages": [
          "tew-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0849445017027542,
        "precision": 0.07924282112249163,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025499131944444444,
        "hf_subset": "eng_Latn-tfr_Latn",
        "languages": [
          "eng-Latn",
          "tfr-Latn"
        ],
        "main_score": 0.025499131944444444,
        "precision": 0.02327834542908072,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.029175646551724135,
        "hf_subset": "tfr_Latn-eng_Latn",
        "languages": [
          "tfr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029175646551724135,
        "precision": 0.02728794642857143,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010807291666666666,
        "hf_subset": "eng_Latn-tgk_Cyrl",
        "languages": [
          "eng-Latn",
          "tgk-Cyrl"
        ],
        "main_score": 0.010807291666666666,
        "precision": 0.008669133771929825,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.3645251396648046e-05,
        "hf_subset": "tgk_Cyrl-eng_Latn",
        "languages": [
          "tgk-Cyrl",
          "eng-Latn"
        ],
        "main_score": 4.3645251396648046e-05,
        "precision": 2.1945224719101123e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.140625,
        "f1": 0.09604583784271284,
        "hf_subset": "eng_Latn-tgl_Latn",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ],
        "main_score": 0.09604583784271284,
        "precision": 0.08480798332590611,
        "recall": 0.140625
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07211717319139194,
        "hf_subset": "tgl_Latn-eng_Latn",
        "languages": [
          "tgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07211717319139194,
        "precision": 0.06458790204678364,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024205872252747253,
        "hf_subset": "eng_Latn-tgo_Latn",
        "languages": [
          "eng-Latn",
          "tgo-Latn"
        ],
        "main_score": 0.024205872252747253,
        "precision": 0.021210645106704888,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005365885331457365,
        "hf_subset": "tgo_Latn-eng_Latn",
        "languages": [
          "tgo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005365885331457365,
        "precision": 0.004733147749042145,
        "recall": 0.015625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08070528104707791,
        "hf_subset": "eng_Latn-tgp_Latn",
        "languages": [
          "eng-Latn",
          "tgp-Latn"
        ],
        "main_score": 0.08070528104707791,
        "precision": 0.07294036818356375,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.07368489583333333,
        "hf_subset": "tgp_Latn-eng_Latn",
        "languages": [
          "tgp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07368489583333333,
        "precision": 0.06821211557539682,
        "recall": 0.09375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00041118421052631577,
        "hf_subset": "eng_Latn-tha_Thai",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ],
        "main_score": 0.00041118421052631577,
        "precision": 0.00021701388888888888,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0004444288913773796,
        "hf_subset": "tha_Thai-eng_Latn",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ],
        "main_score": 0.0004444288913773796,
        "precision": 0.00023370726495726494,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013774181547619047,
        "hf_subset": "eng_Latn-tif_Latn",
        "languages": [
          "eng-Latn",
          "tif-Latn"
        ],
        "main_score": 0.013774181547619047,
        "precision": 0.011616204975579976,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00012807377049180329,
        "hf_subset": "tif_Latn-eng_Latn",
        "languages": [
          "tif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00012807377049180329,
        "precision": 6.510416666666667e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017544304653679652,
        "hf_subset": "eng_Latn-tim_Latn",
        "languages": [
          "eng-Latn",
          "tim-Latn"
        ],
        "main_score": 0.017544304653679652,
        "precision": 0.015657366777356102,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007892219387755101,
        "hf_subset": "tim_Latn-eng_Latn",
        "languages": [
          "tim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007892219387755101,
        "precision": 0.006680895618556701,
        "recall": 0.015625
      },
      {
        "accuracy": 0.11627906976744186,
        "f1": 0.08049690936998442,
        "hf_subset": "eng_Latn-tiw_Latn",
        "languages": [
          "eng-Latn",
          "tiw-Latn"
        ],
        "main_score": 0.08049690936998442,
        "precision": 0.07287210798838706,
        "recall": 0.11627906976744186
      },
      {
        "accuracy": 0.09767441860465116,
        "f1": 0.07239659151429079,
        "hf_subset": "tiw_Latn-eng_Latn",
        "languages": [
          "tiw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07239659151429079,
        "precision": 0.06716957461143508,
        "recall": 0.09767441860465116
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022900497004357298,
        "hf_subset": "eng_Latn-tiy_Latn",
        "languages": [
          "eng-Latn",
          "tiy-Latn"
        ],
        "main_score": 0.022900497004357298,
        "precision": 0.01918078932008767,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005158253205128205,
        "hf_subset": "tiy_Latn-eng_Latn",
        "languages": [
          "tiy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005158253205128205,
        "precision": 0.004586884469696969,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.09782608695652174,
        "f1": 0.047575914423740505,
        "hf_subset": "eng_Latn-tke_Latn",
        "languages": [
          "eng-Latn",
          "tke-Latn"
        ],
        "main_score": 0.047575914423740505,
        "precision": 0.03588250517598344,
        "recall": 0.09782608695652174
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.012348417627920735,
        "hf_subset": "tke_Latn-eng_Latn",
        "languages": [
          "tke-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012348417627920735,
        "precision": 0.011639492753623188,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.044562251984126985,
        "hf_subset": "eng_Latn-tku_Latn",
        "languages": [
          "eng-Latn",
          "tku-Latn"
        ],
        "main_score": 0.044562251984126985,
        "precision": 0.03901768804112554,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.027120535714285715,
        "hf_subset": "tku_Latn-eng_Latn",
        "languages": [
          "tku-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027120535714285715,
        "precision": 0.023726558985605037,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014851016240440456,
        "hf_subset": "eng_Latn-tlf_Latn",
        "languages": [
          "eng-Latn",
          "tlf-Latn"
        ],
        "main_score": 0.014851016240440456,
        "precision": 0.012465482211151369,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003970286885245902,
        "hf_subset": "tlf_Latn-eng_Latn",
        "languages": [
          "tlf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003970286885245902,
        "precision": 0.0039385330578512396,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010906736492673992,
        "hf_subset": "eng_Latn-tmd_Latn",
        "languages": [
          "eng-Latn",
          "tmd-Latn"
        ],
        "main_score": 0.010906736492673992,
        "precision": 0.008776907129076424,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004870923913043479,
        "hf_subset": "tmd_Latn-eng_Latn",
        "languages": [
          "tmd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004870923913043479,
        "precision": 0.0044156118374868375,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03186848958333333,
        "hf_subset": "eng_Latn-tna_Latn",
        "languages": [
          "eng-Latn",
          "tna-Latn"
        ],
        "main_score": 0.03186848958333333,
        "precision": 0.03012152777777778,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022563244047619047,
        "hf_subset": "tna_Latn-eng_Latn",
        "languages": [
          "tna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022563244047619047,
        "precision": 0.020186844405594408,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.04518233502608503,
        "hf_subset": "eng_Latn-tnc_Latn",
        "languages": [
          "eng-Latn",
          "tnc-Latn"
        ],
        "main_score": 0.04518233502608503,
        "precision": 0.03950580018939394,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021323529411764706,
        "hf_subset": "tnc_Latn-eng_Latn",
        "languages": [
          "tnc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021323529411764706,
        "precision": 0.01932410037878788,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02412912608225108,
        "hf_subset": "eng_Latn-tnk_Latn",
        "languages": [
          "eng-Latn",
          "tnk-Latn"
        ],
        "main_score": 0.02412912608225108,
        "precision": 0.02122395833333333,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004625582750582751,
        "hf_subset": "tnk_Latn-eng_Latn",
        "languages": [
          "tnk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004625582750582751,
        "precision": 0.0042918669871794875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014056299603174602,
        "hf_subset": "eng_Latn-tnn_Latn",
        "languages": [
          "eng-Latn",
          "tnn-Latn"
        ],
        "main_score": 0.014056299603174602,
        "precision": 0.010879907852564102,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0060506465517241375,
        "hf_subset": "tnn_Latn-eng_Latn",
        "languages": [
          "tnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0060506465517241375,
        "precision": 0.005185081845238095,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017447916666666667,
        "hf_subset": "eng_Latn-tnp_Latn",
        "languages": [
          "eng-Latn",
          "tnp-Latn"
        ],
        "main_score": 0.017447916666666667,
        "precision": 0.015516493055555556,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005968372926093514,
        "hf_subset": "tnp_Latn-eng_Latn",
        "languages": [
          "tnp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005968372926093514,
        "precision": 0.005087890625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03653273809523809,
        "hf_subset": "eng_Latn-toc_Latn",
        "languages": [
          "eng-Latn",
          "toc-Latn"
        ],
        "main_score": 0.03653273809523809,
        "precision": 0.03217075892857142,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013801265099148164,
        "hf_subset": "toc_Latn-eng_Latn",
        "languages": [
          "toc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013801265099148164,
        "precision": 0.011660469966053983,
        "recall": 0.03125
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.07663276176948051,
        "hf_subset": "eng_Latn-tod_Latn",
        "languages": [
          "eng-Latn",
          "tod-Latn"
        ],
        "main_score": 0.07663276176948051,
        "precision": 0.06871720130997475,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.0465797829079079,
        "hf_subset": "tod_Latn-eng_Latn",
        "languages": [
          "tod-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0465797829079079,
        "precision": 0.04545919841099676,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020684248494843006,
        "hf_subset": "eng_Latn-tof_Latn",
        "languages": [
          "eng-Latn",
          "tof-Latn"
        ],
        "main_score": 0.020684248494843006,
        "precision": 0.018728113129154796,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01607886698854165,
        "hf_subset": "tof_Latn-eng_Latn",
        "languages": [
          "tof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01607886698854165,
        "precision": 0.01347972582462472,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.031016444493006994,
        "hf_subset": "eng_Latn-toj_Latn",
        "languages": [
          "eng-Latn",
          "toj-Latn"
        ],
        "main_score": 0.031016444493006994,
        "precision": 0.02482742228835979,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013188733552631579,
        "hf_subset": "toj_Latn-eng_Latn",
        "languages": [
          "toj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013188733552631579,
        "precision": 0.011159337698938992,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007486979166666666,
        "hf_subset": "eng_Latn-ton_Latn",
        "languages": [
          "eng-Latn",
          "ton-Latn"
        ],
        "main_score": 0.007486979166666666,
        "precision": 0.006380208333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009248621323529412,
        "hf_subset": "ton_Latn-eng_Latn",
        "languages": [
          "ton-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009248621323529412,
        "precision": 0.008614676339285714,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.028605812590187588,
        "hf_subset": "eng_Latn-too_Latn",
        "languages": [
          "eng-Latn",
          "too-Latn"
        ],
        "main_score": 0.028605812590187588,
        "precision": 0.02431640625,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013701467803030302,
        "hf_subset": "too_Latn-eng_Latn",
        "languages": [
          "too-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013701467803030302,
        "precision": 0.011774553571428571,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.037239583333333326,
        "hf_subset": "eng_Latn-top_Latn",
        "languages": [
          "eng-Latn",
          "top-Latn"
        ],
        "main_score": 0.037239583333333326,
        "precision": 0.03389756944444444,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012016369047619048,
        "hf_subset": "top_Latn-eng_Latn",
        "languages": [
          "top-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012016369047619048,
        "precision": 0.01040190620782726,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023485036375661378,
        "hf_subset": "eng_Latn-tos_Latn",
        "languages": [
          "eng-Latn",
          "tos-Latn"
        ],
        "main_score": 0.023485036375661378,
        "precision": 0.02037593482905983,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011236077366664715,
        "hf_subset": "tos_Latn-eng_Latn",
        "languages": [
          "tos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011236077366664715,
        "precision": 0.009857854992026188,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.18439716312056736,
        "f1": 0.13119292634311408,
        "hf_subset": "eng_Latn-tpa_Latn",
        "languages": [
          "eng-Latn",
          "tpa-Latn"
        ],
        "main_score": 0.13119292634311408,
        "precision": 0.12025920297196893,
        "recall": 0.18439716312056736
      },
      {
        "accuracy": 0.15602836879432624,
        "f1": 0.108201666712305,
        "hf_subset": "tpa_Latn-eng_Latn",
        "languages": [
          "tpa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.108201666712305,
        "precision": 0.0967371146542479,
        "recall": 0.15602836879432624
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.09757677218614719,
        "hf_subset": "eng_Latn-tpi_Latn",
        "languages": [
          "eng-Latn",
          "tpi-Latn"
        ],
        "main_score": 0.09757677218614719,
        "precision": 0.08571501662361701,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.07327001792564852,
        "hf_subset": "tpi_Latn-eng_Latn",
        "languages": [
          "tpi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07327001792564852,
        "precision": 0.06624340503246753,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03680716604823747,
        "hf_subset": "eng_Latn-tpt_Latn",
        "languages": [
          "eng-Latn",
          "tpt-Latn"
        ],
        "main_score": 0.03680716604823747,
        "precision": 0.030558021622474747,
        "recall": 0.0625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.020281184071729956,
        "hf_subset": "tpt_Latn-eng_Latn",
        "languages": [
          "tpt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020281184071729956,
        "precision": 0.018930288461538464,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010125005895114128,
        "hf_subset": "eng_Latn-tpz_Latn",
        "languages": [
          "eng-Latn",
          "tpz-Latn"
        ],
        "main_score": 0.010125005895114128,
        "precision": 0.007950458829365079,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007421875,
        "hf_subset": "tpz_Latn-eng_Latn",
        "languages": [
          "tpz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007421875,
        "precision": 0.006184895833333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024873173701298698,
        "hf_subset": "eng_Latn-trc_Latn",
        "languages": [
          "eng-Latn",
          "trc-Latn"
        ],
        "main_score": 0.024873173701298698,
        "precision": 0.0208984375,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01444255614177489,
        "hf_subset": "trc_Latn-eng_Latn",
        "languages": [
          "trc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01444255614177489,
        "precision": 0.012484681372549019,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01418499484232243,
        "hf_subset": "eng_Latn-tsw_Latn",
        "languages": [
          "eng-Latn",
          "tsw-Latn"
        ],
        "main_score": 0.01418499484232243,
        "precision": 0.011961054981203006,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0078125,
        "hf_subset": "tsw_Latn-eng_Latn",
        "languages": [
          "tsw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.006640625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01638454861111111,
        "hf_subset": "eng_Latn-ttc_Latn",
        "languages": [
          "eng-Latn",
          "ttc-Latn"
        ],
        "main_score": 0.01638454861111111,
        "precision": 0.013075850938967137,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013368055555555557,
        "hf_subset": "ttc_Latn-eng_Latn",
        "languages": [
          "ttc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013368055555555557,
        "precision": 0.012641059027777778,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016649305555555556,
        "hf_subset": "eng_Latn-tte_Latn",
        "languages": [
          "eng-Latn",
          "tte-Latn"
        ],
        "main_score": 0.016649305555555556,
        "precision": 0.014239875637755101,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011791087962962962,
        "hf_subset": "tte_Latn-eng_Latn",
        "languages": [
          "tte-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011791087962962962,
        "precision": 0.010583382009345794,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04373782772015733,
        "hf_subset": "eng_Latn-tuc_Latn",
        "languages": [
          "eng-Latn",
          "tuc-Latn"
        ],
        "main_score": 0.04373782772015733,
        "precision": 0.038822176597911894,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03809762286324786,
        "hf_subset": "tuc_Latn-eng_Latn",
        "languages": [
          "tuc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03809762286324786,
        "precision": 0.037007649739583336,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0162906568877551,
        "hf_subset": "eng_Latn-tue_Latn",
        "languages": [
          "eng-Latn",
          "tue-Latn"
        ],
        "main_score": 0.0162906568877551,
        "precision": 0.014595702166175749,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016550611413043478,
        "hf_subset": "tue_Latn-eng_Latn",
        "languages": [
          "tue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016550611413043478,
        "precision": 0.014732988365800864,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008441526333634718,
        "hf_subset": "eng_Latn-tuf_Latn",
        "languages": [
          "eng-Latn",
          "tuf-Latn"
        ],
        "main_score": 0.008441526333634718,
        "precision": 0.006935925856656692,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010706018518518517,
        "hf_subset": "tuf_Latn-eng_Latn",
        "languages": [
          "tuf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010706018518518517,
        "precision": 0.009915865384615384,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020703125,
        "hf_subset": "eng_Latn-tuo_Latn",
        "languages": [
          "eng-Latn",
          "tuo-Latn"
        ],
        "main_score": 0.020703125,
        "precision": 0.01798735119047619,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015684185606060604,
        "hf_subset": "tuo_Latn-eng_Latn",
        "languages": [
          "tuo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015684185606060604,
        "precision": 0.013411458333333334,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.018473684454842543,
        "hf_subset": "eng_Latn-tur_Latn",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.018473684454842543,
        "precision": 0.015972997271825398,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.026252003205128202,
        "hf_subset": "tur_Latn-eng_Latn",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026252003205128202,
        "precision": 0.024088541666666664,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01663564524555904,
        "hf_subset": "eng_Latn-tvk_Latn",
        "languages": [
          "eng-Latn",
          "tvk-Latn"
        ],
        "main_score": 0.01663564524555904,
        "precision": 0.013535792606516292,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013250612745098039,
        "hf_subset": "tvk_Latn-eng_Latn",
        "languages": [
          "tvk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013250612745098039,
        "precision": 0.01261660447761194,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03165890548029557,
        "hf_subset": "eng_Latn-twi_Latn",
        "languages": [
          "eng-Latn",
          "twi-Latn"
        ],
        "main_score": 0.03165890548029557,
        "precision": 0.02999441964285714,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "twi_Latn-eng_Latn",
        "languages": [
          "twi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011798743717440751,
        "hf_subset": "eng_Latn-txq_Latn",
        "languages": [
          "eng-Latn",
          "txq-Latn"
        ],
        "main_score": 0.011798743717440751,
        "precision": 0.008951108607628003,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01893194674392936,
        "hf_subset": "txq_Latn-eng_Latn",
        "languages": [
          "txq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01893194674392936,
        "precision": 0.016953125,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "eng_Latn-txu_Latn",
        "languages": [
          "eng-Latn",
          "txu-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007626488095238094,
        "hf_subset": "txu_Latn-eng_Latn",
        "languages": [
          "txu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007626488095238094,
        "precision": 0.006510416666666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.078125,
        "f1": 0.04198671656162465,
        "hf_subset": "eng_Latn-tzj_Latn",
        "languages": [
          "eng-Latn",
          "tzj-Latn"
        ],
        "main_score": 0.04198671656162465,
        "precision": 0.035945719824990216,
        "recall": 0.078125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.039532223418942164,
        "hf_subset": "tzj_Latn-eng_Latn",
        "languages": [
          "tzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.039532223418942164,
        "precision": 0.03382595486111111,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013874569790648418,
        "hf_subset": "eng_Latn-tzo_Latn",
        "languages": [
          "eng-Latn",
          "tzo-Latn"
        ],
        "main_score": 0.013874569790648418,
        "precision": 0.01095610119047619,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004723288255360624,
        "hf_subset": "tzo_Latn-eng_Latn",
        "languages": [
          "tzo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004723288255360624,
        "precision": 0.004331836954164257,
        "recall": 0.015625
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.08565848214285714,
        "hf_subset": "eng_Latn-ubr_Latn",
        "languages": [
          "eng-Latn",
          "ubr-Latn"
        ],
        "main_score": 0.08565848214285714,
        "precision": 0.08035026850414079,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07832561728395061,
        "hf_subset": "ubr_Latn-eng_Latn",
        "languages": [
          "ubr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07832561728395061,
        "precision": 0.07340890695382883,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010416666666666668,
        "hf_subset": "eng_Latn-ubu_Latn",
        "languages": [
          "eng-Latn",
          "ubu-Latn"
        ],
        "main_score": 0.010416666666666668,
        "precision": 0.008530560661764705,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004485629759432329,
        "hf_subset": "ubu_Latn-eng_Latn",
        "languages": [
          "ubu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004485629759432329,
        "precision": 0.0042049489425668675,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003955078125,
        "hf_subset": "eng_Latn-udu_Latn",
        "languages": [
          "eng-Latn",
          "udu-Latn"
        ],
        "main_score": 0.003955078125,
        "precision": 0.003930817610062893,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004059436274509804,
        "hf_subset": "udu_Latn-eng_Latn",
        "languages": [
          "udu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004059436274509804,
        "precision": 0.003984375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.026915445665445667,
        "hf_subset": "eng_Latn-uig_Latn",
        "languages": [
          "eng-Latn",
          "uig-Latn"
        ],
        "main_score": 0.026915445665445667,
        "precision": 0.023319659124850657,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018776633522727272,
        "hf_subset": "uig_Latn-eng_Latn",
        "languages": [
          "uig-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018776633522727272,
        "precision": 0.015625,
        "recall": 0.03125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.04544229561342081,
        "hf_subset": "eng_Latn-ukr_Cyrl",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ],
        "main_score": 0.04544229561342081,
        "precision": 0.03453698536706349,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021556332236842106,
        "hf_subset": "ukr_Cyrl-eng_Latn",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.021556332236842106,
        "precision": 0.018365716314935065,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.0994141719187675,
        "hf_subset": "eng_Latn-uli_Latn",
        "languages": [
          "eng-Latn",
          "uli-Latn"
        ],
        "main_score": 0.0994141719187675,
        "precision": 0.09181315104166667,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08526574337121212,
        "hf_subset": "uli_Latn-eng_Latn",
        "languages": [
          "uli-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08526574337121212,
        "precision": 0.0803071639009139,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.09424083769633508,
        "f1": 0.06256896099828037,
        "hf_subset": "eng_Latn-ulk_Latn",
        "languages": [
          "eng-Latn",
          "ulk-Latn"
        ],
        "main_score": 0.06256896099828037,
        "precision": 0.055584642233856896,
        "recall": 0.09424083769633508
      },
      {
        "accuracy": 0.04712041884816754,
        "f1": 0.035270652763723286,
        "hf_subset": "ulk_Latn-eng_Latn",
        "languages": [
          "ulk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.035270652763723286,
        "precision": 0.03261343804537522,
        "recall": 0.04712041884816754
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02208533653846154,
        "hf_subset": "eng_Latn-upv_Latn",
        "languages": [
          "eng-Latn",
          "upv-Latn"
        ],
        "main_score": 0.02208533653846154,
        "precision": 0.019986979166666665,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012006851411696917,
        "hf_subset": "upv_Latn-eng_Latn",
        "languages": [
          "upv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012006851411696917,
        "precision": 0.011865935257177034,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011777935606060604,
        "hf_subset": "eng_Latn-ura_Latn",
        "languages": [
          "eng-Latn",
          "ura-Latn"
        ],
        "main_score": 0.011777935606060604,
        "precision": 0.009114583333333332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004918395748987854,
        "hf_subset": "ura_Latn-eng_Latn",
        "languages": [
          "ura-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004918395748987854,
        "precision": 0.004448784722222222,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005255796033235057,
        "hf_subset": "eng_Latn-urb_Latn",
        "languages": [
          "eng-Latn",
          "urb-Latn"
        ],
        "main_score": 0.005255796033235057,
        "precision": 0.004629907852564103,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007291666666666667,
        "hf_subset": "urb_Latn-eng_Latn",
        "languages": [
          "urb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007291666666666667,
        "precision": 0.006293402777777778,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013470643939393939,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.013470643939393939,
        "precision": 0.011663925438596491,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009013310185185185,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.009013310185185185,
        "precision": 0.007291100789511807,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.08333333333333333,
        "f1": 0.05009524661618257,
        "hf_subset": "eng_Latn-uri_Latn",
        "languages": [
          "eng-Latn",
          "uri-Latn"
        ],
        "main_score": 0.05009524661618257,
        "precision": 0.04489336332823728,
        "recall": 0.08333333333333333
      },
      {
        "accuracy": 0.027777777777777776,
        "f1": 0.023280423280423283,
        "hf_subset": "uri_Latn-eng_Latn",
        "languages": [
          "uri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023280423280423283,
        "precision": 0.0222663139329806,
        "recall": 0.027777777777777776
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.017582677738927736,
        "hf_subset": "eng_Latn-urt_Latn",
        "languages": [
          "eng-Latn",
          "urt-Latn"
        ],
        "main_score": 0.017582677738927736,
        "precision": 0.014455318986568988,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.015775240384615384,
        "hf_subset": "urt_Latn-eng_Latn",
        "languages": [
          "urt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015775240384615384,
        "precision": 0.0157015931372549,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.08888888888888889,
        "f1": 0.06944444444444445,
        "hf_subset": "eng_Latn-urw_Latn",
        "languages": [
          "eng-Latn",
          "urw-Latn"
        ],
        "main_score": 0.06944444444444445,
        "precision": 0.06492063492063492,
        "recall": 0.08888888888888889
      },
      {
        "accuracy": 0.05555555555555555,
        "f1": 0.030968660968660966,
        "hf_subset": "urw_Latn-eng_Latn",
        "languages": [
          "urw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030968660968660966,
        "precision": 0.027645502645502647,
        "recall": 0.05555555555555555
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009895833333333333,
        "hf_subset": "eng_Latn-usa_Latn",
        "languages": [
          "eng-Latn",
          "usa-Latn"
        ],
        "main_score": 0.009895833333333333,
        "precision": 0.00895675505050505,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000244140625,
        "hf_subset": "usa_Latn-eng_Latn",
        "languages": [
          "usa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000244140625,
        "precision": 0.00012600806451612903,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03708316423160173,
        "hf_subset": "eng_Latn-usp_Latn",
        "languages": [
          "eng-Latn",
          "usp-Latn"
        ],
        "main_score": 0.03708316423160173,
        "precision": 0.035032242063492064,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009943181818181818,
        "hf_subset": "usp_Latn-eng_Latn",
        "languages": [
          "usp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009943181818181818,
        "precision": 0.009205426356589146,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011575945755633255,
        "hf_subset": "eng_Latn-uvh_Latn",
        "languages": [
          "eng-Latn",
          "uvh-Latn"
        ],
        "main_score": 0.011575945755633255,
        "precision": 0.009133854306882936,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009013489906832298,
        "hf_subset": "uvh_Latn-eng_Latn",
        "languages": [
          "uvh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009013489906832298,
        "precision": 0.008506467490842492,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.026293682795698922,
        "hf_subset": "eng_Latn-uvl_Latn",
        "languages": [
          "eng-Latn",
          "uvl-Latn"
        ],
        "main_score": 0.026293682795698922,
        "precision": 0.022265624999999997,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011393229166666666,
        "hf_subset": "uvl_Latn-eng_Latn",
        "languages": [
          "uvl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011393229166666666,
        "precision": 0.010323660714285714,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016788474462365588,
        "hf_subset": "eng_Latn-vid_Latn",
        "languages": [
          "eng-Latn",
          "vid-Latn"
        ],
        "main_score": 0.016788474462365588,
        "precision": 0.014127604166666665,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002667682926829268,
        "hf_subset": "vid_Latn-eng_Latn",
        "languages": [
          "vid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002667682926829268,
        "precision": 0.001985143442622951,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01644345238095238,
        "hf_subset": "eng_Latn-vie_Latn",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ],
        "main_score": 0.01644345238095238,
        "precision": 0.014652990238927738,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01521902024371069,
        "hf_subset": "vie_Latn-eng_Latn",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01521902024371069,
        "precision": 0.014151555031202974,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0050347222222222225,
        "hf_subset": "eng_Latn-viv_Latn",
        "languages": [
          "eng-Latn",
          "viv-Latn"
        ],
        "main_score": 0.0050347222222222225,
        "precision": 0.004529229525862069,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0039544753086419755,
        "hf_subset": "viv_Latn-eng_Latn",
        "languages": [
          "viv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0039544753086419755,
        "precision": 0.003930512422360248,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03988095238095238,
        "hf_subset": "eng_Latn-vmy_Latn",
        "languages": [
          "eng-Latn",
          "vmy-Latn"
        ],
        "main_score": 0.03988095238095238,
        "precision": 0.03838641826923077,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005909778225806452,
        "hf_subset": "vmy_Latn-eng_Latn",
        "languages": [
          "vmy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005909778225806452,
        "precision": 0.005233698593073593,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0002232142857142857,
        "hf_subset": "eng_Latn-waj_Latn",
        "languages": [
          "eng-Latn",
          "waj-Latn"
        ],
        "main_score": 0.0002232142857142857,
        "precision": 0.00011488970588235294,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 8.138020833333333e-05,
        "hf_subset": "waj_Latn-eng_Latn",
        "languages": [
          "waj-Latn",
          "eng-Latn"
        ],
        "main_score": 8.138020833333333e-05,
        "precision": 4.111842105263158e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0014280913978494624,
        "hf_subset": "eng_Latn-wal_Ethi",
        "languages": [
          "eng-Latn",
          "wal-Ethi"
        ],
        "main_score": 0.0014280913978494624,
        "precision": 0.0008452868852459016,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00035709308807134894,
        "hf_subset": "wal_Ethi-eng_Latn",
        "languages": [
          "wal-Ethi",
          "eng-Latn"
        ],
        "main_score": 0.00035709308807134894,
        "precision": 0.00018476277372262773,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.10878208705357142,
        "hf_subset": "eng_Latn-wap_Latn",
        "languages": [
          "eng-Latn",
          "wap-Latn"
        ],
        "main_score": 0.10878208705357142,
        "precision": 0.1040756608422939,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.08051530934343434,
        "hf_subset": "wap_Latn-eng_Latn",
        "languages": [
          "wap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08051530934343434,
        "precision": 0.07560007628367003,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.035435267857142856,
        "hf_subset": "eng_Latn-wat_Latn",
        "languages": [
          "eng-Latn",
          "wat-Latn"
        ],
        "main_score": 0.035435267857142856,
        "precision": 0.03190104166666667,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021871878178581806,
        "hf_subset": "wat_Latn-eng_Latn",
        "languages": [
          "wat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021871878178581806,
        "precision": 0.019797129953379955,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01622080176767677,
        "hf_subset": "eng_Latn-wbi_Latn",
        "languages": [
          "eng-Latn",
          "wbi-Latn"
        ],
        "main_score": 0.01622080176767677,
        "precision": 0.014545773237179486,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.014322916666666666,
        "hf_subset": "wbi_Latn-eng_Latn",
        "languages": [
          "wbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014322916666666666,
        "precision": 0.013671875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001697198275862069,
        "hf_subset": "eng_Latn-wbp_Latn",
        "languages": [
          "eng-Latn",
          "wbp-Latn"
        ],
        "main_score": 0.001697198275862069,
        "precision": 0.001045093201754386,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00146875,
        "hf_subset": "wbp_Latn-eng_Latn",
        "languages": [
          "wbp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00146875,
        "precision": 0.0008655391782911944,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.109375,
        "f1": 0.06739831349206349,
        "hf_subset": "eng_Latn-wed_Latn",
        "languages": [
          "eng-Latn",
          "wed-Latn"
        ],
        "main_score": 0.06739831349206349,
        "precision": 0.05610405219780219,
        "recall": 0.109375
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.08444464877570346,
        "hf_subset": "wed_Latn-eng_Latn",
        "languages": [
          "wed-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08444464877570346,
        "precision": 0.07645878427128427,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013041958041958042,
        "hf_subset": "eng_Latn-wer_Latn",
        "languages": [
          "eng-Latn",
          "wer-Latn"
        ],
        "main_score": 0.013041958041958042,
        "precision": 0.011256510416666667,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003978240184294872,
        "hf_subset": "wer_Latn-eng_Latn",
        "languages": [
          "wer-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003978240184294872,
        "precision": 0.002695763437950938,
        "recall": 0.015625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05748221544715447,
        "hf_subset": "eng_Latn-wim_Latn",
        "languages": [
          "eng-Latn",
          "wim-Latn"
        ],
        "main_score": 0.05748221544715447,
        "precision": 0.05082310267857143,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.0655702674062049,
        "hf_subset": "wim_Latn-eng_Latn",
        "languages": [
          "wim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0655702674062049,
        "precision": 0.062242445054945056,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007161458333333333,
        "hf_subset": "eng_Latn-wiu_Latn",
        "languages": [
          "eng-Latn",
          "wiu-Latn"
        ],
        "main_score": 0.007161458333333333,
        "precision": 0.006214488636363636,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "wiu_Latn-eng_Latn",
        "languages": [
          "wiu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04112796160130719,
        "hf_subset": "eng_Latn-wiv_Latn",
        "languages": [
          "eng-Latn",
          "wiv-Latn"
        ],
        "main_score": 0.04112796160130719,
        "precision": 0.0354371377320596,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018808917797888385,
        "hf_subset": "wiv_Latn-eng_Latn",
        "languages": [
          "wiv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018808917797888385,
        "precision": 0.01788330078125,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004774305555555556,
        "hf_subset": "eng_Latn-wmt_Latn",
        "languages": [
          "eng-Latn",
          "wmt-Latn"
        ],
        "main_score": 0.004774305555555556,
        "precision": 0.003154451884920635,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003296224704085529,
        "hf_subset": "wmt_Latn-eng_Latn",
        "languages": [
          "wmt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003296224704085529,
        "precision": 0.0001704800219210841,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01929139254385965,
        "hf_subset": "eng_Latn-wmw_Latn",
        "languages": [
          "eng-Latn",
          "wmw-Latn"
        ],
        "main_score": 0.01929139254385965,
        "precision": 0.017024168494152045,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007860725308641976,
        "hf_subset": "wmw_Latn-eng_Latn",
        "languages": [
          "wmw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007860725308641976,
        "precision": 0.007836762422360248,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0044921875,
        "hf_subset": "eng_Latn-wnc_Latn",
        "languages": [
          "eng-Latn",
          "wnc-Latn"
        ],
        "main_score": 0.0044921875,
        "precision": 0.003099524456521739,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "wnc_Latn-eng_Latn",
        "languages": [
          "wnc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019416877815315318,
        "hf_subset": "eng_Latn-wnu_Latn",
        "languages": [
          "eng-Latn",
          "wnu-Latn"
        ],
        "main_score": 0.019416877815315318,
        "precision": 0.017205427234299516,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006161156551781552,
        "hf_subset": "wnu_Latn-eng_Latn",
        "languages": [
          "wnu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006161156551781552,
        "precision": 0.0053625274122807015,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014681069000180718,
        "hf_subset": "eng_Latn-wol_Latn",
        "languages": [
          "eng-Latn",
          "wol-Latn"
        ],
        "main_score": 0.014681069000180718,
        "precision": 0.013317232494591966,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019803159393047838,
        "hf_subset": "wol_Latn-eng_Latn",
        "languages": [
          "wol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019803159393047838,
        "precision": 0.01707558348183348,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.018229166666666668,
        "hf_subset": "eng_Latn-wos_Latn",
        "languages": [
          "eng-Latn",
          "wos-Latn"
        ],
        "main_score": 0.018229166666666668,
        "precision": 0.017578125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011820211038961038,
        "hf_subset": "wos_Latn-eng_Latn",
        "languages": [
          "wos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011820211038961038,
        "precision": 0.01177014802631579,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002666170634920635,
        "hf_subset": "eng_Latn-wrk_Latn",
        "languages": [
          "eng-Latn",
          "wrk-Latn"
        ],
        "main_score": 0.002666170634920635,
        "precision": 0.0015937500000000001,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000244140625,
        "hf_subset": "wrk_Latn-eng_Latn",
        "languages": [
          "wrk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000244140625,
        "precision": 0.00012600806451612903,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.21875,
        "f1": 0.14889864532357738,
        "hf_subset": "eng_Latn-wro_Latn",
        "languages": [
          "eng-Latn",
          "wro-Latn"
        ],
        "main_score": 0.14889864532357738,
        "precision": 0.13187412630772005,
        "recall": 0.21875
      },
      {
        "accuracy": 0.19921875,
        "f1": 0.16303824721377913,
        "hf_subset": "wro_Latn-eng_Latn",
        "languages": [
          "wro-Latn",
          "eng-Latn"
        ],
        "main_score": 0.16303824721377913,
        "precision": 0.15296786452526942,
        "recall": 0.19921875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.010416666666666666,
        "hf_subset": "eng_Latn-wrs_Latn",
        "languages": [
          "eng-Latn",
          "wrs-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.009765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008370535714285714,
        "hf_subset": "wrs_Latn-eng_Latn",
        "languages": [
          "wrs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008370535714285714,
        "precision": 0.006941105769230769,
        "recall": 0.015625
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.09200972261434218,
        "hf_subset": "eng_Latn-wsk_Latn",
        "languages": [
          "eng-Latn",
          "wsk-Latn"
        ],
        "main_score": 0.09200972261434218,
        "precision": 0.08217329545454546,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.125,
        "f1": 0.10132693997410284,
        "hf_subset": "wsk_Latn-eng_Latn",
        "languages": [
          "wsk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.10132693997410284,
        "precision": 0.09496444310897435,
        "recall": 0.125
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.10690597380050505,
        "hf_subset": "eng_Latn-wuv_Latn",
        "languages": [
          "eng-Latn",
          "wuv-Latn"
        ],
        "main_score": 0.10690597380050505,
        "precision": 0.09855257207049486,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.09976933331425519,
        "hf_subset": "wuv_Latn-eng_Latn",
        "languages": [
          "wuv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09976933331425519,
        "precision": 0.09424930013702695,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01816907051282051,
        "hf_subset": "eng_Latn-xav_Latn",
        "languages": [
          "eng-Latn",
          "xav-Latn"
        ],
        "main_score": 0.01816907051282051,
        "precision": 0.015836302997076022,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027636054421768708,
        "hf_subset": "xav_Latn-eng_Latn",
        "languages": [
          "xav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027636054421768708,
        "precision": 0.0020345052083333335,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016648065476190476,
        "hf_subset": "eng_Latn-xbi_Latn",
        "languages": [
          "eng-Latn",
          "xbi-Latn"
        ],
        "main_score": 0.016648065476190476,
        "precision": 0.013718938253012047,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.031454613095238095,
        "hf_subset": "xbi_Latn-eng_Latn",
        "languages": [
          "xbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.031454613095238095,
        "precision": 0.028725007988794064,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011988146551724137,
        "hf_subset": "eng_Latn-xed_Latn",
        "languages": [
          "eng-Latn",
          "xed-Latn"
        ],
        "main_score": 0.011988146551724137,
        "precision": 0.010686383928571429,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011930628867855843,
        "hf_subset": "xed_Latn-eng_Latn",
        "languages": [
          "xed-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011930628867855843,
        "precision": 0.011826160914702582,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008220223063973063,
        "hf_subset": "eng_Latn-xla_Latn",
        "languages": [
          "eng-Latn",
          "xla-Latn"
        ],
        "main_score": 0.008220223063973063,
        "precision": 0.008022836538461538,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007621677442528735,
        "hf_subset": "xla_Latn-eng_Latn",
        "languages": [
          "xla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007621677442528735,
        "precision": 0.0060953164160401,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.024317620313714063,
        "hf_subset": "eng_Latn-xnn_Latn",
        "languages": [
          "eng-Latn",
          "xnn-Latn"
        ],
        "main_score": 0.024317620313714063,
        "precision": 0.021146594291125538,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.034486130189255185,
        "hf_subset": "xnn_Latn-eng_Latn",
        "languages": [
          "xnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.034486130189255185,
        "precision": 0.030869943858225113,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01586222888127854,
        "hf_subset": "eng_Latn-xon_Latn",
        "languages": [
          "eng-Latn",
          "xon-Latn"
        ],
        "main_score": 0.01586222888127854,
        "precision": 0.012699962797619046,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.022234309071729956,
        "hf_subset": "xon_Latn-eng_Latn",
        "languages": [
          "xon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022234309071729956,
        "precision": 0.021534455128205128,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009824810606060606,
        "hf_subset": "eng_Latn-xsi_Latn",
        "languages": [
          "eng-Latn",
          "xsi-Latn"
        ],
        "main_score": 0.009824810606060606,
        "precision": 0.0078125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010729166666666666,
        "hf_subset": "xsi_Latn-eng_Latn",
        "languages": [
          "xsi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010729166666666666,
        "precision": 0.009928385416666668,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.034564393939393936,
        "hf_subset": "eng_Latn-xtd_Latn",
        "languages": [
          "eng-Latn",
          "xtd-Latn"
        ],
        "main_score": 0.034564393939393936,
        "precision": 0.03359375,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.020182291666666664,
        "hf_subset": "xtd_Latn-eng_Latn",
        "languages": [
          "xtd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020182291666666664,
        "precision": 0.017708333333333333,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02734375,
        "hf_subset": "eng_Latn-xtm_Latn",
        "languages": [
          "eng-Latn",
          "xtm-Latn"
        ],
        "main_score": 0.02734375,
        "precision": 0.022600446428571428,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.010090468778507573,
        "hf_subset": "xtm_Latn-eng_Latn",
        "languages": [
          "xtm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010090468778507573,
        "precision": 0.0076776881122318395,
        "recall": 0.03125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.021918402777777776,
        "hf_subset": "eng_Latn-yaa_Latn",
        "languages": [
          "eng-Latn",
          "yaa-Latn"
        ],
        "main_score": 0.021918402777777776,
        "precision": 0.018238593514328806,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014547821969696971,
        "hf_subset": "yaa_Latn-eng_Latn",
        "languages": [
          "yaa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014547821969696971,
        "precision": 0.012313988095238095,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006119791666666667,
        "hf_subset": "eng_Latn-yad_Latn",
        "languages": [
          "eng-Latn",
          "yad-Latn"
        ],
        "main_score": 0.006119791666666667,
        "precision": 0.004231770833333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007494212962962962,
        "hf_subset": "yad_Latn-eng_Latn",
        "languages": [
          "yad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007494212962962962,
        "precision": 0.006044082296380091,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013349454365079364,
        "hf_subset": "eng_Latn-yal_Latn",
        "languages": [
          "eng-Latn",
          "yal-Latn"
        ],
        "main_score": 0.013349454365079364,
        "precision": 0.011436060855263159,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005939916237113402,
        "hf_subset": "yal_Latn-eng_Latn",
        "languages": [
          "yal-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005939916237113402,
        "precision": 0.0052490234375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06709324204441391,
        "hf_subset": "eng_Latn-yap_Latn",
        "languages": [
          "eng-Latn",
          "yap-Latn"
        ],
        "main_score": 0.06709324204441391,
        "precision": 0.06296369121469927,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.09375,
        "f1": 0.07728247549019607,
        "hf_subset": "yap_Latn-eng_Latn",
        "languages": [
          "yap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07728247549019607,
        "precision": 0.07372504340277777,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004175646551724138,
        "hf_subset": "eng_Latn-yaq_Latn",
        "languages": [
          "eng-Latn",
          "yaq-Latn"
        ],
        "main_score": 0.004175646551724138,
        "precision": 0.004045758928571429,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "yaq_Latn-eng_Latn",
        "languages": [
          "yaq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0077563757183908046,
        "hf_subset": "eng_Latn-yby_Latn",
        "languages": [
          "eng-Latn",
          "yby-Latn"
        ],
        "main_score": 0.0077563757183908046,
        "precision": 0.006556919642857142,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0031249999999999997,
        "hf_subset": "yby_Latn-eng_Latn",
        "languages": [
          "yby-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0031249999999999997,
        "precision": 0.002232142857142857,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005859375,
        "hf_subset": "eng_Latn-ycn_Latn",
        "languages": [
          "eng-Latn",
          "ycn-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005022321428571428,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004764976904223228,
        "hf_subset": "ycn_Latn-eng_Latn",
        "languages": [
          "ycn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004764976904223228,
        "precision": 0.0033607366557734204,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0126953125,
        "hf_subset": "eng_Latn-yka_Latn",
        "languages": [
          "eng-Latn",
          "yka-Latn"
        ],
        "main_score": 0.0126953125,
        "precision": 0.009584901059085842,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017299107142857144,
        "hf_subset": "yka_Latn-eng_Latn",
        "languages": [
          "yka-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017299107142857144,
        "precision": 0.01657652243589744,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012736344537815126,
        "hf_subset": "eng_Latn-yle_Latn",
        "languages": [
          "eng-Latn",
          "yle-Latn"
        ],
        "main_score": 0.012736344537815126,
        "precision": 0.009789413060897435,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003720238095238095,
        "hf_subset": "yle_Latn-eng_Latn",
        "languages": [
          "yle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003720238095238095,
        "precision": 0.0001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005208333333333333,
        "hf_subset": "eng_Latn-yml_Latn",
        "languages": [
          "eng-Latn",
          "yml-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.0046875,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009765625,
        "hf_subset": "yml_Latn-eng_Latn",
        "languages": [
          "yml-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.009114583333333334,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02604349860209235,
        "hf_subset": "eng_Latn-yon_Latn",
        "languages": [
          "eng-Latn",
          "yon-Latn"
        ],
        "main_score": 0.02604349860209235,
        "precision": 0.020345052083333332,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0057295759959327935,
        "hf_subset": "yon_Latn-eng_Latn",
        "languages": [
          "yon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0057295759959327935,
        "precision": 0.0037815581961951443,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.029188368055555556,
        "hf_subset": "eng_Latn-yor_Latn",
        "languages": [
          "eng-Latn",
          "yor-Latn"
        ],
        "main_score": 0.029188368055555556,
        "precision": 0.025265066964285716,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.026403356481481483,
        "hf_subset": "yor_Latn-eng_Latn",
        "languages": [
          "yor-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026403356481481483,
        "precision": 0.025301567413522012,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0071906887755102036,
        "hf_subset": "eng_Latn-yrb_Latn",
        "languages": [
          "eng-Latn",
          "yrb-Latn"
        ],
        "main_score": 0.0071906887755102036,
        "precision": 0.005940755208333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004014756944444444,
        "hf_subset": "yrb_Latn-eng_Latn",
        "languages": [
          "yrb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004014756944444444,
        "precision": 0.003961267605633803,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002959280303030303,
        "hf_subset": "eng_Latn-yre_Latn",
        "languages": [
          "eng-Latn",
          "yre-Latn"
        ],
        "main_score": 0.002959280303030303,
        "precision": 0.002139136904761905,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.975446428571428e-05,
        "hf_subset": "yre_Latn-eng_Latn",
        "languages": [
          "yre-Latn",
          "eng-Latn"
        ],
        "main_score": 6.975446428571428e-05,
        "precision": 3.519144144144144e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.028004092261904763,
        "hf_subset": "eng_Latn-yss_Latn",
        "languages": [
          "eng-Latn",
          "yss-Latn"
        ],
        "main_score": 0.028004092261904763,
        "precision": 0.02269345238095238,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01650774952584163,
        "hf_subset": "yss_Latn-eng_Latn",
        "languages": [
          "yss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01650774952584163,
        "precision": 0.014973958333333332,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008289930555555556,
        "hf_subset": "eng_Latn-yuj_Latn",
        "languages": [
          "eng-Latn",
          "yuj-Latn"
        ],
        "main_score": 0.008289930555555556,
        "precision": 0.00806198255470136,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.015625,
        "hf_subset": "yuj_Latn-eng_Latn",
        "languages": [
          "yuj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015625,
        "precision": 0.015625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03680893759018759,
        "hf_subset": "eng_Latn-yut_Latn",
        "languages": [
          "eng-Latn",
          "yut-Latn"
        ],
        "main_score": 0.03680893759018759,
        "precision": 0.03128255208333333,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00820943138651472,
        "hf_subset": "yut_Latn-eng_Latn",
        "languages": [
          "yut-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00820943138651472,
        "precision": 0.008017578125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019137806637806634,
        "hf_subset": "eng_Latn-yuw_Latn",
        "languages": [
          "eng-Latn",
          "yuw-Latn"
        ],
        "main_score": 0.019137806637806634,
        "precision": 0.015176782852564102,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004076086956521739,
        "hf_subset": "yuw_Latn-eng_Latn",
        "languages": [
          "yuw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004076086956521739,
        "precision": 0.003993055555555555,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014352509469696968,
        "hf_subset": "eng_Latn-yva_Latn",
        "languages": [
          "eng-Latn",
          "yva-Latn"
        ],
        "main_score": 0.014352509469696968,
        "precision": 0.012462797619047618,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019759114583333334,
        "hf_subset": "yva_Latn-eng_Latn",
        "languages": [
          "yva-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019759114583333334,
        "precision": 0.016164434523809522,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.050449051816239314,
        "hf_subset": "eng_Latn-zaa_Latn",
        "languages": [
          "eng-Latn",
          "zaa-Latn"
        ],
        "main_score": 0.050449051816239314,
        "precision": 0.04375656512605042,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04252852182539682,
        "hf_subset": "zaa_Latn-eng_Latn",
        "languages": [
          "zaa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04252852182539682,
        "precision": 0.03776327838827839,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.037487934362934364,
        "hf_subset": "eng_Latn-zab_Latn",
        "languages": [
          "eng-Latn",
          "zab-Latn"
        ],
        "main_score": 0.037487934362934364,
        "precision": 0.031984508547008544,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018147786458333336,
        "hf_subset": "zab_Latn-eng_Latn",
        "languages": [
          "zab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018147786458333336,
        "precision": 0.016013115748498813,
        "recall": 0.03125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05236235119047619,
        "hf_subset": "eng_Latn-zac_Latn",
        "languages": [
          "eng-Latn",
          "zac-Latn"
        ],
        "main_score": 0.05236235119047619,
        "precision": 0.04573567708333333,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.031708359638047134,
        "hf_subset": "zac_Latn-eng_Latn",
        "languages": [
          "zac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.031708359638047134,
        "precision": 0.0269967797532656,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.025204613095238096,
        "hf_subset": "eng_Latn-zad_Latn",
        "languages": [
          "eng-Latn",
          "zad-Latn"
        ],
        "main_score": 0.025204613095238096,
        "precision": 0.0232717803030303,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008543261054421769,
        "hf_subset": "zad_Latn-eng_Latn",
        "languages": [
          "zad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008543261054421769,
        "precision": 0.007201728951890035,
        "recall": 0.015625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04930441337719298,
        "hf_subset": "eng_Latn-zai_Latn",
        "languages": [
          "eng-Latn",
          "zai-Latn"
        ],
        "main_score": 0.04930441337719298,
        "precision": 0.046068274456521736,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02495828823953824,
        "hf_subset": "zai_Latn-eng_Latn",
        "languages": [
          "zai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02495828823953824,
        "precision": 0.02061453086843712,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007552083333333333,
        "hf_subset": "eng_Latn-zaj_Latn",
        "languages": [
          "eng-Latn",
          "zaj-Latn"
        ],
        "main_score": 0.007552083333333333,
        "precision": 0.004926215277777778,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0027561706310040793,
        "hf_subset": "zaj_Latn-eng_Latn",
        "languages": [
          "zaj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027561706310040793,
        "precision": 0.0017258659836784835,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.025895182291666666,
        "hf_subset": "eng_Latn-zam_Latn",
        "languages": [
          "eng-Latn",
          "zam-Latn"
        ],
        "main_score": 0.025895182291666666,
        "precision": 0.02388902889784946,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.023772321428571427,
        "hf_subset": "zam_Latn-eng_Latn",
        "languages": [
          "zam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023772321428571427,
        "precision": 0.020182291666666664,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018136160714285712,
        "hf_subset": "eng_Latn-zao_Latn",
        "languages": [
          "eng-Latn",
          "zao-Latn"
        ],
        "main_score": 0.018136160714285712,
        "precision": 0.017227564102564104,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012575383771929825,
        "hf_subset": "zao_Latn-eng_Latn",
        "languages": [
          "zao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012575383771929825,
        "precision": 0.011173282657657659,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03236060049019608,
        "hf_subset": "eng_Latn-zap_Latn",
        "languages": [
          "eng-Latn",
          "zap-Latn"
        ],
        "main_score": 0.03236060049019608,
        "precision": 0.027587890625,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021754092261904764,
        "hf_subset": "zap_Latn-eng_Latn",
        "languages": [
          "zap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021754092261904764,
        "precision": 0.02001764320238585,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01987847222222222,
        "hf_subset": "eng_Latn-zar_Latn",
        "languages": [
          "eng-Latn",
          "zar-Latn"
        ],
        "main_score": 0.01987847222222222,
        "precision": 0.016026475694444445,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012517197327044025,
        "hf_subset": "zar_Latn-eng_Latn",
        "languages": [
          "zar-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012517197327044025,
        "precision": 0.011142828525641026,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03262590958931419,
        "hf_subset": "eng_Latn-zas_Latn",
        "languages": [
          "eng-Latn",
          "zas-Latn"
        ],
        "main_score": 0.03262590958931419,
        "precision": 0.02948097909035409,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010966614906832298,
        "hf_subset": "zas_Latn-eng_Latn",
        "languages": [
          "zas-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010966614906832298,
        "precision": 0.009808550824175824,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.036062823172198166,
        "hf_subset": "eng_Latn-zat_Latn",
        "languages": [
          "eng-Latn",
          "zat-Latn"
        ],
        "main_score": 0.036062823172198166,
        "precision": 0.03203554258241759,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01021515376984127,
        "hf_subset": "zat_Latn-eng_Latn",
        "languages": [
          "zat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01021515376984127,
        "precision": 0.008120057309085842,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02462396355908584,
        "hf_subset": "eng_Latn-zav_Latn",
        "languages": [
          "eng-Latn",
          "zav-Latn"
        ],
        "main_score": 0.02462396355908584,
        "precision": 0.022550243981165036,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015885416666666666,
        "hf_subset": "zav_Latn-eng_Latn",
        "languages": [
          "zav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015885416666666666,
        "precision": 0.014457614942528736,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.0397808908045977,
        "hf_subset": "eng_Latn-zaw_Latn",
        "languages": [
          "eng-Latn",
          "zaw-Latn"
        ],
        "main_score": 0.0397808908045977,
        "precision": 0.038445425724637675,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.028915550595238093,
        "hf_subset": "zaw_Latn-eng_Latn",
        "languages": [
          "zaw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028915550595238093,
        "precision": 0.02590215773809524,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024023437499999998,
        "hf_subset": "eng_Latn-zca_Latn",
        "languages": [
          "eng-Latn",
          "zca-Latn"
        ],
        "main_score": 0.024023437499999998,
        "precision": 0.01920984642621871,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018532027867965366,
        "hf_subset": "zca_Latn-eng_Latn",
        "languages": [
          "zca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018532027867965366,
        "precision": 0.017277489543114546,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03247982486263736,
        "hf_subset": "eng_Latn-zga_Latn",
        "languages": [
          "eng-Latn",
          "zga-Latn"
        ],
        "main_score": 0.03247982486263736,
        "precision": 0.02928586704911433,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.010416666666666666,
        "hf_subset": "zga_Latn-eng_Latn",
        "languages": [
          "zga-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.009765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015959821428571427,
        "hf_subset": "eng_Latn-zia_Latn",
        "languages": [
          "eng-Latn",
          "zia-Latn"
        ],
        "main_score": 0.015959821428571427,
        "precision": 0.012178969109195402,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020399305555555557,
        "hf_subset": "zia_Latn-eng_Latn",
        "languages": [
          "zia-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0020399305555555557,
        "precision": 0.0013459737827715354,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008190403496168583,
        "hf_subset": "eng_Latn-ziw_Latn",
        "languages": [
          "eng-Latn",
          "ziw-Latn"
        ],
        "main_score": 0.008190403496168583,
        "precision": 0.005580357142857142,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.5407801418439715e-05,
        "hf_subset": "ziw_Latn-eng_Latn",
        "languages": [
          "ziw-Latn",
          "eng-Latn"
        ],
        "main_score": 5.5407801418439715e-05,
        "precision": 2.7901785714285713e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05358162922427035,
        "hf_subset": "eng_Latn-zlm_Latn",
        "languages": [
          "eng-Latn",
          "zlm-Latn"
        ],
        "main_score": 0.05358162922427035,
        "precision": 0.0455078125,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.04436848958333333,
        "hf_subset": "zlm_Latn-eng_Latn",
        "languages": [
          "zlm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04436848958333333,
        "precision": 0.0426077178030303,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.053962783029878614,
        "hf_subset": "eng_Latn-zos_Latn",
        "languages": [
          "eng-Latn",
          "zos-Latn"
        ],
        "main_score": 0.053962783029878614,
        "precision": 0.04710710456057423,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.033062826188340166,
        "hf_subset": "zos_Latn-eng_Latn",
        "languages": [
          "zos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.033062826188340166,
        "precision": 0.0310168736668712,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03124302455357143,
        "hf_subset": "eng_Latn-zpc_Latn",
        "languages": [
          "eng-Latn",
          "zpc-Latn"
        ],
        "main_score": 0.03124302455357143,
        "precision": 0.025879356278801842,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01522037838414718,
        "hf_subset": "zpc_Latn-eng_Latn",
        "languages": [
          "zpc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01522037838414718,
        "precision": 0.01414853050595238,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.035590277777777776,
        "hf_subset": "eng_Latn-zpl_Latn",
        "languages": [
          "eng-Latn",
          "zpl-Latn"
        ],
        "main_score": 0.035590277777777776,
        "precision": 0.03095894607843137,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01642646499238965,
        "hf_subset": "zpl_Latn-eng_Latn",
        "languages": [
          "zpl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01642646499238965,
        "precision": 0.014664702625475073,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.027793560606060606,
        "hf_subset": "eng_Latn-zpm_Latn",
        "languages": [
          "eng-Latn",
          "zpm-Latn"
        ],
        "main_score": 0.027793560606060606,
        "precision": 0.02601996527777778,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021088986280487804,
        "hf_subset": "zpm_Latn-eng_Latn",
        "languages": [
          "zpm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021088986280487804,
        "precision": 0.01922065906954887,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02826450892857143,
        "hf_subset": "eng_Latn-zpo_Latn",
        "languages": [
          "eng-Latn",
          "zpo-Latn"
        ],
        "main_score": 0.02826450892857143,
        "precision": 0.02325768849206349,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019355572089947086,
        "hf_subset": "zpo_Latn-eng_Latn",
        "languages": [
          "zpo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019355572089947086,
        "precision": 0.01795384810819262,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015885416666666666,
        "hf_subset": "eng_Latn-zpq_Latn",
        "languages": [
          "eng-Latn",
          "zpq-Latn"
        ],
        "main_score": 0.015885416666666666,
        "precision": 0.014257812500000001,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014499495489078822,
        "hf_subset": "zpq_Latn-eng_Latn",
        "languages": [
          "zpq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014499495489078822,
        "precision": 0.011820281498015874,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.037621753246753244,
        "hf_subset": "eng_Latn-zpu_Latn",
        "languages": [
          "eng-Latn",
          "zpu-Latn"
        ],
        "main_score": 0.037621753246753244,
        "precision": 0.03388439546578455,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016668911637931036,
        "hf_subset": "zpu_Latn-eng_Latn",
        "languages": [
          "zpu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016668911637931036,
        "precision": 0.01621700310559006,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.031036086309523807,
        "hf_subset": "eng_Latn-zpv_Latn",
        "languages": [
          "eng-Latn",
          "zpv-Latn"
        ],
        "main_score": 0.031036086309523807,
        "precision": 0.025028617216117217,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01699810606060606,
        "hf_subset": "zpv_Latn-eng_Latn",
        "languages": [
          "zpv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01699810606060606,
        "precision": 0.0156608371559633,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.027299783549783546,
        "hf_subset": "eng_Latn-zpz_Latn",
        "languages": [
          "eng-Latn",
          "zpz-Latn"
        ],
        "main_score": 0.027299783549783546,
        "precision": 0.02572337962962963,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013105751811594202,
        "hf_subset": "zpz_Latn-eng_Latn",
        "languages": [
          "zpz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013105751811594202,
        "precision": 0.011761675824175824,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03715080492424242,
        "hf_subset": "eng_Latn-zsr_Latn",
        "languages": [
          "eng-Latn",
          "zsr-Latn"
        ],
        "main_score": 0.03715080492424242,
        "precision": 0.033185686383928575,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013862987231182794,
        "hf_subset": "zsr_Latn-eng_Latn",
        "languages": [
          "zsr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013862987231182794,
        "precision": 0.011798287877309393,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03082873774509804,
        "hf_subset": "eng_Latn-ztq_Latn",
        "languages": [
          "eng-Latn",
          "ztq-Latn"
        ],
        "main_score": 0.03082873774509804,
        "precision": 0.028764204545454544,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018529647435897436,
        "hf_subset": "ztq_Latn-eng_Latn",
        "languages": [
          "ztq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018529647435897436,
        "precision": 0.016499310661764705,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018998579545454544,
        "hf_subset": "eng_Latn-zty_Latn",
        "languages": [
          "eng-Latn",
          "zty-Latn"
        ],
        "main_score": 0.018998579545454544,
        "precision": 0.016536458333333334,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007899305555555555,
        "hf_subset": "zty_Latn-eng_Latn",
        "languages": [
          "zty-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007899305555555555,
        "precision": 0.006626674107142857,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02130174512987013,
        "hf_subset": "eng_Latn-zyp_Latn",
        "languages": [
          "eng-Latn",
          "zyp-Latn"
        ],
        "main_score": 0.02130174512987013,
        "precision": 0.016739888146734522,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.024962797619047617,
        "hf_subset": "zyp_Latn-eng_Latn",
        "languages": [
          "zyp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024962797619047617,
        "precision": 0.022250306372549017,
        "recall": 0.03515625
      }
    ]
  },
  "task_name": "BibleNLPBitextMining"
}