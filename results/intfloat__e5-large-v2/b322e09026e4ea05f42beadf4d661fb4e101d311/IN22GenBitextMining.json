{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 79.78099274635315,
  "kg_co2_emissions": 0.004481961092196336,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.2724609375,
        "f1": 0.22183604235965215,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.22183604235965215,
        "precision": 0.20607390520720598,
        "recall": 0.2724609375
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.03213491871673767,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.03213491871673767,
        "precision": 0.028292220969287168,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.027799126871392493,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.027799126871392493,
        "precision": 0.02356942283700096,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017789496268346945,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0017789496268346945,
        "precision": 0.0014826420589030905,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.032712766693991494,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.032712766693991494,
        "precision": 0.028099156542740047,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.004791507967698744,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.004791507967698744,
        "precision": 0.003541983190302558,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.039103868358078005,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.039103868358078005,
        "precision": 0.035295916055224176,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006702255793484925,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.006702255793484925,
        "precision": 0.005757360201362052,
        "recall": 0.015625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.00997475921792328,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.00997475921792328,
        "precision": 0.008860109145647528,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.0771628382075478,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0771628382075478,
        "precision": 0.07048284018498863,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002453559599578504,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.002453559599578504,
        "precision": 0.0022220501941929817,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.04234254351411617,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.04234254351411617,
        "precision": 0.03755649515415141,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006910790940269885,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.006910790940269885,
        "precision": 0.006206159391773616,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.058978506015935184,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.058978506015935184,
        "precision": 0.05158323984320844,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.012692257587782883,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.012692257587782883,
        "precision": 0.011112705419920495,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.008183951106267242,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.008183951106267242,
        "precision": 0.006625076687609209,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.04529489291512194,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.04529489291512194,
        "precision": 0.03959529504671894,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013189531159525187,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0013189531159525187,
        "precision": 0.0009124961255756287,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.030388207610603953,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.030388207610603953,
        "precision": 0.027815450875635906,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.00717749841909544,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.00717749841909544,
        "precision": 0.005830439814814814,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0035845250763822806,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0035845250763822806,
        "precision": 0.002663704617133319,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.017172443441974692,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.017172443441974692,
        "precision": 0.016370271381578948,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.2412109375,
        "f1": 0.1891043706499093,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.1891043706499093,
        "precision": 0.17433697344632848,
        "recall": 0.2412109375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03838463242395573,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.03838463242395573,
        "precision": 0.035494155732671,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0947265625,
        "f1": 0.06744427087610132,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.06744427087610132,
        "precision": 0.061383506481807626,
        "recall": 0.0947265625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00140625,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.00140625,
        "precision": 0.0012406329719387755,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.05988050816295137,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.05988050816295137,
        "precision": 0.054935618637689976,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003473730690780125,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.003473730690780125,
        "precision": 0.0029820260833563973,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.08045540685325386,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.08045540685325386,
        "precision": 0.07357532586488855,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005251353112461266,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.005251353112461266,
        "precision": 0.0046743853335632695,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.01859878513930492,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.01859878513930492,
        "precision": 0.01598204629126302,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.147195790033853,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.147195790033853,
        "precision": 0.13507040621054295,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0013800091770288124,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0013800091770288124,
        "precision": 0.0011977799540565544,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.08526221483418414,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.08526221483418414,
        "precision": 0.0783828433841888,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0028993477209895923,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0028993477209895923,
        "precision": 0.0024825090838333976,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.158203125,
        "f1": 0.11629213864937307,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.11629213864937307,
        "precision": 0.10623309202421907,
        "recall": 0.158203125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003304147513002542,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.003304147513002542,
        "precision": 0.003137610887676988,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0028797664284634,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0028797664284634,
        "precision": 0.0025470067584325395,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.08078052569635387,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.08078052569635387,
        "precision": 0.07426688938088068,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9073486328125e-06,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 1.9073486328125e-06,
        "precision": 9.546065493646139e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.045823580318057985,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.045823580318057985,
        "precision": 0.04114041057296092,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007746409406565656,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.007746409406565656,
        "precision": 0.006548008325926525,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.001835481702803901,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.001835481702803901,
        "precision": 0.0015015231365975218,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.026186385856924507,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.026186385856924507,
        "precision": 0.0233907386739418,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.03791117716795077,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.03791117716795077,
        "precision": 0.03343113862715644,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07184894845909168,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.07184894845909168,
        "precision": 0.06488979223482719,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.388671875,
        "f1": 0.3578586664694001,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3578586664694001,
        "precision": 0.3487907554570795,
        "recall": 0.388671875
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.06528444220469594,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06528444220469594,
        "precision": 0.06149366349130825,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.384765625,
        "f1": 0.35214934613487003,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.35214934613487003,
        "precision": 0.3416961396033781,
        "recall": 0.384765625
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.028410351839235116,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.028410351839235116,
        "precision": 0.023382722465487955,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.376953125,
        "f1": 0.3407229588094708,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.3407229588094708,
        "precision": 0.3304249217579296,
        "recall": 0.376953125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006042115058512224,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.006042115058512224,
        "precision": 0.005273966555598688,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.2861328125,
        "f1": 0.26758018362977604,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.26758018362977604,
        "precision": 0.2613315629874109,
        "recall": 0.2861328125
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.14247118612609977,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.14247118612609977,
        "precision": 0.13117298092022356,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.1826171875,
        "f1": 0.1561400761032396,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1561400761032396,
        "precision": 0.14741402781461183,
        "recall": 0.1826171875
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.09207366441184678,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09207366441184678,
        "precision": 0.08013836044597764,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0018276282281535516,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0018276282281535516,
        "precision": 0.001568832314638937,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.10126761137760315,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.10126761137760315,
        "precision": 0.09208130491031223,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.00597898762259997,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.00597898762259997,
        "precision": 0.005262348916035111,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.240234375,
        "f1": 0.21553504915691282,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.21553504915691282,
        "precision": 0.20809019143117138,
        "recall": 0.240234375
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.10331152851208597,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.10331152851208597,
        "precision": 0.09305570967971313,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001584174608071667,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001584174608071667,
        "precision": 0.0013382691880576272,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.3857421875,
        "f1": 0.35534157772927305,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.35534157772927305,
        "precision": 0.3453244834592491,
        "recall": 0.3857421875
      },
      {
        "accuracy": 0.2109375,
        "f1": 0.1840874674370768,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.1840874674370768,
        "precision": 0.17429200586484594,
        "recall": 0.2109375
      },
      {
        "accuracy": 0.216796875,
        "f1": 0.19208178390492736,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.19208178390492736,
        "precision": 0.18434976136001902,
        "recall": 0.216796875
      },
      {
        "accuracy": 0.2998046875,
        "f1": 0.27775257140748505,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.27775257140748505,
        "precision": 0.27098656504651747,
        "recall": 0.2998046875
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.0387948719310002,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0387948719310002,
        "precision": 0.03331343763601165,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.1196114188545829,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.1196114188545829,
        "precision": 0.10926856224784337,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.4013671875,
        "f1": 0.36376247562602626,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.36376247562602626,
        "precision": 0.3526681082589286,
        "recall": 0.4013671875
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.0843279348999215,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0843279348999215,
        "precision": 0.08205243406645654,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.48828125,
        "f1": 0.44191242784992785,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.44191242784992785,
        "precision": 0.42560535980946135,
        "recall": 0.48828125
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.029361192545320908,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.029361192545320908,
        "precision": 0.02432942440211449,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.7314453125,
        "f1": 0.6813895089285714,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6813895089285714,
        "precision": 0.6619652157738095,
        "recall": 0.7314453125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0013213190673514986,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0013213190673514986,
        "precision": 0.0007589584874620072,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.3271484375,
        "f1": 0.29899370377886003,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.29899370377886003,
        "precision": 0.2904571050524061,
        "recall": 0.3271484375
      },
      {
        "accuracy": 0.607421875,
        "f1": 0.5363289000496032,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5363289000496032,
        "precision": 0.5081732855902777,
        "recall": 0.607421875
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.15020765367445055,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.15020765367445055,
        "precision": 0.14161194816468253,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.31640625,
        "f1": 0.254156978546627,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.254156978546627,
        "precision": 0.23318459426857863,
        "recall": 0.31640625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003824964640394328,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003824964640394328,
        "precision": 0.0035473949703120683,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.419921875,
        "f1": 0.35263872683306274,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.35263872683306274,
        "precision": 0.3293314558896475,
        "recall": 0.419921875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006269420413890945,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.006269420413890945,
        "precision": 0.005781716088787172,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.25,
        "f1": 0.23282691839463465,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.23282691839463465,
        "precision": 0.22711974963075804,
        "recall": 0.25
      },
      {
        "accuracy": 0.2421875,
        "f1": 0.181362652246229,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.181362652246229,
        "precision": 0.16281838007912225,
        "recall": 0.2421875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005263922022942482,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.005263922022942482,
        "precision": 0.004751601761917312,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.56640625,
        "f1": 0.5196665467024673,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5196665467024673,
        "precision": 0.5041293233676046,
        "recall": 0.56640625
      },
      {
        "accuracy": 0.2294921875,
        "f1": 0.19874120020604397,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.19874120020604397,
        "precision": 0.1877139136904762,
        "recall": 0.2294921875
      },
      {
        "accuracy": 0.20703125,
        "f1": 0.18810453869047616,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.18810453869047616,
        "precision": 0.18067491319444443,
        "recall": 0.20703125
      },
      {
        "accuracy": 0.3720703125,
        "f1": 0.33433753811403766,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.33433753811403766,
        "precision": 0.3236059676001083,
        "recall": 0.3720703125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.007284007352941176,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.007284007352941176,
        "precision": 0.0061517096185064925,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013166601838847684,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.013166601838847684,
        "precision": 0.011111724415348256,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.2109375,
        "f1": 0.1651153203350469,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.1651153203350469,
        "precision": 0.15159404800590437,
        "recall": 0.2109375
      },
      {
        "accuracy": 0.2373046875,
        "f1": 0.18814240857826384,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.18814240857826384,
        "precision": 0.17445716248119558,
        "recall": 0.2373046875
      },
      {
        "accuracy": 0.2392578125,
        "f1": 0.19467392958603896,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.19467392958603896,
        "precision": 0.17964833560536686,
        "recall": 0.2392578125
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.016734413302945013,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.016734413302945013,
        "precision": 0.013491476505966968,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.2373046875,
        "f1": 0.18875263869160352,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.18875263869160352,
        "precision": 0.17461046601027008,
        "recall": 0.2373046875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0027681601167929295,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.0027681601167929295,
        "precision": 0.002056536256329455,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.12242346408340803,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.12242346408340803,
        "precision": 0.10949745141057665,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.0556640625,
        "f1": 0.03171369519222657,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.03171369519222657,
        "precision": 0.02693387514268944,
        "recall": 0.0556640625
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.08457122113487003,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.08457122113487003,
        "precision": 0.0741823971926511,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02932343222470902,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.02932343222470902,
        "precision": 0.025810345923225057,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0008949449073641237,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0008949449073641237,
        "precision": 0.0005259731359649123,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.021523664052960925,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.021523664052960925,
        "precision": 0.018902423658857484,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.00283209234497694,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.00283209234497694,
        "precision": 0.0022449487612940778,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.11313210185223899,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.11313210185223899,
        "precision": 0.10362761662780179,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.025728732512117707,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.025728732512117707,
        "precision": 0.02232005219023673,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0018075980392156861,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0018075980392156861,
        "precision": 0.0011875296656917076,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.19154287026729216,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.19154287026729216,
        "precision": 0.17971265067340828,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.146484375,
        "f1": 0.10711107119477288,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.10711107119477288,
        "precision": 0.09662936216379386,
        "recall": 0.146484375
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.11755533149576117,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.11755533149576117,
        "precision": 0.10502777833889966,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.14834663683291163,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.14834663683291163,
        "precision": 0.13559141596250973,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02284314500443412,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.02284314500443412,
        "precision": 0.018916249394183012,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.0645051787922998,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0645051787922998,
        "precision": 0.05776277570004336,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.3564453125,
        "f1": 0.32777670247235274,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.32777670247235274,
        "precision": 0.31964488698533394,
        "recall": 0.3564453125
      },
      {
        "accuracy": 0.4287109375,
        "f1": 0.3954637504178694,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3954637504178694,
        "precision": 0.3861841607905124,
        "recall": 0.4287109375
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.06697729142841073,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06697729142841073,
        "precision": 0.06377139052143017,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.02728116421433337,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.02728116421433337,
        "precision": 0.022382103828565227,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.451171875,
        "f1": 0.4096371694711538,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.4096371694711538,
        "precision": 0.3972705402794684,
        "recall": 0.451171875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004309851427308324,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.004309851427308324,
        "precision": 0.003214892156606795,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.259765625,
        "f1": 0.23812069142879688,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.23812069142879688,
        "precision": 0.23051226528497823,
        "recall": 0.259765625
      },
      {
        "accuracy": 0.3037109375,
        "f1": 0.23974815036909902,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.23974815036909902,
        "precision": 0.22154753883269507,
        "recall": 0.3037109375
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.15352436192279942,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.15352436192279942,
        "precision": 0.14475786258012818,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.609375,
        "f1": 0.5437577504960317,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5437577504960317,
        "precision": 0.5166910807291667,
        "recall": 0.609375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002134328505373616,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002134328505373616,
        "precision": 0.001755286136389652,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.21875,
        "f1": 0.16790258107267528,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.16790258107267528,
        "precision": 0.15440350248397516,
        "recall": 0.21875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0029283897425249165,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0029283897425249165,
        "precision": 0.002614095770856869,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.216796875,
        "f1": 0.1945633510511228,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1945633510511228,
        "precision": 0.18758838311188822,
        "recall": 0.216796875
      },
      {
        "accuracy": 0.2099609375,
        "f1": 0.15911003174852822,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.15911003174852822,
        "precision": 0.14426012698630852,
        "recall": 0.2099609375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0022204970854172454,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0022204970854172454,
        "precision": 0.0016060459017289992,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.3916015625,
        "f1": 0.3603960330034549,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.3603960330034549,
        "precision": 0.35247148047807225,
        "recall": 0.3916015625
      },
      {
        "accuracy": 0.224609375,
        "f1": 0.19652432528409092,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.19652432528409092,
        "precision": 0.1854239327566964,
        "recall": 0.224609375
      },
      {
        "accuracy": 0.21875,
        "f1": 0.19060856374253735,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.19060856374253735,
        "precision": 0.18084153052362825,
        "recall": 0.21875
      },
      {
        "accuracy": 0.302734375,
        "f1": 0.2780629319780598,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2780629319780598,
        "precision": 0.27060675773623843,
        "recall": 0.302734375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00031257398200757575,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.00031257398200757575,
        "precision": 0.00017197594548490127,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0008746768753814291,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.0008746768753814291,
        "precision": 0.000606920871237646,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.038377165482174534,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.038377165482174534,
        "precision": 0.037953241952008394,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.03875243470127543,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.03875243470127543,
        "precision": 0.03858197748866125,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.007409333422960483,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.007409333422960483,
        "precision": 0.0069773172379584015,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.04349071643120613,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.04349071643120613,
        "precision": 0.04282307031735851,
        "recall": 0.046875
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.038496852405854605,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.038496852405854605,
        "precision": 0.03774351536135092,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.11654284109477123,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.11654284109477123,
        "precision": 0.10525580512152777,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.03649721132759784,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.03649721132759784,
        "precision": 0.03632901278409091,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004333582700999981,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.004333582700999981,
        "precision": 0.003828059780389725,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07436201493818681,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.07436201493818681,
        "precision": 0.06767694382440476,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.0052311809483627115,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.0052311809483627115,
        "precision": 0.004030787212037632,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.03375573536706349,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.03375573536706349,
        "precision": 0.030060179620726494,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0033782303718469875,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.0033782303718469875,
        "precision": 0.002631538858595843,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.046721490586837555,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.046721490586837555,
        "precision": 0.04247184993847883,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.047813943232265996,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.047813943232265996,
        "precision": 0.04551125663527693,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004517382718604775,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.004517382718604775,
        "precision": 0.0042716066214601375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.024439320181670932,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.024439320181670932,
        "precision": 0.021483830157136327,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03163056820119622,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.03163056820119622,
        "precision": 0.030595876874030963,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.035834805578151316,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.035834805578151316,
        "precision": 0.03555308011481343,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.09284933933140141,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.09284933933140141,
        "precision": 0.0860699738629426,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.03069026741712728,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.03069026741712728,
        "precision": 0.03032045199906789,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.05133095132023295,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.05133095132023295,
        "precision": 0.04554264964337028,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.14727662916396467,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.14727662916396467,
        "precision": 0.13371404210504922,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.39453125,
        "f1": 0.35583290407509155,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.35583290407509155,
        "precision": 0.34324840964722925,
        "recall": 0.39453125
      },
      {
        "accuracy": 0.7294921875,
        "f1": 0.6803160652281746,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6803160652281746,
        "precision": 0.6607596261160714,
        "recall": 0.7294921875
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.08278656029006762,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.08278656029006762,
        "precision": 0.07836181804331999,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.5048828125,
        "f1": 0.4582076560592186,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4582076560592186,
        "precision": 0.4429389105902778,
        "recall": 0.5048828125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.027671243686868685,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.027671243686868685,
        "precision": 0.02350168006906288,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0035426837493038148,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0035426837493038148,
        "precision": 0.002935893316752692,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.3115234375,
        "f1": 0.28148075054906996,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.28148075054906996,
        "precision": 0.2717532925516324,
        "recall": 0.3115234375
      },
      {
        "accuracy": 0.7646484375,
        "f1": 0.7092610677083333,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7092610677083333,
        "precision": 0.6848563058035714,
        "recall": 0.7646484375
      },
      {
        "accuracy": 0.162109375,
        "f1": 0.13674173496906172,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.13674173496906172,
        "precision": 0.12782061688311688,
        "recall": 0.162109375
      },
      {
        "accuracy": 0.396484375,
        "f1": 0.318178083851912,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.318178083851912,
        "precision": 0.2923956712775072,
        "recall": 0.396484375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0024839068519899423,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0024839068519899423,
        "precision": 0.0022500194293256686,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.583984375,
        "f1": 0.5169465300324676,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5169465300324676,
        "precision": 0.49096912202380955,
        "recall": 0.583984375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0031690628835838713,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0031690628835838713,
        "precision": 0.0027768640414003055,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.244140625,
        "f1": 0.21977598033665457,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.21977598033665457,
        "precision": 0.21220560358783974,
        "recall": 0.244140625
      },
      {
        "accuracy": 0.296875,
        "f1": 0.23370673922431734,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.23370673922431734,
        "precision": 0.2124569847470238,
        "recall": 0.296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001830560863511198,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001830560863511198,
        "precision": 0.0015719223785830249,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.572265625,
        "f1": 0.5209711729242978,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5209711729242978,
        "precision": 0.5037078373015873,
        "recall": 0.572265625
      },
      {
        "accuracy": 0.2099609375,
        "f1": 0.18092680431547617,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.18092680431547617,
        "precision": 0.16975953733766233,
        "recall": 0.2099609375
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.17607654634547187,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.17607654634547187,
        "precision": 0.16805830130801505,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.380859375,
        "f1": 0.34196799294455543,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.34196799294455543,
        "precision": 0.3297899672856589,
        "recall": 0.380859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0010289053155890526,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.0010289053155890526,
        "precision": 0.0007021625342210054,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0017047515110032987,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0017047515110032987,
        "precision": 0.0014282631035636077,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0037532494446357134,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0037532494446357134,
        "precision": 0.00280571574516887,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0034691189769798635,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.0034691189769798635,
        "precision": 0.0029882330419818133,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000980325746628131,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.000980325746628131,
        "precision": 0.0006529269224581724,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0044631736865942025,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.0044631736865942025,
        "precision": 0.003750188091800402,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.11027800324675323,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.11027800324675323,
        "precision": 0.09891207510964913,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0032192000405981986,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0032192000405981986,
        "precision": 0.0025088856933133063,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002755837912087912,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.002755837912087912,
        "precision": 0.0025220114087301584,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006658163472940737,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.006658163472940737,
        "precision": 0.004906005563188901,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06633371862002377,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.06633371862002377,
        "precision": 0.057675122457837305,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.0050977836960295455,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.0050977836960295455,
        "precision": 0.0037859650973105677,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.029959266049869072,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.029959266049869072,
        "precision": 0.02562666600972012,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005344083780898323,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.005344083780898323,
        "precision": 0.004766009651295467,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06577537337112413,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.06577537337112413,
        "precision": 0.05790457046374353,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.01241459237613383,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.01241459237613383,
        "precision": 0.010220212315513327,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005474661284283703,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.005474661284283703,
        "precision": 0.004593174838293428,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023367256647907314,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.023367256647907314,
        "precision": 0.019756355575235075,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.002745370995485685,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.002745370995485685,
        "precision": 0.001834540012184806,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0019293006491545894,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.0019293006491545894,
        "precision": 0.0015318329951475459,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.08721031381302521,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.08721031381302521,
        "precision": 0.07731875465029761,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 9.216148855182321e-05,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 9.216148855182321e-05,
        "precision": 4.752866060920126e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016438508809099396,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.016438508809099396,
        "precision": 0.015150873107760874,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03594305240070042,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.03594305240070042,
        "precision": 0.031657881145185834,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.2939453125,
        "f1": 0.2698897321211774,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.2698897321211774,
        "precision": 0.2634247904118828,
        "recall": 0.2939453125
      },
      {
        "accuracy": 0.33203125,
        "f1": 0.297428861102705,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.297428861102705,
        "precision": 0.28730039446208766,
        "recall": 0.33203125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.06834004544965576,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.06834004544965576,
        "precision": 0.06573153699171524,
        "recall": 0.078125
      },
      {
        "accuracy": 0.2802734375,
        "f1": 0.250613560886522,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.250613560886522,
        "precision": 0.2409524075702461,
        "recall": 0.2802734375
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.023431402057284112,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.023431402057284112,
        "precision": 0.019152095319661954,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.3193359375,
        "f1": 0.28075501744258313,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.28075501744258313,
        "precision": 0.270029279167527,
        "recall": 0.3193359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0021822791616646657,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0021822791616646657,
        "precision": 0.0016888786764705883,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.046453319986163324,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.046453319986163324,
        "precision": 0.03965796477572672,
        "recall": 0.078125
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.12832089378720238,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.12832089378720238,
        "precision": 0.12081058187724014,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.041115197991346886,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.041115197991346886,
        "precision": 0.0352069131689134,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0005804273540660555,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0005804273540660555,
        "precision": 0.0003339626354946871,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.0351211049651818,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0351211049651818,
        "precision": 0.030026491701296384,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003768756141390384,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0003768756141390384,
        "precision": 0.0002074268613409295,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.236328125,
        "f1": 0.21563668418682952,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.21563668418682952,
        "precision": 0.2092214788478152,
        "recall": 0.236328125
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.045807200595947145,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.045807200595947145,
        "precision": 0.03972544176650835,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013883062135037743,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0013883062135037743,
        "precision": 0.0008186154854476401,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.322265625,
        "f1": 0.29761185346261176,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.29761185346261176,
        "precision": 0.2916803098192402,
        "recall": 0.322265625
      },
      {
        "accuracy": 0.1884765625,
        "f1": 0.1642516121031746,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.1642516121031746,
        "precision": 0.15482584635416666,
        "recall": 0.1884765625
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.16517906093358395,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.16517906093358395,
        "precision": 0.15731593795687135,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.6923828125,
        "f1": 0.6396645943032662,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.6396645943032662,
        "precision": 0.6201533537183812,
        "recall": 0.6923828125
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.06684981047343179,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.06684981047343179,
        "precision": 0.05800691725553858,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.220703125,
        "f1": 0.17164097598308123,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.17164097598308123,
        "precision": 0.15621579066403285,
        "recall": 0.220703125
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.11106604953913513,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.11106604953913513,
        "precision": 0.09932223041353902,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.48046875,
        "f1": 0.40496911129235347,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.40496911129235347,
        "precision": 0.37985097584706956,
        "recall": 0.48046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005110912636006541,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.005110912636006541,
        "precision": 0.00444630015975069,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.2861328125,
        "f1": 0.22028131008578528,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.22028131008578528,
        "precision": 0.2008209889069264,
        "recall": 0.2861328125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0050209560685692805,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0050209560685692805,
        "precision": 0.004570577345546035,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.6376953125,
        "f1": 0.5649830204517704,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5649830204517704,
        "precision": 0.5383560775162337,
        "recall": 0.6376953125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.006673752071267429,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.006673752071267429,
        "precision": 0.005629726468371861,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03956398222683838,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.03956398222683838,
        "precision": 0.03485391464513251,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0025580262324195044,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0025580262324195044,
        "precision": 0.0021069293736354832,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.439453125,
        "f1": 0.374397081867785,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.374397081867785,
        "precision": 0.35065452938988095,
        "recall": 0.439453125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0032796223958333334,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0032796223958333334,
        "precision": 0.0028458337291033435,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.6533203125,
        "f1": 0.5855848524305556,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5855848524305556,
        "precision": 0.5583182198660713,
        "recall": 0.6533203125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.008153222047083224,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.008153222047083224,
        "precision": 0.007612021124743816,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.005653053324137185,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.005653053324137185,
        "precision": 0.005336623789145435,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.3388671875,
        "f1": 0.26852673693494,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.26852673693494,
        "precision": 0.2442964099702381,
        "recall": 0.3388671875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003289917117808648,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003289917117808648,
        "precision": 0.002766160608868678,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.259765625,
        "f1": 0.2064624917704711,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2064624917704711,
        "precision": 0.19207846567461517,
        "recall": 0.259765625
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.022464657738095237,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.022464657738095237,
        "precision": 0.020294411848431174,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0017962642146410804,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0017962642146410804,
        "precision": 0.0015547603438228438,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.05896136224376114,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.05896136224376114,
        "precision": 0.05352352628349415,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009233523637820513,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.0009233523637820513,
        "precision": 0.000634765625,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.001953125,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.001953125,
        "precision": 0.001953125,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.13981779577482703,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.13981779577482703,
        "precision": 0.13485619765711515,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.13792894155280927,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.13792894155280927,
        "precision": 0.13370597580486507,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.032349810074493994,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.032349810074493994,
        "precision": 0.030549223115362817,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.1484375,
        "f1": 0.13656123991935482,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.13656123991935482,
        "precision": 0.13151304891060198,
        "recall": 0.1484375
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06989082423652736,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.06989082423652736,
        "precision": 0.06191991060155123,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.13494964392006803,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.13494964392006803,
        "precision": 0.12995931299687558,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.099609375,
        "f1": 0.07743739630084988,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.07743739630084988,
        "precision": 0.07022162543402777,
        "recall": 0.099609375
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.1250918433779762,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.1250918433779762,
        "precision": 0.12046348625886524,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0041338532086887345,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.0041338532086887345,
        "precision": 0.0030644686259920636,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0012826011047431043,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.0012826011047431043,
        "precision": 0.0008412403776544911,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.01676596280820509,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.01676596280820509,
        "precision": 0.014808001009610626,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0012001397883138615,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.0012001397883138615,
        "precision": 0.0007423012441275894,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03142658585977104,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.03142658585977104,
        "precision": 0.02871106164821698,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.15921893566269593,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.15921893566269593,
        "precision": 0.15414232106036385,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014783660633611926,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0014783660633611926,
        "precision": 0.001279165918342912,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.01392158780986142,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.01392158780986142,
        "precision": 0.012387611620719918,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.125,
        "f1": 0.10884342522323485,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.10884342522323485,
        "precision": 0.10415508523192157,
        "recall": 0.125
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.14111328125,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.14111328125,
        "precision": 0.13757304032305695,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.2265625,
        "f1": 0.20261140046296294,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.20261140046296294,
        "precision": 0.19408511952457264,
        "recall": 0.2265625
      },
      {
        "accuracy": 0.134765625,
        "f1": 0.12331859023217635,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.12331859023217635,
        "precision": 0.11907130111882715,
        "recall": 0.134765625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025562255985259096,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.025562255985259096,
        "precision": 0.022398046091293845,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.059410104476422074,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.059410104476422074,
        "precision": 0.05379203045218671,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06621113500642953,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.06621113500642953,
        "precision": 0.06124267460607602,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.185546875,
        "f1": 0.14513709358168153,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.14513709358168153,
        "precision": 0.1352558886994722,
        "recall": 0.185546875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004366577276872187,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.004366577276872187,
        "precision": 0.0034921802002628945,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.45703125,
        "f1": 0.3831278476298008,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3831278476298008,
        "precision": 0.35687153016254575,
        "recall": 0.45703125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0031409009508159324,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0031409009508159324,
        "precision": 0.00234826598504577,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.25,
        "f1": 0.18943036454110523,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.18943036454110523,
        "precision": 0.173868713923746,
        "recall": 0.25
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.009474464699074073,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.009474464699074073,
        "precision": 0.0077267499025111715,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.026081608860551116,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.026081608860551116,
        "precision": 0.023211828861242925,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.36328125,
        "f1": 0.3050274405499015,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.3050274405499015,
        "precision": 0.2873998231538992,
        "recall": 0.36328125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00321227898486981,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.00321227898486981,
        "precision": 0.0027576184978931433,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004251459406834873,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004251459406834873,
        "precision": 0.003816328370361049,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.2958984375,
        "f1": 0.2421017242306305,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.2421017242306305,
        "precision": 0.22685491273615424,
        "recall": 0.2958984375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0037659153793797345,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0037659153793797345,
        "precision": 0.003226485906862745,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0021159478855194065,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0021159478855194065,
        "precision": 0.0013641093884930915,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.2470703125,
        "f1": 0.18935892124368686,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.18935892124368686,
        "precision": 0.17163620807148303,
        "recall": 0.2470703125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0014710239281400966,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0014710239281400966,
        "precision": 0.000990470430381538,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.08489012420888807,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.08489012420888807,
        "precision": 0.07926254117145345,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.025927898949961108,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.025927898949961108,
        "precision": 0.023132460167751116,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003637947095437499,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.003637947095437499,
        "precision": 0.0031453231847268152,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.03871040979381301,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.03871040979381301,
        "precision": 0.03523072636663528,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.002100318867032713,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.002100318867032713,
        "precision": 0.0016507673972398188,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0022913971306905458,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0022913971306905458,
        "precision": 0.0014962806035875888,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005308677092996289,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.005308677092996289,
        "precision": 0.0045283064416294875,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005290188622826212,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.005290188622826212,
        "precision": 0.004570112545668124,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001963297526041667,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.001963297526041667,
        "precision": 0.0019582378926701572,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0032207453925749523,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0032207453925749523,
        "precision": 0.0024304547855316136,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.05652036029353666,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.05652036029353666,
        "precision": 0.05121303432544298,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004566031528961771,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.004566031528961771,
        "precision": 0.0038322799896289106,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.05561388832011534,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.05561388832011534,
        "precision": 0.04984118393542221,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002282222985347985,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.002282222985347985,
        "precision": 0.0021415844298245616,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0031309200452569086,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0031309200452569086,
        "precision": 0.002338867087018202,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.024480198463302075,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.024480198463302075,
        "precision": 0.021115849358486427,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004008241631470577,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.004008241631470577,
        "precision": 0.0029886067495436637,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005042380314765723,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.005042380314765723,
        "precision": 0.004351007156485268,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0947265625,
        "f1": 0.07236547722387565,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.07236547722387565,
        "precision": 0.0660636482657967,
        "recall": 0.0947265625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03798786524175071,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.03798786524175071,
        "precision": 0.03259781125992064,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0037286641692661914,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0037286641692661914,
        "precision": 0.0034194174124636137,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.07218158266476882,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.07218158266476882,
        "precision": 0.06475776094055047,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0025825167984161387,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0025825167984161387,
        "precision": 0.001911097895340368,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0020561966189443655,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0020561966189443655,
        "precision": 0.0017070939583659225,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.029252081894697687,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.029252081894697687,
        "precision": 0.02469292323983704,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000240336396721095,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.000240336396721095,
        "precision": 0.00012824035418525063,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05704432130909692,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.05704432130909692,
        "precision": 0.05064034857800277,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.1826171875,
        "f1": 0.13930279607105056,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.13930279607105056,
        "precision": 0.127285455229685,
        "recall": 0.1826171875
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.07583944917929293,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.07583944917929293,
        "precision": 0.06768477105653416,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.3095703125,
        "f1": 0.2487786851921756,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2487786851921756,
        "precision": 0.2298728707273629,
        "recall": 0.3095703125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0021707639832427533,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0021707639832427533,
        "precision": 0.001818105444202534,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.2255859375,
        "f1": 0.17329143418477658,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.17329143418477658,
        "precision": 0.15870951422709237,
        "recall": 0.2255859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0047520541314644135,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0047520541314644135,
        "precision": 0.004141927083333333,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.4248046875,
        "f1": 0.3513801167365621,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.3513801167365621,
        "precision": 0.3282769521251828,
        "recall": 0.4248046875
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.010326587475024976,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.010326587475024976,
        "precision": 0.009065707989211441,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.03579138125036563,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.03579138125036563,
        "precision": 0.031778409641426766,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.630859375,
        "f1": 0.5684638874580281,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.5684638874580281,
        "precision": 0.5432728973500458,
        "recall": 0.630859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002316234680689482,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.002316234680689482,
        "precision": 0.001808740759408602,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.380859375,
        "f1": 0.31527196490575393,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.31527196490575393,
        "precision": 0.2936539643082612,
        "recall": 0.380859375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004655195678038748,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004655195678038748,
        "precision": 0.004027549303398856,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.009724613362129379,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.009724613362129379,
        "precision": 0.008757432468449244,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030438956567796606,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0030438956567796606,
        "precision": 0.0021099289165695412,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.3037109375,
        "f1": 0.24374637757565148,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.24374637757565148,
        "precision": 0.2232512943328373,
        "recall": 0.3037109375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004783350586662507,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004783350586662507,
        "precision": 0.004114500388497254,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.181640625,
        "f1": 0.1378559648787342,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.1378559648787342,
        "precision": 0.12605057381006882,
        "recall": 0.181640625
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.020744897501026274,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.020744897501026274,
        "precision": 0.018472413003663004,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003493294471655903,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.003493294471655903,
        "precision": 0.002860561954540511,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.04247991220904461,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.04247991220904461,
        "precision": 0.038504373183392504,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0019787540909250345,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.0019787540909250345,
        "precision": 0.001652838491371772,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.00292858530395338,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.00292858530395338,
        "precision": 0.0022193405798211223,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0035585797742771785,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.0035585797742771785,
        "precision": 0.003034044990496234,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00211137901854665,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.00211137901854665,
        "precision": 0.0017561935420244096,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013698557035519126,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0013698557035519126,
        "precision": 0.0012220390518125855,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006203365574417686,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.006203365574417686,
        "precision": 0.005171558209246901,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.06795545322347307,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.06795545322347307,
        "precision": 0.05959124105004553,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0025138492436768533,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.0025138492436768533,
        "precision": 0.0017705610382649241,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.09739068115044677,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.09739068115044677,
        "precision": 0.08757527779808824,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0009510163069421714,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.0009510163069421714,
        "precision": 0.0005922132210125219,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005230523920323208,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.005230523920323208,
        "precision": 0.0040055057115093,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0556640625,
        "f1": 0.033250992514201806,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.033250992514201806,
        "precision": 0.028942841774575786,
        "recall": 0.0556640625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0018079135308060297,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0018079135308060297,
        "precision": 0.001105922807726576,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.06736935436173802,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.06736935436173802,
        "precision": 0.05867255167792276,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0022818692390899503,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.0022818692390899503,
        "precision": 0.0017587124990985732,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012013313247723992,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.012013313247723992,
        "precision": 0.010806006218296915,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.00561432344643322,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.00561432344643322,
        "precision": 0.005341061633392008,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0556640625,
        "f1": 0.03531637828742608,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.03531637828742608,
        "precision": 0.03132287594663197,
        "recall": 0.0556640625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0020488050054072405,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.0020488050054072405,
        "precision": 0.0012717813179526187,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003440880437083245,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.003440880437083245,
        "precision": 0.003235920028606179,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.03393587174627023,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.03393587174627023,
        "precision": 0.028653772058696344,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 7.938890293225481e-05,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 7.938890293225481e-05,
        "precision": 4.045154580727639e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016883185456979613,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.0016883185456979613,
        "precision": 0.0013673693908582887,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0044319954990185255,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.0044319954990185255,
        "precision": 0.003866844846491228,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.255859375,
        "f1": 0.2375290803323396,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.2375290803323396,
        "precision": 0.23120930200523476,
        "recall": 0.255859375
      },
      {
        "accuracy": 0.255859375,
        "f1": 0.2349329686425507,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.2349329686425507,
        "precision": 0.2290048772727638,
        "recall": 0.255859375
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.05634506458215697,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.05634506458215697,
        "precision": 0.053165524325086144,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.2392578125,
        "f1": 0.21961167621057087,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.21961167621057087,
        "precision": 0.2131406564640107,
        "recall": 0.2392578125
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.0655557671728845,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.0655557671728845,
        "precision": 0.05842607366930466,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.2509765625,
        "f1": 0.2295638702966184,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.2295638702966184,
        "precision": 0.22228687106165038,
        "recall": 0.2509765625
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.026402804897606137,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.026402804897606137,
        "precision": 0.02281657420305669,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.2255859375,
        "f1": 0.20471738151330376,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.20471738151330376,
        "precision": 0.1970241970486111,
        "recall": 0.2255859375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.00571673781692164,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.00571673781692164,
        "precision": 0.004280352351641414,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.17142780403802602,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.17142780403802602,
        "precision": 0.1620999280718016,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004276665740660306,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.004276665740660306,
        "precision": 0.0031909027883380643,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.047918862858585376,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.047918862858585376,
        "precision": 0.043295812406873115,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0033801101555410514,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.0033801101555410514,
        "precision": 0.0024260389478707577,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.031473214285714285,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.031473214285714285,
        "precision": 0.028786057692307694,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005026976210566194,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.005026976210566194,
        "precision": 0.004544120791679386,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.02959496832432637,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.02959496832432637,
        "precision": 0.025394595017987152,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.2529296875,
        "f1": 0.23642828364743362,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.23642828364743362,
        "precision": 0.23004980129379166,
        "recall": 0.2529296875
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.16610756691853837,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.16610756691853837,
        "precision": 0.15897926198619994,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.2470703125,
        "f1": 0.2215643361865865,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.2215643361865865,
        "precision": 0.2136553670365744,
        "recall": 0.2470703125
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.21407396578295015,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.21407396578295015,
        "precision": 0.20722501197888313,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04183591623531518,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.04183591623531518,
        "precision": 0.03715907166834902,
        "recall": 0.0625
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.08562399325503306,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.08562399325503306,
        "precision": 0.07725909890925327,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07063743548118548,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.07063743548118548,
        "precision": 0.06480013634069581,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.12301210865223436,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.12301210865223436,
        "precision": 0.11593663273653816,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.005574421657519013,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.005574421657519013,
        "precision": 0.0053915532998652675,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1826171875,
        "f1": 0.14299457186304915,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.14299457186304915,
        "precision": 0.13175477860977097,
        "recall": 0.1826171875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0033655831467560154,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0033655831467560154,
        "precision": 0.002591619815319977,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.1875,
        "f1": 0.14548432476683854,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.14548432476683854,
        "precision": 0.13346218471937704,
        "recall": 0.1875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005697741890042176,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.005697741890042176,
        "precision": 0.004992061184366571,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.026603017933122242,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.026603017933122242,
        "precision": 0.023887564529654372,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.294921875,
        "f1": 0.24845521250116803,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.24845521250116803,
        "precision": 0.23341514395458857,
        "recall": 0.294921875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0024279720568783068,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0024279720568783068,
        "precision": 0.001879032571517413,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.275390625,
        "f1": 0.22479552782287157,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.22479552782287157,
        "precision": 0.20824611586330338,
        "recall": 0.275390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0032811777308053023,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0032811777308053023,
        "precision": 0.003129185824112839,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.25,
        "f1": 0.21409619186216153,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.21409619186216153,
        "precision": 0.20196779935247128,
        "recall": 0.25
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004791963725812231,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.004791963725812231,
        "precision": 0.0038690213164592757,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0026861384620487346,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0026861384620487346,
        "precision": 0.002107093404216564,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004858605936041513,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004858605936041513,
        "precision": 0.004485536668502628,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.0970113630521304,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.0970113630521304,
        "precision": 0.09054487450483545,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.022353766378566522,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.022353766378566522,
        "precision": 0.01961397566938671,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020777761697768813,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0020777761697768813,
        "precision": 0.0016056315104166668,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.03364540538008377,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.03364540538008377,
        "precision": 0.02987051181559454,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0022449818710486642,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0022449818710486642,
        "precision": 0.002105329565008569,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006556392483612878,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.006556392483612878,
        "precision": 0.005950741641539852,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002978890994876659,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.002978890994876659,
        "precision": 0.0023050624975103897,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.006608932062561095,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.006608932062561095,
        "precision": 0.0063982928240740745,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001962842039800995,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.001962842039800995,
        "precision": 0.0019580078125,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0020805969771139935,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0020805969771139935,
        "precision": 0.0016697701631627829,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.03168588915659228,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.03168588915659228,
        "precision": 0.02715748324841942,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00246581318887258,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.00246581318887258,
        "precision": 0.0020512669123200827,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.02888544640612655,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.02888544640612655,
        "precision": 0.025828028650188125,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002462395715497737,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.002462395715497737,
        "precision": 0.002049340358728283,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004601694508448541,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.004601694508448541,
        "precision": 0.004022299500338754,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.014929719970708086,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.014929719970708086,
        "precision": 0.012734280309478872,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005592178004287379,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.005592178004287379,
        "precision": 0.0046556562057497855,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.060079132564484126,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.060079132564484126,
        "precision": 0.050980050223214286,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005564292478354979,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.005564292478354979,
        "precision": 0.005019535630513607,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.03952327692562067,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.03952327692562067,
        "precision": 0.036327174467467804,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.019275140801466722,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.019275140801466722,
        "precision": 0.01648758910468912,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004312618442443537,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.004312618442443537,
        "precision": 0.003545787347056878,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.006038167253443888,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.006038167253443888,
        "precision": 0.005395738444669366,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005402666004738015,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0005402666004738015,
        "precision": 0.0003518248744356027,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.019762126697745592,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.019762126697745592,
        "precision": 0.016923743477077934,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0011308331425518925,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0011308331425518925,
        "precision": 0.000750424163510101,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.04070009493359529,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.04070009493359529,
        "precision": 0.03509582950629414,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.09023119372368463,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.09023119372368463,
        "precision": 0.0802427442923192,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.390625,
        "f1": 0.354736089648199,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.354736089648199,
        "precision": 0.3429927169184982,
        "recall": 0.390625
      },
      {
        "accuracy": 0.57421875,
        "f1": 0.532198373458139,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.532198373458139,
        "precision": 0.5174506645698052,
        "recall": 0.57421875
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.08424970843164051,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.08424970843164051,
        "precision": 0.08052598908266433,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.466796875,
        "f1": 0.4249488186700962,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.4249488186700962,
        "precision": 0.4108004571383478,
        "recall": 0.466796875
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.029400089640496348,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.029400089640496348,
        "precision": 0.024074397011408732,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.568359375,
        "f1": 0.5228488674411527,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5228488674411527,
        "precision": 0.5085384464605734,
        "recall": 0.568359375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003934733655331872,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.003934733655331872,
        "precision": 0.003180247934347226,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.3271484375,
        "f1": 0.2916317365686724,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.2916317365686724,
        "precision": 0.2802215407396933,
        "recall": 0.3271484375
      },
      {
        "accuracy": 0.333984375,
        "f1": 0.27903892440025246,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.27903892440025246,
        "precision": 0.2623512676304496,
        "recall": 0.333984375
      },
      {
        "accuracy": 0.171875,
        "f1": 0.14575852378843743,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.14575852378843743,
        "precision": 0.13739628342238,
        "recall": 0.171875
      },
      {
        "accuracy": 0.267578125,
        "f1": 0.20610660668392744,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.20610660668392744,
        "precision": 0.1883000856023317,
        "recall": 0.267578125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0032919788129184436,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0032919788129184436,
        "precision": 0.003122122173282754,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.18581614049502376,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.18581614049502376,
        "precision": 0.17155270864903477,
        "recall": 0.23828125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007406340486304431,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.007406340486304431,
        "precision": 0.006559812311839984,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.2421875,
        "f1": 0.21798122202405046,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.21798122202405046,
        "precision": 0.2104128727692035,
        "recall": 0.2421875
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.1372031648301403,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.1372031648301403,
        "precision": 0.12146484527529842,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00268325153241223,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00268325153241223,
        "precision": 0.0023631086521674304,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.205078125,
        "f1": 0.17702663547390107,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.17702663547390107,
        "precision": 0.16672169518849206,
        "recall": 0.205078125
      },
      {
        "accuracy": 0.2080078125,
        "f1": 0.18309583351222058,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.18309583351222058,
        "precision": 0.17434983701480433,
        "recall": 0.2080078125
      },
      {
        "accuracy": 0.3564453125,
        "f1": 0.32754518271928024,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.32754518271928024,
        "precision": 0.3184471678325079,
        "recall": 0.3564453125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005767893571300472,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.005767893571300472,
        "precision": 0.00481872020364859,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.007321319863172542,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.007321319863172542,
        "precision": 0.006815159797224696,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.203125,
        "f1": 0.1891069642575286,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.1891069642575286,
        "precision": 0.18484252577811291,
        "recall": 0.203125
      },
      {
        "accuracy": 0.21484375,
        "f1": 0.19926696592004348,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.19926696592004348,
        "precision": 0.19565330899871686,
        "recall": 0.21484375
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.05496229728303337,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.05496229728303337,
        "precision": 0.051521430529448624,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.18496447576992753,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.18496447576992753,
        "precision": 0.1804023439236603,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.03652545942154169,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.03652545942154169,
        "precision": 0.031491242151826485,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.1738186500186012,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.1738186500186012,
        "precision": 0.16884503919939187,
        "recall": 0.189453125
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.011265716248754899,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.011265716248754899,
        "precision": 0.00947846912202381,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.177734375,
        "f1": 0.16457559367715618,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.16457559367715618,
        "precision": 0.1598318142361111,
        "recall": 0.177734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014433211807982028,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.014433211807982028,
        "precision": 0.011482195817551312,
        "recall": 0.03125
      },
      {
        "accuracy": 0.177734375,
        "f1": 0.15989654876373627,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.15989654876373627,
        "precision": 0.15366681134259258,
        "recall": 0.177734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018855547664141412,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.018855547664141412,
        "precision": 0.015499180851317799,
        "recall": 0.03125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0031812263257575755,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0031812263257575755,
        "precision": 0.0027834478775062657,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.015270462994998943,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.015270462994998943,
        "precision": 0.013357356348079004,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006513558759652509,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.006513558759652509,
        "precision": 0.0059256505875936154,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.1682720269097222,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.1682720269097222,
        "precision": 0.16382057070533632,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.017799436891233766,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.017799436891233766,
        "precision": 0.015576650582107842,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002999016039722747,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.002999016039722747,
        "precision": 0.002557102981889266,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.1596348917977654,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.1596348917977654,
        "precision": 0.1556724811675751,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.212890625,
        "f1": 0.19314780214759653,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.19314780214759653,
        "precision": 0.18792228834932523,
        "recall": 0.212890625
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.15858865715788933,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.15858865715788933,
        "precision": 0.1529462592842784,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00011488970588235294,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.00011488970588235294,
        "precision": 6.103515625e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00021701388888888888,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.00021701388888888888,
        "precision": 0.0001220703125,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.18193423202614378,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.18193423202614378,
        "precision": 0.17714720044113025,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.19921875,
        "f1": 0.18631481598160923,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.18631481598160923,
        "precision": 0.18192392092699197,
        "recall": 0.19921875
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.04854240114485864,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.04854240114485864,
        "precision": 0.045476344687384984,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.1826171875,
        "f1": 0.16692219178592727,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.16692219178592727,
        "precision": 0.1607398412560904,
        "recall": 0.1826171875
      },
      {
        "accuracy": 0.126953125,
        "f1": 0.08457063578272217,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.08457063578272217,
        "precision": 0.07286649304471571,
        "recall": 0.126953125
      },
      {
        "accuracy": 0.18359375,
        "f1": 0.16477990904669865,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.16477990904669865,
        "precision": 0.1591141036882147,
        "recall": 0.18359375
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.08928183903769842,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.08928183903769842,
        "precision": 0.07804478236607142,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.17578125,
        "f1": 0.1600731259300595,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.1600731259300595,
        "precision": 0.1539540280577957,
        "recall": 0.17578125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0034012784235070838,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.0034012784235070838,
        "precision": 0.002791938193613769,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.2431640625,
        "f1": 0.21406947544642854,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.21406947544642854,
        "precision": 0.2033319382440476,
        "recall": 0.2431640625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.002526275651997459,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.002526275651997459,
        "precision": 0.0017264953469829864,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.021127077132936507,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.021127077132936507,
        "precision": 0.019941058361362368,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0019249305382117881,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.0019249305382117881,
        "precision": 0.0013001474440338656,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.031487269705740686,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.031487269705740686,
        "precision": 0.028305662726207582,
        "recall": 0.046875
      },
      {
        "accuracy": 0.2041015625,
        "f1": 0.18700565145650538,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.18700565145650538,
        "precision": 0.182480425984447,
        "recall": 0.2041015625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004395726263016559,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.004395726263016559,
        "precision": 0.003908436902373632,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.016504634793768604,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.016504634793768604,
        "precision": 0.014428786845043264,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.1273631966991342,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.1273631966991342,
        "precision": 0.12254488760964911,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.15648560452564556,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.15648560452564556,
        "precision": 0.15213989954235388,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.1767578125,
        "f1": 0.16005079857261642,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.16005079857261642,
        "precision": 0.155052851262859,
        "recall": 0.1767578125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021356414310515874,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.021356414310515874,
        "precision": 0.019435718454946634,
        "recall": 0.03125
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.0384164015620817,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0384164015620817,
        "precision": 0.03337876176552856,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.3046875,
        "f1": 0.27786094455042,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.27786094455042,
        "precision": 0.27061786954365075,
        "recall": 0.3046875
      },
      {
        "accuracy": 0.36328125,
        "f1": 0.33081911750925236,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.33081911750925236,
        "precision": 0.3201290598507396,
        "recall": 0.36328125
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.07387733538928391,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.07387733538928391,
        "precision": 0.07065303592891484,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.296875,
        "f1": 0.2740634270785638,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.2740634270785638,
        "precision": 0.26678810966629135,
        "recall": 0.296875
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.02499939007858274,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.02499939007858274,
        "precision": 0.0205699821871455,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.37890625,
        "f1": 0.3369325663428111,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.3369325663428111,
        "precision": 0.3241940269446735,
        "recall": 0.37890625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002441685424996042,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.002441685424996042,
        "precision": 0.002214356275274026,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.6767578125,
        "f1": 0.620009138539412,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.620009138539412,
        "precision": 0.5980926029265873,
        "recall": 0.6767578125
      },
      {
        "accuracy": 0.080078125,
        "f1": 0.049268916934460026,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.049268916934460026,
        "precision": 0.04274131167800745,
        "recall": 0.080078125
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.13089312949673637,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.13089312949673637,
        "precision": 0.12359369044215743,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.072265625,
        "f1": 0.04878090749672781,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.04878090749672781,
        "precision": 0.04351568493298551,
        "recall": 0.072265625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005793992610398861,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0005793992610398861,
        "precision": 0.00037256211880756784,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.045494747293957555,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.045494747293957555,
        "precision": 0.040267510809503,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006635616987179486,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0006635616987179486,
        "precision": 0.0004945816532258065,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.240234375,
        "f1": 0.21805309855370994,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.21805309855370994,
        "precision": 0.21113829982476084,
        "recall": 0.240234375
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.04158129325818775,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.04158129325818775,
        "precision": 0.035571898804320684,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0010381613122723036,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0010381613122723036,
        "precision": 0.0007148096581074269,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.3583984375,
        "f1": 0.33018803741716984,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.33018803741716984,
        "precision": 0.3213381706070337,
        "recall": 0.3583984375
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.16044461507190594,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.16044461507190594,
        "precision": 0.15192858763415404,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.16764443158006972,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.16764443158006972,
        "precision": 0.15960441812338144,
        "recall": 0.189453125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}