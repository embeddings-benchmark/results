{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 628.0697288513184,
  "kg_co2_emissions": 0.03491477358503524,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.03557312252964427,
        "f1": 0.03259222661396575,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.03259222661396575,
        "precision": 0.031712309429700734,
        "recall": 0.03557312252964427
      },
      {
        "accuracy": 0.10474308300395258,
        "f1": 0.06319503388415573,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.06319503388415573,
        "precision": 0.05474001936810675,
        "recall": 0.10474308300395258
      },
      {
        "accuracy": 0.05731225296442688,
        "f1": 0.04852737292376137,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.04852737292376137,
        "precision": 0.04700325390917595,
        "recall": 0.05731225296442688
      },
      {
        "accuracy": 0.11363636363636363,
        "f1": 0.07623061208179324,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.07623061208179324,
        "precision": 0.0664601473599381,
        "recall": 0.11363636363636363
      },
      {
        "accuracy": 0.07015810276679842,
        "f1": 0.060672959260882176,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.060672959260882176,
        "precision": 0.0591267313880272,
        "recall": 0.07015810276679842
      },
      {
        "accuracy": 0.17885375494071146,
        "f1": 0.13230406780307966,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.13230406780307966,
        "precision": 0.11847314186289824,
        "recall": 0.17885375494071146
      },
      {
        "accuracy": 0.06620553359683795,
        "f1": 0.05652836722261687,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.05652836722261687,
        "precision": 0.054149040318948786,
        "recall": 0.06620553359683795
      },
      {
        "accuracy": 0.12648221343873517,
        "f1": 0.08573321358660446,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.08573321358660446,
        "precision": 0.07474551189383774,
        "recall": 0.12648221343873517
      },
      {
        "accuracy": 0.05632411067193676,
        "f1": 0.050420537121304385,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.050420537121304385,
        "precision": 0.048686594202898545,
        "recall": 0.05632411067193676
      },
      {
        "accuracy": 0.12845849802371542,
        "f1": 0.09400604621960731,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.09400604621960731,
        "precision": 0.08558161638057471,
        "recall": 0.12845849802371542
      },
      {
        "accuracy": 0.07114624505928854,
        "f1": 0.061427836493290824,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.061427836493290824,
        "precision": 0.05886996731858392,
        "recall": 0.07114624505928854
      },
      {
        "accuracy": 0.14723320158102768,
        "f1": 0.10374405888242343,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.10374405888242343,
        "precision": 0.09124940030325406,
        "recall": 0.14723320158102768
      },
      {
        "accuracy": 0.07509881422924901,
        "f1": 0.06669411506368028,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.06669411506368028,
        "precision": 0.0637697766853777,
        "recall": 0.07509881422924901
      },
      {
        "accuracy": 0.1541501976284585,
        "f1": 0.11021096724712162,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.11021096724712162,
        "precision": 0.09867194970461406,
        "recall": 0.1541501976284585
      },
      {
        "accuracy": 0.11758893280632411,
        "f1": 0.10496600777952038,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.10496600777952038,
        "precision": 0.10142233763315665,
        "recall": 0.11758893280632411
      },
      {
        "accuracy": 0.18478260869565216,
        "f1": 0.12502373363283856,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.12502373363283856,
        "precision": 0.10976057868350358,
        "recall": 0.18478260869565216
      },
      {
        "accuracy": 0.0533596837944664,
        "f1": 0.045725684654442544,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.045725684654442544,
        "precision": 0.04414980823255205,
        "recall": 0.0533596837944664
      },
      {
        "accuracy": 0.13142292490118576,
        "f1": 0.0972989419125152,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.0972989419125152,
        "precision": 0.088382609631902,
        "recall": 0.13142292490118576
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.0320189176423795,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0320189176423795,
        "precision": 0.03137507391615574,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.09189723320158102,
        "f1": 0.0577894725239792,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.0577894725239792,
        "precision": 0.049823448594083324,
        "recall": 0.09189723320158102
      },
      {
        "accuracy": 0.08300395256916997,
        "f1": 0.06846640626595835,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06846640626595835,
        "precision": 0.06590373447408528,
        "recall": 0.08300395256916997
      },
      {
        "accuracy": 0.17490118577075098,
        "f1": 0.12909824342266613,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.12909824342266613,
        "precision": 0.11558841111270778,
        "recall": 0.17490118577075098
      },
      {
        "accuracy": 0.08300395256916997,
        "f1": 0.07672712725100043,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07672712725100043,
        "precision": 0.07519253443166486,
        "recall": 0.08300395256916997
      },
      {
        "accuracy": 0.17193675889328064,
        "f1": 0.1257974579597859,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.1257974579597859,
        "precision": 0.11420550725334497,
        "recall": 0.17193675889328064
      },
      {
        "accuracy": 0.06126482213438735,
        "f1": 0.05486784947630925,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.05486784947630925,
        "precision": 0.05310924118098164,
        "recall": 0.06126482213438735
      },
      {
        "accuracy": 0.12154150197628459,
        "f1": 0.07974802480880683,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.07974802480880683,
        "precision": 0.07152526376309239,
        "recall": 0.12154150197628459
      },
      {
        "accuracy": 0.05928853754940711,
        "f1": 0.051787445760418147,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.051787445760418147,
        "precision": 0.0500045858242744,
        "recall": 0.05928853754940711
      },
      {
        "accuracy": 0.12549407114624506,
        "f1": 0.08133344168203208,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.08133344168203208,
        "precision": 0.07202701318372427,
        "recall": 0.12549407114624506
      },
      {
        "accuracy": 0.1422924901185771,
        "f1": 0.13118153554003217,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.13118153554003217,
        "precision": 0.12821040784352966,
        "recall": 0.1422924901185771
      },
      {
        "accuracy": 0.21541501976284586,
        "f1": 0.14457260405382935,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.14457260405382935,
        "precision": 0.12484540910001876,
        "recall": 0.21541501976284586
      },
      {
        "accuracy": 0.07015810276679842,
        "f1": 0.06194690408011155,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06194690408011155,
        "precision": 0.05964255728641918,
        "recall": 0.07015810276679842
      },
      {
        "accuracy": 0.14130434782608695,
        "f1": 0.09166949070865234,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.09166949070865234,
        "precision": 0.07996976576086086,
        "recall": 0.14130434782608695
      },
      {
        "accuracy": 0.042490118577075096,
        "f1": 0.03838216020664673,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.03838216020664673,
        "precision": 0.03785177150936498,
        "recall": 0.042490118577075096
      },
      {
        "accuracy": 0.1492094861660079,
        "f1": 0.10977653577208912,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.10977653577208912,
        "precision": 0.09990660234772485,
        "recall": 0.1492094861660079
      },
      {
        "accuracy": 0.036561264822134384,
        "f1": 0.03247518814289,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.03247518814289,
        "precision": 0.03165561793279184,
        "recall": 0.036561264822134384
      },
      {
        "accuracy": 0.13932806324110672,
        "f1": 0.10888585438690065,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.10888585438690065,
        "precision": 0.10089575391367676,
        "recall": 0.13932806324110672
      },
      {
        "accuracy": 0.046442687747035576,
        "f1": 0.04305006587615283,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.04305006587615283,
        "precision": 0.04158432147562582,
        "recall": 0.046442687747035576
      },
      {
        "accuracy": 0.10869565217391304,
        "f1": 0.06201894288340862,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.06201894288340862,
        "precision": 0.0536157273211901,
        "recall": 0.10869565217391304
      },
      {
        "accuracy": 0.058300395256917,
        "f1": 0.05055966670244784,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.05055966670244784,
        "precision": 0.04927452213550158,
        "recall": 0.058300395256917
      },
      {
        "accuracy": 0.1600790513833992,
        "f1": 0.11446455756444283,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.11446455756444283,
        "precision": 0.10226050798068169,
        "recall": 0.1600790513833992
      },
      {
        "accuracy": 0.05434782608695652,
        "f1": 0.047850084697910786,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.047850084697910786,
        "precision": 0.046588692253088836,
        "recall": 0.05434782608695652
      },
      {
        "accuracy": 0.15217391304347827,
        "f1": 0.11362894511020362,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.11362894511020362,
        "precision": 0.10469876287235008,
        "recall": 0.15217391304347827
      },
      {
        "accuracy": 0.10573122529644269,
        "f1": 0.09010699198623139,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.09010699198623139,
        "precision": 0.08625304563520879,
        "recall": 0.10573122529644269
      },
      {
        "accuracy": 0.21442687747035574,
        "f1": 0.15668192239900994,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.15668192239900994,
        "precision": 0.14081998388576036,
        "recall": 0.21442687747035574
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.026872487727997472,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.026872487727997472,
        "precision": 0.026224504551651952,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.11857707509881422,
        "f1": 0.08993060943148852,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.08993060943148852,
        "precision": 0.08231779768531466,
        "recall": 0.11857707509881422
      },
      {
        "accuracy": 0.06719367588932806,
        "f1": 0.06128234800927198,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06128234800927198,
        "precision": 0.05992464626272722,
        "recall": 0.06719367588932806
      },
      {
        "accuracy": 0.16304347826086957,
        "f1": 0.11981627974661635,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.11981627974661635,
        "precision": 0.10937349273346715,
        "recall": 0.16304347826086957
      },
      {
        "accuracy": 0.07114624505928854,
        "f1": 0.0633898842950973,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0633898842950973,
        "precision": 0.06147648072506795,
        "recall": 0.07114624505928854
      },
      {
        "accuracy": 0.17588932806324112,
        "f1": 0.13303924167182857,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.13303924167182857,
        "precision": 0.1225958147400835,
        "recall": 0.17588932806324112
      },
      {
        "accuracy": 0.05434782608695652,
        "f1": 0.0497334455667789,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0497334455667789,
        "precision": 0.04872894315829098,
        "recall": 0.05434782608695652
      },
      {
        "accuracy": 0.12944664031620554,
        "f1": 0.08389290368176335,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.08389290368176335,
        "precision": 0.0750648523798029,
        "recall": 0.12944664031620554
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.03270797346079895,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.03270797346079895,
        "precision": 0.03205841881218428,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.14130434782608695,
        "f1": 0.10265513889608444,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.10265513889608444,
        "precision": 0.09365048816017991,
        "recall": 0.14130434782608695
      },
      {
        "accuracy": 0.05928853754940711,
        "f1": 0.05377963262576431,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.05377963262576431,
        "precision": 0.05258237703163302,
        "recall": 0.05928853754940711
      },
      {
        "accuracy": 0.16403162055335968,
        "f1": 0.121682924392453,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.121682924392453,
        "precision": 0.11196422662592033,
        "recall": 0.16403162055335968
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.009881422924901186,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.009881422924901186,
        "precision": 0.009387351778656126,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.008581304617889982,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.008581304617889982,
        "precision": 0.006640589799218751,
        "recall": 0.021739130434782608
      }
    ],
    "validation": [
      {
        "accuracy": 0.04513540621865597,
        "f1": 0.038055575275921176,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.038055575275921176,
        "precision": 0.036413452869731494,
        "recall": 0.04513540621865597
      },
      {
        "accuracy": 0.09829488465396188,
        "f1": 0.05512896645244085,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.05512896645244085,
        "precision": 0.04736223128919601,
        "recall": 0.09829488465396188
      },
      {
        "accuracy": 0.055165496489468405,
        "f1": 0.04808693269521979,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.04808693269521979,
        "precision": 0.04648619661226289,
        "recall": 0.055165496489468405
      },
      {
        "accuracy": 0.1123370110330993,
        "f1": 0.07446041864665381,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.07446041864665381,
        "precision": 0.0653948609512883,
        "recall": 0.1123370110330993
      },
      {
        "accuracy": 0.07221664994984955,
        "f1": 0.06167186544256382,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06167186544256382,
        "precision": 0.058948519657821476,
        "recall": 0.07221664994984955
      },
      {
        "accuracy": 0.16549648946840523,
        "f1": 0.11997005557687604,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.11997005557687604,
        "precision": 0.10615099266052123,
        "recall": 0.16549648946840523
      },
      {
        "accuracy": 0.06820461384152457,
        "f1": 0.05517615116411505,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.05517615116411505,
        "precision": 0.0517017523446502,
        "recall": 0.06820461384152457
      },
      {
        "accuracy": 0.13941825476429287,
        "f1": 0.0964349257611397,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.0964349257611397,
        "precision": 0.08584005658759332,
        "recall": 0.13941825476429287
      },
      {
        "accuracy": 0.06619859578736209,
        "f1": 0.05372307398385633,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.05372307398385633,
        "precision": 0.04990441409699183,
        "recall": 0.06619859578736209
      },
      {
        "accuracy": 0.13841524573721165,
        "f1": 0.09275937480551323,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.09275937480551323,
        "precision": 0.08093976068487839,
        "recall": 0.13841524573721165
      },
      {
        "accuracy": 0.06920762286860582,
        "f1": 0.0616752343708493,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0616752343708493,
        "precision": 0.05949183888000336,
        "recall": 0.06920762286860582
      },
      {
        "accuracy": 0.1534603811434303,
        "f1": 0.1036305683740977,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.1036305683740977,
        "precision": 0.09051141438216456,
        "recall": 0.1534603811434303
      },
      {
        "accuracy": 0.09327983951855567,
        "f1": 0.08143142076760086,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.08143142076760086,
        "precision": 0.07854935740209207,
        "recall": 0.09327983951855567
      },
      {
        "accuracy": 0.15947843530591777,
        "f1": 0.10742442774476302,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.10742442774476302,
        "precision": 0.09474884038156654,
        "recall": 0.15947843530591777
      },
      {
        "accuracy": 0.1123370110330993,
        "f1": 0.10399139664163651,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.10399139664163651,
        "precision": 0.10126454241952912,
        "recall": 0.1123370110330993
      },
      {
        "accuracy": 0.16449348044132397,
        "f1": 0.11113460632016299,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.11113460632016299,
        "precision": 0.09736633948386854,
        "recall": 0.16449348044132397
      },
      {
        "accuracy": 0.08425275827482448,
        "f1": 0.07528640672884936,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.07528640672884936,
        "precision": 0.0730035093625866,
        "recall": 0.08425275827482448
      },
      {
        "accuracy": 0.1534603811434303,
        "f1": 0.11671611921363464,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.11671611921363464,
        "precision": 0.10803590146619234,
        "recall": 0.1534603811434303
      },
      {
        "accuracy": 0.05015045135406219,
        "f1": 0.044882730461172145,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.044882730461172145,
        "precision": 0.043602170930691714,
        "recall": 0.05015045135406219
      },
      {
        "accuracy": 0.09829488465396188,
        "f1": 0.05792023096419122,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.05792023096419122,
        "precision": 0.049695991288970585,
        "recall": 0.09829488465396188
      },
      {
        "accuracy": 0.08926780341023069,
        "f1": 0.07739383682740206,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07739383682740206,
        "precision": 0.07404368637383953,
        "recall": 0.08926780341023069
      },
      {
        "accuracy": 0.17753259779338015,
        "f1": 0.13124067785552238,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.13124067785552238,
        "precision": 0.11768652518401766,
        "recall": 0.17753259779338015
      },
      {
        "accuracy": 0.09729187562688064,
        "f1": 0.08607421553358756,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.08607421553358756,
        "precision": 0.08353991596357026,
        "recall": 0.09729187562688064
      },
      {
        "accuracy": 0.16148445336008024,
        "f1": 0.11076672475742351,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.11076672475742351,
        "precision": 0.09986539427361894,
        "recall": 0.16148445336008024
      },
      {
        "accuracy": 0.07522567703109329,
        "f1": 0.06603670661106124,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.06603670661106124,
        "precision": 0.06317957704531219,
        "recall": 0.07522567703109329
      },
      {
        "accuracy": 0.13239719157472418,
        "f1": 0.07953218251838787,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.07953218251838787,
        "precision": 0.06863227155102782,
        "recall": 0.13239719157472418
      },
      {
        "accuracy": 0.06820461384152457,
        "f1": 0.06264030185795481,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.06264030185795481,
        "precision": 0.060347709796054826,
        "recall": 0.06820461384152457
      },
      {
        "accuracy": 0.11835506519558676,
        "f1": 0.07979534032112563,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.07979534032112563,
        "precision": 0.07188241902344537,
        "recall": 0.11835506519558676
      },
      {
        "accuracy": 0.17552657973921765,
        "f1": 0.16833794845461425,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.16833794845461425,
        "precision": 0.16621725388024286,
        "recall": 0.17552657973921765
      },
      {
        "accuracy": 0.22567703109327983,
        "f1": 0.15656710361442203,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.15656710361442203,
        "precision": 0.1376449598343071,
        "recall": 0.22567703109327983
      },
      {
        "accuracy": 0.08625877632898696,
        "f1": 0.0792711467736543,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0792711467736543,
        "precision": 0.07655108181687921,
        "recall": 0.08625877632898696
      },
      {
        "accuracy": 0.1534603811434303,
        "f1": 0.10170697685241314,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.10170697685241314,
        "precision": 0.08902693471625245,
        "recall": 0.1534603811434303
      },
      {
        "accuracy": 0.06720160481444333,
        "f1": 0.05807904428048974,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.05807904428048974,
        "precision": 0.05555266263366173,
        "recall": 0.06720160481444333
      },
      {
        "accuracy": 0.15747241725175526,
        "f1": 0.1112510824558733,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.1112510824558733,
        "precision": 0.10012112227401103,
        "recall": 0.15747241725175526
      },
      {
        "accuracy": 0.08124373119358075,
        "f1": 0.07139545781805895,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07139545781805895,
        "precision": 0.06910098297579707,
        "recall": 0.08124373119358075
      },
      {
        "accuracy": 0.17352056168505517,
        "f1": 0.12248770419043623,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.12248770419043623,
        "precision": 0.10897146458569693,
        "recall": 0.17352056168505517
      },
      {
        "accuracy": 0.0641925777331996,
        "f1": 0.05817913510646883,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.05817913510646883,
        "precision": 0.056003648426076996,
        "recall": 0.0641925777331996
      },
      {
        "accuracy": 0.11033099297893681,
        "f1": 0.07013924282653965,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.07013924282653965,
        "precision": 0.06277370981324668,
        "recall": 0.11033099297893681
      },
      {
        "accuracy": 0.07422266800401203,
        "f1": 0.06238766424587044,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06238766424587044,
        "precision": 0.05908874920911028,
        "recall": 0.07422266800401203
      },
      {
        "accuracy": 0.15446339017051153,
        "f1": 0.10901206458398117,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.10901206458398117,
        "precision": 0.09779034245961242,
        "recall": 0.15446339017051153
      },
      {
        "accuracy": 0.08324974924774323,
        "f1": 0.07356167147895273,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07356167147895273,
        "precision": 0.07094053869814748,
        "recall": 0.08324974924774323
      },
      {
        "accuracy": 0.16449348044132397,
        "f1": 0.11889987980357285,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.11889987980357285,
        "precision": 0.10739469506218048,
        "recall": 0.16449348044132397
      },
      {
        "accuracy": 0.09729187562688064,
        "f1": 0.08349448730897163,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.08349448730897163,
        "precision": 0.08007543651561398,
        "recall": 0.09729187562688064
      },
      {
        "accuracy": 0.19358074222668004,
        "f1": 0.13982126755446714,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.13982126755446714,
        "precision": 0.12428385254495164,
        "recall": 0.19358074222668004
      },
      {
        "accuracy": 0.055165496489468405,
        "f1": 0.045340980205573984,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.045340980205573984,
        "precision": 0.042668652215148845,
        "recall": 0.055165496489468405
      },
      {
        "accuracy": 0.14543630892678033,
        "f1": 0.107194496129171,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.107194496129171,
        "precision": 0.09639300647852621,
        "recall": 0.14543630892678033
      },
      {
        "accuracy": 0.08826479438314945,
        "f1": 0.07375197246452804,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07375197246452804,
        "precision": 0.07045084496735224,
        "recall": 0.08826479438314945
      },
      {
        "accuracy": 0.17352056168505517,
        "f1": 0.1198304336535016,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.1198304336535016,
        "precision": 0.10745686869660082,
        "recall": 0.17352056168505517
      },
      {
        "accuracy": 0.09027081243731194,
        "f1": 0.07431828191099972,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.07431828191099972,
        "precision": 0.07098875618192652,
        "recall": 0.09027081243731194
      },
      {
        "accuracy": 0.1855566700100301,
        "f1": 0.134688371728692,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.134688371728692,
        "precision": 0.12112396449634727,
        "recall": 0.1855566700100301
      },
      {
        "accuracy": 0.0641925777331996,
        "f1": 0.05643456685847015,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.05643456685847015,
        "precision": 0.05440076954620585,
        "recall": 0.0641925777331996
      },
      {
        "accuracy": 0.1283851554663992,
        "f1": 0.07873310919230088,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.07873310919230088,
        "precision": 0.06879661935225354,
        "recall": 0.1283851554663992
      },
      {
        "accuracy": 0.06720160481444333,
        "f1": 0.05975927516589105,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.05975927516589105,
        "precision": 0.058353968716184396,
        "recall": 0.06720160481444333
      },
      {
        "accuracy": 0.15546639919759278,
        "f1": 0.1147999776886437,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.1147999776886437,
        "precision": 0.10443202088640433,
        "recall": 0.15546639919759278
      },
      {
        "accuracy": 0.07723169508525576,
        "f1": 0.06767830106613987,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06767830106613987,
        "precision": 0.06559634060178753,
        "recall": 0.07723169508525576
      },
      {
        "accuracy": 0.16950852557673018,
        "f1": 0.12208924354921169,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.12208924354921169,
        "precision": 0.11011421975225469,
        "recall": 0.16950852557673018
      },
      {
        "accuracy": 0.010030090270812437,
        "f1": 0.009194249414911402,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.009194249414911402,
        "precision": 0.00911826388255676,
        "recall": 0.010030090270812437
      },
      {
        "accuracy": 0.01905717151454363,
        "f1": 0.007420154694609638,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.007420154694609638,
        "precision": 0.005927258057787577,
        "recall": 0.01905717151454363
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}