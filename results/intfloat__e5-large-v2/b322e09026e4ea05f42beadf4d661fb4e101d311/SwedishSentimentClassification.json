{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.73999,
        "f1": 0.738879,
        "f1_weighted": 0.738911,
        "ap": 0.675676,
        "ap_weighted": 0.675676,
        "scores_per_experiment": [
          {
            "accuracy": 0.740723,
            "f1": 0.73702,
            "f1_weighted": 0.737112,
            "ap": 0.668329,
            "ap_weighted": 0.668329
          },
          {
            "accuracy": 0.722168,
            "f1": 0.72069,
            "f1_weighted": 0.720749,
            "ap": 0.655437,
            "ap_weighted": 0.655437
          },
          {
            "accuracy": 0.727051,
            "f1": 0.726839,
            "f1_weighted": 0.726861,
            "ap": 0.663745,
            "ap_weighted": 0.663745
          },
          {
            "accuracy": 0.734375,
            "f1": 0.734375,
            "f1_weighted": 0.734375,
            "ap": 0.673589,
            "ap_weighted": 0.673589
          },
          {
            "accuracy": 0.758789,
            "f1": 0.758091,
            "f1_weighted": 0.758129,
            "ap": 0.69117,
            "ap_weighted": 0.69117
          },
          {
            "accuracy": 0.729004,
            "f1": 0.72862,
            "f1_weighted": 0.72865,
            "ap": 0.664634,
            "ap_weighted": 0.664634
          },
          {
            "accuracy": 0.75293,
            "f1": 0.749718,
            "f1_weighted": 0.749801,
            "ap": 0.67976,
            "ap_weighted": 0.67976
          },
          {
            "accuracy": 0.766602,
            "f1": 0.76577,
            "f1_weighted": 0.765729,
            "ap": 0.715686,
            "ap_weighted": 0.715686
          },
          {
            "accuracy": 0.710449,
            "f1": 0.709851,
            "f1_weighted": 0.70989,
            "ap": 0.647167,
            "ap_weighted": 0.647167
          },
          {
            "accuracy": 0.757812,
            "f1": 0.75781,
            "f1_weighted": 0.757808,
            "ap": 0.697245,
            "ap_weighted": 0.697245
          }
        ],
        "main_score": 0.73999,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.744385,
        "f1": 0.743259,
        "f1_weighted": 0.743279,
        "ap": 0.679366,
        "ap_weighted": 0.679366,
        "scores_per_experiment": [
          {
            "accuracy": 0.743164,
            "f1": 0.738957,
            "f1_weighted": 0.739022,
            "ap": 0.669477,
            "ap_weighted": 0.669477
          },
          {
            "accuracy": 0.737793,
            "f1": 0.735729,
            "f1_weighted": 0.735774,
            "ap": 0.667757,
            "ap_weighted": 0.667757
          },
          {
            "accuracy": 0.744629,
            "f1": 0.744339,
            "f1_weighted": 0.744356,
            "ap": 0.679289,
            "ap_weighted": 0.679289
          },
          {
            "accuracy": 0.734375,
            "f1": 0.734375,
            "f1_weighted": 0.734375,
            "ap": 0.672989,
            "ap_weighted": 0.672989
          },
          {
            "accuracy": 0.765137,
            "f1": 0.764564,
            "f1_weighted": 0.764587,
            "ap": 0.697427,
            "ap_weighted": 0.697427
          },
          {
            "accuracy": 0.744141,
            "f1": 0.744011,
            "f1_weighted": 0.744023,
            "ap": 0.680044,
            "ap_weighted": 0.680044
          },
          {
            "accuracy": 0.757812,
            "f1": 0.755288,
            "f1_weighted": 0.755337,
            "ap": 0.684928,
            "ap_weighted": 0.684928
          },
          {
            "accuracy": 0.763184,
            "f1": 0.762211,
            "f1_weighted": 0.762181,
            "ap": 0.712158,
            "ap_weighted": 0.712158
          },
          {
            "accuracy": 0.714355,
            "f1": 0.713886,
            "f1_weighted": 0.713908,
            "ap": 0.650582,
            "ap_weighted": 0.650582
          },
          {
            "accuracy": 0.739258,
            "f1": 0.739233,
            "f1_weighted": 0.739228,
            "ap": 0.679013,
            "ap_weighted": 0.679013
          }
        ],
        "main_score": 0.744385,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 26.163898944854736,
  "kg_co2_emissions": 0.0013121071224692434
}