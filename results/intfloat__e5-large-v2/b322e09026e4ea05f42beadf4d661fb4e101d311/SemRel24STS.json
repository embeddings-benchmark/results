{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 36.96586632728577,
  "kg_co2_emissions": 0.001846059516294846,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.7524182496279631,
        "cosine_spearman": 0.7557573283930347,
        "euclidean_pearson": 0.7319421406752146,
        "euclidean_spearman": 0.7557573283930347,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.7557573283930347,
        "manhattan_pearson": 0.7291733842979685,
        "manhattan_spearman": 0.7526700630056298,
        "pearson": 0.7524182496279631,
        "spearman": 0.7557573283930347
      },
      {
        "cosine_pearson": 0.20313425718299843,
        "cosine_spearman": 0.182129327868137,
        "euclidean_pearson": 0.16425957103383526,
        "euclidean_spearman": 0.18084239846540417,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.182129327868137,
        "manhattan_pearson": 0.16324054194377768,
        "manhattan_spearman": 0.17781670427643953,
        "pearson": 0.20313425718299843,
        "spearman": 0.182129327868137
      },
      {
        "cosine_pearson": 0.3840497178898979,
        "cosine_spearman": 0.36190169888514184,
        "euclidean_pearson": 0.3859198428185168,
        "euclidean_spearman": 0.36190169888514184,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.36190169888514184,
        "manhattan_pearson": 0.3913505309570315,
        "manhattan_spearman": 0.36817273491304964,
        "pearson": 0.3840497178898979,
        "spearman": 0.36190169888514184
      },
      {
        "cosine_pearson": 0.46577221397112506,
        "cosine_spearman": 0.4464064888004238,
        "euclidean_pearson": 0.4671488541745975,
        "euclidean_spearman": 0.4464064888004238,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.4464064888004238,
        "manhattan_pearson": 0.4643844463102899,
        "manhattan_spearman": 0.4412284173048883,
        "pearson": 0.46577221397112506,
        "spearman": 0.4464064888004238
      },
      {
        "cosine_pearson": 0.22140992165776027,
        "cosine_spearman": 0.19059598503421143,
        "euclidean_pearson": 0.2438509948351316,
        "euclidean_spearman": 0.19059598503421143,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.19059598503421143,
        "manhattan_pearson": 0.24287496769962408,
        "manhattan_spearman": 0.18809526117803807,
        "pearson": 0.22140992165776027,
        "spearman": 0.19059598503421143
      },
      {
        "cosine_pearson": 0.796834383281114,
        "cosine_spearman": 0.7767604111614905,
        "euclidean_pearson": 0.7973035549939217,
        "euclidean_spearman": 0.7767607071082023,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7767604111614905,
        "manhattan_pearson": 0.7967902321523783,
        "manhattan_spearman": 0.7760768292573478,
        "pearson": 0.796834383281114,
        "spearman": 0.7767604111614905
      },
      {
        "cosine_pearson": 0.40380099892681437,
        "cosine_spearman": 0.3829125461227685,
        "euclidean_pearson": 0.4047528799665325,
        "euclidean_spearman": 0.3829125461227685,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.3829125461227685,
        "manhattan_pearson": 0.40185332794573636,
        "manhattan_spearman": 0.3801672811753527,
        "pearson": 0.40380099892681437,
        "spearman": 0.3829125461227685
      },
      {
        "cosine_pearson": 0.5900180029666647,
        "cosine_spearman": 0.56912117648725,
        "euclidean_pearson": 0.5819206498659184,
        "euclidean_spearman": 0.5691217766539813,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.56912117648725,
        "manhattan_pearson": 0.5815525301460889,
        "manhattan_spearman": 0.5693810958347184,
        "pearson": 0.5900180029666647,
        "spearman": 0.56912117648725
      },
      {
        "cosine_pearson": 0.4907073274625792,
        "cosine_spearman": 0.5034598713048554,
        "euclidean_pearson": 0.5111803471532708,
        "euclidean_spearman": 0.5034598713048554,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.5034598713048554,
        "manhattan_pearson": 0.508937906934073,
        "manhattan_spearman": 0.5034006674909848,
        "pearson": 0.4907073274625792,
        "spearman": 0.5034598713048554
      },
      {
        "cosine_pearson": 0.4723323830955669,
        "cosine_spearman": 0.4591635456250378,
        "euclidean_pearson": 0.47949321492671926,
        "euclidean_spearman": 0.4591635456250378,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.4591635456250378,
        "manhattan_pearson": 0.473283361938112,
        "manhattan_spearman": 0.45340938265750996,
        "pearson": 0.4723323830955669,
        "spearman": 0.4591635456250378
      },
      {
        "cosine_pearson": 0.5073229617467836,
        "cosine_spearman": 0.46053371991816716,
        "euclidean_pearson": 0.5282343114667439,
        "euclidean_spearman": 0.46053371991816716,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.46053371991816716,
        "manhattan_pearson": 0.5262853326430039,
        "manhattan_spearman": 0.459054460413841,
        "pearson": 0.5073229617467836,
        "spearman": 0.46053371991816716
      },
      {
        "cosine_pearson": 0.18936887961890672,
        "cosine_spearman": 0.22598457803584712,
        "euclidean_pearson": 0.2772061383408565,
        "euclidean_spearman": 0.22571533979824449,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.22598457803584712,
        "manhattan_pearson": 0.27712500015096014,
        "manhattan_spearman": 0.22598246071248332,
        "pearson": 0.18936887961890672,
        "spearman": 0.22598457803584712
      }
    ]
  },
  "task_name": "SemRel24STS"
}