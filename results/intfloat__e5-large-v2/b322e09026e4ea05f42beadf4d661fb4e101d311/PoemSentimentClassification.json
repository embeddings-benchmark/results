{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 12.684525728225708,
  "kg_co2_emissions": 0.0003906006416489259,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.5028846153846154,
        "f1": 0.4033903924257708,
        "f1_weighted": 0.5357630725229354,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5028846153846154,
        "scores_per_experiment": [
          {
            "accuracy": 0.5673076923076923,
            "f1": 0.44368131868131866,
            "f1_weighted": 0.5964180050718513
          },
          {
            "accuracy": 0.5384615384615384,
            "f1": 0.44221470019342357,
            "f1_weighted": 0.5709715816098794
          },
          {
            "accuracy": 0.5384615384615384,
            "f1": 0.4591836734693877,
            "f1_weighted": 0.5839874411302982
          },
          {
            "accuracy": 0.5096153846153846,
            "f1": 0.41805166078421896,
            "f1_weighted": 0.5811969556938251
          },
          {
            "accuracy": 0.4807692307692308,
            "f1": 0.3824276661884266,
            "f1_weighted": 0.5277931059853584
          },
          {
            "accuracy": 0.4519230769230769,
            "f1": 0.3711547507962336,
            "f1_weighted": 0.4644039533762143
          },
          {
            "accuracy": 0.49038461538461536,
            "f1": 0.38765306122448984,
            "f1_weighted": 0.5086695447409734
          },
          {
            "accuracy": 0.47115384615384615,
            "f1": 0.3503321678321678,
            "f1_weighted": 0.5136437600860678
          },
          {
            "accuracy": 0.4519230769230769,
            "f1": 0.37176653989789976,
            "f1_weighted": 0.47143716512356654
          },
          {
            "accuracy": 0.5288461538461539,
            "f1": 0.40743838519014164,
            "f1_weighted": 0.5391092124113201
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5133333333333333,
        "f1": 0.39200158019388337,
        "f1_weighted": 0.5529835905047912,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5133333333333333,
        "scores_per_experiment": [
          {
            "accuracy": 0.6095238095238096,
            "f1": 0.4483284937830392,
            "f1_weighted": 0.6468461377552287
          },
          {
            "accuracy": 0.5428571428571428,
            "f1": 0.42399267399267404,
            "f1_weighted": 0.5911390197104484
          },
          {
            "accuracy": 0.5619047619047619,
            "f1": 0.4375912750421269,
            "f1_weighted": 0.6147685915781779
          },
          {
            "accuracy": 0.47619047619047616,
            "f1": 0.3465339233038348,
            "f1_weighted": 0.5426352015732546
          },
          {
            "accuracy": 0.44761904761904764,
            "f1": 0.33522621130037533,
            "f1_weighted": 0.49947854623737314
          },
          {
            "accuracy": 0.4380952380952381,
            "f1": 0.35219703977798333,
            "f1_weighted": 0.4439918946301925
          },
          {
            "accuracy": 0.5714285714285714,
            "f1": 0.43753531617609287,
            "f1_weighted": 0.621193864097239
          },
          {
            "accuracy": 0.5523809523809524,
            "f1": 0.40185613796233266,
            "f1_weighted": 0.586466292802576
          },
          {
            "accuracy": 0.3904761904761905,
            "f1": 0.3251829439909935,
            "f1_weighted": 0.42807955718172436
          },
          {
            "accuracy": 0.5428571428571428,
            "f1": 0.4115717866093806,
            "f1_weighted": 0.5552367994816975
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}