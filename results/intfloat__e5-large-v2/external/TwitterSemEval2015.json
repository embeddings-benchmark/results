{
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
    "task_name": "TwitterSemEval2015",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "default",
                "languages": [
                    "eng-Latn"
                ],
                "cos_sim_accuracy": 0.8694641473445789,
                "cos_sim_ap": 0.7691572747061197,
                "cos_sim_f1": 0.7014348097317529,
                "cos_sim_precision": 0.6653254437869822,
                "cos_sim_recall": 0.7416886543535619,
                "dot_accuracy": 0.8480061989628658,
                "dot_ap": 0.7079525488951769,
                "dot_f1": 0.6544780728844966,
                "dot_precision": 0.6153310104529617,
                "dot_recall": 0.6989445910290237,
                "euclidean_accuracy": 0.8694641473445789,
                "euclidean_ap": 0.7680774009393652,
                "euclidean_f1": 0.7030522503879979,
                "euclidean_precision": 0.6894977168949772,
                "euclidean_recall": 0.7171503957783643,
                "manhattan_accuracy": 0.868629671574179,
                "manhattan_ap": 0.7676518632600318,
                "manhattan_f1": 0.7016056518946692,
                "manhattan_precision": 0.68360450563204,
                "manhattan_recall": 0.7205804749340371,
                "max_accuracy": 0.8694641473445789,
                "max_ap": 0.7691572747061197,
                "max_f1": 0.7030522503879979,
                "main_score": 0.7691572747061197
            }
        ]
    }
}