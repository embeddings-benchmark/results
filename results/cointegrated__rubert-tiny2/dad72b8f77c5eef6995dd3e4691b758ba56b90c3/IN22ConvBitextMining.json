{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "task_name": "IN22ConvBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.038554,
        "recall": 0.063207,
        "f1": 0.043679,
        "accuracy": 0.063207,
        "main_score": 0.043679,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.033914,
        "recall": 0.053227,
        "f1": 0.037653,
        "accuracy": 0.053227,
        "main_score": 0.037653,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.025331,
        "recall": 0.036593,
        "f1": 0.02797,
        "accuracy": 0.036593,
        "main_score": 0.02797,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 2.9e-05,
        "recall": 0.002661,
        "f1": 5.8e-05,
        "accuracy": 0.002661,
        "main_score": 5.8e-05,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0219,
        "recall": 0.043912,
        "f1": 0.025512,
        "accuracy": 0.043912,
        "main_score": 0.025512,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.025842,
        "recall": 0.047239,
        "f1": 0.03027,
        "accuracy": 0.047239,
        "main_score": 0.03027,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.032666,
        "recall": 0.050566,
        "f1": 0.036178,
        "accuracy": 0.050566,
        "main_score": 0.036178,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016614,
        "recall": 0.028609,
        "f1": 0.018848,
        "accuracy": 0.028609,
        "main_score": 0.018848,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004362,
        "recall": 0.013972,
        "f1": 0.005763,
        "accuracy": 0.013972,
        "main_score": 0.005763,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.026272,
        "recall": 0.042582,
        "f1": 0.02981,
        "accuracy": 0.042582,
        "main_score": 0.02981,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.007777,
        "recall": 0.013972,
        "f1": 0.008449,
        "accuracy": 0.013972,
        "main_score": 0.008449,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.031441,
        "recall": 0.049235,
        "f1": 0.034817,
        "accuracy": 0.049235,
        "main_score": 0.034817,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.033431,
        "recall": 0.055223,
        "f1": 0.037802,
        "accuracy": 0.055223,
        "main_score": 0.037802,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.037595,
        "recall": 0.056554,
        "f1": 0.04148,
        "accuracy": 0.056554,
        "main_score": 0.04148,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.038392,
        "recall": 0.05988,
        "f1": 0.042703,
        "accuracy": 0.05988,
        "main_score": 0.042703,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.02402,
        "recall": 0.038589,
        "f1": 0.027001,
        "accuracy": 0.038589,
        "main_score": 0.027001,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.020857,
        "recall": 0.041916,
        "f1": 0.024712,
        "accuracy": 0.041916,
        "main_score": 0.024712,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.028218,
        "recall": 0.041251,
        "f1": 0.03107,
        "accuracy": 0.041251,
        "main_score": 0.03107,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.018988,
        "recall": 0.033932,
        "f1": 0.022051,
        "accuracy": 0.033932,
        "main_score": 0.022051,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.006645,
        "recall": 0.019295,
        "f1": 0.007921,
        "accuracy": 0.019295,
        "main_score": 0.007921,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.008568,
        "recall": 0.01996,
        "f1": 0.010255,
        "accuracy": 0.01996,
        "main_score": 0.010255,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004867,
        "recall": 0.010645,
        "f1": 0.005684,
        "accuracy": 0.010645,
        "main_score": 0.005684,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.034797,
        "recall": 0.057219,
        "f1": 0.039331,
        "accuracy": 0.057219,
        "main_score": 0.039331,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.021852,
        "recall": 0.041251,
        "f1": 0.025094,
        "accuracy": 0.041251,
        "main_score": 0.025094,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.020861,
        "recall": 0.037924,
        "f1": 0.024742,
        "accuracy": 0.037924,
        "main_score": 0.024742,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000692,
        "recall": 0.003327,
        "f1": 0.000717,
        "accuracy": 0.003327,
        "main_score": 0.000717,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.02055,
        "recall": 0.03992,
        "f1": 0.0242,
        "accuracy": 0.03992,
        "main_score": 0.0242,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.023531,
        "recall": 0.041251,
        "f1": 0.026751,
        "accuracy": 0.041251,
        "main_score": 0.026751,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.023538,
        "recall": 0.039255,
        "f1": 0.026914,
        "accuracy": 0.039255,
        "main_score": 0.026914,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015921,
        "recall": 0.027279,
        "f1": 0.018073,
        "accuracy": 0.027279,
        "main_score": 0.018073,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004598,
        "recall": 0.012641,
        "f1": 0.005536,
        "accuracy": 0.012641,
        "main_score": 0.005536,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.024977,
        "recall": 0.040585,
        "f1": 0.028193,
        "accuracy": 0.040585,
        "main_score": 0.028193,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.008457,
        "recall": 0.017299,
        "f1": 0.00967,
        "accuracy": 0.017299,
        "main_score": 0.00967,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.024126,
        "recall": 0.040585,
        "f1": 0.027579,
        "accuracy": 0.040585,
        "main_score": 0.027579,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.028555,
        "recall": 0.044578,
        "f1": 0.031962,
        "accuracy": 0.044578,
        "main_score": 0.031962,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.035306,
        "recall": 0.05855,
        "f1": 0.040052,
        "accuracy": 0.05855,
        "main_score": 0.040052,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.027902,
        "recall": 0.045908,
        "f1": 0.031343,
        "accuracy": 0.045908,
        "main_score": 0.031343,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.018577,
        "recall": 0.033932,
        "f1": 0.021523,
        "accuracy": 0.033932,
        "main_score": 0.021523,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.018618,
        "recall": 0.034597,
        "f1": 0.021526,
        "accuracy": 0.034597,
        "main_score": 0.021526,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.028644,
        "recall": 0.047904,
        "f1": 0.0324,
        "accuracy": 0.047904,
        "main_score": 0.0324,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.016515,
        "recall": 0.031936,
        "f1": 0.019349,
        "accuracy": 0.031936,
        "main_score": 0.019349,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.007055,
        "recall": 0.017299,
        "f1": 0.008633,
        "accuracy": 0.017299,
        "main_score": 0.008633,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.014127,
        "recall": 0.027279,
        "f1": 0.016303,
        "accuracy": 0.027279,
        "main_score": 0.016303,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004969,
        "recall": 0.012641,
        "f1": 0.005976,
        "accuracy": 0.012641,
        "main_score": 0.005976,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.034141,
        "recall": 0.05855,
        "f1": 0.039136,
        "accuracy": 0.05855,
        "main_score": 0.039136,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.024976,
        "recall": 0.044578,
        "f1": 0.028419,
        "accuracy": 0.044578,
        "main_score": 0.028419,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.041459,
        "recall": 0.056554,
        "f1": 0.044918,
        "accuracy": 0.056554,
        "main_score": 0.044918,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00999,
        "recall": 0.013307,
        "f1": 0.010307,
        "accuracy": 0.013307,
        "main_score": 0.010307,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.050726,
        "recall": 0.06986,
        "f1": 0.054635,
        "accuracy": 0.06986,
        "main_score": 0.054635,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.03316,
        "recall": 0.0499,
        "f1": 0.036928,
        "accuracy": 0.0499,
        "main_score": 0.036928,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.054007,
        "recall": 0.069195,
        "f1": 0.057265,
        "accuracy": 0.069195,
        "main_score": 0.057265,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.019928,
        "recall": 0.030605,
        "f1": 0.021953,
        "accuracy": 0.030605,
        "main_score": 0.021953,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.021585,
        "recall": 0.031936,
        "f1": 0.023717,
        "accuracy": 0.031936,
        "main_score": 0.023717,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.017436,
        "recall": 0.032601,
        "f1": 0.020755,
        "accuracy": 0.032601,
        "main_score": 0.020755,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.032533,
        "recall": 0.043912,
        "f1": 0.034307,
        "accuracy": 0.043912,
        "main_score": 0.034307,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.019759,
        "recall": 0.036593,
        "f1": 0.022616,
        "accuracy": 0.036593,
        "main_score": 0.022616,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.026435,
        "recall": 0.047239,
        "f1": 0.03081,
        "accuracy": 0.047239,
        "main_score": 0.03081,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.03241,
        "recall": 0.053227,
        "f1": 0.036268,
        "accuracy": 0.053227,
        "main_score": 0.036268,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.028738,
        "recall": 0.046574,
        "f1": 0.032097,
        "accuracy": 0.046574,
        "main_score": 0.032097,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.052421,
        "recall": 0.066534,
        "f1": 0.0554,
        "accuracy": 0.066534,
        "main_score": 0.0554,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019299,
        "recall": 0.039255,
        "f1": 0.02297,
        "accuracy": 0.039255,
        "main_score": 0.02297,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.019982,
        "recall": 0.029275,
        "f1": 0.021665,
        "accuracy": 0.029275,
        "main_score": 0.021665,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.041546,
        "recall": 0.057884,
        "f1": 0.045407,
        "accuracy": 0.057884,
        "main_score": 0.045407,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.030437,
        "recall": 0.044578,
        "f1": 0.032717,
        "accuracy": 0.044578,
        "main_score": 0.032717,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.044495,
        "recall": 0.05988,
        "f1": 0.047449,
        "accuracy": 0.05988,
        "main_score": 0.047449,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.033257,
        "recall": 0.041916,
        "f1": 0.034866,
        "accuracy": 0.041916,
        "main_score": 0.034866,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.024036,
        "recall": 0.041916,
        "f1": 0.027971,
        "accuracy": 0.041916,
        "main_score": 0.027971,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.021425,
        "recall": 0.038589,
        "f1": 0.024841,
        "accuracy": 0.038589,
        "main_score": 0.024841,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.04052,
        "recall": 0.055888,
        "f1": 0.043679,
        "accuracy": 0.055888,
        "main_score": 0.043679,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.0109,
        "recall": 0.015303,
        "f1": 0.01135,
        "accuracy": 0.015303,
        "main_score": 0.01135,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.045555,
        "recall": 0.05855,
        "f1": 0.04816,
        "accuracy": 0.05855,
        "main_score": 0.04816,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.036195,
        "recall": 0.057884,
        "f1": 0.040715,
        "accuracy": 0.057884,
        "main_score": 0.040715,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.083441,
        "recall": 0.113107,
        "f1": 0.090174,
        "accuracy": 0.113107,
        "main_score": 0.090174,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.009156,
        "recall": 0.015968,
        "f1": 0.010085,
        "accuracy": 0.015968,
        "main_score": 0.010085,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.03216,
        "recall": 0.047904,
        "f1": 0.034991,
        "accuracy": 0.047904,
        "main_score": 0.034991,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.030311,
        "recall": 0.05988,
        "f1": 0.035752,
        "accuracy": 0.05988,
        "main_score": 0.035752,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.029302,
        "recall": 0.036593,
        "f1": 0.030693,
        "accuracy": 0.036593,
        "main_score": 0.030693,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.017991,
        "recall": 0.030605,
        "f1": 0.020093,
        "accuracy": 0.030605,
        "main_score": 0.020093,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.021477,
        "recall": 0.035263,
        "f1": 0.024399,
        "accuracy": 0.035263,
        "main_score": 0.024399,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.024474,
        "recall": 0.044578,
        "f1": 0.028235,
        "accuracy": 0.044578,
        "main_score": 0.028235,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.025724,
        "recall": 0.039255,
        "f1": 0.028635,
        "accuracy": 0.039255,
        "main_score": 0.028635,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.076736,
        "recall": 0.113772,
        "f1": 0.084342,
        "accuracy": 0.113772,
        "main_score": 0.084342,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.010829,
        "recall": 0.01996,
        "f1": 0.012262,
        "accuracy": 0.01996,
        "main_score": 0.012262,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.025256,
        "recall": 0.047239,
        "f1": 0.030188,
        "accuracy": 0.047239,
        "main_score": 0.030188,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.055685,
        "recall": 0.086494,
        "f1": 0.062044,
        "accuracy": 0.086494,
        "main_score": 0.062044,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.03018,
        "recall": 0.038589,
        "f1": 0.031781,
        "accuracy": 0.038589,
        "main_score": 0.031781,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.039093,
        "recall": 0.047904,
        "f1": 0.040587,
        "accuracy": 0.047904,
        "main_score": 0.040587,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.047592,
        "recall": 0.059215,
        "f1": 0.049133,
        "accuracy": 0.059215,
        "main_score": 0.049133,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001742,
        "recall": 0.00998,
        "f1": 0.002382,
        "accuracy": 0.00998,
        "main_score": 0.002382,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.001429,
        "recall": 0.010645,
        "f1": 0.002291,
        "accuracy": 0.010645,
        "main_score": 0.002291,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.012338,
        "recall": 0.017299,
        "f1": 0.013009,
        "accuracy": 0.017299,
        "main_score": 0.013009,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.019433,
        "recall": 0.035263,
        "f1": 0.021262,
        "accuracy": 0.035263,
        "main_score": 0.021262,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.018126,
        "recall": 0.031936,
        "f1": 0.020006,
        "accuracy": 0.031936,
        "main_score": 0.020006,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.009494,
        "recall": 0.020625,
        "f1": 0.01089,
        "accuracy": 0.020625,
        "main_score": 0.01089,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.019017,
        "recall": 0.033267,
        "f1": 0.021237,
        "accuracy": 0.033267,
        "main_score": 0.021237,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000399,
        "recall": 0.005323,
        "f1": 0.000715,
        "accuracy": 0.005323,
        "main_score": 0.000715,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.013657,
        "recall": 0.026613,
        "f1": 0.015306,
        "accuracy": 0.026613,
        "main_score": 0.015306,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.003686,
        "recall": 0.017299,
        "f1": 0.00478,
        "accuracy": 0.017299,
        "main_score": 0.00478,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.010439,
        "recall": 0.020625,
        "f1": 0.012081,
        "accuracy": 0.020625,
        "main_score": 0.012081,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.003379,
        "recall": 0.010645,
        "f1": 0.003877,
        "accuracy": 0.010645,
        "main_score": 0.003877,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002039,
        "recall": 0.008649,
        "f1": 0.002536,
        "accuracy": 0.008649,
        "main_score": 0.002536,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.001284,
        "recall": 0.007319,
        "f1": 0.001724,
        "accuracy": 0.007319,
        "main_score": 0.001724,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.000962,
        "recall": 0.010645,
        "f1": 0.001656,
        "accuracy": 0.010645,
        "main_score": 0.001656,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.023532,
        "recall": 0.036593,
        "f1": 0.025577,
        "accuracy": 0.036593,
        "main_score": 0.025577,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001041,
        "recall": 0.006653,
        "f1": 0.001346,
        "accuracy": 0.006653,
        "main_score": 0.001346,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001412,
        "recall": 0.00998,
        "f1": 0.001934,
        "accuracy": 0.00998,
        "main_score": 0.001934,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.016109,
        "recall": 0.027944,
        "f1": 0.017586,
        "accuracy": 0.027944,
        "main_score": 0.017586,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.015555,
        "recall": 0.025283,
        "f1": 0.016947,
        "accuracy": 0.025283,
        "main_score": 0.016947,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.013503,
        "recall": 0.038589,
        "f1": 0.016345,
        "accuracy": 0.038589,
        "main_score": 0.016345,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.014841,
        "recall": 0.023952,
        "f1": 0.015965,
        "accuracy": 0.023952,
        "main_score": 0.015965,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.025274,
        "recall": 0.043912,
        "f1": 0.028504,
        "accuracy": 0.043912,
        "main_score": 0.028504,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.023883,
        "recall": 0.046574,
        "f1": 0.027866,
        "accuracy": 0.046574,
        "main_score": 0.027866,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.052635,
        "recall": 0.077844,
        "f1": 0.057686,
        "accuracy": 0.077844,
        "main_score": 0.057686,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.047244,
        "recall": 0.061876,
        "f1": 0.050575,
        "accuracy": 0.061876,
        "main_score": 0.050575,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.007577,
        "recall": 0.012641,
        "f1": 0.008198,
        "accuracy": 0.012641,
        "main_score": 0.008198,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.040892,
        "recall": 0.062542,
        "f1": 0.045428,
        "accuracy": 0.062542,
        "main_score": 0.045428,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.053451,
        "recall": 0.069195,
        "f1": 0.05681,
        "accuracy": 0.069195,
        "main_score": 0.05681,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.032476,
        "recall": 0.052562,
        "f1": 0.036081,
        "accuracy": 0.052562,
        "main_score": 0.036081,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.025218,
        "recall": 0.037259,
        "f1": 0.027703,
        "accuracy": 0.037259,
        "main_score": 0.027703,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.014478,
        "recall": 0.028609,
        "f1": 0.017156,
        "accuracy": 0.028609,
        "main_score": 0.017156,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.045882,
        "recall": 0.05988,
        "f1": 0.049283,
        "accuracy": 0.05988,
        "main_score": 0.049283,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.030487,
        "recall": 0.053892,
        "f1": 0.035214,
        "accuracy": 0.053892,
        "main_score": 0.035214,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.028212,
        "recall": 0.047239,
        "f1": 0.031814,
        "accuracy": 0.047239,
        "main_score": 0.031814,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.03256,
        "recall": 0.053892,
        "f1": 0.036712,
        "accuracy": 0.053892,
        "main_score": 0.036712,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.022112,
        "recall": 0.037924,
        "f1": 0.024962,
        "accuracy": 0.037924,
        "main_score": 0.024962,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.055206,
        "recall": 0.069195,
        "f1": 0.057982,
        "accuracy": 0.069195,
        "main_score": 0.057982,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.02418,
        "recall": 0.045243,
        "f1": 0.02836,
        "accuracy": 0.045243,
        "main_score": 0.02836,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.018692,
        "recall": 0.033932,
        "f1": 0.021309,
        "accuracy": 0.033932,
        "main_score": 0.021309,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.040749,
        "recall": 0.054558,
        "f1": 0.044103,
        "accuracy": 0.054558,
        "main_score": 0.044103,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.047365,
        "recall": 0.067864,
        "f1": 0.051124,
        "accuracy": 0.067864,
        "main_score": 0.051124,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.059757,
        "recall": 0.081171,
        "f1": 0.063832,
        "accuracy": 0.081171,
        "main_score": 0.063832,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.035405,
        "recall": 0.044578,
        "f1": 0.037481,
        "accuracy": 0.044578,
        "main_score": 0.037481,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.026195,
        "recall": 0.041251,
        "f1": 0.029467,
        "accuracy": 0.041251,
        "main_score": 0.029467,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.023371,
        "recall": 0.043247,
        "f1": 0.027304,
        "accuracy": 0.043247,
        "main_score": 0.027304,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.029003,
        "recall": 0.041916,
        "f1": 0.031484,
        "accuracy": 0.041916,
        "main_score": 0.031484,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.038674,
        "recall": 0.055223,
        "f1": 0.042137,
        "accuracy": 0.055223,
        "main_score": 0.042137,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003334,
        "recall": 0.005988,
        "f1": 0.003564,
        "accuracy": 0.005988,
        "main_score": 0.003564,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.045239,
        "recall": 0.064538,
        "f1": 0.049035,
        "accuracy": 0.064538,
        "main_score": 0.049035,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.045422,
        "recall": 0.065868,
        "f1": 0.04953,
        "accuracy": 0.065868,
        "main_score": 0.04953,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.019567,
        "recall": 0.02994,
        "f1": 0.021837,
        "accuracy": 0.02994,
        "main_score": 0.021837,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.019136,
        "recall": 0.027279,
        "f1": 0.02043,
        "accuracy": 0.027279,
        "main_score": 0.02043,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.024261,
        "recall": 0.043912,
        "f1": 0.027489,
        "accuracy": 0.043912,
        "main_score": 0.027489,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.022406,
        "recall": 0.029275,
        "f1": 0.023772,
        "accuracy": 0.029275,
        "main_score": 0.023772,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.041336,
        "recall": 0.061876,
        "f1": 0.046089,
        "accuracy": 0.061876,
        "main_score": 0.046089,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.023994,
        "recall": 0.037259,
        "f1": 0.027153,
        "accuracy": 0.037259,
        "main_score": 0.027153,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.027841,
        "recall": 0.041916,
        "f1": 0.030794,
        "accuracy": 0.041916,
        "main_score": 0.030794,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.028971,
        "recall": 0.045243,
        "f1": 0.03193,
        "accuracy": 0.045243,
        "main_score": 0.03193,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.03767,
        "recall": 0.054558,
        "f1": 0.040513,
        "accuracy": 0.054558,
        "main_score": 0.040513,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.016902,
        "recall": 0.028609,
        "f1": 0.019184,
        "accuracy": 0.028609,
        "main_score": 0.019184,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.026228,
        "recall": 0.045908,
        "f1": 0.030295,
        "accuracy": 0.045908,
        "main_score": 0.030295,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.034261,
        "recall": 0.052562,
        "f1": 0.037948,
        "accuracy": 0.052562,
        "main_score": 0.037948,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.021536,
        "recall": 0.032601,
        "f1": 0.023316,
        "accuracy": 0.032601,
        "main_score": 0.023316,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.029516,
        "recall": 0.038589,
        "f1": 0.031035,
        "accuracy": 0.038589,
        "main_score": 0.031035,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.021421,
        "recall": 0.028609,
        "f1": 0.022477,
        "accuracy": 0.028609,
        "main_score": 0.022477,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.030115,
        "recall": 0.050566,
        "f1": 0.034427,
        "accuracy": 0.050566,
        "main_score": 0.034427,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.022855,
        "recall": 0.03992,
        "f1": 0.026589,
        "accuracy": 0.03992,
        "main_score": 0.026589,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.047608,
        "recall": 0.067199,
        "f1": 0.051653,
        "accuracy": 0.067199,
        "main_score": 0.051653,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.087253,
        "recall": 0.113772,
        "f1": 0.093619,
        "accuracy": 0.113772,
        "main_score": 0.093619,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.008857,
        "recall": 0.013972,
        "f1": 0.009711,
        "accuracy": 0.013972,
        "main_score": 0.009711,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.050736,
        "recall": 0.065868,
        "f1": 0.053806,
        "accuracy": 0.065868,
        "main_score": 0.053806,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.040961,
        "recall": 0.064538,
        "f1": 0.046023,
        "accuracy": 0.064538,
        "main_score": 0.046023,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.013051,
        "recall": 0.023952,
        "f1": 0.014726,
        "accuracy": 0.023952,
        "main_score": 0.014726,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.030858,
        "recall": 0.047904,
        "f1": 0.034415,
        "accuracy": 0.047904,
        "main_score": 0.034415,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.037168,
        "recall": 0.063207,
        "f1": 0.042772,
        "accuracy": 0.063207,
        "main_score": 0.042772,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.03215,
        "recall": 0.040585,
        "f1": 0.034138,
        "accuracy": 0.040585,
        "main_score": 0.034138,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.020954,
        "recall": 0.031271,
        "f1": 0.022757,
        "accuracy": 0.031271,
        "main_score": 0.022757,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.022291,
        "recall": 0.037924,
        "f1": 0.025587,
        "accuracy": 0.037924,
        "main_score": 0.025587,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.023661,
        "recall": 0.045908,
        "f1": 0.027998,
        "accuracy": 0.045908,
        "main_score": 0.027998,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.02608,
        "recall": 0.041251,
        "f1": 0.029349,
        "accuracy": 0.041251,
        "main_score": 0.029349,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.082113,
        "recall": 0.119095,
        "f1": 0.089875,
        "accuracy": 0.119095,
        "main_score": 0.089875,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.015554,
        "recall": 0.025283,
        "f1": 0.017325,
        "accuracy": 0.025283,
        "main_score": 0.017325,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.025751,
        "recall": 0.044578,
        "f1": 0.029927,
        "accuracy": 0.044578,
        "main_score": 0.029927,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.078121,
        "recall": 0.104458,
        "f1": 0.084018,
        "accuracy": 0.104458,
        "main_score": 0.084018,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.029748,
        "recall": 0.041251,
        "f1": 0.031753,
        "accuracy": 0.041251,
        "main_score": 0.031753,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.040579,
        "recall": 0.050566,
        "f1": 0.042568,
        "accuracy": 0.050566,
        "main_score": 0.042568,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.046425,
        "recall": 0.061211,
        "f1": 0.048863,
        "accuracy": 0.061211,
        "main_score": 0.048863,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.018359,
        "recall": 0.033932,
        "f1": 0.021007,
        "accuracy": 0.033932,
        "main_score": 0.021007,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.015628,
        "recall": 0.02994,
        "f1": 0.018166,
        "accuracy": 0.02994,
        "main_score": 0.018166,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.017553,
        "recall": 0.034597,
        "f1": 0.020369,
        "accuracy": 0.034597,
        "main_score": 0.020369,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.008677,
        "recall": 0.017964,
        "f1": 0.010217,
        "accuracy": 0.017964,
        "main_score": 0.010217,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00068,
        "recall": 0.003327,
        "f1": 0.000695,
        "accuracy": 0.003327,
        "main_score": 0.000695,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024932,
        "recall": 0.046574,
        "f1": 0.029467,
        "accuracy": 0.046574,
        "main_score": 0.029467,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.015435,
        "recall": 0.027279,
        "f1": 0.017769,
        "accuracy": 0.027279,
        "main_score": 0.017769,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.009013,
        "recall": 0.01996,
        "f1": 0.010883,
        "accuracy": 0.01996,
        "main_score": 0.010883,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003308,
        "recall": 0.007319,
        "f1": 0.003905,
        "accuracy": 0.007319,
        "main_score": 0.003905,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.011396,
        "recall": 0.024617,
        "f1": 0.013881,
        "accuracy": 0.024617,
        "main_score": 0.013881,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.017667,
        "recall": 0.034597,
        "f1": 0.020707,
        "accuracy": 0.034597,
        "main_score": 0.020707,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.020913,
        "recall": 0.037259,
        "f1": 0.024005,
        "accuracy": 0.037259,
        "main_score": 0.024005,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.019852,
        "recall": 0.03992,
        "f1": 0.022827,
        "accuracy": 0.03992,
        "main_score": 0.022827,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.01844,
        "recall": 0.037259,
        "f1": 0.021535,
        "accuracy": 0.037259,
        "main_score": 0.021535,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.015185,
        "recall": 0.030605,
        "f1": 0.017937,
        "accuracy": 0.030605,
        "main_score": 0.017937,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.008992,
        "recall": 0.019295,
        "f1": 0.010654,
        "accuracy": 0.019295,
        "main_score": 0.010654,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.023166,
        "recall": 0.03992,
        "f1": 0.026616,
        "accuracy": 0.03992,
        "main_score": 0.026616,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.012171,
        "recall": 0.021291,
        "f1": 0.013631,
        "accuracy": 0.021291,
        "main_score": 0.013631,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.008856,
        "recall": 0.020625,
        "f1": 0.010781,
        "accuracy": 0.020625,
        "main_score": 0.010781,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.0139,
        "recall": 0.033267,
        "f1": 0.016737,
        "accuracy": 0.033267,
        "main_score": 0.016737,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.02348,
        "recall": 0.046574,
        "f1": 0.028224,
        "accuracy": 0.046574,
        "main_score": 0.028224,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002478,
        "recall": 0.005988,
        "f1": 0.002935,
        "accuracy": 0.005988,
        "main_score": 0.002935,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.005988,
        "recall": 0.013972,
        "f1": 0.006923,
        "accuracy": 0.013972,
        "main_score": 0.006923,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.003961,
        "recall": 0.010645,
        "f1": 0.004833,
        "accuracy": 0.010645,
        "main_score": 0.004833,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.024712,
        "recall": 0.02994,
        "f1": 0.025539,
        "accuracy": 0.02994,
        "main_score": 0.025539,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.030477,
        "recall": 0.037924,
        "f1": 0.032167,
        "accuracy": 0.037924,
        "main_score": 0.032167,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.008422,
        "recall": 0.011311,
        "f1": 0.008841,
        "accuracy": 0.011311,
        "main_score": 0.008841,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025368,
        "recall": 0.030605,
        "f1": 0.026062,
        "accuracy": 0.030605,
        "main_score": 0.026062,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.018101,
        "recall": 0.027944,
        "f1": 0.019895,
        "accuracy": 0.027944,
        "main_score": 0.019895,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.029849,
        "recall": 0.037924,
        "f1": 0.031317,
        "accuracy": 0.037924,
        "main_score": 0.031317,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004052,
        "recall": 0.010645,
        "f1": 0.004745,
        "accuracy": 0.010645,
        "main_score": 0.004745,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006508,
        "recall": 0.014637,
        "f1": 0.007913,
        "accuracy": 0.014637,
        "main_score": 0.007913,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.017995,
        "recall": 0.024617,
        "f1": 0.019097,
        "accuracy": 0.024617,
        "main_score": 0.019097,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.005477,
        "recall": 0.011976,
        "f1": 0.006417,
        "accuracy": 0.011976,
        "main_score": 0.006417,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005699,
        "recall": 0.011976,
        "f1": 0.006607,
        "accuracy": 0.011976,
        "main_score": 0.006607,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.007152,
        "recall": 0.014637,
        "f1": 0.008077,
        "accuracy": 0.014637,
        "main_score": 0.008077,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.0052,
        "recall": 0.011311,
        "f1": 0.006354,
        "accuracy": 0.011311,
        "main_score": 0.006354,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.032086,
        "recall": 0.043247,
        "f1": 0.03421,
        "accuracy": 0.043247,
        "main_score": 0.03421,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.005212,
        "recall": 0.00998,
        "f1": 0.005555,
        "accuracy": 0.00998,
        "main_score": 0.005555,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.004769,
        "recall": 0.013307,
        "f1": 0.006264,
        "accuracy": 0.013307,
        "main_score": 0.006264,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.028884,
        "recall": 0.035928,
        "f1": 0.030601,
        "accuracy": 0.035928,
        "main_score": 0.030601,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.020788,
        "recall": 0.027279,
        "f1": 0.021699,
        "accuracy": 0.027279,
        "main_score": 0.021699,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.023427,
        "recall": 0.028609,
        "f1": 0.024268,
        "accuracy": 0.028609,
        "main_score": 0.024268,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.037033,
        "recall": 0.043912,
        "f1": 0.038558,
        "accuracy": 0.043912,
        "main_score": 0.038558,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.02908,
        "recall": 0.041251,
        "f1": 0.031557,
        "accuracy": 0.041251,
        "main_score": 0.031557,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.025605,
        "recall": 0.040585,
        "f1": 0.028334,
        "accuracy": 0.040585,
        "main_score": 0.028334,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.013189,
        "recall": 0.020625,
        "f1": 0.014535,
        "accuracy": 0.020625,
        "main_score": 0.014535,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.03284,
        "recall": 0.051896,
        "f1": 0.03605,
        "accuracy": 0.051896,
        "main_score": 0.03605,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 3.7e-05,
        "recall": 0.002661,
        "f1": 7.2e-05,
        "accuracy": 0.002661,
        "main_score": 7.2e-05,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013212,
        "recall": 0.023287,
        "f1": 0.014702,
        "accuracy": 0.023287,
        "main_score": 0.014702,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.022986,
        "recall": 0.036593,
        "f1": 0.025091,
        "accuracy": 0.036593,
        "main_score": 0.025091,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.037166,
        "recall": 0.054558,
        "f1": 0.040825,
        "accuracy": 0.054558,
        "main_score": 0.040825,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.008662,
        "recall": 0.014637,
        "f1": 0.009274,
        "accuracy": 0.014637,
        "main_score": 0.009274,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004969,
        "recall": 0.011976,
        "f1": 0.006076,
        "accuracy": 0.011976,
        "main_score": 0.006076,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.004054,
        "recall": 0.007984,
        "f1": 0.00448,
        "accuracy": 0.007984,
        "main_score": 0.00448,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.018759,
        "recall": 0.027944,
        "f1": 0.020504,
        "accuracy": 0.027944,
        "main_score": 0.020504,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.019984,
        "recall": 0.027944,
        "f1": 0.021543,
        "accuracy": 0.027944,
        "main_score": 0.021543,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.032103,
        "recall": 0.049235,
        "f1": 0.035256,
        "accuracy": 0.049235,
        "main_score": 0.035256,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.022626,
        "recall": 0.033267,
        "f1": 0.02467,
        "accuracy": 0.033267,
        "main_score": 0.02467,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.032286,
        "recall": 0.051231,
        "f1": 0.035537,
        "accuracy": 0.051231,
        "main_score": 0.035537,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.016548,
        "recall": 0.022621,
        "f1": 0.017495,
        "accuracy": 0.022621,
        "main_score": 0.017495,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.025342,
        "recall": 0.03992,
        "f1": 0.028171,
        "accuracy": 0.03992,
        "main_score": 0.028171,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.022703,
        "recall": 0.037924,
        "f1": 0.025505,
        "accuracy": 0.037924,
        "main_score": 0.025505,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.004029,
        "recall": 0.011976,
        "f1": 0.004757,
        "accuracy": 0.011976,
        "main_score": 0.004757,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009445,
        "recall": 0.020625,
        "f1": 0.011009,
        "accuracy": 0.020625,
        "main_score": 0.011009,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006197,
        "recall": 0.012641,
        "f1": 0.006965,
        "accuracy": 0.012641,
        "main_score": 0.006965,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.007067,
        "recall": 0.017964,
        "f1": 0.008847,
        "accuracy": 0.017964,
        "main_score": 0.008847,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.007623,
        "recall": 0.017964,
        "f1": 0.0091,
        "accuracy": 0.017964,
        "main_score": 0.0091,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.031596,
        "recall": 0.044578,
        "f1": 0.034053,
        "accuracy": 0.044578,
        "main_score": 0.034053,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.029896,
        "recall": 0.040585,
        "f1": 0.031305,
        "accuracy": 0.040585,
        "main_score": 0.031305,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.006169,
        "recall": 0.009315,
        "f1": 0.006505,
        "accuracy": 0.009315,
        "main_score": 0.006505,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.04126,
        "recall": 0.053227,
        "f1": 0.043795,
        "accuracy": 0.053227,
        "main_score": 0.043795,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.02045,
        "recall": 0.031936,
        "f1": 0.022964,
        "accuracy": 0.031936,
        "main_score": 0.022964,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.033096,
        "recall": 0.043912,
        "f1": 0.034731,
        "accuracy": 0.043912,
        "main_score": 0.034731,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.023631,
        "recall": 0.043247,
        "f1": 0.026943,
        "accuracy": 0.043247,
        "main_score": 0.026943,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.019029,
        "recall": 0.025948,
        "f1": 0.020462,
        "accuracy": 0.025948,
        "main_score": 0.020462,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.005685,
        "recall": 0.015303,
        "f1": 0.007131,
        "accuracy": 0.015303,
        "main_score": 0.007131,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.00938,
        "recall": 0.020625,
        "f1": 0.011423,
        "accuracy": 0.020625,
        "main_score": 0.011423,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.009846,
        "recall": 0.022621,
        "f1": 0.011613,
        "accuracy": 0.022621,
        "main_score": 0.011613,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.009959,
        "recall": 0.021956,
        "f1": 0.011879,
        "accuracy": 0.021956,
        "main_score": 0.011879,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.007741,
        "recall": 0.017299,
        "f1": 0.009504,
        "accuracy": 0.017299,
        "main_score": 0.009504,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.03137,
        "recall": 0.040585,
        "f1": 0.03296,
        "accuracy": 0.040585,
        "main_score": 0.03296,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.01378,
        "recall": 0.028609,
        "f1": 0.016301,
        "accuracy": 0.028609,
        "main_score": 0.016301,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.003915,
        "recall": 0.011976,
        "f1": 0.004976,
        "accuracy": 0.011976,
        "main_score": 0.004976,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.028773,
        "recall": 0.041916,
        "f1": 0.030728,
        "accuracy": 0.041916,
        "main_score": 0.030728,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.033524,
        "recall": 0.046574,
        "f1": 0.035711,
        "accuracy": 0.046574,
        "main_score": 0.035711,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.042741,
        "recall": 0.05988,
        "f1": 0.045583,
        "accuracy": 0.05988,
        "main_score": 0.045583,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.02519,
        "recall": 0.031271,
        "f1": 0.026439,
        "accuracy": 0.031271,
        "main_score": 0.026439,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.028681,
        "recall": 0.047904,
        "f1": 0.032119,
        "accuracy": 0.047904,
        "main_score": 0.032119,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.023699,
        "recall": 0.044578,
        "f1": 0.027701,
        "accuracy": 0.044578,
        "main_score": 0.027701,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.019408,
        "recall": 0.033267,
        "f1": 0.021782,
        "accuracy": 0.033267,
        "main_score": 0.021782,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.021783,
        "recall": 0.031936,
        "f1": 0.02393,
        "accuracy": 0.031936,
        "main_score": 0.02393,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00068,
        "recall": 0.002661,
        "f1": 0.000695,
        "accuracy": 0.002661,
        "main_score": 0.000695,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030806,
        "recall": 0.055888,
        "f1": 0.035295,
        "accuracy": 0.055888,
        "main_score": 0.035295,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.039446,
        "recall": 0.064538,
        "f1": 0.045048,
        "accuracy": 0.064538,
        "main_score": 0.045048,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.020534,
        "recall": 0.036593,
        "f1": 0.023482,
        "accuracy": 0.036593,
        "main_score": 0.023482,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.020901,
        "recall": 0.040585,
        "f1": 0.024549,
        "accuracy": 0.040585,
        "main_score": 0.024549,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006223,
        "recall": 0.013972,
        "f1": 0.006986,
        "accuracy": 0.013972,
        "main_score": 0.006986,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.021844,
        "recall": 0.037259,
        "f1": 0.02507,
        "accuracy": 0.037259,
        "main_score": 0.02507,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.008532,
        "recall": 0.017299,
        "f1": 0.010023,
        "accuracy": 0.017299,
        "main_score": 0.010023,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.025032,
        "recall": 0.03992,
        "f1": 0.028059,
        "accuracy": 0.03992,
        "main_score": 0.028059,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.031745,
        "recall": 0.050566,
        "f1": 0.035706,
        "accuracy": 0.050566,
        "main_score": 0.035706,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.025948,
        "recall": 0.043247,
        "f1": 0.0295,
        "accuracy": 0.043247,
        "main_score": 0.0295,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.022338,
        "recall": 0.035928,
        "f1": 0.024982,
        "accuracy": 0.035928,
        "main_score": 0.024982,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.016249,
        "recall": 0.032601,
        "f1": 0.019392,
        "accuracy": 0.032601,
        "main_score": 0.019392,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.020422,
        "recall": 0.035928,
        "f1": 0.023097,
        "accuracy": 0.035928,
        "main_score": 0.023097,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.015622,
        "recall": 0.027944,
        "f1": 0.017916,
        "accuracy": 0.027944,
        "main_score": 0.017916,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.011005,
        "recall": 0.021291,
        "f1": 0.012797,
        "accuracy": 0.021291,
        "main_score": 0.012797,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.018197,
        "recall": 0.033267,
        "f1": 0.021176,
        "accuracy": 0.033267,
        "main_score": 0.021176,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006062,
        "recall": 0.010645,
        "f1": 0.006727,
        "accuracy": 0.010645,
        "main_score": 0.006727,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.027775,
        "recall": 0.051896,
        "f1": 0.032614,
        "accuracy": 0.051896,
        "main_score": 0.032614,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.028674,
        "recall": 0.047239,
        "f1": 0.03267,
        "accuracy": 0.047239,
        "main_score": 0.03267,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.025285,
        "recall": 0.04857,
        "f1": 0.029617,
        "accuracy": 0.04857,
        "main_score": 0.029617,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.020286,
        "recall": 0.033932,
        "f1": 0.022939,
        "accuracy": 0.033932,
        "main_score": 0.022939,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00069,
        "recall": 0.003327,
        "f1": 0.000715,
        "accuracy": 0.003327,
        "main_score": 0.000715,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023121,
        "recall": 0.044578,
        "f1": 0.02641,
        "accuracy": 0.044578,
        "main_score": 0.02641,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.022527,
        "recall": 0.038589,
        "f1": 0.02598,
        "accuracy": 0.038589,
        "main_score": 0.02598,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.024638,
        "recall": 0.039255,
        "f1": 0.027718,
        "accuracy": 0.039255,
        "main_score": 0.027718,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.02499,
        "recall": 0.040585,
        "f1": 0.027073,
        "accuracy": 0.040585,
        "main_score": 0.027073,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006298,
        "recall": 0.013307,
        "f1": 0.007243,
        "accuracy": 0.013307,
        "main_score": 0.007243,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.019995,
        "recall": 0.035263,
        "f1": 0.023196,
        "accuracy": 0.035263,
        "main_score": 0.023196,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.009359,
        "recall": 0.017299,
        "f1": 0.010295,
        "accuracy": 0.017299,
        "main_score": 0.010295,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.022506,
        "recall": 0.037259,
        "f1": 0.024445,
        "accuracy": 0.037259,
        "main_score": 0.024445,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.035976,
        "recall": 0.053892,
        "f1": 0.039764,
        "accuracy": 0.053892,
        "main_score": 0.039764,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.025708,
        "recall": 0.04857,
        "f1": 0.030218,
        "accuracy": 0.04857,
        "main_score": 0.030218,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.020113,
        "recall": 0.033267,
        "f1": 0.022567,
        "accuracy": 0.033267,
        "main_score": 0.022567,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019598,
        "recall": 0.033932,
        "f1": 0.022446,
        "accuracy": 0.033932,
        "main_score": 0.022446,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.025718,
        "recall": 0.039255,
        "f1": 0.028165,
        "accuracy": 0.039255,
        "main_score": 0.028165,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.017309,
        "recall": 0.027944,
        "f1": 0.019563,
        "accuracy": 0.027944,
        "main_score": 0.019563,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.008919,
        "recall": 0.023952,
        "f1": 0.01053,
        "accuracy": 0.023952,
        "main_score": 0.01053,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.013882,
        "recall": 0.027279,
        "f1": 0.015922,
        "accuracy": 0.027279,
        "main_score": 0.015922,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004409,
        "recall": 0.00998,
        "f1": 0.005007,
        "accuracy": 0.00998,
        "main_score": 0.005007,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.034248,
        "recall": 0.053227,
        "f1": 0.038015,
        "accuracy": 0.053227,
        "main_score": 0.038015,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.033994,
        "recall": 0.054558,
        "f1": 0.038185,
        "accuracy": 0.054558,
        "main_score": 0.038185,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.022627,
        "recall": 0.041916,
        "f1": 0.0265,
        "accuracy": 0.041916,
        "main_score": 0.0265,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.021872,
        "recall": 0.039255,
        "f1": 0.025121,
        "accuracy": 0.039255,
        "main_score": 0.025121,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000694,
        "recall": 0.002661,
        "f1": 0.000721,
        "accuracy": 0.002661,
        "main_score": 0.000721,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027589,
        "recall": 0.043247,
        "f1": 0.030318,
        "accuracy": 0.043247,
        "main_score": 0.030318,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.020068,
        "recall": 0.037259,
        "f1": 0.023305,
        "accuracy": 0.037259,
        "main_score": 0.023305,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.024681,
        "recall": 0.039255,
        "f1": 0.02769,
        "accuracy": 0.039255,
        "main_score": 0.02769,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016551,
        "recall": 0.027279,
        "f1": 0.018491,
        "accuracy": 0.027279,
        "main_score": 0.018491,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.005067,
        "recall": 0.011976,
        "f1": 0.006219,
        "accuracy": 0.011976,
        "main_score": 0.006219,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.024321,
        "recall": 0.041251,
        "f1": 0.027972,
        "accuracy": 0.041251,
        "main_score": 0.027972,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.006651,
        "recall": 0.011976,
        "f1": 0.007102,
        "accuracy": 0.011976,
        "main_score": 0.007102,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.028585,
        "recall": 0.046574,
        "f1": 0.032187,
        "accuracy": 0.046574,
        "main_score": 0.032187,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.032259,
        "recall": 0.051231,
        "f1": 0.036186,
        "accuracy": 0.051231,
        "main_score": 0.036186,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.031474,
        "recall": 0.051896,
        "f1": 0.035092,
        "accuracy": 0.051896,
        "main_score": 0.035092,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.021808,
        "recall": 0.037259,
        "f1": 0.024664,
        "accuracy": 0.037259,
        "main_score": 0.024664,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.021276,
        "recall": 0.040585,
        "f1": 0.024858,
        "accuracy": 0.040585,
        "main_score": 0.024858,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.027503,
        "recall": 0.043912,
        "f1": 0.030477,
        "accuracy": 0.043912,
        "main_score": 0.030477,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.015531,
        "recall": 0.031271,
        "f1": 0.018527,
        "accuracy": 0.031271,
        "main_score": 0.018527,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.010726,
        "recall": 0.027944,
        "f1": 0.01301,
        "accuracy": 0.027944,
        "main_score": 0.01301,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.015375,
        "recall": 0.031271,
        "f1": 0.017746,
        "accuracy": 0.031271,
        "main_score": 0.017746,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004264,
        "recall": 0.010645,
        "f1": 0.005108,
        "accuracy": 0.010645,
        "main_score": 0.005108,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.03641,
        "recall": 0.063872,
        "f1": 0.042126,
        "accuracy": 0.063872,
        "main_score": 0.042126,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.027283,
        "recall": 0.052562,
        "f1": 0.031977,
        "accuracy": 0.052562,
        "main_score": 0.031977,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.025394,
        "recall": 0.04857,
        "f1": 0.029751,
        "accuracy": 0.04857,
        "main_score": 0.029751,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.021366,
        "recall": 0.040585,
        "f1": 0.025428,
        "accuracy": 0.040585,
        "main_score": 0.025428,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000695,
        "recall": 0.003327,
        "f1": 0.000724,
        "accuracy": 0.003327,
        "main_score": 0.000724,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017373,
        "recall": 0.036593,
        "f1": 0.020316,
        "accuracy": 0.036593,
        "main_score": 0.020316,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.029598,
        "recall": 0.050566,
        "f1": 0.033924,
        "accuracy": 0.050566,
        "main_score": 0.033924,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.024639,
        "recall": 0.045243,
        "f1": 0.028879,
        "accuracy": 0.045243,
        "main_score": 0.028879,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016512,
        "recall": 0.032601,
        "f1": 0.018507,
        "accuracy": 0.032601,
        "main_score": 0.018507,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004766,
        "recall": 0.013307,
        "f1": 0.006038,
        "accuracy": 0.013307,
        "main_score": 0.006038,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.020863,
        "recall": 0.041251,
        "f1": 0.024588,
        "accuracy": 0.041251,
        "main_score": 0.024588,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.006964,
        "recall": 0.014637,
        "f1": 0.007837,
        "accuracy": 0.014637,
        "main_score": 0.007837,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.028853,
        "recall": 0.045243,
        "f1": 0.032227,
        "accuracy": 0.045243,
        "main_score": 0.032227,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.028434,
        "recall": 0.054558,
        "f1": 0.033673,
        "accuracy": 0.054558,
        "main_score": 0.033673,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.030949,
        "recall": 0.05855,
        "f1": 0.036291,
        "accuracy": 0.05855,
        "main_score": 0.036291,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.018834,
        "recall": 0.041916,
        "f1": 0.023124,
        "accuracy": 0.041916,
        "main_score": 0.023124,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.020514,
        "recall": 0.038589,
        "f1": 0.023907,
        "accuracy": 0.038589,
        "main_score": 0.023907,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.027582,
        "recall": 0.04857,
        "f1": 0.031518,
        "accuracy": 0.04857,
        "main_score": 0.031518,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.01729,
        "recall": 0.034597,
        "f1": 0.020761,
        "accuracy": 0.034597,
        "main_score": 0.020761,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.007477,
        "recall": 0.022621,
        "f1": 0.009236,
        "accuracy": 0.022621,
        "main_score": 0.009236,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.0106,
        "recall": 0.025283,
        "f1": 0.013233,
        "accuracy": 0.025283,
        "main_score": 0.013233,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004628,
        "recall": 0.011976,
        "f1": 0.005635,
        "accuracy": 0.011976,
        "main_score": 0.005635,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.025178,
        "recall": 0.047904,
        "f1": 0.030383,
        "accuracy": 0.047904,
        "main_score": 0.030383,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.019509,
        "recall": 0.034597,
        "f1": 0.022475,
        "accuracy": 0.034597,
        "main_score": 0.022475,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.046857,
        "recall": 0.066534,
        "f1": 0.051032,
        "accuracy": 0.066534,
        "main_score": 0.051032,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.076282,
        "recall": 0.107784,
        "f1": 0.083149,
        "accuracy": 0.107784,
        "main_score": 0.083149,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00987,
        "recall": 0.015303,
        "f1": 0.010631,
        "accuracy": 0.015303,
        "main_score": 0.010631,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.052746,
        "recall": 0.073187,
        "f1": 0.057065,
        "accuracy": 0.073187,
        "main_score": 0.057065,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.041005,
        "recall": 0.061876,
        "f1": 0.045329,
        "accuracy": 0.061876,
        "main_score": 0.045329,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.083733,
        "recall": 0.113772,
        "f1": 0.090732,
        "accuracy": 0.113772,
        "main_score": 0.090732,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.009714,
        "recall": 0.019295,
        "f1": 0.011115,
        "accuracy": 0.019295,
        "main_score": 0.011115,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.029203,
        "recall": 0.042582,
        "f1": 0.032131,
        "accuracy": 0.042582,
        "main_score": 0.032131,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.030909,
        "recall": 0.054558,
        "f1": 0.035865,
        "accuracy": 0.054558,
        "main_score": 0.035865,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.030541,
        "recall": 0.037924,
        "f1": 0.031961,
        "accuracy": 0.037924,
        "main_score": 0.031961,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.020467,
        "recall": 0.033267,
        "f1": 0.023024,
        "accuracy": 0.033267,
        "main_score": 0.023024,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.020084,
        "recall": 0.035928,
        "f1": 0.023428,
        "accuracy": 0.035928,
        "main_score": 0.023428,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.022443,
        "recall": 0.045908,
        "f1": 0.027171,
        "accuracy": 0.045908,
        "main_score": 0.027171,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.026818,
        "recall": 0.042582,
        "f1": 0.030018,
        "accuracy": 0.042582,
        "main_score": 0.030018,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.011406,
        "recall": 0.018629,
        "f1": 0.01254,
        "accuracy": 0.018629,
        "main_score": 0.01254,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.031237,
        "recall": 0.055888,
        "f1": 0.036162,
        "accuracy": 0.055888,
        "main_score": 0.036162,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.057214,
        "recall": 0.085163,
        "f1": 0.063455,
        "accuracy": 0.085163,
        "main_score": 0.063455,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.029687,
        "recall": 0.040585,
        "f1": 0.03161,
        "accuracy": 0.040585,
        "main_score": 0.03161,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.041162,
        "recall": 0.050566,
        "f1": 0.042925,
        "accuracy": 0.050566,
        "main_score": 0.042925,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.042692,
        "recall": 0.057219,
        "f1": 0.045287,
        "accuracy": 0.057219,
        "main_score": 0.045287,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.020444,
        "recall": 0.040585,
        "f1": 0.023399,
        "accuracy": 0.040585,
        "main_score": 0.023399,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.018948,
        "recall": 0.037259,
        "f1": 0.022381,
        "accuracy": 0.037259,
        "main_score": 0.022381,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.016906,
        "recall": 0.033932,
        "f1": 0.01977,
        "accuracy": 0.033932,
        "main_score": 0.01977,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.009843,
        "recall": 0.019295,
        "f1": 0.011176,
        "accuracy": 0.019295,
        "main_score": 0.011176,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000675,
        "recall": 0.002661,
        "f1": 0.000685,
        "accuracy": 0.002661,
        "main_score": 0.000685,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018893,
        "recall": 0.033932,
        "f1": 0.021615,
        "accuracy": 0.033932,
        "main_score": 0.021615,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.016268,
        "recall": 0.027279,
        "f1": 0.018477,
        "accuracy": 0.027279,
        "main_score": 0.018477,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.016422,
        "recall": 0.029275,
        "f1": 0.018378,
        "accuracy": 0.029275,
        "main_score": 0.018378,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.025424,
        "recall": 0.041251,
        "f1": 0.028325,
        "accuracy": 0.041251,
        "main_score": 0.028325,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.002732,
        "recall": 0.007984,
        "f1": 0.003089,
        "accuracy": 0.007984,
        "main_score": 0.003089,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.015744,
        "recall": 0.025283,
        "f1": 0.017479,
        "accuracy": 0.025283,
        "main_score": 0.017479,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.014262,
        "recall": 0.024617,
        "f1": 0.015537,
        "accuracy": 0.024617,
        "main_score": 0.015537,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.018123,
        "recall": 0.028609,
        "f1": 0.019911,
        "accuracy": 0.028609,
        "main_score": 0.019911,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.018571,
        "recall": 0.035928,
        "f1": 0.021873,
        "accuracy": 0.035928,
        "main_score": 0.021873,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.023255,
        "recall": 0.042582,
        "f1": 0.02638,
        "accuracy": 0.042582,
        "main_score": 0.02638,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.019439,
        "recall": 0.035263,
        "f1": 0.02219,
        "accuracy": 0.035263,
        "main_score": 0.02219,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.010773,
        "recall": 0.020625,
        "f1": 0.012284,
        "accuracy": 0.020625,
        "main_score": 0.012284,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.010932,
        "recall": 0.022621,
        "f1": 0.012679,
        "accuracy": 0.022621,
        "main_score": 0.012679,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.008833,
        "recall": 0.018629,
        "f1": 0.010369,
        "accuracy": 0.018629,
        "main_score": 0.010369,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.012769,
        "recall": 0.022621,
        "f1": 0.014077,
        "accuracy": 0.022621,
        "main_score": 0.014077,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.013204,
        "recall": 0.025283,
        "f1": 0.015182,
        "accuracy": 0.025283,
        "main_score": 0.015182,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.005317,
        "recall": 0.008649,
        "f1": 0.005943,
        "accuracy": 0.008649,
        "main_score": 0.005943,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.025621,
        "recall": 0.043912,
        "f1": 0.029379,
        "accuracy": 0.043912,
        "main_score": 0.029379,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.021808,
        "recall": 0.040585,
        "f1": 0.025571,
        "accuracy": 0.040585,
        "main_score": 0.025571,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.012497,
        "recall": 0.022621,
        "f1": 0.0146,
        "accuracy": 0.022621,
        "main_score": 0.0146,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.028764,
        "recall": 0.047239,
        "f1": 0.033078,
        "accuracy": 0.047239,
        "main_score": 0.033078,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 3.3e-05,
        "recall": 0.002661,
        "f1": 6.5e-05,
        "accuracy": 0.002661,
        "main_score": 6.5e-05,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015106,
        "recall": 0.02994,
        "f1": 0.017695,
        "accuracy": 0.02994,
        "main_score": 0.017695,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.022605,
        "recall": 0.03992,
        "f1": 0.026102,
        "accuracy": 0.03992,
        "main_score": 0.026102,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.022821,
        "recall": 0.03992,
        "f1": 0.026188,
        "accuracy": 0.03992,
        "main_score": 0.026188,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.012297,
        "recall": 0.023287,
        "f1": 0.01417,
        "accuracy": 0.023287,
        "main_score": 0.01417,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004554,
        "recall": 0.010645,
        "f1": 0.005445,
        "accuracy": 0.010645,
        "main_score": 0.005445,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.022084,
        "recall": 0.042582,
        "f1": 0.02589,
        "accuracy": 0.042582,
        "main_score": 0.02589,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.002535,
        "recall": 0.007319,
        "f1": 0.003042,
        "accuracy": 0.007319,
        "main_score": 0.003042,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.0209,
        "recall": 0.035928,
        "f1": 0.023116,
        "accuracy": 0.035928,
        "main_score": 0.023116,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.024044,
        "recall": 0.03992,
        "f1": 0.027742,
        "accuracy": 0.03992,
        "main_score": 0.027742,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.02318,
        "recall": 0.045908,
        "f1": 0.027877,
        "accuracy": 0.045908,
        "main_score": 0.027877,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.02508,
        "recall": 0.042582,
        "f1": 0.028732,
        "accuracy": 0.042582,
        "main_score": 0.028732,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.028035,
        "recall": 0.049235,
        "f1": 0.032691,
        "accuracy": 0.049235,
        "main_score": 0.032691,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.012036,
        "recall": 0.023287,
        "f1": 0.014093,
        "accuracy": 0.023287,
        "main_score": 0.014093,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.01113,
        "recall": 0.021956,
        "f1": 0.013245,
        "accuracy": 0.021956,
        "main_score": 0.013245,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.005186,
        "recall": 0.013307,
        "f1": 0.006247,
        "accuracy": 0.013307,
        "main_score": 0.006247,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.008683,
        "recall": 0.018629,
        "f1": 0.010085,
        "accuracy": 0.018629,
        "main_score": 0.010085,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004104,
        "recall": 0.009315,
        "f1": 0.004816,
        "accuracy": 0.009315,
        "main_score": 0.004816,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.020473,
        "recall": 0.035263,
        "f1": 0.023688,
        "accuracy": 0.035263,
        "main_score": 0.023688,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.015153,
        "recall": 0.028609,
        "f1": 0.01786,
        "accuracy": 0.028609,
        "main_score": 0.01786,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.042982,
        "recall": 0.060546,
        "f1": 0.04646,
        "accuracy": 0.060546,
        "main_score": 0.04646,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.055832,
        "recall": 0.07984,
        "f1": 0.060775,
        "accuracy": 0.07984,
        "main_score": 0.060775,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.009641,
        "recall": 0.013307,
        "f1": 0.010062,
        "accuracy": 0.013307,
        "main_score": 0.010062,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.039969,
        "recall": 0.04857,
        "f1": 0.041911,
        "accuracy": 0.04857,
        "main_score": 0.041911,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.030905,
        "recall": 0.050566,
        "f1": 0.03514,
        "accuracy": 0.050566,
        "main_score": 0.03514,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.075778,
        "recall": 0.09847,
        "f1": 0.080548,
        "accuracy": 0.09847,
        "main_score": 0.080548,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.009443,
        "recall": 0.01996,
        "f1": 0.011133,
        "accuracy": 0.01996,
        "main_score": 0.011133,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.02473,
        "recall": 0.036593,
        "f1": 0.027083,
        "accuracy": 0.036593,
        "main_score": 0.027083,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.021015,
        "recall": 0.037259,
        "f1": 0.024818,
        "accuracy": 0.037259,
        "main_score": 0.024818,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.025687,
        "recall": 0.035263,
        "f1": 0.027554,
        "accuracy": 0.035263,
        "main_score": 0.027554,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.015296,
        "recall": 0.024617,
        "f1": 0.016848,
        "accuracy": 0.024617,
        "main_score": 0.016848,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.015856,
        "recall": 0.028609,
        "f1": 0.018659,
        "accuracy": 0.028609,
        "main_score": 0.018659,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.016561,
        "recall": 0.027944,
        "f1": 0.018773,
        "accuracy": 0.027944,
        "main_score": 0.018773,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.019762,
        "recall": 0.035928,
        "f1": 0.022378,
        "accuracy": 0.035928,
        "main_score": 0.022378,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.060903,
        "recall": 0.086494,
        "f1": 0.065737,
        "accuracy": 0.086494,
        "main_score": 0.065737,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.009316,
        "recall": 0.017299,
        "f1": 0.010594,
        "accuracy": 0.017299,
        "main_score": 0.010594,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.015061,
        "recall": 0.025948,
        "f1": 0.017282,
        "accuracy": 0.025948,
        "main_score": 0.017282,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.023992,
        "recall": 0.030605,
        "f1": 0.025469,
        "accuracy": 0.030605,
        "main_score": 0.025469,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.033321,
        "recall": 0.040585,
        "f1": 0.034895,
        "accuracy": 0.040585,
        "main_score": 0.034895,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.04232,
        "recall": 0.055888,
        "f1": 0.044166,
        "accuracy": 0.055888,
        "main_score": 0.044166,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.0069,
        "recall": 0.015968,
        "f1": 0.00802,
        "accuracy": 0.015968,
        "main_score": 0.00802,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.009935,
        "recall": 0.017299,
        "f1": 0.010953,
        "accuracy": 0.017299,
        "main_score": 0.010953,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.035278,
        "recall": 0.047904,
        "f1": 0.037339,
        "accuracy": 0.047904,
        "main_score": 0.037339,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.030049,
        "recall": 0.037924,
        "f1": 0.031558,
        "accuracy": 0.037924,
        "main_score": 0.031558,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.006948,
        "recall": 0.011311,
        "f1": 0.007365,
        "accuracy": 0.011311,
        "main_score": 0.007365,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.047392,
        "recall": 0.063872,
        "f1": 0.050232,
        "accuracy": 0.063872,
        "main_score": 0.050232,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.019141,
        "recall": 0.02994,
        "f1": 0.02124,
        "accuracy": 0.02994,
        "main_score": 0.02124,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.03393,
        "recall": 0.041916,
        "f1": 0.03574,
        "accuracy": 0.041916,
        "main_score": 0.03574,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.01427,
        "recall": 0.029275,
        "f1": 0.016427,
        "accuracy": 0.029275,
        "main_score": 0.016427,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.023996,
        "recall": 0.02994,
        "f1": 0.025355,
        "accuracy": 0.02994,
        "main_score": 0.025355,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.003877,
        "recall": 0.009315,
        "f1": 0.004759,
        "accuracy": 0.009315,
        "main_score": 0.004759,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.034753,
        "recall": 0.045908,
        "f1": 0.036929,
        "accuracy": 0.045908,
        "main_score": 0.036929,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.011176,
        "recall": 0.020625,
        "f1": 0.012679,
        "accuracy": 0.020625,
        "main_score": 0.012679,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.010013,
        "recall": 0.017964,
        "f1": 0.011205,
        "accuracy": 0.017964,
        "main_score": 0.011205,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.01409,
        "recall": 0.025283,
        "f1": 0.016111,
        "accuracy": 0.025283,
        "main_score": 0.016111,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.008732,
        "recall": 0.017964,
        "f1": 0.009951,
        "accuracy": 0.017964,
        "main_score": 0.009951,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.032565,
        "recall": 0.042582,
        "f1": 0.034297,
        "accuracy": 0.042582,
        "main_score": 0.034297,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.013638,
        "recall": 0.022621,
        "f1": 0.015002,
        "accuracy": 0.022621,
        "main_score": 0.015002,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006656,
        "recall": 0.017964,
        "f1": 0.008363,
        "accuracy": 0.017964,
        "main_score": 0.008363,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.027943,
        "recall": 0.037259,
        "f1": 0.029604,
        "accuracy": 0.037259,
        "main_score": 0.029604,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.047419,
        "recall": 0.063207,
        "f1": 0.050566,
        "accuracy": 0.063207,
        "main_score": 0.050566,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.02884,
        "recall": 0.036593,
        "f1": 0.030251,
        "accuracy": 0.036593,
        "main_score": 0.030251,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.014268,
        "recall": 0.028609,
        "f1": 0.016201,
        "accuracy": 0.028609,
        "main_score": 0.016201,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.015661,
        "recall": 0.029275,
        "f1": 0.017969,
        "accuracy": 0.029275,
        "main_score": 0.017969,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.044185,
        "recall": 0.063207,
        "f1": 0.047504,
        "accuracy": 0.063207,
        "main_score": 0.047504,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.035579,
        "recall": 0.047904,
        "f1": 0.037891,
        "accuracy": 0.047904,
        "main_score": 0.037891,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.005918,
        "recall": 0.00998,
        "f1": 0.006428,
        "accuracy": 0.00998,
        "main_score": 0.006428,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.061828,
        "recall": 0.082502,
        "f1": 0.066077,
        "accuracy": 0.082502,
        "main_score": 0.066077,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.025497,
        "recall": 0.039255,
        "f1": 0.028238,
        "accuracy": 0.039255,
        "main_score": 0.028238,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.041938,
        "recall": 0.052562,
        "f1": 0.043962,
        "accuracy": 0.052562,
        "main_score": 0.043962,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.028713,
        "recall": 0.050566,
        "f1": 0.033206,
        "accuracy": 0.050566,
        "main_score": 0.033206,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.023118,
        "recall": 0.030605,
        "f1": 0.02469,
        "accuracy": 0.030605,
        "main_score": 0.02469,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.0094,
        "recall": 0.021956,
        "f1": 0.011698,
        "accuracy": 0.021956,
        "main_score": 0.011698,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.043661,
        "recall": 0.061876,
        "f1": 0.04685,
        "accuracy": 0.061876,
        "main_score": 0.04685,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.017208,
        "recall": 0.034597,
        "f1": 0.020119,
        "accuracy": 0.034597,
        "main_score": 0.020119,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.012266,
        "recall": 0.025283,
        "f1": 0.013985,
        "accuracy": 0.025283,
        "main_score": 0.013985,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.020563,
        "recall": 0.035928,
        "f1": 0.023764,
        "accuracy": 0.035928,
        "main_score": 0.023764,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.015026,
        "recall": 0.026613,
        "f1": 0.016791,
        "accuracy": 0.026613,
        "main_score": 0.016791,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.037909,
        "recall": 0.049235,
        "f1": 0.040152,
        "accuracy": 0.049235,
        "main_score": 0.040152,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019625,
        "recall": 0.037259,
        "f1": 0.023118,
        "accuracy": 0.037259,
        "main_score": 0.023118,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.011415,
        "recall": 0.021291,
        "f1": 0.013008,
        "accuracy": 0.021291,
        "main_score": 0.013008,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.035646,
        "recall": 0.049235,
        "f1": 0.038344,
        "accuracy": 0.049235,
        "main_score": 0.038344,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.048627,
        "recall": 0.065203,
        "f1": 0.051967,
        "accuracy": 0.065203,
        "main_score": 0.051967,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.030058,
        "recall": 0.035928,
        "f1": 0.031131,
        "accuracy": 0.035928,
        "main_score": 0.031131,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.005933,
        "recall": 0.00998,
        "f1": 0.006644,
        "accuracy": 0.00998,
        "main_score": 0.006644,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.005022,
        "recall": 0.00998,
        "f1": 0.005672,
        "accuracy": 0.00998,
        "main_score": 0.005672,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.030091,
        "recall": 0.038589,
        "f1": 0.031887,
        "accuracy": 0.038589,
        "main_score": 0.031887,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.043505,
        "recall": 0.059215,
        "f1": 0.046389,
        "accuracy": 0.059215,
        "main_score": 0.046389,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.011794,
        "recall": 0.015303,
        "f1": 0.012309,
        "accuracy": 0.015303,
        "main_score": 0.012309,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031719,
        "recall": 0.037924,
        "f1": 0.033043,
        "accuracy": 0.037924,
        "main_score": 0.033043,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.018774,
        "recall": 0.029275,
        "f1": 0.020492,
        "accuracy": 0.029275,
        "main_score": 0.020492,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.04989,
        "recall": 0.065868,
        "f1": 0.052641,
        "accuracy": 0.065868,
        "main_score": 0.052641,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00164,
        "recall": 0.005323,
        "f1": 0.00187,
        "accuracy": 0.005323,
        "main_score": 0.00187,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.033765,
        "recall": 0.044578,
        "f1": 0.036265,
        "accuracy": 0.044578,
        "main_score": 0.036265,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.006988,
        "recall": 0.015303,
        "f1": 0.008231,
        "accuracy": 0.015303,
        "main_score": 0.008231,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.024515,
        "recall": 0.031271,
        "f1": 0.026097,
        "accuracy": 0.031271,
        "main_score": 0.026097,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.004969,
        "recall": 0.011311,
        "f1": 0.005611,
        "accuracy": 0.011311,
        "main_score": 0.005611,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002155,
        "recall": 0.006653,
        "f1": 0.002731,
        "accuracy": 0.006653,
        "main_score": 0.002731,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.005715,
        "recall": 0.011976,
        "f1": 0.006661,
        "accuracy": 0.011976,
        "main_score": 0.006661,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.003487,
        "recall": 0.008649,
        "f1": 0.004323,
        "accuracy": 0.008649,
        "main_score": 0.004323,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.041883,
        "recall": 0.054558,
        "f1": 0.044406,
        "accuracy": 0.054558,
        "main_score": 0.044406,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.004295,
        "recall": 0.007984,
        "f1": 0.004851,
        "accuracy": 0.007984,
        "main_score": 0.004851,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.004276,
        "recall": 0.009315,
        "f1": 0.00511,
        "accuracy": 0.009315,
        "main_score": 0.00511,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.041269,
        "recall": 0.05855,
        "f1": 0.043693,
        "accuracy": 0.05855,
        "main_score": 0.043693,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.024937,
        "recall": 0.031271,
        "f1": 0.026381,
        "accuracy": 0.031271,
        "main_score": 0.026381,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.030087,
        "recall": 0.036593,
        "f1": 0.031523,
        "accuracy": 0.036593,
        "main_score": 0.031523,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 41.419904470443726,
  "kg_co2_emissions": 0.0012035137688716862
}