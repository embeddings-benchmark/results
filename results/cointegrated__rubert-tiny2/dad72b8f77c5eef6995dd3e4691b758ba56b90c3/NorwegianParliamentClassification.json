{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.525833,
        "f1": 0.521591,
        "f1_weighted": 0.521591,
        "ap": 0.514571,
        "ap_weighted": 0.514571,
        "scores_per_experiment": [
          {
            "accuracy": 0.558333,
            "f1": 0.557565,
            "f1_weighted": 0.557565,
            "ap": 0.532879,
            "ap_weighted": 0.532879
          },
          {
            "accuracy": 0.47,
            "f1": 0.462897,
            "f1_weighted": 0.462897,
            "ap": 0.486169,
            "ap_weighted": 0.486169
          },
          {
            "accuracy": 0.538333,
            "f1": 0.538322,
            "f1_weighted": 0.538322,
            "ap": 0.520651,
            "ap_weighted": 0.520651
          },
          {
            "accuracy": 0.535,
            "f1": 0.53046,
            "f1_weighted": 0.53046,
            "ap": 0.519025,
            "ap_weighted": 0.519025
          },
          {
            "accuracy": 0.571667,
            "f1": 0.57119,
            "f1_weighted": 0.57119,
            "ap": 0.540648,
            "ap_weighted": 0.540648
          },
          {
            "accuracy": 0.483333,
            "f1": 0.466033,
            "f1_weighted": 0.466033,
            "ap": 0.491871,
            "ap_weighted": 0.491871
          },
          {
            "accuracy": 0.523333,
            "f1": 0.520872,
            "f1_weighted": 0.520872,
            "ap": 0.512302,
            "ap_weighted": 0.512302
          },
          {
            "accuracy": 0.534167,
            "f1": 0.533511,
            "f1_weighted": 0.533511,
            "ap": 0.518345,
            "ap_weighted": 0.518345
          },
          {
            "accuracy": 0.545833,
            "f1": 0.540524,
            "f1_weighted": 0.540524,
            "ap": 0.524646,
            "ap_weighted": 0.524646
          },
          {
            "accuracy": 0.498333,
            "f1": 0.494537,
            "f1_weighted": 0.494537,
            "ap": 0.49917,
            "ap_weighted": 0.49917
          }
        ],
        "main_score": 0.525833,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.526917,
        "f1": 0.522857,
        "f1_weighted": 0.522857,
        "ap": 0.515535,
        "ap_weighted": 0.515535,
        "scores_per_experiment": [
          {
            "accuracy": 0.550833,
            "f1": 0.550308,
            "f1_weighted": 0.550308,
            "ap": 0.52819,
            "ap_weighted": 0.52819
          },
          {
            "accuracy": 0.465833,
            "f1": 0.456531,
            "f1_weighted": 0.456531,
            "ap": 0.484498,
            "ap_weighted": 0.484498
          },
          {
            "accuracy": 0.548333,
            "f1": 0.548313,
            "f1_weighted": 0.548313,
            "ap": 0.526534,
            "ap_weighted": 0.526534
          },
          {
            "accuracy": 0.531667,
            "f1": 0.527249,
            "f1_weighted": 0.527249,
            "ap": 0.517076,
            "ap_weighted": 0.517076
          },
          {
            "accuracy": 0.579167,
            "f1": 0.579131,
            "f1_weighted": 0.579131,
            "ap": 0.545738,
            "ap_weighted": 0.545738
          },
          {
            "accuracy": 0.4725,
            "f1": 0.457273,
            "f1_weighted": 0.457273,
            "ap": 0.486816,
            "ap_weighted": 0.486816
          },
          {
            "accuracy": 0.533333,
            "f1": 0.531647,
            "f1_weighted": 0.531647,
            "ap": 0.517929,
            "ap_weighted": 0.517929
          },
          {
            "accuracy": 0.543333,
            "f1": 0.543008,
            "f1_weighted": 0.543008,
            "ap": 0.52365,
            "ap_weighted": 0.52365
          },
          {
            "accuracy": 0.556667,
            "f1": 0.551564,
            "f1_weighted": 0.551564,
            "ap": 0.53098,
            "ap_weighted": 0.53098
          },
          {
            "accuracy": 0.4875,
            "f1": 0.483546,
            "f1_weighted": 0.483546,
            "ap": 0.493939,
            "ap_weighted": 0.493939
          }
        ],
        "main_score": 0.526917,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 16.252256155014038,
  "kg_co2_emissions": 0.0005570463474205026
}