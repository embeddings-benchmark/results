{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.703467,
        "f1": 0.703126,
        "f1_weighted": 0.703132,
        "ap": 0.644512,
        "ap_weighted": 0.644512,
        "scores_per_experiment": [
          {
            "accuracy": 0.713867,
            "f1": 0.713493,
            "f1_weighted": 0.713523,
            "ap": 0.650956,
            "ap_weighted": 0.650956
          },
          {
            "accuracy": 0.706543,
            "f1": 0.706388,
            "f1_weighted": 0.706408,
            "ap": 0.645463,
            "ap_weighted": 0.645463
          },
          {
            "accuracy": 0.701172,
            "f1": 0.70088,
            "f1_weighted": 0.700852,
            "ap": 0.645317,
            "ap_weighted": 0.645317
          },
          {
            "accuracy": 0.694824,
            "f1": 0.693755,
            "f1_weighted": 0.693808,
            "ap": 0.632669,
            "ap_weighted": 0.632669
          },
          {
            "accuracy": 0.708008,
            "f1": 0.707562,
            "f1_weighted": 0.707528,
            "ap": 0.652528,
            "ap_weighted": 0.652528
          },
          {
            "accuracy": 0.687012,
            "f1": 0.686957,
            "f1_weighted": 0.686969,
            "ap": 0.629014,
            "ap_weighted": 0.629014
          },
          {
            "accuracy": 0.710449,
            "f1": 0.71006,
            "f1_weighted": 0.710029,
            "ap": 0.654597,
            "ap_weighted": 0.654597
          },
          {
            "accuracy": 0.71875,
            "f1": 0.71875,
            "f1_weighted": 0.718749,
            "ap": 0.658792,
            "ap_weighted": 0.658792
          },
          {
            "accuracy": 0.687988,
            "f1": 0.687398,
            "f1_weighted": 0.687438,
            "ap": 0.627861,
            "ap_weighted": 0.627861
          },
          {
            "accuracy": 0.706055,
            "f1": 0.706021,
            "f1_weighted": 0.706012,
            "ap": 0.647919,
            "ap_weighted": 0.647919
          }
        ],
        "main_score": 0.703467,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.712109,
        "f1": 0.711686,
        "f1_weighted": 0.711695,
        "ap": 0.650982,
        "ap_weighted": 0.650982,
        "scores_per_experiment": [
          {
            "accuracy": 0.71875,
            "f1": 0.718156,
            "f1_weighted": 0.718182,
            "ap": 0.654094,
            "ap_weighted": 0.654094
          },
          {
            "accuracy": 0.708984,
            "f1": 0.708494,
            "f1_weighted": 0.708517,
            "ap": 0.645757,
            "ap_weighted": 0.645757
          },
          {
            "accuracy": 0.702637,
            "f1": 0.702517,
            "f1_weighted": 0.702506,
            "ap": 0.645111,
            "ap_weighted": 0.645111
          },
          {
            "accuracy": 0.70752,
            "f1": 0.706127,
            "f1_weighted": 0.706166,
            "ap": 0.642465,
            "ap_weighted": 0.642465
          },
          {
            "accuracy": 0.716797,
            "f1": 0.716484,
            "f1_weighted": 0.716466,
            "ap": 0.659791,
            "ap_weighted": 0.659791
          },
          {
            "accuracy": 0.706055,
            "f1": 0.705943,
            "f1_weighted": 0.705954,
            "ap": 0.644831,
            "ap_weighted": 0.644831
          },
          {
            "accuracy": 0.710938,
            "f1": 0.710816,
            "f1_weighted": 0.710804,
            "ap": 0.652886,
            "ap_weighted": 0.652886
          },
          {
            "accuracy": 0.726074,
            "f1": 0.726074,
            "f1_weighted": 0.726073,
            "ap": 0.665278,
            "ap_weighted": 0.665278
          },
          {
            "accuracy": 0.70459,
            "f1": 0.70352,
            "f1_weighted": 0.703555,
            "ap": 0.640532,
            "ap_weighted": 0.640532
          },
          {
            "accuracy": 0.71875,
            "f1": 0.718728,
            "f1_weighted": 0.718723,
            "ap": 0.659079,
            "ap_weighted": 0.659079
          }
        ],
        "main_score": 0.712109,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.490787744522095,
  "kg_co2_emissions": 0.00045795363852394654
}