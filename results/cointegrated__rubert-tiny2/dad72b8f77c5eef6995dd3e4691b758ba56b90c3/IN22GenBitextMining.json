{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.118009,
        "recall": 0.15918,
        "f1": 0.129128,
        "accuracy": 0.15918,
        "main_score": 0.129128,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.079015,
        "recall": 0.130859,
        "f1": 0.091247,
        "accuracy": 0.130859,
        "main_score": 0.091247,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.044843,
        "recall": 0.074219,
        "f1": 0.051567,
        "accuracy": 0.074219,
        "main_score": 0.051567,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00011,
        "recall": 0.001953,
        "f1": 0.000199,
        "accuracy": 0.001953,
        "main_score": 0.000199,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.042573,
        "recall": 0.078125,
        "f1": 0.050395,
        "accuracy": 0.078125,
        "main_score": 0.050395,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.094437,
        "recall": 0.134766,
        "f1": 0.104393,
        "accuracy": 0.134766,
        "main_score": 0.104393,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.05982,
        "recall": 0.101562,
        "f1": 0.070086,
        "accuracy": 0.101562,
        "main_score": 0.070086,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.059984,
        "recall": 0.083008,
        "f1": 0.064934,
        "accuracy": 0.083008,
        "main_score": 0.064934,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.015958,
        "recall": 0.037109,
        "f1": 0.020314,
        "accuracy": 0.037109,
        "main_score": 0.020314,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.115423,
        "recall": 0.160156,
        "f1": 0.127653,
        "accuracy": 0.160156,
        "main_score": 0.127653,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.017007,
        "recall": 0.030273,
        "f1": 0.019468,
        "accuracy": 0.030273,
        "main_score": 0.019468,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.087213,
        "recall": 0.123047,
        "f1": 0.096834,
        "accuracy": 0.123047,
        "main_score": 0.096834,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.119141,
        "recall": 0.15918,
        "f1": 0.129367,
        "accuracy": 0.15918,
        "main_score": 0.129367,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.102458,
        "recall": 0.144531,
        "f1": 0.112423,
        "accuracy": 0.144531,
        "main_score": 0.112423,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.122762,
        "recall": 0.15918,
        "f1": 0.13182,
        "accuracy": 0.15918,
        "main_score": 0.13182,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.023994,
        "recall": 0.048828,
        "f1": 0.028241,
        "accuracy": 0.048828,
        "main_score": 0.028241,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.05413,
        "recall": 0.080078,
        "f1": 0.059619,
        "accuracy": 0.080078,
        "main_score": 0.059619,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.080204,
        "recall": 0.109375,
        "f1": 0.087223,
        "accuracy": 0.109375,
        "main_score": 0.087223,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.052372,
        "recall": 0.087891,
        "f1": 0.060572,
        "accuracy": 0.087891,
        "main_score": 0.060572,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.027812,
        "recall": 0.051758,
        "f1": 0.032567,
        "accuracy": 0.051758,
        "main_score": 0.032567,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.029497,
        "recall": 0.053711,
        "f1": 0.033949,
        "accuracy": 0.053711,
        "main_score": 0.033949,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.012683,
        "recall": 0.027344,
        "f1": 0.015553,
        "accuracy": 0.027344,
        "main_score": 0.015553,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.097608,
        "recall": 0.134766,
        "f1": 0.10741,
        "accuracy": 0.134766,
        "main_score": 0.10741,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.046846,
        "recall": 0.082031,
        "f1": 0.054446,
        "accuracy": 0.082031,
        "main_score": 0.054446,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.034515,
        "recall": 0.05957,
        "f1": 0.040351,
        "accuracy": 0.05957,
        "main_score": 0.040351,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001118,
        "recall": 0.00293,
        "f1": 0.001224,
        "accuracy": 0.00293,
        "main_score": 0.001224,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.04199,
        "recall": 0.078125,
        "f1": 0.049092,
        "accuracy": 0.078125,
        "main_score": 0.049092,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.058994,
        "recall": 0.097656,
        "f1": 0.068299,
        "accuracy": 0.097656,
        "main_score": 0.068299,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.04144,
        "recall": 0.067383,
        "f1": 0.047476,
        "accuracy": 0.067383,
        "main_score": 0.047476,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.067413,
        "recall": 0.09375,
        "f1": 0.073209,
        "accuracy": 0.09375,
        "main_score": 0.073209,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.012577,
        "recall": 0.030273,
        "f1": 0.015011,
        "accuracy": 0.030273,
        "main_score": 0.015011,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.093091,
        "recall": 0.130859,
        "f1": 0.10262,
        "accuracy": 0.130859,
        "main_score": 0.10262,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.020774,
        "recall": 0.032227,
        "f1": 0.022819,
        "accuracy": 0.032227,
        "main_score": 0.022819,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.079898,
        "recall": 0.110352,
        "f1": 0.08734,
        "accuracy": 0.110352,
        "main_score": 0.08734,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.094157,
        "recall": 0.132812,
        "f1": 0.104112,
        "accuracy": 0.132812,
        "main_score": 0.104112,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.116157,
        "recall": 0.15332,
        "f1": 0.1264,
        "accuracy": 0.15332,
        "main_score": 0.1264,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.082215,
        "recall": 0.116211,
        "f1": 0.090344,
        "accuracy": 0.116211,
        "main_score": 0.090344,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.022141,
        "recall": 0.041992,
        "f1": 0.025339,
        "accuracy": 0.041992,
        "main_score": 0.025339,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.045462,
        "recall": 0.072266,
        "f1": 0.051439,
        "accuracy": 0.072266,
        "main_score": 0.051439,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.133953,
        "recall": 0.183594,
        "f1": 0.146682,
        "accuracy": 0.183594,
        "main_score": 0.146682,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.033881,
        "recall": 0.05957,
        "f1": 0.039142,
        "accuracy": 0.05957,
        "main_score": 0.039142,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.044097,
        "recall": 0.068359,
        "f1": 0.049328,
        "accuracy": 0.068359,
        "main_score": 0.049328,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.038874,
        "recall": 0.06543,
        "f1": 0.044199,
        "accuracy": 0.06543,
        "main_score": 0.044199,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.009093,
        "recall": 0.018555,
        "f1": 0.010769,
        "accuracy": 0.018555,
        "main_score": 0.010769,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.1217,
        "recall": 0.168945,
        "f1": 0.134361,
        "accuracy": 0.168945,
        "main_score": 0.134361,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.077856,
        "recall": 0.110352,
        "f1": 0.085889,
        "accuracy": 0.110352,
        "main_score": 0.085889,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.284502,
        "recall": 0.316406,
        "f1": 0.29277,
        "accuracy": 0.316406,
        "main_score": 0.29277,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.057693,
        "recall": 0.081055,
        "f1": 0.061963,
        "accuracy": 0.081055,
        "main_score": 0.061963,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.318451,
        "recall": 0.354492,
        "f1": 0.328289,
        "accuracy": 0.354492,
        "main_score": 0.328289,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.092181,
        "recall": 0.145508,
        "f1": 0.103513,
        "accuracy": 0.145508,
        "main_score": 0.103513,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.30915,
        "recall": 0.338867,
        "f1": 0.317315,
        "accuracy": 0.338867,
        "main_score": 0.317315,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.067398,
        "recall": 0.099609,
        "f1": 0.074299,
        "accuracy": 0.099609,
        "main_score": 0.074299,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.234278,
        "recall": 0.259766,
        "f1": 0.240926,
        "accuracy": 0.259766,
        "main_score": 0.240926,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.071343,
        "recall": 0.113281,
        "f1": 0.080616,
        "accuracy": 0.113281,
        "main_score": 0.080616,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.175557,
        "recall": 0.213867,
        "f1": 0.18502,
        "accuracy": 0.213867,
        "main_score": 0.18502,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.070044,
        "recall": 0.102539,
        "f1": 0.077642,
        "accuracy": 0.102539,
        "main_score": 0.077642,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.070681,
        "recall": 0.107422,
        "f1": 0.078899,
        "accuracy": 0.107422,
        "main_score": 0.078899,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.077971,
        "recall": 0.115234,
        "f1": 0.087079,
        "accuracy": 0.115234,
        "main_score": 0.087079,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.089842,
        "recall": 0.128906,
        "f1": 0.099652,
        "accuracy": 0.128906,
        "main_score": 0.099652,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.278264,
        "recall": 0.305664,
        "f1": 0.284304,
        "accuracy": 0.305664,
        "main_score": 0.284304,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.051234,
        "recall": 0.074219,
        "f1": 0.056497,
        "accuracy": 0.074219,
        "main_score": 0.056497,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.044739,
        "recall": 0.071289,
        "f1": 0.050235,
        "accuracy": 0.071289,
        "main_score": 0.050235,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.301594,
        "recall": 0.333008,
        "f1": 0.309773,
        "accuracy": 0.333008,
        "main_score": 0.309773,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.197448,
        "recall": 0.245117,
        "f1": 0.210053,
        "accuracy": 0.245117,
        "main_score": 0.210053,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.226756,
        "recall": 0.276367,
        "f1": 0.240247,
        "accuracy": 0.276367,
        "main_score": 0.240247,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.258646,
        "recall": 0.274414,
        "f1": 0.262777,
        "accuracy": 0.274414,
        "main_score": 0.262777,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.051258,
        "recall": 0.078125,
        "f1": 0.057903,
        "accuracy": 0.078125,
        "main_score": 0.057903,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.040213,
        "recall": 0.05957,
        "f1": 0.044816,
        "accuracy": 0.05957,
        "main_score": 0.044816,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.280826,
        "recall": 0.305664,
        "f1": 0.287315,
        "accuracy": 0.305664,
        "main_score": 0.287315,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.059453,
        "recall": 0.084961,
        "f1": 0.064029,
        "accuracy": 0.084961,
        "main_score": 0.064029,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.255451,
        "recall": 0.276367,
        "f1": 0.260632,
        "accuracy": 0.276367,
        "main_score": 0.260632,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.053573,
        "recall": 0.088867,
        "f1": 0.060894,
        "accuracy": 0.088867,
        "main_score": 0.060894,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.345177,
        "recall": 0.386719,
        "f1": 0.356901,
        "accuracy": 0.386719,
        "main_score": 0.356901,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.029405,
        "recall": 0.041992,
        "f1": 0.031668,
        "accuracy": 0.041992,
        "main_score": 0.031668,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.264417,
        "recall": 0.291992,
        "f1": 0.271712,
        "accuracy": 0.291992,
        "main_score": 0.271712,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.071664,
        "recall": 0.108398,
        "f1": 0.081058,
        "accuracy": 0.108398,
        "main_score": 0.081058,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.153884,
        "recall": 0.185547,
        "f1": 0.161948,
        "accuracy": 0.185547,
        "main_score": 0.161948,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.035302,
        "recall": 0.050781,
        "f1": 0.038294,
        "accuracy": 0.050781,
        "main_score": 0.038294,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.044178,
        "recall": 0.074219,
        "f1": 0.050896,
        "accuracy": 0.074219,
        "main_score": 0.050896,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.059419,
        "recall": 0.079102,
        "f1": 0.06391,
        "accuracy": 0.079102,
        "main_score": 0.06391,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.051996,
        "recall": 0.080078,
        "f1": 0.058367,
        "accuracy": 0.080078,
        "main_score": 0.058367,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.301402,
        "recall": 0.356445,
        "f1": 0.314717,
        "accuracy": 0.356445,
        "main_score": 0.314717,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019277,
        "recall": 0.030273,
        "f1": 0.021453,
        "accuracy": 0.030273,
        "main_score": 0.021453,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.084244,
        "recall": 0.116211,
        "f1": 0.092111,
        "accuracy": 0.116211,
        "main_score": 0.092111,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.340902,
        "recall": 0.382812,
        "f1": 0.352356,
        "accuracy": 0.382812,
        "main_score": 0.352356,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.176656,
        "recall": 0.210938,
        "f1": 0.185176,
        "accuracy": 0.210938,
        "main_score": 0.185176,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.205328,
        "recall": 0.236328,
        "f1": 0.21394,
        "accuracy": 0.236328,
        "main_score": 0.21394,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.291237,
        "recall": 0.316406,
        "f1": 0.297216,
        "accuracy": 0.316406,
        "main_score": 0.297216,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.006712,
        "recall": 0.012695,
        "f1": 0.007579,
        "accuracy": 0.012695,
        "main_score": 0.007579,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.002208,
        "recall": 0.007812,
        "f1": 0.002419,
        "accuracy": 0.007812,
        "main_score": 0.002419,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.104486,
        "recall": 0.144531,
        "f1": 0.111226,
        "accuracy": 0.144531,
        "main_score": 0.111226,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.088095,
        "recall": 0.120117,
        "f1": 0.094217,
        "accuracy": 0.120117,
        "main_score": 0.094217,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.09356,
        "recall": 0.142578,
        "f1": 0.100699,
        "accuracy": 0.142578,
        "main_score": 0.100699,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.011048,
        "recall": 0.03125,
        "f1": 0.013381,
        "accuracy": 0.03125,
        "main_score": 0.013381,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.090258,
        "recall": 0.129883,
        "f1": 0.096264,
        "accuracy": 0.129883,
        "main_score": 0.096264,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.005093,
        "recall": 0.015625,
        "f1": 0.005776,
        "accuracy": 0.015625,
        "main_score": 0.005776,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.073483,
        "recall": 0.094727,
        "f1": 0.077328,
        "accuracy": 0.094727,
        "main_score": 0.077328,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.003855,
        "recall": 0.016602,
        "f1": 0.004929,
        "accuracy": 0.016602,
        "main_score": 0.004929,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.074144,
        "recall": 0.117188,
        "f1": 0.080502,
        "accuracy": 0.117188,
        "main_score": 0.080502,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.005328,
        "recall": 0.015625,
        "f1": 0.006158,
        "accuracy": 0.015625,
        "main_score": 0.006158,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003541,
        "recall": 0.014648,
        "f1": 0.004501,
        "accuracy": 0.014648,
        "main_score": 0.004501,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.004624,
        "recall": 0.016602,
        "f1": 0.006053,
        "accuracy": 0.016602,
        "main_score": 0.006053,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.004133,
        "recall": 0.014648,
        "f1": 0.005315,
        "accuracy": 0.014648,
        "main_score": 0.005315,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.083827,
        "recall": 0.123047,
        "f1": 0.090347,
        "accuracy": 0.123047,
        "main_score": 0.090347,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.002776,
        "recall": 0.008789,
        "f1": 0.003251,
        "accuracy": 0.008789,
        "main_score": 0.003251,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002472,
        "recall": 0.010742,
        "f1": 0.003137,
        "accuracy": 0.010742,
        "main_score": 0.003137,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.081352,
        "recall": 0.099609,
        "f1": 0.085149,
        "accuracy": 0.099609,
        "main_score": 0.085149,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.077664,
        "recall": 0.117188,
        "f1": 0.083582,
        "accuracy": 0.117188,
        "main_score": 0.083582,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.087381,
        "recall": 0.137695,
        "f1": 0.095073,
        "accuracy": 0.137695,
        "main_score": 0.095073,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.077283,
        "recall": 0.121094,
        "f1": 0.083876,
        "accuracy": 0.121094,
        "main_score": 0.083876,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.064165,
        "recall": 0.099609,
        "f1": 0.073177,
        "accuracy": 0.099609,
        "main_score": 0.073177,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.06173,
        "recall": 0.095703,
        "f1": 0.070245,
        "accuracy": 0.095703,
        "main_score": 0.070245,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.30579,
        "recall": 0.34375,
        "f1": 0.316282,
        "accuracy": 0.34375,
        "main_score": 0.316282,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.266487,
        "recall": 0.301758,
        "f1": 0.274901,
        "accuracy": 0.301758,
        "main_score": 0.274901,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.057095,
        "recall": 0.082031,
        "f1": 0.062084,
        "accuracy": 0.082031,
        "main_score": 0.062084,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.098475,
        "recall": 0.162109,
        "f1": 0.112524,
        "accuracy": 0.162109,
        "main_score": 0.112524,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.275211,
        "recall": 0.308594,
        "f1": 0.283791,
        "accuracy": 0.308594,
        "main_score": 0.283791,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.095067,
        "recall": 0.135742,
        "f1": 0.105795,
        "accuracy": 0.135742,
        "main_score": 0.105795,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.220402,
        "recall": 0.25,
        "f1": 0.227737,
        "accuracy": 0.25,
        "main_score": 0.227737,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.053071,
        "recall": 0.087891,
        "f1": 0.06118,
        "accuracy": 0.087891,
        "main_score": 0.06118,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.193293,
        "recall": 0.243164,
        "f1": 0.20671,
        "accuracy": 0.243164,
        "main_score": 0.20671,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.103335,
        "recall": 0.141602,
        "f1": 0.112813,
        "accuracy": 0.141602,
        "main_score": 0.112813,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.058743,
        "recall": 0.098633,
        "f1": 0.067564,
        "accuracy": 0.098633,
        "main_score": 0.067564,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.075086,
        "recall": 0.109375,
        "f1": 0.083622,
        "accuracy": 0.109375,
        "main_score": 0.083622,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.079145,
        "recall": 0.116211,
        "f1": 0.088822,
        "accuracy": 0.116211,
        "main_score": 0.088822,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.256013,
        "recall": 0.283203,
        "f1": 0.262722,
        "accuracy": 0.283203,
        "main_score": 0.262722,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.058652,
        "recall": 0.086914,
        "f1": 0.06475,
        "accuracy": 0.086914,
        "main_score": 0.06475,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.035144,
        "recall": 0.05957,
        "f1": 0.040086,
        "accuracy": 0.05957,
        "main_score": 0.040086,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.271007,
        "recall": 0.298828,
        "f1": 0.27873,
        "accuracy": 0.298828,
        "main_score": 0.27873,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.221807,
        "recall": 0.272461,
        "f1": 0.235006,
        "accuracy": 0.272461,
        "main_score": 0.235006,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.256735,
        "recall": 0.301758,
        "f1": 0.268974,
        "accuracy": 0.301758,
        "main_score": 0.268974,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.241146,
        "recall": 0.260742,
        "f1": 0.246309,
        "accuracy": 0.260742,
        "main_score": 0.246309,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.083782,
        "recall": 0.128906,
        "f1": 0.095145,
        "accuracy": 0.128906,
        "main_score": 0.095145,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.077764,
        "recall": 0.118164,
        "f1": 0.087587,
        "accuracy": 0.118164,
        "main_score": 0.087587,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.089943,
        "recall": 0.132812,
        "f1": 0.098861,
        "accuracy": 0.132812,
        "main_score": 0.098861,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.062791,
        "recall": 0.088867,
        "f1": 0.067996,
        "accuracy": 0.088867,
        "main_score": 0.067996,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.010877,
        "recall": 0.014648,
        "f1": 0.011398,
        "accuracy": 0.014648,
        "main_score": 0.011398,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.103048,
        "recall": 0.143555,
        "f1": 0.112477,
        "accuracy": 0.143555,
        "main_score": 0.112477,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.074493,
        "recall": 0.107422,
        "f1": 0.081929,
        "accuracy": 0.107422,
        "main_score": 0.081929,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.090291,
        "recall": 0.119141,
        "f1": 0.097524,
        "accuracy": 0.119141,
        "main_score": 0.097524,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.044676,
        "recall": 0.056641,
        "f1": 0.047104,
        "accuracy": 0.056641,
        "main_score": 0.047104,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.075596,
        "recall": 0.111328,
        "f1": 0.084736,
        "accuracy": 0.111328,
        "main_score": 0.084736,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.056601,
        "recall": 0.074219,
        "f1": 0.060668,
        "accuracy": 0.074219,
        "main_score": 0.060668,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.092399,
        "recall": 0.131836,
        "f1": 0.102406,
        "accuracy": 0.131836,
        "main_score": 0.102406,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.069857,
        "recall": 0.107422,
        "f1": 0.080219,
        "accuracy": 0.107422,
        "main_score": 0.080219,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.070087,
        "recall": 0.104492,
        "f1": 0.07772,
        "accuracy": 0.104492,
        "main_score": 0.07772,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.090106,
        "recall": 0.131836,
        "f1": 0.100177,
        "accuracy": 0.131836,
        "main_score": 0.100177,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.061461,
        "recall": 0.083008,
        "f1": 0.06557,
        "accuracy": 0.083008,
        "main_score": 0.06557,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.045447,
        "recall": 0.071289,
        "f1": 0.050777,
        "accuracy": 0.071289,
        "main_score": 0.050777,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.051516,
        "recall": 0.074219,
        "f1": 0.05703,
        "accuracy": 0.074219,
        "main_score": 0.05703,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.067184,
        "recall": 0.091797,
        "f1": 0.07262,
        "accuracy": 0.091797,
        "main_score": 0.07262,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.065335,
        "recall": 0.083984,
        "f1": 0.069441,
        "accuracy": 0.083984,
        "main_score": 0.069441,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.070141,
        "recall": 0.097656,
        "f1": 0.075974,
        "accuracy": 0.097656,
        "main_score": 0.075974,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.044074,
        "recall": 0.051758,
        "f1": 0.045234,
        "accuracy": 0.051758,
        "main_score": 0.045234,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.069365,
        "recall": 0.094727,
        "f1": 0.075782,
        "accuracy": 0.094727,
        "main_score": 0.075782,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.049756,
        "recall": 0.072266,
        "f1": 0.055437,
        "accuracy": 0.072266,
        "main_score": 0.055437,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.290488,
        "recall": 0.319336,
        "f1": 0.297768,
        "accuracy": 0.319336,
        "main_score": 0.297768,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.344628,
        "recall": 0.384766,
        "f1": 0.35573,
        "accuracy": 0.384766,
        "main_score": 0.35573,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.055813,
        "recall": 0.083008,
        "f1": 0.060719,
        "accuracy": 0.083008,
        "main_score": 0.060719,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.247444,
        "recall": 0.275391,
        "f1": 0.254721,
        "accuracy": 0.275391,
        "main_score": 0.254721,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.062378,
        "recall": 0.101562,
        "f1": 0.070625,
        "accuracy": 0.101562,
        "main_score": 0.070625,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.025636,
        "recall": 0.037109,
        "f1": 0.02794,
        "accuracy": 0.037109,
        "main_score": 0.02794,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.245933,
        "recall": 0.274414,
        "f1": 0.253335,
        "accuracy": 0.274414,
        "main_score": 0.253335,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.068841,
        "recall": 0.099609,
        "f1": 0.076179,
        "accuracy": 0.099609,
        "main_score": 0.076179,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.145524,
        "recall": 0.177734,
        "f1": 0.154142,
        "accuracy": 0.177734,
        "main_score": 0.154142,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.029394,
        "recall": 0.045898,
        "f1": 0.032795,
        "accuracy": 0.045898,
        "main_score": 0.032795,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.058122,
        "recall": 0.094727,
        "f1": 0.066856,
        "accuracy": 0.094727,
        "main_score": 0.066856,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.039365,
        "recall": 0.057617,
        "f1": 0.042998,
        "accuracy": 0.057617,
        "main_score": 0.042998,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.061817,
        "recall": 0.092773,
        "f1": 0.068504,
        "accuracy": 0.092773,
        "main_score": 0.068504,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.29595,
        "recall": 0.341797,
        "f1": 0.306872,
        "accuracy": 0.341797,
        "main_score": 0.306872,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.026673,
        "recall": 0.040039,
        "f1": 0.029506,
        "accuracy": 0.040039,
        "main_score": 0.029506,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.05305,
        "recall": 0.079102,
        "f1": 0.059542,
        "accuracy": 0.079102,
        "main_score": 0.059542,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.397609,
        "recall": 0.435547,
        "f1": 0.407946,
        "accuracy": 0.435547,
        "main_score": 0.407946,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.164902,
        "recall": 0.202148,
        "f1": 0.174538,
        "accuracy": 0.202148,
        "main_score": 0.174538,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.194959,
        "recall": 0.231445,
        "f1": 0.204429,
        "accuracy": 0.231445,
        "main_score": 0.204429,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.299878,
        "recall": 0.323242,
        "f1": 0.305501,
        "accuracy": 0.323242,
        "main_score": 0.305501,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.065592,
        "recall": 0.102539,
        "f1": 0.074532,
        "accuracy": 0.102539,
        "main_score": 0.074532,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.064628,
        "recall": 0.103516,
        "f1": 0.073379,
        "accuracy": 0.103516,
        "main_score": 0.073379,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.04012,
        "recall": 0.082031,
        "f1": 0.048163,
        "accuracy": 0.082031,
        "main_score": 0.048163,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.018206,
        "recall": 0.03418,
        "f1": 0.020839,
        "accuracy": 0.03418,
        "main_score": 0.020839,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001901,
        "recall": 0.004883,
        "f1": 0.002315,
        "accuracy": 0.004883,
        "main_score": 0.002315,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.069194,
        "recall": 0.121094,
        "f1": 0.082136,
        "accuracy": 0.121094,
        "main_score": 0.082136,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.079495,
        "recall": 0.123047,
        "f1": 0.090434,
        "accuracy": 0.123047,
        "main_score": 0.090434,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.018929,
        "recall": 0.042969,
        "f1": 0.023386,
        "accuracy": 0.042969,
        "main_score": 0.023386,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00749,
        "recall": 0.019531,
        "f1": 0.009312,
        "accuracy": 0.019531,
        "main_score": 0.009312,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.048954,
        "recall": 0.083008,
        "f1": 0.056386,
        "accuracy": 0.083008,
        "main_score": 0.056386,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.051068,
        "recall": 0.086914,
        "f1": 0.059332,
        "accuracy": 0.086914,
        "main_score": 0.059332,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.112191,
        "recall": 0.145508,
        "f1": 0.121615,
        "accuracy": 0.145508,
        "main_score": 0.121615,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.04753,
        "recall": 0.088867,
        "f1": 0.056531,
        "accuracy": 0.088867,
        "main_score": 0.056531,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.075272,
        "recall": 0.110352,
        "f1": 0.083165,
        "accuracy": 0.110352,
        "main_score": 0.083165,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.073506,
        "recall": 0.113281,
        "f1": 0.082912,
        "accuracy": 0.113281,
        "main_score": 0.082912,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.015175,
        "recall": 0.03418,
        "f1": 0.018032,
        "accuracy": 0.03418,
        "main_score": 0.018032,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.070784,
        "recall": 0.108398,
        "f1": 0.079502,
        "accuracy": 0.108398,
        "main_score": 0.079502,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.02937,
        "recall": 0.053711,
        "f1": 0.033639,
        "accuracy": 0.053711,
        "main_score": 0.033639,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.020421,
        "recall": 0.036133,
        "f1": 0.023403,
        "accuracy": 0.036133,
        "main_score": 0.023403,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.063439,
        "recall": 0.102539,
        "f1": 0.072817,
        "accuracy": 0.102539,
        "main_score": 0.072817,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.07363,
        "recall": 0.115234,
        "f1": 0.082727,
        "accuracy": 0.115234,
        "main_score": 0.082727,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004963,
        "recall": 0.012695,
        "f1": 0.006019,
        "accuracy": 0.012695,
        "main_score": 0.006019,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.013637,
        "recall": 0.024414,
        "f1": 0.015066,
        "accuracy": 0.024414,
        "main_score": 0.015066,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.012921,
        "recall": 0.02832,
        "f1": 0.015189,
        "accuracy": 0.02832,
        "main_score": 0.015189,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.220485,
        "recall": 0.245117,
        "f1": 0.226058,
        "accuracy": 0.245117,
        "main_score": 0.226058,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.249642,
        "recall": 0.277344,
        "f1": 0.256112,
        "accuracy": 0.277344,
        "main_score": 0.256112,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.058674,
        "recall": 0.086914,
        "f1": 0.063953,
        "accuracy": 0.086914,
        "main_score": 0.063953,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.202735,
        "recall": 0.223633,
        "f1": 0.207795,
        "accuracy": 0.223633,
        "main_score": 0.207795,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.030581,
        "recall": 0.058594,
        "f1": 0.035602,
        "accuracy": 0.058594,
        "main_score": 0.035602,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.238446,
        "recall": 0.263672,
        "f1": 0.244301,
        "accuracy": 0.263672,
        "main_score": 0.244301,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.006281,
        "recall": 0.013672,
        "f1": 0.00746,
        "accuracy": 0.013672,
        "main_score": 0.00746,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.018074,
        "recall": 0.038086,
        "f1": 0.02144,
        "accuracy": 0.038086,
        "main_score": 0.02144,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.139336,
        "recall": 0.166992,
        "f1": 0.146212,
        "accuracy": 0.166992,
        "main_score": 0.146212,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.007694,
        "recall": 0.018555,
        "f1": 0.009071,
        "accuracy": 0.018555,
        "main_score": 0.009071,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.012385,
        "recall": 0.030273,
        "f1": 0.014804,
        "accuracy": 0.030273,
        "main_score": 0.014804,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.017871,
        "recall": 0.032227,
        "f1": 0.020551,
        "accuracy": 0.032227,
        "main_score": 0.020551,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.009919,
        "recall": 0.024414,
        "f1": 0.01196,
        "accuracy": 0.024414,
        "main_score": 0.01196,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.232159,
        "recall": 0.255859,
        "f1": 0.237232,
        "accuracy": 0.255859,
        "main_score": 0.237232,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.007553,
        "recall": 0.011719,
        "f1": 0.007878,
        "accuracy": 0.011719,
        "main_score": 0.007878,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.010207,
        "recall": 0.027344,
        "f1": 0.012653,
        "accuracy": 0.027344,
        "main_score": 0.012653,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.235031,
        "recall": 0.262695,
        "f1": 0.240996,
        "accuracy": 0.262695,
        "main_score": 0.240996,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.151312,
        "recall": 0.179688,
        "f1": 0.157986,
        "accuracy": 0.179688,
        "main_score": 0.157986,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.172915,
        "recall": 0.201172,
        "f1": 0.180572,
        "accuracy": 0.201172,
        "main_score": 0.180572,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.2681,
        "recall": 0.292969,
        "f1": 0.275212,
        "accuracy": 0.292969,
        "main_score": 0.275212,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.105234,
        "recall": 0.145508,
        "f1": 0.114813,
        "accuracy": 0.145508,
        "main_score": 0.114813,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.103967,
        "recall": 0.133789,
        "f1": 0.111484,
        "accuracy": 0.133789,
        "main_score": 0.111484,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.046013,
        "recall": 0.077148,
        "f1": 0.052146,
        "accuracy": 0.077148,
        "main_score": 0.052146,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.05644,
        "recall": 0.087891,
        "f1": 0.063782,
        "accuracy": 0.087891,
        "main_score": 0.063782,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003101,
        "recall": 0.005859,
        "f1": 0.003235,
        "accuracy": 0.005859,
        "main_score": 0.003235,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.033698,
        "recall": 0.058594,
        "f1": 0.039053,
        "accuracy": 0.058594,
        "main_score": 0.039053,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.070698,
        "recall": 0.101562,
        "f1": 0.078451,
        "accuracy": 0.101562,
        "main_score": 0.078451,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.060743,
        "recall": 0.094727,
        "f1": 0.069411,
        "accuracy": 0.094727,
        "main_score": 0.069411,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.044139,
        "recall": 0.05957,
        "f1": 0.047786,
        "accuracy": 0.05957,
        "main_score": 0.047786,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.023141,
        "recall": 0.047852,
        "f1": 0.028175,
        "accuracy": 0.047852,
        "main_score": 0.028175,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.01594,
        "recall": 0.024414,
        "f1": 0.017513,
        "accuracy": 0.024414,
        "main_score": 0.017513,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.068803,
        "recall": 0.09375,
        "f1": 0.074243,
        "accuracy": 0.09375,
        "main_score": 0.074243,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.091278,
        "recall": 0.125977,
        "f1": 0.10019,
        "accuracy": 0.125977,
        "main_score": 0.10019,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.108907,
        "recall": 0.146484,
        "f1": 0.118019,
        "accuracy": 0.146484,
        "main_score": 0.118019,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.096595,
        "recall": 0.128906,
        "f1": 0.103964,
        "accuracy": 0.128906,
        "main_score": 0.103964,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.028324,
        "recall": 0.053711,
        "f1": 0.032759,
        "accuracy": 0.053711,
        "main_score": 0.032759,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.041469,
        "recall": 0.05957,
        "f1": 0.044806,
        "accuracy": 0.05957,
        "main_score": 0.044806,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.082575,
        "recall": 0.113281,
        "f1": 0.090987,
        "accuracy": 0.113281,
        "main_score": 0.090987,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.042114,
        "recall": 0.066406,
        "f1": 0.047571,
        "accuracy": 0.066406,
        "main_score": 0.047571,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.027042,
        "recall": 0.048828,
        "f1": 0.031652,
        "accuracy": 0.048828,
        "main_score": 0.031652,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.03597,
        "recall": 0.054688,
        "f1": 0.039834,
        "accuracy": 0.054688,
        "main_score": 0.039834,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.016388,
        "recall": 0.030273,
        "f1": 0.019186,
        "accuracy": 0.030273,
        "main_score": 0.019186,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.025142,
        "recall": 0.042969,
        "f1": 0.028613,
        "accuracy": 0.042969,
        "main_score": 0.028613,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.03277,
        "recall": 0.056641,
        "f1": 0.037831,
        "accuracy": 0.056641,
        "main_score": 0.037831,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.186492,
        "recall": 0.213867,
        "f1": 0.193839,
        "accuracy": 0.213867,
        "main_score": 0.193839,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.156377,
        "recall": 0.177734,
        "f1": 0.161592,
        "accuracy": 0.177734,
        "main_score": 0.161592,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.034853,
        "recall": 0.053711,
        "f1": 0.038926,
        "accuracy": 0.053711,
        "main_score": 0.038926,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.195648,
        "recall": 0.224609,
        "f1": 0.203578,
        "accuracy": 0.224609,
        "main_score": 0.203578,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.045795,
        "recall": 0.081055,
        "f1": 0.05382,
        "accuracy": 0.081055,
        "main_score": 0.05382,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.165017,
        "recall": 0.191406,
        "f1": 0.171517,
        "accuracy": 0.191406,
        "main_score": 0.171517,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.06137,
        "recall": 0.084961,
        "f1": 0.067226,
        "accuracy": 0.084961,
        "main_score": 0.067226,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.144807,
        "recall": 0.164062,
        "f1": 0.149708,
        "accuracy": 0.164062,
        "main_score": 0.149708,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.021816,
        "recall": 0.043945,
        "f1": 0.026109,
        "accuracy": 0.043945,
        "main_score": 0.026109,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.04218,
        "recall": 0.058594,
        "f1": 0.04563,
        "accuracy": 0.058594,
        "main_score": 0.04563,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.023183,
        "recall": 0.046875,
        "f1": 0.028223,
        "accuracy": 0.046875,
        "main_score": 0.028223,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.024302,
        "recall": 0.041992,
        "f1": 0.027807,
        "accuracy": 0.041992,
        "main_score": 0.027807,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.026161,
        "recall": 0.043945,
        "f1": 0.029668,
        "accuracy": 0.043945,
        "main_score": 0.029668,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.159315,
        "recall": 0.179688,
        "f1": 0.164369,
        "accuracy": 0.179688,
        "main_score": 0.164369,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.030386,
        "recall": 0.046875,
        "f1": 0.033756,
        "accuracy": 0.046875,
        "main_score": 0.033756,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.01461,
        "recall": 0.027344,
        "f1": 0.016933,
        "accuracy": 0.027344,
        "main_score": 0.016933,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.159143,
        "recall": 0.182617,
        "f1": 0.164876,
        "accuracy": 0.182617,
        "main_score": 0.164876,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.19307,
        "recall": 0.223633,
        "f1": 0.201384,
        "accuracy": 0.223633,
        "main_score": 0.201384,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.192599,
        "recall": 0.224609,
        "f1": 0.201268,
        "accuracy": 0.224609,
        "main_score": 0.201268,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.147498,
        "recall": 0.166016,
        "f1": 0.152243,
        "accuracy": 0.166016,
        "main_score": 0.152243,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.090176,
        "recall": 0.129883,
        "f1": 0.099911,
        "accuracy": 0.129883,
        "main_score": 0.099911,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.0846,
        "recall": 0.126953,
        "f1": 0.094725,
        "accuracy": 0.126953,
        "main_score": 0.094725,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.046495,
        "recall": 0.084961,
        "f1": 0.055764,
        "accuracy": 0.084961,
        "main_score": 0.055764,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.02508,
        "recall": 0.047852,
        "f1": 0.02979,
        "accuracy": 0.047852,
        "main_score": 0.02979,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000977,
        "f1": 4e-06,
        "accuracy": 0.000977,
        "main_score": 4e-06,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.074032,
        "recall": 0.125,
        "f1": 0.085626,
        "accuracy": 0.125,
        "main_score": 0.085626,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.095759,
        "recall": 0.148438,
        "f1": 0.108936,
        "accuracy": 0.148438,
        "main_score": 0.108936,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.024831,
        "recall": 0.047852,
        "f1": 0.029927,
        "accuracy": 0.047852,
        "main_score": 0.029927,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.117773,
        "recall": 0.150391,
        "f1": 0.126528,
        "accuracy": 0.150391,
        "main_score": 0.126528,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.007758,
        "recall": 0.020508,
        "f1": 0.009884,
        "accuracy": 0.020508,
        "main_score": 0.009884,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.066435,
        "recall": 0.101562,
        "f1": 0.075268,
        "accuracy": 0.101562,
        "main_score": 0.075268,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.031284,
        "recall": 0.053711,
        "f1": 0.035907,
        "accuracy": 0.053711,
        "main_score": 0.035907,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.062203,
        "recall": 0.102539,
        "f1": 0.071632,
        "accuracy": 0.102539,
        "main_score": 0.071632,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.085596,
        "recall": 0.128906,
        "f1": 0.095093,
        "accuracy": 0.128906,
        "main_score": 0.095093,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.097322,
        "recall": 0.132812,
        "f1": 0.105951,
        "accuracy": 0.132812,
        "main_score": 0.105951,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.014466,
        "recall": 0.039062,
        "f1": 0.018029,
        "accuracy": 0.039062,
        "main_score": 0.018029,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.063505,
        "recall": 0.092773,
        "f1": 0.070936,
        "accuracy": 0.092773,
        "main_score": 0.070936,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.050895,
        "recall": 0.075195,
        "f1": 0.056614,
        "accuracy": 0.075195,
        "main_score": 0.056614,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.023316,
        "recall": 0.043945,
        "f1": 0.027454,
        "accuracy": 0.043945,
        "main_score": 0.027454,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.048012,
        "recall": 0.076172,
        "f1": 0.054779,
        "accuracy": 0.076172,
        "main_score": 0.054779,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.049958,
        "recall": 0.086914,
        "f1": 0.05891,
        "accuracy": 0.086914,
        "main_score": 0.05891,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.005562,
        "recall": 0.012695,
        "f1": 0.006565,
        "accuracy": 0.012695,
        "main_score": 0.006565,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.105905,
        "recall": 0.15332,
        "f1": 0.117473,
        "accuracy": 0.15332,
        "main_score": 0.117473,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.095934,
        "recall": 0.137695,
        "f1": 0.106822,
        "accuracy": 0.137695,
        "main_score": 0.106822,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.056916,
        "recall": 0.09668,
        "f1": 0.065142,
        "accuracy": 0.09668,
        "main_score": 0.065142,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.040489,
        "recall": 0.066406,
        "f1": 0.046531,
        "accuracy": 0.066406,
        "main_score": 0.046531,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001467,
        "recall": 0.00293,
        "f1": 0.001631,
        "accuracy": 0.00293,
        "main_score": 0.001631,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.040743,
        "recall": 0.073242,
        "f1": 0.04715,
        "accuracy": 0.073242,
        "main_score": 0.04715,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.070906,
        "recall": 0.100586,
        "f1": 0.078666,
        "accuracy": 0.100586,
        "main_score": 0.078666,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.048798,
        "recall": 0.088867,
        "f1": 0.058316,
        "accuracy": 0.088867,
        "main_score": 0.058316,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.051096,
        "recall": 0.073242,
        "f1": 0.055852,
        "accuracy": 0.073242,
        "main_score": 0.055852,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.015018,
        "recall": 0.03125,
        "f1": 0.017969,
        "accuracy": 0.03125,
        "main_score": 0.017969,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.096204,
        "recall": 0.134766,
        "f1": 0.106481,
        "accuracy": 0.134766,
        "main_score": 0.106481,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.021499,
        "recall": 0.03418,
        "f1": 0.023889,
        "accuracy": 0.03418,
        "main_score": 0.023889,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.070129,
        "recall": 0.097656,
        "f1": 0.076727,
        "accuracy": 0.097656,
        "main_score": 0.076727,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.093668,
        "recall": 0.138672,
        "f1": 0.105376,
        "accuracy": 0.138672,
        "main_score": 0.105376,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.09281,
        "recall": 0.12793,
        "f1": 0.101528,
        "accuracy": 0.12793,
        "main_score": 0.101528,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.020633,
        "recall": 0.047852,
        "f1": 0.025932,
        "accuracy": 0.047852,
        "main_score": 0.025932,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.046037,
        "recall": 0.06543,
        "f1": 0.050245,
        "accuracy": 0.06543,
        "main_score": 0.050245,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.064422,
        "recall": 0.100586,
        "f1": 0.073427,
        "accuracy": 0.100586,
        "main_score": 0.073427,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.046245,
        "recall": 0.075195,
        "f1": 0.052813,
        "accuracy": 0.075195,
        "main_score": 0.052813,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.024825,
        "recall": 0.044922,
        "f1": 0.02898,
        "accuracy": 0.044922,
        "main_score": 0.02898,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.033503,
        "recall": 0.064453,
        "f1": 0.039448,
        "accuracy": 0.064453,
        "main_score": 0.039448,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.018107,
        "recall": 0.032227,
        "f1": 0.021066,
        "accuracy": 0.032227,
        "main_score": 0.021066,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.097592,
        "recall": 0.139648,
        "f1": 0.107981,
        "accuracy": 0.139648,
        "main_score": 0.107981,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.113239,
        "recall": 0.152344,
        "f1": 0.123976,
        "accuracy": 0.152344,
        "main_score": 0.123976,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.046318,
        "recall": 0.083984,
        "f1": 0.054568,
        "accuracy": 0.083984,
        "main_score": 0.054568,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.038752,
        "recall": 0.064453,
        "f1": 0.044643,
        "accuracy": 0.064453,
        "main_score": 0.044643,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00242,
        "recall": 0.005859,
        "f1": 0.002701,
        "accuracy": 0.005859,
        "main_score": 0.002701,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.040559,
        "recall": 0.083984,
        "f1": 0.049608,
        "accuracy": 0.083984,
        "main_score": 0.049608,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.059396,
        "recall": 0.102539,
        "f1": 0.068813,
        "accuracy": 0.102539,
        "main_score": 0.068813,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.027358,
        "recall": 0.050781,
        "f1": 0.032147,
        "accuracy": 0.050781,
        "main_score": 0.032147,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.066965,
        "recall": 0.098633,
        "f1": 0.074134,
        "accuracy": 0.098633,
        "main_score": 0.074134,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.014389,
        "recall": 0.032227,
        "f1": 0.017662,
        "accuracy": 0.032227,
        "main_score": 0.017662,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.091928,
        "recall": 0.138672,
        "f1": 0.103974,
        "accuracy": 0.138672,
        "main_score": 0.103974,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.019776,
        "recall": 0.033203,
        "f1": 0.022106,
        "accuracy": 0.033203,
        "main_score": 0.022106,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.084579,
        "recall": 0.119141,
        "f1": 0.092718,
        "accuracy": 0.119141,
        "main_score": 0.092718,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.107402,
        "recall": 0.143555,
        "f1": 0.116752,
        "accuracy": 0.143555,
        "main_score": 0.116752,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.082783,
        "recall": 0.125977,
        "f1": 0.093361,
        "accuracy": 0.125977,
        "main_score": 0.093361,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.020101,
        "recall": 0.041016,
        "f1": 0.023874,
        "accuracy": 0.041016,
        "main_score": 0.023874,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.047515,
        "recall": 0.080078,
        "f1": 0.054684,
        "accuracy": 0.080078,
        "main_score": 0.054684,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.081148,
        "recall": 0.116211,
        "f1": 0.09049,
        "accuracy": 0.116211,
        "main_score": 0.09049,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.021385,
        "recall": 0.041016,
        "f1": 0.025236,
        "accuracy": 0.041016,
        "main_score": 0.025236,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.042605,
        "recall": 0.069336,
        "f1": 0.04875,
        "accuracy": 0.069336,
        "main_score": 0.04875,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.042046,
        "recall": 0.075195,
        "f1": 0.048417,
        "accuracy": 0.075195,
        "main_score": 0.048417,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007505,
        "recall": 0.015625,
        "f1": 0.008821,
        "accuracy": 0.015625,
        "main_score": 0.008821,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.140573,
        "recall": 0.188477,
        "f1": 0.15278,
        "accuracy": 0.188477,
        "main_score": 0.15278,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.097721,
        "recall": 0.138672,
        "f1": 0.108273,
        "accuracy": 0.138672,
        "main_score": 0.108273,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.063279,
        "recall": 0.110352,
        "f1": 0.074414,
        "accuracy": 0.110352,
        "main_score": 0.074414,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.041448,
        "recall": 0.078125,
        "f1": 0.048856,
        "accuracy": 0.078125,
        "main_score": 0.048856,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002095,
        "recall": 0.003906,
        "f1": 0.002202,
        "accuracy": 0.003906,
        "main_score": 0.002202,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.053,
        "recall": 0.09375,
        "f1": 0.060905,
        "accuracy": 0.09375,
        "main_score": 0.060905,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.10102,
        "recall": 0.143555,
        "f1": 0.111304,
        "accuracy": 0.143555,
        "main_score": 0.111304,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.051425,
        "recall": 0.095703,
        "f1": 0.060723,
        "accuracy": 0.095703,
        "main_score": 0.060723,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.083303,
        "recall": 0.114258,
        "f1": 0.091082,
        "accuracy": 0.114258,
        "main_score": 0.091082,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.016469,
        "recall": 0.032227,
        "f1": 0.018814,
        "accuracy": 0.032227,
        "main_score": 0.018814,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.096919,
        "recall": 0.144531,
        "f1": 0.108646,
        "accuracy": 0.144531,
        "main_score": 0.108646,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.01736,
        "recall": 0.02832,
        "f1": 0.019313,
        "accuracy": 0.02832,
        "main_score": 0.019313,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.086689,
        "recall": 0.120117,
        "f1": 0.095404,
        "accuracy": 0.120117,
        "main_score": 0.095404,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.120861,
        "recall": 0.169922,
        "f1": 0.133534,
        "accuracy": 0.169922,
        "main_score": 0.133534,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.100779,
        "recall": 0.141602,
        "f1": 0.110206,
        "accuracy": 0.141602,
        "main_score": 0.110206,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.02724,
        "recall": 0.060547,
        "f1": 0.033012,
        "accuracy": 0.060547,
        "main_score": 0.033012,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.072074,
        "recall": 0.102539,
        "f1": 0.079445,
        "accuracy": 0.102539,
        "main_score": 0.079445,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.062062,
        "recall": 0.099609,
        "f1": 0.070955,
        "accuracy": 0.099609,
        "main_score": 0.070955,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.05334,
        "recall": 0.09668,
        "f1": 0.062371,
        "accuracy": 0.09668,
        "main_score": 0.062371,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.028481,
        "recall": 0.048828,
        "f1": 0.033022,
        "accuracy": 0.048828,
        "main_score": 0.033022,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.027604,
        "recall": 0.050781,
        "f1": 0.031586,
        "accuracy": 0.050781,
        "main_score": 0.031586,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.011431,
        "recall": 0.023438,
        "f1": 0.013493,
        "accuracy": 0.023438,
        "main_score": 0.013493,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.054794,
        "recall": 0.077148,
        "f1": 0.060098,
        "accuracy": 0.077148,
        "main_score": 0.060098,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.04226,
        "recall": 0.066406,
        "f1": 0.048733,
        "accuracy": 0.066406,
        "main_score": 0.048733,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.279115,
        "recall": 0.308594,
        "f1": 0.286979,
        "accuracy": 0.308594,
        "main_score": 0.286979,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.349215,
        "recall": 0.389648,
        "f1": 0.360365,
        "accuracy": 0.389648,
        "main_score": 0.360365,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.062694,
        "recall": 0.088867,
        "f1": 0.067464,
        "accuracy": 0.088867,
        "main_score": 0.067464,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.267391,
        "recall": 0.292969,
        "f1": 0.274366,
        "accuracy": 0.292969,
        "main_score": 0.274366,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.05834,
        "recall": 0.09668,
        "f1": 0.065727,
        "accuracy": 0.09668,
        "main_score": 0.065727,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.339023,
        "recall": 0.37793,
        "f1": 0.349683,
        "accuracy": 0.37793,
        "main_score": 0.349683,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.024873,
        "recall": 0.041016,
        "f1": 0.028057,
        "accuracy": 0.041016,
        "main_score": 0.028057,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.258756,
        "recall": 0.290039,
        "f1": 0.267396,
        "accuracy": 0.290039,
        "main_score": 0.267396,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.064192,
        "recall": 0.100586,
        "f1": 0.072898,
        "accuracy": 0.100586,
        "main_score": 0.072898,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.157951,
        "recall": 0.189453,
        "f1": 0.166284,
        "accuracy": 0.189453,
        "main_score": 0.166284,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.02839,
        "recall": 0.043945,
        "f1": 0.031397,
        "accuracy": 0.043945,
        "main_score": 0.031397,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.040694,
        "recall": 0.071289,
        "f1": 0.046678,
        "accuracy": 0.071289,
        "main_score": 0.046678,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.041313,
        "recall": 0.066406,
        "f1": 0.046774,
        "accuracy": 0.066406,
        "main_score": 0.046774,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.060145,
        "recall": 0.092773,
        "f1": 0.067056,
        "accuracy": 0.092773,
        "main_score": 0.067056,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.020706,
        "recall": 0.03418,
        "f1": 0.023646,
        "accuracy": 0.03418,
        "main_score": 0.023646,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.04505,
        "recall": 0.075195,
        "f1": 0.051927,
        "accuracy": 0.075195,
        "main_score": 0.051927,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.333908,
        "recall": 0.374023,
        "f1": 0.345147,
        "accuracy": 0.374023,
        "main_score": 0.345147,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.179508,
        "recall": 0.214844,
        "f1": 0.188436,
        "accuracy": 0.214844,
        "main_score": 0.188436,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.208499,
        "recall": 0.245117,
        "f1": 0.218359,
        "accuracy": 0.245117,
        "main_score": 0.218359,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.296112,
        "recall": 0.325195,
        "f1": 0.303551,
        "accuracy": 0.325195,
        "main_score": 0.303551,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.060482,
        "recall": 0.09082,
        "f1": 0.067225,
        "accuracy": 0.09082,
        "main_score": 0.067225,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.055884,
        "recall": 0.087891,
        "f1": 0.063252,
        "accuracy": 0.087891,
        "main_score": 0.063252,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.032497,
        "recall": 0.060547,
        "f1": 0.038846,
        "accuracy": 0.060547,
        "main_score": 0.038846,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.01477,
        "recall": 0.032227,
        "f1": 0.017772,
        "accuracy": 0.032227,
        "main_score": 0.017772,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001101,
        "recall": 0.00293,
        "f1": 0.001197,
        "accuracy": 0.00293,
        "main_score": 0.001197,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.043451,
        "recall": 0.076172,
        "f1": 0.050599,
        "accuracy": 0.076172,
        "main_score": 0.050599,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.05241,
        "recall": 0.087891,
        "f1": 0.060155,
        "accuracy": 0.087891,
        "main_score": 0.060155,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.023394,
        "recall": 0.046875,
        "f1": 0.028392,
        "accuracy": 0.046875,
        "main_score": 0.028392,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.08191,
        "recall": 0.114258,
        "f1": 0.089459,
        "accuracy": 0.114258,
        "main_score": 0.089459,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.005058,
        "recall": 0.016602,
        "f1": 0.006716,
        "accuracy": 0.016602,
        "main_score": 0.006716,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.04503,
        "recall": 0.081055,
        "f1": 0.053486,
        "accuracy": 0.081055,
        "main_score": 0.053486,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.019859,
        "recall": 0.041016,
        "f1": 0.024341,
        "accuracy": 0.041016,
        "main_score": 0.024341,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.066845,
        "recall": 0.102539,
        "f1": 0.075429,
        "accuracy": 0.102539,
        "main_score": 0.075429,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.050744,
        "recall": 0.085938,
        "f1": 0.058704,
        "accuracy": 0.085938,
        "main_score": 0.058704,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.053558,
        "recall": 0.085938,
        "f1": 0.060681,
        "accuracy": 0.085938,
        "main_score": 0.060681,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.069029,
        "recall": 0.101562,
        "f1": 0.07735,
        "accuracy": 0.101562,
        "main_score": 0.07735,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.012245,
        "recall": 0.027344,
        "f1": 0.014547,
        "accuracy": 0.027344,
        "main_score": 0.014547,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.033568,
        "recall": 0.060547,
        "f1": 0.039702,
        "accuracy": 0.060547,
        "main_score": 0.039702,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.025769,
        "recall": 0.046875,
        "f1": 0.030653,
        "accuracy": 0.046875,
        "main_score": 0.030653,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.028379,
        "recall": 0.053711,
        "f1": 0.033656,
        "accuracy": 0.053711,
        "main_score": 0.033656,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.033808,
        "recall": 0.060547,
        "f1": 0.03865,
        "accuracy": 0.060547,
        "main_score": 0.03865,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002984,
        "recall": 0.007812,
        "f1": 0.003652,
        "accuracy": 0.007812,
        "main_score": 0.003652,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.060823,
        "recall": 0.089844,
        "f1": 0.066902,
        "accuracy": 0.089844,
        "main_score": 0.066902,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.113551,
        "recall": 0.148438,
        "f1": 0.122533,
        "accuracy": 0.148438,
        "main_score": 0.122533,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.023234,
        "recall": 0.042969,
        "f1": 0.027164,
        "accuracy": 0.042969,
        "main_score": 0.027164,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.05411,
        "recall": 0.082031,
        "f1": 0.060613,
        "accuracy": 0.082031,
        "main_score": 0.060613,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000246,
        "recall": 0.001953,
        "f1": 0.000395,
        "accuracy": 0.001953,
        "main_score": 0.000395,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024473,
        "recall": 0.046875,
        "f1": 0.028427,
        "accuracy": 0.046875,
        "main_score": 0.028427,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.040116,
        "recall": 0.06543,
        "f1": 0.045946,
        "accuracy": 0.06543,
        "main_score": 0.045946,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.031617,
        "recall": 0.06543,
        "f1": 0.038587,
        "accuracy": 0.06543,
        "main_score": 0.038587,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.03296,
        "recall": 0.046875,
        "f1": 0.036015,
        "accuracy": 0.046875,
        "main_score": 0.036015,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.009417,
        "recall": 0.027344,
        "f1": 0.012733,
        "accuracy": 0.027344,
        "main_score": 0.012733,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.069638,
        "recall": 0.095703,
        "f1": 0.076709,
        "accuracy": 0.095703,
        "main_score": 0.076709,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.009906,
        "recall": 0.015625,
        "f1": 0.010647,
        "accuracy": 0.015625,
        "main_score": 0.010647,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.042644,
        "recall": 0.05957,
        "f1": 0.046276,
        "accuracy": 0.05957,
        "main_score": 0.046276,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.050849,
        "recall": 0.080078,
        "f1": 0.058162,
        "accuracy": 0.080078,
        "main_score": 0.058162,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.072664,
        "recall": 0.09668,
        "f1": 0.078767,
        "accuracy": 0.09668,
        "main_score": 0.078767,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.04614,
        "recall": 0.073242,
        "f1": 0.05198,
        "accuracy": 0.073242,
        "main_score": 0.05198,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.016739,
        "recall": 0.039062,
        "f1": 0.020449,
        "accuracy": 0.039062,
        "main_score": 0.020449,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.025736,
        "recall": 0.042969,
        "f1": 0.029077,
        "accuracy": 0.042969,
        "main_score": 0.029077,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.026742,
        "recall": 0.049805,
        "f1": 0.031438,
        "accuracy": 0.049805,
        "main_score": 0.031438,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.022242,
        "recall": 0.039062,
        "f1": 0.025379,
        "accuracy": 0.039062,
        "main_score": 0.025379,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.017971,
        "recall": 0.032227,
        "f1": 0.020635,
        "accuracy": 0.032227,
        "main_score": 0.020635,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.010101,
        "recall": 0.023438,
        "f1": 0.012623,
        "accuracy": 0.023438,
        "main_score": 0.012623,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.072925,
        "recall": 0.102539,
        "f1": 0.079647,
        "accuracy": 0.102539,
        "main_score": 0.079647,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.045153,
        "recall": 0.068359,
        "f1": 0.050667,
        "accuracy": 0.068359,
        "main_score": 0.050667,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.289783,
        "recall": 0.318359,
        "f1": 0.297755,
        "accuracy": 0.318359,
        "main_score": 0.297755,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.337198,
        "recall": 0.378906,
        "f1": 0.348254,
        "accuracy": 0.378906,
        "main_score": 0.348254,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.057844,
        "recall": 0.083984,
        "f1": 0.062836,
        "accuracy": 0.083984,
        "main_score": 0.062836,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.261305,
        "recall": 0.288086,
        "f1": 0.268734,
        "accuracy": 0.288086,
        "main_score": 0.268734,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.068122,
        "recall": 0.101562,
        "f1": 0.075063,
        "accuracy": 0.101562,
        "main_score": 0.075063,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.389445,
        "recall": 0.430664,
        "f1": 0.400925,
        "accuracy": 0.430664,
        "main_score": 0.400925,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.032596,
        "recall": 0.047852,
        "f1": 0.035727,
        "accuracy": 0.047852,
        "main_score": 0.035727,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.25581,
        "recall": 0.285156,
        "f1": 0.263381,
        "accuracy": 0.285156,
        "main_score": 0.263381,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.059716,
        "recall": 0.086914,
        "f1": 0.066382,
        "accuracy": 0.086914,
        "main_score": 0.066382,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.147365,
        "recall": 0.183594,
        "f1": 0.15663,
        "accuracy": 0.183594,
        "main_score": 0.15663,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.03578,
        "recall": 0.052734,
        "f1": 0.039327,
        "accuracy": 0.052734,
        "main_score": 0.039327,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.057987,
        "recall": 0.09082,
        "f1": 0.066222,
        "accuracy": 0.09082,
        "main_score": 0.066222,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.034382,
        "recall": 0.053711,
        "f1": 0.038684,
        "accuracy": 0.053711,
        "main_score": 0.038684,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.074456,
        "recall": 0.102539,
        "f1": 0.080859,
        "accuracy": 0.102539,
        "main_score": 0.080859,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.295113,
        "recall": 0.341797,
        "f1": 0.306441,
        "accuracy": 0.341797,
        "main_score": 0.306441,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.031099,
        "recall": 0.042969,
        "f1": 0.033586,
        "accuracy": 0.042969,
        "main_score": 0.033586,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.040953,
        "recall": 0.064453,
        "f1": 0.046018,
        "accuracy": 0.064453,
        "main_score": 0.046018,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.15785,
        "recall": 0.194336,
        "f1": 0.167086,
        "accuracy": 0.194336,
        "main_score": 0.167086,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.191589,
        "recall": 0.228516,
        "f1": 0.201789,
        "accuracy": 0.228516,
        "main_score": 0.201789,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.29114,
        "recall": 0.30957,
        "f1": 0.296095,
        "accuracy": 0.30957,
        "main_score": 0.296095,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.037492,
        "recall": 0.061523,
        "f1": 0.042803,
        "accuracy": 0.061523,
        "main_score": 0.042803,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.056973,
        "recall": 0.083984,
        "f1": 0.063359,
        "accuracy": 0.083984,
        "main_score": 0.063359,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.208323,
        "recall": 0.239258,
        "f1": 0.215911,
        "accuracy": 0.239258,
        "main_score": 0.215911,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.191107,
        "recall": 0.213867,
        "f1": 0.196913,
        "accuracy": 0.213867,
        "main_score": 0.196913,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.051558,
        "recall": 0.069336,
        "f1": 0.055082,
        "accuracy": 0.069336,
        "main_score": 0.055082,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.216743,
        "recall": 0.257812,
        "f1": 0.22714,
        "accuracy": 0.257812,
        "main_score": 0.22714,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.057199,
        "recall": 0.102539,
        "f1": 0.067071,
        "accuracy": 0.102539,
        "main_score": 0.067071,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.186176,
        "recall": 0.208984,
        "f1": 0.191824,
        "accuracy": 0.208984,
        "main_score": 0.191824,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.066499,
        "recall": 0.105469,
        "f1": 0.075984,
        "accuracy": 0.105469,
        "main_score": 0.075984,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.164277,
        "recall": 0.18457,
        "f1": 0.169579,
        "accuracy": 0.18457,
        "main_score": 0.169579,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.045932,
        "recall": 0.073242,
        "f1": 0.051941,
        "accuracy": 0.073242,
        "main_score": 0.051941,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.194754,
        "recall": 0.225586,
        "f1": 0.202902,
        "accuracy": 0.225586,
        "main_score": 0.202902,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.058138,
        "recall": 0.083984,
        "f1": 0.064632,
        "accuracy": 0.083984,
        "main_score": 0.064632,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.03239,
        "recall": 0.055664,
        "f1": 0.036926,
        "accuracy": 0.055664,
        "main_score": 0.036926,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.056652,
        "recall": 0.087891,
        "f1": 0.064456,
        "accuracy": 0.087891,
        "main_score": 0.064456,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.042701,
        "recall": 0.067383,
        "f1": 0.048214,
        "accuracy": 0.067383,
        "main_score": 0.048214,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.181211,
        "recall": 0.202148,
        "f1": 0.186484,
        "accuracy": 0.202148,
        "main_score": 0.186484,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.04065,
        "recall": 0.066406,
        "f1": 0.045993,
        "accuracy": 0.066406,
        "main_score": 0.045993,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.028975,
        "recall": 0.053711,
        "f1": 0.034338,
        "accuracy": 0.053711,
        "main_score": 0.034338,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.179291,
        "recall": 0.203125,
        "f1": 0.185566,
        "accuracy": 0.203125,
        "main_score": 0.185566,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.238622,
        "recall": 0.276367,
        "f1": 0.248874,
        "accuracy": 0.276367,
        "main_score": 0.248874,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.171979,
        "recall": 0.19043,
        "f1": 0.176522,
        "accuracy": 0.19043,
        "main_score": 0.176522,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.041144,
        "recall": 0.070312,
        "f1": 0.047833,
        "accuracy": 0.070312,
        "main_score": 0.047833,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.042069,
        "recall": 0.072266,
        "f1": 0.049021,
        "accuracy": 0.072266,
        "main_score": 0.049021,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.237585,
        "recall": 0.280273,
        "f1": 0.248373,
        "accuracy": 0.280273,
        "main_score": 0.248373,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.218627,
        "recall": 0.242188,
        "f1": 0.224221,
        "accuracy": 0.242188,
        "main_score": 0.224221,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.051672,
        "recall": 0.073242,
        "f1": 0.056001,
        "accuracy": 0.073242,
        "main_score": 0.056001,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.252491,
        "recall": 0.296875,
        "f1": 0.264362,
        "accuracy": 0.296875,
        "main_score": 0.264362,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.061549,
        "recall": 0.113281,
        "f1": 0.072247,
        "accuracy": 0.113281,
        "main_score": 0.072247,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.216311,
        "recall": 0.240234,
        "f1": 0.222661,
        "accuracy": 0.240234,
        "main_score": 0.222661,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.086249,
        "recall": 0.129883,
        "f1": 0.097523,
        "accuracy": 0.129883,
        "main_score": 0.097523,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.178121,
        "recall": 0.202148,
        "f1": 0.184153,
        "accuracy": 0.202148,
        "main_score": 0.184153,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.04586,
        "recall": 0.078125,
        "f1": 0.052796,
        "accuracy": 0.078125,
        "main_score": 0.052796,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.197214,
        "recall": 0.226562,
        "f1": 0.205192,
        "accuracy": 0.226562,
        "main_score": 0.205192,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.073186,
        "recall": 0.102539,
        "f1": 0.080626,
        "accuracy": 0.102539,
        "main_score": 0.080626,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.040117,
        "recall": 0.067383,
        "f1": 0.046153,
        "accuracy": 0.067383,
        "main_score": 0.046153,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.064951,
        "recall": 0.106445,
        "f1": 0.074876,
        "accuracy": 0.106445,
        "main_score": 0.074876,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.045308,
        "recall": 0.074219,
        "f1": 0.05218,
        "accuracy": 0.074219,
        "main_score": 0.05218,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.215892,
        "recall": 0.238281,
        "f1": 0.221276,
        "accuracy": 0.238281,
        "main_score": 0.221276,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.043136,
        "recall": 0.075195,
        "f1": 0.049614,
        "accuracy": 0.075195,
        "main_score": 0.049614,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.030205,
        "recall": 0.057617,
        "f1": 0.036372,
        "accuracy": 0.057617,
        "main_score": 0.036372,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.216639,
        "recall": 0.239258,
        "f1": 0.222168,
        "accuracy": 0.239258,
        "main_score": 0.222168,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.242196,
        "recall": 0.288086,
        "f1": 0.254832,
        "accuracy": 0.288086,
        "main_score": 0.254832,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.197006,
        "recall": 0.216797,
        "f1": 0.201675,
        "accuracy": 0.216797,
        "main_score": 0.201675,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.008387,
        "recall": 0.016602,
        "f1": 0.009379,
        "accuracy": 0.016602,
        "main_score": 0.009379,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.008225,
        "recall": 0.017578,
        "f1": 0.00935,
        "accuracy": 0.017578,
        "main_score": 0.00935,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.226722,
        "recall": 0.248047,
        "f1": 0.231971,
        "accuracy": 0.248047,
        "main_score": 0.231971,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.24752,
        "recall": 0.280273,
        "f1": 0.255511,
        "accuracy": 0.280273,
        "main_score": 0.255511,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.049664,
        "recall": 0.076172,
        "f1": 0.054111,
        "accuracy": 0.076172,
        "main_score": 0.054111,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.213378,
        "recall": 0.235352,
        "f1": 0.219034,
        "accuracy": 0.235352,
        "main_score": 0.219034,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.022713,
        "recall": 0.049805,
        "f1": 0.027567,
        "accuracy": 0.049805,
        "main_score": 0.027567,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.260907,
        "recall": 0.290039,
        "f1": 0.268104,
        "accuracy": 0.290039,
        "main_score": 0.268104,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.002311,
        "recall": 0.007812,
        "f1": 0.003019,
        "accuracy": 0.007812,
        "main_score": 0.003019,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.249722,
        "recall": 0.282227,
        "f1": 0.258869,
        "accuracy": 0.282227,
        "main_score": 0.258869,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.009505,
        "recall": 0.025391,
        "f1": 0.011542,
        "accuracy": 0.025391,
        "main_score": 0.011542,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.124471,
        "recall": 0.154297,
        "f1": 0.131701,
        "accuracy": 0.154297,
        "main_score": 0.131701,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.003762,
        "recall": 0.008789,
        "f1": 0.004265,
        "accuracy": 0.008789,
        "main_score": 0.004265,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.007485,
        "recall": 0.022461,
        "f1": 0.009623,
        "accuracy": 0.022461,
        "main_score": 0.009623,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.00492,
        "recall": 0.013672,
        "f1": 0.006235,
        "accuracy": 0.013672,
        "main_score": 0.006235,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.009446,
        "recall": 0.018555,
        "f1": 0.010274,
        "accuracy": 0.018555,
        "main_score": 0.010274,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.24294,
        "recall": 0.269531,
        "f1": 0.249076,
        "accuracy": 0.269531,
        "main_score": 0.249076,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.002323,
        "recall": 0.010742,
        "f1": 0.003102,
        "accuracy": 0.010742,
        "main_score": 0.003102,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.008908,
        "recall": 0.017578,
        "f1": 0.010084,
        "accuracy": 0.017578,
        "main_score": 0.010084,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.252885,
        "recall": 0.28418,
        "f1": 0.259498,
        "accuracy": 0.28418,
        "main_score": 0.259498,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.140855,
        "recall": 0.172852,
        "f1": 0.148696,
        "accuracy": 0.172852,
        "main_score": 0.148696,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.18188,
        "recall": 0.213867,
        "f1": 0.189856,
        "accuracy": 0.213867,
        "main_score": 0.189856,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 34.49377489089966,
  "kg_co2_emissions": 0.000965267295569315
}