{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.112821,
            "f1": 0.101309,
            "f1_weighted": 0.101349,
            "precision": 0.168962,
            "precision_weighted": 0.168977,
            "recall": 0.112779,
            "recall_weighted": 0.112821,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.112598,
            "f1": 0.109326,
            "f1_weighted": 0.109248,
            "precision": 0.158992,
            "precision_weighted": 0.158958,
            "recall": 0.112667,
            "recall_weighted": 0.112598,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.113489,
            "f1": 0.098005,
            "f1_weighted": 0.097981,
            "precision": 0.159665,
            "precision_weighted": 0.15973,
            "recall": 0.113778,
            "recall_weighted": 0.113489,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.109476,
            "f1": 0.10158,
            "f1_weighted": 0.101636,
            "precision": 0.152015,
            "precision_weighted": 0.152037,
            "recall": 0.109356,
            "recall_weighted": 0.109476,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.116388,
            "f1": 0.098394,
            "f1_weighted": 0.098422,
            "precision": 0.132407,
            "precision_weighted": 0.132294,
            "recall": 0.116284,
            "recall_weighted": 0.116388,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.118841,
            "f1": 0.105822,
            "f1_weighted": 0.105789,
            "precision": 0.148149,
            "precision_weighted": 0.148204,
            "recall": 0.118929,
            "recall_weighted": 0.118841,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.111483,
            "f1": 0.098528,
            "f1_weighted": 0.098584,
            "precision": 0.132214,
            "precision_weighted": 0.132186,
            "recall": 0.111389,
            "recall_weighted": 0.111483,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.102564,
            "f1": 0.0956,
            "f1_weighted": 0.095571,
            "precision": 0.140896,
            "precision_weighted": 0.140846,
            "recall": 0.102586,
            "recall_weighted": 0.102564,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.106577,
            "f1": 0.095144,
            "f1_weighted": 0.09514,
            "precision": 0.1317,
            "precision_weighted": 0.131689,
            "recall": 0.106589,
            "recall_weighted": 0.106577,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.103233,
            "f1": 0.090065,
            "f1_weighted": 0.090147,
            "precision": 0.188582,
            "precision_weighted": 0.18862,
            "recall": 0.103134,
            "recall_weighted": 0.103233,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.110747,
        "f1": 0.099377,
        "f1_weighted": 0.099387,
        "precision": 0.151358,
        "precision_weighted": 0.151354,
        "recall": 0.110749,
        "recall_weighted": 0.110747,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.099377,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.629921197891235,
  "kg_co2_emissions": null
}