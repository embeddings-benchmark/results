{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.568896,
        "f1": 0.561542,
        "f1_weighted": 0.568059,
        "ap": 0.461401,
        "ap_weighted": 0.461401,
        "scores_per_experiment": [
          {
            "accuracy": 0.634277,
            "f1": 0.62726,
            "f1_weighted": 0.635501,
            "ap": 0.503065,
            "ap_weighted": 0.503065
          },
          {
            "accuracy": 0.502441,
            "f1": 0.502438,
            "f1_weighted": 0.502634,
            "ap": 0.427181,
            "ap_weighted": 0.427181
          },
          {
            "accuracy": 0.566895,
            "f1": 0.542052,
            "f1_weighted": 0.559239,
            "ap": 0.443682,
            "ap_weighted": 0.443682
          },
          {
            "accuracy": 0.580078,
            "f1": 0.578727,
            "f1_weighted": 0.574882,
            "ap": 0.480294,
            "ap_weighted": 0.480294
          },
          {
            "accuracy": 0.625977,
            "f1": 0.622798,
            "f1_weighted": 0.628377,
            "ap": 0.500318,
            "ap_weighted": 0.500318
          },
          {
            "accuracy": 0.480957,
            "f1": 0.478269,
            "f1_weighted": 0.484303,
            "ap": 0.410984,
            "ap_weighted": 0.410984
          },
          {
            "accuracy": 0.606445,
            "f1": 0.596722,
            "f1_weighted": 0.606812,
            "ap": 0.479129,
            "ap_weighted": 0.479129
          },
          {
            "accuracy": 0.62793,
            "f1": 0.61378,
            "f1_weighted": 0.625692,
            "ap": 0.493024,
            "ap_weighted": 0.493024
          },
          {
            "accuracy": 0.506836,
            "f1": 0.5067,
            "f1_weighted": 0.50538,
            "ap": 0.431185,
            "ap_weighted": 0.431185
          },
          {
            "accuracy": 0.557129,
            "f1": 0.546675,
            "f1_weighted": 0.557768,
            "ap": 0.445151,
            "ap_weighted": 0.445151
          }
        ],
        "main_score": 0.561542,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.632379770278931,
  "kg_co2_emissions": 0.0002149874075588309
}