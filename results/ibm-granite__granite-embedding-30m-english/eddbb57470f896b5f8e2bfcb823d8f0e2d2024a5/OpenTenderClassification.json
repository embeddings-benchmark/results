{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.279599,
            "f1": 0.263088,
            "f1_weighted": 0.263105,
            "precision": 0.276293,
            "precision_weighted": 0.27629,
            "recall": 0.279568,
            "recall_weighted": 0.279599,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.28874,
            "f1": 0.274587,
            "f1_weighted": 0.274549,
            "precision": 0.289454,
            "precision_weighted": 0.289451,
            "recall": 0.288757,
            "recall_weighted": 0.28874,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.293868,
            "f1": 0.27475,
            "f1_weighted": 0.274784,
            "precision": 0.285221,
            "precision_weighted": 0.285254,
            "recall": 0.293812,
            "recall_weighted": 0.293868,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.273133,
            "f1": 0.254647,
            "f1_weighted": 0.254705,
            "precision": 0.266977,
            "precision_weighted": 0.266994,
            "recall": 0.273064,
            "recall_weighted": 0.273133,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.253066,
            "f1": 0.228596,
            "f1_weighted": 0.228661,
            "precision": 0.247294,
            "precision_weighted": 0.247302,
            "recall": 0.252954,
            "recall_weighted": 0.253066,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.271572,
            "f1": 0.254298,
            "f1_weighted": 0.254229,
            "precision": 0.266147,
            "precision_weighted": 0.266029,
            "recall": 0.27156,
            "recall_weighted": 0.271572,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.292531,
            "f1": 0.273385,
            "f1_weighted": 0.273425,
            "precision": 0.295853,
            "precision_weighted": 0.295864,
            "recall": 0.292444,
            "recall_weighted": 0.292531,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.256856,
            "f1": 0.23895,
            "f1_weighted": 0.238886,
            "precision": 0.263912,
            "precision_weighted": 0.263802,
            "recall": 0.256876,
            "recall_weighted": 0.256856,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.280491,
            "f1": 0.260727,
            "f1_weighted": 0.260713,
            "precision": 0.265597,
            "precision_weighted": 0.265586,
            "recall": 0.280508,
            "recall_weighted": 0.280491,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.265106,
            "f1": 0.24168,
            "f1_weighted": 0.241659,
            "precision": 0.254982,
            "precision_weighted": 0.254932,
            "recall": 0.265081,
            "recall_weighted": 0.265106,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.275496,
        "f1": 0.256471,
        "f1_weighted": 0.256472,
        "precision": 0.271173,
        "precision_weighted": 0.27115,
        "recall": 0.275462,
        "recall_weighted": 0.275496,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.256471,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 28.933308839797974,
  "kg_co2_emissions": null
}