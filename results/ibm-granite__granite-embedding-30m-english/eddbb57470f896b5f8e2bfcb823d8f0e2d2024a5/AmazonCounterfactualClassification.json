{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.24.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.628561,
        "f1": 0.515046,
        "f1_weighted": 0.699775,
        "ap": 0.154995,
        "ap_weighted": 0.154995,
        "scores_per_experiment": [
          {
            "accuracy": 0.703898,
            "f1": 0.56216,
            "f1_weighted": 0.759361,
            "ap": 0.170386,
            "ap_weighted": 0.170386
          },
          {
            "accuracy": 0.634183,
            "f1": 0.520291,
            "f1_weighted": 0.705322,
            "ap": 0.157512,
            "ap_weighted": 0.157512
          },
          {
            "accuracy": 0.575712,
            "f1": 0.478482,
            "f1_weighted": 0.656738,
            "ap": 0.139346,
            "ap_weighted": 0.139346
          },
          {
            "accuracy": 0.543478,
            "f1": 0.452014,
            "f1_weighted": 0.629236,
            "ap": 0.126383,
            "ap_weighted": 0.126383
          },
          {
            "accuracy": 0.571964,
            "f1": 0.483918,
            "f1_weighted": 0.65266,
            "ap": 0.150257,
            "ap_weighted": 0.150257
          },
          {
            "accuracy": 0.649925,
            "f1": 0.534163,
            "f1_weighted": 0.71799,
            "ap": 0.166955,
            "ap_weighted": 0.166955
          },
          {
            "accuracy": 0.664918,
            "f1": 0.535062,
            "f1_weighted": 0.729569,
            "ap": 0.157565,
            "ap_weighted": 0.157565
          },
          {
            "accuracy": 0.617691,
            "f1": 0.499622,
            "f1_weighted": 0.692031,
            "ap": 0.140081,
            "ap_weighted": 0.140081
          },
          {
            "accuracy": 0.678411,
            "f1": 0.553784,
            "f1_weighted": 0.740459,
            "ap": 0.176057,
            "ap_weighted": 0.176057
          },
          {
            "accuracy": 0.645427,
            "f1": 0.530964,
            "f1_weighted": 0.714383,
            "ap": 0.165405,
            "ap_weighted": 0.165405
          }
        ],
        "main_score": 0.628561,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "accuracy": 0.609254,
        "f1": 0.550092,
        "f1_weighted": 0.648014,
        "ap": 0.250517,
        "ap_weighted": 0.250517,
        "scores_per_experiment": [
          {
            "accuracy": 0.601493,
            "f1": 0.537631,
            "f1_weighted": 0.642271,
            "ap": 0.236664,
            "ap_weighted": 0.236664
          },
          {
            "accuracy": 0.610448,
            "f1": 0.554733,
            "f1_weighted": 0.650647,
            "ap": 0.254111,
            "ap_weighted": 0.254111
          },
          {
            "accuracy": 0.49403,
            "f1": 0.470583,
            "f1_weighted": 0.538429,
            "ap": 0.22683,
            "ap_weighted": 0.22683
          },
          {
            "accuracy": 0.598507,
            "f1": 0.541085,
            "f1_weighted": 0.639939,
            "ap": 0.243095,
            "ap_weighted": 0.243095
          },
          {
            "accuracy": 0.646269,
            "f1": 0.584122,
            "f1_weighted": 0.682021,
            "ap": 0.272024,
            "ap_weighted": 0.272024
          },
          {
            "accuracy": 0.61791,
            "f1": 0.546416,
            "f1_weighted": 0.656077,
            "ap": 0.238194,
            "ap_weighted": 0.238194
          },
          {
            "accuracy": 0.68209,
            "f1": 0.598988,
            "f1_weighted": 0.710153,
            "ap": 0.270515,
            "ap_weighted": 0.270515
          },
          {
            "accuracy": 0.629851,
            "f1": 0.576399,
            "f1_weighted": 0.668031,
            "ap": 0.272862,
            "ap_weighted": 0.272862
          },
          {
            "accuracy": 0.640299,
            "f1": 0.577103,
            "f1_weighted": 0.676654,
            "ap": 0.265631,
            "ap_weighted": 0.265631
          },
          {
            "accuracy": 0.571642,
            "f1": 0.513853,
            "f1_weighted": 0.615921,
            "ap": 0.225244,
            "ap_weighted": 0.225244
          }
        ],
        "main_score": 0.609254,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 4.307290315628052,
  "kg_co2_emissions": null
}