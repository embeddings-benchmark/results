{
  "dataset_revision": "96d1d9b37c4693f74c46c83d63a290573f78d511",
  "task_name": "WikipediaOrganicInorganicClassification",
  "mteb_version": "1.26.4",
  "scores": {
    "test": [
      {
        "accuracy": 0.901901,
        "f1": 0.900046,
        "f1_weighted": 0.901672,
        "ap": 0.841883,
        "ap_weighted": 0.841883,
        "scores_per_experiment": [
          {
            "accuracy": 0.904943,
            "f1": 0.901668,
            "f1_weighted": 0.903919,
            "ap": 0.860828,
            "ap_weighted": 0.860828
          },
          {
            "accuracy": 0.923954,
            "f1": 0.921866,
            "f1_weighted": 0.923469,
            "ap": 0.885192,
            "ap_weighted": 0.885192
          },
          {
            "accuracy": 0.897338,
            "f1": 0.893801,
            "f1_weighted": 0.896233,
            "ap": 0.848196,
            "ap_weighted": 0.848196
          },
          {
            "accuracy": 0.836502,
            "f1": 0.834888,
            "f1_weighted": 0.836936,
            "ap": 0.739075,
            "ap_weighted": 0.739075
          },
          {
            "accuracy": 0.935361,
            "f1": 0.933321,
            "f1_weighted": 0.934785,
            "ap": 0.909549,
            "ap_weighted": 0.909549
          },
          {
            "accuracy": 0.912548,
            "f1": 0.912299,
            "f1_weighted": 0.912885,
            "ap": 0.836222,
            "ap_weighted": 0.836222
          },
          {
            "accuracy": 0.893536,
            "f1": 0.891142,
            "f1_weighted": 0.893168,
            "ap": 0.830813,
            "ap_weighted": 0.830813
          },
          {
            "accuracy": 0.908745,
            "f1": 0.907913,
            "f1_weighted": 0.909012,
            "ap": 0.839821,
            "ap_weighted": 0.839821
          },
          {
            "accuracy": 0.889734,
            "f1": 0.88786,
            "f1_weighted": 0.889679,
            "ap": 0.819811,
            "ap_weighted": 0.819811
          },
          {
            "accuracy": 0.91635,
            "f1": 0.915705,
            "f1_weighted": 0.91663,
            "ap": 0.849318,
            "ap_weighted": 0.849318
          }
        ],
        "main_score": 0.901901,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 2.6150753498077393,
  "kg_co2_emissions": null
}