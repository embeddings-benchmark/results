{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.996094,
        "recall": 0.99707,
        "f1": 0.996419,
        "accuracy": 0.99707,
        "main_score": 0.996419,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.476881,
        "recall": 0.555664,
        "f1": 0.498362,
        "accuracy": 0.555664,
        "main_score": 0.498362,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.972493,
        "recall": 0.981445,
        "f1": 0.975423,
        "accuracy": 0.981445,
        "main_score": 0.975423,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.990479,
        "recall": 0.993164,
        "f1": 0.991276,
        "accuracy": 0.993164,
        "main_score": 0.991276,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.936361,
        "recall": 0.955078,
        "f1": 0.942383,
        "accuracy": 0.955078,
        "main_score": 0.942383,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.907878,
        "recall": 0.933594,
        "f1": 0.915983,
        "accuracy": 0.933594,
        "main_score": 0.915983,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005247,
        "recall": 0.014648,
        "f1": 0.006014,
        "accuracy": 0.014648,
        "main_score": 0.006014,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002942,
        "recall": 0.011719,
        "f1": 0.003647,
        "accuracy": 0.011719,
        "main_score": 0.003647,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.910596,
        "recall": 0.936523,
        "f1": 0.918848,
        "accuracy": 0.936523,
        "main_score": 0.918848,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.993164,
        "f1": 0.991211,
        "accuracy": 0.993164,
        "main_score": 0.991211,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.474735,
        "recall": 0.548828,
        "f1": 0.494575,
        "accuracy": 0.548828,
        "main_score": 0.494575,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.978516,
        "recall": 0.985352,
        "f1": 0.980794,
        "accuracy": 0.985352,
        "main_score": 0.980794,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.944173,
        "recall": 0.961914,
        "f1": 0.950033,
        "accuracy": 0.961914,
        "main_score": 0.950033,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.89196,
        "recall": 0.924805,
        "f1": 0.902507,
        "accuracy": 0.924805,
        "main_score": 0.902507,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003777,
        "recall": 0.011719,
        "f1": 0.004248,
        "accuracy": 0.011719,
        "main_score": 0.004248,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002133,
        "recall": 0.011719,
        "f1": 0.003162,
        "accuracy": 0.011719,
        "main_score": 0.003162,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.90625,
        "recall": 0.932617,
        "f1": 0.914388,
        "accuracy": 0.932617,
        "main_score": 0.914388,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.446189,
        "recall": 0.504883,
        "f1": 0.46023,
        "accuracy": 0.504883,
        "main_score": 0.46023,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.435207,
        "recall": 0.492188,
        "f1": 0.448226,
        "accuracy": 0.492188,
        "main_score": 0.448226,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.487298,
        "recall": 0.532227,
        "f1": 0.49887,
        "accuracy": 0.532227,
        "main_score": 0.49887,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.405492,
        "recall": 0.446289,
        "f1": 0.414001,
        "accuracy": 0.446289,
        "main_score": 0.414001,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.475054,
        "recall": 0.526367,
        "f1": 0.488173,
        "accuracy": 0.526367,
        "main_score": 0.488173,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.439065,
        "recall": 0.500977,
        "f1": 0.454682,
        "accuracy": 0.500977,
        "main_score": 0.454682,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.457093,
        "recall": 0.511719,
        "f1": 0.471243,
        "accuracy": 0.511719,
        "main_score": 0.471243,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.413998,
        "recall": 0.46582,
        "f1": 0.427847,
        "accuracy": 0.46582,
        "main_score": 0.427847,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.425504,
        "recall": 0.482422,
        "f1": 0.439246,
        "accuracy": 0.482422,
        "main_score": 0.439246,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.474041,
        "recall": 0.535156,
        "f1": 0.489758,
        "accuracy": 0.535156,
        "main_score": 0.489758,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.446574,
        "recall": 0.500977,
        "f1": 0.460559,
        "accuracy": 0.500977,
        "main_score": 0.460559,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.448021,
        "recall": 0.512695,
        "f1": 0.465029,
        "accuracy": 0.512695,
        "main_score": 0.465029,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.007835,
        "recall": 0.017578,
        "f1": 0.008518,
        "accuracy": 0.017578,
        "main_score": 0.008518,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.482251,
        "recall": 0.540039,
        "f1": 0.497603,
        "accuracy": 0.540039,
        "main_score": 0.497603,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.437423,
        "recall": 0.505859,
        "f1": 0.455232,
        "accuracy": 0.505859,
        "main_score": 0.455232,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.433792,
        "recall": 0.489258,
        "f1": 0.448205,
        "accuracy": 0.489258,
        "main_score": 0.448205,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.459441,
        "recall": 0.524414,
        "f1": 0.475702,
        "accuracy": 0.524414,
        "main_score": 0.475702,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006942,
        "recall": 0.016602,
        "f1": 0.007778,
        "accuracy": 0.016602,
        "main_score": 0.007778,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.499002,
        "recall": 0.548828,
        "f1": 0.511498,
        "accuracy": 0.548828,
        "main_score": 0.511498,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.383693,
        "recall": 0.441406,
        "f1": 0.397967,
        "accuracy": 0.441406,
        "main_score": 0.397967,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.444307,
        "recall": 0.495117,
        "f1": 0.45679,
        "accuracy": 0.495117,
        "main_score": 0.45679,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.413611,
        "recall": 0.476562,
        "f1": 0.429134,
        "accuracy": 0.476562,
        "main_score": 0.429134,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.968424,
        "recall": 0.978516,
        "f1": 0.97168,
        "accuracy": 0.978516,
        "main_score": 0.97168,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.549268,
        "recall": 0.613281,
        "f1": 0.566969,
        "accuracy": 0.613281,
        "main_score": 0.566969,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.934408,
        "recall": 0.954102,
        "f1": 0.940755,
        "accuracy": 0.954102,
        "main_score": 0.940755,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.9764,
        "recall": 0.983398,
        "f1": 0.978678,
        "accuracy": 0.983398,
        "main_score": 0.978678,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.975749,
        "recall": 0.983398,
        "f1": 0.97819,
        "accuracy": 0.983398,
        "main_score": 0.97819,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.881877,
        "recall": 0.911133,
        "f1": 0.890698,
        "accuracy": 0.911133,
        "main_score": 0.890698,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.974772,
        "recall": 0.982422,
        "f1": 0.977214,
        "accuracy": 0.982422,
        "main_score": 0.977214,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.979818,
        "recall": 0.986328,
        "f1": 0.981934,
        "accuracy": 0.986328,
        "main_score": 0.981934,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.006162,
        "recall": 0.016602,
        "f1": 0.007209,
        "accuracy": 0.016602,
        "main_score": 0.007209,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.973633,
        "recall": 0.982422,
        "f1": 0.976562,
        "accuracy": 0.982422,
        "main_score": 0.976562,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.964355,
        "recall": 0.975586,
        "f1": 0.968099,
        "accuracy": 0.975586,
        "main_score": 0.968099,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.952181,
        "recall": 0.96582,
        "f1": 0.95638,
        "accuracy": 0.96582,
        "main_score": 0.95638,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.003691,
        "recall": 0.016602,
        "f1": 0.004903,
        "accuracy": 0.016602,
        "main_score": 0.004903,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.924154,
        "recall": 0.945312,
        "f1": 0.930794,
        "accuracy": 0.945312,
        "main_score": 0.930794,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.9646,
        "recall": 0.975586,
        "f1": 0.968164,
        "accuracy": 0.975586,
        "main_score": 0.968164,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.969238,
        "recall": 0.978516,
        "f1": 0.972168,
        "accuracy": 0.978516,
        "main_score": 0.972168,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.43915,
        "recall": 0.529297,
        "f1": 0.463574,
        "accuracy": 0.529297,
        "main_score": 0.463574,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.937744,
        "recall": 0.957031,
        "f1": 0.943913,
        "accuracy": 0.957031,
        "main_score": 0.943913,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.895378,
        "recall": 0.925781,
        "f1": 0.904915,
        "accuracy": 0.925781,
        "main_score": 0.904915,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.996094,
        "recall": 0.99707,
        "f1": 0.996419,
        "accuracy": 0.99707,
        "main_score": 0.996419,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003627,
        "recall": 0.012695,
        "f1": 0.004537,
        "accuracy": 0.012695,
        "main_score": 0.004537,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002508,
        "recall": 0.013672,
        "f1": 0.003377,
        "accuracy": 0.013672,
        "main_score": 0.003377,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.894189,
        "recall": 0.923828,
        "f1": 0.903223,
        "accuracy": 0.923828,
        "main_score": 0.903223,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.996094,
        "recall": 0.99707,
        "f1": 0.996419,
        "accuracy": 0.99707,
        "main_score": 0.996419,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.939779,
        "recall": 0.958008,
        "f1": 0.945638,
        "accuracy": 0.958008,
        "main_score": 0.945638,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.935361,
        "recall": 0.954102,
        "f1": 0.941162,
        "accuracy": 0.954102,
        "main_score": 0.941162,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.523725,
        "recall": 0.59375,
        "f1": 0.543055,
        "accuracy": 0.59375,
        "main_score": 0.543055,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.926188,
        "recall": 0.946289,
        "f1": 0.932682,
        "accuracy": 0.946289,
        "main_score": 0.932682,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.9375,
        "recall": 0.956055,
        "f1": 0.943327,
        "accuracy": 0.956055,
        "main_score": 0.943327,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.95988,
        "recall": 0.97168,
        "f1": 0.963607,
        "accuracy": 0.97168,
        "main_score": 0.963607,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.950358,
        "recall": 0.96582,
        "f1": 0.955241,
        "accuracy": 0.96582,
        "main_score": 0.955241,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.940755,
        "recall": 0.958984,
        "f1": 0.946615,
        "accuracy": 0.958984,
        "main_score": 0.946615,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.839023,
        "recall": 0.879883,
        "f1": 0.851528,
        "accuracy": 0.879883,
        "main_score": 0.851528,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.969271,
        "recall": 0.978516,
        "f1": 0.972168,
        "accuracy": 0.978516,
        "main_score": 0.972168,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.956543,
        "recall": 0.969727,
        "f1": 0.960775,
        "accuracy": 0.969727,
        "main_score": 0.960775,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.965169,
        "recall": 0.976562,
        "f1": 0.968913,
        "accuracy": 0.976562,
        "main_score": 0.968913,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.007093,
        "recall": 0.015625,
        "f1": 0.007768,
        "accuracy": 0.015625,
        "main_score": 0.007768,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.968099,
        "recall": 0.978516,
        "f1": 0.971517,
        "accuracy": 0.978516,
        "main_score": 0.971517,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.953613,
        "recall": 0.967773,
        "f1": 0.958171,
        "accuracy": 0.967773,
        "main_score": 0.958171,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.91526,
        "recall": 0.938477,
        "f1": 0.922152,
        "accuracy": 0.938477,
        "main_score": 0.922152,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.923096,
        "recall": 0.945312,
        "f1": 0.929915,
        "accuracy": 0.945312,
        "main_score": 0.929915,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005278,
        "recall": 0.014648,
        "f1": 0.006111,
        "accuracy": 0.014648,
        "main_score": 0.006111,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.839274,
        "recall": 0.879883,
        "f1": 0.851628,
        "accuracy": 0.879883,
        "main_score": 0.851628,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.926172,
        "recall": 0.947266,
        "f1": 0.93278,
        "accuracy": 0.947266,
        "main_score": 0.93278,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.951774,
        "recall": 0.96582,
        "f1": 0.95612,
        "accuracy": 0.96582,
        "main_score": 0.95612,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.95516,
        "recall": 0.96875,
        "f1": 0.959375,
        "accuracy": 0.96875,
        "main_score": 0.959375,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.480594,
        "recall": 0.560547,
        "f1": 0.502779,
        "accuracy": 0.560547,
        "main_score": 0.502779,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.987305,
        "f1": 0.984049,
        "accuracy": 0.987305,
        "main_score": 0.984049,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.957357,
        "recall": 0.970703,
        "f1": 0.961589,
        "accuracy": 0.970703,
        "main_score": 0.961589,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.915527,
        "recall": 0.939453,
        "f1": 0.923177,
        "accuracy": 0.939453,
        "main_score": 0.923177,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001261,
        "recall": 0.005859,
        "f1": 0.001489,
        "accuracy": 0.005859,
        "main_score": 0.001489,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00374,
        "recall": 0.012695,
        "f1": 0.004781,
        "accuracy": 0.012695,
        "main_score": 0.004781,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.918213,
        "recall": 0.941406,
        "f1": 0.925521,
        "accuracy": 0.941406,
        "main_score": 0.925521,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.493567,
        "recall": 0.572266,
        "f1": 0.515621,
        "accuracy": 0.572266,
        "main_score": 0.515621,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.955648,
        "recall": 0.969727,
        "f1": 0.960189,
        "accuracy": 0.969727,
        "main_score": 0.960189,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.902588,
        "recall": 0.931641,
        "f1": 0.912012,
        "accuracy": 0.931641,
        "main_score": 0.912012,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001893,
        "recall": 0.009766,
        "f1": 0.002406,
        "accuracy": 0.009766,
        "main_score": 0.002406,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.98877,
        "recall": 0.992188,
        "f1": 0.989909,
        "accuracy": 0.992188,
        "main_score": 0.989909,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.003267,
        "recall": 0.011719,
        "f1": 0.003997,
        "accuracy": 0.011719,
        "main_score": 0.003997,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.925049,
        "recall": 0.945312,
        "f1": 0.931185,
        "accuracy": 0.945312,
        "main_score": 0.931185,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.444406,
        "recall": 0.530273,
        "f1": 0.467566,
        "accuracy": 0.530273,
        "main_score": 0.467566,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.978516,
        "recall": 0.985352,
        "f1": 0.980794,
        "accuracy": 0.985352,
        "main_score": 0.980794,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.942546,
        "recall": 0.960938,
        "f1": 0.948568,
        "accuracy": 0.960938,
        "main_score": 0.948568,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.893799,
        "recall": 0.924805,
        "f1": 0.903678,
        "accuracy": 0.924805,
        "main_score": 0.903678,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004879,
        "recall": 0.011719,
        "f1": 0.005427,
        "accuracy": 0.011719,
        "main_score": 0.005427,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002738,
        "recall": 0.011719,
        "f1": 0.003298,
        "accuracy": 0.011719,
        "main_score": 0.003298,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.909131,
        "recall": 0.935547,
        "f1": 0.917383,
        "accuracy": 0.935547,
        "main_score": 0.917383,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.886263,
        "recall": 0.917969,
        "f1": 0.896126,
        "accuracy": 0.917969,
        "main_score": 0.896126,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.878613,
        "recall": 0.912109,
        "f1": 0.888756,
        "accuracy": 0.912109,
        "main_score": 0.888756,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.443722,
        "recall": 0.513672,
        "f1": 0.462187,
        "accuracy": 0.513672,
        "main_score": 0.462187,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.853418,
        "recall": 0.890625,
        "f1": 0.864458,
        "accuracy": 0.890625,
        "main_score": 0.864458,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.861702,
        "recall": 0.891602,
        "f1": 0.869946,
        "accuracy": 0.891602,
        "main_score": 0.869946,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.793409,
        "recall": 0.839844,
        "f1": 0.806474,
        "accuracy": 0.839844,
        "main_score": 0.806474,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.897607,
        "recall": 0.925781,
        "f1": 0.906315,
        "accuracy": 0.925781,
        "main_score": 0.906315,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.873333,
        "recall": 0.905273,
        "f1": 0.882508,
        "accuracy": 0.905273,
        "main_score": 0.882508,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.875521,
        "recall": 0.911133,
        "f1": 0.886314,
        "accuracy": 0.911133,
        "main_score": 0.886314,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.914266,
        "recall": 0.938477,
        "f1": 0.921832,
        "accuracy": 0.938477,
        "main_score": 0.921832,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.886182,
        "recall": 0.916016,
        "f1": 0.895006,
        "accuracy": 0.916016,
        "main_score": 0.895006,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.884318,
        "recall": 0.916992,
        "f1": 0.894279,
        "accuracy": 0.916992,
        "main_score": 0.894279,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.007322,
        "recall": 0.017578,
        "f1": 0.008552,
        "accuracy": 0.017578,
        "main_score": 0.008552,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.910621,
        "recall": 0.935547,
        "f1": 0.91818,
        "accuracy": 0.935547,
        "main_score": 0.91818,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.884505,
        "recall": 0.916992,
        "f1": 0.894661,
        "accuracy": 0.916992,
        "main_score": 0.894661,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.874465,
        "recall": 0.907227,
        "f1": 0.884408,
        "accuracy": 0.907227,
        "main_score": 0.884408,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.843443,
        "recall": 0.880859,
        "f1": 0.854622,
        "accuracy": 0.880859,
        "main_score": 0.854622,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006392,
        "recall": 0.017578,
        "f1": 0.007291,
        "accuracy": 0.017578,
        "main_score": 0.007291,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.797689,
        "recall": 0.842773,
        "f1": 0.810767,
        "accuracy": 0.842773,
        "main_score": 0.810767,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.860872,
        "recall": 0.895508,
        "f1": 0.871159,
        "accuracy": 0.895508,
        "main_score": 0.871159,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.887842,
        "recall": 0.918945,
        "f1": 0.897168,
        "accuracy": 0.918945,
        "main_score": 0.897168,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.935498,
        "recall": 0.954102,
        "f1": 0.941146,
        "accuracy": 0.954102,
        "main_score": 0.941146,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.516801,
        "recall": 0.588867,
        "f1": 0.536196,
        "accuracy": 0.588867,
        "main_score": 0.536196,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.963704,
        "recall": 0.975586,
        "f1": 0.967611,
        "accuracy": 0.975586,
        "main_score": 0.967611,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.918457,
        "recall": 0.944336,
        "f1": 0.926921,
        "accuracy": 0.944336,
        "main_score": 0.926921,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004825,
        "recall": 0.012695,
        "f1": 0.005332,
        "accuracy": 0.012695,
        "main_score": 0.005332,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005976,
        "recall": 0.014648,
        "f1": 0.006628,
        "accuracy": 0.014648,
        "main_score": 0.006628,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.91805,
        "recall": 0.942383,
        "f1": 0.925846,
        "accuracy": 0.942383,
        "main_score": 0.925846,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.993164,
        "f1": 0.991211,
        "accuracy": 0.993164,
        "main_score": 0.991211,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.473866,
        "recall": 0.553711,
        "f1": 0.495278,
        "accuracy": 0.553711,
        "main_score": 0.495278,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.969727,
        "recall": 0.979492,
        "f1": 0.972982,
        "accuracy": 0.979492,
        "main_score": 0.972982,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.937012,
        "recall": 0.956055,
        "f1": 0.943034,
        "accuracy": 0.956055,
        "main_score": 0.943034,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.900505,
        "recall": 0.929688,
        "f1": 0.909733,
        "accuracy": 0.929688,
        "main_score": 0.909733,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002596,
        "recall": 0.011719,
        "f1": 0.00309,
        "accuracy": 0.011719,
        "main_score": 0.00309,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.986003,
        "recall": 0.990234,
        "f1": 0.987305,
        "accuracy": 0.990234,
        "main_score": 0.987305,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001883,
        "recall": 0.010742,
        "f1": 0.002527,
        "accuracy": 0.010742,
        "main_score": 0.002527,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.895915,
        "recall": 0.925781,
        "f1": 0.905339,
        "accuracy": 0.925781,
        "main_score": 0.905339,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.996094,
        "recall": 0.99707,
        "f1": 0.996419,
        "accuracy": 0.99707,
        "main_score": 0.996419,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.507831,
        "recall": 0.582031,
        "f1": 0.527849,
        "accuracy": 0.582031,
        "main_score": 0.527849,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.966634,
        "recall": 0.977539,
        "f1": 0.970215,
        "accuracy": 0.977539,
        "main_score": 0.970215,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.893392,
        "recall": 0.924805,
        "f1": 0.903483,
        "accuracy": 0.924805,
        "main_score": 0.903483,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.993164,
        "f1": 0.991211,
        "accuracy": 0.993164,
        "main_score": 0.991211,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.003369,
        "recall": 0.011719,
        "f1": 0.004103,
        "accuracy": 0.011719,
        "main_score": 0.004103,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.977051,
        "recall": 0.984375,
        "f1": 0.979492,
        "accuracy": 0.984375,
        "main_score": 0.979492,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001565,
        "recall": 0.012695,
        "f1": 0.002401,
        "accuracy": 0.012695,
        "main_score": 0.002401,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.901644,
        "recall": 0.928711,
        "f1": 0.910059,
        "accuracy": 0.928711,
        "main_score": 0.910059,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.993164,
        "f1": 0.991211,
        "accuracy": 0.993164,
        "main_score": 0.991211,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.995931,
        "recall": 0.99707,
        "f1": 0.996257,
        "accuracy": 0.99707,
        "main_score": 0.996257,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000832,
        "recall": 0.005859,
        "f1": 0.00126,
        "accuracy": 0.005859,
        "main_score": 0.00126,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.003521,
        "recall": 0.011719,
        "f1": 0.00445,
        "accuracy": 0.011719,
        "main_score": 0.00445,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.00664,
        "recall": 0.013672,
        "f1": 0.007178,
        "accuracy": 0.013672,
        "main_score": 0.007178,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.002815,
        "recall": 0.009766,
        "f1": 0.003286,
        "accuracy": 0.009766,
        "main_score": 0.003286,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00285,
        "recall": 0.005859,
        "f1": 0.003323,
        "accuracy": 0.005859,
        "main_score": 0.003323,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004138,
        "recall": 0.010742,
        "f1": 0.004746,
        "accuracy": 0.010742,
        "main_score": 0.004746,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.001875,
        "recall": 0.006836,
        "f1": 0.002342,
        "accuracy": 0.006836,
        "main_score": 0.002342,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.001165,
        "recall": 0.004883,
        "f1": 0.001322,
        "accuracy": 0.004883,
        "main_score": 0.001322,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.002565,
        "recall": 0.008789,
        "f1": 0.003319,
        "accuracy": 0.008789,
        "main_score": 0.003319,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004187,
        "recall": 0.010742,
        "f1": 0.005255,
        "accuracy": 0.010742,
        "main_score": 0.005255,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.001887,
        "recall": 0.010742,
        "f1": 0.002482,
        "accuracy": 0.010742,
        "main_score": 0.002482,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.005859,
        "f1": 0.00082,
        "accuracy": 0.005859,
        "main_score": 0.00082,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.002584,
        "recall": 0.005859,
        "f1": 0.002861,
        "accuracy": 0.005859,
        "main_score": 0.002861,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002139,
        "recall": 0.007812,
        "f1": 0.00262,
        "accuracy": 0.007812,
        "main_score": 0.00262,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.004259,
        "recall": 0.009766,
        "f1": 0.004928,
        "accuracy": 0.009766,
        "main_score": 0.004928,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.001094,
        "recall": 0.003906,
        "f1": 0.001189,
        "accuracy": 0.003906,
        "main_score": 0.001189,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.003139,
        "recall": 0.006836,
        "f1": 0.003314,
        "accuracy": 0.006836,
        "main_score": 0.003314,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.080457,
        "recall": 0.118164,
        "f1": 0.08991,
        "accuracy": 0.118164,
        "main_score": 0.08991,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.003812,
        "recall": 0.009766,
        "f1": 0.004386,
        "accuracy": 0.009766,
        "main_score": 0.004386,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.001592,
        "recall": 0.003906,
        "f1": 0.001854,
        "accuracy": 0.003906,
        "main_score": 0.001854,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001715,
        "recall": 0.005859,
        "f1": 0.002083,
        "accuracy": 0.005859,
        "main_score": 0.002083,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003204,
        "recall": 0.009766,
        "f1": 0.00421,
        "accuracy": 0.009766,
        "main_score": 0.00421,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.509265,
        "recall": 0.589844,
        "f1": 0.530781,
        "accuracy": 0.589844,
        "main_score": 0.530781,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.965169,
        "recall": 0.976562,
        "f1": 0.968913,
        "accuracy": 0.976562,
        "main_score": 0.968913,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.918734,
        "recall": 0.942383,
        "f1": 0.926172,
        "accuracy": 0.942383,
        "main_score": 0.926172,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003752,
        "recall": 0.012695,
        "f1": 0.004323,
        "accuracy": 0.012695,
        "main_score": 0.004323,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.98877,
        "recall": 0.992188,
        "f1": 0.989909,
        "accuracy": 0.992188,
        "main_score": 0.989909,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.004646,
        "recall": 0.012695,
        "f1": 0.005186,
        "accuracy": 0.012695,
        "main_score": 0.005186,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.925374,
        "recall": 0.946289,
        "f1": 0.931868,
        "accuracy": 0.946289,
        "main_score": 0.931868,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.991699,
        "recall": 0.994141,
        "f1": 0.992513,
        "accuracy": 0.994141,
        "main_score": 0.992513,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.450623,
        "recall": 0.53125,
        "f1": 0.472433,
        "accuracy": 0.53125,
        "main_score": 0.472433,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.973145,
        "recall": 0.981445,
        "f1": 0.975911,
        "accuracy": 0.981445,
        "main_score": 0.975911,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.954427,
        "recall": 0.96875,
        "f1": 0.958984,
        "accuracy": 0.96875,
        "main_score": 0.958984,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.896191,
        "recall": 0.926758,
        "f1": 0.905924,
        "accuracy": 0.926758,
        "main_score": 0.905924,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.991699,
        "recall": 0.994141,
        "f1": 0.992513,
        "accuracy": 0.994141,
        "main_score": 0.992513,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004101,
        "recall": 0.011719,
        "f1": 0.004725,
        "accuracy": 0.011719,
        "main_score": 0.004725,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005108,
        "recall": 0.014648,
        "f1": 0.006089,
        "accuracy": 0.014648,
        "main_score": 0.006089,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.911702,
        "recall": 0.936523,
        "f1": 0.919661,
        "accuracy": 0.936523,
        "main_score": 0.919661,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.993164,
        "f1": 0.991211,
        "accuracy": 0.993164,
        "main_score": 0.991211,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.451253,
        "recall": 0.532227,
        "f1": 0.473285,
        "accuracy": 0.532227,
        "main_score": 0.473285,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.9611,
        "recall": 0.972656,
        "f1": 0.964844,
        "accuracy": 0.972656,
        "main_score": 0.964844,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.923584,
        "recall": 0.946289,
        "f1": 0.930729,
        "accuracy": 0.946289,
        "main_score": 0.930729,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.880534,
        "recall": 0.913086,
        "f1": 0.890592,
        "accuracy": 0.913086,
        "main_score": 0.890592,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.987305,
        "recall": 0.991211,
        "f1": 0.988607,
        "accuracy": 0.991211,
        "main_score": 0.988607,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.986328,
        "recall": 0.990234,
        "f1": 0.98763,
        "accuracy": 0.990234,
        "main_score": 0.98763,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.991699,
        "recall": 0.994141,
        "f1": 0.992513,
        "accuracy": 0.994141,
        "main_score": 0.992513,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003107,
        "recall": 0.012695,
        "f1": 0.004169,
        "accuracy": 0.012695,
        "main_score": 0.004169,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.978353,
        "recall": 0.985352,
        "f1": 0.980632,
        "accuracy": 0.985352,
        "main_score": 0.980632,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.004409,
        "recall": 0.012695,
        "f1": 0.005149,
        "accuracy": 0.012695,
        "main_score": 0.005149,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.903141,
        "recall": 0.928711,
        "f1": 0.910872,
        "accuracy": 0.928711,
        "main_score": 0.910872,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.984701,
        "recall": 0.989258,
        "f1": 0.986165,
        "accuracy": 0.989258,
        "main_score": 0.986165,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.984212,
        "recall": 0.989258,
        "f1": 0.98584,
        "accuracy": 0.989258,
        "main_score": 0.98584,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.988607,
        "recall": 0.992188,
        "f1": 0.989746,
        "accuracy": 0.992188,
        "main_score": 0.989746,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.466012,
        "recall": 0.543945,
        "f1": 0.487075,
        "accuracy": 0.543945,
        "main_score": 0.487075,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.94401,
        "recall": 0.961914,
        "f1": 0.94987,
        "accuracy": 0.961914,
        "main_score": 0.94987,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.980957,
        "recall": 0.987305,
        "f1": 0.983073,
        "accuracy": 0.987305,
        "main_score": 0.983073,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.928467,
        "recall": 0.949219,
        "f1": 0.934961,
        "accuracy": 0.949219,
        "main_score": 0.934961,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.981283,
        "recall": 0.987305,
        "f1": 0.983236,
        "accuracy": 0.987305,
        "main_score": 0.983236,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.858317,
        "recall": 0.897461,
        "f1": 0.870833,
        "accuracy": 0.897461,
        "main_score": 0.870833,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.98584,
        "recall": 0.990234,
        "f1": 0.987305,
        "accuracy": 0.990234,
        "main_score": 0.987305,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002928,
        "recall": 0.012695,
        "f1": 0.003491,
        "accuracy": 0.012695,
        "main_score": 0.003491,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.978353,
        "recall": 0.985352,
        "f1": 0.980632,
        "accuracy": 0.985352,
        "main_score": 0.980632,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.968587,
        "recall": 0.978516,
        "f1": 0.971842,
        "accuracy": 0.978516,
        "main_score": 0.971842,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.004409,
        "recall": 0.014648,
        "f1": 0.005305,
        "accuracy": 0.014648,
        "main_score": 0.005305,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.882894,
        "recall": 0.916016,
        "f1": 0.893457,
        "accuracy": 0.916016,
        "main_score": 0.893457,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.979574,
        "recall": 0.985352,
        "f1": 0.981348,
        "accuracy": 0.985352,
        "main_score": 0.981348,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.002401,
        "recall": 0.006836,
        "f1": 0.00273,
        "accuracy": 0.006836,
        "main_score": 0.00273,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.003319,
        "recall": 0.007812,
        "f1": 0.003619,
        "accuracy": 0.007812,
        "main_score": 0.003619,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.005518,
        "recall": 0.012695,
        "f1": 0.00597,
        "accuracy": 0.012695,
        "main_score": 0.00597,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.004217,
        "recall": 0.009766,
        "f1": 0.004473,
        "accuracy": 0.009766,
        "main_score": 0.004473,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.0037,
        "recall": 0.007812,
        "f1": 0.004132,
        "accuracy": 0.007812,
        "main_score": 0.004132,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004418,
        "recall": 0.011719,
        "f1": 0.005186,
        "accuracy": 0.011719,
        "main_score": 0.005186,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.002924,
        "recall": 0.006836,
        "f1": 0.003404,
        "accuracy": 0.006836,
        "main_score": 0.003404,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.003226,
        "recall": 0.006836,
        "f1": 0.003457,
        "accuracy": 0.006836,
        "main_score": 0.003457,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003689,
        "recall": 0.007812,
        "f1": 0.004104,
        "accuracy": 0.007812,
        "main_score": 0.004104,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004769,
        "recall": 0.011719,
        "f1": 0.00528,
        "accuracy": 0.011719,
        "main_score": 0.00528,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.00364,
        "recall": 0.006836,
        "f1": 0.004019,
        "accuracy": 0.006836,
        "main_score": 0.004019,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.003551,
        "recall": 0.006836,
        "f1": 0.00383,
        "accuracy": 0.006836,
        "main_score": 0.00383,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.003176,
        "recall": 0.006836,
        "f1": 0.003368,
        "accuracy": 0.006836,
        "main_score": 0.003368,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.059495,
        "recall": 0.098633,
        "f1": 0.069245,
        "accuracy": 0.098633,
        "main_score": 0.069245,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.003541,
        "recall": 0.008789,
        "f1": 0.003919,
        "accuracy": 0.008789,
        "main_score": 0.003919,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.003816,
        "recall": 0.008789,
        "f1": 0.004264,
        "accuracy": 0.008789,
        "main_score": 0.004264,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.002318,
        "recall": 0.004883,
        "f1": 0.002571,
        "accuracy": 0.004883,
        "main_score": 0.002571,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.002352,
        "recall": 0.006836,
        "f1": 0.002662,
        "accuracy": 0.006836,
        "main_score": 0.002662,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.003249,
        "recall": 0.007812,
        "f1": 0.003503,
        "accuracy": 0.007812,
        "main_score": 0.003503,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.002157,
        "recall": 0.005859,
        "f1": 0.002313,
        "accuracy": 0.005859,
        "main_score": 0.002313,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.005856,
        "recall": 0.010742,
        "f1": 0.00637,
        "accuracy": 0.010742,
        "main_score": 0.00637,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003773,
        "recall": 0.007812,
        "f1": 0.004243,
        "accuracy": 0.007812,
        "main_score": 0.004243,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.894694,
        "recall": 0.924805,
        "f1": 0.904134,
        "accuracy": 0.924805,
        "main_score": 0.904134,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.901995,
        "recall": 0.927734,
        "f1": 0.910075,
        "accuracy": 0.927734,
        "main_score": 0.910075,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.543964,
        "recall": 0.608398,
        "f1": 0.561424,
        "accuracy": 0.608398,
        "main_score": 0.561424,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.922314,
        "recall": 0.944336,
        "f1": 0.929427,
        "accuracy": 0.944336,
        "main_score": 0.929427,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.878258,
        "recall": 0.90625,
        "f1": 0.886069,
        "accuracy": 0.90625,
        "main_score": 0.886069,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.858154,
        "recall": 0.895508,
        "f1": 0.869648,
        "accuracy": 0.895508,
        "main_score": 0.869648,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.923096,
        "recall": 0.944336,
        "f1": 0.92959,
        "accuracy": 0.944336,
        "main_score": 0.92959,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.926188,
        "recall": 0.947266,
        "f1": 0.93265,
        "accuracy": 0.947266,
        "main_score": 0.93265,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.894531,
        "recall": 0.922852,
        "f1": 0.903241,
        "accuracy": 0.922852,
        "main_score": 0.903241,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.808415,
        "recall": 0.858398,
        "f1": 0.82373,
        "accuracy": 0.858398,
        "main_score": 0.82373,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.933594,
        "recall": 0.952148,
        "f1": 0.939616,
        "accuracy": 0.952148,
        "main_score": 0.939616,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.885286,
        "recall": 0.916992,
        "f1": 0.895312,
        "accuracy": 0.916992,
        "main_score": 0.895312,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.911947,
        "recall": 0.936523,
        "f1": 0.919564,
        "accuracy": 0.936523,
        "main_score": 0.919564,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.006512,
        "recall": 0.014648,
        "f1": 0.007007,
        "accuracy": 0.014648,
        "main_score": 0.007007,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.934001,
        "recall": 0.953125,
        "f1": 0.940007,
        "accuracy": 0.953125,
        "main_score": 0.940007,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.902832,
        "recall": 0.932617,
        "f1": 0.912272,
        "accuracy": 0.932617,
        "main_score": 0.912272,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.899211,
        "recall": 0.925781,
        "f1": 0.907411,
        "accuracy": 0.925781,
        "main_score": 0.907411,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.875407,
        "recall": 0.908203,
        "f1": 0.885286,
        "accuracy": 0.908203,
        "main_score": 0.885286,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00603,
        "recall": 0.016602,
        "f1": 0.006869,
        "accuracy": 0.016602,
        "main_score": 0.006869,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.880452,
        "recall": 0.914062,
        "f1": 0.890788,
        "accuracy": 0.914062,
        "main_score": 0.890788,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.908561,
        "recall": 0.93457,
        "f1": 0.916588,
        "accuracy": 0.93457,
        "main_score": 0.916588,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.924886,
        "recall": 0.947266,
        "f1": 0.931868,
        "accuracy": 0.947266,
        "main_score": 0.931868,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.430996,
        "recall": 0.507812,
        "f1": 0.452072,
        "accuracy": 0.507812,
        "main_score": 0.452072,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.969434,
        "recall": 0.978516,
        "f1": 0.972331,
        "accuracy": 0.978516,
        "main_score": 0.972331,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.931803,
        "recall": 0.951172,
        "f1": 0.937988,
        "accuracy": 0.951172,
        "main_score": 0.937988,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.869548,
        "recall": 0.908203,
        "f1": 0.881738,
        "accuracy": 0.908203,
        "main_score": 0.881738,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001336,
        "recall": 0.008789,
        "f1": 0.00197,
        "accuracy": 0.008789,
        "main_score": 0.00197,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.987142,
        "recall": 0.991211,
        "f1": 0.988444,
        "accuracy": 0.991211,
        "main_score": 0.988444,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.973958,
        "recall": 0.982422,
        "f1": 0.976725,
        "accuracy": 0.982422,
        "main_score": 0.976725,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001933,
        "recall": 0.010742,
        "f1": 0.002603,
        "accuracy": 0.010742,
        "main_score": 0.002603,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.882487,
        "recall": 0.916992,
        "f1": 0.893522,
        "accuracy": 0.916992,
        "main_score": 0.893522,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.484421,
        "recall": 0.5625,
        "f1": 0.505963,
        "accuracy": 0.5625,
        "main_score": 0.505963,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.972493,
        "recall": 0.981445,
        "f1": 0.975423,
        "accuracy": 0.981445,
        "main_score": 0.975423,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.946126,
        "recall": 0.963867,
        "f1": 0.951986,
        "accuracy": 0.963867,
        "main_score": 0.951986,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.892611,
        "recall": 0.923828,
        "f1": 0.902669,
        "accuracy": 0.923828,
        "main_score": 0.902669,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.996094,
        "recall": 0.99707,
        "f1": 0.996419,
        "accuracy": 0.99707,
        "main_score": 0.996419,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005621,
        "recall": 0.011719,
        "f1": 0.00608,
        "accuracy": 0.011719,
        "main_score": 0.00608,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002706,
        "recall": 0.010742,
        "f1": 0.003207,
        "accuracy": 0.010742,
        "main_score": 0.003207,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.906331,
        "recall": 0.932617,
        "f1": 0.914421,
        "accuracy": 0.932617,
        "main_score": 0.914421,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.450451,
        "recall": 0.530273,
        "f1": 0.471506,
        "accuracy": 0.530273,
        "main_score": 0.471506,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.98877,
        "recall": 0.992188,
        "f1": 0.989909,
        "accuracy": 0.992188,
        "main_score": 0.989909,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.953857,
        "recall": 0.967773,
        "f1": 0.958236,
        "accuracy": 0.967773,
        "main_score": 0.958236,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.935417,
        "recall": 0.955078,
        "f1": 0.941732,
        "accuracy": 0.955078,
        "main_score": 0.941732,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005051,
        "recall": 0.013672,
        "f1": 0.005715,
        "accuracy": 0.013672,
        "main_score": 0.005715,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.003647,
        "recall": 0.011719,
        "f1": 0.004503,
        "accuracy": 0.011719,
        "main_score": 0.004503,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.921224,
        "recall": 0.942383,
        "f1": 0.927734,
        "accuracy": 0.942383,
        "main_score": 0.927734,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 50.05108118057251,
  "kg_co2_emissions": 0.0032961134613599978
}