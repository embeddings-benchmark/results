{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.597998,
        "f1": 0.591245,
        "f1_weighted": 0.59552,
        "ap": 0.482496,
        "ap_weighted": 0.482496,
        "scores_per_experiment": [
          {
            "accuracy": 0.655273,
            "f1": 0.633977,
            "f1_weighted": 0.648203,
            "ap": 0.513532,
            "ap_weighted": 0.513532
          },
          {
            "accuracy": 0.543945,
            "f1": 0.543651,
            "f1_weighted": 0.541784,
            "ap": 0.453605,
            "ap_weighted": 0.453605
          },
          {
            "accuracy": 0.562988,
            "f1": 0.560966,
            "f1_weighted": 0.565767,
            "ap": 0.456868,
            "ap_weighted": 0.456868
          },
          {
            "accuracy": 0.588379,
            "f1": 0.588245,
            "f1_weighted": 0.587046,
            "ap": 0.482395,
            "ap_weighted": 0.482395
          },
          {
            "accuracy": 0.586426,
            "f1": 0.583453,
            "f1_weighted": 0.577784,
            "ap": 0.487391,
            "ap_weighted": 0.487391
          },
          {
            "accuracy": 0.591309,
            "f1": 0.581406,
            "f1_weighted": 0.59178,
            "ap": 0.468016,
            "ap_weighted": 0.468016
          },
          {
            "accuracy": 0.608887,
            "f1": 0.608539,
            "f1_weighted": 0.606661,
            "ap": 0.498436,
            "ap_weighted": 0.498436
          },
          {
            "accuracy": 0.617188,
            "f1": 0.617082,
            "f1_weighted": 0.616058,
            "ap": 0.50347,
            "ap_weighted": 0.50347
          },
          {
            "accuracy": 0.612793,
            "f1": 0.593242,
            "f1_weighted": 0.607611,
            "ap": 0.478153,
            "ap_weighted": 0.478153
          },
          {
            "accuracy": 0.612793,
            "f1": 0.601885,
            "f1_weighted": 0.612503,
            "ap": 0.48309,
            "ap_weighted": 0.48309
          }
        ],
        "main_score": 0.591245,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 8.135620355606079,
  "kg_co2_emissions": 0.0002891298494171612
}