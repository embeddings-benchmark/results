{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "task_name": "PoemSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.522857,
        "f1": 0.390405,
        "f1_weighted": 0.574785,
        "scores_per_experiment": [
          {
            "accuracy": 0.542857,
            "f1": 0.426813,
            "f1_weighted": 0.601081
          },
          {
            "accuracy": 0.580952,
            "f1": 0.441214,
            "f1_weighted": 0.624899
          },
          {
            "accuracy": 0.485714,
            "f1": 0.372653,
            "f1_weighted": 0.550483
          },
          {
            "accuracy": 0.504762,
            "f1": 0.391865,
            "f1_weighted": 0.571402
          },
          {
            "accuracy": 0.571429,
            "f1": 0.412669,
            "f1_weighted": 0.609781
          },
          {
            "accuracy": 0.466667,
            "f1": 0.362374,
            "f1_weighted": 0.494324
          },
          {
            "accuracy": 0.561905,
            "f1": 0.422161,
            "f1_weighted": 0.634956
          },
          {
            "accuracy": 0.495238,
            "f1": 0.345424,
            "f1_weighted": 0.544364
          },
          {
            "accuracy": 0.457143,
            "f1": 0.331387,
            "f1_weighted": 0.515745
          },
          {
            "accuracy": 0.561905,
            "f1": 0.39749,
            "f1_weighted": 0.600817
          }
        ],
        "main_score": 0.522857,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.576923,
        "f1": 0.438597,
        "f1_weighted": 0.629722,
        "scores_per_experiment": [
          {
            "accuracy": 0.625,
            "f1": 0.461289,
            "f1_weighted": 0.669248
          },
          {
            "accuracy": 0.644231,
            "f1": 0.488423,
            "f1_weighted": 0.680966
          },
          {
            "accuracy": 0.625,
            "f1": 0.489035,
            "f1_weighted": 0.688765
          },
          {
            "accuracy": 0.615385,
            "f1": 0.489585,
            "f1_weighted": 0.679128
          },
          {
            "accuracy": 0.596154,
            "f1": 0.435786,
            "f1_weighted": 0.651626
          },
          {
            "accuracy": 0.471154,
            "f1": 0.379599,
            "f1_weighted": 0.52218
          },
          {
            "accuracy": 0.586538,
            "f1": 0.46982,
            "f1_weighted": 0.655198
          },
          {
            "accuracy": 0.519231,
            "f1": 0.358436,
            "f1_weighted": 0.566825
          },
          {
            "accuracy": 0.471154,
            "f1": 0.357338,
            "f1_weighted": 0.529515
          },
          {
            "accuracy": 0.615385,
            "f1": 0.456657,
            "f1_weighted": 0.653769
          }
        ],
        "main_score": 0.576923,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 13.236542224884033,
  "kg_co2_emissions": 0.00039473382814064816
}