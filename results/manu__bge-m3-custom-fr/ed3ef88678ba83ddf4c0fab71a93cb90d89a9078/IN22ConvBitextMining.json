{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "task_name": "IN22ConvBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.857635,
        "recall": 0.89155,
        "f1": 0.867803,
        "accuracy": 0.89155,
        "main_score": 0.867803,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.13738,
        "recall": 0.190951,
        "f1": 0.14942,
        "accuracy": 0.190951,
        "main_score": 0.14942,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.628247,
        "recall": 0.697937,
        "f1": 0.648388,
        "accuracy": 0.697937,
        "main_score": 0.648388,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.81028,
        "recall": 0.850965,
        "f1": 0.821898,
        "accuracy": 0.850965,
        "main_score": 0.821898,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.491242,
        "recall": 0.568862,
        "f1": 0.512475,
        "accuracy": 0.568862,
        "main_score": 0.512475,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.848448,
        "recall": 0.88157,
        "f1": 0.858008,
        "accuracy": 0.88157,
        "main_score": 0.858008,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.848425,
        "recall": 0.884232,
        "f1": 0.859405,
        "accuracy": 0.884232,
        "main_score": 0.859405,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.750479,
        "recall": 0.801065,
        "f1": 0.765281,
        "accuracy": 0.801065,
        "main_score": 0.765281,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.42494,
        "recall": 0.509647,
        "f1": 0.448149,
        "accuracy": 0.509647,
        "main_score": 0.448149,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.817083,
        "recall": 0.856287,
        "f1": 0.828681,
        "accuracy": 0.856287,
        "main_score": 0.828681,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.798841,
        "recall": 0.842981,
        "f1": 0.811886,
        "accuracy": 0.842981,
        "main_score": 0.811886,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.839938,
        "recall": 0.877578,
        "f1": 0.850988,
        "accuracy": 0.877578,
        "main_score": 0.850988,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002344,
        "recall": 0.007319,
        "f1": 0.002588,
        "accuracy": 0.007319,
        "main_score": 0.002588,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.864427,
        "recall": 0.893546,
        "f1": 0.873177,
        "accuracy": 0.893546,
        "main_score": 0.873177,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.857064,
        "recall": 0.89155,
        "f1": 0.867447,
        "accuracy": 0.89155,
        "main_score": 0.867447,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.819413,
        "recall": 0.860945,
        "f1": 0.831884,
        "accuracy": 0.860945,
        "main_score": 0.831884,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.70788,
        "recall": 0.768463,
        "f1": 0.725736,
        "accuracy": 0.768463,
        "main_score": 0.725736,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001453,
        "recall": 0.005988,
        "f1": 0.001869,
        "accuracy": 0.005988,
        "main_score": 0.001869,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.476769,
        "recall": 0.564205,
        "f1": 0.500649,
        "accuracy": 0.564205,
        "main_score": 0.500649,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.729508,
        "recall": 0.78177,
        "f1": 0.745221,
        "accuracy": 0.78177,
        "main_score": 0.745221,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.808412,
        "recall": 0.848969,
        "f1": 0.820161,
        "accuracy": 0.848969,
        "main_score": 0.820161,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.856498,
        "recall": 0.888224,
        "f1": 0.865992,
        "accuracy": 0.888224,
        "main_score": 0.865992,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.828857,
        "recall": 0.870925,
        "f1": 0.841431,
        "accuracy": 0.870925,
        "main_score": 0.841431,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.125398,
        "recall": 0.184963,
        "f1": 0.138736,
        "accuracy": 0.184963,
        "main_score": 0.138736,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.675269,
        "recall": 0.745176,
        "f1": 0.695628,
        "accuracy": 0.745176,
        "main_score": 0.695628,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.912237,
        "recall": 0.934797,
        "f1": 0.918907,
        "accuracy": 0.934797,
        "main_score": 0.918907,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.526803,
        "recall": 0.61477,
        "f1": 0.550659,
        "accuracy": 0.61477,
        "main_score": 0.550659,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.903249,
        "recall": 0.925482,
        "f1": 0.910037,
        "accuracy": 0.925482,
        "main_score": 0.910037,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.919716,
        "recall": 0.940785,
        "f1": 0.926205,
        "accuracy": 0.940785,
        "main_score": 0.926205,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.812858,
        "recall": 0.856287,
        "f1": 0.826007,
        "accuracy": 0.856287,
        "main_score": 0.826007,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.452376,
        "recall": 0.545576,
        "f1": 0.478165,
        "accuracy": 0.545576,
        "main_score": 0.478165,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.839722,
        "recall": 0.875582,
        "f1": 0.8506,
        "accuracy": 0.875582,
        "main_score": 0.8506,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.877628,
        "recall": 0.906853,
        "f1": 0.886619,
        "accuracy": 0.906853,
        "main_score": 0.886619,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.895121,
        "recall": 0.922156,
        "f1": 0.903251,
        "accuracy": 0.922156,
        "main_score": 0.903251,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001207,
        "recall": 0.005323,
        "f1": 0.001458,
        "accuracy": 0.005323,
        "main_score": 0.001458,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.897727,
        "recall": 0.922821,
        "f1": 0.905411,
        "accuracy": 0.922821,
        "main_score": 0.905411,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.90774,
        "recall": 0.93147,
        "f1": 0.915258,
        "accuracy": 0.93147,
        "main_score": 0.915258,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.871585,
        "recall": 0.903526,
        "f1": 0.881433,
        "accuracy": 0.903526,
        "main_score": 0.881433,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.7446,
        "recall": 0.803726,
        "f1": 0.762062,
        "accuracy": 0.803726,
        "main_score": 0.762062,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001078,
        "recall": 0.003992,
        "f1": 0.001259,
        "accuracy": 0.003992,
        "main_score": 0.001259,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.514764,
        "recall": 0.600798,
        "f1": 0.538193,
        "accuracy": 0.600798,
        "main_score": 0.538193,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.81375,
        "recall": 0.854957,
        "f1": 0.826281,
        "accuracy": 0.854957,
        "main_score": 0.826281,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.87984,
        "recall": 0.91018,
        "f1": 0.88931,
        "accuracy": 0.91018,
        "main_score": 0.88931,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.909847,
        "recall": 0.930805,
        "f1": 0.916336,
        "accuracy": 0.930805,
        "main_score": 0.916336,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.147085,
        "recall": 0.183633,
        "f1": 0.156013,
        "accuracy": 0.183633,
        "main_score": 0.156013,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.139912,
        "recall": 0.184963,
        "f1": 0.150299,
        "accuracy": 0.184963,
        "main_score": 0.150299,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.171285,
        "recall": 0.212242,
        "f1": 0.181138,
        "accuracy": 0.212242,
        "main_score": 0.181138,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.115885,
        "recall": 0.144378,
        "f1": 0.12214,
        "accuracy": 0.144378,
        "main_score": 0.12214,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.171409,
        "recall": 0.203593,
        "f1": 0.179445,
        "accuracy": 0.203593,
        "main_score": 0.179445,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.14951,
        "recall": 0.18829,
        "f1": 0.158859,
        "accuracy": 0.18829,
        "main_score": 0.158859,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.181237,
        "recall": 0.228876,
        "f1": 0.192409,
        "accuracy": 0.228876,
        "main_score": 0.192409,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.143609,
        "recall": 0.176979,
        "f1": 0.151657,
        "accuracy": 0.176979,
        "main_score": 0.151657,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.144945,
        "recall": 0.187625,
        "f1": 0.155144,
        "accuracy": 0.187625,
        "main_score": 0.155144,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.164597,
        "recall": 0.207585,
        "f1": 0.175079,
        "accuracy": 0.207585,
        "main_score": 0.175079,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.144122,
        "recall": 0.185629,
        "f1": 0.153427,
        "accuracy": 0.185629,
        "main_score": 0.153427,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.150543,
        "recall": 0.196274,
        "f1": 0.161627,
        "accuracy": 0.196274,
        "main_score": 0.161627,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003635,
        "recall": 0.010645,
        "f1": 0.004216,
        "accuracy": 0.010645,
        "main_score": 0.004216,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.155044,
        "recall": 0.202927,
        "f1": 0.166469,
        "accuracy": 0.202927,
        "main_score": 0.166469,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.13957,
        "recall": 0.18829,
        "f1": 0.150625,
        "accuracy": 0.18829,
        "main_score": 0.150625,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.147512,
        "recall": 0.192947,
        "f1": 0.158022,
        "accuracy": 0.192947,
        "main_score": 0.158022,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.129914,
        "recall": 0.173653,
        "f1": 0.139423,
        "accuracy": 0.173653,
        "main_score": 0.139423,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.003353,
        "recall": 0.011311,
        "f1": 0.004017,
        "accuracy": 0.011311,
        "main_score": 0.004017,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.174892,
        "recall": 0.220892,
        "f1": 0.186085,
        "accuracy": 0.220892,
        "main_score": 0.186085,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.136767,
        "recall": 0.183633,
        "f1": 0.147104,
        "accuracy": 0.183633,
        "main_score": 0.147104,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.139967,
        "recall": 0.179641,
        "f1": 0.149444,
        "accuracy": 0.179641,
        "main_score": 0.149444,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.143553,
        "recall": 0.182302,
        "f1": 0.152489,
        "accuracy": 0.182302,
        "main_score": 0.152489,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.624234,
        "recall": 0.689953,
        "f1": 0.642597,
        "accuracy": 0.689953,
        "main_score": 0.642597,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.685491,
        "recall": 0.745842,
        "f1": 0.702889,
        "accuracy": 0.745842,
        "main_score": 0.702889,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.157373,
        "recall": 0.217565,
        "f1": 0.170628,
        "accuracy": 0.217565,
        "main_score": 0.170628,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.65174,
        "recall": 0.71191,
        "f1": 0.667992,
        "accuracy": 0.71191,
        "main_score": 0.667992,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.439401,
        "recall": 0.513639,
        "f1": 0.459388,
        "accuracy": 0.513639,
        "main_score": 0.459388,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.68566,
        "recall": 0.745176,
        "f1": 0.702211,
        "accuracy": 0.745176,
        "main_score": 0.702211,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.719515,
        "recall": 0.774451,
        "f1": 0.735024,
        "accuracy": 0.774451,
        "main_score": 0.735024,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.614596,
        "recall": 0.680639,
        "f1": 0.633745,
        "accuracy": 0.680639,
        "main_score": 0.633745,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.386893,
        "recall": 0.470393,
        "f1": 0.40917,
        "accuracy": 0.470393,
        "main_score": 0.40917,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.695543,
        "recall": 0.757818,
        "f1": 0.713349,
        "accuracy": 0.757818,
        "main_score": 0.713349,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.642502,
        "recall": 0.710579,
        "f1": 0.661695,
        "accuracy": 0.710579,
        "main_score": 0.661695,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.687611,
        "recall": 0.746507,
        "f1": 0.704297,
        "accuracy": 0.746507,
        "main_score": 0.704297,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003205,
        "recall": 0.009315,
        "f1": 0.00357,
        "accuracy": 0.009315,
        "main_score": 0.00357,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.708318,
        "recall": 0.76314,
        "f1": 0.723998,
        "accuracy": 0.76314,
        "main_score": 0.723998,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.681489,
        "recall": 0.744511,
        "f1": 0.699563,
        "accuracy": 0.744511,
        "main_score": 0.699563,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.694504,
        "recall": 0.752495,
        "f1": 0.710904,
        "accuracy": 0.752495,
        "main_score": 0.710904,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.550053,
        "recall": 0.62475,
        "f1": 0.570486,
        "accuracy": 0.62475,
        "main_score": 0.570486,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00037,
        "recall": 0.004657,
        "f1": 0.000644,
        "accuracy": 0.004657,
        "main_score": 0.000644,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.499083,
        "recall": 0.57352,
        "f1": 0.520009,
        "accuracy": 0.57352,
        "main_score": 0.520009,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.593604,
        "recall": 0.659348,
        "f1": 0.612614,
        "accuracy": 0.659348,
        "main_score": 0.612614,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.65173,
        "recall": 0.715236,
        "f1": 0.669393,
        "accuracy": 0.715236,
        "main_score": 0.669393,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.728445,
        "recall": 0.781104,
        "f1": 0.743368,
        "accuracy": 0.781104,
        "main_score": 0.743368,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.82059,
        "recall": 0.862941,
        "f1": 0.832988,
        "accuracy": 0.862941,
        "main_score": 0.832988,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.91314,
        "recall": 0.933466,
        "f1": 0.919182,
        "accuracy": 0.933466,
        "main_score": 0.919182,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.129723,
        "recall": 0.196274,
        "f1": 0.143829,
        "accuracy": 0.196274,
        "main_score": 0.143829,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.667177,
        "recall": 0.739854,
        "f1": 0.688326,
        "accuracy": 0.739854,
        "main_score": 0.688326,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.494918,
        "recall": 0.588822,
        "f1": 0.51995,
        "accuracy": 0.588822,
        "main_score": 0.51995,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.920388,
        "recall": 0.940785,
        "f1": 0.92646,
        "accuracy": 0.940785,
        "main_score": 0.92646,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.929519,
        "recall": 0.947438,
        "f1": 0.934753,
        "accuracy": 0.947438,
        "main_score": 0.934753,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.83043,
        "recall": 0.869594,
        "f1": 0.841769,
        "accuracy": 0.869594,
        "main_score": 0.841769,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.406842,
        "recall": 0.506986,
        "f1": 0.432598,
        "accuracy": 0.506986,
        "main_score": 0.432598,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.842643,
        "recall": 0.874917,
        "f1": 0.85213,
        "accuracy": 0.874917,
        "main_score": 0.85213,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.909366,
        "recall": 0.932801,
        "f1": 0.91657,
        "accuracy": 0.932801,
        "main_score": 0.91657,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.899581,
        "recall": 0.924817,
        "f1": 0.907165,
        "accuracy": 0.924817,
        "main_score": 0.907165,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00112,
        "recall": 0.003992,
        "f1": 0.001353,
        "accuracy": 0.003992,
        "main_score": 0.001353,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.919357,
        "recall": 0.939454,
        "f1": 0.925307,
        "accuracy": 0.939454,
        "main_score": 0.925307,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.905073,
        "recall": 0.930805,
        "f1": 0.912824,
        "accuracy": 0.930805,
        "main_score": 0.912824,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.88065,
        "recall": 0.91151,
        "f1": 0.889885,
        "accuracy": 0.91151,
        "main_score": 0.889885,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.728462,
        "recall": 0.790419,
        "f1": 0.746414,
        "accuracy": 0.790419,
        "main_score": 0.746414,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001177,
        "recall": 0.004657,
        "f1": 0.001494,
        "accuracy": 0.004657,
        "main_score": 0.001494,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.482195,
        "recall": 0.568862,
        "f1": 0.505706,
        "accuracy": 0.568862,
        "main_score": 0.505706,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.838163,
        "recall": 0.874917,
        "f1": 0.849272,
        "accuracy": 0.874917,
        "main_score": 0.849272,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.90426,
        "recall": 0.926148,
        "f1": 0.910882,
        "accuracy": 0.926148,
        "main_score": 0.910882,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.938922,
        "recall": 0.954757,
        "f1": 0.943725,
        "accuracy": 0.954757,
        "main_score": 0.943725,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.526597,
        "recall": 0.60346,
        "f1": 0.547879,
        "accuracy": 0.60346,
        "main_score": 0.547879,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.556388,
        "recall": 0.62475,
        "f1": 0.574924,
        "accuracy": 0.62475,
        "main_score": 0.574924,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.155094,
        "recall": 0.209581,
        "f1": 0.167892,
        "accuracy": 0.209581,
        "main_score": 0.167892,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.474056,
        "recall": 0.550233,
        "f1": 0.495314,
        "accuracy": 0.550233,
        "main_score": 0.495314,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.515089,
        "recall": 0.574185,
        "f1": 0.531311,
        "accuracy": 0.574185,
        "main_score": 0.531311,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.579793,
        "recall": 0.642049,
        "f1": 0.596438,
        "accuracy": 0.642049,
        "main_score": 0.596438,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.597699,
        "recall": 0.665336,
        "f1": 0.616202,
        "accuracy": 0.665336,
        "main_score": 0.616202,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.535844,
        "recall": 0.598137,
        "f1": 0.553103,
        "accuracy": 0.598137,
        "main_score": 0.553103,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.332539,
        "recall": 0.40652,
        "f1": 0.352211,
        "accuracy": 0.40652,
        "main_score": 0.352211,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.569574,
        "recall": 0.644045,
        "f1": 0.590734,
        "accuracy": 0.644045,
        "main_score": 0.590734,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.557197,
        "recall": 0.628743,
        "f1": 0.576876,
        "accuracy": 0.628743,
        "main_score": 0.576876,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.631967,
        "recall": 0.697272,
        "f1": 0.650415,
        "accuracy": 0.697272,
        "main_score": 0.650415,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003021,
        "recall": 0.008649,
        "f1": 0.003301,
        "accuracy": 0.008649,
        "main_score": 0.003301,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.591049,
        "recall": 0.656021,
        "f1": 0.608813,
        "accuracy": 0.656021,
        "main_score": 0.608813,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.576447,
        "recall": 0.637392,
        "f1": 0.593317,
        "accuracy": 0.637392,
        "main_score": 0.593317,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.543509,
        "recall": 0.616766,
        "f1": 0.563611,
        "accuracy": 0.616766,
        "main_score": 0.563611,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.478011,
        "recall": 0.558882,
        "f1": 0.500044,
        "accuracy": 0.558882,
        "main_score": 0.500044,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000909,
        "recall": 0.003992,
        "f1": 0.001078,
        "accuracy": 0.003992,
        "main_score": 0.001078,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.414937,
        "recall": 0.492349,
        "f1": 0.43652,
        "accuracy": 0.492349,
        "main_score": 0.43652,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.484617,
        "recall": 0.554225,
        "f1": 0.504063,
        "accuracy": 0.554225,
        "main_score": 0.504063,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.553794,
        "recall": 0.619428,
        "f1": 0.572494,
        "accuracy": 0.619428,
        "main_score": 0.572494,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.57408,
        "recall": 0.640053,
        "f1": 0.592461,
        "accuracy": 0.640053,
        "main_score": 0.592461,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.849403,
        "recall": 0.886228,
        "f1": 0.860693,
        "accuracy": 0.886228,
        "main_score": 0.860693,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.916611,
        "recall": 0.938789,
        "f1": 0.923543,
        "accuracy": 0.938789,
        "main_score": 0.923543,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.141805,
        "recall": 0.202927,
        "f1": 0.155451,
        "accuracy": 0.202927,
        "main_score": 0.155451,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.697882,
        "recall": 0.769128,
        "f1": 0.718722,
        "accuracy": 0.769128,
        "main_score": 0.718722,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.91589,
        "recall": 0.936793,
        "f1": 0.922501,
        "accuracy": 0.936793,
        "main_score": 0.922501,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.555167,
        "recall": 0.640053,
        "f1": 0.578555,
        "accuracy": 0.640053,
        "main_score": 0.578555,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.922433,
        "recall": 0.943446,
        "f1": 0.929154,
        "accuracy": 0.943446,
        "main_score": 0.929154,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.822865,
        "recall": 0.866267,
        "f1": 0.835976,
        "accuracy": 0.866267,
        "main_score": 0.835976,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.453274,
        "recall": 0.552894,
        "f1": 0.480346,
        "accuracy": 0.552894,
        "main_score": 0.480346,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.859636,
        "recall": 0.896208,
        "f1": 0.871093,
        "accuracy": 0.896208,
        "main_score": 0.871093,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.88483,
        "recall": 0.914837,
        "f1": 0.893945,
        "accuracy": 0.914837,
        "main_score": 0.893945,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.909803,
        "recall": 0.932136,
        "f1": 0.916722,
        "accuracy": 0.932136,
        "main_score": 0.916722,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002089,
        "recall": 0.005988,
        "f1": 0.002173,
        "accuracy": 0.005988,
        "main_score": 0.002173,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.919661,
        "recall": 0.939454,
        "f1": 0.925837,
        "accuracy": 0.939454,
        "main_score": 0.925837,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.903526,
        "recall": 0.928809,
        "f1": 0.911488,
        "accuracy": 0.928809,
        "main_score": 0.911488,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.903471,
        "recall": 0.929474,
        "f1": 0.911523,
        "accuracy": 0.929474,
        "main_score": 0.911523,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.769456,
        "recall": 0.826347,
        "f1": 0.78643,
        "accuracy": 0.826347,
        "main_score": 0.78643,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001151,
        "recall": 0.005323,
        "f1": 0.001395,
        "accuracy": 0.005323,
        "main_score": 0.001395,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.551513,
        "recall": 0.637392,
        "f1": 0.575075,
        "accuracy": 0.637392,
        "main_score": 0.575075,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.826647,
        "recall": 0.869594,
        "f1": 0.840009,
        "accuracy": 0.869594,
        "main_score": 0.840009,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.886361,
        "recall": 0.915502,
        "f1": 0.895599,
        "accuracy": 0.915502,
        "main_score": 0.895599,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.929253,
        "recall": 0.945442,
        "f1": 0.934433,
        "accuracy": 0.945442,
        "main_score": 0.934433,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.841779,
        "recall": 0.88024,
        "f1": 0.85318,
        "accuracy": 0.88024,
        "main_score": 0.85318,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.920182,
        "recall": 0.940785,
        "f1": 0.926436,
        "accuracy": 0.940785,
        "main_score": 0.926436,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.154912,
        "recall": 0.220226,
        "f1": 0.168713,
        "accuracy": 0.220226,
        "main_score": 0.168713,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.704729,
        "recall": 0.77179,
        "f1": 0.724317,
        "accuracy": 0.77179,
        "main_score": 0.724317,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.926092,
        "recall": 0.946108,
        "f1": 0.932402,
        "accuracy": 0.946108,
        "main_score": 0.932402,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.553032,
        "recall": 0.636727,
        "f1": 0.575629,
        "accuracy": 0.636727,
        "main_score": 0.575629,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.909493,
        "recall": 0.932136,
        "f1": 0.916105,
        "accuracy": 0.932136,
        "main_score": 0.916105,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.835451,
        "recall": 0.874251,
        "f1": 0.847122,
        "accuracy": 0.874251,
        "main_score": 0.847122,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.465425,
        "recall": 0.564205,
        "f1": 0.492247,
        "accuracy": 0.564205,
        "main_score": 0.492247,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.848661,
        "recall": 0.883566,
        "f1": 0.859239,
        "accuracy": 0.883566,
        "main_score": 0.859239,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.875316,
        "recall": 0.906188,
        "f1": 0.884742,
        "accuracy": 0.906188,
        "main_score": 0.884742,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.906582,
        "recall": 0.928809,
        "f1": 0.913077,
        "accuracy": 0.928809,
        "main_score": 0.913077,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002079,
        "recall": 0.005323,
        "f1": 0.002151,
        "accuracy": 0.005323,
        "main_score": 0.002151,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.89542,
        "recall": 0.918829,
        "f1": 0.902275,
        "accuracy": 0.918829,
        "main_score": 0.902275,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.893901,
        "recall": 0.92016,
        "f1": 0.902031,
        "accuracy": 0.92016,
        "main_score": 0.902031,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.896968,
        "recall": 0.924152,
        "f1": 0.905169,
        "accuracy": 0.924152,
        "main_score": 0.905169,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.730669,
        "recall": 0.793746,
        "f1": 0.749588,
        "accuracy": 0.793746,
        "main_score": 0.749588,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001226,
        "recall": 0.004657,
        "f1": 0.001509,
        "accuracy": 0.004657,
        "main_score": 0.001509,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.557363,
        "recall": 0.636727,
        "f1": 0.579021,
        "accuracy": 0.636727,
        "main_score": 0.579021,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.8308,
        "recall": 0.870259,
        "f1": 0.842807,
        "accuracy": 0.870259,
        "main_score": 0.842807,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.896103,
        "recall": 0.919494,
        "f1": 0.903471,
        "accuracy": 0.919494,
        "main_score": 0.903471,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.92648,
        "recall": 0.944777,
        "f1": 0.932091,
        "accuracy": 0.944777,
        "main_score": 0.932091,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.751013,
        "recall": 0.804391,
        "f1": 0.766829,
        "accuracy": 0.804391,
        "main_score": 0.766829,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.838124,
        "recall": 0.874917,
        "f1": 0.849447,
        "accuracy": 0.874917,
        "main_score": 0.849447,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.123982,
        "recall": 0.182967,
        "f1": 0.137014,
        "accuracy": 0.182967,
        "main_score": 0.137014,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.615643,
        "recall": 0.690619,
        "f1": 0.637043,
        "accuracy": 0.690619,
        "main_score": 0.637043,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.835253,
        "recall": 0.865602,
        "f1": 0.84417,
        "accuracy": 0.865602,
        "main_score": 0.84417,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.492407,
        "recall": 0.580173,
        "f1": 0.516045,
        "accuracy": 0.580173,
        "main_score": 0.516045,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.831748,
        "recall": 0.865602,
        "f1": 0.841698,
        "accuracy": 0.865602,
        "main_score": 0.841698,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.86052,
        "recall": 0.892216,
        "f1": 0.87006,
        "accuracy": 0.892216,
        "main_score": 0.87006,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.394556,
        "recall": 0.485695,
        "f1": 0.418331,
        "accuracy": 0.485695,
        "main_score": 0.418331,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.775223,
        "recall": 0.822355,
        "f1": 0.789413,
        "accuracy": 0.822355,
        "main_score": 0.789413,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.82535,
        "recall": 0.862275,
        "f1": 0.836353,
        "accuracy": 0.862275,
        "main_score": 0.836353,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.830106,
        "recall": 0.869594,
        "f1": 0.842315,
        "accuracy": 0.869594,
        "main_score": 0.842315,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001366,
        "recall": 0.004657,
        "f1": 0.0014,
        "accuracy": 0.004657,
        "main_score": 0.0014,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.839843,
        "recall": 0.876248,
        "f1": 0.850901,
        "accuracy": 0.876248,
        "main_score": 0.850901,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.833588,
        "recall": 0.870925,
        "f1": 0.844888,
        "accuracy": 0.870925,
        "main_score": 0.844888,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.801968,
        "recall": 0.848969,
        "f1": 0.816217,
        "accuracy": 0.848969,
        "main_score": 0.816217,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.674892,
        "recall": 0.745176,
        "f1": 0.695714,
        "accuracy": 0.745176,
        "main_score": 0.695714,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001057,
        "recall": 0.005323,
        "f1": 0.001339,
        "accuracy": 0.005323,
        "main_score": 0.001339,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.469458,
        "recall": 0.561544,
        "f1": 0.495195,
        "accuracy": 0.561544,
        "main_score": 0.495195,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.801719,
        "recall": 0.844977,
        "f1": 0.815027,
        "accuracy": 0.844977,
        "main_score": 0.815027,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.851985,
        "recall": 0.884897,
        "f1": 0.861898,
        "accuracy": 0.884897,
        "main_score": 0.861898,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.8361,
        "recall": 0.870925,
        "f1": 0.8465,
        "accuracy": 0.870925,
        "main_score": 0.8465,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.453183,
        "recall": 0.529607,
        "f1": 0.473501,
        "accuracy": 0.529607,
        "main_score": 0.473501,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.483627,
        "recall": 0.551564,
        "f1": 0.501576,
        "accuracy": 0.551564,
        "main_score": 0.501576,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.12832,
        "recall": 0.176314,
        "f1": 0.139032,
        "accuracy": 0.176314,
        "main_score": 0.139032,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.395259,
        "recall": 0.467066,
        "f1": 0.414631,
        "accuracy": 0.467066,
        "main_score": 0.414631,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.390925,
        "recall": 0.457086,
        "f1": 0.407532,
        "accuracy": 0.457086,
        "main_score": 0.407532,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.313572,
        "recall": 0.379907,
        "f1": 0.3313,
        "accuracy": 0.379907,
        "main_score": 0.3313,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.474189,
        "recall": 0.54491,
        "f1": 0.49227,
        "accuracy": 0.54491,
        "main_score": 0.49227,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.477824,
        "recall": 0.552894,
        "f1": 0.497688,
        "accuracy": 0.552894,
        "main_score": 0.497688,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.41399,
        "recall": 0.479042,
        "f1": 0.431034,
        "accuracy": 0.479042,
        "main_score": 0.431034,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.469479,
        "recall": 0.540918,
        "f1": 0.488971,
        "accuracy": 0.540918,
        "main_score": 0.488971,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.428633,
        "recall": 0.499667,
        "f1": 0.447164,
        "accuracy": 0.499667,
        "main_score": 0.447164,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.465273,
        "recall": 0.532269,
        "f1": 0.482824,
        "accuracy": 0.532269,
        "main_score": 0.482824,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001946,
        "recall": 0.007319,
        "f1": 0.002285,
        "accuracy": 0.007319,
        "main_score": 0.002285,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.504676,
        "recall": 0.572854,
        "f1": 0.522865,
        "accuracy": 0.572854,
        "main_score": 0.522865,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.461574,
        "recall": 0.539587,
        "f1": 0.482568,
        "accuracy": 0.539587,
        "main_score": 0.482568,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.488865,
        "recall": 0.566201,
        "f1": 0.509655,
        "accuracy": 0.566201,
        "main_score": 0.509655,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.383231,
        "recall": 0.455755,
        "f1": 0.402494,
        "accuracy": 0.455755,
        "main_score": 0.402494,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001757,
        "recall": 0.008649,
        "f1": 0.002385,
        "accuracy": 0.008649,
        "main_score": 0.002385,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.355483,
        "recall": 0.432468,
        "f1": 0.376732,
        "accuracy": 0.432468,
        "main_score": 0.376732,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.389187,
        "recall": 0.463074,
        "f1": 0.408957,
        "accuracy": 0.463074,
        "main_score": 0.408957,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.430983,
        "recall": 0.500998,
        "f1": 0.44891,
        "accuracy": 0.500998,
        "main_score": 0.44891,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.529865,
        "recall": 0.596141,
        "f1": 0.547475,
        "accuracy": 0.596141,
        "main_score": 0.547475,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.792604,
        "recall": 0.840985,
        "f1": 0.807076,
        "accuracy": 0.840985,
        "main_score": 0.807076,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.848045,
        "recall": 0.884897,
        "f1": 0.859126,
        "accuracy": 0.884897,
        "main_score": 0.859126,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.144284,
        "recall": 0.206254,
        "f1": 0.157664,
        "accuracy": 0.206254,
        "main_score": 0.157664,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.690525,
        "recall": 0.759148,
        "f1": 0.710521,
        "accuracy": 0.759148,
        "main_score": 0.710521,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.832308,
        "recall": 0.867598,
        "f1": 0.842444,
        "accuracy": 0.867598,
        "main_score": 0.842444,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.545788,
        "recall": 0.621424,
        "f1": 0.565872,
        "accuracy": 0.621424,
        "main_score": 0.565872,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.853804,
        "recall": 0.889554,
        "f1": 0.864417,
        "accuracy": 0.889554,
        "main_score": 0.864417,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.859548,
        "recall": 0.892881,
        "f1": 0.86974,
        "accuracy": 0.892881,
        "main_score": 0.86974,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.754929,
        "recall": 0.803061,
        "f1": 0.768992,
        "accuracy": 0.803061,
        "main_score": 0.768992,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.446029,
        "recall": 0.538922,
        "f1": 0.4707,
        "accuracy": 0.538922,
        "main_score": 0.4707,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.80432,
        "recall": 0.848969,
        "f1": 0.817224,
        "accuracy": 0.848969,
        "main_score": 0.817224,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.848425,
        "recall": 0.882901,
        "f1": 0.858616,
        "accuracy": 0.882901,
        "main_score": 0.858616,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002113,
        "recall": 0.005323,
        "f1": 0.002206,
        "accuracy": 0.005323,
        "main_score": 0.002206,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.876225,
        "recall": 0.903526,
        "f1": 0.884431,
        "accuracy": 0.903526,
        "main_score": 0.884431,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.842138,
        "recall": 0.88024,
        "f1": 0.853572,
        "accuracy": 0.88024,
        "main_score": 0.853572,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.850654,
        "recall": 0.884897,
        "f1": 0.861201,
        "accuracy": 0.884897,
        "main_score": 0.861201,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.710457,
        "recall": 0.775782,
        "f1": 0.729932,
        "accuracy": 0.775782,
        "main_score": 0.729932,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001086,
        "recall": 0.006653,
        "f1": 0.001401,
        "accuracy": 0.006653,
        "main_score": 0.001401,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.536341,
        "recall": 0.620093,
        "f1": 0.559709,
        "accuracy": 0.620093,
        "main_score": 0.559709,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.735856,
        "recall": 0.788423,
        "f1": 0.751547,
        "accuracy": 0.788423,
        "main_score": 0.751547,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.812999,
        "recall": 0.85163,
        "f1": 0.824309,
        "accuracy": 0.85163,
        "main_score": 0.824309,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.878173,
        "recall": 0.905522,
        "f1": 0.886383,
        "accuracy": 0.905522,
        "main_score": 0.886383,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.793231,
        "recall": 0.844311,
        "f1": 0.808326,
        "accuracy": 0.844311,
        "main_score": 0.808326,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.886456,
        "recall": 0.914172,
        "f1": 0.895021,
        "accuracy": 0.914172,
        "main_score": 0.895021,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.131754,
        "recall": 0.185629,
        "f1": 0.144085,
        "accuracy": 0.185629,
        "main_score": 0.144085,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.646634,
        "recall": 0.72189,
        "f1": 0.668191,
        "accuracy": 0.72189,
        "main_score": 0.668191,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.903637,
        "recall": 0.927478,
        "f1": 0.911035,
        "accuracy": 0.927478,
        "main_score": 0.911035,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.503569,
        "recall": 0.59481,
        "f1": 0.528531,
        "accuracy": 0.59481,
        "main_score": 0.528531,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.88534,
        "recall": 0.912841,
        "f1": 0.893714,
        "accuracy": 0.912841,
        "main_score": 0.893714,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.888079,
        "recall": 0.916168,
        "f1": 0.896619,
        "accuracy": 0.916168,
        "main_score": 0.896619,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.82312,
        "recall": 0.865602,
        "f1": 0.836153,
        "accuracy": 0.865602,
        "main_score": 0.836153,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.419968,
        "recall": 0.520293,
        "f1": 0.446209,
        "accuracy": 0.520293,
        "main_score": 0.446209,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.812279,
        "recall": 0.853626,
        "f1": 0.824975,
        "accuracy": 0.853626,
        "main_score": 0.824975,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.886882,
        "recall": 0.914837,
        "f1": 0.895301,
        "accuracy": 0.914837,
        "main_score": 0.895301,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001925,
        "recall": 0.005988,
        "f1": 0.002221,
        "accuracy": 0.005988,
        "main_score": 0.002221,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.876857,
        "recall": 0.908184,
        "f1": 0.886519,
        "accuracy": 0.908184,
        "main_score": 0.886519,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.880612,
        "recall": 0.909514,
        "f1": 0.889591,
        "accuracy": 0.909514,
        "main_score": 0.889591,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.851936,
        "recall": 0.888889,
        "f1": 0.863231,
        "accuracy": 0.888889,
        "main_score": 0.863231,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.734073,
        "recall": 0.795742,
        "f1": 0.752604,
        "accuracy": 0.795742,
        "main_score": 0.752604,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000822,
        "recall": 0.003992,
        "f1": 0.000957,
        "accuracy": 0.003992,
        "main_score": 0.000957,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.490031,
        "recall": 0.576181,
        "f1": 0.513365,
        "accuracy": 0.576181,
        "main_score": 0.513365,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.82587,
        "recall": 0.867598,
        "f1": 0.838837,
        "accuracy": 0.867598,
        "main_score": 0.838837,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.872262,
        "recall": 0.90153,
        "f1": 0.881293,
        "accuracy": 0.90153,
        "main_score": 0.881293,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.885972,
        "recall": 0.912841,
        "f1": 0.894202,
        "accuracy": 0.912841,
        "main_score": 0.894202,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.828966,
        "recall": 0.870925,
        "f1": 0.841596,
        "accuracy": 0.870925,
        "main_score": 0.841596,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.894029,
        "recall": 0.920825,
        "f1": 0.902406,
        "accuracy": 0.920825,
        "main_score": 0.902406,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.129573,
        "recall": 0.188955,
        "f1": 0.142881,
        "accuracy": 0.188955,
        "main_score": 0.142881,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.680807,
        "recall": 0.750499,
        "f1": 0.701005,
        "accuracy": 0.750499,
        "main_score": 0.701005,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.895753,
        "recall": 0.922156,
        "f1": 0.903761,
        "accuracy": 0.922156,
        "main_score": 0.903761,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.602202,
        "recall": 0.680639,
        "f1": 0.624088,
        "accuracy": 0.680639,
        "main_score": 0.624088,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.912475,
        "recall": 0.934132,
        "f1": 0.919206,
        "accuracy": 0.934132,
        "main_score": 0.919206,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.907574,
        "recall": 0.927478,
        "f1": 0.913883,
        "accuracy": 0.927478,
        "main_score": 0.913883,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.813445,
        "recall": 0.854957,
        "f1": 0.826007,
        "accuracy": 0.854957,
        "main_score": 0.826007,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.437456,
        "recall": 0.528277,
        "f1": 0.461562,
        "accuracy": 0.528277,
        "main_score": 0.461562,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.845187,
        "recall": 0.880905,
        "f1": 0.85642,
        "accuracy": 0.880905,
        "main_score": 0.85642,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.85727,
        "recall": 0.892881,
        "f1": 0.868132,
        "accuracy": 0.892881,
        "main_score": 0.868132,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.002485,
        "recall": 0.006653,
        "f1": 0.002778,
        "accuracy": 0.006653,
        "main_score": 0.002778,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.891572,
        "recall": 0.916833,
        "f1": 0.899236,
        "accuracy": 0.916833,
        "main_score": 0.899236,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.886006,
        "recall": 0.912176,
        "f1": 0.894167,
        "accuracy": 0.912176,
        "main_score": 0.894167,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.881654,
        "recall": 0.908184,
        "f1": 0.889765,
        "accuracy": 0.908184,
        "main_score": 0.889765,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.759282,
        "recall": 0.813706,
        "f1": 0.775323,
        "accuracy": 0.813706,
        "main_score": 0.775323,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000825,
        "recall": 0.005323,
        "f1": 0.00127,
        "accuracy": 0.005323,
        "main_score": 0.00127,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.528426,
        "recall": 0.612774,
        "f1": 0.551865,
        "accuracy": 0.612774,
        "main_score": 0.551865,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.801115,
        "recall": 0.844977,
        "f1": 0.814626,
        "accuracy": 0.844977,
        "main_score": 0.814626,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.861078,
        "recall": 0.892216,
        "f1": 0.870484,
        "accuracy": 0.892216,
        "main_score": 0.870484,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.902306,
        "recall": 0.926148,
        "f1": 0.909581,
        "accuracy": 0.926148,
        "main_score": 0.909581,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001623,
        "recall": 0.005323,
        "f1": 0.001851,
        "accuracy": 0.005323,
        "main_score": 0.001851,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.002184,
        "recall": 0.005988,
        "f1": 0.002331,
        "accuracy": 0.005988,
        "main_score": 0.002331,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.002858,
        "recall": 0.008649,
        "f1": 0.003337,
        "accuracy": 0.008649,
        "main_score": 0.003337,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.00139,
        "recall": 0.004657,
        "f1": 0.001776,
        "accuracy": 0.004657,
        "main_score": 0.001776,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001335,
        "recall": 0.002661,
        "f1": 0.001338,
        "accuracy": 0.002661,
        "main_score": 0.001338,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002056,
        "recall": 0.003992,
        "f1": 0.002111,
        "accuracy": 0.003992,
        "main_score": 0.002111,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.000736,
        "recall": 0.003992,
        "f1": 0.000799,
        "accuracy": 0.003992,
        "main_score": 0.000799,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.002042,
        "recall": 0.003992,
        "f1": 0.002085,
        "accuracy": 0.003992,
        "main_score": 0.002085,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001452,
        "recall": 0.005988,
        "f1": 0.001562,
        "accuracy": 0.005988,
        "main_score": 0.001562,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.002175,
        "recall": 0.006653,
        "f1": 0.00279,
        "accuracy": 0.006653,
        "main_score": 0.00279,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.002668,
        "recall": 0.004657,
        "f1": 0.002674,
        "accuracy": 0.004657,
        "main_score": 0.002674,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.000864,
        "recall": 0.003992,
        "f1": 0.000995,
        "accuracy": 0.003992,
        "main_score": 0.000995,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000753,
        "recall": 0.002661,
        "f1": 0.000822,
        "accuracy": 0.002661,
        "main_score": 0.000822,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002125,
        "recall": 0.004657,
        "f1": 0.002234,
        "accuracy": 0.004657,
        "main_score": 0.002234,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.00239,
        "recall": 0.004657,
        "f1": 0.002555,
        "accuracy": 0.004657,
        "main_score": 0.002555,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.001499,
        "recall": 0.004657,
        "f1": 0.001637,
        "accuracy": 0.004657,
        "main_score": 0.001637,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001756,
        "recall": 0.005988,
        "f1": 0.002023,
        "accuracy": 0.005988,
        "main_score": 0.002023,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.027684,
        "recall": 0.041251,
        "f1": 0.030429,
        "accuracy": 0.041251,
        "main_score": 0.030429,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.002525,
        "recall": 0.007984,
        "f1": 0.003104,
        "accuracy": 0.007984,
        "main_score": 0.003104,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.000899,
        "recall": 0.002661,
        "f1": 0.001022,
        "accuracy": 0.002661,
        "main_score": 0.001022,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001996,
        "f1": 1.2e-05,
        "accuracy": 0.001996,
        "main_score": 1.2e-05,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002083,
        "recall": 0.004657,
        "f1": 0.00216,
        "accuracy": 0.004657,
        "main_score": 0.00216,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.848719,
        "recall": 0.883566,
        "f1": 0.859233,
        "accuracy": 0.883566,
        "main_score": 0.859233,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.906548,
        "recall": 0.93014,
        "f1": 0.913898,
        "accuracy": 0.93014,
        "main_score": 0.913898,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.14889,
        "recall": 0.207585,
        "f1": 0.161481,
        "accuracy": 0.207585,
        "main_score": 0.161481,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.710696,
        "recall": 0.775116,
        "f1": 0.729634,
        "accuracy": 0.775116,
        "main_score": 0.729634,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.919428,
        "recall": 0.937458,
        "f1": 0.924773,
        "accuracy": 0.937458,
        "main_score": 0.924773,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.5576,
        "recall": 0.634731,
        "f1": 0.578052,
        "accuracy": 0.634731,
        "main_score": 0.578052,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.91222,
        "recall": 0.930805,
        "f1": 0.91792,
        "accuracy": 0.930805,
        "main_score": 0.91792,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.892692,
        "recall": 0.919494,
        "f1": 0.900776,
        "accuracy": 0.919494,
        "main_score": 0.900776,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.815558,
        "recall": 0.858949,
        "f1": 0.828679,
        "accuracy": 0.858949,
        "main_score": 0.828679,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.460289,
        "recall": 0.550233,
        "f1": 0.484313,
        "accuracy": 0.550233,
        "main_score": 0.484313,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.884686,
        "recall": 0.91018,
        "f1": 0.892371,
        "accuracy": 0.91018,
        "main_score": 0.892371,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.873137,
        "recall": 0.902861,
        "f1": 0.882063,
        "accuracy": 0.902861,
        "main_score": 0.882063,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.9056,
        "recall": 0.928144,
        "f1": 0.912641,
        "accuracy": 0.928144,
        "main_score": 0.912641,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002761,
        "recall": 0.006653,
        "f1": 0.00285,
        "accuracy": 0.006653,
        "main_score": 0.00285,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.891927,
        "recall": 0.917498,
        "f1": 0.899956,
        "accuracy": 0.917498,
        "main_score": 0.899956,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.885551,
        "recall": 0.91151,
        "f1": 0.893128,
        "accuracy": 0.91151,
        "main_score": 0.893128,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.776255,
        "recall": 0.827678,
        "f1": 0.791407,
        "accuracy": 0.827678,
        "main_score": 0.791407,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00094,
        "recall": 0.004657,
        "f1": 0.001159,
        "accuracy": 0.004657,
        "main_score": 0.001159,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.536538,
        "recall": 0.617432,
        "f1": 0.558958,
        "accuracy": 0.617432,
        "main_score": 0.558958,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.800665,
        "recall": 0.845642,
        "f1": 0.814473,
        "accuracy": 0.845642,
        "main_score": 0.814473,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.879264,
        "recall": 0.906188,
        "f1": 0.887615,
        "accuracy": 0.906188,
        "main_score": 0.887615,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.918241,
        "recall": 0.938124,
        "f1": 0.924396,
        "accuracy": 0.938124,
        "main_score": 0.924396,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.85906,
        "recall": 0.894877,
        "f1": 0.869882,
        "accuracy": 0.894877,
        "main_score": 0.869882,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.910956,
        "recall": 0.934797,
        "f1": 0.918585,
        "accuracy": 0.934797,
        "main_score": 0.918585,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.128537,
        "recall": 0.187625,
        "f1": 0.141836,
        "accuracy": 0.187625,
        "main_score": 0.141836,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.701974,
        "recall": 0.766467,
        "f1": 0.721251,
        "accuracy": 0.766467,
        "main_score": 0.721251,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.90906,
        "recall": 0.932801,
        "f1": 0.916323,
        "accuracy": 0.932801,
        "main_score": 0.916323,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.536982,
        "recall": 0.619428,
        "f1": 0.559358,
        "accuracy": 0.619428,
        "main_score": 0.559358,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.911255,
        "recall": 0.935462,
        "f1": 0.918607,
        "accuracy": 0.935462,
        "main_score": 0.918607,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.909736,
        "recall": 0.93014,
        "f1": 0.916012,
        "accuracy": 0.93014,
        "main_score": 0.916012,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.818081,
        "recall": 0.858949,
        "f1": 0.830402,
        "accuracy": 0.858949,
        "main_score": 0.830402,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.449554,
        "recall": 0.54491,
        "f1": 0.4758,
        "accuracy": 0.54491,
        "main_score": 0.4758,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.848536,
        "recall": 0.885562,
        "f1": 0.859991,
        "accuracy": 0.885562,
        "main_score": 0.859991,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.881637,
        "recall": 0.91018,
        "f1": 0.890419,
        "accuracy": 0.91018,
        "main_score": 0.890419,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.899396,
        "recall": 0.924817,
        "f1": 0.907152,
        "accuracy": 0.924817,
        "main_score": 0.907152,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002352,
        "recall": 0.006653,
        "f1": 0.002607,
        "accuracy": 0.006653,
        "main_score": 0.002607,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.908916,
        "recall": 0.929474,
        "f1": 0.915005,
        "accuracy": 0.929474,
        "main_score": 0.915005,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.879253,
        "recall": 0.910845,
        "f1": 0.8888,
        "accuracy": 0.910845,
        "main_score": 0.8888,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.75751,
        "recall": 0.814371,
        "f1": 0.774007,
        "accuracy": 0.814371,
        "main_score": 0.774007,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001359,
        "recall": 0.005323,
        "f1": 0.001723,
        "accuracy": 0.005323,
        "main_score": 0.001723,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.501209,
        "recall": 0.586161,
        "f1": 0.524572,
        "accuracy": 0.586161,
        "main_score": 0.524572,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.811677,
        "recall": 0.85163,
        "f1": 0.824373,
        "accuracy": 0.85163,
        "main_score": 0.824373,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.87627,
        "recall": 0.904857,
        "f1": 0.884954,
        "accuracy": 0.904857,
        "main_score": 0.884954,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.919938,
        "recall": 0.94012,
        "f1": 0.926236,
        "accuracy": 0.94012,
        "main_score": 0.926236,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.832065,
        "recall": 0.870259,
        "f1": 0.843912,
        "accuracy": 0.870259,
        "main_score": 0.843912,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.891745,
        "recall": 0.916833,
        "f1": 0.89939,
        "accuracy": 0.916833,
        "main_score": 0.89939,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.135164,
        "recall": 0.194278,
        "f1": 0.148698,
        "accuracy": 0.194278,
        "main_score": 0.148698,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.706536,
        "recall": 0.769794,
        "f1": 0.724865,
        "accuracy": 0.769794,
        "main_score": 0.724865,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.89165,
        "recall": 0.918829,
        "f1": 0.9,
        "accuracy": 0.918829,
        "main_score": 0.9,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.519732,
        "recall": 0.606121,
        "f1": 0.543325,
        "accuracy": 0.606121,
        "main_score": 0.543325,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.910224,
        "recall": 0.930805,
        "f1": 0.916367,
        "accuracy": 0.930805,
        "main_score": 0.916367,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.915635,
        "recall": 0.938124,
        "f1": 0.922523,
        "accuracy": 0.938124,
        "main_score": 0.922523,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.791129,
        "recall": 0.839654,
        "f1": 0.806067,
        "accuracy": 0.839654,
        "main_score": 0.806067,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.473157,
        "recall": 0.56487,
        "f1": 0.498039,
        "accuracy": 0.56487,
        "main_score": 0.498039,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.859121,
        "recall": 0.892216,
        "f1": 0.869276,
        "accuracy": 0.892216,
        "main_score": 0.869276,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.852983,
        "recall": 0.888224,
        "f1": 0.86372,
        "accuracy": 0.888224,
        "main_score": 0.86372,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.89444,
        "recall": 0.920825,
        "f1": 0.902539,
        "accuracy": 0.920825,
        "main_score": 0.902539,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000715,
        "recall": 0.003992,
        "f1": 0.000762,
        "accuracy": 0.003992,
        "main_score": 0.000762,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.899651,
        "recall": 0.924817,
        "f1": 0.907143,
        "accuracy": 0.924817,
        "main_score": 0.907143,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.891317,
        "recall": 0.918164,
        "f1": 0.899556,
        "accuracy": 0.918164,
        "main_score": 0.899556,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.74138,
        "recall": 0.800399,
        "f1": 0.75891,
        "accuracy": 0.800399,
        "main_score": 0.75891,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001223,
        "recall": 0.005988,
        "f1": 0.001517,
        "accuracy": 0.005988,
        "main_score": 0.001517,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.536454,
        "recall": 0.621424,
        "f1": 0.559946,
        "accuracy": 0.621424,
        "main_score": 0.559946,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.798813,
        "recall": 0.842315,
        "f1": 0.8121,
        "accuracy": 0.842315,
        "main_score": 0.8121,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.865835,
        "recall": 0.896873,
        "f1": 0.875272,
        "accuracy": 0.896873,
        "main_score": 0.875272,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.915879,
        "recall": 0.934797,
        "f1": 0.921579,
        "accuracy": 0.934797,
        "main_score": 0.921579,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.719899,
        "recall": 0.7831,
        "f1": 0.738918,
        "accuracy": 0.7831,
        "main_score": 0.738918,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.768127,
        "recall": 0.817698,
        "f1": 0.782476,
        "accuracy": 0.817698,
        "main_score": 0.782476,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.135854,
        "recall": 0.181637,
        "f1": 0.146105,
        "accuracy": 0.181637,
        "main_score": 0.146105,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.555052,
        "recall": 0.632735,
        "f1": 0.577242,
        "accuracy": 0.632735,
        "main_score": 0.577242,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.707032,
        "recall": 0.759814,
        "f1": 0.721995,
        "accuracy": 0.759814,
        "main_score": 0.721995,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.478551,
        "recall": 0.557552,
        "f1": 0.500093,
        "accuracy": 0.557552,
        "main_score": 0.500093,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.762355,
        "recall": 0.809714,
        "f1": 0.77616,
        "accuracy": 0.809714,
        "main_score": 0.77616,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.770766,
        "recall": 0.815702,
        "f1": 0.783771,
        "accuracy": 0.815702,
        "main_score": 0.783771,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.688329,
        "recall": 0.747838,
        "f1": 0.705116,
        "accuracy": 0.747838,
        "main_score": 0.705116,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.389097,
        "recall": 0.479707,
        "f1": 0.413233,
        "accuracy": 0.479707,
        "main_score": 0.413233,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.745349,
        "recall": 0.795742,
        "f1": 0.760096,
        "accuracy": 0.795742,
        "main_score": 0.760096,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.748904,
        "recall": 0.799734,
        "f1": 0.763603,
        "accuracy": 0.799734,
        "main_score": 0.763603,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.790287,
        "recall": 0.830339,
        "f1": 0.802108,
        "accuracy": 0.830339,
        "main_score": 0.802108,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002335,
        "recall": 0.007319,
        "f1": 0.002841,
        "accuracy": 0.007319,
        "main_score": 0.002841,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.791897,
        "recall": 0.836327,
        "f1": 0.804786,
        "accuracy": 0.836327,
        "main_score": 0.804786,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.775478,
        "recall": 0.822355,
        "f1": 0.789411,
        "accuracy": 0.822355,
        "main_score": 0.789411,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.749929,
        "recall": 0.803061,
        "f1": 0.765263,
        "accuracy": 0.803061,
        "main_score": 0.765263,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000973,
        "recall": 0.004657,
        "f1": 0.001217,
        "accuracy": 0.004657,
        "main_score": 0.001217,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.434772,
        "recall": 0.513639,
        "f1": 0.456063,
        "accuracy": 0.513639,
        "main_score": 0.456063,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.666885,
        "recall": 0.727212,
        "f1": 0.683926,
        "accuracy": 0.727212,
        "main_score": 0.683926,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.742249,
        "recall": 0.792415,
        "f1": 0.756946,
        "accuracy": 0.792415,
        "main_score": 0.756946,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.784003,
        "recall": 0.828343,
        "f1": 0.796887,
        "accuracy": 0.828343,
        "main_score": 0.796887,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001802,
        "recall": 0.006653,
        "f1": 0.00203,
        "accuracy": 0.006653,
        "main_score": 0.00203,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.001698,
        "recall": 0.004657,
        "f1": 0.001842,
        "accuracy": 0.004657,
        "main_score": 0.001842,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001775,
        "recall": 0.006653,
        "f1": 0.001987,
        "accuracy": 0.006653,
        "main_score": 0.001987,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.001306,
        "recall": 0.005323,
        "f1": 0.001648,
        "accuracy": 0.005323,
        "main_score": 0.001648,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.002661,
        "f1": 0.001118,
        "accuracy": 0.002661,
        "main_score": 0.001118,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001757,
        "recall": 0.005988,
        "f1": 0.001955,
        "accuracy": 0.005988,
        "main_score": 0.001955,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.001679,
        "recall": 0.004657,
        "f1": 0.001805,
        "accuracy": 0.004657,
        "main_score": 0.001805,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.001874,
        "recall": 0.005323,
        "f1": 0.002146,
        "accuracy": 0.005323,
        "main_score": 0.002146,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001762,
        "recall": 0.004657,
        "f1": 0.001955,
        "accuracy": 0.004657,
        "main_score": 0.001955,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.00295,
        "recall": 0.006653,
        "f1": 0.003343,
        "accuracy": 0.006653,
        "main_score": 0.003343,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.001388,
        "recall": 0.005988,
        "f1": 0.001731,
        "accuracy": 0.005988,
        "main_score": 0.001731,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.001682,
        "recall": 0.003992,
        "f1": 0.00181,
        "accuracy": 0.003992,
        "main_score": 0.00181,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001667,
        "recall": 0.002661,
        "f1": 0.001781,
        "accuracy": 0.002661,
        "main_score": 0.001781,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.02594,
        "recall": 0.043247,
        "f1": 0.029921,
        "accuracy": 0.043247,
        "main_score": 0.029921,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.001727,
        "recall": 0.005988,
        "f1": 0.001898,
        "accuracy": 0.005988,
        "main_score": 0.001898,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.001782,
        "recall": 0.004657,
        "f1": 0.001992,
        "accuracy": 0.004657,
        "main_score": 0.001992,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.001162,
        "recall": 0.005323,
        "f1": 0.001407,
        "accuracy": 0.005323,
        "main_score": 0.001407,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.002158,
        "recall": 0.005323,
        "f1": 0.002274,
        "accuracy": 0.005323,
        "main_score": 0.002274,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002857,
        "recall": 0.007984,
        "f1": 0.003264,
        "accuracy": 0.007984,
        "main_score": 0.003264,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.001175,
        "recall": 0.003327,
        "f1": 0.001397,
        "accuracy": 0.003327,
        "main_score": 0.001397,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001015,
        "recall": 0.003992,
        "f1": 0.001142,
        "accuracy": 0.003992,
        "main_score": 0.001142,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002043,
        "recall": 0.006653,
        "f1": 0.002388,
        "accuracy": 0.006653,
        "main_score": 0.002388,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.494925,
        "recall": 0.575516,
        "f1": 0.517368,
        "accuracy": 0.575516,
        "main_score": 0.517368,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.546567,
        "recall": 0.615436,
        "f1": 0.565604,
        "accuracy": 0.615436,
        "main_score": 0.565604,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.166737,
        "recall": 0.225549,
        "f1": 0.180603,
        "accuracy": 0.225549,
        "main_score": 0.180603,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.529441,
        "recall": 0.602129,
        "f1": 0.549833,
        "accuracy": 0.602129,
        "main_score": 0.549833,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.492327,
        "recall": 0.550898,
        "f1": 0.507359,
        "accuracy": 0.550898,
        "main_score": 0.507359,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.408582,
        "recall": 0.488357,
        "f1": 0.430396,
        "accuracy": 0.488357,
        "main_score": 0.430396,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.554522,
        "recall": 0.626081,
        "f1": 0.574239,
        "accuracy": 0.626081,
        "main_score": 0.574239,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.576926,
        "recall": 0.644711,
        "f1": 0.595363,
        "accuracy": 0.644711,
        "main_score": 0.595363,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.496342,
        "recall": 0.562209,
        "f1": 0.513901,
        "accuracy": 0.562209,
        "main_score": 0.513901,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.359722,
        "recall": 0.44511,
        "f1": 0.382776,
        "accuracy": 0.44511,
        "main_score": 0.382776,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.557211,
        "recall": 0.626081,
        "f1": 0.576006,
        "accuracy": 0.626081,
        "main_score": 0.576006,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.521946,
        "recall": 0.592814,
        "f1": 0.54108,
        "accuracy": 0.592814,
        "main_score": 0.54108,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.552315,
        "recall": 0.628743,
        "f1": 0.573676,
        "accuracy": 0.628743,
        "main_score": 0.573676,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003348,
        "recall": 0.009315,
        "f1": 0.003999,
        "accuracy": 0.009315,
        "main_score": 0.003999,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.549245,
        "recall": 0.615436,
        "f1": 0.567208,
        "accuracy": 0.615436,
        "main_score": 0.567208,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.532637,
        "recall": 0.606121,
        "f1": 0.553377,
        "accuracy": 0.606121,
        "main_score": 0.553377,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.548041,
        "recall": 0.620758,
        "f1": 0.567875,
        "accuracy": 0.620758,
        "main_score": 0.567875,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.425909,
        "recall": 0.501663,
        "f1": 0.446322,
        "accuracy": 0.501663,
        "main_score": 0.446322,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000482,
        "recall": 0.005988,
        "f1": 0.000802,
        "accuracy": 0.005988,
        "main_score": 0.000802,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.468481,
        "recall": 0.54358,
        "f1": 0.48929,
        "accuracy": 0.54358,
        "main_score": 0.48929,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.509513,
        "recall": 0.58483,
        "f1": 0.530271,
        "accuracy": 0.58483,
        "main_score": 0.530271,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.570275,
        "recall": 0.638723,
        "f1": 0.589095,
        "accuracy": 0.638723,
        "main_score": 0.589095,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.709527,
        "recall": 0.773786,
        "f1": 0.728849,
        "accuracy": 0.773786,
        "main_score": 0.728849,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.818857,
        "recall": 0.86161,
        "f1": 0.831897,
        "accuracy": 0.86161,
        "main_score": 0.831897,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.124716,
        "recall": 0.180971,
        "f1": 0.136627,
        "accuracy": 0.180971,
        "main_score": 0.136627,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.559819,
        "recall": 0.646041,
        "f1": 0.584538,
        "accuracy": 0.646041,
        "main_score": 0.584538,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.806913,
        "recall": 0.848303,
        "f1": 0.819464,
        "accuracy": 0.848303,
        "main_score": 0.819464,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.450577,
        "recall": 0.536926,
        "f1": 0.473226,
        "accuracy": 0.536926,
        "main_score": 0.473226,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.796235,
        "recall": 0.84165,
        "f1": 0.81015,
        "accuracy": 0.84165,
        "main_score": 0.81015,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.815084,
        "recall": 0.858949,
        "f1": 0.828711,
        "accuracy": 0.858949,
        "main_score": 0.828711,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.762293,
        "recall": 0.817033,
        "f1": 0.779314,
        "accuracy": 0.817033,
        "main_score": 0.779314,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.372157,
        "recall": 0.46507,
        "f1": 0.396886,
        "accuracy": 0.46507,
        "main_score": 0.396886,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.743005,
        "recall": 0.795742,
        "f1": 0.758818,
        "accuracy": 0.795742,
        "main_score": 0.758818,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.813506,
        "recall": 0.854291,
        "f1": 0.825948,
        "accuracy": 0.854291,
        "main_score": 0.825948,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.799714,
        "recall": 0.844977,
        "f1": 0.813612,
        "accuracy": 0.844977,
        "main_score": 0.813612,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000788,
        "recall": 0.003327,
        "f1": 0.000878,
        "accuracy": 0.003327,
        "main_score": 0.000878,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.790342,
        "recall": 0.837658,
        "f1": 0.804528,
        "accuracy": 0.837658,
        "main_score": 0.804528,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.799418,
        "recall": 0.842981,
        "f1": 0.812669,
        "accuracy": 0.842981,
        "main_score": 0.812669,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.75487,
        "recall": 0.809049,
        "f1": 0.770842,
        "accuracy": 0.809049,
        "main_score": 0.770842,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.63693,
        "recall": 0.715902,
        "f1": 0.659851,
        "accuracy": 0.715902,
        "main_score": 0.659851,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001378,
        "recall": 0.005988,
        "f1": 0.001764,
        "accuracy": 0.005988,
        "main_score": 0.001764,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.438108,
        "recall": 0.529607,
        "f1": 0.46216,
        "accuracy": 0.529607,
        "main_score": 0.46216,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.814842,
        "recall": 0.856953,
        "f1": 0.827789,
        "accuracy": 0.856953,
        "main_score": 0.827789,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.801724,
        "recall": 0.849634,
        "f1": 0.816529,
        "accuracy": 0.849634,
        "main_score": 0.816529,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.795051,
        "recall": 0.843646,
        "f1": 0.809472,
        "accuracy": 0.843646,
        "main_score": 0.809472,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.894563,
        "recall": 0.92016,
        "f1": 0.902462,
        "accuracy": 0.92016,
        "main_score": 0.902462,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.135243,
        "recall": 0.190951,
        "f1": 0.147516,
        "accuracy": 0.190951,
        "main_score": 0.147516,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.640269,
        "recall": 0.719894,
        "f1": 0.663271,
        "accuracy": 0.719894,
        "main_score": 0.663271,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.889565,
        "recall": 0.914172,
        "f1": 0.896974,
        "accuracy": 0.914172,
        "main_score": 0.896974,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.521291,
        "recall": 0.610113,
        "f1": 0.54552,
        "accuracy": 0.610113,
        "main_score": 0.54552,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.882069,
        "recall": 0.91018,
        "f1": 0.890654,
        "accuracy": 0.91018,
        "main_score": 0.890654,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.888928,
        "recall": 0.914837,
        "f1": 0.896973,
        "accuracy": 0.914837,
        "main_score": 0.896973,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.837688,
        "recall": 0.876248,
        "f1": 0.849114,
        "accuracy": 0.876248,
        "main_score": 0.849114,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.429228,
        "recall": 0.517631,
        "f1": 0.453191,
        "accuracy": 0.517631,
        "main_score": 0.453191,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.821802,
        "recall": 0.86161,
        "f1": 0.83375,
        "accuracy": 0.86161,
        "main_score": 0.83375,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.872184,
        "recall": 0.902196,
        "f1": 0.881182,
        "accuracy": 0.902196,
        "main_score": 0.881182,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.872147,
        "recall": 0.899534,
        "f1": 0.879962,
        "accuracy": 0.899534,
        "main_score": 0.879962,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.8e-05,
        "recall": 0.002661,
        "f1": 3.5e-05,
        "accuracy": 0.002661,
        "main_score": 3.5e-05,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.875371,
        "recall": 0.906188,
        "f1": 0.884431,
        "accuracy": 0.906188,
        "main_score": 0.884431,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.871002,
        "recall": 0.90153,
        "f1": 0.88024,
        "accuracy": 0.90153,
        "main_score": 0.88024,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.847956,
        "recall": 0.885562,
        "f1": 0.859137,
        "accuracy": 0.885562,
        "main_score": 0.859137,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.736337,
        "recall": 0.798403,
        "f1": 0.754839,
        "accuracy": 0.798403,
        "main_score": 0.754839,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000414,
        "recall": 0.004657,
        "f1": 0.000702,
        "accuracy": 0.004657,
        "main_score": 0.000702,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.493047,
        "recall": 0.572854,
        "f1": 0.514706,
        "accuracy": 0.572854,
        "main_score": 0.514706,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.844961,
        "recall": 0.88157,
        "f1": 0.856267,
        "accuracy": 0.88157,
        "main_score": 0.856267,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.889643,
        "recall": 0.916168,
        "f1": 0.897583,
        "accuracy": 0.916168,
        "main_score": 0.897583,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.833699,
        "recall": 0.870925,
        "f1": 0.844945,
        "accuracy": 0.870925,
        "main_score": 0.844945,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.909614,
        "recall": 0.932801,
        "f1": 0.916523,
        "accuracy": 0.932801,
        "main_score": 0.916523,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.136289,
        "recall": 0.195609,
        "f1": 0.149441,
        "accuracy": 0.195609,
        "main_score": 0.149441,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.716923,
        "recall": 0.7831,
        "f1": 0.736094,
        "accuracy": 0.7831,
        "main_score": 0.736094,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.930251,
        "recall": 0.948104,
        "f1": 0.935751,
        "accuracy": 0.948104,
        "main_score": 0.935751,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.536944,
        "recall": 0.620758,
        "f1": 0.558911,
        "accuracy": 0.620758,
        "main_score": 0.558911,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.915376,
        "recall": 0.936128,
        "f1": 0.921723,
        "accuracy": 0.936128,
        "main_score": 0.921723,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.932125,
        "recall": 0.9501,
        "f1": 0.937591,
        "accuracy": 0.9501,
        "main_score": 0.937591,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.815966,
        "recall": 0.859614,
        "f1": 0.828979,
        "accuracy": 0.859614,
        "main_score": 0.828979,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.49051,
        "recall": 0.586161,
        "f1": 0.516844,
        "accuracy": 0.586161,
        "main_score": 0.516844,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.871575,
        "recall": 0.903526,
        "f1": 0.881428,
        "accuracy": 0.903526,
        "main_score": 0.881428,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.871745,
        "recall": 0.902861,
        "f1": 0.88113,
        "accuracy": 0.902861,
        "main_score": 0.88113,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.904535,
        "recall": 0.928809,
        "f1": 0.911998,
        "accuracy": 0.928809,
        "main_score": 0.911998,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001416,
        "recall": 0.003992,
        "f1": 0.001487,
        "accuracy": 0.003992,
        "main_score": 0.001487,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.909514,
        "recall": 0.932136,
        "f1": 0.916383,
        "accuracy": 0.932136,
        "main_score": 0.916383,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.900166,
        "recall": 0.926813,
        "f1": 0.908317,
        "accuracy": 0.926813,
        "main_score": 0.908317,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.901907,
        "recall": 0.926813,
        "f1": 0.909625,
        "accuracy": 0.926813,
        "main_score": 0.909625,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.764409,
        "recall": 0.817033,
        "f1": 0.779888,
        "accuracy": 0.817033,
        "main_score": 0.779888,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001117,
        "recall": 0.004657,
        "f1": 0.001401,
        "accuracy": 0.004657,
        "main_score": 0.001401,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.540116,
        "recall": 0.620758,
        "f1": 0.561569,
        "accuracy": 0.620758,
        "main_score": 0.561569,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.825432,
        "recall": 0.863606,
        "f1": 0.837074,
        "accuracy": 0.863606,
        "main_score": 0.837074,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.892532,
        "recall": 0.917498,
        "f1": 0.899957,
        "accuracy": 0.917498,
        "main_score": 0.899957,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 51.596261739730835,
  "kg_co2_emissions": 0.0024517820044163783
}