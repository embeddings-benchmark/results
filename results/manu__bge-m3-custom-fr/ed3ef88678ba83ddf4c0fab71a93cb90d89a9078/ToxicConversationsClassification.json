{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "task_name": "ToxicConversationsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.67749,
        "f1": 0.524542,
        "f1_weighted": 0.74853,
        "ap": 0.134189,
        "ap_weighted": 0.134189,
        "scores_per_experiment": [
          {
            "accuracy": 0.746582,
            "f1": 0.564144,
            "f1_weighted": 0.80152,
            "ap": 0.143775,
            "ap_weighted": 0.143775
          },
          {
            "accuracy": 0.70459,
            "f1": 0.541684,
            "f1_weighted": 0.7717,
            "ap": 0.139272,
            "ap_weighted": 0.139272
          },
          {
            "accuracy": 0.695801,
            "f1": 0.538765,
            "f1_weighted": 0.765317,
            "ap": 0.141091,
            "ap_weighted": 0.141091
          },
          {
            "accuracy": 0.763184,
            "f1": 0.581689,
            "f1_weighted": 0.813636,
            "ap": 0.158462,
            "ap_weighted": 0.158462
          },
          {
            "accuracy": 0.52002,
            "f1": 0.431794,
            "f1_weighted": 0.62027,
            "ap": 0.111315,
            "ap_weighted": 0.111315
          },
          {
            "accuracy": 0.567871,
            "f1": 0.461274,
            "f1_weighted": 0.663001,
            "ap": 0.118091,
            "ap_weighted": 0.118091
          },
          {
            "accuracy": 0.759766,
            "f1": 0.561032,
            "f1_weighted": 0.809665,
            "ap": 0.131895,
            "ap_weighted": 0.131895
          },
          {
            "accuracy": 0.614746,
            "f1": 0.492547,
            "f1_weighted": 0.70217,
            "ap": 0.1301,
            "ap_weighted": 0.1301
          },
          {
            "accuracy": 0.695801,
            "f1": 0.537966,
            "f1_weighted": 0.76529,
            "ap": 0.13987,
            "ap_weighted": 0.13987
          },
          {
            "accuracy": 0.706543,
            "f1": 0.534524,
            "f1_weighted": 0.772725,
            "ap": 0.128021,
            "ap_weighted": 0.128021
          }
        ],
        "main_score": 0.67749,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.40325140953064,
  "kg_co2_emissions": 0.0006020501446410764
}