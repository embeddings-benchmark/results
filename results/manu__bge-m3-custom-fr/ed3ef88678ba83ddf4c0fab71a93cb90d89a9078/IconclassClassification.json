{
  "dataset_revision": "1cd02f1579dab39fedc95de8cc15fd620557a9f2",
  "task_name": "IconclassClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.549505,
            "f1": 0.536898,
            "f1_weighted": 0.538738,
            "precision": 0.568678,
            "precision_weighted": 0.570233,
            "recall": 0.54809,
            "recall_weighted": 0.549505,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.559406,
            "f1": 0.551693,
            "f1_weighted": 0.552904,
            "precision": 0.571707,
            "precision_weighted": 0.571946,
            "recall": 0.557532,
            "recall_weighted": 0.559406,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.549505,
            "f1": 0.547391,
            "f1_weighted": 0.548554,
            "precision": 0.549187,
            "precision_weighted": 0.550501,
            "recall": 0.548529,
            "recall_weighted": 0.549505,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.564356,
            "f1": 0.556538,
            "f1_weighted": 0.558086,
            "precision": 0.56295,
            "precision_weighted": 0.563861,
            "recall": 0.562363,
            "recall_weighted": 0.564356,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.554455,
            "f1": 0.543597,
            "f1_weighted": 0.544965,
            "precision": 0.552972,
            "precision_weighted": 0.55384,
            "recall": 0.552921,
            "recall_weighted": 0.554455,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.529703,
            "f1": 0.523485,
            "f1_weighted": 0.525304,
            "precision": 0.534421,
            "precision_weighted": 0.535676,
            "recall": 0.527448,
            "recall_weighted": 0.529703,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.554455,
            "f1": 0.540322,
            "f1_weighted": 0.542349,
            "precision": 0.539033,
            "precision_weighted": 0.540738,
            "recall": 0.552262,
            "recall_weighted": 0.554455,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.559406,
            "f1": 0.551908,
            "f1_weighted": 0.553031,
            "precision": 0.559556,
            "precision_weighted": 0.560155,
            "recall": 0.557971,
            "recall_weighted": 0.559406,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.564356,
            "f1": 0.55001,
            "f1_weighted": 0.552209,
            "precision": 0.554783,
            "precision_weighted": 0.556117,
            "recall": 0.561484,
            "recall_weighted": 0.564356,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.529703,
            "f1": 0.522761,
            "f1_weighted": 0.523697,
            "precision": 0.528475,
            "precision_weighted": 0.528843,
            "recall": 0.528327,
            "recall_weighted": 0.529703,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.551485,
        "f1": 0.54246,
        "f1_weighted": 0.543984,
        "precision": 0.552176,
        "precision_weighted": 0.553191,
        "recall": 0.549693,
        "recall_weighted": 0.551485,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.54246,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 14.517158269882202,
  "kg_co2_emissions": null
}