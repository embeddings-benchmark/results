{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "task_name": "MTOPDomainClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.544518,
        "f1": 0.525174,
        "f1_weighted": 0.548027,
        "scores_per_experiment": [
          {
            "accuracy": 0.569146,
            "f1": 0.548094,
            "f1_weighted": 0.573442
          },
          {
            "accuracy": 0.50303,
            "f1": 0.492296,
            "f1_weighted": 0.50765
          },
          {
            "accuracy": 0.516804,
            "f1": 0.496706,
            "f1_weighted": 0.521996
          },
          {
            "accuracy": 0.553168,
            "f1": 0.531162,
            "f1_weighted": 0.557764
          },
          {
            "accuracy": 0.55427,
            "f1": 0.535662,
            "f1_weighted": 0.557926
          },
          {
            "accuracy": 0.502479,
            "f1": 0.485268,
            "f1_weighted": 0.503417
          },
          {
            "accuracy": 0.580165,
            "f1": 0.55909,
            "f1_weighted": 0.588661
          },
          {
            "accuracy": 0.553168,
            "f1": 0.539996,
            "f1_weighted": 0.558294
          },
          {
            "accuracy": 0.579063,
            "f1": 0.548524,
            "f1_weighted": 0.577698
          },
          {
            "accuracy": 0.533884,
            "f1": 0.514944,
            "f1_weighted": 0.533418
          }
        ],
        "main_score": 0.544518,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.5592,
        "f1": 0.534509,
        "f1_weighted": 0.564034,
        "scores_per_experiment": [
          {
            "accuracy": 0.577628,
            "f1": 0.550804,
            "f1_weighted": 0.583013
          },
          {
            "accuracy": 0.522682,
            "f1": 0.507865,
            "f1_weighted": 0.529014
          },
          {
            "accuracy": 0.533671,
            "f1": 0.508259,
            "f1_weighted": 0.541683
          },
          {
            "accuracy": 0.567202,
            "f1": 0.54328,
            "f1_weighted": 0.573101
          },
          {
            "accuracy": 0.580727,
            "f1": 0.554111,
            "f1_weighted": 0.586535
          },
          {
            "accuracy": 0.517611,
            "f1": 0.497094,
            "f1_weighted": 0.518555
          },
          {
            "accuracy": 0.597633,
            "f1": 0.568064,
            "f1_weighted": 0.604136
          },
          {
            "accuracy": 0.568893,
            "f1": 0.546465,
            "f1_weighted": 0.574041
          },
          {
            "accuracy": 0.583263,
            "f1": 0.5511,
            "f1_weighted": 0.584638
          },
          {
            "accuracy": 0.542688,
            "f1": 0.518049,
            "f1_weighted": 0.545621
          }
        ],
        "main_score": 0.5592,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.047353506088257,
  "kg_co2_emissions": null
}