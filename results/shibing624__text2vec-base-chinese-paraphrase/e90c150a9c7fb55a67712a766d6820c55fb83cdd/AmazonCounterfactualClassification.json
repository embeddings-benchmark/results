{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.588412,
        "f1": 0.564188,
        "f1_weighted": 0.604151,
        "ap": 0.738774,
        "ap_weighted": 0.738774,
        "scores_per_experiment": [
          {
            "accuracy": 0.596567,
            "f1": 0.561372,
            "f1_weighted": 0.610431,
            "ap": 0.731165,
            "ap_weighted": 0.731165
          },
          {
            "accuracy": 0.560086,
            "f1": 0.54101,
            "f1_weighted": 0.577957,
            "ap": 0.728541,
            "ap_weighted": 0.728541
          },
          {
            "accuracy": 0.577253,
            "f1": 0.564744,
            "f1_weighted": 0.593879,
            "ap": 0.747475,
            "ap_weighted": 0.747475
          },
          {
            "accuracy": 0.594421,
            "f1": 0.576834,
            "f1_weighted": 0.610897,
            "ap": 0.749339,
            "ap_weighted": 0.749339
          },
          {
            "accuracy": 0.624464,
            "f1": 0.601002,
            "f1_weighted": 0.639205,
            "ap": 0.758243,
            "ap_weighted": 0.758243
          },
          {
            "accuracy": 0.585837,
            "f1": 0.554822,
            "f1_weighted": 0.601218,
            "ap": 0.729455,
            "ap_weighted": 0.729455
          },
          {
            "accuracy": 0.577253,
            "f1": 0.551825,
            "f1_weighted": 0.593977,
            "ap": 0.730481,
            "ap_weighted": 0.730481
          },
          {
            "accuracy": 0.577253,
            "f1": 0.563403,
            "f1_weighted": 0.594107,
            "ap": 0.745237,
            "ap_weighted": 0.745237
          },
          {
            "accuracy": 0.596567,
            "f1": 0.557785,
            "f1_weighted": 0.609494,
            "ap": 0.728206,
            "ap_weighted": 0.728206
          },
          {
            "accuracy": 0.594421,
            "f1": 0.569082,
            "f1_weighted": 0.610341,
            "ap": 0.7396,
            "ap_weighted": 0.7396
          }
        ],
        "main_score": 0.588412,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.57666,
        "f1": 0.555244,
        "f1_weighted": 0.592856,
        "ap": 0.733979,
        "ap_weighted": 0.733979,
        "scores_per_experiment": [
          {
            "accuracy": 0.619914,
            "f1": 0.587182,
            "f1_weighted": 0.632733,
            "ap": 0.74368,
            "ap_weighted": 0.74368
          },
          {
            "accuracy": 0.511777,
            "f1": 0.485258,
            "f1_weighted": 0.531042,
            "ap": 0.695737,
            "ap_weighted": 0.695737
          },
          {
            "accuracy": 0.570664,
            "f1": 0.560651,
            "f1_weighted": 0.586642,
            "ap": 0.746227,
            "ap_weighted": 0.746227
          },
          {
            "accuracy": 0.594218,
            "f1": 0.576508,
            "f1_weighted": 0.610445,
            "ap": 0.747194,
            "ap_weighted": 0.747194
          },
          {
            "accuracy": 0.592077,
            "f1": 0.569698,
            "f1_weighted": 0.608152,
            "ap": 0.739942,
            "ap_weighted": 0.739942
          },
          {
            "accuracy": 0.591006,
            "f1": 0.572961,
            "f1_weighted": 0.60736,
            "ap": 0.74491,
            "ap_weighted": 0.74491
          },
          {
            "accuracy": 0.571734,
            "f1": 0.553247,
            "f1_weighted": 0.58886,
            "ap": 0.733681,
            "ap_weighted": 0.733681
          },
          {
            "accuracy": 0.535332,
            "f1": 0.523364,
            "f1_weighted": 0.55296,
            "ap": 0.722883,
            "ap_weighted": 0.722883
          },
          {
            "accuracy": 0.593148,
            "f1": 0.560656,
            "f1_weighted": 0.607475,
            "ap": 0.730115,
            "ap_weighted": 0.730115
          },
          {
            "accuracy": 0.586724,
            "f1": 0.562912,
            "f1_weighted": 0.602889,
            "ap": 0.73542,
            "ap_weighted": 0.73542
          }
        ],
        "main_score": 0.57666,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 24.251598834991455,
  "kg_co2_emissions": null
}