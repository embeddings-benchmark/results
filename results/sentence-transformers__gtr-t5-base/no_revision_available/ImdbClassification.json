{
  "dataset_revision": "3d86128a09e091d6018b6d26cad27f2739fc2db7",
  "task_name": "ImdbClassification",
  "mteb_version": "1.34.14",
  "scores": {
    "test": [
      {
        "accuracy": 0.66628,
        "f1": 0.663776,
        "f1_weighted": 0.663776,
        "ap": 0.610259,
        "ap_weighted": 0.610259,
        "scores_per_experiment": [
          {
            "accuracy": 0.67872,
            "f1": 0.67603,
            "f1_weighted": 0.67603,
            "ap": 0.628419,
            "ap_weighted": 0.628419
          },
          {
            "accuracy": 0.69988,
            "f1": 0.699844,
            "f1_weighted": 0.699844,
            "ap": 0.640791,
            "ap_weighted": 0.640791
          },
          {
            "accuracy": 0.67984,
            "f1": 0.675814,
            "f1_weighted": 0.675814,
            "ap": 0.616368,
            "ap_weighted": 0.616368
          },
          {
            "accuracy": 0.68376,
            "f1": 0.682301,
            "f1_weighted": 0.682301,
            "ap": 0.621618,
            "ap_weighted": 0.621618
          },
          {
            "accuracy": 0.6972,
            "f1": 0.697149,
            "f1_weighted": 0.697149,
            "ap": 0.638523,
            "ap_weighted": 0.638523
          },
          {
            "accuracy": 0.6608,
            "f1": 0.650038,
            "f1_weighted": 0.650038,
            "ap": 0.599543,
            "ap_weighted": 0.599543
          },
          {
            "accuracy": 0.6374,
            "f1": 0.637296,
            "f1_weighted": 0.637296,
            "ap": 0.58824,
            "ap_weighted": 0.58824
          },
          {
            "accuracy": 0.62068,
            "f1": 0.620024,
            "f1_weighted": 0.620024,
            "ap": 0.573786,
            "ap_weighted": 0.573786
          },
          {
            "accuracy": 0.65108,
            "f1": 0.645992,
            "f1_weighted": 0.645992,
            "ap": 0.593951,
            "ap_weighted": 0.593951
          },
          {
            "accuracy": 0.65344,
            "f1": 0.653272,
            "f1_weighted": 0.653272,
            "ap": 0.601347,
            "ap_weighted": 0.601347
          }
        ],
        "main_score": 0.66628,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 159.46412014961243,
  "kg_co2_emissions": null
}