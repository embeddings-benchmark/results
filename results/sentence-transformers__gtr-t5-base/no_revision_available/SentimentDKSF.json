{
  "dataset_revision": "b4d5a8dd501db610b5ad89e9aa13f863b842b395",
  "task_name": "SentimentDKSF",
  "mteb_version": "1.34.14",
  "scores": {
    "test": [
      {
        "accuracy": 0.442549,
        "f1": 0.379355,
        "f1_weighted": 0.444911,
        "scores_per_experiment": [
          {
            "accuracy": 0.363283,
            "f1": 0.316563,
            "f1_weighted": 0.401234
          },
          {
            "accuracy": 0.493305,
            "f1": 0.43636,
            "f1_weighted": 0.49689
          },
          {
            "accuracy": 0.45054,
            "f1": 0.401588,
            "f1_weighted": 0.467037
          },
          {
            "accuracy": 0.408207,
            "f1": 0.34195,
            "f1_weighted": 0.394199
          },
          {
            "accuracy": 0.451404,
            "f1": 0.362455,
            "f1_weighted": 0.4347
          },
          {
            "accuracy": 0.493305,
            "f1": 0.428808,
            "f1_weighted": 0.488567
          },
          {
            "accuracy": 0.420302,
            "f1": 0.337952,
            "f1_weighted": 0.420437
          },
          {
            "accuracy": 0.485961,
            "f1": 0.426078,
            "f1_weighted": 0.480768
          },
          {
            "accuracy": 0.475162,
            "f1": 0.402685,
            "f1_weighted": 0.480705
          },
          {
            "accuracy": 0.384017,
            "f1": 0.339116,
            "f1_weighted": 0.384574
          }
        ],
        "main_score": 0.442549,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 6.319506883621216,
  "kg_co2_emissions": null
}