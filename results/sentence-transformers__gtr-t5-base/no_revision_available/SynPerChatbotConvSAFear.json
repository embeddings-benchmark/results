{
  "dataset_revision": "3c22f7e6bf4e366c86d69293c9164bf9e9d80aac",
  "task_name": "SynPerChatbotConvSAFear",
  "mteb_version": "1.34.14",
  "scores": {
    "test": [
      {
        "accuracy": 0.624786,
        "f1": 0.598189,
        "f1_weighted": 0.617412,
        "ap": 0.66391,
        "ap_weighted": 0.66391,
        "scores_per_experiment": [
          {
            "accuracy": 0.564103,
            "f1": 0.562953,
            "f1_weighted": 0.567742,
            "ap": 0.650175,
            "ap_weighted": 0.650175
          },
          {
            "accuracy": 0.589744,
            "f1": 0.584615,
            "f1_weighted": 0.594477,
            "ap": 0.657699,
            "ap_weighted": 0.657699
          },
          {
            "accuracy": 0.683761,
            "f1": 0.658192,
            "f1_weighted": 0.678168,
            "ap": 0.694475,
            "ap_weighted": 0.694475
          },
          {
            "accuracy": 0.649573,
            "f1": 0.631369,
            "f1_weighted": 0.648872,
            "ap": 0.679743,
            "ap_weighted": 0.679743
          },
          {
            "accuracy": 0.649573,
            "f1": 0.628284,
            "f1_weighted": 0.647292,
            "ap": 0.677049,
            "ap_weighted": 0.677049
          },
          {
            "accuracy": 0.623932,
            "f1": 0.558642,
            "f1_weighted": 0.594914,
            "ap": 0.641335,
            "ap_weighted": 0.641335
          },
          {
            "accuracy": 0.623932,
            "f1": 0.582143,
            "f1_weighted": 0.610379,
            "ap": 0.650073,
            "ap_weighted": 0.650073
          },
          {
            "accuracy": 0.641026,
            "f1": 0.571951,
            "f1_weighted": 0.608693,
            "ap": 0.649002,
            "ap_weighted": 0.649002
          },
          {
            "accuracy": 0.57265,
            "f1": 0.572368,
            "f1_weighted": 0.574711,
            "ap": 0.659805,
            "ap_weighted": 0.659805
          },
          {
            "accuracy": 0.649573,
            "f1": 0.631369,
            "f1_weighted": 0.648872,
            "ap": 0.679743,
            "ap_weighted": 0.679743
          }
        ],
        "main_score": 0.624786,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 6.569813251495361,
  "kg_co2_emissions": null
}