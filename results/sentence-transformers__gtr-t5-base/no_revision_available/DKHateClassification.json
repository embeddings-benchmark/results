{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "1.34.14",
  "scores": {
    "test": [
      {
        "accuracy": 0.564134,
        "f1": 0.457631,
        "f1_weighted": 0.635802,
        "ap": 0.13483,
        "ap_weighted": 0.13483,
        "scores_per_experiment": [
          {
            "accuracy": 0.571429,
            "f1": 0.466333,
            "f1_weighted": 0.644132,
            "ap": 0.136537,
            "ap_weighted": 0.136537
          },
          {
            "accuracy": 0.607903,
            "f1": 0.478259,
            "f1_weighted": 0.673515,
            "ap": 0.133638,
            "ap_weighted": 0.133638
          },
          {
            "accuracy": 0.583587,
            "f1": 0.458758,
            "f1_weighted": 0.653901,
            "ap": 0.12717,
            "ap_weighted": 0.12717
          },
          {
            "accuracy": 0.504559,
            "f1": 0.428533,
            "f1_weighted": 0.58502,
            "ap": 0.131511,
            "ap_weighted": 0.131511
          },
          {
            "accuracy": 0.537994,
            "f1": 0.465726,
            "f1_weighted": 0.613248,
            "ap": 0.154016,
            "ap_weighted": 0.154016
          },
          {
            "accuracy": 0.544073,
            "f1": 0.451764,
            "f1_weighted": 0.620655,
            "ap": 0.134907,
            "ap_weighted": 0.134907
          },
          {
            "accuracy": 0.492401,
            "f1": 0.42314,
            "f1_weighted": 0.573206,
            "ap": 0.132412,
            "ap_weighted": 0.132412
          },
          {
            "accuracy": 0.553191,
            "f1": 0.427826,
            "f1_weighted": 0.628899,
            "ap": 0.117742,
            "ap_weighted": 0.117742
          },
          {
            "accuracy": 0.574468,
            "f1": 0.482006,
            "f1_weighted": 0.646309,
            "ap": 0.15094,
            "ap_weighted": 0.15094
          },
          {
            "accuracy": 0.671733,
            "f1": 0.493961,
            "f1_weighted": 0.719138,
            "ap": 0.129428,
            "ap_weighted": 0.129428
          }
        ],
        "main_score": 0.564134,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 2.676509141921997,
  "kg_co2_emissions": null
}