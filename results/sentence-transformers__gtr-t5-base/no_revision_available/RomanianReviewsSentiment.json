{
  "dataset_revision": "358bcc95aeddd5d07a4524ee416f03d993099b23",
  "task_name": "RomanianReviewsSentiment",
  "mteb_version": "1.34.14",
  "scores": {
    "test": [
      {
        "accuracy": 0.35083,
        "f1": 0.302565,
        "f1_weighted": 0.376847,
        "scores_per_experiment": [
          {
            "accuracy": 0.399414,
            "f1": 0.326209,
            "f1_weighted": 0.422249
          },
          {
            "accuracy": 0.319336,
            "f1": 0.279834,
            "f1_weighted": 0.338758
          },
          {
            "accuracy": 0.320312,
            "f1": 0.298115,
            "f1_weighted": 0.363399
          },
          {
            "accuracy": 0.405762,
            "f1": 0.336871,
            "f1_weighted": 0.438091
          },
          {
            "accuracy": 0.339844,
            "f1": 0.297876,
            "f1_weighted": 0.369353
          },
          {
            "accuracy": 0.326172,
            "f1": 0.265145,
            "f1_weighted": 0.341452
          },
          {
            "accuracy": 0.35791,
            "f1": 0.311238,
            "f1_weighted": 0.394387
          },
          {
            "accuracy": 0.408691,
            "f1": 0.341324,
            "f1_weighted": 0.422522
          },
          {
            "accuracy": 0.358887,
            "f1": 0.309147,
            "f1_weighted": 0.377058
          },
          {
            "accuracy": 0.271973,
            "f1": 0.25989,
            "f1_weighted": 0.3012
          }
        ],
        "main_score": 0.35083,
        "hf_subset": "default",
        "languages": [
          "ron-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 5.457130670547485,
  "kg_co2_emissions": null
}