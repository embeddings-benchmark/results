{
  "dataset_revision": "3d96e36e10a88d5b7a3f617cf8362d997504494b",
  "task_name": "KorSarcasmClassification",
  "mteb_version": "1.34.14",
  "scores": {
    "train": [
      {
        "accuracy": 0.521729,
        "f1": 0.516151,
        "f1_weighted": 0.516164,
        "ap": 0.512694,
        "ap_weighted": 0.512694,
        "scores_per_experiment": [
          {
            "accuracy": 0.583984,
            "f1": 0.580139,
            "f1_weighted": 0.580217,
            "ap": 0.549604,
            "ap_weighted": 0.549604
          },
          {
            "accuracy": 0.575684,
            "f1": 0.573546,
            "f1_weighted": 0.573605,
            "ap": 0.543444,
            "ap_weighted": 0.543444
          },
          {
            "accuracy": 0.503906,
            "f1": 0.47779,
            "f1_weighted": 0.478018,
            "ap": 0.500781,
            "ap_weighted": 0.500781
          },
          {
            "accuracy": 0.472168,
            "f1": 0.465125,
            "f1_weighted": 0.465006,
            "ap": 0.485841,
            "ap_weighted": 0.485841
          },
          {
            "accuracy": 0.462891,
            "f1": 0.462188,
            "f1_weighted": 0.462226,
            "ap": 0.481924,
            "ap_weighted": 0.481924
          },
          {
            "accuracy": 0.555176,
            "f1": 0.555167,
            "f1_weighted": 0.555163,
            "ap": 0.529636,
            "ap_weighted": 0.529636
          },
          {
            "accuracy": 0.555176,
            "f1": 0.554513,
            "f1_weighted": 0.554546,
            "ap": 0.529864,
            "ap_weighted": 0.529864
          },
          {
            "accuracy": 0.562012,
            "f1": 0.550839,
            "f1_weighted": 0.550701,
            "ap": 0.533138,
            "ap_weighted": 0.533138
          },
          {
            "accuracy": 0.477051,
            "f1": 0.473717,
            "f1_weighted": 0.473635,
            "ap": 0.488076,
            "ap_weighted": 0.488076
          },
          {
            "accuracy": 0.469238,
            "f1": 0.468487,
            "f1_weighted": 0.468526,
            "ap": 0.484635,
            "ap_weighted": 0.484635
          }
        ],
        "main_score": 0.521729,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ]
      }
    ]
  },
  "evaluation_time": 2.7858073711395264,
  "kg_co2_emissions": null
}