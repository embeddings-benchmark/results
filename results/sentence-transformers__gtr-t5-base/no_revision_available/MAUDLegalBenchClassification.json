{
  "dataset_revision": "12ca3b695563788fead87a982ad1a068284413f4",
  "task_name": "MAUDLegalBenchClassification",
  "mteb_version": "1.34.14",
  "scores": {
    "test": [
      {
        "accuracy": 0.308447,
        "f1": 0.166171,
        "f1_weighted": 0.321251,
        "scores_per_experiment": [
          {
            "accuracy": 0.333496,
            "f1": 0.173643,
            "f1_weighted": 0.341918
          },
          {
            "accuracy": 0.290039,
            "f1": 0.162772,
            "f1_weighted": 0.313248
          },
          {
            "accuracy": 0.272461,
            "f1": 0.16554,
            "f1_weighted": 0.294891
          },
          {
            "accuracy": 0.28418,
            "f1": 0.148765,
            "f1_weighted": 0.280682
          },
          {
            "accuracy": 0.241211,
            "f1": 0.149859,
            "f1_weighted": 0.255597
          },
          {
            "accuracy": 0.34082,
            "f1": 0.187322,
            "f1_weighted": 0.349984
          },
          {
            "accuracy": 0.335449,
            "f1": 0.176636,
            "f1_weighted": 0.371444
          },
          {
            "accuracy": 0.317871,
            "f1": 0.172664,
            "f1_weighted": 0.335387
          },
          {
            "accuracy": 0.325195,
            "f1": 0.159333,
            "f1_weighted": 0.321884
          },
          {
            "accuracy": 0.34375,
            "f1": 0.165174,
            "f1_weighted": 0.347477
          }
        ],
        "main_score": 0.308447,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 18.820935487747192,
  "kg_co2_emissions": null
}