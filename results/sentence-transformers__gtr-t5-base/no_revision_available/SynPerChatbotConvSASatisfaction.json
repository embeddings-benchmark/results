{
  "dataset_revision": "50fd9d5d09edd53af89af765636be5db6f983f0e",
  "task_name": "SynPerChatbotConvSASatisfaction",
  "mteb_version": "1.34.14",
  "scores": {
    "test": [
      {
        "accuracy": 0.57296,
        "f1": 0.556831,
        "f1_weighted": 0.569236,
        "ap": 0.68588,
        "ap_weighted": 0.68588,
        "scores_per_experiment": [
          {
            "accuracy": 0.592075,
            "f1": 0.583373,
            "f1_weighted": 0.599794,
            "ap": 0.68753,
            "ap_weighted": 0.68753
          },
          {
            "accuracy": 0.615385,
            "f1": 0.608224,
            "f1_weighted": 0.622669,
            "ap": 0.704758,
            "ap_weighted": 0.704758
          },
          {
            "accuracy": 0.559441,
            "f1": 0.559402,
            "f1_weighted": 0.560523,
            "ap": 0.692732,
            "ap_weighted": 0.692732
          },
          {
            "accuracy": 0.58042,
            "f1": 0.575752,
            "f1_weighted": 0.587888,
            "ap": 0.687507,
            "ap_weighted": 0.687507
          },
          {
            "accuracy": 0.503497,
            "f1": 0.499142,
            "f1_weighted": 0.486406,
            "ap": 0.675773,
            "ap_weighted": 0.675773
          },
          {
            "accuracy": 0.641026,
            "f1": 0.628425,
            "f1_weighted": 0.647087,
            "ap": 0.712109,
            "ap_weighted": 0.712109
          },
          {
            "accuracy": 0.512821,
            "f1": 0.507641,
            "f1_weighted": 0.493869,
            "ap": 0.684506,
            "ap_weighted": 0.684506
          },
          {
            "accuracy": 0.596737,
            "f1": 0.588691,
            "f1_weighted": 0.60438,
            "ap": 0.691414,
            "ap_weighted": 0.691414
          },
          {
            "accuracy": 0.543124,
            "f1": 0.433091,
            "f1_weighted": 0.501206,
            "ap": 0.617219,
            "ap_weighted": 0.617219
          },
          {
            "accuracy": 0.585082,
            "f1": 0.584574,
            "f1_weighted": 0.588535,
            "ap": 0.705258,
            "ap_weighted": 0.705258
          }
        ],
        "main_score": 0.57296,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 10.7613525390625,
  "kg_co2_emissions": null
}