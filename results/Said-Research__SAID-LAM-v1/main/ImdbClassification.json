{
  "dataset_revision": "3d86128a09e091d6018b6d26cad27f2739fc2db7",
  "task_name": "ImdbClassification",
  "mteb_model_name": "Said-Research/SAID-LAM-v1",
  "mteb_version": "2.1.0",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.69412,
            "f1": 0.6935784423055186,
            "f1_weighted": 0.6935784423055186,
            "precision": 0.6955020915573527,
            "precision_weighted": 0.6955020915573527,
            "recall": 0.6941200000000001,
            "recall_weighted": 0.69412,
            "ap": 0.6318199571987306,
            "ap_weighted": 0.6318199571987306
          },
          {
            "accuracy": 0.67664,
            "f1": 0.6765571986428526,
            "f1_weighted": 0.6765571986428526,
            "precision": 0.6768210647703248,
            "precision_weighted": 0.6768210647703248,
            "recall": 0.67664,
            "recall_weighted": 0.67664,
            "ap": 0.6205531504132231,
            "ap_weighted": 0.6205531504132231
          },
          {
            "accuracy": 0.60468,
            "f1": 0.6046749898089508,
            "f1_weighted": 0.6046749898089508,
            "precision": 0.6046853069588252,
            "precision_weighted": 0.604685306958825,
            "recall": 0.60468,
            "recall_weighted": 0.60468,
            "ap": 0.5633764821529288,
            "ap_weighted": 0.5633764821529288
          },
          {
            "accuracy": 0.69964,
            "f1": 0.6996169493256106,
            "f1_weighted": 0.6996169493256105,
            "precision": 0.6997012983934223,
            "precision_weighted": 0.6997012983934223,
            "recall": 0.69964,
            "recall_weighted": 0.69964,
            "ap": 0.6403868610048041,
            "ap_weighted": 0.6403868610048041
          },
          {
            "accuracy": 0.62868,
            "f1": 0.6285021512002535,
            "f1_weighted": 0.6285021512002535,
            "precision": 0.628926886943459,
            "precision_weighted": 0.628926886943459,
            "recall": 0.62868,
            "recall_weighted": 0.62868,
            "ap": 0.5802043197669962,
            "ap_weighted": 0.5802043197669962
          },
          {
            "accuracy": 0.61116,
            "f1": 0.6096885414135875,
            "f1_weighted": 0.6096885414135876,
            "precision": 0.6128619399972481,
            "precision_weighted": 0.6128619399972481,
            "recall": 0.61116,
            "recall_weighted": 0.61116,
            "ap": 0.5665851172069825,
            "ap_weighted": 0.5665851172069825
          },
          {
            "accuracy": 0.58252,
            "f1": 0.5793595506253222,
            "f1_weighted": 0.5793595506253223,
            "precision": 0.5850768739621982,
            "precision_weighted": 0.5850768739621982,
            "recall": 0.58252,
            "recall_weighted": 0.58252,
            "ap": 0.5470634621940411,
            "ap_weighted": 0.5470634621940411
          },
          {
            "accuracy": 0.63216,
            "f1": 0.6238310783923597,
            "f1_weighted": 0.6238310783923597,
            "precision": 0.6450022329641687,
            "precision_weighted": 0.6450022329641687,
            "recall": 0.63216,
            "recall_weighted": 0.63216,
            "ap": 0.5795404389642417,
            "ap_weighted": 0.5795404389642417
          },
          {
            "accuracy": 0.64296,
            "f1": 0.6424060119608275,
            "f1_weighted": 0.6424060119608275,
            "precision": 0.6438514240283133,
            "precision_weighted": 0.6438514240283133,
            "recall": 0.64296,
            "recall_weighted": 0.64296,
            "ap": 0.5936638763459534,
            "ap_weighted": 0.5936638763459534
          },
          {
            "accuracy": 0.65772,
            "f1": 0.6557293992942383,
            "f1_weighted": 0.6557293992942382,
            "precision": 0.6614541646179226,
            "precision_weighted": 0.6614541646179226,
            "recall": 0.65772,
            "recall_weighted": 0.65772,
            "ap": 0.6004519019512533,
            "ap_weighted": 0.6004519019512533
          }
        ],
        "accuracy": 0.643028,
        "f1": 0.6413944312969522,
        "f1_weighted": 0.6413944312969522,
        "precision": 0.6453883284193236,
        "precision_weighted": 0.6453883284193236,
        "recall": 0.643028,
        "recall_weighted": 0.643028,
        "ap": 0.5923645567199154,
        "ap_weighted": 0.5923645567199154,
        "main_score": 0.643028,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 6206.736694186926,
  "mteb_dataset_name": "ImdbClassification",
  "model_revision": "main"
}