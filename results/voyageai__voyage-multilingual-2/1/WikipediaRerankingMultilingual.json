{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "map": 0.913288,
        "mrr": 0.913288,
        "nAUC_map_max": 0.513473,
        "nAUC_map_std": 0.272742,
        "nAUC_map_diff1": 0.81014,
        "nAUC_mrr_max": 0.513473,
        "nAUC_mrr_std": 0.272742,
        "nAUC_mrr_diff1": 0.81014,
        "main_score": 0.913288,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.879807,
        "mrr": 0.879807,
        "nAUC_map_max": 0.410875,
        "nAUC_map_std": 0.236823,
        "nAUC_map_diff1": 0.785936,
        "nAUC_mrr_max": 0.410875,
        "nAUC_mrr_std": 0.236823,
        "nAUC_mrr_diff1": 0.785936,
        "main_score": 0.879807,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.919542,
        "mrr": 0.919542,
        "nAUC_map_max": 0.464522,
        "nAUC_map_std": 0.304582,
        "nAUC_map_diff1": 0.840931,
        "nAUC_mrr_max": 0.464522,
        "nAUC_mrr_std": 0.304582,
        "nAUC_mrr_diff1": 0.840931,
        "main_score": 0.919542,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.923433,
        "mrr": 0.923877,
        "nAUC_map_max": 0.458261,
        "nAUC_map_std": 0.331518,
        "nAUC_map_diff1": 0.856558,
        "nAUC_mrr_max": 0.471105,
        "nAUC_mrr_std": 0.340172,
        "nAUC_mrr_diff1": 0.855201,
        "main_score": 0.923433,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.911266,
        "mrr": 0.911266,
        "nAUC_map_max": 0.57292,
        "nAUC_map_std": 0.273003,
        "nAUC_map_diff1": 0.826046,
        "nAUC_mrr_max": 0.57292,
        "nAUC_mrr_std": 0.273003,
        "nAUC_mrr_diff1": 0.826046,
        "main_score": 0.911266,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.933544,
        "mrr": 0.933544,
        "nAUC_map_max": 0.533446,
        "nAUC_map_std": 0.489576,
        "nAUC_map_diff1": 0.856435,
        "nAUC_mrr_max": 0.533446,
        "nAUC_mrr_std": 0.489576,
        "nAUC_mrr_diff1": 0.856435,
        "main_score": 0.933544,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.891594,
        "mrr": 0.891594,
        "nAUC_map_max": 0.560267,
        "nAUC_map_std": 0.392221,
        "nAUC_map_diff1": 0.812803,
        "nAUC_mrr_max": 0.560267,
        "nAUC_mrr_std": 0.392221,
        "nAUC_mrr_diff1": 0.812803,
        "main_score": 0.891594,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.931171,
        "mrr": 0.931171,
        "nAUC_map_max": 0.44531,
        "nAUC_map_std": 0.24551,
        "nAUC_map_diff1": 0.837629,
        "nAUC_mrr_max": 0.44531,
        "nAUC_mrr_std": 0.24551,
        "nAUC_mrr_diff1": 0.837629,
        "main_score": 0.931171,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.878014,
        "mrr": 0.879023,
        "nAUC_map_max": 0.478428,
        "nAUC_map_std": 0.296064,
        "nAUC_map_diff1": 0.833259,
        "nAUC_mrr_max": 0.482976,
        "nAUC_mrr_std": 0.30212,
        "nAUC_mrr_diff1": 0.8309,
        "main_score": 0.878014,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.91144,
        "mrr": 0.91144,
        "nAUC_map_max": 0.506051,
        "nAUC_map_std": 0.318697,
        "nAUC_map_diff1": 0.82167,
        "nAUC_mrr_max": 0.506051,
        "nAUC_mrr_std": 0.318697,
        "nAUC_mrr_diff1": 0.82167,
        "main_score": 0.91144,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.905719,
        "mrr": 0.906052,
        "nAUC_map_max": 0.449092,
        "nAUC_map_std": 0.247827,
        "nAUC_map_diff1": 0.825081,
        "nAUC_mrr_max": 0.447869,
        "nAUC_mrr_std": 0.255036,
        "nAUC_mrr_diff1": 0.824039,
        "main_score": 0.905719,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.899303,
        "mrr": 0.899303,
        "nAUC_map_max": 0.467261,
        "nAUC_map_std": 0.253797,
        "nAUC_map_diff1": 0.794612,
        "nAUC_mrr_max": 0.467261,
        "nAUC_mrr_std": 0.253797,
        "nAUC_mrr_diff1": 0.794612,
        "main_score": 0.899303,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.911844,
        "mrr": 0.912177,
        "nAUC_map_max": 0.46908,
        "nAUC_map_std": 0.344986,
        "nAUC_map_diff1": 0.844196,
        "nAUC_mrr_max": 0.466759,
        "nAUC_mrr_std": 0.344758,
        "nAUC_mrr_diff1": 0.843153,
        "main_score": 0.911844,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.921712,
        "mrr": 0.922046,
        "nAUC_map_max": 0.460669,
        "nAUC_map_std": 0.311764,
        "nAUC_map_diff1": 0.854127,
        "nAUC_mrr_max": 0.463166,
        "nAUC_mrr_std": 0.320545,
        "nAUC_mrr_diff1": 0.853003,
        "main_score": 0.921712,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.903349,
        "mrr": 0.903349,
        "nAUC_map_max": 0.500027,
        "nAUC_map_std": 0.275412,
        "nAUC_map_diff1": 0.825346,
        "nAUC_mrr_max": 0.500027,
        "nAUC_mrr_std": 0.275412,
        "nAUC_mrr_diff1": 0.825346,
        "main_score": 0.903349,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.925163,
        "mrr": 0.925163,
        "nAUC_map_max": 0.4391,
        "nAUC_map_std": 0.225034,
        "nAUC_map_diff1": 0.847249,
        "nAUC_mrr_max": 0.4391,
        "nAUC_mrr_std": 0.225034,
        "nAUC_mrr_diff1": 0.847249,
        "main_score": 0.925163,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 4961.323037385941,
  "kg_co2_emissions": null
}