{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.990973,
        "recall": 0.993982,
        "f1": 0.991976,
        "accuracy": 0.993982,
        "main_score": 0.991976,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.971414,
        "recall": 0.980943,
        "f1": 0.97459,
        "accuracy": 0.980943,
        "main_score": 0.97459,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.969325,
        "recall": 0.977934,
        "f1": 0.971983,
        "accuracy": 0.977934,
        "main_score": 0.971983,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.920177,
        "recall": 0.944835,
        "f1": 0.928017,
        "accuracy": 0.944835,
        "main_score": 0.928017,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.996991,
        "recall": 0.997994,
        "f1": 0.997325,
        "accuracy": 0.997994,
        "main_score": 0.997325,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.983785,
        "recall": 0.988967,
        "f1": 0.985456,
        "accuracy": 0.988967,
        "main_score": 0.985456,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.932414,
        "recall": 0.951856,
        "f1": 0.938382,
        "accuracy": 0.951856,
        "main_score": 0.938382,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.888031,
        "recall": 0.921765,
        "f1": 0.898629,
        "accuracy": 0.921765,
        "main_score": 0.898629,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.765384,
        "recall": 0.814443,
        "f1": 0.778722,
        "accuracy": 0.814443,
        "main_score": 0.778722,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.738893,
        "recall": 0.807422,
        "f1": 0.759882,
        "accuracy": 0.807422,
        "main_score": 0.759882,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.954062,
        "recall": 0.966901,
        "f1": 0.95784,
        "accuracy": 0.966901,
        "main_score": 0.95784,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.917753,
        "recall": 0.943831,
        "f1": 0.926112,
        "accuracy": 0.943831,
        "main_score": 0.926112,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.916667,
        "recall": 0.940822,
        "f1": 0.924125,
        "accuracy": 0.940822,
        "main_score": 0.924125,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.872818,
        "recall": 0.911735,
        "f1": 0.884988,
        "accuracy": 0.911735,
        "main_score": 0.884988,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.979605,
        "recall": 0.985958,
        "f1": 0.981612,
        "accuracy": 0.985958,
        "main_score": 0.981612,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.927817,
        "recall": 0.94985,
        "f1": 0.934804,
        "accuracy": 0.94985,
        "main_score": 0.934804,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.995486,
        "recall": 0.996991,
        "f1": 0.995988,
        "accuracy": 0.996991,
        "main_score": 0.995988,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.967235,
        "recall": 0.977934,
        "f1": 0.970746,
        "accuracy": 0.977934,
        "main_score": 0.970746,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.916249,
        "recall": 0.937813,
        "f1": 0.922583,
        "accuracy": 0.937813,
        "main_score": 0.922583,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.850719,
        "recall": 0.89669,
        "f1": 0.865229,
        "accuracy": 0.89669,
        "main_score": 0.865229,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.964536,
        "recall": 0.974925,
        "f1": 0.96782,
        "accuracy": 0.974925,
        "main_score": 0.96782,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.946506,
        "recall": 0.963892,
        "f1": 0.95219,
        "accuracy": 0.963892,
        "main_score": 0.95219,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.96899,
        "recall": 0.977934,
        "f1": 0.971815,
        "accuracy": 0.977934,
        "main_score": 0.971815,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.948847,
        "recall": 0.964895,
        "f1": 0.954029,
        "accuracy": 0.964895,
        "main_score": 0.954029,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.627247,
        "recall": 0.682046,
        "f1": 0.640691,
        "accuracy": 0.682046,
        "main_score": 0.640691,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.591584,
        "recall": 0.689067,
        "f1": 0.618728,
        "accuracy": 0.689067,
        "main_score": 0.618728,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.863954,
        "recall": 0.894684,
        "f1": 0.872888,
        "accuracy": 0.894684,
        "main_score": 0.872888,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.787204,
        "recall": 0.848546,
        "f1": 0.805734,
        "accuracy": 0.848546,
        "main_score": 0.805734,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.894577,
        "recall": 0.925777,
        "f1": 0.904363,
        "accuracy": 0.925777,
        "main_score": 0.904363,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.818489,
        "recall": 0.872618,
        "f1": 0.835139,
        "accuracy": 0.872618,
        "main_score": 0.835139,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.90097,
        "recall": 0.928786,
        "f1": 0.909194,
        "accuracy": 0.928786,
        "main_score": 0.909194,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.800485,
        "recall": 0.858576,
        "f1": 0.818441,
        "accuracy": 0.858576,
        "main_score": 0.818441,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.983283,
        "recall": 0.987964,
        "f1": 0.984788,
        "accuracy": 0.987964,
        "main_score": 0.984788,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.97225,
        "recall": 0.97994,
        "f1": 0.974758,
        "accuracy": 0.97994,
        "main_score": 0.974758,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.984203,
        "recall": 0.988967,
        "f1": 0.98569,
        "accuracy": 0.988967,
        "main_score": 0.98569,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.963474,
        "recall": 0.974925,
        "f1": 0.967135,
        "accuracy": 0.974925,
        "main_score": 0.967135,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.038947,
        "recall": 0.060181,
        "f1": 0.042196,
        "accuracy": 0.060181,
        "main_score": 0.042196,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.044587,
        "recall": 0.088265,
        "f1": 0.051858,
        "accuracy": 0.088265,
        "main_score": 0.051858,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.335187,
        "recall": 0.373119,
        "f1": 0.34508,
        "accuracy": 0.373119,
        "main_score": 0.34508,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.274887,
        "recall": 0.398195,
        "f1": 0.304396,
        "accuracy": 0.398195,
        "main_score": 0.304396,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.970328,
        "recall": 0.977934,
        "f1": 0.972436,
        "accuracy": 0.977934,
        "main_score": 0.972436,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.942828,
        "recall": 0.961886,
        "f1": 0.949181,
        "accuracy": 0.961886,
        "main_score": 0.949181,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.840024,
        "recall": 0.874624,
        "f1": 0.849686,
        "accuracy": 0.874624,
        "main_score": 0.849686,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.770846,
        "recall": 0.838516,
        "f1": 0.791594,
        "accuracy": 0.838516,
        "main_score": 0.791594,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.965313,
        "recall": 0.974925,
        "f1": 0.968138,
        "accuracy": 0.974925,
        "main_score": 0.968138,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.928118,
        "recall": 0.950853,
        "f1": 0.935473,
        "accuracy": 0.950853,
        "main_score": 0.935473,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.977014,
        "recall": 0.983952,
        "f1": 0.979171,
        "accuracy": 0.983952,
        "main_score": 0.979171,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.938148,
        "recall": 0.957874,
        "f1": 0.9445,
        "accuracy": 0.957874,
        "main_score": 0.9445,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.989803,
        "recall": 0.992979,
        "f1": 0.990806,
        "accuracy": 0.992979,
        "main_score": 0.990806,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.959044,
        "recall": 0.971916,
        "f1": 0.963223,
        "accuracy": 0.971916,
        "main_score": 0.963223,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.413613,
        "recall": 0.451354,
        "f1": 0.423147,
        "accuracy": 0.451354,
        "main_score": 0.423147,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.350592,
        "recall": 0.485456,
        "f1": 0.385902,
        "accuracy": 0.485456,
        "main_score": 0.385902,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.985289,
        "recall": 0.98997,
        "f1": 0.986794,
        "accuracy": 0.98997,
        "main_score": 0.986794,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.935807,
        "recall": 0.956871,
        "f1": 0.942828,
        "accuracy": 0.956871,
        "main_score": 0.942828,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.983032,
        "recall": 0.987964,
        "f1": 0.98452,
        "accuracy": 0.987964,
        "main_score": 0.98452,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.953694,
        "recall": 0.968907,
        "f1": 0.958709,
        "accuracy": 0.968907,
        "main_score": 0.958709,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.005026,
        "recall": 0.01003,
        "f1": 0.00555,
        "accuracy": 0.01003,
        "main_score": 0.00555,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010342,
        "recall": 0.029087,
        "f1": 0.012464,
        "accuracy": 0.029087,
        "main_score": 0.012464,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.995553,
        "recall": 0.997036,
        "f1": 0.996047,
        "accuracy": 0.997036,
        "main_score": 0.996047,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.980731,
        "recall": 0.987154,
        "f1": 0.982872,
        "accuracy": 0.987154,
        "main_score": 0.982872,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.962451,
        "recall": 0.974308,
        "f1": 0.966238,
        "accuracy": 0.974308,
        "main_score": 0.966238,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.917655,
        "recall": 0.943676,
        "f1": 0.926054,
        "accuracy": 0.943676,
        "main_score": 0.926054,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.992589,
        "recall": 0.995059,
        "f1": 0.993412,
        "accuracy": 0.995059,
        "main_score": 0.993412,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.938933,
        "recall": 0.956522,
        "f1": 0.944302,
        "accuracy": 0.956522,
        "main_score": 0.944302,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.884058,
        "recall": 0.91996,
        "f1": 0.895389,
        "accuracy": 0.91996,
        "main_score": 0.895389,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.818046,
        "recall": 0.860672,
        "f1": 0.830247,
        "accuracy": 0.860672,
        "main_score": 0.830247,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.727282,
        "recall": 0.796443,
        "f1": 0.747301,
        "accuracy": 0.796443,
        "main_score": 0.747301,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.961957,
        "recall": 0.974308,
        "f1": 0.966074,
        "accuracy": 0.974308,
        "main_score": 0.966074,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.904809,
        "recall": 0.935771,
        "f1": 0.91502,
        "accuracy": 0.935771,
        "main_score": 0.91502,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.91082,
        "recall": 0.937747,
        "f1": 0.919203,
        "accuracy": 0.937747,
        "main_score": 0.919203,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.86553,
        "recall": 0.908103,
        "f1": 0.879183,
        "accuracy": 0.908103,
        "main_score": 0.879183,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.987401,
        "recall": 0.991107,
        "f1": 0.988538,
        "accuracy": 0.991107,
        "main_score": 0.988538,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.934206,
        "recall": 0.954545,
        "f1": 0.940613,
        "accuracy": 0.954545,
        "main_score": 0.940613,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.995553,
        "recall": 0.997036,
        "f1": 0.996047,
        "accuracy": 0.997036,
        "main_score": 0.996047,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.991436,
        "recall": 0.994071,
        "f1": 0.99226,
        "accuracy": 0.994071,
        "main_score": 0.99226,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.919829,
        "recall": 0.942688,
        "f1": 0.92668,
        "accuracy": 0.942688,
        "main_score": 0.92668,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.870224,
        "recall": 0.910079,
        "f1": 0.882708,
        "accuracy": 0.910079,
        "main_score": 0.882708,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.981061,
        "recall": 0.987154,
        "f1": 0.983037,
        "accuracy": 0.987154,
        "main_score": 0.983037,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.953557,
        "recall": 0.968379,
        "f1": 0.958333,
        "accuracy": 0.968379,
        "main_score": 0.958333,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.980731,
        "recall": 0.986166,
        "f1": 0.982378,
        "accuracy": 0.986166,
        "main_score": 0.982378,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.943017,
        "recall": 0.960474,
        "f1": 0.948584,
        "accuracy": 0.960474,
        "main_score": 0.948584,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.613462,
        "recall": 0.675889,
        "f1": 0.629682,
        "accuracy": 0.675889,
        "main_score": 0.629682,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.591732,
        "recall": 0.692688,
        "f1": 0.620253,
        "accuracy": 0.692688,
        "main_score": 0.620253,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.865629,
        "recall": 0.899209,
        "f1": 0.875659,
        "accuracy": 0.899209,
        "main_score": 0.875659,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.78083,
        "recall": 0.842885,
        "f1": 0.799741,
        "accuracy": 0.842885,
        "main_score": 0.799741,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.904044,
        "recall": 0.93083,
        "f1": 0.912368,
        "accuracy": 0.93083,
        "main_score": 0.912368,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.826449,
        "recall": 0.878458,
        "f1": 0.842688,
        "accuracy": 0.878458,
        "main_score": 0.842688,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.908663,
        "recall": 0.933794,
        "f1": 0.916107,
        "accuracy": 0.933794,
        "main_score": 0.916107,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.834025,
        "recall": 0.883399,
        "f1": 0.849242,
        "accuracy": 0.883399,
        "main_score": 0.849242,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.983531,
        "recall": 0.988142,
        "f1": 0.985013,
        "accuracy": 0.988142,
        "main_score": 0.985013,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.97365,
        "recall": 0.981225,
        "f1": 0.97612,
        "accuracy": 0.981225,
        "main_score": 0.97612,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.997036,
        "recall": 0.998024,
        "f1": 0.997365,
        "accuracy": 0.998024,
        "main_score": 0.997365,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.976285,
        "recall": 0.98419,
        "f1": 0.97892,
        "accuracy": 0.98419,
        "main_score": 0.97892,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.051016,
        "recall": 0.071146,
        "f1": 0.055359,
        "accuracy": 0.071146,
        "main_score": 0.055359,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.03893,
        "recall": 0.088933,
        "f1": 0.04824,
        "accuracy": 0.088933,
        "main_score": 0.04824,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.300655,
        "recall": 0.34585,
        "f1": 0.311734,
        "accuracy": 0.34585,
        "main_score": 0.311734,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.281901,
        "recall": 0.398221,
        "f1": 0.310009,
        "accuracy": 0.398221,
        "main_score": 0.310009,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.985507,
        "recall": 0.990119,
        "f1": 0.986989,
        "accuracy": 0.990119,
        "main_score": 0.986989,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.952899,
        "recall": 0.968379,
        "f1": 0.958004,
        "accuracy": 0.968379,
        "main_score": 0.958004,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.888982,
        "recall": 0.917984,
        "f1": 0.897454,
        "accuracy": 0.917984,
        "main_score": 0.897454,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.812533,
        "recall": 0.870553,
        "f1": 0.830929,
        "accuracy": 0.870553,
        "main_score": 0.830929,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.975132,
        "recall": 0.983202,
        "f1": 0.977767,
        "accuracy": 0.983202,
        "main_score": 0.977767,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.951416,
        "recall": 0.966403,
        "f1": 0.956192,
        "accuracy": 0.966403,
        "main_score": 0.956192,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.994071,
        "recall": 0.996047,
        "f1": 0.99473,
        "accuracy": 0.996047,
        "main_score": 0.99473,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.956192,
        "recall": 0.970356,
        "f1": 0.960804,
        "accuracy": 0.970356,
        "main_score": 0.960804,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.992589,
        "recall": 0.995059,
        "f1": 0.993412,
        "accuracy": 0.995059,
        "main_score": 0.993412,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.974802,
        "recall": 0.983202,
        "f1": 0.977602,
        "accuracy": 0.983202,
        "main_score": 0.977602,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.405871,
        "recall": 0.44664,
        "f1": 0.416101,
        "accuracy": 0.44664,
        "main_score": 0.416101,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.357116,
        "recall": 0.480237,
        "f1": 0.388128,
        "accuracy": 0.480237,
        "main_score": 0.388128,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.985178,
        "recall": 0.990119,
        "f1": 0.986825,
        "accuracy": 0.990119,
        "main_score": 0.986825,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.953557,
        "recall": 0.968379,
        "f1": 0.958333,
        "accuracy": 0.968379,
        "main_score": 0.958333,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.986989,
        "recall": 0.991107,
        "f1": 0.988307,
        "accuracy": 0.991107,
        "main_score": 0.988307,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.969203,
        "recall": 0.979249,
        "f1": 0.972497,
        "accuracy": 0.979249,
        "main_score": 0.972497,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.015963,
        "recall": 0.020751,
        "f1": 0.016425,
        "accuracy": 0.020751,
        "main_score": 0.016425,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014803,
        "recall": 0.037549,
        "f1": 0.018026,
        "accuracy": 0.037549,
        "main_score": 0.018026,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 8003.843384742737,
  "kg_co2_emissions": null
}