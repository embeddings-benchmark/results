{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.468783,
        "recall": 0.558594,
        "f1": 0.49128,
        "accuracy": 0.558594,
        "main_score": 0.49128,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.952474,
        "recall": 0.966797,
        "f1": 0.957031,
        "accuracy": 0.966797,
        "main_score": 0.957031,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.978467,
        "recall": 0.984375,
        "f1": 0.980208,
        "accuracy": 0.984375,
        "main_score": 0.980208,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.906087,
        "recall": 0.931641,
        "f1": 0.914062,
        "accuracy": 0.931641,
        "main_score": 0.914062,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.963704,
        "recall": 0.974609,
        "f1": 0.967122,
        "accuracy": 0.974609,
        "main_score": 0.967122,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.972168,
        "recall": 0.980469,
        "f1": 0.974772,
        "accuracy": 0.980469,
        "main_score": 0.974772,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.828619,
        "recall": 0.870117,
        "f1": 0.840988,
        "accuracy": 0.870117,
        "main_score": 0.840988,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.858366,
        "recall": 0.895508,
        "f1": 0.869727,
        "accuracy": 0.895508,
        "main_score": 0.869727,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.978353,
        "recall": 0.985352,
        "f1": 0.980632,
        "accuracy": 0.985352,
        "main_score": 0.980632,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003012,
        "recall": 0.008789,
        "f1": 0.003546,
        "accuracy": 0.008789,
        "main_score": 0.003546,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.840504,
        "recall": 0.879883,
        "f1": 0.85223,
        "accuracy": 0.879883,
        "main_score": 0.85223,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.872803,
        "recall": 0.910156,
        "f1": 0.884621,
        "accuracy": 0.910156,
        "main_score": 0.884621,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.954508,
        "recall": 0.96875,
        "f1": 0.959049,
        "accuracy": 0.96875,
        "main_score": 0.959049,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005258,
        "recall": 0.016602,
        "f1": 0.006882,
        "accuracy": 0.016602,
        "main_score": 0.006882,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.84145,
        "recall": 0.880859,
        "f1": 0.853078,
        "accuracy": 0.880859,
        "main_score": 0.853078,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.947428,
        "recall": 0.962891,
        "f1": 0.952474,
        "accuracy": 0.962891,
        "main_score": 0.952474,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.975098,
        "recall": 0.983398,
        "f1": 0.977865,
        "accuracy": 0.983398,
        "main_score": 0.977865,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.984212,
        "recall": 0.989258,
        "f1": 0.98584,
        "accuracy": 0.989258,
        "main_score": 0.98584,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.471644,
        "recall": 0.556641,
        "f1": 0.4924,
        "accuracy": 0.556641,
        "main_score": 0.4924,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.953483,
        "recall": 0.967773,
        "f1": 0.958008,
        "accuracy": 0.967773,
        "main_score": 0.958008,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.904704,
        "recall": 0.933594,
        "f1": 0.913639,
        "accuracy": 0.933594,
        "main_score": 0.913639,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.967448,
        "recall": 0.977539,
        "f1": 0.970703,
        "accuracy": 0.977539,
        "main_score": 0.970703,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.97041,
        "recall": 0.979492,
        "f1": 0.973307,
        "accuracy": 0.979492,
        "main_score": 0.973307,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.836084,
        "recall": 0.87793,
        "f1": 0.848261,
        "accuracy": 0.87793,
        "main_score": 0.848261,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.853037,
        "recall": 0.893555,
        "f1": 0.865237,
        "accuracy": 0.893555,
        "main_score": 0.865237,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.981283,
        "recall": 0.987305,
        "f1": 0.983236,
        "accuracy": 0.987305,
        "main_score": 0.983236,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004156,
        "recall": 0.010742,
        "f1": 0.004796,
        "accuracy": 0.010742,
        "main_score": 0.004796,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.829031,
        "recall": 0.870117,
        "f1": 0.840969,
        "accuracy": 0.870117,
        "main_score": 0.840969,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.876709,
        "recall": 0.914062,
        "f1": 0.888249,
        "accuracy": 0.914062,
        "main_score": 0.888249,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.965495,
        "recall": 0.976562,
        "f1": 0.969076,
        "accuracy": 0.976562,
        "main_score": 0.969076,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005935,
        "recall": 0.017578,
        "f1": 0.007088,
        "accuracy": 0.017578,
        "main_score": 0.007088,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.85459,
        "recall": 0.888672,
        "f1": 0.864195,
        "accuracy": 0.888672,
        "main_score": 0.864195,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.951986,
        "recall": 0.966797,
        "f1": 0.956706,
        "accuracy": 0.966797,
        "main_score": 0.956706,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.98584,
        "recall": 0.990234,
        "f1": 0.987305,
        "accuracy": 0.990234,
        "main_score": 0.987305,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.495671,
        "recall": 0.53418,
        "f1": 0.505224,
        "accuracy": 0.53418,
        "main_score": 0.505224,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.499224,
        "recall": 0.536133,
        "f1": 0.509264,
        "accuracy": 0.536133,
        "main_score": 0.509264,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.483542,
        "recall": 0.519531,
        "f1": 0.492244,
        "accuracy": 0.519531,
        "main_score": 0.492244,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.435162,
        "recall": 0.474609,
        "f1": 0.444335,
        "accuracy": 0.474609,
        "main_score": 0.444335,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.487746,
        "recall": 0.53125,
        "f1": 0.497907,
        "accuracy": 0.53125,
        "main_score": 0.497907,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.480593,
        "recall": 0.517578,
        "f1": 0.490181,
        "accuracy": 0.517578,
        "main_score": 0.490181,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.480702,
        "recall": 0.518555,
        "f1": 0.489619,
        "accuracy": 0.518555,
        "main_score": 0.489619,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.468894,
        "recall": 0.510742,
        "f1": 0.479735,
        "accuracy": 0.510742,
        "main_score": 0.479735,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.459176,
        "recall": 0.494141,
        "f1": 0.467102,
        "accuracy": 0.494141,
        "main_score": 0.467102,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.478195,
        "recall": 0.518555,
        "f1": 0.487763,
        "accuracy": 0.518555,
        "main_score": 0.487763,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.443248,
        "recall": 0.490234,
        "f1": 0.456091,
        "accuracy": 0.490234,
        "main_score": 0.456091,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.455488,
        "recall": 0.494141,
        "f1": 0.465028,
        "accuracy": 0.494141,
        "main_score": 0.465028,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004406,
        "recall": 0.007812,
        "f1": 0.004738,
        "accuracy": 0.007812,
        "main_score": 0.004738,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.496528,
        "recall": 0.53418,
        "f1": 0.504978,
        "accuracy": 0.53418,
        "main_score": 0.504978,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.416305,
        "recall": 0.463867,
        "f1": 0.428658,
        "accuracy": 0.463867,
        "main_score": 0.428658,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.461888,
        "recall": 0.503906,
        "f1": 0.472274,
        "accuracy": 0.503906,
        "main_score": 0.472274,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.490209,
        "recall": 0.53418,
        "f1": 0.501319,
        "accuracy": 0.53418,
        "main_score": 0.501319,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00569,
        "recall": 0.012695,
        "f1": 0.007001,
        "accuracy": 0.012695,
        "main_score": 0.007001,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.502498,
        "recall": 0.540039,
        "f1": 0.51176,
        "accuracy": 0.540039,
        "main_score": 0.51176,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.410619,
        "recall": 0.456055,
        "f1": 0.422579,
        "accuracy": 0.456055,
        "main_score": 0.422579,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.47682,
        "recall": 0.515625,
        "f1": 0.48648,
        "accuracy": 0.515625,
        "main_score": 0.48648,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.442324,
        "recall": 0.477539,
        "f1": 0.451326,
        "accuracy": 0.477539,
        "main_score": 0.451326,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.958659,
        "recall": 0.969727,
        "f1": 0.96203,
        "accuracy": 0.969727,
        "main_score": 0.96203,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.968669,
        "recall": 0.977539,
        "f1": 0.971419,
        "accuracy": 0.977539,
        "main_score": 0.971419,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.504835,
        "recall": 0.584961,
        "f1": 0.526038,
        "accuracy": 0.584961,
        "main_score": 0.526038,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.95791,
        "recall": 0.969727,
        "f1": 0.961426,
        "accuracy": 0.969727,
        "main_score": 0.961426,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.915771,
        "recall": 0.94043,
        "f1": 0.923405,
        "accuracy": 0.94043,
        "main_score": 0.923405,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.948079,
        "recall": 0.962891,
        "f1": 0.952753,
        "accuracy": 0.962891,
        "main_score": 0.952753,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.984375,
        "recall": 0.989258,
        "f1": 0.986003,
        "accuracy": 0.989258,
        "main_score": 0.986003,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.943229,
        "recall": 0.959961,
        "f1": 0.948372,
        "accuracy": 0.959961,
        "main_score": 0.948372,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.86984,
        "recall": 0.902344,
        "f1": 0.879637,
        "accuracy": 0.902344,
        "main_score": 0.879637,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.97876,
        "recall": 0.985352,
        "f1": 0.980859,
        "accuracy": 0.985352,
        "main_score": 0.980859,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.838216,
        "recall": 0.87793,
        "f1": 0.850265,
        "accuracy": 0.87793,
        "main_score": 0.850265,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.970378,
        "recall": 0.978516,
        "f1": 0.972982,
        "accuracy": 0.978516,
        "main_score": 0.972982,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003137,
        "recall": 0.006836,
        "f1": 0.003309,
        "accuracy": 0.006836,
        "main_score": 0.003309,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.980225,
        "recall": 0.986328,
        "f1": 0.982161,
        "accuracy": 0.986328,
        "main_score": 0.982161,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.79637,
        "recall": 0.841797,
        "f1": 0.809862,
        "accuracy": 0.841797,
        "main_score": 0.809862,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.905924,
        "recall": 0.932617,
        "f1": 0.914179,
        "accuracy": 0.932617,
        "main_score": 0.914179,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.942871,
        "recall": 0.958984,
        "f1": 0.948079,
        "accuracy": 0.958984,
        "main_score": 0.948079,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006805,
        "recall": 0.020508,
        "f1": 0.008496,
        "accuracy": 0.020508,
        "main_score": 0.008496,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.900228,
        "recall": 0.927734,
        "f1": 0.908659,
        "accuracy": 0.927734,
        "main_score": 0.908659,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.891227,
        "recall": 0.920898,
        "f1": 0.900098,
        "accuracy": 0.920898,
        "main_score": 0.900098,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.95109,
        "recall": 0.96582,
        "f1": 0.955632,
        "accuracy": 0.96582,
        "main_score": 0.955632,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.981201,
        "recall": 0.986328,
        "f1": 0.982812,
        "accuracy": 0.986328,
        "main_score": 0.982812,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.976888,
        "recall": 0.984375,
        "f1": 0.979329,
        "accuracy": 0.984375,
        "main_score": 0.979329,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.422936,
        "recall": 0.527344,
        "f1": 0.449509,
        "accuracy": 0.527344,
        "main_score": 0.449509,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.946452,
        "recall": 0.963867,
        "f1": 0.952148,
        "accuracy": 0.963867,
        "main_score": 0.952148,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.862386,
        "recall": 0.90332,
        "f1": 0.875065,
        "accuracy": 0.90332,
        "main_score": 0.875065,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.957601,
        "recall": 0.970703,
        "f1": 0.961816,
        "accuracy": 0.970703,
        "main_score": 0.961816,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.955892,
        "recall": 0.969727,
        "f1": 0.960286,
        "accuracy": 0.969727,
        "main_score": 0.960286,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.844271,
        "recall": 0.890625,
        "f1": 0.859017,
        "accuracy": 0.890625,
        "main_score": 0.859017,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.981608,
        "recall": 0.987305,
        "f1": 0.983398,
        "accuracy": 0.987305,
        "main_score": 0.983398,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.850586,
        "recall": 0.893555,
        "f1": 0.863821,
        "accuracy": 0.893555,
        "main_score": 0.863821,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.974447,
        "recall": 0.982422,
        "f1": 0.977051,
        "accuracy": 0.982422,
        "main_score": 0.977051,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001901,
        "recall": 0.005859,
        "f1": 0.002326,
        "accuracy": 0.005859,
        "main_score": 0.002326,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.988932,
        "recall": 0.992188,
        "f1": 0.989909,
        "accuracy": 0.992188,
        "main_score": 0.989909,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.717816,
        "recall": 0.786133,
        "f1": 0.737522,
        "accuracy": 0.786133,
        "main_score": 0.737522,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.852979,
        "recall": 0.895508,
        "f1": 0.866243,
        "accuracy": 0.895508,
        "main_score": 0.866243,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.952637,
        "recall": 0.967773,
        "f1": 0.95752,
        "accuracy": 0.967773,
        "main_score": 0.95752,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.0049,
        "recall": 0.014648,
        "f1": 0.006082,
        "accuracy": 0.014648,
        "main_score": 0.006082,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.830769,
        "recall": 0.876953,
        "f1": 0.844666,
        "accuracy": 0.876953,
        "main_score": 0.844666,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.939616,
        "recall": 0.958984,
        "f1": 0.945964,
        "accuracy": 0.958984,
        "main_score": 0.945964,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.905859,
        "recall": 0.928711,
        "f1": 0.912547,
        "accuracy": 0.928711,
        "main_score": 0.912547,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.917529,
        "recall": 0.938477,
        "f1": 0.923745,
        "accuracy": 0.938477,
        "main_score": 0.923745,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.484672,
        "recall": 0.557617,
        "f1": 0.502833,
        "accuracy": 0.557617,
        "main_score": 0.502833,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.902051,
        "recall": 0.926758,
        "f1": 0.909635,
        "accuracy": 0.926758,
        "main_score": 0.909635,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.870903,
        "recall": 0.900391,
        "f1": 0.879413,
        "accuracy": 0.900391,
        "main_score": 0.879413,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.909077,
        "recall": 0.931641,
        "f1": 0.915788,
        "accuracy": 0.931641,
        "main_score": 0.915788,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.923706,
        "recall": 0.943359,
        "f1": 0.929435,
        "accuracy": 0.943359,
        "main_score": 0.929435,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.904093,
        "recall": 0.927734,
        "f1": 0.9111,
        "accuracy": 0.927734,
        "main_score": 0.9111,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.782072,
        "recall": 0.826172,
        "f1": 0.794568,
        "accuracy": 0.826172,
        "main_score": 0.794568,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.935335,
        "recall": 0.953125,
        "f1": 0.94082,
        "accuracy": 0.953125,
        "main_score": 0.94082,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.776371,
        "recall": 0.819336,
        "f1": 0.788615,
        "accuracy": 0.819336,
        "main_score": 0.788615,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.958455,
        "recall": 0.969727,
        "f1": 0.961968,
        "accuracy": 0.969727,
        "main_score": 0.961968,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001861,
        "recall": 0.005859,
        "f1": 0.002616,
        "accuracy": 0.005859,
        "main_score": 0.002616,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.928011,
        "recall": 0.948242,
        "f1": 0.934147,
        "accuracy": 0.948242,
        "main_score": 0.934147,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.713451,
        "recall": 0.768555,
        "f1": 0.728707,
        "accuracy": 0.768555,
        "main_score": 0.728707,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.794124,
        "recall": 0.848633,
        "f1": 0.810649,
        "accuracy": 0.848633,
        "main_score": 0.810649,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.885368,
        "recall": 0.917969,
        "f1": 0.89554,
        "accuracy": 0.917969,
        "main_score": 0.89554,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.007609,
        "recall": 0.021484,
        "f1": 0.009648,
        "accuracy": 0.021484,
        "main_score": 0.009648,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.802254,
        "recall": 0.847656,
        "f1": 0.815633,
        "accuracy": 0.847656,
        "main_score": 0.815633,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.850666,
        "recall": 0.885742,
        "f1": 0.860793,
        "accuracy": 0.885742,
        "main_score": 0.860793,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.898682,
        "recall": 0.924805,
        "f1": 0.906399,
        "accuracy": 0.924805,
        "main_score": 0.906399,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.891878,
        "recall": 0.916016,
        "f1": 0.898625,
        "accuracy": 0.916016,
        "main_score": 0.898625,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.966309,
        "recall": 0.976562,
        "f1": 0.969564,
        "accuracy": 0.976562,
        "main_score": 0.969564,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.977051,
        "recall": 0.984375,
        "f1": 0.979492,
        "accuracy": 0.984375,
        "main_score": 0.979492,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.441021,
        "recall": 0.518555,
        "f1": 0.460205,
        "accuracy": 0.518555,
        "main_score": 0.460205,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.952507,
        "recall": 0.966797,
        "f1": 0.957031,
        "accuracy": 0.966797,
        "main_score": 0.957031,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.955485,
        "recall": 0.96875,
        "f1": 0.959654,
        "accuracy": 0.96875,
        "main_score": 0.959654,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.912028,
        "recall": 0.939453,
        "f1": 0.920964,
        "accuracy": 0.939453,
        "main_score": 0.920964,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.982747,
        "recall": 0.988281,
        "f1": 0.984538,
        "accuracy": 0.988281,
        "main_score": 0.984538,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.963135,
        "recall": 0.974609,
        "f1": 0.966862,
        "accuracy": 0.974609,
        "main_score": 0.966862,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.814608,
        "recall": 0.860352,
        "f1": 0.828018,
        "accuracy": 0.860352,
        "main_score": 0.828018,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.969727,
        "recall": 0.979492,
        "f1": 0.972982,
        "accuracy": 0.979492,
        "main_score": 0.972982,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.872795,
        "recall": 0.905273,
        "f1": 0.882737,
        "accuracy": 0.905273,
        "main_score": 0.882737,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.971029,
        "recall": 0.980469,
        "f1": 0.974121,
        "accuracy": 0.980469,
        "main_score": 0.974121,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003293,
        "recall": 0.010742,
        "f1": 0.004023,
        "accuracy": 0.010742,
        "main_score": 0.004023,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.979818,
        "recall": 0.986328,
        "f1": 0.981934,
        "accuracy": 0.986328,
        "main_score": 0.981934,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.842701,
        "recall": 0.882812,
        "f1": 0.855094,
        "accuracy": 0.882812,
        "main_score": 0.855094,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.913851,
        "recall": 0.938477,
        "f1": 0.921289,
        "accuracy": 0.938477,
        "main_score": 0.921289,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.92863,
        "recall": 0.949219,
        "f1": 0.934961,
        "accuracy": 0.949219,
        "main_score": 0.934961,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.008582,
        "recall": 0.019531,
        "f1": 0.010114,
        "accuracy": 0.019531,
        "main_score": 0.010114,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.840626,
        "recall": 0.878906,
        "f1": 0.851345,
        "accuracy": 0.878906,
        "main_score": 0.851345,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.927116,
        "recall": 0.948242,
        "f1": 0.933594,
        "accuracy": 0.948242,
        "main_score": 0.933594,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.974121,
        "recall": 0.982422,
        "f1": 0.976888,
        "accuracy": 0.982422,
        "main_score": 0.976888,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.979085,
        "recall": 0.985352,
        "f1": 0.981022,
        "accuracy": 0.985352,
        "main_score": 0.981022,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.457416,
        "recall": 0.556641,
        "f1": 0.482601,
        "accuracy": 0.556641,
        "main_score": 0.482601,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.972168,
        "recall": 0.981445,
        "f1": 0.97526,
        "accuracy": 0.981445,
        "main_score": 0.97526,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.909749,
        "recall": 0.936523,
        "f1": 0.918197,
        "accuracy": 0.936523,
        "main_score": 0.918197,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.978027,
        "recall": 0.985352,
        "f1": 0.980469,
        "accuracy": 0.985352,
        "main_score": 0.980469,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.979085,
        "recall": 0.985352,
        "f1": 0.981022,
        "accuracy": 0.985352,
        "main_score": 0.981022,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.859635,
        "recall": 0.898438,
        "f1": 0.871387,
        "accuracy": 0.898438,
        "main_score": 0.871387,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.865885,
        "recall": 0.90332,
        "f1": 0.877479,
        "accuracy": 0.90332,
        "main_score": 0.877479,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001938,
        "recall": 0.005859,
        "f1": 0.002429,
        "accuracy": 0.005859,
        "main_score": 0.002429,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.814381,
        "recall": 0.861328,
        "f1": 0.828449,
        "accuracy": 0.861328,
        "main_score": 0.828449,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.914909,
        "recall": 0.939453,
        "f1": 0.922526,
        "accuracy": 0.939453,
        "main_score": 0.922526,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.970703,
        "recall": 0.980469,
        "f1": 0.973958,
        "accuracy": 0.980469,
        "main_score": 0.973958,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.010388,
        "recall": 0.024414,
        "f1": 0.012267,
        "accuracy": 0.024414,
        "main_score": 0.012267,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.877108,
        "recall": 0.910156,
        "f1": 0.886903,
        "accuracy": 0.910156,
        "main_score": 0.886903,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.956706,
        "recall": 0.970703,
        "f1": 0.961263,
        "accuracy": 0.970703,
        "main_score": 0.961263,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.974365,
        "recall": 0.982422,
        "f1": 0.976953,
        "accuracy": 0.982422,
        "main_score": 0.976953,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.444606,
        "recall": 0.521484,
        "f1": 0.463398,
        "accuracy": 0.521484,
        "main_score": 0.463398,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.941325,
        "recall": 0.959961,
        "f1": 0.947331,
        "accuracy": 0.959961,
        "main_score": 0.947331,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.969759,
        "recall": 0.978516,
        "f1": 0.972493,
        "accuracy": 0.978516,
        "main_score": 0.972493,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.910075,
        "recall": 0.9375,
        "f1": 0.918685,
        "accuracy": 0.9375,
        "main_score": 0.918685,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.969889,
        "recall": 0.978516,
        "f1": 0.972656,
        "accuracy": 0.978516,
        "main_score": 0.972656,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.985677,
        "recall": 0.990234,
        "f1": 0.987142,
        "accuracy": 0.990234,
        "main_score": 0.987142,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.81867,
        "recall": 0.858398,
        "f1": 0.830073,
        "accuracy": 0.858398,
        "main_score": 0.830073,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.978516,
        "recall": 0.985352,
        "f1": 0.980794,
        "accuracy": 0.985352,
        "main_score": 0.980794,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.862151,
        "recall": 0.900391,
        "f1": 0.873942,
        "accuracy": 0.900391,
        "main_score": 0.873942,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.981283,
        "recall": 0.987305,
        "f1": 0.983236,
        "accuracy": 0.987305,
        "main_score": 0.983236,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00229,
        "recall": 0.008789,
        "f1": 0.003013,
        "accuracy": 0.008789,
        "main_score": 0.003013,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.791032,
        "recall": 0.837891,
        "f1": 0.804594,
        "accuracy": 0.837891,
        "main_score": 0.804594,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.858887,
        "recall": 0.897461,
        "f1": 0.871061,
        "accuracy": 0.897461,
        "main_score": 0.871061,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.954183,
        "recall": 0.96875,
        "f1": 0.958887,
        "accuracy": 0.96875,
        "main_score": 0.958887,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00599,
        "recall": 0.018555,
        "f1": 0.007598,
        "accuracy": 0.018555,
        "main_score": 0.007598,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.820306,
        "recall": 0.861328,
        "f1": 0.832151,
        "accuracy": 0.861328,
        "main_score": 0.832151,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.951497,
        "recall": 0.966797,
        "f1": 0.956543,
        "accuracy": 0.966797,
        "main_score": 0.956543,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.981608,
        "recall": 0.987305,
        "f1": 0.983398,
        "accuracy": 0.987305,
        "main_score": 0.983398,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.867193,
        "recall": 0.899414,
        "f1": 0.876958,
        "accuracy": 0.899414,
        "main_score": 0.876958,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.885206,
        "recall": 0.911133,
        "f1": 0.892707,
        "accuracy": 0.911133,
        "main_score": 0.892707,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.475682,
        "recall": 0.555664,
        "f1": 0.497042,
        "accuracy": 0.555664,
        "main_score": 0.497042,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.887135,
        "recall": 0.914062,
        "f1": 0.895296,
        "accuracy": 0.914062,
        "main_score": 0.895296,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.863607,
        "recall": 0.895508,
        "f1": 0.872495,
        "accuracy": 0.895508,
        "main_score": 0.872495,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.797971,
        "recall": 0.845703,
        "f1": 0.812166,
        "accuracy": 0.845703,
        "main_score": 0.812166,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.839008,
        "recall": 0.875,
        "f1": 0.849422,
        "accuracy": 0.875,
        "main_score": 0.849422,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.894401,
        "recall": 0.917969,
        "f1": 0.90108,
        "accuracy": 0.917969,
        "main_score": 0.90108,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.859026,
        "recall": 0.890625,
        "f1": 0.868435,
        "accuracy": 0.890625,
        "main_score": 0.868435,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.90525,
        "recall": 0.930664,
        "f1": 0.913135,
        "accuracy": 0.930664,
        "main_score": 0.913135,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.742694,
        "recall": 0.795898,
        "f1": 0.757941,
        "accuracy": 0.795898,
        "main_score": 0.757941,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.867677,
        "recall": 0.896484,
        "f1": 0.875884,
        "accuracy": 0.896484,
        "main_score": 0.875884,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000722,
        "recall": 0.004883,
        "f1": 0.00118,
        "accuracy": 0.004883,
        "main_score": 0.00118,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.894517,
        "recall": 0.919922,
        "f1": 0.901745,
        "accuracy": 0.919922,
        "main_score": 0.901745,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.673224,
        "recall": 0.731445,
        "f1": 0.689782,
        "accuracy": 0.731445,
        "main_score": 0.689782,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.799326,
        "recall": 0.84668,
        "f1": 0.81336,
        "accuracy": 0.84668,
        "main_score": 0.81336,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.857699,
        "recall": 0.893555,
        "f1": 0.869043,
        "accuracy": 0.893555,
        "main_score": 0.869043,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.007727,
        "recall": 0.020508,
        "f1": 0.009582,
        "accuracy": 0.020508,
        "main_score": 0.009582,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.82545,
        "recall": 0.866211,
        "f1": 0.837584,
        "accuracy": 0.866211,
        "main_score": 0.837584,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.780319,
        "recall": 0.828125,
        "f1": 0.794665,
        "accuracy": 0.828125,
        "main_score": 0.794665,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.866147,
        "recall": 0.898438,
        "f1": 0.875675,
        "accuracy": 0.898438,
        "main_score": 0.875675,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.921183,
        "recall": 0.941406,
        "f1": 0.927463,
        "accuracy": 0.941406,
        "main_score": 0.927463,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.977051,
        "recall": 0.984375,
        "f1": 0.979492,
        "accuracy": 0.984375,
        "main_score": 0.979492,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.993001,
        "recall": 0.995117,
        "f1": 0.993652,
        "accuracy": 0.995117,
        "main_score": 0.993652,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.449298,
        "recall": 0.537109,
        "f1": 0.471047,
        "accuracy": 0.537109,
        "main_score": 0.471047,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.980143,
        "recall": 0.986328,
        "f1": 0.982096,
        "accuracy": 0.986328,
        "main_score": 0.982096,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.908854,
        "recall": 0.935547,
        "f1": 0.917122,
        "accuracy": 0.935547,
        "main_score": 0.917122,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.970378,
        "recall": 0.979492,
        "f1": 0.973307,
        "accuracy": 0.979492,
        "main_score": 0.973307,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.955762,
        "recall": 0.969727,
        "f1": 0.960286,
        "accuracy": 0.969727,
        "main_score": 0.960286,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.855766,
        "recall": 0.893555,
        "f1": 0.867285,
        "accuracy": 0.893555,
        "main_score": 0.867285,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.859158,
        "recall": 0.896484,
        "f1": 0.870364,
        "accuracy": 0.896484,
        "main_score": 0.870364,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.983236,
        "recall": 0.988281,
        "f1": 0.984863,
        "accuracy": 0.988281,
        "main_score": 0.984863,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004083,
        "recall": 0.011719,
        "f1": 0.004696,
        "accuracy": 0.011719,
        "main_score": 0.004696,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.83121,
        "recall": 0.875,
        "f1": 0.844273,
        "accuracy": 0.875,
        "main_score": 0.844273,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.896566,
        "recall": 0.927734,
        "f1": 0.906315,
        "accuracy": 0.927734,
        "main_score": 0.906315,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.958659,
        "recall": 0.97168,
        "f1": 0.962891,
        "accuracy": 0.97168,
        "main_score": 0.962891,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.008809,
        "recall": 0.023438,
        "f1": 0.010967,
        "accuracy": 0.023438,
        "main_score": 0.010967,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.885734,
        "recall": 0.915039,
        "f1": 0.894325,
        "accuracy": 0.915039,
        "main_score": 0.894325,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.922201,
        "recall": 0.946289,
        "f1": 0.92985,
        "accuracy": 0.946289,
        "main_score": 0.92985,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.973958,
        "recall": 0.982422,
        "f1": 0.976725,
        "accuracy": 0.982422,
        "main_score": 0.976725,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.874463,
        "recall": 0.90918,
        "f1": 0.885124,
        "accuracy": 0.90918,
        "main_score": 0.885124,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.887884,
        "recall": 0.916016,
        "f1": 0.896201,
        "accuracy": 0.916016,
        "main_score": 0.896201,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.449472,
        "recall": 0.526367,
        "f1": 0.469056,
        "accuracy": 0.526367,
        "main_score": 0.469056,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.869803,
        "recall": 0.898438,
        "f1": 0.877944,
        "accuracy": 0.898438,
        "main_score": 0.877944,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.831156,
        "recall": 0.868164,
        "f1": 0.841531,
        "accuracy": 0.868164,
        "main_score": 0.841531,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.798901,
        "recall": 0.84375,
        "f1": 0.812068,
        "accuracy": 0.84375,
        "main_score": 0.812068,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.884749,
        "recall": 0.914062,
        "f1": 0.893378,
        "accuracy": 0.914062,
        "main_score": 0.893378,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.887294,
        "recall": 0.912109,
        "f1": 0.894197,
        "accuracy": 0.912109,
        "main_score": 0.894197,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.883577,
        "recall": 0.916016,
        "f1": 0.89362,
        "accuracy": 0.916016,
        "main_score": 0.89362,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.730754,
        "recall": 0.780273,
        "f1": 0.744772,
        "accuracy": 0.780273,
        "main_score": 0.744772,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.871981,
        "recall": 0.90625,
        "f1": 0.882188,
        "accuracy": 0.90625,
        "main_score": 0.882188,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.883854,
        "recall": 0.913086,
        "f1": 0.892708,
        "accuracy": 0.913086,
        "main_score": 0.892708,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003099,
        "recall": 0.009766,
        "f1": 0.003788,
        "accuracy": 0.009766,
        "main_score": 0.003788,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.878778,
        "recall": 0.910156,
        "f1": 0.888216,
        "accuracy": 0.910156,
        "main_score": 0.888216,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.771856,
        "recall": 0.820312,
        "f1": 0.786063,
        "accuracy": 0.820312,
        "main_score": 0.786063,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.797501,
        "recall": 0.844727,
        "f1": 0.811296,
        "accuracy": 0.844727,
        "main_score": 0.811296,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.882764,
        "recall": 0.914062,
        "f1": 0.892448,
        "accuracy": 0.914062,
        "main_score": 0.892448,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00941,
        "recall": 0.022461,
        "f1": 0.011663,
        "accuracy": 0.022461,
        "main_score": 0.011663,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.742166,
        "recall": 0.794922,
        "f1": 0.756827,
        "accuracy": 0.794922,
        "main_score": 0.756827,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.87793,
        "recall": 0.907227,
        "f1": 0.886593,
        "accuracy": 0.907227,
        "main_score": 0.886593,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.911865,
        "recall": 0.936523,
        "f1": 0.919499,
        "accuracy": 0.936523,
        "main_score": 0.919499,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.870013,
        "recall": 0.894531,
        "f1": 0.877087,
        "accuracy": 0.894531,
        "main_score": 0.877087,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.970622,
        "recall": 0.979492,
        "f1": 0.973372,
        "accuracy": 0.979492,
        "main_score": 0.973372,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.984538,
        "recall": 0.989258,
        "f1": 0.986003,
        "accuracy": 0.989258,
        "main_score": 0.986003,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.443033,
        "recall": 0.524414,
        "f1": 0.46254,
        "accuracy": 0.524414,
        "main_score": 0.46254,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.961751,
        "recall": 0.973633,
        "f1": 0.965658,
        "accuracy": 0.973633,
        "main_score": 0.965658,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.96582,
        "recall": 0.976562,
        "f1": 0.969238,
        "accuracy": 0.976562,
        "main_score": 0.969238,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.94751,
        "recall": 0.962891,
        "f1": 0.952376,
        "accuracy": 0.962891,
        "main_score": 0.952376,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.966634,
        "recall": 0.977539,
        "f1": 0.970215,
        "accuracy": 0.977539,
        "main_score": 0.970215,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.988607,
        "recall": 0.992188,
        "f1": 0.989746,
        "accuracy": 0.992188,
        "main_score": 0.989746,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.975016,
        "recall": 0.982422,
        "f1": 0.977279,
        "accuracy": 0.982422,
        "main_score": 0.977279,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.82341,
        "recall": 0.867188,
        "f1": 0.836258,
        "accuracy": 0.867188,
        "main_score": 0.836258,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.984212,
        "recall": 0.989258,
        "f1": 0.98584,
        "accuracy": 0.989258,
        "main_score": 0.98584,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.848562,
        "recall": 0.886719,
        "f1": 0.859928,
        "accuracy": 0.886719,
        "main_score": 0.859928,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.003547,
        "recall": 0.007812,
        "f1": 0.003989,
        "accuracy": 0.007812,
        "main_score": 0.003989,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.790579,
        "recall": 0.836914,
        "f1": 0.803764,
        "accuracy": 0.836914,
        "main_score": 0.803764,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.867008,
        "recall": 0.90332,
        "f1": 0.877962,
        "accuracy": 0.90332,
        "main_score": 0.877962,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.962565,
        "recall": 0.974609,
        "f1": 0.966471,
        "accuracy": 0.974609,
        "main_score": 0.966471,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006264,
        "recall": 0.018555,
        "f1": 0.008068,
        "accuracy": 0.018555,
        "main_score": 0.008068,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.847143,
        "recall": 0.886719,
        "f1": 0.858789,
        "accuracy": 0.886719,
        "main_score": 0.858789,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.937093,
        "recall": 0.955078,
        "f1": 0.942773,
        "accuracy": 0.955078,
        "main_score": 0.942773,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.975586,
        "recall": 0.983398,
        "f1": 0.97819,
        "accuracy": 0.983398,
        "main_score": 0.97819,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.98641,
        "recall": 0.990234,
        "f1": 0.987533,
        "accuracy": 0.990234,
        "main_score": 0.987533,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001061,
        "recall": 0.00293,
        "f1": 0.001136,
        "accuracy": 0.00293,
        "main_score": 0.001136,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.001018,
        "recall": 0.00293,
        "f1": 0.001058,
        "accuracy": 0.00293,
        "main_score": 0.001058,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.002938,
        "recall": 0.008789,
        "f1": 0.003445,
        "accuracy": 0.008789,
        "main_score": 0.003445,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.00025,
        "recall": 0.001953,
        "f1": 0.000403,
        "accuracy": 0.001953,
        "main_score": 0.000403,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002115,
        "recall": 0.005859,
        "f1": 0.002576,
        "accuracy": 0.005859,
        "main_score": 0.002576,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000125,
        "recall": 0.003906,
        "f1": 0.000232,
        "accuracy": 0.003906,
        "main_score": 0.000232,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.000285,
        "recall": 0.00293,
        "f1": 0.000495,
        "accuracy": 0.00293,
        "main_score": 0.000495,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000345,
        "recall": 0.003906,
        "f1": 0.000527,
        "accuracy": 0.003906,
        "main_score": 0.000527,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 5.4e-05,
        "recall": 0.00293,
        "f1": 0.000104,
        "accuracy": 0.00293,
        "main_score": 0.000104,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000579,
        "recall": 0.004883,
        "f1": 0.000821,
        "accuracy": 0.004883,
        "main_score": 0.000821,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 2.1e-05,
        "recall": 0.001953,
        "f1": 4.1e-05,
        "accuracy": 0.001953,
        "main_score": 4.1e-05,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.000492,
        "recall": 0.003906,
        "f1": 0.000819,
        "accuracy": 0.003906,
        "main_score": 0.000819,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001546,
        "recall": 0.00293,
        "f1": 0.001778,
        "accuracy": 0.00293,
        "main_score": 0.001778,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001545,
        "recall": 0.003906,
        "f1": 0.001777,
        "accuracy": 0.003906,
        "main_score": 0.001777,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.001151,
        "recall": 0.006836,
        "f1": 0.00173,
        "accuracy": 0.006836,
        "main_score": 0.00173,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.000186,
        "recall": 0.003906,
        "f1": 0.000344,
        "accuracy": 0.003906,
        "main_score": 0.000344,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001493,
        "recall": 0.005859,
        "f1": 0.002125,
        "accuracy": 0.005859,
        "main_score": 0.002125,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00126,
        "recall": 0.004883,
        "f1": 0.001491,
        "accuracy": 0.004883,
        "main_score": 0.001491,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.000701,
        "recall": 0.003906,
        "f1": 0.001011,
        "accuracy": 0.003906,
        "main_score": 0.001011,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.001565,
        "recall": 0.005859,
        "f1": 0.001944,
        "accuracy": 0.005859,
        "main_score": 0.001944,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000707,
        "recall": 0.003906,
        "f1": 0.001047,
        "accuracy": 0.003906,
        "main_score": 0.001047,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000131,
        "recall": 0.001953,
        "f1": 0.000235,
        "accuracy": 0.001953,
        "main_score": 0.000235,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.45298,
        "recall": 0.539062,
        "f1": 0.474508,
        "accuracy": 0.539062,
        "main_score": 0.474508,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.966634,
        "recall": 0.977539,
        "f1": 0.970215,
        "accuracy": 0.977539,
        "main_score": 0.970215,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.98763,
        "recall": 0.991211,
        "f1": 0.98877,
        "accuracy": 0.991211,
        "main_score": 0.98877,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.923665,
        "recall": 0.946289,
        "f1": 0.93099,
        "accuracy": 0.946289,
        "main_score": 0.93099,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.969889,
        "recall": 0.979492,
        "f1": 0.972982,
        "accuracy": 0.979492,
        "main_score": 0.972982,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.973958,
        "recall": 0.982422,
        "f1": 0.976725,
        "accuracy": 0.982422,
        "main_score": 0.976725,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.861744,
        "recall": 0.899414,
        "f1": 0.873161,
        "accuracy": 0.899414,
        "main_score": 0.873161,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.861305,
        "recall": 0.897461,
        "f1": 0.872445,
        "accuracy": 0.897461,
        "main_score": 0.872445,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.987305,
        "recall": 0.991211,
        "f1": 0.988607,
        "accuracy": 0.991211,
        "main_score": 0.988607,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003532,
        "recall": 0.011719,
        "f1": 0.004412,
        "accuracy": 0.011719,
        "main_score": 0.004412,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.835388,
        "recall": 0.87793,
        "f1": 0.847965,
        "accuracy": 0.87793,
        "main_score": 0.847965,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.893148,
        "recall": 0.924805,
        "f1": 0.90306,
        "accuracy": 0.924805,
        "main_score": 0.90306,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.96875,
        "recall": 0.978516,
        "f1": 0.971842,
        "accuracy": 0.978516,
        "main_score": 0.971842,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.004406,
        "recall": 0.016602,
        "f1": 0.006222,
        "accuracy": 0.016602,
        "main_score": 0.006222,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.855225,
        "recall": 0.893555,
        "f1": 0.866738,
        "accuracy": 0.893555,
        "main_score": 0.866738,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.930339,
        "recall": 0.952148,
        "f1": 0.937337,
        "accuracy": 0.952148,
        "main_score": 0.937337,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.979574,
        "recall": 0.985352,
        "f1": 0.981348,
        "accuracy": 0.985352,
        "main_score": 0.981348,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.990479,
        "recall": 0.993164,
        "f1": 0.991276,
        "accuracy": 0.993164,
        "main_score": 0.991276,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.870182,
        "recall": 0.904297,
        "f1": 0.88005,
        "accuracy": 0.904297,
        "main_score": 0.88005,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.846167,
        "recall": 0.883789,
        "f1": 0.856924,
        "accuracy": 0.883789,
        "main_score": 0.856924,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.427081,
        "recall": 0.500977,
        "f1": 0.444853,
        "accuracy": 0.500977,
        "main_score": 0.444853,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.810638,
        "recall": 0.852539,
        "f1": 0.822868,
        "accuracy": 0.852539,
        "main_score": 0.822868,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.678713,
        "recall": 0.735352,
        "f1": 0.693434,
        "accuracy": 0.735352,
        "main_score": 0.693434,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.764499,
        "recall": 0.8125,
        "f1": 0.77759,
        "accuracy": 0.8125,
        "main_score": 0.77759,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.858244,
        "recall": 0.891602,
        "f1": 0.867749,
        "accuracy": 0.891602,
        "main_score": 0.867749,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.822282,
        "recall": 0.864258,
        "f1": 0.834581,
        "accuracy": 0.864258,
        "main_score": 0.834581,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.825677,
        "recall": 0.866211,
        "f1": 0.837412,
        "accuracy": 0.866211,
        "main_score": 0.837412,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.631344,
        "recall": 0.693359,
        "f1": 0.647493,
        "accuracy": 0.693359,
        "main_score": 0.647493,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.873877,
        "recall": 0.90625,
        "f1": 0.883496,
        "accuracy": 0.90625,
        "main_score": 0.883496,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.782495,
        "recall": 0.826172,
        "f1": 0.79477,
        "accuracy": 0.826172,
        "main_score": 0.79477,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.811572,
        "recall": 0.854492,
        "f1": 0.823847,
        "accuracy": 0.854492,
        "main_score": 0.823847,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003272,
        "recall": 0.009766,
        "f1": 0.004006,
        "accuracy": 0.009766,
        "main_score": 0.004006,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.858133,
        "recall": 0.893555,
        "f1": 0.868703,
        "accuracy": 0.893555,
        "main_score": 0.868703,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.807881,
        "recall": 0.852539,
        "f1": 0.821054,
        "accuracy": 0.852539,
        "main_score": 0.821054,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.808956,
        "recall": 0.853516,
        "f1": 0.822008,
        "accuracy": 0.853516,
        "main_score": 0.822008,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.010089,
        "recall": 0.023438,
        "f1": 0.012711,
        "accuracy": 0.023438,
        "main_score": 0.012711,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.689272,
        "recall": 0.744141,
        "f1": 0.704153,
        "accuracy": 0.744141,
        "main_score": 0.704153,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.715516,
        "recall": 0.771484,
        "f1": 0.73118,
        "accuracy": 0.771484,
        "main_score": 0.73118,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.826351,
        "recall": 0.870117,
        "f1": 0.839309,
        "accuracy": 0.870117,
        "main_score": 0.839309,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.751876,
        "recall": 0.796875,
        "f1": 0.763941,
        "accuracy": 0.796875,
        "main_score": 0.763941,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.854754,
        "recall": 0.888672,
        "f1": 0.864153,
        "accuracy": 0.888672,
        "main_score": 0.864153,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.895209,
        "recall": 0.920898,
        "f1": 0.902558,
        "accuracy": 0.920898,
        "main_score": 0.902558,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.446096,
        "recall": 0.517578,
        "f1": 0.463504,
        "accuracy": 0.517578,
        "main_score": 0.463504,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.912093,
        "recall": 0.935547,
        "f1": 0.918978,
        "accuracy": 0.935547,
        "main_score": 0.918978,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.801217,
        "recall": 0.836914,
        "f1": 0.810645,
        "accuracy": 0.836914,
        "main_score": 0.810645,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.792863,
        "recall": 0.84082,
        "f1": 0.806876,
        "accuracy": 0.84082,
        "main_score": 0.806876,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.914827,
        "recall": 0.939453,
        "f1": 0.922266,
        "accuracy": 0.939453,
        "main_score": 0.922266,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.899202,
        "recall": 0.923828,
        "f1": 0.906562,
        "accuracy": 0.923828,
        "main_score": 0.906562,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.859253,
        "recall": 0.892578,
        "f1": 0.868754,
        "accuracy": 0.892578,
        "main_score": 0.868754,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.753183,
        "recall": 0.796875,
        "f1": 0.765048,
        "accuracy": 0.796875,
        "main_score": 0.765048,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.906527,
        "recall": 0.928711,
        "f1": 0.913072,
        "accuracy": 0.928711,
        "main_score": 0.913072,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.773675,
        "recall": 0.821289,
        "f1": 0.78726,
        "accuracy": 0.821289,
        "main_score": 0.78726,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.870492,
        "recall": 0.902344,
        "f1": 0.87993,
        "accuracy": 0.902344,
        "main_score": 0.87993,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003324,
        "recall": 0.009766,
        "f1": 0.003973,
        "accuracy": 0.009766,
        "main_score": 0.003973,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.90958,
        "recall": 0.932617,
        "f1": 0.916423,
        "accuracy": 0.932617,
        "main_score": 0.916423,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.75829,
        "recall": 0.808594,
        "f1": 0.772185,
        "accuracy": 0.808594,
        "main_score": 0.772185,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.833243,
        "recall": 0.871094,
        "f1": 0.844387,
        "accuracy": 0.871094,
        "main_score": 0.844387,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.008517,
        "recall": 0.022461,
        "f1": 0.011254,
        "accuracy": 0.022461,
        "main_score": 0.011254,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.796981,
        "recall": 0.838867,
        "f1": 0.808464,
        "accuracy": 0.838867,
        "main_score": 0.808464,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.783286,
        "recall": 0.833008,
        "f1": 0.797894,
        "accuracy": 0.833008,
        "main_score": 0.797894,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.857683,
        "recall": 0.890625,
        "f1": 0.867151,
        "accuracy": 0.890625,
        "main_score": 0.867151,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.874168,
        "recall": 0.898438,
        "f1": 0.88123,
        "accuracy": 0.898438,
        "main_score": 0.88123,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.968506,
        "recall": 0.978516,
        "f1": 0.971745,
        "accuracy": 0.978516,
        "main_score": 0.971745,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.971354,
        "recall": 0.980469,
        "f1": 0.974284,
        "accuracy": 0.980469,
        "main_score": 0.974284,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.488532,
        "recall": 0.567383,
        "f1": 0.508797,
        "accuracy": 0.567383,
        "main_score": 0.508797,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.940999,
        "recall": 0.958984,
        "f1": 0.94668,
        "accuracy": 0.958984,
        "main_score": 0.94668,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.952425,
        "recall": 0.96582,
        "f1": 0.956445,
        "accuracy": 0.96582,
        "main_score": 0.956445,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.909098,
        "recall": 0.933594,
        "f1": 0.916374,
        "accuracy": 0.933594,
        "main_score": 0.916374,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.94987,
        "recall": 0.964844,
        "f1": 0.95459,
        "accuracy": 0.964844,
        "main_score": 0.95459,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.975586,
        "recall": 0.983398,
        "f1": 0.97819,
        "accuracy": 0.983398,
        "main_score": 0.97819,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.954427,
        "recall": 0.967773,
        "f1": 0.958659,
        "accuracy": 0.967773,
        "main_score": 0.958659,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.825846,
        "recall": 0.873047,
        "f1": 0.840383,
        "accuracy": 0.873047,
        "main_score": 0.840383,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.968587,
        "recall": 0.978516,
        "f1": 0.971842,
        "accuracy": 0.978516,
        "main_score": 0.971842,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.875846,
        "recall": 0.90918,
        "f1": 0.886035,
        "accuracy": 0.90918,
        "main_score": 0.886035,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.963867,
        "recall": 0.975586,
        "f1": 0.967773,
        "accuracy": 0.975586,
        "main_score": 0.967773,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004334,
        "recall": 0.010742,
        "f1": 0.005358,
        "accuracy": 0.010742,
        "main_score": 0.005358,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.984863,
        "recall": 0.989258,
        "f1": 0.986165,
        "accuracy": 0.989258,
        "main_score": 0.986165,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.79013,
        "recall": 0.837891,
        "f1": 0.804006,
        "accuracy": 0.837891,
        "main_score": 0.804006,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.849691,
        "recall": 0.889648,
        "f1": 0.861816,
        "accuracy": 0.889648,
        "main_score": 0.861816,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.006426,
        "recall": 0.019531,
        "f1": 0.008402,
        "accuracy": 0.019531,
        "main_score": 0.008402,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.833914,
        "recall": 0.875977,
        "f1": 0.846373,
        "accuracy": 0.875977,
        "main_score": 0.846373,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.922184,
        "recall": 0.942383,
        "f1": 0.92841,
        "accuracy": 0.942383,
        "main_score": 0.92841,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.968506,
        "recall": 0.978516,
        "f1": 0.971745,
        "accuracy": 0.978516,
        "main_score": 0.971745,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.961133,
        "recall": 0.972656,
        "f1": 0.964681,
        "accuracy": 0.972656,
        "main_score": 0.964681,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.004496,
        "recall": 0.009766,
        "f1": 0.00525,
        "accuracy": 0.009766,
        "main_score": 0.00525,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.004938,
        "recall": 0.011719,
        "f1": 0.005456,
        "accuracy": 0.011719,
        "main_score": 0.005456,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.003589,
        "recall": 0.009766,
        "f1": 0.004676,
        "accuracy": 0.009766,
        "main_score": 0.004676,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.002786,
        "recall": 0.005859,
        "f1": 0.003184,
        "accuracy": 0.005859,
        "main_score": 0.003184,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002075,
        "recall": 0.007812,
        "f1": 0.002664,
        "accuracy": 0.007812,
        "main_score": 0.002664,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002696,
        "recall": 0.008789,
        "f1": 0.003247,
        "accuracy": 0.008789,
        "main_score": 0.003247,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.003005,
        "recall": 0.006836,
        "f1": 0.003555,
        "accuracy": 0.006836,
        "main_score": 0.003555,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.002664,
        "recall": 0.007812,
        "f1": 0.003092,
        "accuracy": 0.007812,
        "main_score": 0.003092,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00472,
        "recall": 0.007812,
        "f1": 0.005424,
        "accuracy": 0.007812,
        "main_score": 0.005424,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004395,
        "recall": 0.010742,
        "f1": 0.005034,
        "accuracy": 0.010742,
        "main_score": 0.005034,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.001699,
        "recall": 0.004883,
        "f1": 0.002029,
        "accuracy": 0.004883,
        "main_score": 0.002029,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.003204,
        "recall": 0.009766,
        "f1": 0.00391,
        "accuracy": 0.009766,
        "main_score": 0.00391,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.00246,
        "recall": 0.004883,
        "f1": 0.002966,
        "accuracy": 0.004883,
        "main_score": 0.002966,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00089,
        "recall": 0.006836,
        "f1": 0.001374,
        "accuracy": 0.006836,
        "main_score": 0.001374,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.004671,
        "recall": 0.008789,
        "f1": 0.005011,
        "accuracy": 0.008789,
        "main_score": 0.005011,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.003979,
        "recall": 0.011719,
        "f1": 0.005299,
        "accuracy": 0.011719,
        "main_score": 0.005299,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.007299,
        "recall": 0.014648,
        "f1": 0.008117,
        "accuracy": 0.014648,
        "main_score": 0.008117,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.003901,
        "recall": 0.008789,
        "f1": 0.004733,
        "accuracy": 0.008789,
        "main_score": 0.004733,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001997,
        "recall": 0.008789,
        "f1": 0.002571,
        "accuracy": 0.008789,
        "main_score": 0.002571,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.0024,
        "recall": 0.008789,
        "f1": 0.003048,
        "accuracy": 0.008789,
        "main_score": 0.003048,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.002369,
        "recall": 0.006836,
        "f1": 0.003265,
        "accuracy": 0.006836,
        "main_score": 0.003265,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.00311,
        "recall": 0.010742,
        "f1": 0.004028,
        "accuracy": 0.010742,
        "main_score": 0.004028,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.851548,
        "recall": 0.884766,
        "f1": 0.861103,
        "accuracy": 0.884766,
        "main_score": 0.861103,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.878651,
        "recall": 0.907227,
        "f1": 0.886836,
        "accuracy": 0.907227,
        "main_score": 0.886836,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.511898,
        "recall": 0.587891,
        "f1": 0.532012,
        "accuracy": 0.587891,
        "main_score": 0.532012,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.901376,
        "recall": 0.924805,
        "f1": 0.907894,
        "accuracy": 0.924805,
        "main_score": 0.907894,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.83022,
        "recall": 0.862305,
        "f1": 0.838481,
        "accuracy": 0.862305,
        "main_score": 0.838481,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.819368,
        "recall": 0.860352,
        "f1": 0.831417,
        "accuracy": 0.860352,
        "main_score": 0.831417,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.853986,
        "recall": 0.885742,
        "f1": 0.863172,
        "accuracy": 0.885742,
        "main_score": 0.863172,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.898592,
        "recall": 0.920898,
        "f1": 0.904604,
        "accuracy": 0.920898,
        "main_score": 0.904604,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.855192,
        "recall": 0.882812,
        "f1": 0.862891,
        "accuracy": 0.882812,
        "main_score": 0.862891,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.800399,
        "recall": 0.841797,
        "f1": 0.811783,
        "accuracy": 0.841797,
        "main_score": 0.811783,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.906091,
        "recall": 0.929688,
        "f1": 0.912874,
        "accuracy": 0.929688,
        "main_score": 0.912874,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.737728,
        "recall": 0.788086,
        "f1": 0.751672,
        "accuracy": 0.788086,
        "main_score": 0.751672,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.866883,
        "recall": 0.898438,
        "f1": 0.876079,
        "accuracy": 0.898438,
        "main_score": 0.876079,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00255,
        "recall": 0.006836,
        "f1": 0.003211,
        "accuracy": 0.006836,
        "main_score": 0.003211,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.882722,
        "recall": 0.910156,
        "f1": 0.89082,
        "accuracy": 0.910156,
        "main_score": 0.89082,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.667584,
        "recall": 0.72168,
        "f1": 0.681772,
        "accuracy": 0.72168,
        "main_score": 0.681772,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.809361,
        "recall": 0.853516,
        "f1": 0.822253,
        "accuracy": 0.853516,
        "main_score": 0.822253,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.847698,
        "recall": 0.886719,
        "f1": 0.85954,
        "accuracy": 0.886719,
        "main_score": 0.85954,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.008083,
        "recall": 0.020508,
        "f1": 0.0101,
        "accuracy": 0.020508,
        "main_score": 0.0101,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.765907,
        "recall": 0.8125,
        "f1": 0.778761,
        "accuracy": 0.8125,
        "main_score": 0.778761,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.852452,
        "recall": 0.884766,
        "f1": 0.861799,
        "accuracy": 0.884766,
        "main_score": 0.861799,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.874596,
        "recall": 0.899414,
        "f1": 0.881263,
        "accuracy": 0.899414,
        "main_score": 0.881263,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.943604,
        "recall": 0.959961,
        "f1": 0.948796,
        "accuracy": 0.959961,
        "main_score": 0.948796,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.95638,
        "recall": 0.969727,
        "f1": 0.960775,
        "accuracy": 0.969727,
        "main_score": 0.960775,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.391041,
        "recall": 0.467773,
        "f1": 0.410249,
        "accuracy": 0.467773,
        "main_score": 0.410249,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.874366,
        "recall": 0.905273,
        "f1": 0.883517,
        "accuracy": 0.905273,
        "main_score": 0.883517,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.933757,
        "recall": 0.954102,
        "f1": 0.940104,
        "accuracy": 0.954102,
        "main_score": 0.940104,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.851912,
        "recall": 0.888672,
        "f1": 0.862703,
        "accuracy": 0.888672,
        "main_score": 0.862703,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.920003,
        "recall": 0.943359,
        "f1": 0.927311,
        "accuracy": 0.943359,
        "main_score": 0.927311,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.963867,
        "recall": 0.974609,
        "f1": 0.967285,
        "accuracy": 0.974609,
        "main_score": 0.967285,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.952148,
        "recall": 0.966797,
        "f1": 0.956868,
        "accuracy": 0.966797,
        "main_score": 0.956868,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.74866,
        "recall": 0.799805,
        "f1": 0.763128,
        "accuracy": 0.799805,
        "main_score": 0.763128,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.936686,
        "recall": 0.956055,
        "f1": 0.942871,
        "accuracy": 0.956055,
        "main_score": 0.942871,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.859483,
        "recall": 0.892578,
        "f1": 0.869378,
        "accuracy": 0.892578,
        "main_score": 0.869378,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.943929,
        "recall": 0.960938,
        "f1": 0.949447,
        "accuracy": 0.960938,
        "main_score": 0.949447,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001909,
        "recall": 0.005859,
        "f1": 0.00234,
        "accuracy": 0.005859,
        "main_score": 0.00234,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.953857,
        "recall": 0.967773,
        "f1": 0.958236,
        "accuracy": 0.967773,
        "main_score": 0.958236,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.687123,
        "recall": 0.748047,
        "f1": 0.70423,
        "accuracy": 0.748047,
        "main_score": 0.70423,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.8125,
        "recall": 0.859375,
        "f1": 0.826368,
        "accuracy": 0.859375,
        "main_score": 0.826368,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.895622,
        "recall": 0.925781,
        "f1": 0.90498,
        "accuracy": 0.925781,
        "main_score": 0.90498,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005533,
        "recall": 0.015625,
        "f1": 0.007019,
        "accuracy": 0.015625,
        "main_score": 0.007019,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.767011,
        "recall": 0.817383,
        "f1": 0.780335,
        "accuracy": 0.817383,
        "main_score": 0.780335,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.957113,
        "recall": 0.96875,
        "f1": 0.960677,
        "accuracy": 0.96875,
        "main_score": 0.960677,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.956624,
        "recall": 0.96875,
        "f1": 0.960305,
        "accuracy": 0.96875,
        "main_score": 0.960305,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.974609,
        "recall": 0.982422,
        "f1": 0.977051,
        "accuracy": 0.982422,
        "main_score": 0.977051,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.983236,
        "recall": 0.988281,
        "f1": 0.984863,
        "accuracy": 0.988281,
        "main_score": 0.984863,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.452925,
        "recall": 0.542969,
        "f1": 0.476569,
        "accuracy": 0.542969,
        "main_score": 0.476569,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.943197,
        "recall": 0.958984,
        "f1": 0.948079,
        "accuracy": 0.958984,
        "main_score": 0.948079,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.984212,
        "recall": 0.989258,
        "f1": 0.98584,
        "accuracy": 0.989258,
        "main_score": 0.98584,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.902181,
        "recall": 0.930664,
        "f1": 0.9111,
        "accuracy": 0.930664,
        "main_score": 0.9111,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.971191,
        "recall": 0.980469,
        "f1": 0.974284,
        "accuracy": 0.980469,
        "main_score": 0.974284,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.979818,
        "recall": 0.986328,
        "f1": 0.981934,
        "accuracy": 0.986328,
        "main_score": 0.981934,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.838509,
        "recall": 0.879883,
        "f1": 0.850698,
        "accuracy": 0.879883,
        "main_score": 0.850698,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.976888,
        "recall": 0.984375,
        "f1": 0.979329,
        "accuracy": 0.984375,
        "main_score": 0.979329,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.89394,
        "recall": 0.922852,
        "f1": 0.90293,
        "accuracy": 0.922852,
        "main_score": 0.90293,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.979004,
        "recall": 0.985352,
        "f1": 0.98112,
        "accuracy": 0.985352,
        "main_score": 0.98112,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001726,
        "recall": 0.007812,
        "f1": 0.002238,
        "accuracy": 0.007812,
        "main_score": 0.002238,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.80543,
        "recall": 0.851562,
        "f1": 0.818646,
        "accuracy": 0.851562,
        "main_score": 0.818646,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.861328,
        "recall": 0.898438,
        "f1": 0.872642,
        "accuracy": 0.898438,
        "main_score": 0.872642,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.96569,
        "recall": 0.975586,
        "f1": 0.96875,
        "accuracy": 0.975586,
        "main_score": 0.96875,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.007656,
        "recall": 0.019531,
        "f1": 0.00884,
        "accuracy": 0.019531,
        "main_score": 0.00884,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.82645,
        "recall": 0.869141,
        "f1": 0.838866,
        "accuracy": 0.869141,
        "main_score": 0.838866,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.958822,
        "recall": 0.97168,
        "f1": 0.963053,
        "accuracy": 0.97168,
        "main_score": 0.963053,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.44375,
        "recall": 0.549805,
        "f1": 0.471352,
        "accuracy": 0.549805,
        "main_score": 0.471352,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.969238,
        "recall": 0.979492,
        "f1": 0.972656,
        "accuracy": 0.979492,
        "main_score": 0.972656,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.908691,
        "recall": 0.936523,
        "f1": 0.917448,
        "accuracy": 0.936523,
        "main_score": 0.917448,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.975423,
        "recall": 0.983398,
        "f1": 0.978027,
        "accuracy": 0.983398,
        "main_score": 0.978027,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.976888,
        "recall": 0.984375,
        "f1": 0.979329,
        "accuracy": 0.984375,
        "main_score": 0.979329,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.906006,
        "recall": 0.935547,
        "f1": 0.91543,
        "accuracy": 0.935547,
        "main_score": 0.91543,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.87373,
        "recall": 0.910156,
        "f1": 0.885045,
        "accuracy": 0.910156,
        "main_score": 0.885045,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.984701,
        "recall": 0.989258,
        "f1": 0.986165,
        "accuracy": 0.989258,
        "main_score": 0.986165,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001096,
        "recall": 0.005859,
        "f1": 0.001674,
        "accuracy": 0.005859,
        "main_score": 0.001674,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.991699,
        "recall": 0.994141,
        "f1": 0.992513,
        "accuracy": 0.994141,
        "main_score": 0.992513,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.798326,
        "recall": 0.850586,
        "f1": 0.813853,
        "accuracy": 0.850586,
        "main_score": 0.813853,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.915202,
        "recall": 0.941406,
        "f1": 0.923503,
        "accuracy": 0.941406,
        "main_score": 0.923503,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.964355,
        "recall": 0.975586,
        "f1": 0.967936,
        "accuracy": 0.975586,
        "main_score": 0.967936,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.007398,
        "recall": 0.019531,
        "f1": 0.008876,
        "accuracy": 0.019531,
        "main_score": 0.008876,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.882764,
        "recall": 0.916016,
        "f1": 0.892904,
        "accuracy": 0.916016,
        "main_score": 0.892904,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.950684,
        "recall": 0.966797,
        "f1": 0.956055,
        "accuracy": 0.966797,
        "main_score": 0.956055,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 574.4400451183319,
  "kg_co2_emissions": null
}