{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.0396,
        "f1": 0.033987,
        "f1_weighted": 0.04169,
        "scores_per_experiment": [
          {
            "accuracy": 0.041504,
            "f1": 0.032845,
            "f1_weighted": 0.043102
          },
          {
            "accuracy": 0.037598,
            "f1": 0.027296,
            "f1_weighted": 0.039461
          },
          {
            "accuracy": 0.038086,
            "f1": 0.03307,
            "f1_weighted": 0.04047
          },
          {
            "accuracy": 0.035156,
            "f1": 0.035516,
            "f1_weighted": 0.036296
          },
          {
            "accuracy": 0.042969,
            "f1": 0.036766,
            "f1_weighted": 0.046012
          },
          {
            "accuracy": 0.037109,
            "f1": 0.032836,
            "f1_weighted": 0.04109
          },
          {
            "accuracy": 0.049805,
            "f1": 0.039312,
            "f1_weighted": 0.052558
          },
          {
            "accuracy": 0.04248,
            "f1": 0.036239,
            "f1_weighted": 0.045072
          },
          {
            "accuracy": 0.033691,
            "f1": 0.02973,
            "f1_weighted": 0.034135
          },
          {
            "accuracy": 0.037598,
            "f1": 0.036265,
            "f1_weighted": 0.038704
          }
        ],
        "main_score": 0.0396,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.037158,
        "f1": 0.038106,
        "f1_weighted": 0.038982,
        "scores_per_experiment": [
          {
            "accuracy": 0.030762,
            "f1": 0.033219,
            "f1_weighted": 0.032353
          },
          {
            "accuracy": 0.037598,
            "f1": 0.039706,
            "f1_weighted": 0.039903
          },
          {
            "accuracy": 0.033203,
            "f1": 0.037131,
            "f1_weighted": 0.031953
          },
          {
            "accuracy": 0.033691,
            "f1": 0.029454,
            "f1_weighted": 0.034483
          },
          {
            "accuracy": 0.039062,
            "f1": 0.037944,
            "f1_weighted": 0.038326
          },
          {
            "accuracy": 0.040527,
            "f1": 0.036332,
            "f1_weighted": 0.043306
          },
          {
            "accuracy": 0.038574,
            "f1": 0.041226,
            "f1_weighted": 0.040203
          },
          {
            "accuracy": 0.040527,
            "f1": 0.041151,
            "f1_weighted": 0.043248
          },
          {
            "accuracy": 0.039551,
            "f1": 0.044887,
            "f1_weighted": 0.043362
          },
          {
            "accuracy": 0.038086,
            "f1": 0.04001,
            "f1_weighted": 0.042686
          }
        ],
        "main_score": 0.037158,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 1900.8715782165527,
  "kg_co2_emissions": 0.0789135819403173
}