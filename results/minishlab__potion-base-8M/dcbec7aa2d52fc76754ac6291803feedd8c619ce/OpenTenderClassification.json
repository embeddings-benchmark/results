{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.195987,
            "f1": 0.182305,
            "f1_weighted": 0.182319,
            "precision": 0.193794,
            "precision_weighted": 0.193786,
            "recall": 0.19596,
            "recall_weighted": 0.195987,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.18194,
            "f1": 0.166088,
            "f1_weighted": 0.166027,
            "precision": 0.181369,
            "precision_weighted": 0.181328,
            "recall": 0.182009,
            "recall_weighted": 0.18194,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.207358,
            "f1": 0.188889,
            "f1_weighted": 0.188841,
            "precision": 0.194555,
            "precision_weighted": 0.19458,
            "recall": 0.207504,
            "recall_weighted": 0.207358,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.19019,
            "f1": 0.175576,
            "f1_weighted": 0.175559,
            "precision": 0.196612,
            "precision_weighted": 0.196571,
            "recall": 0.190192,
            "recall_weighted": 0.19019,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.183055,
            "f1": 0.171719,
            "f1_weighted": 0.171782,
            "precision": 0.190901,
            "precision_weighted": 0.190956,
            "recall": 0.183,
            "recall_weighted": 0.183055,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.166109,
            "f1": 0.151949,
            "f1_weighted": 0.151909,
            "precision": 0.169598,
            "precision_weighted": 0.169601,
            "recall": 0.166217,
            "recall_weighted": 0.166109,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.185507,
            "f1": 0.170224,
            "f1_weighted": 0.170187,
            "precision": 0.186225,
            "precision_weighted": 0.18621,
            "recall": 0.185511,
            "recall_weighted": 0.185507,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.174582,
            "f1": 0.160327,
            "f1_weighted": 0.160301,
            "precision": 0.183802,
            "precision_weighted": 0.183841,
            "recall": 0.174675,
            "recall_weighted": 0.174582,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.171014,
            "f1": 0.150687,
            "f1_weighted": 0.150688,
            "precision": 0.16425,
            "precision_weighted": 0.16431,
            "recall": 0.171092,
            "recall_weighted": 0.171014,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.177926,
            "f1": 0.164295,
            "f1_weighted": 0.16433,
            "precision": 0.1774,
            "precision_weighted": 0.177424,
            "recall": 0.177914,
            "recall_weighted": 0.177926,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.183367,
        "f1": 0.168206,
        "f1_weighted": 0.168194,
        "precision": 0.183851,
        "precision_weighted": 0.183861,
        "recall": 0.183407,
        "recall_weighted": 0.183367,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.168206,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 20.73552703857422,
  "kg_co2_emissions": null
}