{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.459008,
        "f1": 0.457431,
        "f1_weighted": 0.45649,
        "scores_per_experiment": [
          {
            "accuracy": 0.430809,
            "f1": 0.42469,
            "f1_weighted": 0.426332
          },
          {
            "accuracy": 0.477807,
            "f1": 0.481901,
            "f1_weighted": 0.479909
          },
          {
            "accuracy": 0.446475,
            "f1": 0.445733,
            "f1_weighted": 0.445963
          },
          {
            "accuracy": 0.511749,
            "f1": 0.508549,
            "f1_weighted": 0.507136
          },
          {
            "accuracy": 0.490862,
            "f1": 0.490448,
            "f1_weighted": 0.489418
          },
          {
            "accuracy": 0.454308,
            "f1": 0.458091,
            "f1_weighted": 0.458793
          },
          {
            "accuracy": 0.417755,
            "f1": 0.402458,
            "f1_weighted": 0.39664
          },
          {
            "accuracy": 0.415144,
            "f1": 0.409524,
            "f1_weighted": 0.405932
          },
          {
            "accuracy": 0.480418,
            "f1": 0.490432,
            "f1_weighted": 0.493259
          },
          {
            "accuracy": 0.464752,
            "f1": 0.462479,
            "f1_weighted": 0.461513
          }
        ],
        "main_score": 0.459008,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.407292,
        "f1": 0.408918,
        "f1_weighted": 0.405185,
        "scores_per_experiment": [
          {
            "accuracy": 0.447917,
            "f1": 0.454365,
            "f1_weighted": 0.458475
          },
          {
            "accuracy": 0.46875,
            "f1": 0.473824,
            "f1_weighted": 0.471847
          },
          {
            "accuracy": 0.395833,
            "f1": 0.393491,
            "f1_weighted": 0.39264
          },
          {
            "accuracy": 0.427083,
            "f1": 0.431766,
            "f1_weighted": 0.423555
          },
          {
            "accuracy": 0.4375,
            "f1": 0.438596,
            "f1_weighted": 0.440485
          },
          {
            "accuracy": 0.364583,
            "f1": 0.377611,
            "f1_weighted": 0.372387
          },
          {
            "accuracy": 0.354167,
            "f1": 0.334222,
            "f1_weighted": 0.314656
          },
          {
            "accuracy": 0.395833,
            "f1": 0.392524,
            "f1_weighted": 0.385685
          },
          {
            "accuracy": 0.458333,
            "f1": 0.455636,
            "f1_weighted": 0.457132
          },
          {
            "accuracy": 0.322917,
            "f1": 0.337139,
            "f1_weighted": 0.334985
          }
        ],
        "main_score": 0.407292,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 12.498164653778076,
  "kg_co2_emissions": 0.00028302780859736304
}