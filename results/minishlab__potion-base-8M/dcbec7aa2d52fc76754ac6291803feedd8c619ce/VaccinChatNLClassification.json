{
  "dataset_revision": "bd27d0058bea2ad52470d9072a3b5da6b97c1ac3",
  "task_name": "VaccinChatNLClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.252991,
            "f1": 0.269169,
            "f1_weighted": 0.232915,
            "precision": 0.30156,
            "precision_weighted": 0.429162,
            "recall": 0.42137,
            "recall_weighted": 0.252991,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.264957,
            "f1": 0.260104,
            "f1_weighted": 0.234728,
            "precision": 0.267503,
            "precision_weighted": 0.431744,
            "recall": 0.443537,
            "recall_weighted": 0.264957,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.271795,
            "f1": 0.288287,
            "f1_weighted": 0.249096,
            "precision": 0.323071,
            "precision_weighted": 0.430483,
            "recall": 0.432599,
            "recall_weighted": 0.271795,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.276068,
            "f1": 0.253626,
            "f1_weighted": 0.262476,
            "precision": 0.282546,
            "precision_weighted": 0.500896,
            "recall": 0.40375,
            "recall_weighted": 0.276068,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.267521,
            "f1": 0.270055,
            "f1_weighted": 0.239341,
            "precision": 0.302375,
            "precision_weighted": 0.431592,
            "recall": 0.427218,
            "recall_weighted": 0.267521,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.276923,
            "f1": 0.266275,
            "f1_weighted": 0.261288,
            "precision": 0.28666,
            "precision_weighted": 0.434861,
            "recall": 0.412843,
            "recall_weighted": 0.276923,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.275214,
            "f1": 0.265014,
            "f1_weighted": 0.256805,
            "precision": 0.296617,
            "precision_weighted": 0.426049,
            "recall": 0.400301,
            "recall_weighted": 0.275214,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.264103,
            "f1": 0.260817,
            "f1_weighted": 0.236065,
            "precision": 0.280965,
            "precision_weighted": 0.334616,
            "recall": 0.403541,
            "recall_weighted": 0.264103,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.273504,
            "f1": 0.272989,
            "f1_weighted": 0.235002,
            "precision": 0.266211,
            "precision_weighted": 0.328209,
            "recall": 0.435908,
            "recall_weighted": 0.273504,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.282051,
            "f1": 0.271823,
            "f1_weighted": 0.251105,
            "precision": 0.284264,
            "precision_weighted": 0.408474,
            "recall": 0.431302,
            "recall_weighted": 0.282051,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.270513,
        "f1": 0.267816,
        "f1_weighted": 0.245882,
        "precision": 0.289177,
        "precision_weighted": 0.415609,
        "recall": 0.421237,
        "recall_weighted": 0.270513,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.267816,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 19.507330894470215,
  "kg_co2_emissions": null
}