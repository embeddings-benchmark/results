{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "task_name": "IN22ConvBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.847328,
        "recall": 0.889554,
        "f1": 0.860368,
        "accuracy": 0.889554,
        "main_score": 0.860368,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.060234,
        "recall": 0.100466,
        "f1": 0.068758,
        "accuracy": 0.100466,
        "main_score": 0.068758,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.432538,
        "recall": 0.531603,
        "f1": 0.45944,
        "accuracy": 0.531603,
        "main_score": 0.45944,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.867798,
        "recall": 0.90153,
        "f1": 0.877889,
        "accuracy": 0.90153,
        "main_score": 0.877889,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.444609,
        "recall": 0.533599,
        "f1": 0.469395,
        "accuracy": 0.533599,
        "main_score": 0.469395,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.846203,
        "recall": 0.882236,
        "f1": 0.856942,
        "accuracy": 0.882236,
        "main_score": 0.856942,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.819644,
        "recall": 0.863606,
        "f1": 0.832749,
        "accuracy": 0.863606,
        "main_score": 0.832749,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.658653,
        "recall": 0.727878,
        "f1": 0.678753,
        "accuracy": 0.727878,
        "main_score": 0.678753,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.168061,
        "recall": 0.245509,
        "f1": 0.18573,
        "accuracy": 0.245509,
        "main_score": 0.18573,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.561603,
        "recall": 0.640719,
        "f1": 0.583855,
        "accuracy": 0.640719,
        "main_score": 0.583855,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.756887,
        "recall": 0.812375,
        "f1": 0.773625,
        "accuracy": 0.812375,
        "main_score": 0.773625,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.834864,
        "recall": 0.873586,
        "f1": 0.846606,
        "accuracy": 0.873586,
        "main_score": 0.846606,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00075,
        "recall": 0.007984,
        "f1": 0.001296,
        "accuracy": 0.007984,
        "main_score": 0.001296,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.844611,
        "recall": 0.88024,
        "f1": 0.855533,
        "accuracy": 0.88024,
        "main_score": 0.855533,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.822078,
        "recall": 0.864937,
        "f1": 0.835288,
        "accuracy": 0.864937,
        "main_score": 0.835288,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.816119,
        "recall": 0.858949,
        "f1": 0.829042,
        "accuracy": 0.858949,
        "main_score": 0.829042,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.431022,
        "recall": 0.518297,
        "f1": 0.454443,
        "accuracy": 0.518297,
        "main_score": 0.454443,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000531,
        "recall": 0.004657,
        "f1": 0.000812,
        "accuracy": 0.004657,
        "main_score": 0.000812,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.312467,
        "recall": 0.40519,
        "f1": 0.33668,
        "accuracy": 0.40519,
        "main_score": 0.33668,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.692182,
        "recall": 0.761144,
        "f1": 0.712879,
        "accuracy": 0.761144,
        "main_score": 0.712879,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.785041,
        "recall": 0.83167,
        "f1": 0.799227,
        "accuracy": 0.83167,
        "main_score": 0.799227,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.842193,
        "recall": 0.882236,
        "f1": 0.854513,
        "accuracy": 0.882236,
        "main_score": 0.854513,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.839942,
        "recall": 0.880905,
        "f1": 0.852406,
        "accuracy": 0.880905,
        "main_score": 0.852406,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.056943,
        "recall": 0.105788,
        "f1": 0.067108,
        "accuracy": 0.105788,
        "main_score": 0.067108,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.475637,
        "recall": 0.575516,
        "f1": 0.503322,
        "accuracy": 0.575516,
        "main_score": 0.503322,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.938257,
        "recall": 0.954757,
        "f1": 0.943313,
        "accuracy": 0.954757,
        "main_score": 0.943313,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.455086,
        "recall": 0.55356,
        "f1": 0.482086,
        "accuracy": 0.55356,
        "main_score": 0.482086,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.909148,
        "recall": 0.930805,
        "f1": 0.915879,
        "accuracy": 0.930805,
        "main_score": 0.915879,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.901253,
        "recall": 0.927478,
        "f1": 0.909559,
        "accuracy": 0.927478,
        "main_score": 0.909559,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.746415,
        "recall": 0.805057,
        "f1": 0.76391,
        "accuracy": 0.805057,
        "main_score": 0.76391,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.191239,
        "recall": 0.284764,
        "f1": 0.213188,
        "accuracy": 0.284764,
        "main_score": 0.213188,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.626564,
        "recall": 0.700599,
        "f1": 0.648072,
        "accuracy": 0.700599,
        "main_score": 0.648072,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.846835,
        "recall": 0.884232,
        "f1": 0.858352,
        "accuracy": 0.884232,
        "main_score": 0.858352,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.915192,
        "recall": 0.936128,
        "f1": 0.92169,
        "accuracy": 0.936128,
        "main_score": 0.92169,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.0004,
        "recall": 0.006653,
        "f1": 0.000715,
        "accuracy": 0.006653,
        "main_score": 0.000715,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.911,
        "recall": 0.932801,
        "f1": 0.917565,
        "accuracy": 0.932801,
        "main_score": 0.917565,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.876525,
        "recall": 0.906188,
        "f1": 0.885673,
        "accuracy": 0.906188,
        "main_score": 0.885673,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.880058,
        "recall": 0.91018,
        "f1": 0.889399,
        "accuracy": 0.91018,
        "main_score": 0.889399,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.459983,
        "recall": 0.554225,
        "f1": 0.485751,
        "accuracy": 0.554225,
        "main_score": 0.485751,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000453,
        "recall": 0.006653,
        "f1": 0.000824,
        "accuracy": 0.006653,
        "main_score": 0.000824,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.35519,
        "recall": 0.453094,
        "f1": 0.380814,
        "accuracy": 0.453094,
        "main_score": 0.380814,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.786172,
        "recall": 0.833666,
        "f1": 0.800567,
        "accuracy": 0.833666,
        "main_score": 0.800567,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.871335,
        "recall": 0.904192,
        "f1": 0.881615,
        "accuracy": 0.904192,
        "main_score": 0.881615,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.912564,
        "recall": 0.934132,
        "f1": 0.919295,
        "accuracy": 0.934132,
        "main_score": 0.919295,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.045058,
        "recall": 0.080506,
        "f1": 0.050898,
        "accuracy": 0.080506,
        "main_score": 0.050898,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.045944,
        "recall": 0.081836,
        "f1": 0.052019,
        "accuracy": 0.081836,
        "main_score": 0.052019,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.061525,
        "recall": 0.08849,
        "f1": 0.066275,
        "accuracy": 0.08849,
        "main_score": 0.066275,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.063461,
        "recall": 0.097139,
        "f1": 0.069132,
        "accuracy": 0.097139,
        "main_score": 0.069132,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.061949,
        "recall": 0.083832,
        "f1": 0.065914,
        "accuracy": 0.083832,
        "main_score": 0.065914,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.051892,
        "recall": 0.08982,
        "f1": 0.05836,
        "accuracy": 0.08982,
        "main_score": 0.05836,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.061547,
        "recall": 0.093812,
        "f1": 0.067138,
        "accuracy": 0.093812,
        "main_score": 0.067138,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.049128,
        "recall": 0.06853,
        "f1": 0.052563,
        "accuracy": 0.06853,
        "main_score": 0.052563,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.03637,
        "recall": 0.050566,
        "f1": 0.039388,
        "accuracy": 0.050566,
        "main_score": 0.039388,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.050719,
        "recall": 0.075848,
        "f1": 0.055396,
        "accuracy": 0.075848,
        "main_score": 0.055396,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.050044,
        "recall": 0.079175,
        "f1": 0.055586,
        "accuracy": 0.079175,
        "main_score": 0.055586,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.060604,
        "recall": 0.096474,
        "f1": 0.066841,
        "accuracy": 0.096474,
        "main_score": 0.066841,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001389,
        "recall": 0.007319,
        "f1": 0.002164,
        "accuracy": 0.007319,
        "main_score": 0.002164,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.054716,
        "recall": 0.087824,
        "f1": 0.06055,
        "accuracy": 0.087824,
        "main_score": 0.06055,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.053245,
        "recall": 0.089155,
        "f1": 0.058704,
        "accuracy": 0.089155,
        "main_score": 0.058704,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.048367,
        "recall": 0.079175,
        "f1": 0.052906,
        "accuracy": 0.079175,
        "main_score": 0.052906,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.048886,
        "recall": 0.067199,
        "f1": 0.052488,
        "accuracy": 0.067199,
        "main_score": 0.052488,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002817,
        "recall": 0.011311,
        "f1": 0.003828,
        "accuracy": 0.011311,
        "main_score": 0.003828,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.052294,
        "recall": 0.073187,
        "f1": 0.056298,
        "accuracy": 0.073187,
        "main_score": 0.056298,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.045617,
        "recall": 0.075183,
        "f1": 0.050293,
        "accuracy": 0.075183,
        "main_score": 0.050293,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.056831,
        "recall": 0.091151,
        "f1": 0.062362,
        "accuracy": 0.091151,
        "main_score": 0.062362,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.053893,
        "recall": 0.07984,
        "f1": 0.058597,
        "accuracy": 0.07984,
        "main_score": 0.058597,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.454483,
        "recall": 0.538257,
        "f1": 0.477928,
        "accuracy": 0.538257,
        "main_score": 0.477928,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.524144,
        "recall": 0.610113,
        "f1": 0.548123,
        "accuracy": 0.610113,
        "main_score": 0.548123,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.075637,
        "recall": 0.115768,
        "f1": 0.084815,
        "accuracy": 0.115768,
        "main_score": 0.084815,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.592363,
        "recall": 0.674651,
        "f1": 0.615918,
        "accuracy": 0.674651,
        "main_score": 0.615918,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.349936,
        "recall": 0.425815,
        "f1": 0.370694,
        "accuracy": 0.425815,
        "main_score": 0.370694,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.539658,
        "recall": 0.62475,
        "f1": 0.563727,
        "accuracy": 0.62475,
        "main_score": 0.563727,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.558419,
        "recall": 0.638723,
        "f1": 0.581405,
        "accuracy": 0.638723,
        "main_score": 0.581405,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.424373,
        "recall": 0.502994,
        "f1": 0.446343,
        "accuracy": 0.502994,
        "main_score": 0.446343,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.172646,
        "recall": 0.247505,
        "f1": 0.191854,
        "accuracy": 0.247505,
        "main_score": 0.191854,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.429875,
        "recall": 0.510313,
        "f1": 0.451077,
        "accuracy": 0.510313,
        "main_score": 0.451077,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.463997,
        "recall": 0.54358,
        "f1": 0.486072,
        "accuracy": 0.54358,
        "main_score": 0.486072,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.54086,
        "recall": 0.618097,
        "f1": 0.562116,
        "accuracy": 0.618097,
        "main_score": 0.562116,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000683,
        "recall": 0.005323,
        "f1": 0.001068,
        "accuracy": 0.005323,
        "main_score": 0.001068,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.548189,
        "recall": 0.630739,
        "f1": 0.571523,
        "accuracy": 0.630739,
        "main_score": 0.571523,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.505776,
        "recall": 0.588822,
        "f1": 0.528995,
        "accuracy": 0.588822,
        "main_score": 0.528995,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.539872,
        "recall": 0.619428,
        "f1": 0.562393,
        "accuracy": 0.619428,
        "main_score": 0.562393,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.294424,
        "recall": 0.377911,
        "f1": 0.316399,
        "accuracy": 0.377911,
        "main_score": 0.316399,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000231,
        "recall": 0.004657,
        "f1": 0.000432,
        "accuracy": 0.004657,
        "main_score": 0.000432,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.332219,
        "recall": 0.414504,
        "f1": 0.355114,
        "accuracy": 0.414504,
        "main_score": 0.355114,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.419906,
        "recall": 0.50499,
        "f1": 0.443285,
        "accuracy": 0.50499,
        "main_score": 0.443285,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.509058,
        "recall": 0.590153,
        "f1": 0.531447,
        "accuracy": 0.590153,
        "main_score": 0.531447,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.556528,
        "recall": 0.640053,
        "f1": 0.579462,
        "accuracy": 0.640053,
        "main_score": 0.579462,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.867814,
        "recall": 0.902861,
        "f1": 0.87868,
        "accuracy": 0.902861,
        "main_score": 0.87868,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.939421,
        "recall": 0.956088,
        "f1": 0.944444,
        "accuracy": 0.956088,
        "main_score": 0.944444,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.071613,
        "recall": 0.124418,
        "f1": 0.082243,
        "accuracy": 0.124418,
        "main_score": 0.082243,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.549849,
        "recall": 0.649368,
        "f1": 0.57795,
        "accuracy": 0.649368,
        "main_score": 0.57795,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.511124,
        "recall": 0.60346,
        "f1": 0.536445,
        "accuracy": 0.60346,
        "main_score": 0.536445,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.947272,
        "recall": 0.959415,
        "f1": 0.950898,
        "accuracy": 0.959415,
        "main_score": 0.950898,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.943169,
        "recall": 0.958749,
        "f1": 0.948148,
        "accuracy": 0.958749,
        "main_score": 0.948148,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.78548,
        "recall": 0.835662,
        "f1": 0.800711,
        "accuracy": 0.835662,
        "main_score": 0.800711,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.2205,
        "recall": 0.318031,
        "f1": 0.243244,
        "accuracy": 0.318031,
        "main_score": 0.243244,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.683634,
        "recall": 0.752495,
        "f1": 0.703344,
        "accuracy": 0.752495,
        "main_score": 0.703344,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.884409,
        "recall": 0.914172,
        "f1": 0.893492,
        "accuracy": 0.914172,
        "main_score": 0.893492,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.947438,
        "recall": 0.962076,
        "f1": 0.952074,
        "accuracy": 0.962076,
        "main_score": 0.952074,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000434,
        "recall": 0.006653,
        "f1": 0.00075,
        "accuracy": 0.006653,
        "main_score": 0.00075,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.9443,
        "recall": 0.959415,
        "f1": 0.948782,
        "accuracy": 0.959415,
        "main_score": 0.948782,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.9112,
        "recall": 0.933466,
        "f1": 0.917999,
        "accuracy": 0.933466,
        "main_score": 0.917999,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.921435,
        "recall": 0.943446,
        "f1": 0.928267,
        "accuracy": 0.943446,
        "main_score": 0.928267,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.506095,
        "recall": 0.598137,
        "f1": 0.531395,
        "accuracy": 0.598137,
        "main_score": 0.531395,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000802,
        "recall": 0.006653,
        "f1": 0.001285,
        "accuracy": 0.006653,
        "main_score": 0.001285,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.384511,
        "recall": 0.487026,
        "f1": 0.410766,
        "accuracy": 0.487026,
        "main_score": 0.410766,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.827833,
        "recall": 0.869594,
        "f1": 0.840598,
        "accuracy": 0.869594,
        "main_score": 0.840598,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.92057,
        "recall": 0.94145,
        "f1": 0.926946,
        "accuracy": 0.94145,
        "main_score": 0.926946,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.955755,
        "recall": 0.966733,
        "f1": 0.959193,
        "accuracy": 0.966733,
        "main_score": 0.959193,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.446741,
        "recall": 0.528277,
        "f1": 0.468879,
        "accuracy": 0.528277,
        "main_score": 0.468879,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.488606,
        "recall": 0.576846,
        "f1": 0.513102,
        "accuracy": 0.576846,
        "main_score": 0.513102,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.069309,
        "recall": 0.106454,
        "f1": 0.077202,
        "accuracy": 0.106454,
        "main_score": 0.077202,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.353725,
        "recall": 0.431138,
        "f1": 0.375087,
        "accuracy": 0.431138,
        "main_score": 0.375087,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.536419,
        "recall": 0.618097,
        "f1": 0.558049,
        "accuracy": 0.618097,
        "main_score": 0.558049,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.514557,
        "recall": 0.602794,
        "f1": 0.538911,
        "accuracy": 0.602794,
        "main_score": 0.538911,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.513093,
        "recall": 0.590818,
        "f1": 0.534091,
        "accuracy": 0.590818,
        "main_score": 0.534091,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.420769,
        "recall": 0.502329,
        "f1": 0.443132,
        "accuracy": 0.502329,
        "main_score": 0.443132,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.145276,
        "recall": 0.206254,
        "f1": 0.160531,
        "accuracy": 0.206254,
        "main_score": 0.160531,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.374235,
        "recall": 0.451763,
        "f1": 0.396074,
        "accuracy": 0.451763,
        "main_score": 0.396074,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.453918,
        "recall": 0.53493,
        "f1": 0.476775,
        "accuracy": 0.53493,
        "main_score": 0.476775,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.532671,
        "recall": 0.61344,
        "f1": 0.55481,
        "accuracy": 0.61344,
        "main_score": 0.55481,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000913,
        "recall": 0.005323,
        "f1": 0.001123,
        "accuracy": 0.005323,
        "main_score": 0.001123,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.511099,
        "recall": 0.59481,
        "f1": 0.533603,
        "accuracy": 0.59481,
        "main_score": 0.533603,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.462114,
        "recall": 0.550233,
        "f1": 0.48582,
        "accuracy": 0.550233,
        "main_score": 0.48582,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.48089,
        "recall": 0.565536,
        "f1": 0.50341,
        "accuracy": 0.565536,
        "main_score": 0.50341,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.31519,
        "recall": 0.388556,
        "f1": 0.335188,
        "accuracy": 0.388556,
        "main_score": 0.335188,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00098,
        "recall": 0.005988,
        "f1": 0.001232,
        "accuracy": 0.005988,
        "main_score": 0.001232,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.287171,
        "recall": 0.353959,
        "f1": 0.305277,
        "accuracy": 0.353959,
        "main_score": 0.305277,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.398571,
        "recall": 0.480373,
        "f1": 0.419816,
        "accuracy": 0.480373,
        "main_score": 0.419816,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.469517,
        "recall": 0.550898,
        "f1": 0.492091,
        "accuracy": 0.550898,
        "main_score": 0.492091,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.487106,
        "recall": 0.575516,
        "f1": 0.510986,
        "accuracy": 0.575516,
        "main_score": 0.510986,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.84705,
        "recall": 0.884232,
        "f1": 0.858638,
        "accuracy": 0.884232,
        "main_score": 0.858638,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.902313,
        "recall": 0.928144,
        "f1": 0.910346,
        "accuracy": 0.928144,
        "main_score": 0.910346,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.065959,
        "recall": 0.117099,
        "f1": 0.076364,
        "accuracy": 0.117099,
        "main_score": 0.076364,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.493998,
        "recall": 0.596806,
        "f1": 0.522315,
        "accuracy": 0.596806,
        "main_score": 0.522315,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.942526,
        "recall": 0.958084,
        "f1": 0.947372,
        "accuracy": 0.958084,
        "main_score": 0.947372,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.505831,
        "recall": 0.596806,
        "f1": 0.530317,
        "accuracy": 0.596806,
        "main_score": 0.530317,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.917554,
        "recall": 0.937458,
        "f1": 0.923832,
        "accuracy": 0.937458,
        "main_score": 0.923832,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.739871,
        "recall": 0.797073,
        "f1": 0.75674,
        "accuracy": 0.797073,
        "main_score": 0.75674,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.200843,
        "recall": 0.29674,
        "f1": 0.223018,
        "accuracy": 0.29674,
        "main_score": 0.223018,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.665559,
        "recall": 0.734531,
        "f1": 0.685025,
        "accuracy": 0.734531,
        "main_score": 0.685025,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.847882,
        "recall": 0.882901,
        "f1": 0.858895,
        "accuracy": 0.882901,
        "main_score": 0.858895,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.92312,
        "recall": 0.942116,
        "f1": 0.929186,
        "accuracy": 0.942116,
        "main_score": 0.929186,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000289,
        "recall": 0.004657,
        "f1": 0.000496,
        "accuracy": 0.004657,
        "main_score": 0.000496,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.921235,
        "recall": 0.94012,
        "f1": 0.926924,
        "accuracy": 0.94012,
        "main_score": 0.926924,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.886505,
        "recall": 0.914172,
        "f1": 0.895,
        "accuracy": 0.914172,
        "main_score": 0.895,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.889632,
        "recall": 0.918164,
        "f1": 0.898337,
        "accuracy": 0.918164,
        "main_score": 0.898337,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.483341,
        "recall": 0.57352,
        "f1": 0.508302,
        "accuracy": 0.57352,
        "main_score": 0.508302,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001068,
        "recall": 0.005988,
        "f1": 0.001388,
        "accuracy": 0.005988,
        "main_score": 0.001388,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.368746,
        "recall": 0.468397,
        "f1": 0.394741,
        "accuracy": 0.468397,
        "main_score": 0.394741,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.799063,
        "recall": 0.843646,
        "f1": 0.812811,
        "accuracy": 0.843646,
        "main_score": 0.812811,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.876266,
        "recall": 0.903526,
        "f1": 0.884719,
        "accuracy": 0.903526,
        "main_score": 0.884719,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.920215,
        "recall": 0.940785,
        "f1": 0.926747,
        "accuracy": 0.940785,
        "main_score": 0.926747,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.822566,
        "recall": 0.868263,
        "f1": 0.836904,
        "accuracy": 0.868263,
        "main_score": 0.836904,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.904857,
        "recall": 0.930805,
        "f1": 0.913041,
        "accuracy": 0.930805,
        "main_score": 0.913041,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.073948,
        "recall": 0.123752,
        "f1": 0.083774,
        "accuracy": 0.123752,
        "main_score": 0.083774,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.533923,
        "recall": 0.630073,
        "f1": 0.561056,
        "accuracy": 0.630073,
        "main_score": 0.561056,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.941561,
        "recall": 0.958749,
        "f1": 0.946973,
        "accuracy": 0.958749,
        "main_score": 0.946973,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.508294,
        "recall": 0.594145,
        "f1": 0.531859,
        "accuracy": 0.594145,
        "main_score": 0.531859,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.909665,
        "recall": 0.932801,
        "f1": 0.916768,
        "accuracy": 0.932801,
        "main_score": 0.916768,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.769694,
        "recall": 0.822355,
        "f1": 0.785321,
        "accuracy": 0.822355,
        "main_score": 0.785321,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.205867,
        "recall": 0.298736,
        "f1": 0.227549,
        "accuracy": 0.298736,
        "main_score": 0.227549,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.662301,
        "recall": 0.7332,
        "f1": 0.682622,
        "accuracy": 0.7332,
        "main_score": 0.682622,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.851697,
        "recall": 0.887558,
        "f1": 0.862675,
        "accuracy": 0.887558,
        "main_score": 0.862675,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.909758,
        "recall": 0.93147,
        "f1": 0.916456,
        "accuracy": 0.93147,
        "main_score": 0.916456,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000957,
        "recall": 0.005988,
        "f1": 0.001181,
        "accuracy": 0.005988,
        "main_score": 0.001181,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.910035,
        "recall": 0.93147,
        "f1": 0.916491,
        "accuracy": 0.93147,
        "main_score": 0.916491,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.886971,
        "recall": 0.915502,
        "f1": 0.895644,
        "accuracy": 0.915502,
        "main_score": 0.895644,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.89618,
        "recall": 0.922156,
        "f1": 0.904073,
        "accuracy": 0.922156,
        "main_score": 0.904073,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.46522,
        "recall": 0.559548,
        "f1": 0.49157,
        "accuracy": 0.559548,
        "main_score": 0.49157,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000179,
        "recall": 0.003992,
        "f1": 0.000337,
        "accuracy": 0.003992,
        "main_score": 0.000337,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.385454,
        "recall": 0.491018,
        "f1": 0.413271,
        "accuracy": 0.491018,
        "main_score": 0.413271,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.805489,
        "recall": 0.850965,
        "f1": 0.819605,
        "accuracy": 0.850965,
        "main_score": 0.819605,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.878709,
        "recall": 0.906853,
        "f1": 0.887514,
        "accuracy": 0.906853,
        "main_score": 0.887514,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.923897,
        "recall": 0.944777,
        "f1": 0.930384,
        "accuracy": 0.944777,
        "main_score": 0.930384,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.707986,
        "recall": 0.769128,
        "f1": 0.726493,
        "accuracy": 0.769128,
        "main_score": 0.726493,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.784327,
        "recall": 0.832335,
        "f1": 0.798836,
        "accuracy": 0.832335,
        "main_score": 0.798836,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.066432,
        "recall": 0.111111,
        "f1": 0.075399,
        "accuracy": 0.111111,
        "main_score": 0.075399,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.412443,
        "recall": 0.508982,
        "f1": 0.439646,
        "accuracy": 0.508982,
        "main_score": 0.439646,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.816374,
        "recall": 0.857618,
        "f1": 0.82902,
        "accuracy": 0.857618,
        "main_score": 0.82902,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.418712,
        "recall": 0.512309,
        "f1": 0.444618,
        "accuracy": 0.512309,
        "main_score": 0.444618,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.759226,
        "recall": 0.809714,
        "f1": 0.77454,
        "accuracy": 0.809714,
        "main_score": 0.77454,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.784586,
        "recall": 0.829674,
        "f1": 0.798305,
        "accuracy": 0.829674,
        "main_score": 0.798305,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.171237,
        "recall": 0.25682,
        "f1": 0.192278,
        "accuracy": 0.25682,
        "main_score": 0.192278,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.541612,
        "recall": 0.616766,
        "f1": 0.563526,
        "accuracy": 0.616766,
        "main_score": 0.563526,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.731822,
        "recall": 0.788423,
        "f1": 0.748937,
        "accuracy": 0.788423,
        "main_score": 0.748937,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.785773,
        "recall": 0.832335,
        "f1": 0.799867,
        "accuracy": 0.832335,
        "main_score": 0.799867,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000231,
        "recall": 0.005323,
        "f1": 0.000422,
        "accuracy": 0.005323,
        "main_score": 0.000422,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.778166,
        "recall": 0.825682,
        "f1": 0.792162,
        "accuracy": 0.825682,
        "main_score": 0.792162,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.736882,
        "recall": 0.797073,
        "f1": 0.755137,
        "accuracy": 0.797073,
        "main_score": 0.755137,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.736172,
        "recall": 0.793746,
        "f1": 0.75387,
        "accuracy": 0.793746,
        "main_score": 0.75387,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.390423,
        "recall": 0.481703,
        "f1": 0.416308,
        "accuracy": 0.481703,
        "main_score": 0.416308,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001157,
        "recall": 0.007319,
        "f1": 0.001503,
        "accuracy": 0.007319,
        "main_score": 0.001503,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.316082,
        "recall": 0.409182,
        "f1": 0.340659,
        "accuracy": 0.409182,
        "main_score": 0.340659,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.704646,
        "recall": 0.768463,
        "f1": 0.72393,
        "accuracy": 0.768463,
        "main_score": 0.72393,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.776103,
        "recall": 0.825682,
        "f1": 0.791088,
        "accuracy": 0.825682,
        "main_score": 0.791088,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.775516,
        "recall": 0.823686,
        "f1": 0.789922,
        "accuracy": 0.823686,
        "main_score": 0.789922,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.173052,
        "recall": 0.229541,
        "f1": 0.186316,
        "accuracy": 0.229541,
        "main_score": 0.186316,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.181248,
        "recall": 0.246174,
        "f1": 0.196153,
        "accuracy": 0.246174,
        "main_score": 0.196153,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.049673,
        "recall": 0.081171,
        "f1": 0.056231,
        "accuracy": 0.081171,
        "main_score": 0.056231,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.164943,
        "recall": 0.21823,
        "f1": 0.176879,
        "accuracy": 0.21823,
        "main_score": 0.176879,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.222489,
        "recall": 0.288756,
        "f1": 0.238149,
        "accuracy": 0.288756,
        "main_score": 0.238149,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.150399,
        "recall": 0.202927,
        "f1": 0.162412,
        "accuracy": 0.202927,
        "main_score": 0.162412,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.209051,
        "recall": 0.272122,
        "f1": 0.22351,
        "accuracy": 0.272122,
        "main_score": 0.22351,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.213401,
        "recall": 0.270126,
        "f1": 0.226966,
        "accuracy": 0.270126,
        "main_score": 0.226966,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.170886,
        "recall": 0.220892,
        "f1": 0.182788,
        "accuracy": 0.220892,
        "main_score": 0.182788,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.170763,
        "recall": 0.222222,
        "f1": 0.182829,
        "accuracy": 0.222222,
        "main_score": 0.182829,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.181068,
        "recall": 0.235529,
        "f1": 0.194087,
        "accuracy": 0.235529,
        "main_score": 0.194087,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.196284,
        "recall": 0.257485,
        "f1": 0.210379,
        "accuracy": 0.257485,
        "main_score": 0.210379,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000923,
        "recall": 0.006653,
        "f1": 0.001447,
        "accuracy": 0.006653,
        "main_score": 0.001447,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.193325,
        "recall": 0.252162,
        "f1": 0.206835,
        "accuracy": 0.252162,
        "main_score": 0.206835,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.183,
        "recall": 0.240852,
        "f1": 0.195805,
        "accuracy": 0.240852,
        "main_score": 0.195805,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.206716,
        "recall": 0.262808,
        "f1": 0.218914,
        "accuracy": 0.262808,
        "main_score": 0.218914,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.139863,
        "recall": 0.190286,
        "f1": 0.151687,
        "accuracy": 0.190286,
        "main_score": 0.151687,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001063,
        "recall": 0.005988,
        "f1": 0.001382,
        "accuracy": 0.005988,
        "main_score": 0.001382,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.151977,
        "recall": 0.204923,
        "f1": 0.164825,
        "accuracy": 0.204923,
        "main_score": 0.164825,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.163342,
        "recall": 0.215569,
        "f1": 0.174808,
        "accuracy": 0.215569,
        "main_score": 0.174808,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.201757,
        "recall": 0.25815,
        "f1": 0.214688,
        "accuracy": 0.25815,
        "main_score": 0.214688,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.233645,
        "recall": 0.298736,
        "f1": 0.248017,
        "accuracy": 0.298736,
        "main_score": 0.248017,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.595101,
        "recall": 0.671324,
        "f1": 0.617086,
        "accuracy": 0.671324,
        "main_score": 0.617086,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.661445,
        "recall": 0.725882,
        "f1": 0.679879,
        "accuracy": 0.725882,
        "main_score": 0.679879,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.068356,
        "recall": 0.109115,
        "f1": 0.076715,
        "accuracy": 0.109115,
        "main_score": 0.076715,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.456351,
        "recall": 0.548902,
        "f1": 0.482684,
        "accuracy": 0.548902,
        "main_score": 0.482684,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.73599,
        "recall": 0.789088,
        "f1": 0.750889,
        "accuracy": 0.789088,
        "main_score": 0.750889,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.393068,
        "recall": 0.480373,
        "f1": 0.416155,
        "accuracy": 0.480373,
        "main_score": 0.416155,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.700672,
        "recall": 0.757152,
        "f1": 0.716929,
        "accuracy": 0.757152,
        "main_score": 0.716929,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.689718,
        "recall": 0.754491,
        "f1": 0.708111,
        "accuracy": 0.754491,
        "main_score": 0.708111,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.553776,
        "recall": 0.628077,
        "f1": 0.57514,
        "accuracy": 0.628077,
        "main_score": 0.57514,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.183472,
        "recall": 0.270126,
        "f1": 0.204225,
        "accuracy": 0.270126,
        "main_score": 0.204225,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.570901,
        "recall": 0.644711,
        "f1": 0.591705,
        "accuracy": 0.644711,
        "main_score": 0.591705,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.693114,
        "recall": 0.750499,
        "f1": 0.709769,
        "accuracy": 0.750499,
        "main_score": 0.709769,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00119,
        "recall": 0.003992,
        "f1": 0.001425,
        "accuracy": 0.003992,
        "main_score": 0.001425,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.706656,
        "recall": 0.761144,
        "f1": 0.721861,
        "accuracy": 0.761144,
        "main_score": 0.721861,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.614128,
        "recall": 0.693945,
        "f1": 0.636601,
        "accuracy": 0.693945,
        "main_score": 0.636601,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.649649,
        "recall": 0.718563,
        "f1": 0.668899,
        "accuracy": 0.718563,
        "main_score": 0.668899,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.417879,
        "recall": 0.503659,
        "f1": 0.44173,
        "accuracy": 0.503659,
        "main_score": 0.44173,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000218,
        "recall": 0.005323,
        "f1": 0.000413,
        "accuracy": 0.005323,
        "main_score": 0.000413,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.348897,
        "recall": 0.437791,
        "f1": 0.371907,
        "accuracy": 0.437791,
        "main_score": 0.371907,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.539168,
        "recall": 0.61477,
        "f1": 0.560705,
        "accuracy": 0.61477,
        "main_score": 0.560705,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.638515,
        "recall": 0.705256,
        "f1": 0.657553,
        "accuracy": 0.705256,
        "main_score": 0.657553,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.693149,
        "recall": 0.757818,
        "f1": 0.712134,
        "accuracy": 0.757818,
        "main_score": 0.712134,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.770004,
        "recall": 0.823021,
        "f1": 0.786063,
        "accuracy": 0.823021,
        "main_score": 0.786063,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.85163,
        "recall": 0.886893,
        "f1": 0.862808,
        "accuracy": 0.886893,
        "main_score": 0.862808,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.065445,
        "recall": 0.112442,
        "f1": 0.075053,
        "accuracy": 0.112442,
        "main_score": 0.075053,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.44278,
        "recall": 0.540918,
        "f1": 0.469927,
        "accuracy": 0.540918,
        "main_score": 0.469927,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.8866,
        "recall": 0.916168,
        "f1": 0.895953,
        "accuracy": 0.916168,
        "main_score": 0.895953,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.445792,
        "recall": 0.539587,
        "f1": 0.471795,
        "accuracy": 0.539587,
        "main_score": 0.471795,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.862481,
        "recall": 0.896873,
        "f1": 0.873287,
        "accuracy": 0.896873,
        "main_score": 0.873287,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.853787,
        "recall": 0.886893,
        "f1": 0.863399,
        "accuracy": 0.886893,
        "main_score": 0.863399,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.732197,
        "recall": 0.787758,
        "f1": 0.74873,
        "accuracy": 0.787758,
        "main_score": 0.74873,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.192807,
        "recall": 0.27811,
        "f1": 0.212004,
        "accuracy": 0.27811,
        "main_score": 0.212004,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.576332,
        "recall": 0.652029,
        "f1": 0.597993,
        "accuracy": 0.652029,
        "main_score": 0.597993,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.863091,
        "recall": 0.896208,
        "f1": 0.87322,
        "accuracy": 0.896208,
        "main_score": 0.87322,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00056,
        "recall": 0.004657,
        "f1": 0.000827,
        "accuracy": 0.004657,
        "main_score": 0.000827,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.862486,
        "recall": 0.893546,
        "f1": 0.87178,
        "accuracy": 0.893546,
        "main_score": 0.87178,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.835928,
        "recall": 0.875582,
        "f1": 0.847651,
        "accuracy": 0.875582,
        "main_score": 0.847651,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.830805,
        "recall": 0.87159,
        "f1": 0.84338,
        "accuracy": 0.87159,
        "main_score": 0.84338,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.42493,
        "recall": 0.520293,
        "f1": 0.451145,
        "accuracy": 0.520293,
        "main_score": 0.451145,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000258,
        "recall": 0.003992,
        "f1": 0.000468,
        "accuracy": 0.003992,
        "main_score": 0.000468,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.330629,
        "recall": 0.420492,
        "f1": 0.353757,
        "accuracy": 0.420492,
        "main_score": 0.353757,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.772616,
        "recall": 0.823686,
        "f1": 0.788318,
        "accuracy": 0.823686,
        "main_score": 0.788318,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.836167,
        "recall": 0.875582,
        "f1": 0.848159,
        "accuracy": 0.875582,
        "main_score": 0.848159,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.849086,
        "recall": 0.886228,
        "f1": 0.860534,
        "accuracy": 0.886228,
        "main_score": 0.860534,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.834781,
        "recall": 0.874917,
        "f1": 0.847339,
        "accuracy": 0.874917,
        "main_score": 0.847339,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.899446,
        "recall": 0.926148,
        "f1": 0.907708,
        "accuracy": 0.926148,
        "main_score": 0.907708,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.06846,
        "recall": 0.117099,
        "f1": 0.078416,
        "accuracy": 0.117099,
        "main_score": 0.078416,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.507097,
        "recall": 0.607452,
        "f1": 0.535652,
        "accuracy": 0.607452,
        "main_score": 0.535652,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.940674,
        "recall": 0.957418,
        "f1": 0.945997,
        "accuracy": 0.957418,
        "main_score": 0.945997,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.51911,
        "recall": 0.607452,
        "f1": 0.542849,
        "accuracy": 0.607452,
        "main_score": 0.542849,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.927146,
        "recall": 0.944112,
        "f1": 0.932579,
        "accuracy": 0.944112,
        "main_score": 0.932579,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.909758,
        "recall": 0.933466,
        "f1": 0.917033,
        "accuracy": 0.933466,
        "main_score": 0.917033,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.733345,
        "recall": 0.795077,
        "f1": 0.751868,
        "accuracy": 0.795077,
        "main_score": 0.751868,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.197012,
        "recall": 0.288756,
        "f1": 0.217791,
        "accuracy": 0.288756,
        "main_score": 0.217791,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.656882,
        "recall": 0.727878,
        "f1": 0.677653,
        "accuracy": 0.727878,
        "main_score": 0.677653,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.836715,
        "recall": 0.878244,
        "f1": 0.849593,
        "accuracy": 0.878244,
        "main_score": 0.849593,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000344,
        "recall": 0.005323,
        "f1": 0.000593,
        "accuracy": 0.005323,
        "main_score": 0.000593,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.906631,
        "recall": 0.929474,
        "f1": 0.913563,
        "accuracy": 0.929474,
        "main_score": 0.913563,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.866163,
        "recall": 0.9002,
        "f1": 0.876493,
        "accuracy": 0.9002,
        "main_score": 0.876493,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.88778,
        "recall": 0.916833,
        "f1": 0.897073,
        "accuracy": 0.916833,
        "main_score": 0.897073,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.478355,
        "recall": 0.566866,
        "f1": 0.502954,
        "accuracy": 0.566866,
        "main_score": 0.502954,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000641,
        "recall": 0.005988,
        "f1": 0.001001,
        "accuracy": 0.005988,
        "main_score": 0.001001,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.373541,
        "recall": 0.471723,
        "f1": 0.398255,
        "accuracy": 0.471723,
        "main_score": 0.398255,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.78024,
        "recall": 0.83167,
        "f1": 0.795834,
        "accuracy": 0.83167,
        "main_score": 0.795834,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.864678,
        "recall": 0.895542,
        "f1": 0.874362,
        "accuracy": 0.895542,
        "main_score": 0.874362,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.908239,
        "recall": 0.932801,
        "f1": 0.915968,
        "accuracy": 0.932801,
        "main_score": 0.915968,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.00067,
        "recall": 0.002661,
        "f1": 0.000675,
        "accuracy": 0.002661,
        "main_score": 0.000675,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.000722,
        "recall": 0.002661,
        "f1": 0.000775,
        "accuracy": 0.002661,
        "main_score": 0.000775,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001382,
        "recall": 0.001996,
        "f1": 0.001426,
        "accuracy": 0.001996,
        "main_score": 0.001426,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.000793,
        "recall": 0.003327,
        "f1": 0.000895,
        "accuracy": 0.003327,
        "main_score": 0.000895,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000945,
        "recall": 0.002661,
        "f1": 0.001126,
        "accuracy": 0.002661,
        "main_score": 0.001126,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001333,
        "recall": 0.002661,
        "f1": 0.001336,
        "accuracy": 0.002661,
        "main_score": 0.001336,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 7.5e-05,
        "recall": 0.001331,
        "f1": 0.000134,
        "accuracy": 0.001331,
        "main_score": 0.000134,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.00161,
        "recall": 0.004657,
        "f1": 0.001799,
        "accuracy": 0.004657,
        "main_score": 0.001799,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000764,
        "recall": 0.003327,
        "f1": 0.000846,
        "accuracy": 0.003327,
        "main_score": 0.000846,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000695,
        "recall": 0.003327,
        "f1": 0.000722,
        "accuracy": 0.003327,
        "main_score": 0.000722,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.000676,
        "recall": 0.001996,
        "f1": 0.000686,
        "accuracy": 0.001996,
        "main_score": 0.000686,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.000162,
        "recall": 0.002661,
        "f1": 0.000279,
        "accuracy": 0.002661,
        "main_score": 0.000279,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000855,
        "recall": 0.003992,
        "f1": 0.000977,
        "accuracy": 0.003992,
        "main_score": 0.000977,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 3.4e-05,
        "recall": 0.002661,
        "f1": 6.6e-05,
        "accuracy": 0.002661,
        "main_score": 6.6e-05,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.000224,
        "recall": 0.001331,
        "f1": 0.000337,
        "accuracy": 0.001331,
        "main_score": 0.000337,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 6e-05,
        "recall": 0.002661,
        "f1": 0.000116,
        "accuracy": 0.002661,
        "main_score": 0.000116,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001362,
        "recall": 0.004657,
        "f1": 0.001392,
        "accuracy": 0.004657,
        "main_score": 0.001392,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.028975,
        "recall": 0.042582,
        "f1": 0.03177,
        "accuracy": 0.042582,
        "main_score": 0.03177,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.000731,
        "recall": 0.002661,
        "f1": 0.000788,
        "accuracy": 0.002661,
        "main_score": 0.000788,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.000738,
        "recall": 0.004657,
        "f1": 0.000806,
        "accuracy": 0.004657,
        "main_score": 0.000806,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.00027,
        "recall": 0.002661,
        "f1": 0.00045,
        "accuracy": 0.002661,
        "main_score": 0.00045,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001331,
        "f1": 7e-06,
        "accuracy": 0.001331,
        "main_score": 7e-06,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.83646,
        "recall": 0.878244,
        "f1": 0.849501,
        "accuracy": 0.878244,
        "main_score": 0.849501,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.907263,
        "recall": 0.932136,
        "f1": 0.915103,
        "accuracy": 0.932136,
        "main_score": 0.915103,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.062975,
        "recall": 0.113772,
        "f1": 0.073378,
        "accuracy": 0.113772,
        "main_score": 0.073378,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.523194,
        "recall": 0.619428,
        "f1": 0.549901,
        "accuracy": 0.619428,
        "main_score": 0.549901,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.946296,
        "recall": 0.96008,
        "f1": 0.950588,
        "accuracy": 0.96008,
        "main_score": 0.950588,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.50164,
        "recall": 0.592814,
        "f1": 0.526793,
        "accuracy": 0.592814,
        "main_score": 0.526793,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.921513,
        "recall": 0.940785,
        "f1": 0.927456,
        "accuracy": 0.940785,
        "main_score": 0.927456,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.90896,
        "recall": 0.932801,
        "f1": 0.916336,
        "accuracy": 0.932801,
        "main_score": 0.916336,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.74745,
        "recall": 0.804391,
        "f1": 0.764309,
        "accuracy": 0.804391,
        "main_score": 0.764309,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.197622,
        "recall": 0.289421,
        "f1": 0.218461,
        "accuracy": 0.289421,
        "main_score": 0.218461,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.688106,
        "recall": 0.75183,
        "f1": 0.706256,
        "accuracy": 0.75183,
        "main_score": 0.706256,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.842648,
        "recall": 0.882236,
        "f1": 0.854881,
        "accuracy": 0.882236,
        "main_score": 0.854881,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.916323,
        "recall": 0.937458,
        "f1": 0.922799,
        "accuracy": 0.937458,
        "main_score": 0.922799,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000264,
        "recall": 0.005323,
        "f1": 0.000474,
        "accuracy": 0.005323,
        "main_score": 0.000474,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.871391,
        "recall": 0.904857,
        "f1": 0.881738,
        "accuracy": 0.904857,
        "main_score": 0.881738,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.891351,
        "recall": 0.918829,
        "f1": 0.900089,
        "accuracy": 0.918829,
        "main_score": 0.900089,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.493567,
        "recall": 0.582834,
        "f1": 0.5184,
        "accuracy": 0.582834,
        "main_score": 0.5184,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000385,
        "recall": 0.003992,
        "f1": 0.000667,
        "accuracy": 0.003992,
        "main_score": 0.000667,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.366929,
        "recall": 0.468397,
        "f1": 0.393242,
        "accuracy": 0.468397,
        "main_score": 0.393242,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.79043,
        "recall": 0.838989,
        "f1": 0.805269,
        "accuracy": 0.838989,
        "main_score": 0.805269,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.871307,
        "recall": 0.900865,
        "f1": 0.880432,
        "accuracy": 0.900865,
        "main_score": 0.880432,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.925006,
        "recall": 0.944777,
        "f1": 0.931182,
        "accuracy": 0.944777,
        "main_score": 0.931182,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.834076,
        "recall": 0.876913,
        "f1": 0.847638,
        "accuracy": 0.876913,
        "main_score": 0.847638,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.897594,
        "recall": 0.924817,
        "f1": 0.90621,
        "accuracy": 0.924817,
        "main_score": 0.90621,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.063094,
        "recall": 0.114438,
        "f1": 0.074071,
        "accuracy": 0.114438,
        "main_score": 0.074071,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.479592,
        "recall": 0.582169,
        "f1": 0.508563,
        "accuracy": 0.582169,
        "main_score": 0.508563,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.911732,
        "recall": 0.936128,
        "f1": 0.919361,
        "accuracy": 0.936128,
        "main_score": 0.919361,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.471498,
        "recall": 0.56354,
        "f1": 0.496945,
        "accuracy": 0.56354,
        "main_score": 0.496945,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.902196,
        "recall": 0.926148,
        "f1": 0.909438,
        "accuracy": 0.926148,
        "main_score": 0.909438,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.896607,
        "recall": 0.922156,
        "f1": 0.904369,
        "accuracy": 0.922156,
        "main_score": 0.904369,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.738047,
        "recall": 0.795077,
        "f1": 0.755071,
        "accuracy": 0.795077,
        "main_score": 0.755071,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.203933,
        "recall": 0.292083,
        "f1": 0.22526,
        "accuracy": 0.292083,
        "main_score": 0.22526,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.616578,
        "recall": 0.696607,
        "f1": 0.639827,
        "accuracy": 0.696607,
        "main_score": 0.639827,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.841949,
        "recall": 0.882901,
        "f1": 0.854725,
        "accuracy": 0.882901,
        "main_score": 0.854725,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.893402,
        "recall": 0.918829,
        "f1": 0.901353,
        "accuracy": 0.918829,
        "main_score": 0.901353,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000133,
        "recall": 0.003992,
        "f1": 0.000241,
        "accuracy": 0.003992,
        "main_score": 0.000241,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.895831,
        "recall": 0.92016,
        "f1": 0.903149,
        "accuracy": 0.92016,
        "main_score": 0.903149,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.853438,
        "recall": 0.89155,
        "f1": 0.865181,
        "accuracy": 0.89155,
        "main_score": 0.865181,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.433747,
        "recall": 0.533599,
        "f1": 0.461316,
        "accuracy": 0.533599,
        "main_score": 0.461316,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000222,
        "recall": 0.003992,
        "f1": 0.000406,
        "accuracy": 0.003992,
        "main_score": 0.000406,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.340297,
        "recall": 0.438456,
        "f1": 0.366366,
        "accuracy": 0.438456,
        "main_score": 0.366366,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.77505,
        "recall": 0.824351,
        "f1": 0.790254,
        "accuracy": 0.824351,
        "main_score": 0.790254,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.85224,
        "recall": 0.888889,
        "f1": 0.863717,
        "accuracy": 0.888889,
        "main_score": 0.863717,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.898503,
        "recall": 0.924817,
        "f1": 0.906653,
        "accuracy": 0.924817,
        "main_score": 0.906653,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.815414,
        "recall": 0.860279,
        "f1": 0.829408,
        "accuracy": 0.860279,
        "main_score": 0.829408,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.897893,
        "recall": 0.923486,
        "f1": 0.905801,
        "accuracy": 0.923486,
        "main_score": 0.905801,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.066368,
        "recall": 0.113107,
        "f1": 0.076056,
        "accuracy": 0.113107,
        "main_score": 0.076056,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.524971,
        "recall": 0.620093,
        "f1": 0.551301,
        "accuracy": 0.620093,
        "main_score": 0.551301,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.936117,
        "recall": 0.954092,
        "f1": 0.941717,
        "accuracy": 0.954092,
        "main_score": 0.941717,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.481778,
        "recall": 0.570858,
        "f1": 0.505885,
        "accuracy": 0.570858,
        "main_score": 0.505885,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.902584,
        "recall": 0.927478,
        "f1": 0.910424,
        "accuracy": 0.927478,
        "main_score": 0.910424,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.902961,
        "recall": 0.927478,
        "f1": 0.910392,
        "accuracy": 0.927478,
        "main_score": 0.910392,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.709216,
        "recall": 0.77179,
        "f1": 0.727336,
        "accuracy": 0.77179,
        "main_score": 0.727336,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.220761,
        "recall": 0.304724,
        "f1": 0.239582,
        "accuracy": 0.304724,
        "main_score": 0.239582,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.634336,
        "recall": 0.708583,
        "f1": 0.655265,
        "accuracy": 0.708583,
        "main_score": 0.655265,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.819794,
        "recall": 0.864271,
        "f1": 0.833546,
        "accuracy": 0.864271,
        "main_score": 0.833546,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.904325,
        "recall": 0.926813,
        "f1": 0.911377,
        "accuracy": 0.926813,
        "main_score": 0.911377,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000507,
        "recall": 0.005988,
        "f1": 0.000871,
        "accuracy": 0.005988,
        "main_score": 0.000871,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.903255,
        "recall": 0.926148,
        "f1": 0.910013,
        "accuracy": 0.926148,
        "main_score": 0.910013,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.860734,
        "recall": 0.894212,
        "f1": 0.871169,
        "accuracy": 0.894212,
        "main_score": 0.871169,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.465613,
        "recall": 0.558217,
        "f1": 0.491076,
        "accuracy": 0.558217,
        "main_score": 0.491076,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000294,
        "recall": 0.005988,
        "f1": 0.00055,
        "accuracy": 0.005988,
        "main_score": 0.00055,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.365987,
        "recall": 0.463074,
        "f1": 0.391618,
        "accuracy": 0.463074,
        "main_score": 0.391618,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.761959,
        "recall": 0.813041,
        "f1": 0.777061,
        "accuracy": 0.813041,
        "main_score": 0.777061,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.852002,
        "recall": 0.884232,
        "f1": 0.861799,
        "accuracy": 0.884232,
        "main_score": 0.861799,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.919661,
        "recall": 0.94012,
        "f1": 0.926049,
        "accuracy": 0.94012,
        "main_score": 0.926049,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.403798,
        "recall": 0.486361,
        "f1": 0.426041,
        "accuracy": 0.486361,
        "main_score": 0.426041,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.451601,
        "recall": 0.540918,
        "f1": 0.475953,
        "accuracy": 0.540918,
        "main_score": 0.475953,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.061706,
        "recall": 0.095143,
        "f1": 0.068866,
        "accuracy": 0.095143,
        "main_score": 0.068866,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.283832,
        "recall": 0.365269,
        "f1": 0.305324,
        "accuracy": 0.365269,
        "main_score": 0.305324,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.503827,
        "recall": 0.591484,
        "f1": 0.526774,
        "accuracy": 0.591484,
        "main_score": 0.526774,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.290433,
        "recall": 0.3666,
        "f1": 0.310223,
        "accuracy": 0.3666,
        "main_score": 0.310223,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.469631,
        "recall": 0.548902,
        "f1": 0.490457,
        "accuracy": 0.548902,
        "main_score": 0.490457,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.462042,
        "recall": 0.54491,
        "f1": 0.484078,
        "accuracy": 0.54491,
        "main_score": 0.484078,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.381963,
        "recall": 0.462409,
        "f1": 0.403418,
        "accuracy": 0.462409,
        "main_score": 0.403418,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.136505,
        "recall": 0.204923,
        "f1": 0.15303,
        "accuracy": 0.204923,
        "main_score": 0.15303,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.39994,
        "recall": 0.483699,
        "f1": 0.421772,
        "accuracy": 0.483699,
        "main_score": 0.421772,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.420169,
        "recall": 0.502994,
        "f1": 0.441803,
        "accuracy": 0.502994,
        "main_score": 0.441803,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.475266,
        "recall": 0.556221,
        "f1": 0.4963,
        "accuracy": 0.556221,
        "main_score": 0.4963,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000189,
        "recall": 0.003992,
        "f1": 0.000341,
        "accuracy": 0.003992,
        "main_score": 0.000341,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.489306,
        "recall": 0.566201,
        "f1": 0.509451,
        "accuracy": 0.566201,
        "main_score": 0.509451,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.417361,
        "recall": 0.50499,
        "f1": 0.440534,
        "accuracy": 0.50499,
        "main_score": 0.440534,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.444149,
        "recall": 0.527611,
        "f1": 0.465912,
        "accuracy": 0.527611,
        "main_score": 0.465912,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000922,
        "recall": 0.005988,
        "f1": 0.00146,
        "accuracy": 0.005988,
        "main_score": 0.00146,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.225116,
        "recall": 0.298736,
        "f1": 0.243503,
        "accuracy": 0.298736,
        "main_score": 0.243503,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.374862,
        "recall": 0.455755,
        "f1": 0.396405,
        "accuracy": 0.455755,
        "main_score": 0.396405,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.44015,
        "recall": 0.517631,
        "f1": 0.460521,
        "accuracy": 0.517631,
        "main_score": 0.460521,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.44533,
        "recall": 0.532934,
        "f1": 0.468631,
        "accuracy": 0.532934,
        "main_score": 0.468631,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001003,
        "recall": 0.003327,
        "f1": 0.001119,
        "accuracy": 0.003327,
        "main_score": 0.001119,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.001696,
        "recall": 0.003992,
        "f1": 0.001838,
        "accuracy": 0.003992,
        "main_score": 0.001838,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001714,
        "recall": 0.003992,
        "f1": 0.001871,
        "accuracy": 0.003992,
        "main_score": 0.001871,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.001089,
        "recall": 0.003992,
        "f1": 0.001273,
        "accuracy": 0.003992,
        "main_score": 0.001273,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001678,
        "recall": 0.003327,
        "f1": 0.001804,
        "accuracy": 0.003327,
        "main_score": 0.001804,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001666,
        "recall": 0.003327,
        "f1": 0.00178,
        "accuracy": 0.003327,
        "main_score": 0.00178,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.001015,
        "recall": 0.003327,
        "f1": 0.001142,
        "accuracy": 0.003327,
        "main_score": 0.001142,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.001666,
        "recall": 0.003327,
        "f1": 0.00178,
        "accuracy": 0.003327,
        "main_score": 0.00178,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001172,
        "recall": 0.003992,
        "f1": 0.001447,
        "accuracy": 0.003992,
        "main_score": 0.001447,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000355,
        "recall": 0.002661,
        "f1": 0.000488,
        "accuracy": 0.002661,
        "main_score": 0.000488,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.000675,
        "recall": 0.002661,
        "f1": 0.000906,
        "accuracy": 0.002661,
        "main_score": 0.000906,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.000345,
        "recall": 0.002661,
        "f1": 0.000469,
        "accuracy": 0.002661,
        "main_score": 0.000469,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001675,
        "recall": 0.003992,
        "f1": 0.001798,
        "accuracy": 0.003992,
        "main_score": 0.001798,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.02496,
        "recall": 0.043247,
        "f1": 0.029125,
        "accuracy": 0.043247,
        "main_score": 0.029125,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.00056,
        "recall": 0.001996,
        "f1": 0.000787,
        "accuracy": 0.001996,
        "main_score": 0.000787,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.000574,
        "recall": 0.003992,
        "f1": 0.00085,
        "accuracy": 0.003992,
        "main_score": 0.00085,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.001698,
        "recall": 0.003992,
        "f1": 0.00184,
        "accuracy": 0.003992,
        "main_score": 0.00184,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001679,
        "recall": 0.004657,
        "f1": 0.001805,
        "accuracy": 0.004657,
        "main_score": 0.001805,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000375,
        "recall": 0.001996,
        "f1": 0.000524,
        "accuracy": 0.001996,
        "main_score": 0.000524,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.001078,
        "recall": 0.005323,
        "f1": 0.001263,
        "accuracy": 0.005323,
        "main_score": 0.001263,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000343,
        "recall": 0.002661,
        "f1": 0.000463,
        "accuracy": 0.002661,
        "main_score": 0.000463,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001005,
        "recall": 0.002661,
        "f1": 0.001124,
        "accuracy": 0.002661,
        "main_score": 0.001124,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.324394,
        "recall": 0.401863,
        "f1": 0.344413,
        "accuracy": 0.401863,
        "main_score": 0.344413,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.364533,
        "recall": 0.443114,
        "f1": 0.384675,
        "accuracy": 0.443114,
        "main_score": 0.384675,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.076197,
        "recall": 0.113772,
        "f1": 0.08458,
        "accuracy": 0.113772,
        "main_score": 0.08458,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.337905,
        "recall": 0.409847,
        "f1": 0.357114,
        "accuracy": 0.409847,
        "main_score": 0.357114,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.419255,
        "recall": 0.494345,
        "f1": 0.438591,
        "accuracy": 0.494345,
        "main_score": 0.438591,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.280111,
        "recall": 0.352628,
        "f1": 0.299227,
        "accuracy": 0.352628,
        "main_score": 0.299227,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.373318,
        "recall": 0.451098,
        "f1": 0.393548,
        "accuracy": 0.451098,
        "main_score": 0.393548,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.410756,
        "recall": 0.489687,
        "f1": 0.431561,
        "accuracy": 0.489687,
        "main_score": 0.431561,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.325375,
        "recall": 0.399202,
        "f1": 0.344991,
        "accuracy": 0.399202,
        "main_score": 0.344991,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.163347,
        "recall": 0.224884,
        "f1": 0.178285,
        "accuracy": 0.224884,
        "main_score": 0.178285,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.336008,
        "recall": 0.40652,
        "f1": 0.353649,
        "accuracy": 0.40652,
        "main_score": 0.353649,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.344212,
        "recall": 0.417166,
        "f1": 0.363185,
        "accuracy": 0.417166,
        "main_score": 0.363185,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.376339,
        "recall": 0.455755,
        "f1": 0.397294,
        "accuracy": 0.455755,
        "main_score": 0.397294,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000984,
        "recall": 0.006653,
        "f1": 0.00152,
        "accuracy": 0.006653,
        "main_score": 0.00152,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.377945,
        "recall": 0.454424,
        "f1": 0.397872,
        "accuracy": 0.454424,
        "main_score": 0.397872,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.337598,
        "recall": 0.411843,
        "f1": 0.357034,
        "accuracy": 0.411843,
        "main_score": 0.357034,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.369363,
        "recall": 0.44511,
        "f1": 0.388966,
        "accuracy": 0.44511,
        "main_score": 0.388966,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.247164,
        "recall": 0.314039,
        "f1": 0.26498,
        "accuracy": 0.314039,
        "main_score": 0.26498,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000397,
        "recall": 0.003992,
        "f1": 0.000695,
        "accuracy": 0.003992,
        "main_score": 0.000695,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.277584,
        "recall": 0.360612,
        "f1": 0.299116,
        "accuracy": 0.360612,
        "main_score": 0.299116,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.361343,
        "recall": 0.434464,
        "f1": 0.38005,
        "accuracy": 0.434464,
        "main_score": 0.38005,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.388076,
        "recall": 0.460413,
        "f1": 0.406463,
        "accuracy": 0.460413,
        "main_score": 0.406463,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.702697,
        "recall": 0.768463,
        "f1": 0.722433,
        "accuracy": 0.768463,
        "main_score": 0.722433,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.777356,
        "recall": 0.832335,
        "f1": 0.794535,
        "accuracy": 0.832335,
        "main_score": 0.794535,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.066319,
        "recall": 0.112442,
        "f1": 0.076188,
        "accuracy": 0.112442,
        "main_score": 0.076188,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.393949,
        "recall": 0.494345,
        "f1": 0.421009,
        "accuracy": 0.494345,
        "main_score": 0.421009,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.821241,
        "recall": 0.862275,
        "f1": 0.834061,
        "accuracy": 0.862275,
        "main_score": 0.834061,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.385332,
        "recall": 0.479042,
        "f1": 0.410621,
        "accuracy": 0.479042,
        "main_score": 0.410621,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.800948,
        "recall": 0.846307,
        "f1": 0.814707,
        "accuracy": 0.846307,
        "main_score": 0.814707,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.793174,
        "recall": 0.842981,
        "f1": 0.808649,
        "accuracy": 0.842981,
        "main_score": 0.808649,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.69296,
        "recall": 0.758483,
        "f1": 0.712391,
        "accuracy": 0.758483,
        "main_score": 0.712391,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.166744,
        "recall": 0.241517,
        "f1": 0.184158,
        "accuracy": 0.241517,
        "main_score": 0.184158,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.515046,
        "recall": 0.606121,
        "f1": 0.541591,
        "accuracy": 0.606121,
        "main_score": 0.541591,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.76981,
        "recall": 0.815037,
        "f1": 0.783616,
        "accuracy": 0.815037,
        "main_score": 0.783616,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.79138,
        "recall": 0.838989,
        "f1": 0.806074,
        "accuracy": 0.838989,
        "main_score": 0.806074,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000183,
        "recall": 0.004657,
        "f1": 0.000337,
        "accuracy": 0.004657,
        "main_score": 0.000337,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.786395,
        "recall": 0.830339,
        "f1": 0.800039,
        "accuracy": 0.830339,
        "main_score": 0.800039,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.767514,
        "recall": 0.819029,
        "f1": 0.783379,
        "accuracy": 0.819029,
        "main_score": 0.783379,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.75947,
        "recall": 0.81171,
        "f1": 0.775427,
        "accuracy": 0.81171,
        "main_score": 0.775427,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.38202,
        "recall": 0.47505,
        "f1": 0.406995,
        "accuracy": 0.47505,
        "main_score": 0.406995,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 9.9e-05,
        "recall": 0.002661,
        "f1": 0.000186,
        "accuracy": 0.002661,
        "main_score": 0.000186,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.288244,
        "recall": 0.383234,
        "f1": 0.312576,
        "accuracy": 0.383234,
        "main_score": 0.312576,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.795176,
        "recall": 0.842315,
        "f1": 0.810047,
        "accuracy": 0.842315,
        "main_score": 0.810047,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.796274,
        "recall": 0.840985,
        "f1": 0.809936,
        "accuracy": 0.840985,
        "main_score": 0.809936,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.796457,
        "recall": 0.844977,
        "f1": 0.811281,
        "accuracy": 0.844977,
        "main_score": 0.811281,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.873182,
        "recall": 0.902861,
        "f1": 0.882557,
        "accuracy": 0.902861,
        "main_score": 0.882557,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.068895,
        "recall": 0.11976,
        "f1": 0.079031,
        "accuracy": 0.11976,
        "main_score": 0.079031,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.482655,
        "recall": 0.580173,
        "f1": 0.50952,
        "accuracy": 0.580173,
        "main_score": 0.50952,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.912503,
        "recall": 0.932801,
        "f1": 0.918511,
        "accuracy": 0.932801,
        "main_score": 0.918511,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.456118,
        "recall": 0.546241,
        "f1": 0.480078,
        "accuracy": 0.546241,
        "main_score": 0.480078,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.876476,
        "recall": 0.905522,
        "f1": 0.885485,
        "accuracy": 0.905522,
        "main_score": 0.885485,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.871224,
        "recall": 0.902196,
        "f1": 0.880683,
        "accuracy": 0.902196,
        "main_score": 0.880683,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.751267,
        "recall": 0.807718,
        "f1": 0.768146,
        "accuracy": 0.807718,
        "main_score": 0.768146,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.196011,
        "recall": 0.285429,
        "f1": 0.216396,
        "accuracy": 0.285429,
        "main_score": 0.216396,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.617821,
        "recall": 0.689953,
        "f1": 0.638086,
        "accuracy": 0.689953,
        "main_score": 0.638086,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.823393,
        "recall": 0.860945,
        "f1": 0.835074,
        "accuracy": 0.860945,
        "main_score": 0.835074,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.87183,
        "recall": 0.90153,
        "f1": 0.881193,
        "accuracy": 0.90153,
        "main_score": 0.881193,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001289,
        "recall": 0.005988,
        "f1": 0.001691,
        "accuracy": 0.005988,
        "main_score": 0.001691,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.868347,
        "recall": 0.898869,
        "f1": 0.877513,
        "accuracy": 0.898869,
        "main_score": 0.877513,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.837564,
        "recall": 0.879574,
        "f1": 0.85027,
        "accuracy": 0.879574,
        "main_score": 0.85027,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.837847,
        "recall": 0.876248,
        "f1": 0.849612,
        "accuracy": 0.876248,
        "main_score": 0.849612,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.429308,
        "recall": 0.523619,
        "f1": 0.454977,
        "accuracy": 0.523619,
        "main_score": 0.454977,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000494,
        "recall": 0.005988,
        "f1": 0.000876,
        "accuracy": 0.005988,
        "main_score": 0.000876,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.356051,
        "recall": 0.452428,
        "f1": 0.38064,
        "accuracy": 0.452428,
        "main_score": 0.38064,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.796702,
        "recall": 0.843646,
        "f1": 0.811033,
        "accuracy": 0.843646,
        "main_score": 0.811033,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.881832,
        "recall": 0.909514,
        "f1": 0.890319,
        "accuracy": 0.909514,
        "main_score": 0.890319,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.838235,
        "recall": 0.878909,
        "f1": 0.850832,
        "accuracy": 0.878909,
        "main_score": 0.850832,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.903626,
        "recall": 0.928144,
        "f1": 0.9112,
        "accuracy": 0.928144,
        "main_score": 0.9112,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.069742,
        "recall": 0.119095,
        "f1": 0.079969,
        "accuracy": 0.119095,
        "main_score": 0.079969,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.523135,
        "recall": 0.622089,
        "f1": 0.550806,
        "accuracy": 0.622089,
        "main_score": 0.550806,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.956143,
        "recall": 0.966733,
        "f1": 0.959316,
        "accuracy": 0.966733,
        "main_score": 0.959316,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.490166,
        "recall": 0.580173,
        "f1": 0.514582,
        "accuracy": 0.580173,
        "main_score": 0.514582,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.91935,
        "recall": 0.938789,
        "f1": 0.925109,
        "accuracy": 0.938789,
        "main_score": 0.925109,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.927334,
        "recall": 0.946773,
        "f1": 0.933267,
        "accuracy": 0.946773,
        "main_score": 0.933267,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.749885,
        "recall": 0.805057,
        "f1": 0.766226,
        "accuracy": 0.805057,
        "main_score": 0.766226,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.233523,
        "recall": 0.329341,
        "f1": 0.255868,
        "accuracy": 0.329341,
        "main_score": 0.255868,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.66194,
        "recall": 0.731204,
        "f1": 0.681585,
        "accuracy": 0.731204,
        "main_score": 0.681585,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.836593,
        "recall": 0.876913,
        "f1": 0.849137,
        "accuracy": 0.876913,
        "main_score": 0.849137,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.92393,
        "recall": 0.942781,
        "f1": 0.929785,
        "accuracy": 0.942781,
        "main_score": 0.929785,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000676,
        "recall": 0.006653,
        "f1": 0.001058,
        "accuracy": 0.006653,
        "main_score": 0.001058,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.925283,
        "recall": 0.943446,
        "f1": 0.930761,
        "accuracy": 0.943446,
        "main_score": 0.930761,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.894167,
        "recall": 0.919494,
        "f1": 0.901841,
        "accuracy": 0.919494,
        "main_score": 0.901841,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.911422,
        "recall": 0.934132,
        "f1": 0.918363,
        "accuracy": 0.934132,
        "main_score": 0.918363,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.453082,
        "recall": 0.546906,
        "f1": 0.478814,
        "accuracy": 0.546906,
        "main_score": 0.478814,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001153,
        "recall": 0.007319,
        "f1": 0.001718,
        "accuracy": 0.007319,
        "main_score": 0.001718,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.359098,
        "recall": 0.460413,
        "f1": 0.384962,
        "accuracy": 0.460413,
        "main_score": 0.384962,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.803655,
        "recall": 0.846307,
        "f1": 0.816879,
        "accuracy": 0.846307,
        "main_score": 0.816879,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.875273,
        "recall": 0.904192,
        "f1": 0.883756,
        "accuracy": 0.904192,
        "main_score": 0.883756,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 85.64944386482239,
  "kg_co2_emissions": 0.0026540186823114137
}