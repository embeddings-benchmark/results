{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "task_name": "EmotionClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.43505,
        "f1": 0.38414,
        "f1_weighted": 0.454781,
        "scores_per_experiment": [
          {
            "accuracy": 0.4645,
            "f1": 0.398425,
            "f1_weighted": 0.481088
          },
          {
            "accuracy": 0.43,
            "f1": 0.381258,
            "f1_weighted": 0.446827
          },
          {
            "accuracy": 0.457,
            "f1": 0.397024,
            "f1_weighted": 0.478134
          },
          {
            "accuracy": 0.42,
            "f1": 0.37051,
            "f1_weighted": 0.441308
          },
          {
            "accuracy": 0.437,
            "f1": 0.400362,
            "f1_weighted": 0.459389
          },
          {
            "accuracy": 0.452,
            "f1": 0.39651,
            "f1_weighted": 0.470965
          },
          {
            "accuracy": 0.433,
            "f1": 0.370483,
            "f1_weighted": 0.455536
          },
          {
            "accuracy": 0.3735,
            "f1": 0.34564,
            "f1_weighted": 0.387803
          },
          {
            "accuracy": 0.458,
            "f1": 0.40891,
            "f1_weighted": 0.474885
          },
          {
            "accuracy": 0.4255,
            "f1": 0.372278,
            "f1_weighted": 0.451878
          }
        ],
        "main_score": 0.43505,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.4415,
        "f1": 0.381669,
        "f1_weighted": 0.463711,
        "scores_per_experiment": [
          {
            "accuracy": 0.475,
            "f1": 0.398869,
            "f1_weighted": 0.492277
          },
          {
            "accuracy": 0.424,
            "f1": 0.372366,
            "f1_weighted": 0.442785
          },
          {
            "accuracy": 0.4455,
            "f1": 0.371371,
            "f1_weighted": 0.469101
          },
          {
            "accuracy": 0.414,
            "f1": 0.355516,
            "f1_weighted": 0.440784
          },
          {
            "accuracy": 0.4395,
            "f1": 0.395804,
            "f1_weighted": 0.465768
          },
          {
            "accuracy": 0.4665,
            "f1": 0.398062,
            "f1_weighted": 0.486642
          },
          {
            "accuracy": 0.4535,
            "f1": 0.385322,
            "f1_weighted": 0.472951
          },
          {
            "accuracy": 0.3945,
            "f1": 0.356178,
            "f1_weighted": 0.415015
          },
          {
            "accuracy": 0.4665,
            "f1": 0.404276,
            "f1_weighted": 0.486787
          },
          {
            "accuracy": 0.436,
            "f1": 0.378929,
            "f1_weighted": 0.465
          }
        ],
        "main_score": 0.4415,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.094954490661621,
  "kg_co2_emissions": 0.00047904232648906576
}