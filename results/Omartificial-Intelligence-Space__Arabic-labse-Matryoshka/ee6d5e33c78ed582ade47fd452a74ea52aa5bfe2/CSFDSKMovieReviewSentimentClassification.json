{
  "dataset_revision": "23a20c659d868740ef9c54854de631fe19cd5c17",
  "task_name": "CSFDSKMovieReviewSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.299658,
        "f1": 0.291941,
        "f1_weighted": 0.293988,
        "scores_per_experiment": [
          {
            "accuracy": 0.303223,
            "f1": 0.298038,
            "f1_weighted": 0.299963
          },
          {
            "accuracy": 0.311035,
            "f1": 0.297565,
            "f1_weighted": 0.300619
          },
          {
            "accuracy": 0.321777,
            "f1": 0.304281,
            "f1_weighted": 0.306645
          },
          {
            "accuracy": 0.294434,
            "f1": 0.295696,
            "f1_weighted": 0.296851
          },
          {
            "accuracy": 0.299316,
            "f1": 0.290189,
            "f1_weighted": 0.291636
          },
          {
            "accuracy": 0.282715,
            "f1": 0.265418,
            "f1_weighted": 0.267716
          },
          {
            "accuracy": 0.290527,
            "f1": 0.284993,
            "f1_weighted": 0.287406
          },
          {
            "accuracy": 0.291504,
            "f1": 0.287663,
            "f1_weighted": 0.289953
          },
          {
            "accuracy": 0.299805,
            "f1": 0.297339,
            "f1_weighted": 0.2989
          },
          {
            "accuracy": 0.302246,
            "f1": 0.298223,
            "f1_weighted": 0.300191
          }
        ],
        "main_score": 0.299658,
        "hf_subset": "default",
        "languages": [
          "slk-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 9.605423927307129,
  "kg_co2_emissions": 0.0003907866875240212
}