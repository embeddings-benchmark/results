{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "2.3.11",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.592705,
            "f1": 0.504206,
            "f1_weighted": 0.661467,
            "precision": 0.557849,
            "precision_weighted": 0.835577,
            "recall": 0.631394,
            "recall_weighted": 0.592705,
            "ap": 0.167849,
            "ap_weighted": 0.167849
          },
          {
            "accuracy": 0.696049,
            "f1": 0.576118,
            "f1_weighted": 0.745391,
            "precision": 0.587062,
            "precision_weighted": 0.848419,
            "recall": 0.679963,
            "recall_weighted": 0.696049,
            "ap": 0.199903,
            "ap_weighted": 0.199903
          },
          {
            "accuracy": 0.726444,
            "f1": 0.57354,
            "f1_weighted": 0.765252,
            "precision": 0.573368,
            "precision_weighted": 0.830577,
            "recall": 0.63457,
            "recall_weighted": 0.726444,
            "ap": 0.178989,
            "ap_weighted": 0.178989
          },
          {
            "accuracy": 0.574468,
            "f1": 0.478723,
            "f1_weighted": 0.646446,
            "precision": 0.534929,
            "precision_weighted": 0.81396,
            "recall": 0.579141,
            "recall_weighted": 0.574468,
            "ap": 0.147242,
            "ap_weighted": 0.147242
          },
          {
            "accuracy": 0.632219,
            "f1": 0.538911,
            "f1_weighted": 0.694634,
            "precision": 0.578042,
            "precision_weighted": 0.851136,
            "recall": 0.674881,
            "recall_weighted": 0.632219,
            "ap": 0.190229,
            "ap_weighted": 0.190229
          },
          {
            "accuracy": 0.613982,
            "f1": 0.509226,
            "f1_weighted": 0.679454,
            "precision": 0.550461,
            "precision_weighted": 0.825718,
            "recall": 0.61217,
            "recall_weighted": 0.613982,
            "ap": 0.16072,
            "ap_weighted": 0.16072
          },
          {
            "accuracy": 0.56231,
            "f1": 0.467206,
            "f1_weighted": 0.636203,
            "precision": 0.527181,
            "precision_weighted": 0.807079,
            "recall": 0.561738,
            "recall_weighted": 0.56231,
            "ap": 0.141305,
            "ap_weighted": 0.141305
          },
          {
            "accuracy": 0.683891,
            "f1": 0.533028,
            "f1_weighted": 0.732296,
            "precision": 0.545814,
            "precision_weighted": 0.814357,
            "recall": 0.589346,
            "recall_weighted": 0.683891,
            "ap": 0.154046,
            "ap_weighted": 0.154046
          },
          {
            "accuracy": 0.772036,
            "f1": 0.610171,
            "f1_weighted": 0.79876,
            "precision": 0.598632,
            "precision_weighted": 0.840614,
            "recall": 0.660611,
            "recall_weighted": 0.772036,
            "ap": 0.202318,
            "ap_weighted": 0.202318
          },
          {
            "accuracy": 0.68997,
            "f1": 0.532358,
            "f1_weighted": 0.73618,
            "precision": 0.543215,
            "precision_weighted": 0.811722,
            "recall": 0.582359,
            "recall_weighted": 0.68997,
            "ap": 0.151377,
            "ap_weighted": 0.151377
          }
        ],
        "accuracy": 0.654407,
        "f1": 0.532349,
        "f1_weighted": 0.709608,
        "precision": 0.559655,
        "precision_weighted": 0.827916,
        "recall": 0.620617,
        "recall_weighted": 0.654407,
        "ap": 0.169398,
        "ap_weighted": 0.169398,
        "main_score": 0.654407,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 31.276676416397095,
  "kg_co2_emissions": null
}