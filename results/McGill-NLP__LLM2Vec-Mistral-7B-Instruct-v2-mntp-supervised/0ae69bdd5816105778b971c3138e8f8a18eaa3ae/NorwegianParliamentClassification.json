{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.567667,
        "f1": 0.563014,
        "f1_weighted": 0.563014,
        "ap": 0.54011,
        "ap_weighted": 0.54011,
        "scores_per_experiment": [
          {
            "accuracy": 0.564167,
            "f1": 0.562548,
            "f1_weighted": 0.562548,
            "ap": 0.535754,
            "ap_weighted": 0.535754
          },
          {
            "accuracy": 0.525,
            "f1": 0.509397,
            "f1_weighted": 0.509397,
            "ap": 0.512961,
            "ap_weighted": 0.512961
          },
          {
            "accuracy": 0.5925,
            "f1": 0.586795,
            "f1_weighted": 0.586795,
            "ap": 0.557435,
            "ap_weighted": 0.557435
          },
          {
            "accuracy": 0.5725,
            "f1": 0.569688,
            "f1_weighted": 0.569688,
            "ap": 0.54252,
            "ap_weighted": 0.54252
          },
          {
            "accuracy": 0.590833,
            "f1": 0.582554,
            "f1_weighted": 0.582554,
            "ap": 0.556903,
            "ap_weighted": 0.556903
          },
          {
            "accuracy": 0.544167,
            "f1": 0.541975,
            "f1_weighted": 0.541975,
            "ap": 0.524347,
            "ap_weighted": 0.524347
          },
          {
            "accuracy": 0.526667,
            "f1": 0.525558,
            "f1_weighted": 0.525558,
            "ap": 0.514121,
            "ap_weighted": 0.514121
          },
          {
            "accuracy": 0.571667,
            "f1": 0.569557,
            "f1_weighted": 0.569557,
            "ap": 0.541806,
            "ap_weighted": 0.541806
          },
          {
            "accuracy": 0.625,
            "f1": 0.624916,
            "f1_weighted": 0.624916,
            "ap": 0.57767,
            "ap_weighted": 0.57767
          },
          {
            "accuracy": 0.564167,
            "f1": 0.557155,
            "f1_weighted": 0.557155,
            "ap": 0.537585,
            "ap_weighted": 0.537585
          }
        ],
        "main_score": 0.567667,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.572333,
        "f1": 0.567621,
        "f1_weighted": 0.567621,
        "ap": 0.543937,
        "ap_weighted": 0.543937,
        "scores_per_experiment": [
          {
            "accuracy": 0.560833,
            "f1": 0.560459,
            "f1_weighted": 0.560459,
            "ap": 0.533913,
            "ap_weighted": 0.533913
          },
          {
            "accuracy": 0.4975,
            "f1": 0.48329,
            "f1_weighted": 0.48329,
            "ap": 0.498755,
            "ap_weighted": 0.498755
          },
          {
            "accuracy": 0.595,
            "f1": 0.587292,
            "f1_weighted": 0.587292,
            "ap": 0.55992,
            "ap_weighted": 0.55992
          },
          {
            "accuracy": 0.6025,
            "f1": 0.600681,
            "f1_weighted": 0.600681,
            "ap": 0.563396,
            "ap_weighted": 0.563396
          },
          {
            "accuracy": 0.601667,
            "f1": 0.590749,
            "f1_weighted": 0.590749,
            "ap": 0.566184,
            "ap_weighted": 0.566184
          },
          {
            "accuracy": 0.531667,
            "f1": 0.527094,
            "f1_weighted": 0.527094,
            "ap": 0.517082,
            "ap_weighted": 0.517082
          },
          {
            "accuracy": 0.56,
            "f1": 0.559107,
            "f1_weighted": 0.559107,
            "ap": 0.533956,
            "ap_weighted": 0.533956
          },
          {
            "accuracy": 0.568333,
            "f1": 0.567391,
            "f1_weighted": 0.567391,
            "ap": 0.539317,
            "ap_weighted": 0.539317
          },
          {
            "accuracy": 0.6275,
            "f1": 0.627469,
            "f1_weighted": 0.627469,
            "ap": 0.579714,
            "ap_weighted": 0.579714
          },
          {
            "accuracy": 0.578333,
            "f1": 0.572682,
            "f1_weighted": 0.572682,
            "ap": 0.547136,
            "ap_weighted": 0.547136
          }
        ],
        "main_score": 0.572333,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 70.31964707374573,
  "kg_co2_emissions": 0.004829617043167022
}