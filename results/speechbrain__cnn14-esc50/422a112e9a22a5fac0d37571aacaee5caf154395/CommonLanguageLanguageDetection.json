{
  "dataset_revision": "445bd662ffd3883ac662e2f1df18724c10688304",
  "task_name": "CommonLanguageLanguageDetection",
  "mteb_version": "2.4.2",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.049,
            "f1": 0.023059,
            "f1_weighted": 0.027637,
            "precision": 0.02077,
            "precision_weighted": 0.026104,
            "recall": 0.046114,
            "recall_weighted": 0.049,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.067,
            "f1": 0.038352,
            "f1_weighted": 0.050615,
            "precision": 0.047389,
            "precision_weighted": 0.076549,
            "recall": 0.056942,
            "recall_weighted": 0.067,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.054,
            "f1": 0.024968,
            "f1_weighted": 0.031716,
            "precision": 0.032211,
            "precision_weighted": 0.047869,
            "recall": 0.044551,
            "recall_weighted": 0.054,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.075,
            "f1": 0.026155,
            "f1_weighted": 0.042474,
            "precision": 0.025916,
            "precision_weighted": 0.038878,
            "recall": 0.042206,
            "recall_weighted": 0.075,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.061,
            "f1": 0.028471,
            "f1_weighted": 0.04381,
            "precision": 0.039186,
            "precision_weighted": 0.06587,
            "recall": 0.044847,
            "recall_weighted": 0.061,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.0475,
            "f1": 0.02214,
            "f1_weighted": 0.032486,
            "precision": 0.024913,
            "precision_weighted": 0.037745,
            "recall": 0.035492,
            "recall_weighted": 0.0475,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.062,
            "f1": 0.028026,
            "f1_weighted": 0.039817,
            "precision": 0.030328,
            "precision_weighted": 0.039013,
            "recall": 0.042066,
            "recall_weighted": 0.062,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.055,
            "f1": 0.023425,
            "f1_weighted": 0.02456,
            "precision": 0.024914,
            "precision_weighted": 0.033997,
            "recall": 0.056761,
            "recall_weighted": 0.055,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.051,
            "f1": 0.02276,
            "f1_weighted": 0.033796,
            "precision": 0.029357,
            "precision_weighted": 0.041448,
            "recall": 0.040397,
            "recall_weighted": 0.051,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.082,
            "f1": 0.038289,
            "f1_weighted": 0.055907,
            "precision": 0.056056,
            "precision_weighted": 0.083302,
            "recall": 0.058501,
            "recall_weighted": 0.082,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.06035,
        "f1": 0.027564,
        "f1_weighted": 0.038282,
        "precision": 0.033104,
        "precision_weighted": 0.049077,
        "recall": 0.046788,
        "recall_weighted": 0.06035,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.06035,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 517.3497319221497,
  "kg_co2_emissions": null
}