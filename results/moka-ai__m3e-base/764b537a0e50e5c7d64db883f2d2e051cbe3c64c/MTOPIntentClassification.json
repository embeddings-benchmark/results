{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "task_name": "MTOPIntentClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.500165,
        "f1": 0.320077,
        "f1_weighted": 0.549646,
        "scores_per_experiment": [
          {
            "accuracy": 0.510193,
            "f1": 0.319675,
            "f1_weighted": 0.557799
          },
          {
            "accuracy": 0.469972,
            "f1": 0.30614,
            "f1_weighted": 0.517507
          },
          {
            "accuracy": 0.509642,
            "f1": 0.312033,
            "f1_weighted": 0.55796
          },
          {
            "accuracy": 0.481543,
            "f1": 0.311298,
            "f1_weighted": 0.528408
          },
          {
            "accuracy": 0.498072,
            "f1": 0.33234,
            "f1_weighted": 0.550297
          },
          {
            "accuracy": 0.477686,
            "f1": 0.297838,
            "f1_weighted": 0.528794
          },
          {
            "accuracy": 0.511846,
            "f1": 0.326731,
            "f1_weighted": 0.557499
          },
          {
            "accuracy": 0.517355,
            "f1": 0.336506,
            "f1_weighted": 0.571906
          },
          {
            "accuracy": 0.503581,
            "f1": 0.329868,
            "f1_weighted": 0.553069
          },
          {
            "accuracy": 0.521763,
            "f1": 0.328335,
            "f1_weighted": 0.573225
          }
        ],
        "main_score": 0.500165,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.507326,
        "f1": 0.357049,
        "f1_weighted": 0.557,
        "scores_per_experiment": [
          {
            "accuracy": 0.509439,
            "f1": 0.347394,
            "f1_weighted": 0.563974
          },
          {
            "accuracy": 0.477881,
            "f1": 0.348089,
            "f1_weighted": 0.528902
          },
          {
            "accuracy": 0.524091,
            "f1": 0.360202,
            "f1_weighted": 0.571278
          },
          {
            "accuracy": 0.499296,
            "f1": 0.365925,
            "f1_weighted": 0.547086
          },
          {
            "accuracy": 0.523246,
            "f1": 0.380452,
            "f1_weighted": 0.572781
          },
          {
            "accuracy": 0.482108,
            "f1": 0.355355,
            "f1_weighted": 0.531282
          },
          {
            "accuracy": 0.516484,
            "f1": 0.353445,
            "f1_weighted": 0.564901
          },
          {
            "accuracy": 0.522401,
            "f1": 0.35293,
            "f1_weighted": 0.573656
          },
          {
            "accuracy": 0.514229,
            "f1": 0.353071,
            "f1_weighted": 0.567267
          },
          {
            "accuracy": 0.504086,
            "f1": 0.353629,
            "f1_weighted": 0.548869
          }
        ],
        "main_score": 0.507326,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 58.90718102455139,
  "kg_co2_emissions": null
}