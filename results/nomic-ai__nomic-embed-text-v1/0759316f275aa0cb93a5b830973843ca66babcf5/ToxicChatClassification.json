{
  "dataset_revision": "3e0319203c7162b9c9f8015b594441f979c199bc",
  "task_name": "ToxicChatClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.807818,
        "f1": 0.683599,
        "f1_weighted": 0.831279,
        "ap": 0.302038,
        "ap_weighted": 0.302038,
        "scores_per_experiment": [
          {
            "accuracy": 0.676117,
            "f1": 0.572529,
            "f1_weighted": 0.730171,
            "ap": 0.209725,
            "ap_weighted": 0.209725
          },
          {
            "accuracy": 0.850515,
            "f1": 0.712821,
            "f1_weighted": 0.861791,
            "ap": 0.319847,
            "ap_weighted": 0.319847
          },
          {
            "accuracy": 0.847938,
            "f1": 0.730166,
            "f1_weighted": 0.863713,
            "ap": 0.358601,
            "ap_weighted": 0.358601
          },
          {
            "accuracy": 0.825601,
            "f1": 0.710996,
            "f1_weighted": 0.847334,
            "ap": 0.33982,
            "ap_weighted": 0.33982
          },
          {
            "accuracy": 0.81701,
            "f1": 0.669938,
            "f1_weighted": 0.834992,
            "ap": 0.265801,
            "ap_weighted": 0.265801
          },
          {
            "accuracy": 0.847079,
            "f1": 0.717704,
            "f1_weighted": 0.86087,
            "ap": 0.332248,
            "ap_weighted": 0.332248
          },
          {
            "accuracy": 0.829897,
            "f1": 0.687326,
            "f1_weighted": 0.845496,
            "ap": 0.287246,
            "ap_weighted": 0.287246
          },
          {
            "accuracy": 0.755155,
            "f1": 0.653258,
            "f1_weighted": 0.794072,
            "ap": 0.291032,
            "ap_weighted": 0.291032
          },
          {
            "accuracy": 0.790378,
            "f1": 0.662785,
            "f1_weighted": 0.818178,
            "ap": 0.273762,
            "ap_weighted": 0.273762
          },
          {
            "accuracy": 0.838488,
            "f1": 0.71847,
            "f1_weighted": 0.856175,
            "ap": 0.342299,
            "ap_weighted": 0.342299
          }
        ],
        "main_score": 0.807818,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.956623554229736,
  "kg_co2_emissions": 0.00028397963934278684
}