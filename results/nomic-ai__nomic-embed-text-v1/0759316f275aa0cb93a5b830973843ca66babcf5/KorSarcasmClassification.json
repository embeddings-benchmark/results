{
  "dataset_revision": "3d96e36e10a88d5b7a3f617cf8362d997504494b",
  "task_name": "KorSarcasmClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.54834,
        "f1": 0.544577,
        "f1_weighted": 0.54457,
        "ap": 0.527342,
        "ap_weighted": 0.527342,
        "scores_per_experiment": [
          {
            "accuracy": 0.600098,
            "f1": 0.595034,
            "f1_weighted": 0.595123,
            "ap": 0.561807,
            "ap_weighted": 0.561807
          },
          {
            "accuracy": 0.537598,
            "f1": 0.537595,
            "f1_weighted": 0.537597,
            "ap": 0.519241,
            "ap_weighted": 0.519241
          },
          {
            "accuracy": 0.627441,
            "f1": 0.618058,
            "f1_weighted": 0.617941,
            "ap": 0.575329,
            "ap_weighted": 0.575329
          },
          {
            "accuracy": 0.533203,
            "f1": 0.533128,
            "f1_weighted": 0.533116,
            "ap": 0.516715,
            "ap_weighted": 0.516715
          },
          {
            "accuracy": 0.503418,
            "f1": 0.493042,
            "f1_weighted": 0.493183,
            "ap": 0.500607,
            "ap_weighted": 0.500607
          },
          {
            "accuracy": 0.56543,
            "f1": 0.565409,
            "f1_weighted": 0.565415,
            "ap": 0.536071,
            "ap_weighted": 0.536071
          },
          {
            "accuracy": 0.59082,
            "f1": 0.589636,
            "f1_weighted": 0.589593,
            "ap": 0.551954,
            "ap_weighted": 0.551954
          },
          {
            "accuracy": 0.543457,
            "f1": 0.538559,
            "f1_weighted": 0.538466,
            "ap": 0.522435,
            "ap_weighted": 0.522435
          },
          {
            "accuracy": 0.494141,
            "f1": 0.488868,
            "f1_weighted": 0.488767,
            "ap": 0.496221,
            "ap_weighted": 0.496221
          },
          {
            "accuracy": 0.487793,
            "f1": 0.486443,
            "f1_weighted": 0.486494,
            "ap": 0.493039,
            "ap_weighted": 0.493039
          }
        ],
        "main_score": 0.54834,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ]
      }
    ]
  },
  "evaluation_time": 9.008614778518677,
  "kg_co2_emissions": 0.0003276495904678162
}