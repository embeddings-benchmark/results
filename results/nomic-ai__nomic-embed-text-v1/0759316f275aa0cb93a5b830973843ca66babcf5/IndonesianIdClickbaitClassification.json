{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.57832,
        "f1": 0.571899,
        "f1_weighted": 0.577631,
        "ap": 0.466853,
        "ap_weighted": 0.466853,
        "scores_per_experiment": [
          {
            "accuracy": 0.627441,
            "f1": 0.6159,
            "f1_weighted": 0.626629,
            "ap": 0.494202,
            "ap_weighted": 0.494202
          },
          {
            "accuracy": 0.507812,
            "f1": 0.505435,
            "f1_weighted": 0.51096,
            "ap": 0.424353,
            "ap_weighted": 0.424353
          },
          {
            "accuracy": 0.583984,
            "f1": 0.575592,
            "f1_weighted": 0.585208,
            "ap": 0.464068,
            "ap_weighted": 0.464068
          },
          {
            "accuracy": 0.566406,
            "f1": 0.56248,
            "f1_weighted": 0.555802,
            "ap": 0.474667,
            "ap_weighted": 0.474667
          },
          {
            "accuracy": 0.601074,
            "f1": 0.600386,
            "f1_weighted": 0.603058,
            "ap": 0.485864,
            "ap_weighted": 0.485864
          },
          {
            "accuracy": 0.553711,
            "f1": 0.537449,
            "f1_weighted": 0.551424,
            "ap": 0.439692,
            "ap_weighted": 0.439692
          },
          {
            "accuracy": 0.59668,
            "f1": 0.593747,
            "f1_weighted": 0.599309,
            "ap": 0.478496,
            "ap_weighted": 0.478496
          },
          {
            "accuracy": 0.575195,
            "f1": 0.574726,
            "f1_weighted": 0.572451,
            "ap": 0.474692,
            "ap_weighted": 0.474692
          },
          {
            "accuracy": 0.606445,
            "f1": 0.591637,
            "f1_weighted": 0.604167,
            "ap": 0.475837,
            "ap_weighted": 0.475837
          },
          {
            "accuracy": 0.564453,
            "f1": 0.561642,
            "f1_weighted": 0.567298,
            "ap": 0.456659,
            "ap_weighted": 0.456659
          }
        ],
        "main_score": 0.571899,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.738237142562866,
  "kg_co2_emissions": 0.0002448283162678831
}