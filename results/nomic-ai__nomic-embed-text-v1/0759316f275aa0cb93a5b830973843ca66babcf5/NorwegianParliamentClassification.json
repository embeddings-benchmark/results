{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.557,
        "f1": 0.5556,
        "f1_weighted": 0.5556,
        "ap": 0.532259,
        "ap_weighted": 0.532259,
        "scores_per_experiment": [
          {
            "accuracy": 0.536667,
            "f1": 0.535261,
            "f1_weighted": 0.535261,
            "ap": 0.519844,
            "ap_weighted": 0.519844
          },
          {
            "accuracy": 0.5675,
            "f1": 0.566891,
            "f1_weighted": 0.566891,
            "ap": 0.538676,
            "ap_weighted": 0.538676
          },
          {
            "accuracy": 0.581667,
            "f1": 0.578972,
            "f1_weighted": 0.578972,
            "ap": 0.546583,
            "ap_weighted": 0.546583
          },
          {
            "accuracy": 0.580833,
            "f1": 0.578409,
            "f1_weighted": 0.578409,
            "ap": 0.54609,
            "ap_weighted": 0.54609
          },
          {
            "accuracy": 0.581667,
            "f1": 0.581662,
            "f1_weighted": 0.581662,
            "ap": 0.547459,
            "ap_weighted": 0.547459
          },
          {
            "accuracy": 0.5625,
            "f1": 0.562449,
            "f1_weighted": 0.562449,
            "ap": 0.535073,
            "ap_weighted": 0.535073
          },
          {
            "accuracy": 0.536667,
            "f1": 0.533023,
            "f1_weighted": 0.533023,
            "ap": 0.519966,
            "ap_weighted": 0.519966
          },
          {
            "accuracy": 0.510833,
            "f1": 0.510144,
            "f1_weighted": 0.510144,
            "ap": 0.505544,
            "ap_weighted": 0.505544
          },
          {
            "accuracy": 0.585833,
            "f1": 0.585024,
            "f1_weighted": 0.585024,
            "ap": 0.549686,
            "ap_weighted": 0.549686
          },
          {
            "accuracy": 0.525833,
            "f1": 0.524168,
            "f1_weighted": 0.524168,
            "ap": 0.513674,
            "ap_weighted": 0.513674
          }
        ],
        "main_score": 0.557,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.54425,
        "f1": 0.543304,
        "f1_weighted": 0.543304,
        "ap": 0.525744,
        "ap_weighted": 0.525744,
        "scores_per_experiment": [
          {
            "accuracy": 0.4925,
            "f1": 0.491432,
            "f1_weighted": 0.491432,
            "ap": 0.496312,
            "ap_weighted": 0.496312
          },
          {
            "accuracy": 0.551667,
            "f1": 0.551063,
            "f1_weighted": 0.551063,
            "ap": 0.528714,
            "ap_weighted": 0.528714
          },
          {
            "accuracy": 0.575833,
            "f1": 0.574258,
            "f1_weighted": 0.574258,
            "ap": 0.543044,
            "ap_weighted": 0.543044
          },
          {
            "accuracy": 0.604167,
            "f1": 0.60253,
            "f1_weighted": 0.60253,
            "ap": 0.5617,
            "ap_weighted": 0.5617
          },
          {
            "accuracy": 0.5975,
            "f1": 0.597453,
            "f1_weighted": 0.597453,
            "ap": 0.558467,
            "ap_weighted": 0.558467
          },
          {
            "accuracy": 0.531667,
            "f1": 0.531603,
            "f1_weighted": 0.531603,
            "ap": 0.51686,
            "ap_weighted": 0.51686
          },
          {
            "accuracy": 0.521667,
            "f1": 0.51908,
            "f1_weighted": 0.51908,
            "ap": 0.511383,
            "ap_weighted": 0.511383
          },
          {
            "accuracy": 0.479167,
            "f1": 0.479166,
            "f1_weighted": 0.479166,
            "ap": 0.490018,
            "ap_weighted": 0.490018
          },
          {
            "accuracy": 0.583333,
            "f1": 0.58324,
            "f1_weighted": 0.58324,
            "ap": 0.548409,
            "ap_weighted": 0.548409
          },
          {
            "accuracy": 0.505,
            "f1": 0.503212,
            "f1_weighted": 0.503212,
            "ap": 0.502528,
            "ap_weighted": 0.502528
          }
        ],
        "main_score": 0.54425,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 49.15342926979065,
  "kg_co2_emissions": 0.0035772515189013846
}