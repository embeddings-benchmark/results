{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.704834,
        "f1": 0.702178,
        "f1_weighted": 0.702246,
        "ap": 0.640826,
        "ap_weighted": 0.640826,
        "scores_per_experiment": [
          {
            "accuracy": 0.694824,
            "f1": 0.684237,
            "f1_weighted": 0.684407,
            "ap": 0.62622,
            "ap_weighted": 0.62622
          },
          {
            "accuracy": 0.714844,
            "f1": 0.711986,
            "f1_weighted": 0.71207,
            "ap": 0.647112,
            "ap_weighted": 0.647112
          },
          {
            "accuracy": 0.66748,
            "f1": 0.666637,
            "f1_weighted": 0.666686,
            "ap": 0.61057,
            "ap_weighted": 0.61057
          },
          {
            "accuracy": 0.700195,
            "f1": 0.698578,
            "f1_weighted": 0.698643,
            "ap": 0.636329,
            "ap_weighted": 0.636329
          },
          {
            "accuracy": 0.747559,
            "f1": 0.747376,
            "f1_weighted": 0.747396,
            "ap": 0.683325,
            "ap_weighted": 0.683325
          },
          {
            "accuracy": 0.686035,
            "f1": 0.685756,
            "f1_weighted": 0.685784,
            "ap": 0.62707,
            "ap_weighted": 0.62707
          },
          {
            "accuracy": 0.73291,
            "f1": 0.730207,
            "f1_weighted": 0.730286,
            "ap": 0.66284,
            "ap_weighted": 0.66284
          },
          {
            "accuracy": 0.711914,
            "f1": 0.705248,
            "f1_weighted": 0.705377,
            "ap": 0.641562,
            "ap_weighted": 0.641562
          },
          {
            "accuracy": 0.659668,
            "f1": 0.659664,
            "f1_weighted": 0.659667,
            "ap": 0.606615,
            "ap_weighted": 0.606615
          },
          {
            "accuracy": 0.73291,
            "f1": 0.732095,
            "f1_weighted": 0.732138,
            "ap": 0.666617,
            "ap_weighted": 0.666617
          }
        ],
        "main_score": 0.704834,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.699951,
        "f1": 0.697471,
        "f1_weighted": 0.697515,
        "ap": 0.636109,
        "ap_weighted": 0.636109,
        "scores_per_experiment": [
          {
            "accuracy": 0.696289,
            "f1": 0.687366,
            "f1_weighted": 0.687469,
            "ap": 0.627645,
            "ap_weighted": 0.627645
          },
          {
            "accuracy": 0.719727,
            "f1": 0.716691,
            "f1_weighted": 0.716748,
            "ap": 0.650652,
            "ap_weighted": 0.650652
          },
          {
            "accuracy": 0.665039,
            "f1": 0.664475,
            "f1_weighted": 0.664501,
            "ap": 0.608602,
            "ap_weighted": 0.608602
          },
          {
            "accuracy": 0.696777,
            "f1": 0.69525,
            "f1_weighted": 0.695292,
            "ap": 0.63316,
            "ap_weighted": 0.63316
          },
          {
            "accuracy": 0.731934,
            "f1": 0.731826,
            "f1_weighted": 0.731837,
            "ap": 0.668627,
            "ap_weighted": 0.668627
          },
          {
            "accuracy": 0.681641,
            "f1": 0.681224,
            "f1_weighted": 0.681247,
            "ap": 0.622505,
            "ap_weighted": 0.622505
          },
          {
            "accuracy": 0.724609,
            "f1": 0.721512,
            "f1_weighted": 0.721569,
            "ap": 0.654751,
            "ap_weighted": 0.654751
          },
          {
            "accuracy": 0.716797,
            "f1": 0.710156,
            "f1_weighted": 0.710242,
            "ap": 0.645193,
            "ap_weighted": 0.645193
          },
          {
            "accuracy": 0.659668,
            "f1": 0.659632,
            "f1_weighted": 0.659639,
            "ap": 0.605776,
            "ap_weighted": 0.605776
          },
          {
            "accuracy": 0.707031,
            "f1": 0.706584,
            "f1_weighted": 0.706606,
            "ap": 0.644177,
            "ap_weighted": 0.644177
          }
        ],
        "main_score": 0.699951,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 19.697643995285034,
  "kg_co2_emissions": 0.0009068392028633923
}