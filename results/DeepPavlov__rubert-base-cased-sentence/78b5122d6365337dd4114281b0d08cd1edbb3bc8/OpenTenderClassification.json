{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.143813,
            "f1": 0.144346,
            "f1_weighted": 0.144307,
            "precision": 0.150118,
            "precision_weighted": 0.150078,
            "recall": 0.14385,
            "recall_weighted": 0.143813,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.146265,
            "f1": 0.148689,
            "f1_weighted": 0.148649,
            "precision": 0.156718,
            "precision_weighted": 0.156688,
            "recall": 0.146321,
            "recall_weighted": 0.146265,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.156522,
            "f1": 0.158342,
            "f1_weighted": 0.158342,
            "precision": 0.164411,
            "precision_weighted": 0.164413,
            "recall": 0.156522,
            "recall_weighted": 0.156522,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.123077,
            "f1": 0.12443,
            "f1_weighted": 0.124464,
            "precision": 0.131179,
            "precision_weighted": 0.131216,
            "recall": 0.123049,
            "recall_weighted": 0.123077,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.146265,
            "f1": 0.147384,
            "f1_weighted": 0.147415,
            "precision": 0.153411,
            "precision_weighted": 0.153429,
            "recall": 0.146217,
            "recall_weighted": 0.146265,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.132887,
            "f1": 0.131696,
            "f1_weighted": 0.131652,
            "precision": 0.132938,
            "precision_weighted": 0.132901,
            "recall": 0.132935,
            "recall_weighted": 0.132887,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.13913,
            "f1": 0.140715,
            "f1_weighted": 0.140727,
            "precision": 0.146125,
            "precision_weighted": 0.146123,
            "recall": 0.139105,
            "recall_weighted": 0.13913,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.13757,
            "f1": 0.138799,
            "f1_weighted": 0.138748,
            "precision": 0.146373,
            "precision_weighted": 0.146327,
            "recall": 0.13763,
            "recall_weighted": 0.13757,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.140691,
            "f1": 0.141283,
            "f1_weighted": 0.141251,
            "precision": 0.14516,
            "precision_weighted": 0.145136,
            "recall": 0.140731,
            "recall_weighted": 0.140691,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.13757,
            "f1": 0.136192,
            "f1_weighted": 0.136164,
            "precision": 0.139071,
            "precision_weighted": 0.139048,
            "recall": 0.137596,
            "recall_weighted": 0.13757,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.140379,
        "f1": 0.141188,
        "f1_weighted": 0.141172,
        "precision": 0.14655,
        "precision_weighted": 0.146536,
        "recall": 0.140395,
        "recall_weighted": 0.140379,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.141188,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 69.94335603713989,
  "kg_co2_emissions": null
}