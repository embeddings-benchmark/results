{
  "dataset_revision": "e6b647fcb6299a2f686f742f4d4c023e553ea67e",
  "evaluation_time": 416.5899872779846,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.89",
  "scores": {
    "devtest": [
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001133707001819716,
        "hf_subset": "ace_Arab-rus_Cyrl",
        "languages": [
          "ace-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.001133707001819716,
        "precision": 0.001066358912826304,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.012471144685373301,
        "hf_subset": "bam_Latn-rus_Cyrl",
        "languages": [
          "bam-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.012471144685373301,
        "precision": 0.01054506854909874,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 3.2774205389390333e-06,
        "hf_subset": "dzo_Tibt-rus_Cyrl",
        "languages": [
          "dzo-Tibt",
          "rus-Cyrl"
        ],
        "main_score": 3.2774205389390333e-06,
        "precision": 1.641432379551692e-06,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.005145363982793094,
        "hf_subset": "hin_Deva-rus_Cyrl",
        "languages": [
          "hin-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.005145363982793094,
        "precision": 0.004796273891124973,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.02035927174088601,
        "hf_subset": "khm_Khmr-rus_Cyrl",
        "languages": [
          "khm-Khmr",
          "rus-Cyrl"
        ],
        "main_score": 0.02035927174088601,
        "precision": 0.018768145136732448,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009945797015617154,
        "hf_subset": "mag_Deva-rus_Cyrl",
        "languages": [
          "mag-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0009945797015617154,
        "precision": 0.0009913715156681909,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.06818181818181818,
        "f1": 0.048898292638411216,
        "hf_subset": "pap_Latn-rus_Cyrl",
        "languages": [
          "pap-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.048898292638411216,
        "precision": 0.0439191835380225,
        "recall": 0.06818181818181818
      },
      {
        "accuracy": 0.03557312252964427,
        "f1": 0.02486572533404171,
        "hf_subset": "sot_Latn-rus_Cyrl",
        "languages": [
          "sot-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.02486572533404171,
        "precision": 0.02208805922837328,
        "recall": 0.03557312252964427
      },
      {
        "accuracy": 0.025691699604743084,
        "f1": 0.015484448648442199,
        "hf_subset": "tur_Latn-rus_Cyrl",
        "languages": [
          "tur-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.015484448648442199,
        "precision": 0.013905319359201865,
        "recall": 0.025691699604743084
      },
      {
        "accuracy": 0.044466403162055336,
        "f1": 0.03182475978128152,
        "hf_subset": "ace_Latn-rus_Cyrl",
        "languages": [
          "ace-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.03182475978128152,
        "precision": 0.02883501930008891,
        "recall": 0.044466403162055336
      },
      {
        "accuracy": 0.03557312252964427,
        "f1": 0.024075308867514893,
        "hf_subset": "ban_Latn-rus_Cyrl",
        "languages": [
          "ban-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.024075308867514893,
        "precision": 0.021854480350308427,
        "recall": 0.03557312252964427
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.004185612379565107,
        "hf_subset": "ell_Grek-rus_Cyrl",
        "languages": [
          "ell-Grek",
          "rus-Cyrl"
        ],
        "main_score": 0.004185612379565107,
        "precision": 0.0040828448546512885,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0015020005237641409,
        "hf_subset": "hne_Deva-rus_Cyrl",
        "languages": [
          "hne-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0015020005237641409,
        "precision": 0.0013274664383386417,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.04940711462450593,
        "f1": 0.03383353441886526,
        "hf_subset": "kik_Latn-rus_Cyrl",
        "languages": [
          "kik-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.03383353441886526,
        "precision": 0.030153236240570435,
        "recall": 0.04940711462450593
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.002541631568716387,
        "hf_subset": "mai_Deva-rus_Cyrl",
        "languages": [
          "mai-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.002541631568716387,
        "precision": 0.0020613370151785874,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0046533278451198,
        "hf_subset": "pbt_Arab-rus_Cyrl",
        "languages": [
          "pbt-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0046533278451198,
        "precision": 0.004467867742129679,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.06620553359683795,
        "f1": 0.04814326281050395,
        "hf_subset": "spa_Latn-rus_Cyrl",
        "languages": [
          "spa-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.04814326281050395,
        "precision": 0.043788175154412134,
        "recall": 0.06620553359683795
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.02017806755174659,
        "hf_subset": "twi_Latn-rus_Cyrl",
        "languages": [
          "twi-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.02017806755174659,
        "precision": 0.019024317309419423,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010145597329651833,
        "hf_subset": "acm_Arab-rus_Cyrl",
        "languages": [
          "acm-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0010145597329651833,
        "precision": 0.0010014696647444104,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.14525691699604742,
        "f1": 0.11086073560428818,
        "hf_subset": "bel_Cyrl-rus_Cyrl",
        "languages": [
          "bel-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.11086073560428818,
        "precision": 0.10334773700284562,
        "recall": 0.14525691699604742
      },
      {
        "accuracy": 0.43280632411067194,
        "f1": 0.37577818870801527,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.37577818870801527,
        "precision": 0.3558500376435159,
        "recall": 0.43280632411067194
      },
      {
        "accuracy": 0.041501976284584984,
        "f1": 0.026878149442163875,
        "hf_subset": "hrv_Latn-rus_Cyrl",
        "languages": [
          "hrv-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.026878149442163875,
        "precision": 0.024278713816826687,
        "recall": 0.041501976284584984
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.01012392391750676,
        "hf_subset": "kin_Latn-rus_Cyrl",
        "languages": [
          "kin-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01012392391750676,
        "precision": 0.009154035757622787,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.003300121649892451,
        "hf_subset": "mal_Mlym-rus_Cyrl",
        "languages": [
          "mal-Mlym",
          "rus-Cyrl"
        ],
        "main_score": 0.003300121649892451,
        "precision": 0.002638213236039323,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0029729822219940797,
        "hf_subset": "pes_Arab-rus_Cyrl",
        "languages": [
          "pes-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0029729822219940797,
        "precision": 0.002968723148307269,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.05237154150197629,
        "f1": 0.037355077953339325,
        "hf_subset": "srd_Latn-rus_Cyrl",
        "languages": [
          "srd-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.037355077953339325,
        "precision": 0.03373208450940497,
        "recall": 0.05237154150197629
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.002176087751640139,
        "hf_subset": "tzm_Tfng-rus_Cyrl",
        "languages": [
          "tzm-Tfng",
          "rus-Cyrl"
        ],
        "main_score": 0.002176087751640139,
        "precision": 0.001829422446460901,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0019998547509032676,
        "hf_subset": "acq_Arab-rus_Cyrl",
        "languages": [
          "acq-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0019998547509032676,
        "precision": 0.001988156239608843,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.036561264822134384,
        "f1": 0.025143724843947945,
        "hf_subset": "bem_Latn-rus_Cyrl",
        "languages": [
          "bem-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.025143724843947945,
        "precision": 0.02301113773510799,
        "recall": 0.036561264822134384
      },
      {
        "accuracy": 0.0691699604743083,
        "f1": 0.04858706820073861,
        "hf_subset": "epo_Latn-rus_Cyrl",
        "languages": [
          "epo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.04858706820073861,
        "precision": 0.04463237150516357,
        "recall": 0.0691699604743083
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.0076997439934873655,
        "hf_subset": "hun_Latn-rus_Cyrl",
        "languages": [
          "hun-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0076997439934873655,
        "precision": 0.006828025689553802,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.07312252964426877,
        "f1": 0.05160251985245124,
        "hf_subset": "kir_Cyrl-rus_Cyrl",
        "languages": [
          "kir-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.05160251985245124,
        "precision": 0.04744010102369672,
        "recall": 0.07312252964426877
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.004677206851119895,
        "hf_subset": "mar_Deva-rus_Cyrl",
        "languages": [
          "mar-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.004677206851119895,
        "precision": 0.004199604743083004,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.015789660474627314,
        "hf_subset": "plt_Latn-rus_Cyrl",
        "languages": [
          "plt-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.015789660474627314,
        "precision": 0.01410636832080522,
        "recall": 0.022727272727272728
      },
      {
        "accuracy": 0.2381422924901186,
        "f1": 0.19570953533156327,
        "hf_subset": "srp_Cyrl-rus_Cyrl",
        "languages": [
          "srp-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.19570953533156327,
        "precision": 0.18437297696853402,
        "recall": 0.2381422924901186
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.007579536322573981,
        "hf_subset": "uig_Arab-rus_Cyrl",
        "languages": [
          "uig-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.007579536322573981,
        "precision": 0.007083579422410006,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001982721994051834,
        "hf_subset": "aeb_Arab-rus_Cyrl",
        "languages": [
          "aeb-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.001982721994051834,
        "precision": 0.0019795138081583094,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.003955420951468382,
        "hf_subset": "ben_Beng-rus_Cyrl",
        "languages": [
          "ben-Beng",
          "rus-Cyrl"
        ],
        "main_score": 0.003955420951468382,
        "precision": 0.0039539971212502,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.029644268774703556,
        "f1": 0.019275931071407303,
        "hf_subset": "est_Latn-rus_Cyrl",
        "languages": [
          "est-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.019275931071407303,
        "precision": 0.017301780654020268,
        "recall": 0.029644268774703556
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.004620522719612709,
        "hf_subset": "hye_Armn-rus_Cyrl",
        "languages": [
          "hye-Armn",
          "rus-Cyrl"
        ],
        "main_score": 0.004620522719612709,
        "precision": 0.004451257803553618,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.01564216498047609,
        "hf_subset": "kmb_Latn-rus_Cyrl",
        "languages": [
          "kmb-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01564216498047609,
        "precision": 0.014534338251446711,
        "recall": 0.022727272727272728
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 2.7144060731789104e-05,
        "hf_subset": "min_Arab-rus_Cyrl",
        "languages": [
          "min-Arab",
          "rus-Cyrl"
        ],
        "main_score": 2.7144060731789104e-05,
        "precision": 1.3698195857116397e-05,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.04940711462450593,
        "f1": 0.03134431152555851,
        "hf_subset": "pol_Latn-rus_Cyrl",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.03134431152555851,
        "precision": 0.028048254294817932,
        "recall": 0.04940711462450593
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.009340212472965218,
        "hf_subset": "ssw_Latn-rus_Cyrl",
        "languages": [
          "ssw-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.009340212472965218,
        "precision": 0.007931039435433515,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.7865612648221344,
        "f1": 0.7394009975531715,
        "hf_subset": "ukr_Cyrl-rus_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.7394009975531715,
        "precision": 0.7202608381956208,
        "recall": 0.7865612648221344
      },
      {
        "accuracy": 0.06719367588932806,
        "f1": 0.047063952804441936,
        "hf_subset": "afr_Latn-rus_Cyrl",
        "languages": [
          "afr-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.047063952804441936,
        "precision": 0.04199791504669595,
        "recall": 0.06719367588932806
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.007699386230997108,
        "hf_subset": "bho_Deva-rus_Cyrl",
        "languages": [
          "bho-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.007699386230997108,
        "precision": 0.007193619050318252,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.025691699604743084,
        "f1": 0.016929942364724972,
        "hf_subset": "eus_Latn-rus_Cyrl",
        "languages": [
          "eus-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.016929942364724972,
        "precision": 0.015352159917377308,
        "recall": 0.025691699604743084
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.015580241259847557,
        "hf_subset": "ibo_Latn-rus_Cyrl",
        "languages": [
          "ibo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.015580241259847557,
        "precision": 0.013872749159069414,
        "recall": 0.022727272727272728
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.004602313535822326,
        "hf_subset": "kmr_Latn-rus_Cyrl",
        "languages": [
          "kmr-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.004602313535822326,
        "precision": 0.00399010706432753,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.041501976284584984,
        "f1": 0.027077545606964636,
        "hf_subset": "min_Latn-rus_Cyrl",
        "languages": [
          "min-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.027077545606964636,
        "precision": 0.024291186330879833,
        "recall": 0.041501976284584984
      },
      {
        "accuracy": 0.06620553359683795,
        "f1": 0.04737245710396731,
        "hf_subset": "por_Latn-rus_Cyrl",
        "languages": [
          "por-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.04737245710396731,
        "precision": 0.042753959637221735,
        "recall": 0.06620553359683795
      },
      {
        "accuracy": 0.042490118577075096,
        "f1": 0.025082836559871858,
        "hf_subset": "sun_Latn-rus_Cyrl",
        "languages": [
          "sun-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.025082836559871858,
        "precision": 0.02178148226852239,
        "recall": 0.042490118577075096
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.007498389291867553,
        "hf_subset": "umb_Latn-rus_Cyrl",
        "languages": [
          "umb-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.007498389291867553,
        "precision": 0.006976537954798825,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0023216710640262287,
        "hf_subset": "ajp_Arab-rus_Cyrl",
        "languages": [
          "ajp-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0023216710640262287,
        "precision": 0.001984321203020384,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 4.553651117465984e-06,
        "hf_subset": "bjn_Arab-rus_Cyrl",
        "languages": [
          "bjn-Arab",
          "rus-Cyrl"
        ],
        "main_score": 4.553651117465984e-06,
        "precision": 2.282083816374408e-06,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.03359683794466403,
        "f1": 0.02324270240073072,
        "hf_subset": "ewe_Latn-rus_Cyrl",
        "languages": [
          "ewe-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.02324270240073072,
        "precision": 0.02131742321972275,
        "recall": 0.03359683794466403
      },
      {
        "accuracy": 0.06521739130434782,
        "f1": 0.048809317102144374,
        "hf_subset": "ilo_Latn-rus_Cyrl",
        "languages": [
          "ilo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.048809317102144374,
        "precision": 0.04523832527297249,
        "recall": 0.06521739130434782
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0016469038208168643,
        "hf_subset": "knc_Arab-rus_Cyrl",
        "languages": [
          "knc-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0016469038208168643,
        "precision": 0.0014822134387351778,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.24604743083003952,
        "f1": 0.19735092428579482,
        "hf_subset": "mkd_Cyrl-rus_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.19735092428579482,
        "precision": 0.18305944849029995,
        "recall": 0.24604743083003952
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.001976284584980237,
        "hf_subset": "prs_Arab-rus_Cyrl",
        "languages": [
          "prs-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.001976284584980237,
        "precision": 0.001976284584980237,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.07608695652173914,
        "f1": 0.05399302789051105,
        "hf_subset": "swe_Latn-rus_Cyrl",
        "languages": [
          "swe-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.05399302789051105,
        "precision": 0.04935557577377412,
        "recall": 0.07608695652173914
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.000996446009233733,
        "hf_subset": "urd_Arab-rus_Cyrl",
        "languages": [
          "urd-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.000996446009233733,
        "precision": 0.0009923116692516802,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.028835241342959155,
        "hf_subset": "aka_Latn-rus_Cyrl",
        "languages": [
          "aka-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.028835241342959155,
        "precision": 0.027051404813608695,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.040513833992094864,
        "f1": 0.02743926376914275,
        "hf_subset": "bjn_Latn-rus_Cyrl",
        "languages": [
          "bjn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.02743926376914275,
        "precision": 0.024746261201509998,
        "recall": 0.040513833992094864
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.023683067381840707,
        "hf_subset": "fao_Latn-rus_Cyrl",
        "languages": [
          "fao-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.023683067381840707,
        "precision": 0.021107403917670086,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.04743083003952569,
        "f1": 0.03313420876887995,
        "hf_subset": "ind_Latn-rus_Cyrl",
        "languages": [
          "ind-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.03313420876887995,
        "precision": 0.029704614065242264,
        "recall": 0.04743083003952569
      },
      {
        "accuracy": 0.043478260869565216,
        "f1": 0.0278773543101209,
        "hf_subset": "knc_Latn-rus_Cyrl",
        "languages": [
          "knc-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0278773543101209,
        "precision": 0.02459731617682099,
        "recall": 0.043478260869565216
      },
      {
        "accuracy": 0.03162055335968379,
        "f1": 0.018669982890149713,
        "hf_subset": "mlt_Latn-rus_Cyrl",
        "languages": [
          "mlt-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.018669982890149713,
        "precision": 0.016418877921595312,
        "recall": 0.03162055335968379
      },
      {
        "accuracy": 0.024703557312252964,
        "f1": 0.015670895211727504,
        "hf_subset": "quy_Latn-rus_Cyrl",
        "languages": [
          "quy-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.015670895211727504,
        "precision": 0.01412159766457529,
        "recall": 0.024703557312252964
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.014710457805781944,
        "hf_subset": "swh_Latn-rus_Cyrl",
        "languages": [
          "swh-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.014710457805781944,
        "precision": 0.014071519210970286,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.009258255643169852,
        "hf_subset": "uzn_Latn-rus_Cyrl",
        "languages": [
          "uzn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.009258255643169852,
        "precision": 0.008151589488971808,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.014068440246262219,
        "hf_subset": "als_Latn-rus_Cyrl",
        "languages": [
          "als-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.014068440246262219,
        "precision": 0.012200718509533094,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 0.0009881422924901185,
        "hf_subset": "bod_Tibt-rus_Cyrl",
        "languages": [
          "bod-Tibt",
          "rus-Cyrl"
        ],
        "main_score": 0.0009881422924901185,
        "precision": 0.0009881422924901185,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.016762920548800665,
        "hf_subset": "fij_Latn-rus_Cyrl",
        "languages": [
          "fij-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.016762920548800665,
        "precision": 0.0149146184476565,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.020843786360340007,
        "hf_subset": "isl_Latn-rus_Cyrl",
        "languages": [
          "isl-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.020843786360340007,
        "precision": 0.01829836761626671,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.041501976284584984,
        "f1": 0.027652682182070128,
        "hf_subset": "kon_Latn-rus_Cyrl",
        "languages": [
          "kon-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.027652682182070128,
        "precision": 0.025332784475650426,
        "recall": 0.041501976284584984
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.004284694773825208,
        "hf_subset": "mni_Beng-rus_Cyrl",
        "languages": [
          "mni-Beng",
          "rus-Cyrl"
        ],
        "main_score": 0.004284694773825208,
        "precision": 0.003953943498600933,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.058300395256917,
        "f1": 0.04074169921689447,
        "hf_subset": "ron_Latn-rus_Cyrl",
        "languages": [
          "ron-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.04074169921689447,
        "precision": 0.03626879392300966,
        "recall": 0.058300395256917
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.02566895562303511,
        "hf_subset": "szl_Latn-rus_Cyrl",
        "languages": [
          "szl-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.02566895562303511,
        "precision": 0.024192845530894697,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.06818181818181818,
        "f1": 0.050321435660771074,
        "hf_subset": "vec_Latn-rus_Cyrl",
        "languages": [
          "vec-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.050321435660771074,
        "precision": 0.04578687743733511,
        "recall": 0.06818181818181818
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0014852869761923788,
        "hf_subset": "amh_Ethi-rus_Cyrl",
        "languages": [
          "amh-Ethi",
          "rus-Cyrl"
        ],
        "main_score": 0.0014852869761923788,
        "precision": 0.001319062219102853,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.044466403162055336,
        "f1": 0.026621931946751155,
        "hf_subset": "bos_Latn-rus_Cyrl",
        "languages": [
          "bos-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.026621931946751155,
        "precision": 0.02339057150369077,
        "recall": 0.044466403162055336
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.015562711437599774,
        "hf_subset": "fin_Latn-rus_Cyrl",
        "languages": [
          "fin-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.015562711437599774,
        "precision": 0.014185045027436331,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.08695652173913043,
        "f1": 0.06350159710354612,
        "hf_subset": "ita_Latn-rus_Cyrl",
        "languages": [
          "ita-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.06350159710354612,
        "precision": 0.05889065362963273,
        "recall": 0.08695652173913043
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.007541395781451285,
        "hf_subset": "kor_Hang-rus_Cyrl",
        "languages": [
          "kor-Hang",
          "rus-Cyrl"
        ],
        "main_score": 0.007541395781451285,
        "precision": 0.006753236154299766,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.018283749450494838,
        "hf_subset": "mos_Latn-rus_Cyrl",
        "languages": [
          "mos-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.018283749450494838,
        "precision": 0.016437240742796295,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.009565375675518904,
        "hf_subset": "run_Latn-rus_Cyrl",
        "languages": [
          "run-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.009565375675518904,
        "precision": 0.008194452974271061,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.004338871438805312,
        "hf_subset": "tam_Taml-rus_Cyrl",
        "languages": [
          "tam-Taml",
          "rus-Cyrl"
        ],
        "main_score": 0.004338871438805312,
        "precision": 0.0036034327438243803,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.03359683794466403,
        "f1": 0.023382999491576247,
        "hf_subset": "vie_Latn-rus_Cyrl",
        "languages": [
          "vie-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.023382999491576247,
        "precision": 0.020809070889855036,
        "recall": 0.03359683794466403
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0014822134387351778,
        "hf_subset": "apc_Arab-rus_Cyrl",
        "languages": [
          "apc-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0014822134387351778,
        "precision": 0.0013175230566534913,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.0266798418972332,
        "f1": 0.018419314525235965,
        "hf_subset": "bug_Latn-rus_Cyrl",
        "languages": [
          "bug-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.018419314525235965,
        "precision": 0.016660435138696007,
        "recall": 0.0266798418972332
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.018940059585735775,
        "hf_subset": "fon_Latn-rus_Cyrl",
        "languages": [
          "fon-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.018940059585735775,
        "precision": 0.017285272546173985,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.03359683794466403,
        "f1": 0.021454391481111515,
        "hf_subset": "jav_Latn-rus_Cyrl",
        "languages": [
          "jav-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.021454391481111515,
        "precision": 0.019067853774087352,
        "recall": 0.03359683794466403
      },
      {
        "accuracy": 0.04743083003952569,
        "f1": 0.03268677378928829,
        "hf_subset": "lao_Laoo-rus_Cyrl",
        "languages": [
          "lao-Laoo",
          "rus-Cyrl"
        ],
        "main_score": 0.03268677378928829,
        "precision": 0.029097647297001365,
        "recall": 0.04743083003952569
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.019644096531233498,
        "hf_subset": "mri_Latn-rus_Cyrl",
        "languages": [
          "mri-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.019644096531233498,
        "precision": 0.01737139729273057,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.00021401344059731334,
        "hf_subset": "rus_Cyrl-ace_Arab",
        "languages": [
          "rus-Cyrl",
          "ace-Arab"
        ],
        "main_score": 0.00021401344059731334,
        "precision": 0.00011096787676764127,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.038537549407114624,
        "f1": 0.014449821708697165,
        "hf_subset": "rus_Cyrl-bam_Latn",
        "languages": [
          "rus-Cyrl",
          "bam-Latn"
        ],
        "main_score": 0.014449821708697165,
        "precision": 0.011606278072726633,
        "recall": 0.038537549407114624
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 1.3519578736970042e-05,
        "hf_subset": "rus_Cyrl-dzo_Tibt",
        "languages": [
          "rus-Cyrl",
          "dzo-Tibt"
        ],
        "main_score": 1.3519578736970042e-05,
        "precision": 6.78658332860538e-06,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.004793307232358647,
        "hf_subset": "rus_Cyrl-hin_Deva",
        "languages": [
          "rus-Cyrl",
          "hin-Deva"
        ],
        "main_score": 0.004793307232358647,
        "precision": 0.003807421438643385,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.04743083003952569,
        "f1": 0.015572295658742814,
        "hf_subset": "rus_Cyrl-khm_Khmr",
        "languages": [
          "rus-Cyrl",
          "khm-Khmr"
        ],
        "main_score": 0.015572295658742814,
        "precision": 0.010915153793327494,
        "recall": 0.04743083003952569
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0015492605953046146,
        "hf_subset": "rus_Cyrl-mag_Deva",
        "languages": [
          "rus-Cyrl",
          "mag-Deva"
        ],
        "main_score": 0.0015492605953046146,
        "precision": 0.0012804389195841892,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.1007905138339921,
        "f1": 0.057801358787101687,
        "hf_subset": "rus_Cyrl-pap_Latn",
        "languages": [
          "rus-Cyrl",
          "pap-Latn"
        ],
        "main_score": 0.057801358787101687,
        "precision": 0.04852557177961154,
        "recall": 0.1007905138339921
      },
      {
        "accuracy": 0.06225296442687747,
        "f1": 0.028167736788401558,
        "hf_subset": "rus_Cyrl-sot_Latn",
        "languages": [
          "rus-Cyrl",
          "sot-Latn"
        ],
        "main_score": 0.028167736788401558,
        "precision": 0.02247974971534385,
        "recall": 0.06225296442687747
      },
      {
        "accuracy": 0.04940711462450593,
        "f1": 0.02471411473456197,
        "hf_subset": "rus_Cyrl-tur_Latn",
        "languages": [
          "rus-Cyrl",
          "tur-Latn"
        ],
        "main_score": 0.02471411473456197,
        "precision": 0.020574747063093993,
        "recall": 0.04940711462450593
      },
      {
        "accuracy": 0.06126482213438735,
        "f1": 0.027497550893022273,
        "hf_subset": "rus_Cyrl-ace_Latn",
        "languages": [
          "rus-Cyrl",
          "ace-Latn"
        ],
        "main_score": 0.027497550893022273,
        "precision": 0.021738984135810456,
        "recall": 0.06126482213438735
      },
      {
        "accuracy": 0.06027667984189723,
        "f1": 0.025716376403257666,
        "hf_subset": "rus_Cyrl-ban_Latn",
        "languages": [
          "rus-Cyrl",
          "ban-Latn"
        ],
        "main_score": 0.025716376403257666,
        "precision": 0.019726363802443112,
        "recall": 0.06027667984189723
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.006097693557194886,
        "hf_subset": "rus_Cyrl-ell_Grek",
        "languages": [
          "rus-Cyrl",
          "ell-Grek"
        ],
        "main_score": 0.006097693557194886,
        "precision": 0.004056567524751943,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.0026914878535320686,
        "hf_subset": "rus_Cyrl-hne_Deva",
        "languages": [
          "rus-Cyrl",
          "hne-Deva"
        ],
        "main_score": 0.0026914878535320686,
        "precision": 0.002029275356747564,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.0741106719367589,
        "f1": 0.03944467331511873,
        "hf_subset": "rus_Cyrl-kik_Latn",
        "languages": [
          "rus-Cyrl",
          "kik-Latn"
        ],
        "main_score": 0.03944467331511873,
        "precision": 0.032297766462786225,
        "recall": 0.0741106719367589
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.0030493725815577233,
        "hf_subset": "rus_Cyrl-mai_Deva",
        "languages": [
          "rus-Cyrl",
          "mai-Deva"
        ],
        "main_score": 0.0030493725815577233,
        "precision": 0.002605413733484032,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.005384038733508875,
        "hf_subset": "rus_Cyrl-pbt_Arab",
        "languages": [
          "rus-Cyrl",
          "pbt-Arab"
        ],
        "main_score": 0.005384038733508875,
        "precision": 0.00440477810789871,
        "recall": 0.019762845849802372
      },
      {
        "accuracy": 0.1373517786561265,
        "f1": 0.08165587958078076,
        "hf_subset": "rus_Cyrl-spa_Latn",
        "languages": [
          "rus-Cyrl",
          "spa-Latn"
        ],
        "main_score": 0.08165587958078076,
        "precision": 0.06807357936310506,
        "recall": 0.1373517786561265
      },
      {
        "accuracy": 0.06225296442687747,
        "f1": 0.029257366405979333,
        "hf_subset": "rus_Cyrl-twi_Latn",
        "languages": [
          "rus-Cyrl",
          "twi-Latn"
        ],
        "main_score": 0.029257366405979333,
        "precision": 0.02352800077764806,
        "recall": 0.06225296442687747
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.0024178195004707064,
        "hf_subset": "rus_Cyrl-acm_Arab",
        "languages": [
          "rus-Cyrl",
          "acm-Arab"
        ],
        "main_score": 0.0024178195004707064,
        "precision": 0.0017958362330434668,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.19466403162055335,
        "f1": 0.12375003177777011,
        "hf_subset": "rus_Cyrl-bel_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bel-Cyrl"
        ],
        "main_score": 0.12375003177777011,
        "precision": 0.10593338222725972,
        "recall": 0.19466403162055335
      },
      {
        "accuracy": 0.45652173913043476,
        "f1": 0.3724410251584164,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.3724410251584164,
        "precision": 0.342070585869993,
        "recall": 0.45652173913043476
      },
      {
        "accuracy": 0.08399209486166008,
        "f1": 0.04638623704086055,
        "hf_subset": "rus_Cyrl-hrv_Latn",
        "languages": [
          "rus-Cyrl",
          "hrv-Latn"
        ],
        "main_score": 0.04638623704086055,
        "precision": 0.03839550244441549,
        "recall": 0.08399209486166008
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.014062006920338519,
        "hf_subset": "rus_Cyrl-kin_Latn",
        "languages": [
          "rus-Cyrl",
          "kin-Latn"
        ],
        "main_score": 0.014062006920338519,
        "precision": 0.011224173157757877,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0031436047855192702,
        "hf_subset": "rus_Cyrl-mal_Mlym",
        "languages": [
          "rus-Cyrl",
          "mal-Mlym"
        ],
        "main_score": 0.0031436047855192702,
        "precision": 0.002670460937906612,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.0014373166314440358,
        "hf_subset": "rus_Cyrl-pes_Arab",
        "languages": [
          "rus-Cyrl",
          "pes-Arab"
        ],
        "main_score": 0.0014373166314440358,
        "precision": 0.0008033759432014458,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.09683794466403162,
        "f1": 0.05756621233399889,
        "hf_subset": "rus_Cyrl-srd_Latn",
        "languages": [
          "rus-Cyrl",
          "srd-Latn"
        ],
        "main_score": 0.05756621233399889,
        "precision": 0.04968934010350803,
        "recall": 0.09683794466403162
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.001699893347135841,
        "hf_subset": "rus_Cyrl-tzm_Tfng",
        "languages": [
          "rus-Cyrl",
          "tzm-Tfng"
        ],
        "main_score": 0.001699893347135841,
        "precision": 0.0010485171310927594,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.002260240898059723,
        "hf_subset": "rus_Cyrl-acq_Arab",
        "languages": [
          "rus-Cyrl",
          "acq-Arab"
        ],
        "main_score": 0.002260240898059723,
        "precision": 0.0017618947651133966,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.05533596837944664,
        "f1": 0.025557096725214855,
        "hf_subset": "rus_Cyrl-bem_Latn",
        "languages": [
          "rus-Cyrl",
          "bem-Latn"
        ],
        "main_score": 0.025557096725214855,
        "precision": 0.020474430485138667,
        "recall": 0.05533596837944664
      },
      {
        "accuracy": 0.10968379446640317,
        "f1": 0.06927653739056441,
        "hf_subset": "rus_Cyrl-epo_Latn",
        "languages": [
          "rus-Cyrl",
          "epo-Latn"
        ],
        "main_score": 0.06927653739056441,
        "precision": 0.05982989891092658,
        "recall": 0.10968379446640317
      },
      {
        "accuracy": 0.038537549407114624,
        "f1": 0.014849251923819416,
        "hf_subset": "rus_Cyrl-hun_Latn",
        "languages": [
          "rus-Cyrl",
          "hun-Latn"
        ],
        "main_score": 0.014849251923819416,
        "precision": 0.011284048389076307,
        "recall": 0.038537549407114624
      },
      {
        "accuracy": 0.11758893280632411,
        "f1": 0.06165323661842153,
        "hf_subset": "rus_Cyrl-kir_Cyrl",
        "languages": [
          "rus-Cyrl",
          "kir-Cyrl"
        ],
        "main_score": 0.06165323661842153,
        "precision": 0.050503588330317734,
        "recall": 0.11758893280632411
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.0034480636194552843,
        "hf_subset": "rus_Cyrl-mar_Deva",
        "languages": [
          "rus-Cyrl",
          "mar-Deva"
        ],
        "main_score": 0.0034480636194552843,
        "precision": 0.002169368933082814,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.036561264822134384,
        "f1": 0.017073160699642913,
        "hf_subset": "rus_Cyrl-plt_Latn",
        "languages": [
          "rus-Cyrl",
          "plt-Latn"
        ],
        "main_score": 0.017073160699642913,
        "precision": 0.013866142221466565,
        "recall": 0.036561264822134384
      },
      {
        "accuracy": 0.27865612648221344,
        "f1": 0.20016211006823656,
        "hf_subset": "rus_Cyrl-srp_Cyrl",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ],
        "main_score": 0.20016211006823656,
        "precision": 0.17808944959872955,
        "recall": 0.27865612648221344
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.0040720001246317035,
        "hf_subset": "rus_Cyrl-uig_Arab",
        "languages": [
          "rus-Cyrl",
          "uig-Arab"
        ],
        "main_score": 0.0040720001246317035,
        "precision": 0.0031827995387129202,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0012523182038248841,
        "hf_subset": "rus_Cyrl-aeb_Arab",
        "languages": [
          "rus-Cyrl",
          "aeb-Arab"
        ],
        "main_score": 0.0012523182038248841,
        "precision": 0.0007219881207918007,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.0021235968806540785,
        "hf_subset": "rus_Cyrl-ben_Beng",
        "languages": [
          "rus-Cyrl",
          "ben-Beng"
        ],
        "main_score": 0.0021235968806540785,
        "precision": 0.0016070065550607899,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.05237154150197629,
        "f1": 0.0241660470816481,
        "hf_subset": "rus_Cyrl-est_Latn",
        "languages": [
          "rus-Cyrl",
          "est-Latn"
        ],
        "main_score": 0.0241660470816481,
        "precision": 0.018918399997223622,
        "recall": 0.05237154150197629
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.004605750841509967,
        "hf_subset": "rus_Cyrl-hye_Armn",
        "languages": [
          "rus-Cyrl",
          "hye-Armn"
        ],
        "main_score": 0.004605750841509967,
        "precision": 0.0036279494319422507,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.042490118577075096,
        "f1": 0.01608906450695449,
        "hf_subset": "rus_Cyrl-kmb_Latn",
        "languages": [
          "rus-Cyrl",
          "kmb-Latn"
        ],
        "main_score": 0.01608906450695449,
        "precision": 0.011956559160697733,
        "recall": 0.042490118577075096
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "rus_Cyrl-min_Arab",
        "languages": [
          "rus-Cyrl",
          "min-Arab"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.09288537549407115,
        "f1": 0.051771987197836086,
        "hf_subset": "rus_Cyrl-pol_Latn",
        "languages": [
          "rus-Cyrl",
          "pol-Latn"
        ],
        "main_score": 0.051771987197836086,
        "precision": 0.04410853399479023,
        "recall": 0.09288537549407115
      },
      {
        "accuracy": 0.044466403162055336,
        "f1": 0.017228533951663395,
        "hf_subset": "rus_Cyrl-ssw_Latn",
        "languages": [
          "rus-Cyrl",
          "ssw-Latn"
        ],
        "main_score": 0.017228533951663395,
        "precision": 0.013109193018982637,
        "recall": 0.044466403162055336
      },
      {
        "accuracy": 0.7786561264822134,
        "f1": 0.723437794089968,
        "hf_subset": "rus_Cyrl-ukr_Cyrl",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ],
        "main_score": 0.723437794089968,
        "precision": 0.6997200263504612,
        "recall": 0.7786561264822134
      },
      {
        "accuracy": 0.116600790513834,
        "f1": 0.07210211321246544,
        "hf_subset": "rus_Cyrl-afr_Latn",
        "languages": [
          "rus-Cyrl",
          "afr-Latn"
        ],
        "main_score": 0.07210211321246544,
        "precision": 0.06112348624182424,
        "recall": 0.116600790513834
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.0030220102875915798,
        "hf_subset": "rus_Cyrl-bho_Deva",
        "languages": [
          "rus-Cyrl",
          "bho-Deva"
        ],
        "main_score": 0.0030220102875915798,
        "precision": 0.001835470214790494,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.04743083003952569,
        "f1": 0.02365778929020036,
        "hf_subset": "rus_Cyrl-eus_Latn",
        "languages": [
          "rus-Cyrl",
          "eus-Latn"
        ],
        "main_score": 0.02365778929020036,
        "precision": 0.01940379187966958,
        "recall": 0.04743083003952569
      },
      {
        "accuracy": 0.046442687747035576,
        "f1": 0.021195749013861974,
        "hf_subset": "rus_Cyrl-ibo_Latn",
        "languages": [
          "rus-Cyrl",
          "ibo-Latn"
        ],
        "main_score": 0.021195749013861974,
        "precision": 0.016908162240490094,
        "recall": 0.046442687747035576
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.01171765155342922,
        "hf_subset": "rus_Cyrl-kmr_Latn",
        "languages": [
          "rus-Cyrl",
          "kmr-Latn"
        ],
        "main_score": 0.01171765155342922,
        "precision": 0.009215324110717323,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.06225296442687747,
        "f1": 0.02836375694406906,
        "hf_subset": "rus_Cyrl-min_Latn",
        "languages": [
          "rus-Cyrl",
          "min-Latn"
        ],
        "main_score": 0.02836375694406906,
        "precision": 0.022454925846135353,
        "recall": 0.06225296442687747
      },
      {
        "accuracy": 0.13043478260869565,
        "f1": 0.07928492684187505,
        "hf_subset": "rus_Cyrl-por_Latn",
        "languages": [
          "rus-Cyrl",
          "por-Latn"
        ],
        "main_score": 0.07928492684187505,
        "precision": 0.06733529877856778,
        "recall": 0.13043478260869565
      },
      {
        "accuracy": 0.06324110671936758,
        "f1": 0.02893478370813233,
        "hf_subset": "rus_Cyrl-sun_Latn",
        "languages": [
          "rus-Cyrl",
          "sun-Latn"
        ],
        "main_score": 0.02893478370813233,
        "precision": 0.023070325496581272,
        "recall": 0.06324110671936758
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.015303158962810913,
        "hf_subset": "rus_Cyrl-umb_Latn",
        "languages": [
          "rus-Cyrl",
          "umb-Latn"
        ],
        "main_score": 0.015303158962810913,
        "precision": 0.012764743528664711,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.002415847475563465,
        "hf_subset": "rus_Cyrl-ajp_Arab",
        "languages": [
          "rus-Cyrl",
          "ajp-Arab"
        ],
        "main_score": 0.002415847475563465,
        "precision": 0.0017720700916484969,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 7.63781482117966e-05,
        "hf_subset": "rus_Cyrl-bjn_Arab",
        "languages": [
          "rus-Cyrl",
          "bjn-Arab"
        ],
        "main_score": 7.63781482117966e-05,
        "precision": 3.909134343916952e-05,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.043478260869565216,
        "f1": 0.017377888407997606,
        "hf_subset": "rus_Cyrl-ewe_Latn",
        "languages": [
          "rus-Cyrl",
          "ewe-Latn"
        ],
        "main_score": 0.017377888407997606,
        "precision": 0.013516673943113951,
        "recall": 0.043478260869565216
      },
      {
        "accuracy": 0.09683794466403162,
        "f1": 0.05242016842050188,
        "hf_subset": "rus_Cyrl-ilo_Latn",
        "languages": [
          "rus-Cyrl",
          "ilo-Latn"
        ],
        "main_score": 0.05242016842050188,
        "precision": 0.044866885307842434,
        "recall": 0.09683794466403162
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.0017652383565558408,
        "hf_subset": "rus_Cyrl-knc_Arab",
        "languages": [
          "rus-Cyrl",
          "knc-Arab"
        ],
        "main_score": 0.0017652383565558408,
        "precision": 0.0011037411523866978,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.2707509881422925,
        "f1": 0.1934600349532923,
        "hf_subset": "rus_Cyrl-mkd_Cyrl",
        "languages": [
          "rus-Cyrl",
          "mkd-Cyrl"
        ],
        "main_score": 0.1934600349532923,
        "precision": 0.1710455631873616,
        "recall": 0.2707509881422925
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.0017780337404365626,
        "hf_subset": "rus_Cyrl-prs_Arab",
        "languages": [
          "rus-Cyrl",
          "prs-Arab"
        ],
        "main_score": 0.0017780337404365626,
        "precision": 0.0010607030776713852,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.11956521739130435,
        "f1": 0.06769061432896153,
        "hf_subset": "rus_Cyrl-swe_Latn",
        "languages": [
          "rus-Cyrl",
          "swe-Latn"
        ],
        "main_score": 0.06769061432896153,
        "precision": 0.056824613169668164,
        "recall": 0.11956521739130435
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.002634228155145421,
        "hf_subset": "rus_Cyrl-urd_Arab",
        "languages": [
          "rus-Cyrl",
          "urd-Arab"
        ],
        "main_score": 0.002634228155145421,
        "precision": 0.002030288529377064,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.06027667984189723,
        "f1": 0.026381264793439756,
        "hf_subset": "rus_Cyrl-aka_Latn",
        "languages": [
          "rus-Cyrl",
          "aka-Latn"
        ],
        "main_score": 0.026381264793439756,
        "precision": 0.020546894326431187,
        "recall": 0.06027667984189723
      },
      {
        "accuracy": 0.05632411067193676,
        "f1": 0.024325786339622724,
        "hf_subset": "rus_Cyrl-bjn_Latn",
        "languages": [
          "rus-Cyrl",
          "bjn-Latn"
        ],
        "main_score": 0.024325786339622724,
        "precision": 0.01919407722273335,
        "recall": 0.05632411067193676
      },
      {
        "accuracy": 0.06225296442687747,
        "f1": 0.027492740280464063,
        "hf_subset": "rus_Cyrl-fao_Latn",
        "languages": [
          "rus-Cyrl",
          "fao-Latn"
        ],
        "main_score": 0.027492740280464063,
        "precision": 0.022095932255633485,
        "recall": 0.06225296442687747
      },
      {
        "accuracy": 0.06620553359683795,
        "f1": 0.03509460623343257,
        "hf_subset": "rus_Cyrl-ind_Latn",
        "languages": [
          "rus-Cyrl",
          "ind-Latn"
        ],
        "main_score": 0.03509460623343257,
        "precision": 0.02964131719871664,
        "recall": 0.06620553359683795
      },
      {
        "accuracy": 0.07114624505928854,
        "f1": 0.03547790135571581,
        "hf_subset": "rus_Cyrl-knc_Latn",
        "languages": [
          "rus-Cyrl",
          "knc-Latn"
        ],
        "main_score": 0.03547790135571581,
        "precision": 0.0284542841837504,
        "recall": 0.07114624505928854
      },
      {
        "accuracy": 0.06027667984189723,
        "f1": 0.028026958666501147,
        "hf_subset": "rus_Cyrl-mlt_Latn",
        "languages": [
          "rus-Cyrl",
          "mlt-Latn"
        ],
        "main_score": 0.028026958666501147,
        "precision": 0.022170072274888337,
        "recall": 0.06027667984189723
      },
      {
        "accuracy": 0.04743083003952569,
        "f1": 0.01940732137866525,
        "hf_subset": "rus_Cyrl-quy_Latn",
        "languages": [
          "rus-Cyrl",
          "quy-Latn"
        ],
        "main_score": 0.01940732137866525,
        "precision": 0.014870879032241265,
        "recall": 0.04743083003952569
      },
      {
        "accuracy": 0.03359683794466403,
        "f1": 0.014689611382060609,
        "hf_subset": "rus_Cyrl-swh_Latn",
        "languages": [
          "rus-Cyrl",
          "swh-Latn"
        ],
        "main_score": 0.014689611382060609,
        "precision": 0.011841888879759436,
        "recall": 0.03359683794466403
      },
      {
        "accuracy": 0.03162055335968379,
        "f1": 0.013073717971912646,
        "hf_subset": "rus_Cyrl-uzn_Latn",
        "languages": [
          "rus-Cyrl",
          "uzn-Latn"
        ],
        "main_score": 0.013073717971912646,
        "precision": 0.010532560904639738,
        "recall": 0.03162055335968379
      },
      {
        "accuracy": 0.06027667984189723,
        "f1": 0.026889272089010777,
        "hf_subset": "rus_Cyrl-als_Latn",
        "languages": [
          "rus-Cyrl",
          "als-Latn"
        ],
        "main_score": 0.026889272089010777,
        "precision": 0.02106430833891706,
        "recall": 0.06027667984189723
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0010776981877863424,
        "hf_subset": "rus_Cyrl-bod_Tibt",
        "languages": [
          "rus-Cyrl",
          "bod-Tibt"
        ],
        "main_score": 0.0010776981877863424,
        "precision": 0.0006428383154385979,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.05039525691699605,
        "f1": 0.023095281539798725,
        "hf_subset": "rus_Cyrl-fij_Latn",
        "languages": [
          "rus-Cyrl",
          "fij-Latn"
        ],
        "main_score": 0.023095281539798725,
        "precision": 0.018804413532709886,
        "recall": 0.05039525691699605
      },
      {
        "accuracy": 0.043478260869565216,
        "f1": 0.018296329417656108,
        "hf_subset": "rus_Cyrl-isl_Latn",
        "languages": [
          "rus-Cyrl",
          "isl-Latn"
        ],
        "main_score": 0.018296329417656108,
        "precision": 0.01461752979802829,
        "recall": 0.043478260869565216
      },
      {
        "accuracy": 0.06225296442687747,
        "f1": 0.03039055484305826,
        "hf_subset": "rus_Cyrl-kon_Latn",
        "languages": [
          "rus-Cyrl",
          "kon-Latn"
        ],
        "main_score": 0.03039055484305826,
        "precision": 0.024577217531174075,
        "recall": 0.06225296442687747
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.00424595649572874,
        "hf_subset": "rus_Cyrl-mni_Beng",
        "languages": [
          "rus-Cyrl",
          "mni-Beng"
        ],
        "main_score": 0.00424595649572874,
        "precision": 0.0033558967490973303,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.09387351778656126,
        "f1": 0.051321996020597324,
        "hf_subset": "rus_Cyrl-ron_Latn",
        "languages": [
          "rus-Cyrl",
          "ron-Latn"
        ],
        "main_score": 0.051321996020597324,
        "precision": 0.04180679237061473,
        "recall": 0.09387351778656126
      },
      {
        "accuracy": 0.06225296442687747,
        "f1": 0.032860716788749994,
        "hf_subset": "rus_Cyrl-szl_Latn",
        "languages": [
          "rus-Cyrl",
          "szl-Latn"
        ],
        "main_score": 0.032860716788749994,
        "precision": 0.028423354741935792,
        "recall": 0.06225296442687747
      },
      {
        "accuracy": 0.11758893280632411,
        "f1": 0.07160503621646377,
        "hf_subset": "rus_Cyrl-vec_Latn",
        "languages": [
          "rus-Cyrl",
          "vec-Latn"
        ],
        "main_score": 0.07160503621646377,
        "precision": 0.060261241558178316,
        "recall": 0.11758893280632411
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.0014237282522529353,
        "hf_subset": "rus_Cyrl-amh_Ethi",
        "languages": [
          "rus-Cyrl",
          "amh-Ethi"
        ],
        "main_score": 0.0014237282522529353,
        "precision": 0.0008427735115497804,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.09881422924901186,
        "f1": 0.05546878587473861,
        "hf_subset": "rus_Cyrl-bos_Latn",
        "languages": [
          "rus-Cyrl",
          "bos-Latn"
        ],
        "main_score": 0.05546878587473861,
        "precision": 0.04610441088313999,
        "recall": 0.09881422924901186
      },
      {
        "accuracy": 0.0533596837944664,
        "f1": 0.022779925588972443,
        "hf_subset": "rus_Cyrl-fin_Latn",
        "languages": [
          "rus-Cyrl",
          "fin-Latn"
        ],
        "main_score": 0.022779925588972443,
        "precision": 0.01751552390639919,
        "recall": 0.0533596837944664
      },
      {
        "accuracy": 0.1482213438735178,
        "f1": 0.09196712378530561,
        "hf_subset": "rus_Cyrl-ita_Latn",
        "languages": [
          "rus-Cyrl",
          "ita-Latn"
        ],
        "main_score": 0.09196712378530561,
        "precision": 0.07814755786593731,
        "recall": 0.1482213438735178
      },
      {
        "accuracy": 0.0266798418972332,
        "f1": 0.007374486312704612,
        "hf_subset": "rus_Cyrl-kor_Hang",
        "languages": [
          "rus-Cyrl",
          "kor-Hang"
        ],
        "main_score": 0.007374486312704612,
        "precision": 0.005319960746155564,
        "recall": 0.0266798418972332
      },
      {
        "accuracy": 0.045454545454545456,
        "f1": 0.019817039496552506,
        "hf_subset": "rus_Cyrl-mos_Latn",
        "languages": [
          "rus-Cyrl",
          "mos-Latn"
        ],
        "main_score": 0.019817039496552506,
        "precision": 0.015688987106512405,
        "recall": 0.045454545454545456
      },
      {
        "accuracy": 0.024703557312252964,
        "f1": 0.009813541850179618,
        "hf_subset": "rus_Cyrl-run_Latn",
        "languages": [
          "rus-Cyrl",
          "run-Latn"
        ],
        "main_score": 0.009813541850179618,
        "precision": 0.008308985319672396,
        "recall": 0.024703557312252964
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.005887285375573624,
        "hf_subset": "rus_Cyrl-tam_Taml",
        "languages": [
          "rus-Cyrl",
          "tam-Taml"
        ],
        "main_score": 0.005887285375573624,
        "precision": 0.004405061946787407,
        "recall": 0.019762845849802372
      },
      {
        "accuracy": 0.06126482213438735,
        "f1": 0.027993102970064198,
        "hf_subset": "rus_Cyrl-vie_Latn",
        "languages": [
          "rus-Cyrl",
          "vie-Latn"
        ],
        "main_score": 0.027993102970064198,
        "precision": 0.02256234580767141,
        "recall": 0.06126482213438735
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.0009649303272539087,
        "hf_subset": "rus_Cyrl-apc_Arab",
        "languages": [
          "rus-Cyrl",
          "apc-Arab"
        ],
        "main_score": 0.0009649303272539087,
        "precision": 0.0005199637057470288,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.05237154150197629,
        "f1": 0.025331978904423964,
        "hf_subset": "rus_Cyrl-bug_Latn",
        "languages": [
          "rus-Cyrl",
          "bug-Latn"
        ],
        "main_score": 0.025331978904423964,
        "precision": 0.020906316786673557,
        "recall": 0.05237154150197629
      },
      {
        "accuracy": 0.039525691699604744,
        "f1": 0.012347295348392691,
        "hf_subset": "rus_Cyrl-fon_Latn",
        "languages": [
          "rus-Cyrl",
          "fon-Latn"
        ],
        "main_score": 0.012347295348392691,
        "precision": 0.00870106089973724,
        "recall": 0.039525691699604744
      },
      {
        "accuracy": 0.05731225296442688,
        "f1": 0.03024107159742691,
        "hf_subset": "rus_Cyrl-jav_Latn",
        "languages": [
          "rus-Cyrl",
          "jav-Latn"
        ],
        "main_score": 0.03024107159742691,
        "precision": 0.02535554884027012,
        "recall": 0.05731225296442688
      },
      {
        "accuracy": 0.0691699604743083,
        "f1": 0.033289070190066286,
        "hf_subset": "rus_Cyrl-lao_Laoo",
        "languages": [
          "rus-Cyrl",
          "lao-Laoo"
        ],
        "main_score": 0.033289070190066286,
        "precision": 0.026824667020540788,
        "recall": 0.0691699604743083
      },
      {
        "accuracy": 0.0533596837944664,
        "f1": 0.018376618505865337,
        "hf_subset": "rus_Cyrl-mri_Latn",
        "languages": [
          "rus-Cyrl",
          "mri-Latn"
        ],
        "main_score": 0.018376618505865337,
        "precision": 0.013135817050471631,
        "recall": 0.0533596837944664
      },
      {
        "accuracy": 0.05237154150197629,
        "f1": 0.0261327581601852,
        "hf_subset": "rus_Cyrl-taq_Latn",
        "languages": [
          "rus-Cyrl",
          "taq-Latn"
        ],
        "main_score": 0.0261327581601852,
        "precision": 0.02153222138150561,
        "recall": 0.05237154150197629
      },
      {
        "accuracy": 0.1067193675889328,
        "f1": 0.05986059688908068,
        "hf_subset": "rus_Cyrl-war_Latn",
        "languages": [
          "rus-Cyrl",
          "war-Latn"
        ],
        "main_score": 0.05986059688908068,
        "precision": 0.05051029242786973,
        "recall": 0.1067193675889328
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.0020246153089110994,
        "hf_subset": "rus_Cyrl-arb_Arab",
        "languages": [
          "rus-Cyrl",
          "arb-Arab"
        ],
        "main_score": 0.0020246153089110994,
        "precision": 0.0015743458492051274,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.4397233201581028,
        "f1": 0.3465774306709401,
        "hf_subset": "rus_Cyrl-bul_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bul-Cyrl"
        ],
        "main_score": 0.3465774306709401,
        "precision": 0.31540603665109596,
        "recall": 0.4397233201581028
      },
      {
        "accuracy": 0.16106719367588934,
        "f1": 0.10429216698979546,
        "hf_subset": "rus_Cyrl-fra_Latn",
        "languages": [
          "rus-Cyrl",
          "fra-Latn"
        ],
        "main_score": 0.10429216698979546,
        "precision": 0.08945130219963797,
        "recall": 0.16106719367588934
      },
      {
        "accuracy": 0.1482213438735178,
        "f1": 0.09823265611335093,
        "hf_subset": "rus_Cyrl-jpn_Jpan",
        "languages": [
          "rus-Cyrl",
          "jpn-Jpan"
        ],
        "main_score": 0.09823265611335093,
        "precision": 0.08540041006738591,
        "recall": 0.1482213438735178
      },
      {
        "accuracy": 0.12055335968379446,
        "f1": 0.0730622934377875,
        "hf_subset": "rus_Cyrl-lij_Latn",
        "languages": [
          "rus-Cyrl",
          "lij-Latn"
        ],
        "main_score": 0.0730622934377875,
        "precision": 0.06061270374075535,
        "recall": 0.12055335968379446
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.004597962201717143,
        "hf_subset": "rus_Cyrl-mya_Mymr",
        "languages": [
          "rus-Cyrl",
          "mya-Mymr"
        ],
        "main_score": 0.004597962201717143,
        "precision": 0.003207785182741132,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.046442687747035576,
        "f1": 0.018799939205974225,
        "hf_subset": "rus_Cyrl-sag_Latn",
        "languages": [
          "rus-Cyrl",
          "sag-Latn"
        ],
        "main_score": 0.018799939205974225,
        "precision": 0.014734650717872342,
        "recall": 0.046442687747035576
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.002064369772722599,
        "hf_subset": "rus_Cyrl-taq_Tfng",
        "languages": [
          "rus-Cyrl",
          "taq-Tfng"
        ],
        "main_score": 0.002064369772722599,
        "precision": 0.0016221944008595439,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.04743083003952569,
        "f1": 0.022767381257779093,
        "hf_subset": "rus_Cyrl-wol_Latn",
        "languages": [
          "rus-Cyrl",
          "wol-Latn"
        ],
        "main_score": 0.022767381257779093,
        "precision": 0.01885518640318428,
        "recall": 0.04743083003952569
      },
      {
        "accuracy": 0.0266798418972332,
        "f1": 0.009682548607157254,
        "hf_subset": "rus_Cyrl-arb_Latn",
        "languages": [
          "rus-Cyrl",
          "arb-Latn"
        ],
        "main_score": 0.009682548607157254,
        "precision": 0.0075277930239565334,
        "recall": 0.0266798418972332
      },
      {
        "accuracy": 0.1422924901185771,
        "f1": 0.09052135181347787,
        "hf_subset": "rus_Cyrl-cat_Latn",
        "languages": [
          "rus-Cyrl",
          "cat-Latn"
        ],
        "main_score": 0.09052135181347787,
        "precision": 0.07795997871827051,
        "recall": 0.1422924901185771
      },
      {
        "accuracy": 0.09486166007905138,
        "f1": 0.053389087307071495,
        "hf_subset": "rus_Cyrl-fur_Latn",
        "languages": [
          "rus-Cyrl",
          "fur-Latn"
        ],
        "main_score": 0.053389087307071495,
        "precision": 0.04403242663058694,
        "recall": 0.09486166007905138
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.0066049766866284445,
        "hf_subset": "rus_Cyrl-kab_Latn",
        "languages": [
          "rus-Cyrl",
          "kab-Latn"
        ],
        "main_score": 0.0066049766866284445,
        "precision": 0.00472412086418621,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.10276679841897234,
        "f1": 0.05684587437497747,
        "hf_subset": "rus_Cyrl-lim_Latn",
        "languages": [
          "rus-Cyrl",
          "lim-Latn"
        ],
        "main_score": 0.05684587437497747,
        "precision": 0.045936754689806306,
        "recall": 0.10276679841897234
      },
      {
        "accuracy": 0.11857707509881422,
        "f1": 0.07297276983636575,
        "hf_subset": "rus_Cyrl-nld_Latn",
        "languages": [
          "rus-Cyrl",
          "nld-Latn"
        ],
        "main_score": 0.07297276983636575,
        "precision": 0.061879953158717894,
        "recall": 0.11857707509881422
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.006167441835975647,
        "hf_subset": "rus_Cyrl-san_Deva",
        "languages": [
          "rus-Cyrl",
          "san-Deva"
        ],
        "main_score": 0.006167441835975647,
        "precision": 0.004619322278820194,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.1482213438735178,
        "f1": 0.08807221076606103,
        "hf_subset": "rus_Cyrl-tat_Cyrl",
        "languages": [
          "rus-Cyrl",
          "tat-Cyrl"
        ],
        "main_score": 0.08807221076606103,
        "precision": 0.07431316066138599,
        "recall": 0.1482213438735178
      },
      {
        "accuracy": 0.041501976284584984,
        "f1": 0.01537193386033355,
        "hf_subset": "rus_Cyrl-xho_Latn",
        "languages": [
          "rus-Cyrl",
          "xho-Latn"
        ],
        "main_score": 0.01537193386033355,
        "precision": 0.011743271099984052,
        "recall": 0.041501976284584984
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0004933148674007888,
        "hf_subset": "rus_Cyrl-ars_Arab",
        "languages": [
          "rus-Cyrl",
          "ars-Arab"
        ],
        "main_score": 0.0004933148674007888,
        "precision": 0.0002571677254230881,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.08596837944664032,
        "f1": 0.04484807533246604,
        "hf_subset": "rus_Cyrl-ceb_Latn",
        "languages": [
          "rus-Cyrl",
          "ceb-Latn"
        ],
        "main_score": 0.04484807533246604,
        "precision": 0.037266668188692134,
        "recall": 0.08596837944664032
      },
      {
        "accuracy": 0.05039525691699605,
        "f1": 0.019769605598512534,
        "hf_subset": "rus_Cyrl-fuv_Latn",
        "languages": [
          "rus-Cyrl",
          "fuv-Latn"
        ],
        "main_score": 0.019769605598512534,
        "precision": 0.01498132764901356,
        "recall": 0.05039525691699605
      },
      {
        "accuracy": 0.04743083003952569,
        "f1": 0.019992578515136198,
        "hf_subset": "rus_Cyrl-kac_Latn",
        "languages": [
          "rus-Cyrl",
          "kac-Latn"
        ],
        "main_score": 0.019992578515136198,
        "precision": 0.015438037615656193,
        "recall": 0.04743083003952569
      },
      {
        "accuracy": 0.04940711462450593,
        "f1": 0.02465957354515248,
        "hf_subset": "rus_Cyrl-lin_Latn",
        "languages": [
          "rus-Cyrl",
          "lin-Latn"
        ],
        "main_score": 0.02465957354515248,
        "precision": 0.020356409454781173,
        "recall": 0.04940711462450593
      },
      {
        "accuracy": 0.12055335968379446,
        "f1": 0.07513200161421504,
        "hf_subset": "rus_Cyrl-nno_Latn",
        "languages": [
          "rus-Cyrl",
          "nno-Latn"
        ],
        "main_score": 0.07513200161421504,
        "precision": 0.06510946839418966,
        "recall": 0.12055335968379446
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.00038419689668876193,
        "hf_subset": "rus_Cyrl-sat_Olck",
        "languages": [
          "rus-Cyrl",
          "sat-Olck"
        ],
        "main_score": 0.00038419689668876193,
        "precision": 0.000204398885582909,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.004674094855744492,
        "hf_subset": "rus_Cyrl-tel_Telu",
        "languages": [
          "rus-Cyrl",
          "tel-Telu"
        ],
        "main_score": 0.004674094855744492,
        "precision": 0.0027953095508421255,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.0012583786220914548,
        "hf_subset": "rus_Cyrl-ydd_Hebr",
        "languages": [
          "rus-Cyrl",
          "ydd-Hebr"
        ],
        "main_score": 0.0012583786220914548,
        "precision": 0.0007073282768562598,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.002253389116686997,
        "hf_subset": "rus_Cyrl-ary_Arab",
        "languages": [
          "rus-Cyrl",
          "ary-Arab"
        ],
        "main_score": 0.002253389116686997,
        "precision": 0.0014439522461813152,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.09189723320158102,
        "f1": 0.050902347210325175,
        "hf_subset": "rus_Cyrl-ces_Latn",
        "languages": [
          "rus-Cyrl",
          "ces-Latn"
        ],
        "main_score": 0.050902347210325175,
        "precision": 0.042510586891001456,
        "recall": 0.09189723320158102
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.004168549464450979,
        "hf_subset": "rus_Cyrl-gaz_Latn",
        "languages": [
          "rus-Cyrl",
          "gaz-Latn"
        ],
        "main_score": 0.004168549464450979,
        "precision": 0.002717059277077449,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.05138339920948617,
        "f1": 0.025698507103994198,
        "hf_subset": "rus_Cyrl-kam_Latn",
        "languages": [
          "rus-Cyrl",
          "kam-Latn"
        ],
        "main_score": 0.025698507103994198,
        "precision": 0.02133042828072443,
        "recall": 0.05138339920948617
      },
      {
        "accuracy": 0.0691699604743083,
        "f1": 0.03748563841778307,
        "hf_subset": "rus_Cyrl-lit_Latn",
        "languages": [
          "rus-Cyrl",
          "lit-Latn"
        ],
        "main_score": 0.03748563841778307,
        "precision": 0.031809853600488436,
        "recall": 0.0691699604743083
      },
      {
        "accuracy": 0.10276679841897234,
        "f1": 0.06293220759623921,
        "hf_subset": "rus_Cyrl-nob_Latn",
        "languages": [
          "rus-Cyrl",
          "nob-Latn"
        ],
        "main_score": 0.06293220759623921,
        "precision": 0.05333754411732468,
        "recall": 0.10276679841897234
      },
      {
        "accuracy": 0.08695652173913043,
        "f1": 0.048148067106234906,
        "hf_subset": "rus_Cyrl-scn_Latn",
        "languages": [
          "rus-Cyrl",
          "scn-Latn"
        ],
        "main_score": 0.048148067106234906,
        "precision": 0.04016021348957884,
        "recall": 0.08695652173913043
      },
      {
        "accuracy": 0.07114624505928854,
        "f1": 0.036489434200147323,
        "hf_subset": "rus_Cyrl-tgk_Cyrl",
        "languages": [
          "rus-Cyrl",
          "tgk-Cyrl"
        ],
        "main_score": 0.036489434200147323,
        "precision": 0.030955572136989868,
        "recall": 0.07114624505928854
      },
      {
        "accuracy": 0.044466403162055336,
        "f1": 0.022820950668008218,
        "hf_subset": "rus_Cyrl-yor_Latn",
        "languages": [
          "rus-Cyrl",
          "yor-Latn"
        ],
        "main_score": 0.022820950668008218,
        "precision": 0.019409249982502527,
        "recall": 0.044466403162055336
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.0008857552718001836,
        "hf_subset": "rus_Cyrl-arz_Arab",
        "languages": [
          "rus-Cyrl",
          "arz-Arab"
        ],
        "main_score": 0.0008857552718001836,
        "precision": 0.0004768207647420976,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.0159999492518851,
        "hf_subset": "rus_Cyrl-cjk_Latn",
        "languages": [
          "rus-Cyrl",
          "cjk-Latn"
        ],
        "main_score": 0.0159999492518851,
        "precision": 0.013070436505636739,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.009463741615995069,
        "hf_subset": "rus_Cyrl-gla_Latn",
        "languages": [
          "rus-Cyrl",
          "gla-Latn"
        ],
        "main_score": 0.009463741615995069,
        "precision": 0.007019752334068772,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.00410428030464308,
        "hf_subset": "rus_Cyrl-kan_Knda",
        "languages": [
          "rus-Cyrl",
          "kan-Knda"
        ],
        "main_score": 0.00410428030464308,
        "precision": 0.0029748492644306084,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.09683794466403162,
        "f1": 0.05307955821448639,
        "hf_subset": "rus_Cyrl-lmo_Latn",
        "languages": [
          "rus-Cyrl",
          "lmo-Latn"
        ],
        "main_score": 0.05307955821448639,
        "precision": 0.043584809463781585,
        "recall": 0.09683794466403162
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.0048500590626410715,
        "hf_subset": "rus_Cyrl-npi_Deva",
        "languages": [
          "rus-Cyrl",
          "npi-Deva"
        ],
        "main_score": 0.0048500590626410715,
        "precision": 0.0036967515591071836,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.08596837944664032,
        "f1": 0.04249587433462139,
        "hf_subset": "rus_Cyrl-shn_Mymr",
        "languages": [
          "rus-Cyrl",
          "shn-Mymr"
        ],
        "main_score": 0.04249587433462139,
        "precision": 0.03473519411996649,
        "recall": 0.08596837944664032
      },
      {
        "accuracy": 0.06422924901185771,
        "f1": 0.028619843941674574,
        "hf_subset": "rus_Cyrl-tgl_Latn",
        "languages": [
          "rus-Cyrl",
          "tgl-Latn"
        ],
        "main_score": 0.028619843941674574,
        "precision": 0.021568138768955136,
        "recall": 0.06422924901185771
      },
      {
        "accuracy": 0.2727272727272727,
        "f1": 0.20277302298053285,
        "hf_subset": "rus_Cyrl-yue_Hant",
        "languages": [
          "rus-Cyrl",
          "yue-Hant"
        ],
        "main_score": 0.20277302298053285,
        "precision": 0.18221020021603423,
        "recall": 0.2727272727272727
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.001958654620733164,
        "hf_subset": "rus_Cyrl-asm_Beng",
        "languages": [
          "rus-Cyrl",
          "asm-Beng"
        ],
        "main_score": 0.001958654620733164,
        "precision": 0.0012530998863276661,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0015392712821771062,
        "hf_subset": "rus_Cyrl-ckb_Arab",
        "languages": [
          "rus-Cyrl",
          "ckb-Arab"
        ],
        "main_score": 0.0015392712821771062,
        "precision": 0.0012780508815587867,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.01094626139984532,
        "hf_subset": "rus_Cyrl-gle_Latn",
        "languages": [
          "rus-Cyrl",
          "gle-Latn"
        ],
        "main_score": 0.01094626139984532,
        "precision": 0.009002463326360436,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.0016226354199634077,
        "hf_subset": "rus_Cyrl-kas_Arab",
        "languages": [
          "rus-Cyrl",
          "kas-Arab"
        ],
        "main_score": 0.0016226354199634077,
        "precision": 0.0008970954923051793,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.04743083003952569,
        "f1": 0.022987816416958694,
        "hf_subset": "rus_Cyrl-ltg_Latn",
        "languages": [
          "rus-Cyrl",
          "ltg-Latn"
        ],
        "main_score": 0.022987816416958694,
        "precision": 0.018943386708293874,
        "recall": 0.04743083003952569
      },
      {
        "accuracy": 0.05533596837944664,
        "f1": 0.027225839095813588,
        "hf_subset": "rus_Cyrl-nso_Latn",
        "languages": [
          "rus-Cyrl",
          "nso-Latn"
        ],
        "main_score": 0.027225839095813588,
        "precision": 0.022668125681959677,
        "recall": 0.05533596837944664
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.0017953217689102596,
        "hf_subset": "rus_Cyrl-sin_Sinh",
        "languages": [
          "rus-Cyrl",
          "sin-Sinh"
        ],
        "main_score": 0.0017953217689102596,
        "precision": 0.0010235204292226934,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.006752070273526896,
        "hf_subset": "rus_Cyrl-tha_Thai",
        "languages": [
          "rus-Cyrl",
          "tha-Thai"
        ],
        "main_score": 0.006752070273526896,
        "precision": 0.005279709758764045,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.2618577075098814,
        "f1": 0.19687952184588456,
        "hf_subset": "rus_Cyrl-zho_Hans",
        "languages": [
          "rus-Cyrl",
          "zho-Hans"
        ],
        "main_score": 0.19687952184588456,
        "precision": 0.17901538439077103,
        "recall": 0.2618577075098814
      },
      {
        "accuracy": 0.11363636363636363,
        "f1": 0.06673631679322824,
        "hf_subset": "rus_Cyrl-ast_Latn",
        "languages": [
          "rus-Cyrl",
          "ast-Latn"
        ],
        "main_score": 0.06673631679322824,
        "precision": 0.05493471215614322,
        "recall": 0.11363636363636363
      },
      {
        "accuracy": 0.043478260869565216,
        "f1": 0.019040037647017054,
        "hf_subset": "rus_Cyrl-crh_Latn",
        "languages": [
          "rus-Cyrl",
          "crh-Latn"
        ],
        "main_score": 0.019040037647017054,
        "precision": 0.014618621414562383,
        "recall": 0.043478260869565216
      },
      {
        "accuracy": 0.13043478260869565,
        "f1": 0.07617223181356278,
        "hf_subset": "rus_Cyrl-glg_Latn",
        "languages": [
          "rus-Cyrl",
          "glg-Latn"
        ],
        "main_score": 0.07617223181356278,
        "precision": 0.06288151529810447,
        "recall": 0.13043478260869565
      },
      {
        "accuracy": 0.04841897233201581,
        "f1": 0.01905536200448473,
        "hf_subset": "rus_Cyrl-kas_Deva",
        "languages": [
          "rus-Cyrl",
          "kas-Deva"
        ],
        "main_score": 0.01905536200448473,
        "precision": 0.014560496251667176,
        "recall": 0.04841897233201581
      },
      {
        "accuracy": 0.11166007905138339,
        "f1": 0.06702346090217945,
        "hf_subset": "rus_Cyrl-ltz_Latn",
        "languages": [
          "rus-Cyrl",
          "ltz-Latn"
        ],
        "main_score": 0.06702346090217945,
        "precision": 0.05605660517890232,
        "recall": 0.11166007905138339
      },
      {
        "accuracy": 0.024703557312252964,
        "f1": 0.007730846472473181,
        "hf_subset": "rus_Cyrl-nus_Latn",
        "languages": [
          "rus-Cyrl",
          "nus-Latn"
        ],
        "main_score": 0.007730846472473181,
        "precision": 0.005921015309667276,
        "recall": 0.024703557312252964
      },
      {
        "accuracy": 0.07905138339920949,
        "f1": 0.0409127010205842,
        "hf_subset": "rus_Cyrl-slk_Latn",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ],
        "main_score": 0.0409127010205842,
        "precision": 0.03350168156245231,
        "recall": 0.07905138339920949
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.001056073820369457,
        "hf_subset": "rus_Cyrl-tir_Ethi",
        "languages": [
          "rus-Cyrl",
          "tir-Ethi"
        ],
        "main_score": 0.001056073820369457,
        "precision": 0.0006050069863249948,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.2826086956521739,
        "f1": 0.21171920004676922,
        "hf_subset": "rus_Cyrl-zho_Hant",
        "languages": [
          "rus-Cyrl",
          "zho-Hant"
        ],
        "main_score": 0.21171920004676922,
        "precision": 0.1903349235393171,
        "recall": 0.2826086956521739
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0026249335459861776,
        "hf_subset": "rus_Cyrl-awa_Deva",
        "languages": [
          "rus-Cyrl",
          "awa-Deva"
        ],
        "main_score": 0.0026249335459861776,
        "precision": 0.0017834884139231965,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.014309294443460316,
        "hf_subset": "rus_Cyrl-cym_Latn",
        "languages": [
          "rus-Cyrl",
          "cym-Latn"
        ],
        "main_score": 0.014309294443460316,
        "precision": 0.011281959424430766,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.06126482213438735,
        "f1": 0.027479694298717414,
        "hf_subset": "rus_Cyrl-grn_Latn",
        "languages": [
          "rus-Cyrl",
          "grn-Latn"
        ],
        "main_score": 0.027479694298717414,
        "precision": 0.02175317079233243,
        "recall": 0.06126482213438735
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.005663185595546715,
        "hf_subset": "rus_Cyrl-kat_Geor",
        "languages": [
          "rus-Cyrl",
          "kat-Geor"
        ],
        "main_score": 0.005663185595546715,
        "precision": 0.004345048419750837,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.036561264822134384,
        "f1": 0.013815241631447164,
        "hf_subset": "rus_Cyrl-lua_Latn",
        "languages": [
          "rus-Cyrl",
          "lua-Latn"
        ],
        "main_score": 0.013815241631447164,
        "precision": 0.010731646424918471,
        "recall": 0.036561264822134384
      },
      {
        "accuracy": 0.04940711462450593,
        "f1": 0.02220175843170495,
        "hf_subset": "rus_Cyrl-nya_Latn",
        "languages": [
          "rus-Cyrl",
          "nya-Latn"
        ],
        "main_score": 0.02220175843170495,
        "precision": 0.018090304940090472,
        "recall": 0.04940711462450593
      },
      {
        "accuracy": 0.0741106719367589,
        "f1": 0.036633584689269416,
        "hf_subset": "rus_Cyrl-slv_Latn",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ],
        "main_score": 0.036633584689269416,
        "precision": 0.02932731095259021,
        "recall": 0.0741106719367589
      },
      {
        "accuracy": 0.08893280632411067,
        "f1": 0.04663685037505044,
        "hf_subset": "rus_Cyrl-tpi_Latn",
        "languages": [
          "rus-Cyrl",
          "tpi-Latn"
        ],
        "main_score": 0.04663685037505044,
        "precision": 0.038403340522928354,
        "recall": 0.08893280632411067
      },
      {
        "accuracy": 0.06818181818181818,
        "f1": 0.034563867721242376,
        "hf_subset": "rus_Cyrl-zsm_Latn",
        "languages": [
          "rus-Cyrl",
          "zsm-Latn"
        ],
        "main_score": 0.034563867721242376,
        "precision": 0.02859701411637008,
        "recall": 0.06818181818181818
      },
      {
        "accuracy": 0.039525691699604744,
        "f1": 0.01729828247814993,
        "hf_subset": "rus_Cyrl-ayr_Latn",
        "languages": [
          "rus-Cyrl",
          "ayr-Latn"
        ],
        "main_score": 0.01729828247814993,
        "precision": 0.014190132468729803,
        "recall": 0.039525691699604744
      },
      {
        "accuracy": 0.13043478260869565,
        "f1": 0.07840387797400239,
        "hf_subset": "rus_Cyrl-dan_Latn",
        "languages": [
          "rus-Cyrl",
          "dan-Latn"
        ],
        "main_score": 0.07840387797400239,
        "precision": 0.06586733219020768,
        "recall": 0.13043478260869565
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.0023182635050707895,
        "hf_subset": "rus_Cyrl-guj_Gujr",
        "languages": [
          "rus-Cyrl",
          "guj-Gujr"
        ],
        "main_score": 0.0023182635050707895,
        "precision": 0.0017358590288230008,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.11462450592885376,
        "f1": 0.06271266612175704,
        "hf_subset": "rus_Cyrl-kaz_Cyrl",
        "languages": [
          "rus-Cyrl",
          "kaz-Cyrl"
        ],
        "main_score": 0.06271266612175704,
        "precision": 0.052759677450293564,
        "recall": 0.11462450592885376
      },
      {
        "accuracy": 0.044466403162055336,
        "f1": 0.0204885950114052,
        "hf_subset": "rus_Cyrl-lug_Latn",
        "languages": [
          "rus-Cyrl",
          "lug-Latn"
        ],
        "main_score": 0.0204885950114052,
        "precision": 0.016785323640832895,
        "recall": 0.044466403162055336
      },
      {
        "accuracy": 0.16304347826086957,
        "f1": 0.10699380220131209,
        "hf_subset": "rus_Cyrl-oci_Latn",
        "languages": [
          "rus-Cyrl",
          "oci-Latn"
        ],
        "main_score": 0.10699380220131209,
        "precision": 0.09162384500081364,
        "recall": 0.16304347826086957
      },
      {
        "accuracy": 0.045454545454545456,
        "f1": 0.023575068066174786,
        "hf_subset": "rus_Cyrl-smo_Latn",
        "languages": [
          "rus-Cyrl",
          "smo-Latn"
        ],
        "main_score": 0.023575068066174786,
        "precision": 0.020263952818030055,
        "recall": 0.045454545454545456
      },
      {
        "accuracy": 0.05039525691699605,
        "f1": 0.022836785576946635,
        "hf_subset": "rus_Cyrl-tsn_Latn",
        "languages": [
          "rus-Cyrl",
          "tsn-Latn"
        ],
        "main_score": 0.022836785576946635,
        "precision": 0.018727868530240072,
        "recall": 0.05039525691699605
      },
      {
        "accuracy": 0.03557312252964427,
        "f1": 0.013042055089920708,
        "hf_subset": "rus_Cyrl-zul_Latn",
        "languages": [
          "rus-Cyrl",
          "zul-Latn"
        ],
        "main_score": 0.013042055089920708,
        "precision": 0.010336366912678993,
        "recall": 0.03557312252964427
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0020306821433544657,
        "hf_subset": "rus_Cyrl-azb_Arab",
        "languages": [
          "rus-Cyrl",
          "azb-Arab"
        ],
        "main_score": 0.0020306821433544657,
        "precision": 0.0016208869728538463,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.20454545454545456,
        "f1": 0.13644122675743228,
        "hf_subset": "rus_Cyrl-deu_Latn",
        "languages": [
          "rus-Cyrl",
          "deu-Latn"
        ],
        "main_score": 0.13644122675743228,
        "precision": 0.11802275635831785,
        "recall": 0.20454545454545456
      },
      {
        "accuracy": 0.05434782608695652,
        "f1": 0.03017674654648614,
        "hf_subset": "rus_Cyrl-hat_Latn",
        "languages": [
          "rus-Cyrl",
          "hat-Latn"
        ],
        "main_score": 0.03017674654648614,
        "precision": 0.025155115380499013,
        "recall": 0.05434782608695652
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.010183652086475542,
        "hf_subset": "rus_Cyrl-kbp_Latn",
        "languages": [
          "rus-Cyrl",
          "kbp-Latn"
        ],
        "main_score": 0.010183652086475542,
        "precision": 0.006869392336213118,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.039525691699604744,
        "f1": 0.01607667979914576,
        "hf_subset": "rus_Cyrl-luo_Latn",
        "languages": [
          "rus-Cyrl",
          "luo-Latn"
        ],
        "main_score": 0.01607667979914576,
        "precision": 0.012660021209814989,
        "recall": 0.039525691699604744
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.0021408937365294946,
        "hf_subset": "rus_Cyrl-ory_Orya",
        "languages": [
          "rus-Cyrl",
          "ory-Orya"
        ],
        "main_score": 0.0021408937365294946,
        "precision": 0.0013256906643353559,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.01269271792082166,
        "hf_subset": "rus_Cyrl-sna_Latn",
        "languages": [
          "rus-Cyrl",
          "sna-Latn"
        ],
        "main_score": 0.01269271792082166,
        "precision": 0.009699664530767108,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.04743083003952569,
        "f1": 0.018000878969450136,
        "hf_subset": "rus_Cyrl-tso_Latn",
        "languages": [
          "rus-Cyrl",
          "tso-Latn"
        ],
        "main_score": 0.018000878969450136,
        "precision": 0.013346044859065086,
        "recall": 0.04743083003952569
      },
      {
        "accuracy": 0.045454545454545456,
        "f1": 0.020424490160412232,
        "hf_subset": "rus_Cyrl-azj_Latn",
        "languages": [
          "rus-Cyrl",
          "azj-Latn"
        ],
        "main_score": 0.020424490160412232,
        "precision": 0.017385100376584455,
        "recall": 0.045454545454545456
      },
      {
        "accuracy": 0.058300395256917,
        "f1": 0.027747438111795794,
        "hf_subset": "rus_Cyrl-dik_Latn",
        "languages": [
          "rus-Cyrl",
          "dik-Latn"
        ],
        "main_score": 0.027747438111795794,
        "precision": 0.02205246865438694,
        "recall": 0.058300395256917
      },
      {
        "accuracy": 0.05138339920948617,
        "f1": 0.02315449161861222,
        "hf_subset": "rus_Cyrl-hau_Latn",
        "languages": [
          "rus-Cyrl",
          "hau-Latn"
        ],
        "main_score": 0.02315449161861222,
        "precision": 0.0183999197083564,
        "recall": 0.05138339920948617
      },
      {
        "accuracy": 0.08695652173913043,
        "f1": 0.04892676799427371,
        "hf_subset": "rus_Cyrl-kea_Latn",
        "languages": [
          "rus-Cyrl",
          "kea-Latn"
        ],
        "main_score": 0.04892676799427371,
        "precision": 0.04056727618765637,
        "recall": 0.08695652173913043
      },
      {
        "accuracy": 0.08794466403162056,
        "f1": 0.04804521656794383,
        "hf_subset": "rus_Cyrl-lus_Latn",
        "languages": [
          "rus-Cyrl",
          "lus-Latn"
        ],
        "main_score": 0.04804521656794383,
        "precision": 0.038957561981277394,
        "recall": 0.08794466403162056
      },
      {
        "accuracy": 0.1225296442687747,
        "f1": 0.07083855571170418,
        "hf_subset": "rus_Cyrl-pag_Latn",
        "languages": [
          "rus-Cyrl",
          "pag-Latn"
        ],
        "main_score": 0.07083855571170418,
        "precision": 0.05835799987232794,
        "recall": 0.1225296442687747
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.001286838255257266,
        "hf_subset": "rus_Cyrl-snd_Arab",
        "languages": [
          "rus-Cyrl",
          "snd-Arab"
        ],
        "main_score": 0.001286838255257266,
        "precision": 0.0008228141932140815,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.03359683794466403,
        "f1": 0.014286704431566129,
        "hf_subset": "rus_Cyrl-tuk_Latn",
        "languages": [
          "rus-Cyrl",
          "tuk-Latn"
        ],
        "main_score": 0.014286704431566129,
        "precision": 0.011042403903033442,
        "recall": 0.03359683794466403
      },
      {
        "accuracy": 0.15711462450592886,
        "f1": 0.09741169001235658,
        "hf_subset": "rus_Cyrl-bak_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bak-Cyrl"
        ],
        "main_score": 0.09741169001235658,
        "precision": 0.08365314133910741,
        "recall": 0.15711462450592886
      },
      {
        "accuracy": 0.0266798418972332,
        "f1": 0.007518661935188028,
        "hf_subset": "rus_Cyrl-dyu_Latn",
        "languages": [
          "rus-Cyrl",
          "dyu-Latn"
        ],
        "main_score": 0.007518661935188028,
        "precision": 0.00573193386068203,
        "recall": 0.0266798418972332
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.0023077359681054873,
        "hf_subset": "rus_Cyrl-heb_Hebr",
        "languages": [
          "rus-Cyrl",
          "heb-Hebr"
        ],
        "main_score": 0.0023077359681054873,
        "precision": 0.0017359400974512325,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.06719367588932806,
        "f1": 0.03505071205811885,
        "hf_subset": "rus_Cyrl-khk_Cyrl",
        "languages": [
          "rus-Cyrl",
          "khk-Cyrl"
        ],
        "main_score": 0.03505071205811885,
        "precision": 0.029625101812010172,
        "recall": 0.06719367588932806
      },
      {
        "accuracy": 0.038537549407114624,
        "f1": 0.016703225487026407,
        "hf_subset": "rus_Cyrl-lvs_Latn",
        "languages": [
          "rus-Cyrl",
          "lvs-Latn"
        ],
        "main_score": 0.016703225487026407,
        "precision": 0.012977311994110412,
        "recall": 0.038537549407114624
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.002051786302858793,
        "hf_subset": "rus_Cyrl-pan_Guru",
        "languages": [
          "rus-Cyrl",
          "pan-Guru"
        ],
        "main_score": 0.002051786302858793,
        "precision": 0.0015867696364221526,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.044466403162055336,
        "f1": 0.02002025934832259,
        "hf_subset": "rus_Cyrl-som_Latn",
        "languages": [
          "rus-Cyrl",
          "som-Latn"
        ],
        "main_score": 0.02002025934832259,
        "precision": 0.016332356620533114,
        "recall": 0.044466403162055336
      },
      {
        "accuracy": 0.04841897233201581,
        "f1": 0.024408276352098194,
        "hf_subset": "rus_Cyrl-tum_Latn",
        "languages": [
          "rus-Cyrl",
          "tum-Latn"
        ],
        "main_score": 0.024408276352098194,
        "precision": 0.020188868322579576,
        "recall": 0.04841897233201581
      },
      {
        "accuracy": 0.044466403162055336,
        "f1": 0.029023526490024616,
        "hf_subset": "taq_Latn-rus_Cyrl",
        "languages": [
          "taq-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.029023526490024616,
        "precision": 0.02665807234774465,
        "recall": 0.044466403162055336
      },
      {
        "accuracy": 0.07608695652173914,
        "f1": 0.060207736968296885,
        "hf_subset": "war_Latn-rus_Cyrl",
        "languages": [
          "war-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.060207736968296885,
        "precision": 0.05549086250667278,
        "recall": 0.07608695652173914
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0019823468076335506,
        "hf_subset": "arb_Arab-rus_Cyrl",
        "languages": [
          "arb-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0019823468076335506,
        "precision": 0.0019793250228032837,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.4209486166007905,
        "f1": 0.36665064679596815,
        "hf_subset": "bul_Cyrl-rus_Cyrl",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.36665064679596815,
        "precision": 0.3488568643209447,
        "recall": 0.4209486166007905
      },
      {
        "accuracy": 0.09189723320158102,
        "f1": 0.06964933273517179,
        "hf_subset": "fra_Latn-rus_Cyrl",
        "languages": [
          "fra-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.06964933273517179,
        "precision": 0.06459349282208636,
        "recall": 0.09189723320158102
      },
      {
        "accuracy": 0.07509881422924901,
        "f1": 0.04714624763355604,
        "hf_subset": "jpn_Jpan-rus_Cyrl",
        "languages": [
          "jpn-Jpan",
          "rus-Cyrl"
        ],
        "main_score": 0.04714624763355604,
        "precision": 0.04220962182029679,
        "recall": 0.07509881422924901
      },
      {
        "accuracy": 0.05731225296442688,
        "f1": 0.04021465446506157,
        "hf_subset": "lij_Latn-rus_Cyrl",
        "languages": [
          "lij-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.04021465446506157,
        "precision": 0.036069065181216046,
        "recall": 0.05731225296442688
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.003311612007264181,
        "hf_subset": "mya_Mymr-rus_Cyrl",
        "languages": [
          "mya-Mymr",
          "rus-Cyrl"
        ],
        "main_score": 0.003311612007264181,
        "precision": 0.002973409989220266,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.012735515171446353,
        "hf_subset": "sag_Latn-rus_Cyrl",
        "languages": [
          "sag-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.012735515171446353,
        "precision": 0.011229865874134649,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.004613700344072568,
        "hf_subset": "taq_Tfng-rus_Cyrl",
        "languages": [
          "taq-Tfng",
          "rus-Cyrl"
        ],
        "main_score": 0.004613700344072568,
        "precision": 0.004447826561454622,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.014185577355173777,
        "hf_subset": "wol_Latn-rus_Cyrl",
        "languages": [
          "wol-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.014185577355173777,
        "precision": 0.013081906016688625,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.00914418633832183,
        "hf_subset": "arb_Latn-rus_Cyrl",
        "languages": [
          "arb-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.00914418633832183,
        "precision": 0.007872577571238286,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.07905138339920949,
        "f1": 0.06115497749142098,
        "hf_subset": "cat_Latn-rus_Cyrl",
        "languages": [
          "cat-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.06115497749142098,
        "precision": 0.05748994624345675,
        "recall": 0.07905138339920949
      },
      {
        "accuracy": 0.05138339920948617,
        "f1": 0.035727832826360176,
        "hf_subset": "fur_Latn-rus_Cyrl",
        "languages": [
          "fur-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.035727832826360176,
        "precision": 0.03251325234042066,
        "recall": 0.05138339920948617
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.007197293654127807,
        "hf_subset": "kab_Latn-rus_Cyrl",
        "languages": [
          "kab-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.007197293654127807,
        "precision": 0.006193998484266938,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.06126482213438735,
        "f1": 0.04582464215458198,
        "hf_subset": "lim_Latn-rus_Cyrl",
        "languages": [
          "lim-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.04582464215458198,
        "precision": 0.04257214245803647,
        "recall": 0.06126482213438735
      },
      {
        "accuracy": 0.09189723320158102,
        "f1": 0.06844605292859712,
        "hf_subset": "nld_Latn-rus_Cyrl",
        "languages": [
          "nld-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.06844605292859712,
        "precision": 0.06253510616771882,
        "recall": 0.09189723320158102
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.00665136639891198,
        "hf_subset": "san_Deva-rus_Cyrl",
        "languages": [
          "san-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.00665136639891198,
        "precision": 0.006159420289855073,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.11166007905138339,
        "f1": 0.08512514741516718,
        "hf_subset": "tat_Cyrl-rus_Cyrl",
        "languages": [
          "tat-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.08512514741516718,
        "precision": 0.0790032042834156,
        "recall": 0.11166007905138339
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.017300616634417475,
        "hf_subset": "xho_Latn-rus_Cyrl",
        "languages": [
          "xho-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.017300616634417475,
        "precision": 0.015013689573451476,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0019822193735237214,
        "hf_subset": "ars_Arab-rus_Cyrl",
        "languages": [
          "ars-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0019822193735237214,
        "precision": 0.001979260917186533,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.058300395256917,
        "f1": 0.0437800524722009,
        "hf_subset": "ceb_Latn-rus_Cyrl",
        "languages": [
          "ceb-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0437800524722009,
        "precision": 0.04012908418199194,
        "recall": 0.058300395256917
      },
      {
        "accuracy": 0.0266798418972332,
        "f1": 0.020805052071036726,
        "hf_subset": "fuv_Latn-rus_Cyrl",
        "languages": [
          "fuv-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.020805052071036726,
        "precision": 0.019607726759406603,
        "recall": 0.0266798418972332
      },
      {
        "accuracy": 0.024703557312252964,
        "f1": 0.017208554124086457,
        "hf_subset": "kac_Latn-rus_Cyrl",
        "languages": [
          "kac-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.017208554124086457,
        "precision": 0.01589953832924723,
        "recall": 0.024703557312252964
      },
      {
        "accuracy": 0.040513833992094864,
        "f1": 0.02645982914084711,
        "hf_subset": "lin_Latn-rus_Cyrl",
        "languages": [
          "lin-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.02645982914084711,
        "precision": 0.023105283828666178,
        "recall": 0.040513833992094864
      },
      {
        "accuracy": 0.08102766798418973,
        "f1": 0.05627099947099935,
        "hf_subset": "nno_Latn-rus_Cyrl",
        "languages": [
          "nno-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.05627099947099935,
        "precision": 0.05053873924160132,
        "recall": 0.08102766798418973
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0006623810971637058,
        "hf_subset": "sat_Olck-rus_Cyrl",
        "languages": [
          "sat-Olck",
          "rus-Cyrl"
        ],
        "main_score": 0.0006623810971637058,
        "precision": 0.0004958842513688943,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.009628486680335085,
        "hf_subset": "tel_Telu-rus_Cyrl",
        "languages": [
          "tel-Telu",
          "rus-Cyrl"
        ],
        "main_score": 0.009628486680335085,
        "precision": 0.007992796123932168,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0010825301174657493,
        "hf_subset": "ydd_Hebr-rus_Cyrl",
        "languages": [
          "ydd-Hebr",
          "rus-Cyrl"
        ],
        "main_score": 0.0010825301174657493,
        "precision": 0.0010371467211935184,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0010057876905702993,
        "hf_subset": "ary_Arab-rus_Cyrl",
        "languages": [
          "ary-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0010057876905702993,
        "precision": 0.0009970444753053449,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.024192284676878787,
        "hf_subset": "ces_Latn-rus_Cyrl",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.024192284676878787,
        "precision": 0.021846328933794762,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0015263750192802997,
        "hf_subset": "gaz_Latn-rus_Cyrl",
        "languages": [
          "gaz-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0015263750192802997,
        "precision": 0.0013398856971635798,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.020988130983133478,
        "hf_subset": "kam_Latn-rus_Cyrl",
        "languages": [
          "kam-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.020988130983133478,
        "precision": 0.019188177406695785,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.025691699604743084,
        "f1": 0.016005363773029132,
        "hf_subset": "lit_Latn-rus_Cyrl",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.016005363773029132,
        "precision": 0.014298035448397766,
        "recall": 0.025691699604743084
      },
      {
        "accuracy": 0.06719367588932806,
        "f1": 0.04048359031847493,
        "hf_subset": "nob_Latn-rus_Cyrl",
        "languages": [
          "nob-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.04048359031847493,
        "precision": 0.034736625772371375,
        "recall": 0.06719367588932806
      },
      {
        "accuracy": 0.04940711462450593,
        "f1": 0.03295100285355158,
        "hf_subset": "scn_Latn-rus_Cyrl",
        "languages": [
          "scn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.03295100285355158,
        "precision": 0.029395110253386224,
        "recall": 0.04940711462450593
      },
      {
        "accuracy": 0.03162055335968379,
        "f1": 0.01957219442226938,
        "hf_subset": "tgk_Cyrl-rus_Cyrl",
        "languages": [
          "tgk-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.01957219442226938,
        "precision": 0.01744480507686301,
        "recall": 0.03162055335968379
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.019750583189318365,
        "hf_subset": "yor_Latn-rus_Cyrl",
        "languages": [
          "yor-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.019750583189318365,
        "precision": 0.01782864170328726,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 2.2715914769887784e-05,
        "hf_subset": "arz_Arab-rus_Cyrl",
        "languages": [
          "arz-Arab",
          "rus-Cyrl"
        ],
        "main_score": 2.2715914769887784e-05,
        "precision": 1.1490026656861844e-05,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.014835785743714133,
        "hf_subset": "cjk_Latn-rus_Cyrl",
        "languages": [
          "cjk-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.014835785743714133,
        "precision": 0.014155460773488057,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.009210022367251892,
        "hf_subset": "gla_Latn-rus_Cyrl",
        "languages": [
          "gla-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.009210022367251892,
        "precision": 0.007507342361044789,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.007153777313744499,
        "hf_subset": "kan_Knda-rus_Cyrl",
        "languages": [
          "kan-Knda",
          "rus-Cyrl"
        ],
        "main_score": 0.007153777313744499,
        "precision": 0.006508387260341725,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.05434782608695652,
        "f1": 0.03984215557105583,
        "hf_subset": "lmo_Latn-rus_Cyrl",
        "languages": [
          "lmo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.03984215557105583,
        "precision": 0.036298468090516144,
        "recall": 0.05434782608695652
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.005748965871704709,
        "hf_subset": "npi_Deva-rus_Cyrl",
        "languages": [
          "npi-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.005748965871704709,
        "precision": 0.005230885792865441,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.05928853754940711,
        "f1": 0.04188374782570354,
        "hf_subset": "shn_Mymr-rus_Cyrl",
        "languages": [
          "shn-Mymr",
          "rus-Cyrl"
        ],
        "main_score": 0.04188374782570354,
        "precision": 0.038070082091821215,
        "recall": 0.05928853754940711
      },
      {
        "accuracy": 0.04940711462450593,
        "f1": 0.0332203906322951,
        "hf_subset": "tgl_Latn-rus_Cyrl",
        "languages": [
          "tgl-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0332203906322951,
        "precision": 0.029477990445844284,
        "recall": 0.04940711462450593
      },
      {
        "accuracy": 0.17588932806324112,
        "f1": 0.12838907731005414,
        "hf_subset": "yue_Hant-rus_Cyrl",
        "languages": [
          "yue-Hant",
          "rus-Cyrl"
        ],
        "main_score": 0.12838907731005414,
        "precision": 0.11695284731215669,
        "recall": 0.17588932806324112
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.004120690601668863,
        "hf_subset": "asm_Beng-rus_Cyrl",
        "languages": [
          "asm-Beng",
          "rus-Cyrl"
        ],
        "main_score": 0.004120690601668863,
        "precision": 0.0037895972962135537,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0015292330300691506,
        "hf_subset": "ckb_Arab-rus_Cyrl",
        "languages": [
          "ckb-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0015292330300691506,
        "precision": 0.0013414795337237737,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.011858686871688744,
        "hf_subset": "gle_Latn-rus_Cyrl",
        "languages": [
          "gle-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.011858686871688744,
        "precision": 0.010699056503295223,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0013276578493969797,
        "hf_subset": "kas_Arab-rus_Cyrl",
        "languages": [
          "kas-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0013276578493969797,
        "precision": 0.0009932358094617171,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.016162471696068534,
        "hf_subset": "ltg_Latn-rus_Cyrl",
        "languages": [
          "ltg-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.016162471696068534,
        "precision": 0.015031526444569922,
        "recall": 0.022727272727272728
      },
      {
        "accuracy": 0.043478260869565216,
        "f1": 0.029238714266577256,
        "hf_subset": "nso_Latn-rus_Cyrl",
        "languages": [
          "nso-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.029238714266577256,
        "precision": 0.026508353755570348,
        "recall": 0.043478260869565216
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.00578518767695456,
        "hf_subset": "sin_Sinh-rus_Cyrl",
        "languages": [
          "sin-Sinh",
          "rus-Cyrl"
        ],
        "main_score": 0.00578518767695456,
        "precision": 0.005280717412554719,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.010084183687650941,
        "hf_subset": "tha_Thai-rus_Cyrl",
        "languages": [
          "tha-Thai",
          "rus-Cyrl"
        ],
        "main_score": 0.010084183687650941,
        "precision": 0.008741993253467131,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.16897233201581027,
        "f1": 0.12425931336081912,
        "hf_subset": "zho_Hans-rus_Cyrl",
        "languages": [
          "zho-Hans",
          "rus-Cyrl"
        ],
        "main_score": 0.12425931336081912,
        "precision": 0.11394476114289573,
        "recall": 0.16897233201581027
      },
      {
        "accuracy": 0.06225296442687747,
        "f1": 0.047127378129063924,
        "hf_subset": "ast_Latn-rus_Cyrl",
        "languages": [
          "ast-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.047127378129063924,
        "precision": 0.04358742628554185,
        "recall": 0.06225296442687747
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.0147692935736414,
        "hf_subset": "crh_Latn-rus_Cyrl",
        "languages": [
          "crh-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0147692935736414,
        "precision": 0.01355613117191567,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.06620553359683795,
        "f1": 0.04445497914904638,
        "hf_subset": "glg_Latn-rus_Cyrl",
        "languages": [
          "glg-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.04445497914904638,
        "precision": 0.04001474375778484,
        "recall": 0.06620553359683795
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.012178650934273123,
        "hf_subset": "kas_Deva-rus_Cyrl",
        "languages": [
          "kas-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.012178650934273123,
        "precision": 0.010748146510496865,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.05928853754940711,
        "f1": 0.04260746607570184,
        "hf_subset": "ltz_Latn-rus_Cyrl",
        "languages": [
          "ltz-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.04260746607570184,
        "precision": 0.03907172890231451,
        "recall": 0.05928853754940711
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.008577021540966397,
        "hf_subset": "nus_Latn-rus_Cyrl",
        "languages": [
          "nus-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.008577021540966397,
        "precision": 0.007975258397451961,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.02130686849425988,
        "hf_subset": "slk_Latn-rus_Cyrl",
        "languages": [
          "slk-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.02130686849425988,
        "precision": 0.019206978434987,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0026388687140516255,
        "hf_subset": "tir_Ethi-rus_Cyrl",
        "languages": [
          "tir-Ethi",
          "rus-Cyrl"
        ],
        "main_score": 0.0026388687140516255,
        "precision": 0.0024722707356681067,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.17885375494071146,
        "f1": 0.12808775962314306,
        "hf_subset": "zho_Hant-rus_Cyrl",
        "languages": [
          "zho-Hant",
          "rus-Cyrl"
        ],
        "main_score": 0.12808775962314306,
        "precision": 0.11478904875825247,
        "recall": 0.17885375494071146
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0014822134387351778,
        "hf_subset": "awa_Deva-rus_Cyrl",
        "languages": [
          "awa-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0014822134387351778,
        "precision": 0.0013175230566534913,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.015376868319535586,
        "hf_subset": "cym_Latn-rus_Cyrl",
        "languages": [
          "cym-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.015376868319535586,
        "precision": 0.013606311508560643,
        "recall": 0.022727272727272728
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.018964342497526737,
        "hf_subset": "grn_Latn-rus_Cyrl",
        "languages": [
          "grn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.018964342497526737,
        "precision": 0.017248241755470798,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0024287010210032305,
        "hf_subset": "kat_Geor-rus_Cyrl",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ],
        "main_score": 0.0024287010210032305,
        "precision": 0.0019789918241377444,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.01718241425610962,
        "hf_subset": "lua_Latn-rus_Cyrl",
        "languages": [
          "lua-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01718241425610962,
        "precision": 0.015033406923854081,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.020758611088302938,
        "hf_subset": "nya_Latn-rus_Cyrl",
        "languages": [
          "nya-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.020758611088302938,
        "precision": 0.01871518814538251,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.036561264822134384,
        "f1": 0.023806765269101762,
        "hf_subset": "slv_Latn-rus_Cyrl",
        "languages": [
          "slv-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.023806765269101762,
        "precision": 0.022107381735337082,
        "recall": 0.036561264822134384
      },
      {
        "accuracy": 0.07312252964426877,
        "f1": 0.05031206616735419,
        "hf_subset": "tpi_Latn-rus_Cyrl",
        "languages": [
          "tpi-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.05031206616735419,
        "precision": 0.045547230564785234,
        "recall": 0.07312252964426877
      },
      {
        "accuracy": 0.05138339920948617,
        "f1": 0.033933343090503915,
        "hf_subset": "zsm_Latn-rus_Cyrl",
        "languages": [
          "zsm-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.033933343090503915,
        "precision": 0.030483954980178862,
        "recall": 0.05138339920948617
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.01297557022589445,
        "hf_subset": "ayr_Latn-rus_Cyrl",
        "languages": [
          "ayr-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01297557022589445,
        "precision": 0.011831639885257083,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.08102766798418973,
        "f1": 0.05726715056426671,
        "hf_subset": "dan_Latn-rus_Cyrl",
        "languages": [
          "dan-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.05726715056426671,
        "precision": 0.05200301427995569,
        "recall": 0.08102766798418973
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0038677711434418186,
        "hf_subset": "guj_Gujr-rus_Cyrl",
        "languages": [
          "guj-Gujr",
          "rus-Cyrl"
        ],
        "main_score": 0.0038677711434418186,
        "precision": 0.003053830227743271,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.07608695652173914,
        "f1": 0.05605330708267391,
        "hf_subset": "kaz_Cyrl-rus_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.05605330708267391,
        "precision": 0.051601937936511286,
        "recall": 0.07608695652173914
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.01466873435576584,
        "hf_subset": "lug_Latn-rus_Cyrl",
        "languages": [
          "lug-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01466873435576584,
        "precision": 0.013239715077950373,
        "recall": 0.022727272727272728
      },
      {
        "accuracy": 0.0741106719367589,
        "f1": 0.053471601635525605,
        "hf_subset": "oci_Latn-rus_Cyrl",
        "languages": [
          "oci-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.053471601635525605,
        "precision": 0.04865978889229296,
        "recall": 0.0741106719367589
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.01952340732186534,
        "hf_subset": "smo_Latn-rus_Cyrl",
        "languages": [
          "smo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01952340732186534,
        "precision": 0.01811244020904565,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.03359683794466403,
        "f1": 0.023635454513902778,
        "hf_subset": "tsn_Latn-rus_Cyrl",
        "languages": [
          "tsn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.023635454513902778,
        "precision": 0.021919616808606133,
        "recall": 0.03359683794466403
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.012065758986048841,
        "hf_subset": "zul_Latn-rus_Cyrl",
        "languages": [
          "zul-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.012065758986048841,
        "precision": 0.011089650573529538,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 0.0009881422924901185,
        "hf_subset": "azb_Arab-rus_Cyrl",
        "languages": [
          "azb-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0009881422924901185,
        "precision": 0.0009881422924901185,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.1373517786561265,
        "f1": 0.10354017949010119,
        "hf_subset": "deu_Latn-rus_Cyrl",
        "languages": [
          "deu-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.10354017949010119,
        "precision": 0.09534133679716703,
        "recall": 0.1373517786561265
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.02670855485927627,
        "hf_subset": "hat_Latn-rus_Cyrl",
        "languages": [
          "hat-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.02670855485927627,
        "precision": 0.02397742573929956,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.012581323730512189,
        "hf_subset": "kbp_Latn-rus_Cyrl",
        "languages": [
          "kbp-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.012581323730512189,
        "precision": 0.011510780426076285,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.020198954536899204,
        "hf_subset": "luo_Latn-rus_Cyrl",
        "languages": [
          "luo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.020198954536899204,
        "precision": 0.018566589025937667,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.00444990690229641,
        "hf_subset": "ory_Orya-rus_Cyrl",
        "languages": [
          "ory-Orya",
          "rus-Cyrl"
        ],
        "main_score": 0.00444990690229641,
        "precision": 0.003907150772252989,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.00925694397728617,
        "hf_subset": "sna_Latn-rus_Cyrl",
        "languages": [
          "sna-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.00925694397728617,
        "precision": 0.008595569256359287,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.023731402189145556,
        "hf_subset": "tso_Latn-rus_Cyrl",
        "languages": [
          "tso-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.023731402189145556,
        "precision": 0.021890980487818432,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.010201520062071858,
        "hf_subset": "azj_Latn-rus_Cyrl",
        "languages": [
          "azj-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.010201520062071858,
        "precision": 0.008904908021040743,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.039525691699604744,
        "f1": 0.020366797377452128,
        "hf_subset": "dik_Latn-rus_Cyrl",
        "languages": [
          "dik-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.020366797377452128,
        "precision": 0.015963466906972944,
        "recall": 0.039525691699604744
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.01985185257046346,
        "hf_subset": "hau_Latn-rus_Cyrl",
        "languages": [
          "hau-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01985185257046346,
        "precision": 0.018051944798702157,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.043478260869565216,
        "f1": 0.026520090224414428,
        "hf_subset": "kea_Latn-rus_Cyrl",
        "languages": [
          "kea-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.026520090224414428,
        "precision": 0.023733713883878422,
        "recall": 0.043478260869565216
      },
      {
        "accuracy": 0.06818181818181818,
        "f1": 0.05086437275668911,
        "hf_subset": "lus_Latn-rus_Cyrl",
        "languages": [
          "lus-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.05086437275668911,
        "precision": 0.04776564565851792,
        "recall": 0.06818181818181818
      },
      {
        "accuracy": 0.1007905138339921,
        "f1": 0.07704592549054909,
        "hf_subset": "pag_Latn-rus_Cyrl",
        "languages": [
          "pag-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.07704592549054909,
        "precision": 0.07061153917190303,
        "recall": 0.1007905138339921
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.003994412777857594,
        "hf_subset": "snd_Arab-rus_Cyrl",
        "languages": [
          "snd-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.003994412777857594,
        "precision": 0.0039736884519123794,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.006049396043002181,
        "hf_subset": "tuk_Latn-rus_Cyrl",
        "languages": [
          "tuk-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.006049396043002181,
        "precision": 0.0053386938072689264,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.10869565217391304,
        "f1": 0.08584857544762182,
        "hf_subset": "bak_Cyrl-rus_Cyrl",
        "languages": [
          "bak-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.08584857544762182,
        "precision": 0.08045614588351743,
        "recall": 0.10869565217391304
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.009737756846915035,
        "hf_subset": "dyu_Latn-rus_Cyrl",
        "languages": [
          "dyu-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.009737756846915035,
        "precision": 0.008807087836158344,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0023234246274268125,
        "hf_subset": "heb_Hebr-rus_Cyrl",
        "languages": [
          "heb-Hebr",
          "rus-Cyrl"
        ],
        "main_score": 0.0023234246274268125,
        "precision": 0.002166325612932433,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.023713257483691744,
        "hf_subset": "khk_Cyrl-rus_Cyrl",
        "languages": [
          "khk-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.023713257483691744,
        "precision": 0.02071959927691153,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.007208480294673509,
        "hf_subset": "lvs_Latn-rus_Cyrl",
        "languages": [
          "lvs-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.007208480294673509,
        "precision": 0.005975812375913406,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.00708520921843405,
        "hf_subset": "pan_Guru-rus_Cyrl",
        "languages": [
          "pan-Guru",
          "rus-Cyrl"
        ],
        "main_score": 0.00708520921843405,
        "precision": 0.006457627517410126,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.01246596763533063,
        "hf_subset": "som_Latn-rus_Cyrl",
        "languages": [
          "som-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01246596763533063,
        "precision": 0.011143621420301262,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.01796116563693068,
        "hf_subset": "tum_Latn-rus_Cyrl",
        "languages": [
          "tum-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01796116563693068,
        "precision": 0.01651995332600467,
        "recall": 0.02865612648221344
      }
    ]
  },
  "task_name": "FloresBitextMining"
}