{
  "dataset_revision": "a74d7350ea12af010cfb1c21e34f1f81fd2e615b",
  "evaluation_time": 9.524729490280151,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.89",
  "scores": {
    "test": [
      {
        "accuracy": 0.628921568627451,
        "f1": 0.6159169904490983,
        "f1_weighted": 0.6265912681296688,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.628921568627451,
        "scores_per_experiment": [
          {
            "accuracy": 0.6617647058823529,
            "f1": 0.649709118272333,
            "f1_weighted": 0.6610531205416992
          },
          {
            "accuracy": 0.6029411764705882,
            "f1": 0.5926768464690884,
            "f1_weighted": 0.6024180506282182
          },
          {
            "accuracy": 0.6127450980392157,
            "f1": 0.6033025321676259,
            "f1_weighted": 0.6142765936160106
          },
          {
            "accuracy": 0.5686274509803921,
            "f1": 0.5733102907690834,
            "f1_weighted": 0.5614142270131112
          },
          {
            "accuracy": 0.6666666666666666,
            "f1": 0.6639795190305878,
            "f1_weighted": 0.6682864871608555
          },
          {
            "accuracy": 0.6666666666666666,
            "f1": 0.6419602690105212,
            "f1_weighted": 0.6648399553521475
          },
          {
            "accuracy": 0.6568627450980392,
            "f1": 0.6375118418535859,
            "f1_weighted": 0.6621685912264631
          },
          {
            "accuracy": 0.6176470588235294,
            "f1": 0.5848440674971288,
            "f1_weighted": 0.6039092909891228
          },
          {
            "accuracy": 0.5882352941176471,
            "f1": 0.5741296614054089,
            "f1_weighted": 0.5816182316695313
          },
          {
            "accuracy": 0.6470588235294118,
            "f1": 0.6377457580156202,
            "f1_weighted": 0.6459281330995272
          }
        ]
      }
    ],
    "train": [
      {
        "accuracy": 0.6449358059914408,
        "f1": 0.6391477266661123,
        "f1_weighted": 0.6465437873726858,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.6449358059914408,
        "scores_per_experiment": [
          {
            "accuracy": 0.6633380884450785,
            "f1": 0.6533804534868717,
            "f1_weighted": 0.6653008953110476
          },
          {
            "accuracy": 0.6419400855920114,
            "f1": 0.6438149627188927,
            "f1_weighted": 0.647458327011264
          },
          {
            "accuracy": 0.6291012838801712,
            "f1": 0.6247967908443607,
            "f1_weighted": 0.628056723389339
          },
          {
            "accuracy": 0.6191155492154066,
            "f1": 0.6143472810725582,
            "f1_weighted": 0.6207381387742289
          },
          {
            "accuracy": 0.6990014265335235,
            "f1": 0.6960814613893466,
            "f1_weighted": 0.699592221974384
          },
          {
            "accuracy": 0.6348074179743224,
            "f1": 0.6245714107703824,
            "f1_weighted": 0.637577677367599
          },
          {
            "accuracy": 0.6462196861626248,
            "f1": 0.6378637311687757,
            "f1_weighted": 0.6522358122380303
          },
          {
            "accuracy": 0.6619115549215406,
            "f1": 0.6539414790846878,
            "f1_weighted": 0.6707314695262635
          },
          {
            "accuracy": 0.5820256776034237,
            "f1": 0.577329144652479,
            "f1_weighted": 0.5716539020106568
          },
          {
            "accuracy": 0.6718972895863052,
            "f1": 0.6653505514727673,
            "f1_weighted": 0.6720927061240443
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5979797979797981,
        "f1": 0.591471961114528,
        "f1_weighted": 0.604319389404907,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.5979797979797981,
        "scores_per_experiment": [
          {
            "accuracy": 0.5555555555555556,
            "f1": 0.557555111562619,
            "f1_weighted": 0.557090171344097
          },
          {
            "accuracy": 0.5959595959595959,
            "f1": 0.6072583705666413,
            "f1_weighted": 0.6052433617983857
          },
          {
            "accuracy": 0.5757575757575758,
            "f1": 0.586036770949614,
            "f1_weighted": 0.5726936769012505
          },
          {
            "accuracy": 0.5959595959595959,
            "f1": 0.5993262803607632,
            "f1_weighted": 0.6077382890340048
          },
          {
            "accuracy": 0.6060606060606061,
            "f1": 0.6026170930518757,
            "f1_weighted": 0.6206164030669961
          },
          {
            "accuracy": 0.6363636363636364,
            "f1": 0.6073893525021345,
            "f1_weighted": 0.640100211679159
          },
          {
            "accuracy": 0.6767676767676768,
            "f1": 0.6702723620016853,
            "f1_weighted": 0.68679641950104
          },
          {
            "accuracy": 0.5757575757575758,
            "f1": 0.5709646482044638,
            "f1_weighted": 0.5930127318129744
          },
          {
            "accuracy": 0.5555555555555556,
            "f1": 0.5224135970177545,
            "f1_weighted": 0.5512409663493254
          },
          {
            "accuracy": 0.6060606060606061,
            "f1": 0.5908860249277288,
            "f1_weighted": 0.6086616625618363
          }
        ]
      }
    ]
  },
  "task_name": "SIB200Classification"
}