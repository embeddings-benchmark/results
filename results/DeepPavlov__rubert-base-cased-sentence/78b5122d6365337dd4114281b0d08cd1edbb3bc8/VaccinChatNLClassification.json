{
  "dataset_revision": "bd27d0058bea2ad52470d9072a3b5da6b97c1ac3",
  "task_name": "VaccinChatNLClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.276068,
            "f1": 0.311218,
            "f1_weighted": 0.27096,
            "precision": 0.301648,
            "precision_weighted": 0.368119,
            "recall": 0.439976,
            "recall_weighted": 0.276068,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.281197,
            "f1": 0.316229,
            "f1_weighted": 0.280588,
            "precision": 0.319956,
            "precision_weighted": 0.364471,
            "recall": 0.415403,
            "recall_weighted": 0.281197,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.291453,
            "f1": 0.331543,
            "f1_weighted": 0.283313,
            "precision": 0.31666,
            "precision_weighted": 0.367543,
            "recall": 0.458224,
            "recall_weighted": 0.291453,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.288889,
            "f1": 0.319241,
            "f1_weighted": 0.285703,
            "precision": 0.306789,
            "precision_weighted": 0.369381,
            "recall": 0.429616,
            "recall_weighted": 0.288889,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.276923,
            "f1": 0.306882,
            "f1_weighted": 0.272523,
            "precision": 0.298509,
            "precision_weighted": 0.381988,
            "recall": 0.426944,
            "recall_weighted": 0.276923,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.291453,
            "f1": 0.327646,
            "f1_weighted": 0.291057,
            "precision": 0.329738,
            "precision_weighted": 0.391765,
            "recall": 0.433529,
            "recall_weighted": 0.291453,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.313675,
            "f1": 0.33685,
            "f1_weighted": 0.307994,
            "precision": 0.332642,
            "precision_weighted": 0.410405,
            "recall": 0.454327,
            "recall_weighted": 0.313675,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.296581,
            "f1": 0.317363,
            "f1_weighted": 0.292626,
            "precision": 0.294231,
            "precision_weighted": 0.383887,
            "recall": 0.440022,
            "recall_weighted": 0.296581,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.306838,
            "f1": 0.337962,
            "f1_weighted": 0.292006,
            "precision": 0.318405,
            "precision_weighted": 0.367848,
            "recall": 0.480798,
            "recall_weighted": 0.306838,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.297436,
            "f1": 0.289538,
            "f1_weighted": 0.298426,
            "precision": 0.277011,
            "precision_weighted": 0.388295,
            "recall": 0.400417,
            "recall_weighted": 0.297436,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.292051,
        "f1": 0.319447,
        "f1_weighted": 0.28752,
        "precision": 0.309559,
        "precision_weighted": 0.37937,
        "recall": 0.437926,
        "recall_weighted": 0.292051,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.319447,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 50.505664110183716,
  "kg_co2_emissions": null
}