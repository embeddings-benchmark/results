{
  "dataset_revision": "aa56583bf2bc52b0565770607d6fc3faebecf9e2",
  "evaluation_time": 62.99775552749634,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.89",
  "scores": {
    "test": [
      {
        "accuracy": 0.856787109375,
        "f1": 0.8538042016659488,
        "f1_weighted": 0.8538200204877902,
        "hf_subset": "default",
        "languages": [
          "ara-Arab",
          "bul-Cyrl",
          "deu-Latn",
          "ell-Grek",
          "eng-Latn",
          "spa-Latn",
          "fra-Latn",
          "hin-Deva",
          "ita-Latn",
          "jpn-Jpan",
          "nld-Latn",
          "pol-Latn",
          "por-Latn",
          "rus-Cyrl",
          "swa-Latn",
          "tha-Thai",
          "tur-Latn",
          "urd-Arab",
          "vie-Latn",
          "cmn-Hans"
        ],
        "main_score": 0.856787109375,
        "scores_per_experiment": [
          {
            "accuracy": 0.845703125,
            "f1": 0.8372259580160584,
            "f1_weighted": 0.8371661784658377
          },
          {
            "accuracy": 0.81494140625,
            "f1": 0.8091529724649803,
            "f1_weighted": 0.8091000577489829
          },
          {
            "accuracy": 0.86572265625,
            "f1": 0.8654791731126998,
            "f1_weighted": 0.8655271746073463
          },
          {
            "accuracy": 0.84033203125,
            "f1": 0.8361286242694028,
            "f1_weighted": 0.8360540980202491
          },
          {
            "accuracy": 0.86572265625,
            "f1": 0.8651755615332755,
            "f1_weighted": 0.8652081171545245
          },
          {
            "accuracy": 0.82470703125,
            "f1": 0.8168944125059406,
            "f1_weighted": 0.8168223650156015
          },
          {
            "accuracy": 0.87109375,
            "f1": 0.8695454749247027,
            "f1_weighted": 0.8696379762238956
          },
          {
            "accuracy": 0.86767578125,
            "f1": 0.8662339618248239,
            "f1_weighted": 0.8663697403891859
          },
          {
            "accuracy": 0.880859375,
            "f1": 0.8819221564920982,
            "f1_weighted": 0.8820031463511822
          },
          {
            "accuracy": 0.89111328125,
            "f1": 0.8902837215155058,
            "f1_weighted": 0.890311350901096
          }
        ]
      }
    ]
  },
  "task_name": "LanguageClassification"
}