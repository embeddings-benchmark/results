{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.686621,
        "f1": 0.684654,
        "f1_weighted": 0.684702,
        "ap": 0.626685,
        "ap_weighted": 0.626685,
        "scores_per_experiment": [
          {
            "accuracy": 0.682617,
            "f1": 0.671053,
            "f1_weighted": 0.671233,
            "ap": 0.616591,
            "ap_weighted": 0.616591
          },
          {
            "accuracy": 0.702637,
            "f1": 0.701415,
            "f1_weighted": 0.701471,
            "ap": 0.639019,
            "ap_weighted": 0.639019
          },
          {
            "accuracy": 0.694336,
            "f1": 0.694294,
            "f1_weighted": 0.694304,
            "ap": 0.635506,
            "ap_weighted": 0.635506
          },
          {
            "accuracy": 0.683105,
            "f1": 0.68227,
            "f1_weighted": 0.682318,
            "ap": 0.623298,
            "ap_weighted": 0.623298
          },
          {
            "accuracy": 0.675781,
            "f1": 0.675737,
            "f1_weighted": 0.675748,
            "ap": 0.61952,
            "ap_weighted": 0.61952
          },
          {
            "accuracy": 0.67627,
            "f1": 0.676036,
            "f1_weighted": 0.676061,
            "ap": 0.619021,
            "ap_weighted": 0.619021
          },
          {
            "accuracy": 0.686035,
            "f1": 0.685468,
            "f1_weighted": 0.685507,
            "ap": 0.626273,
            "ap_weighted": 0.626273
          },
          {
            "accuracy": 0.687012,
            "f1": 0.68694,
            "f1_weighted": 0.686926,
            "ap": 0.631083,
            "ap_weighted": 0.631083
          },
          {
            "accuracy": 0.676758,
            "f1": 0.671708,
            "f1_weighted": 0.671827,
            "ap": 0.614582,
            "ap_weighted": 0.614582
          },
          {
            "accuracy": 0.70166,
            "f1": 0.701616,
            "f1_weighted": 0.701626,
            "ap": 0.641962,
            "ap_weighted": 0.641962
          }
        ],
        "main_score": 0.686621,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.694531,
        "f1": 0.692274,
        "f1_weighted": 0.692313,
        "ap": 0.632078,
        "ap_weighted": 0.632078,
        "scores_per_experiment": [
          {
            "accuracy": 0.690918,
            "f1": 0.679958,
            "f1_weighted": 0.680073,
            "ap": 0.622745,
            "ap_weighted": 0.622745
          },
          {
            "accuracy": 0.711426,
            "f1": 0.70954,
            "f1_weighted": 0.709586,
            "ap": 0.645042,
            "ap_weighted": 0.645042
          },
          {
            "accuracy": 0.695801,
            "f1": 0.69564,
            "f1_weighted": 0.695654,
            "ap": 0.635492,
            "ap_weighted": 0.635492
          },
          {
            "accuracy": 0.693848,
            "f1": 0.692262,
            "f1_weighted": 0.692305,
            "ap": 0.630636,
            "ap_weighted": 0.630636
          },
          {
            "accuracy": 0.696777,
            "f1": 0.696699,
            "f1_weighted": 0.696708,
            "ap": 0.636849,
            "ap_weighted": 0.636849
          },
          {
            "accuracy": 0.684082,
            "f1": 0.683611,
            "f1_weighted": 0.683635,
            "ap": 0.624411,
            "ap_weighted": 0.624411
          },
          {
            "accuracy": 0.685547,
            "f1": 0.68467,
            "f1_weighted": 0.684702,
            "ap": 0.624803,
            "ap_weighted": 0.624803
          },
          {
            "accuracy": 0.697266,
            "f1": 0.697242,
            "f1_weighted": 0.697247,
            "ap": 0.637836,
            "ap_weighted": 0.637836
          },
          {
            "accuracy": 0.687012,
            "f1": 0.680653,
            "f1_weighted": 0.680741,
            "ap": 0.62153,
            "ap_weighted": 0.62153
          },
          {
            "accuracy": 0.702637,
            "f1": 0.702466,
            "f1_weighted": 0.70248,
            "ap": 0.641438,
            "ap_weighted": 0.641438
          }
        ],
        "main_score": 0.694531,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 26.030032634735107,
  "kg_co2_emissions": 0.0014558063258192215
}