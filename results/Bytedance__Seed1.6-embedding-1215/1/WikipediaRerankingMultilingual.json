{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.38.29",
  "scores": {
    "test": [
      {
        "map": 0.900092,
        "mrr": 0.900092,
        "nAUC_map_max": 0.61561,
        "nAUC_map_std": 0.483858,
        "nAUC_map_diff1": 0.840916,
        "nAUC_mrr_max": 0.61561,
        "nAUC_mrr_std": 0.483858,
        "nAUC_mrr_diff1": 0.840916,
        "main_score": 0.900092,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.858435,
        "mrr": 0.858435,
        "nAUC_map_max": 0.491278,
        "nAUC_map_std": 0.34631,
        "nAUC_map_diff1": 0.76838,
        "nAUC_mrr_max": 0.491278,
        "nAUC_mrr_std": 0.34631,
        "nAUC_mrr_diff1": 0.76838,
        "main_score": 0.858435,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.917619,
        "mrr": 0.917619,
        "nAUC_map_max": 0.584672,
        "nAUC_map_std": 0.451151,
        "nAUC_map_diff1": 0.879723,
        "nAUC_mrr_max": 0.584672,
        "nAUC_mrr_std": 0.451151,
        "nAUC_mrr_diff1": 0.879723,
        "main_score": 0.917619,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.917425,
        "mrr": 0.91787,
        "nAUC_map_max": 0.532969,
        "nAUC_map_std": 0.40744,
        "nAUC_map_diff1": 0.884103,
        "nAUC_mrr_max": 0.538783,
        "nAUC_mrr_std": 0.410441,
        "nAUC_mrr_diff1": 0.882975,
        "main_score": 0.917425,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.921752,
        "mrr": 0.921752,
        "nAUC_map_max": 0.618823,
        "nAUC_map_std": 0.392573,
        "nAUC_map_diff1": 0.83816,
        "nAUC_mrr_max": 0.618823,
        "nAUC_mrr_std": 0.392573,
        "nAUC_mrr_diff1": 0.83816,
        "main_score": 0.921752,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.940182,
        "mrr": 0.940182,
        "nAUC_map_max": 0.590173,
        "nAUC_map_std": 0.524727,
        "nAUC_map_diff1": 0.910835,
        "nAUC_mrr_max": 0.590173,
        "nAUC_mrr_std": 0.524727,
        "nAUC_mrr_diff1": 0.910835,
        "main_score": 0.940182,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.893036,
        "mrr": 0.893036,
        "nAUC_map_max": 0.600214,
        "nAUC_map_std": 0.389424,
        "nAUC_map_diff1": 0.828529,
        "nAUC_mrr_max": 0.600214,
        "nAUC_mrr_std": 0.389424,
        "nAUC_mrr_diff1": 0.828529,
        "main_score": 0.893036,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.916879,
        "mrr": 0.916879,
        "nAUC_map_max": 0.514305,
        "nAUC_map_std": 0.323298,
        "nAUC_map_diff1": 0.838643,
        "nAUC_mrr_max": 0.514305,
        "nAUC_mrr_std": 0.323298,
        "nAUC_mrr_diff1": 0.838643,
        "main_score": 0.916879,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.879038,
        "mrr": 0.880047,
        "nAUC_map_max": 0.509129,
        "nAUC_map_std": 0.314063,
        "nAUC_map_diff1": 0.822411,
        "nAUC_mrr_max": 0.516009,
        "nAUC_mrr_std": 0.321945,
        "nAUC_mrr_diff1": 0.81991,
        "main_score": 0.879038,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.925827,
        "mrr": 0.925827,
        "nAUC_map_max": 0.669785,
        "nAUC_map_std": 0.372076,
        "nAUC_map_diff1": 0.879227,
        "nAUC_mrr_max": 0.669785,
        "nAUC_mrr_std": 0.372076,
        "nAUC_mrr_diff1": 0.879227,
        "main_score": 0.925827,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.916872,
        "mrr": 0.917206,
        "nAUC_map_max": 0.544541,
        "nAUC_map_std": 0.343244,
        "nAUC_map_diff1": 0.825133,
        "nAUC_mrr_max": 0.544207,
        "nAUC_mrr_std": 0.351668,
        "nAUC_mrr_diff1": 0.823965,
        "main_score": 0.916872,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.912289,
        "mrr": 0.912289,
        "nAUC_map_max": 0.506356,
        "nAUC_map_std": 0.302236,
        "nAUC_map_diff1": 0.853312,
        "nAUC_mrr_max": 0.506356,
        "nAUC_mrr_std": 0.302236,
        "nAUC_mrr_diff1": 0.853312,
        "main_score": 0.912289,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.910713,
        "mrr": 0.911047,
        "nAUC_map_max": 0.549591,
        "nAUC_map_std": 0.403852,
        "nAUC_map_diff1": 0.876143,
        "nAUC_mrr_max": 0.548646,
        "nAUC_mrr_std": 0.40966,
        "nAUC_mrr_diff1": 0.875222,
        "main_score": 0.910713,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.901641,
        "mrr": 0.901975,
        "nAUC_map_max": 0.524283,
        "nAUC_map_std": 0.365441,
        "nAUC_map_diff1": 0.848181,
        "nAUC_mrr_max": 0.527882,
        "nAUC_mrr_std": 0.372706,
        "nAUC_mrr_diff1": 0.847254,
        "main_score": 0.901641,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.90144,
        "mrr": 0.90144,
        "nAUC_map_max": 0.50429,
        "nAUC_map_std": 0.332439,
        "nAUC_map_diff1": 0.814256,
        "nAUC_mrr_max": 0.50429,
        "nAUC_mrr_std": 0.332439,
        "nAUC_mrr_diff1": 0.814256,
        "main_score": 0.90144,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.923253,
        "mrr": 0.923253,
        "nAUC_map_max": 0.42041,
        "nAUC_map_std": 0.338781,
        "nAUC_map_diff1": 0.85903,
        "nAUC_mrr_max": 0.42041,
        "nAUC_mrr_std": 0.338781,
        "nAUC_mrr_diff1": 0.85903,
        "main_score": 0.923253,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 586.8689124584198,
  "kg_co2_emissions": null
}