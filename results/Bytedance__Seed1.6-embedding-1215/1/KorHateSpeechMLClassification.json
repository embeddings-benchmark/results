{
  "dataset_revision": "c657d15baf277c48d467f0625f7d33c50d4352ef",
  "task_name": "KorHateSpeechMLClassification",
  "mteb_version": "1.38.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.762494,
        "f1": 0.716802,
        "lrap": 0.847485,
        "scores_per_experiment": [
          {
            "accuracy": 0.766814,
            "f1": 0.733561,
            "lrap": 0.85087
          },
          {
            "accuracy": 0.767796,
            "f1": 0.729272,
            "lrap": 0.852697
          },
          {
            "accuracy": 0.765341,
            "f1": 0.727095,
            "lrap": 0.851852
          },
          {
            "accuracy": 0.77025,
            "f1": 0.736485,
            "lrap": 0.853775
          },
          {
            "accuracy": 0.73785,
            "f1": 0.702196,
            "lrap": 0.828874
          },
          {
            "accuracy": 0.744723,
            "f1": 0.688828,
            "lrap": 0.837833
          },
          {
            "accuracy": 0.761905,
            "f1": 0.694323,
            "lrap": 0.846793
          },
          {
            "accuracy": 0.769269,
            "f1": 0.737188,
            "lrap": 0.852002
          },
          {
            "accuracy": 0.772214,
            "f1": 0.698657,
            "lrap": 0.849084
          },
          {
            "accuracy": 0.768778,
            "f1": 0.720415,
            "lrap": 0.851075
          }
        ],
        "main_score": 0.762494,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ]
      }
    ]
  },
  "evaluation_time": 10.669026613235474,
  "kg_co2_emissions": null
}