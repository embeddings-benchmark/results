{
  "dataset_revision": "7ebf0b4caa7b2ae39698a889de782c09e6f5ee56",
  "task_name": "DalajClassification",
  "mteb_version": "1.38.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.496284,
        "f1": 0.491865,
        "f1_weighted": 0.491865,
        "ap": 0.498339,
        "ap_weighted": 0.498339,
        "scores_per_experiment": [
          {
            "accuracy": 0.503378,
            "f1": 0.501466,
            "f1_weighted": 0.501466,
            "ap": 0.501702,
            "ap_weighted": 0.501702
          },
          {
            "accuracy": 0.490991,
            "f1": 0.490057,
            "f1_weighted": 0.490057,
            "ap": 0.49557,
            "ap_weighted": 0.49557
          },
          {
            "accuracy": 0.488739,
            "f1": 0.475322,
            "f1_weighted": 0.475322,
            "ap": 0.494465,
            "ap_weighted": 0.494465
          },
          {
            "accuracy": 0.512387,
            "f1": 0.509921,
            "f1_weighted": 0.509921,
            "ap": 0.506373,
            "ap_weighted": 0.506373
          },
          {
            "accuracy": 0.518018,
            "f1": 0.511574,
            "f1_weighted": 0.511574,
            "ap": 0.509273,
            "ap_weighted": 0.509273
          },
          {
            "accuracy": 0.5,
            "f1": 0.499838,
            "f1_weighted": 0.499838,
            "ap": 0.5,
            "ap_weighted": 0.5
          },
          {
            "accuracy": 0.47973,
            "f1": 0.466468,
            "f1_weighted": 0.466468,
            "ap": 0.490465,
            "ap_weighted": 0.490465
          },
          {
            "accuracy": 0.47973,
            "f1": 0.47457,
            "f1_weighted": 0.47457,
            "ap": 0.490377,
            "ap_weighted": 0.490377
          },
          {
            "accuracy": 0.504505,
            "f1": 0.504079,
            "f1_weighted": 0.504079,
            "ap": 0.502274,
            "ap_weighted": 0.502274
          },
          {
            "accuracy": 0.48536,
            "f1": 0.485354,
            "f1_weighted": 0.485354,
            "ap": 0.492893,
            "ap_weighted": 0.492893
          }
        ],
        "main_score": 0.496284,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 10.447202682495117,
  "kg_co2_emissions": null
}