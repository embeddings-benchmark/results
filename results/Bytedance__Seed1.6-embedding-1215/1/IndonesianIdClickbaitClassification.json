{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.38.29",
  "scores": {
    "train": [
      {
        "accuracy": 0.619336,
        "f1": 0.610702,
        "f1_weighted": 0.61699,
        "ap": 0.497842,
        "ap_weighted": 0.497842,
        "scores_per_experiment": [
          {
            "accuracy": 0.679199,
            "f1": 0.658079,
            "f1_weighted": 0.671772,
            "ap": 0.537049,
            "ap_weighted": 0.537049
          },
          {
            "accuracy": 0.506348,
            "f1": 0.498941,
            "f1_weighted": 0.489125,
            "ap": 0.44018,
            "ap_weighted": 0.44018
          },
          {
            "accuracy": 0.565918,
            "f1": 0.564901,
            "f1_weighted": 0.56829,
            "ap": 0.460652,
            "ap_weighted": 0.460652
          },
          {
            "accuracy": 0.637207,
            "f1": 0.634539,
            "f1_weighted": 0.639571,
            "ap": 0.510048,
            "ap_weighted": 0.510048
          },
          {
            "accuracy": 0.665527,
            "f1": 0.662209,
            "f1_weighted": 0.667604,
            "ap": 0.533409,
            "ap_weighted": 0.533409
          },
          {
            "accuracy": 0.558594,
            "f1": 0.529655,
            "f1_weighted": 0.548454,
            "ap": 0.437028,
            "ap_weighted": 0.437028
          },
          {
            "accuracy": 0.674316,
            "f1": 0.666218,
            "f1_weighted": 0.674596,
            "ap": 0.537447,
            "ap_weighted": 0.537447
          },
          {
            "accuracy": 0.625,
            "f1": 0.621675,
            "f1_weighted": 0.62739,
            "ap": 0.499357,
            "ap_weighted": 0.499357
          },
          {
            "accuracy": 0.62793,
            "f1": 0.627076,
            "f1_weighted": 0.629951,
            "ap": 0.505886,
            "ap_weighted": 0.505886
          },
          {
            "accuracy": 0.65332,
            "f1": 0.643731,
            "f1_weighted": 0.653149,
            "ap": 0.517362,
            "ap_weighted": 0.517362
          }
        ],
        "main_score": 0.610702,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 13.48923945426941,
  "kg_co2_emissions": null
}