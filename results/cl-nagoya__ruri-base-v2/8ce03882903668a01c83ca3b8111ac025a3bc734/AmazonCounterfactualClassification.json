{
  "dataset_revision": "1f7e6a9d6fa6e64c53d146e428565640410c0df1",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "2.2.0",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.703863,
            "f1": 0.570007,
            "f1_weighted": 0.762553,
            "precision": 0.586642,
            "precision_weighted": 0.886919,
            "recall": 0.719565,
            "recall_weighted": 0.703863,
            "ap": 0.182816,
            "ap_weighted": 0.182816
          },
          {
            "accuracy": 0.736052,
            "f1": 0.581825,
            "f1_weighted": 0.785644,
            "precision": 0.585173,
            "precision_weighted": 0.879072,
            "recall": 0.698706,
            "recall_weighted": 0.736052,
            "ap": 0.177147,
            "ap_weighted": 0.177147
          },
          {
            "accuracy": 0.671674,
            "f1": 0.540472,
            "f1_weighted": 0.737538,
            "precision": 0.569838,
            "precision_weighted": 0.876987,
            "recall": 0.68235,
            "recall_weighted": 0.671674,
            "ap": 0.160223,
            "ap_weighted": 0.160223
          },
          {
            "accuracy": 0.759657,
            "f1": 0.604282,
            "f1_weighted": 0.803289,
            "precision": 0.598904,
            "precision_weighted": 0.885197,
            "recall": 0.72148,
            "recall_weighted": 0.759657,
            "ap": 0.195402,
            "ap_weighted": 0.195402
          },
          {
            "accuracy": 0.742489,
            "f1": 0.583346,
            "f1_weighted": 0.790011,
            "precision": 0.584399,
            "precision_weighted": 0.8771,
            "recall": 0.692598,
            "recall_weighted": 0.742489,
            "ap": 0.174985,
            "ap_weighted": 0.174985
          },
          {
            "accuracy": 0.718884,
            "f1": 0.581495,
            "f1_weighted": 0.773942,
            "precision": 0.591942,
            "precision_weighted": 0.888669,
            "recall": 0.727899,
            "recall_weighted": 0.718884,
            "ap": 0.190002,
            "ap_weighted": 0.190002
          },
          {
            "accuracy": 0.725322,
            "f1": 0.583382,
            "f1_weighted": 0.778549,
            "precision": 0.591046,
            "precision_weighted": 0.886453,
            "recall": 0.721791,
            "recall_weighted": 0.725322,
            "ap": 0.187856,
            "ap_weighted": 0.187856
          },
          {
            "accuracy": 0.66309,
            "f1": 0.522276,
            "f1_weighted": 0.730436,
            "precision": 0.553732,
            "precision_weighted": 0.86358,
            "recall": 0.638872,
            "recall_weighted": 0.66309,
            "ap": 0.140683,
            "ap_weighted": 0.140683
          },
          {
            "accuracy": 0.572961,
            "f1": 0.477717,
            "f1_weighted": 0.656719,
            "precision": 0.552433,
            "precision_weighted": 0.872329,
            "recall": 0.646946,
            "recall_weighted": 0.572961,
            "ap": 0.139463,
            "ap_weighted": 0.139463
          },
          {
            "accuracy": 0.697425,
            "f1": 0.546214,
            "f1_weighted": 0.756448,
            "precision": 0.564144,
            "precision_weighted": 0.86809,
            "recall": 0.657919,
            "recall_weighted": 0.697425,
            "ap": 0.151497,
            "ap_weighted": 0.151497
          }
        ],
        "accuracy": 0.699142,
        "f1": 0.559102,
        "f1_weighted": 0.757513,
        "precision": 0.577825,
        "precision_weighted": 0.87844,
        "recall": 0.690813,
        "recall_weighted": 0.699142,
        "ap": 0.170008,
        "ap_weighted": 0.170008,
        "main_score": 0.699142,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.711991,
            "f1": 0.584763,
            "f1_weighted": 0.767361,
            "precision": 0.59732,
            "precision_weighted": 0.888711,
            "recall": 0.738042,
            "recall_weighted": 0.711991,
            "ap": 0.201255,
            "ap_weighted": 0.201255
          },
          {
            "accuracy": 0.745182,
            "f1": 0.611413,
            "f1_weighted": 0.792538,
            "precision": 0.610505,
            "precision_weighted": 0.892794,
            "recall": 0.756538,
            "recall_weighted": 0.745182,
            "ap": 0.22025,
            "ap_weighted": 0.22025
          },
          {
            "accuracy": 0.632762,
            "f1": 0.511741,
            "f1_weighted": 0.704855,
            "precision": 0.555039,
            "precision_weighted": 0.861799,
            "recall": 0.643161,
            "recall_weighted": 0.632762,
            "ap": 0.146173,
            "ap_weighted": 0.146173
          },
          {
            "accuracy": 0.747323,
            "f1": 0.592245,
            "f1_weighted": 0.792016,
            "precision": 0.590371,
            "precision_weighted": 0.874417,
            "recall": 0.69778,
            "recall_weighted": 0.747323,
            "ap": 0.185414,
            "ap_weighted": 0.185414
          },
          {
            "accuracy": 0.737687,
            "f1": 0.591284,
            "f1_weighted": 0.785616,
            "precision": 0.592823,
            "precision_weighted": 0.878699,
            "recall": 0.710857,
            "recall_weighted": 0.737687,
            "ap": 0.190934,
            "ap_weighted": 0.190934
          },
          {
            "accuracy": 0.735546,
            "f1": 0.60496,
            "f1_weighted": 0.785397,
            "precision": 0.607997,
            "precision_weighted": 0.893061,
            "recall": 0.75578,
            "recall_weighted": 0.735546,
            "ap": 0.217148,
            "ap_weighted": 0.217148
          },
          {
            "accuracy": 0.752677,
            "f1": 0.600031,
            "f1_weighted": 0.796327,
            "precision": 0.596173,
            "precision_weighted": 0.878032,
            "recall": 0.709987,
            "recall_weighted": 0.752677,
            "ap": 0.193737,
            "ap_weighted": 0.193737
          },
          {
            "accuracy": 0.682013,
            "f1": 0.550649,
            "f1_weighted": 0.743663,
            "precision": 0.574141,
            "precision_weighted": 0.872802,
            "recall": 0.684442,
            "recall_weighted": 0.682013,
            "ap": 0.168381,
            "ap_weighted": 0.168381
          },
          {
            "accuracy": 0.553533,
            "f1": 0.466634,
            "f1_weighted": 0.637666,
            "precision": 0.548438,
            "precision_weighted": 0.863505,
            "recall": 0.63129,
            "recall_weighted": 0.553533,
            "ap": 0.138557,
            "ap_weighted": 0.138557
          },
          {
            "accuracy": 0.694861,
            "f1": 0.550746,
            "f1_weighted": 0.752888,
            "precision": 0.568287,
            "precision_weighted": 0.865495,
            "recall": 0.663932,
            "recall_weighted": 0.694861,
            "ap": 0.159903,
            "ap_weighted": 0.159903
          }
        ],
        "accuracy": 0.699358,
        "f1": 0.566447,
        "f1_weighted": 0.755833,
        "precision": 0.584109,
        "precision_weighted": 0.876931,
        "recall": 0.699181,
        "recall_weighted": 0.699358,
        "ap": 0.182175,
        "ap_weighted": 0.182175,
        "main_score": 0.699358,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ]
  },
  "evaluation_time": 4.535019636154175,
  "kg_co2_emissions": null
}