{
  "dataset_revision": "3ac713aa0829eeadda73182f38bbbd788d21254b",
  "task_name": "SpeechCommands",
  "mteb_version": "2.4.2",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.17771,
            "f1": 0.069565,
            "f1_weighted": 0.177141,
            "precision": 0.099965,
            "precision_weighted": 0.281647,
            "recall": 0.121653,
            "recall_weighted": 0.17771,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.17137,
            "f1": 0.071115,
            "f1_weighted": 0.175768,
            "precision": 0.133092,
            "precision_weighted": 0.375713,
            "recall": 0.141294,
            "recall_weighted": 0.17137,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.190798,
            "f1": 0.077102,
            "f1_weighted": 0.193596,
            "precision": 0.103288,
            "precision_weighted": 0.279858,
            "recall": 0.122704,
            "recall_weighted": 0.190798,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.183845,
            "f1": 0.075706,
            "f1_weighted": 0.183655,
            "precision": 0.091912,
            "precision_weighted": 0.25086,
            "recall": 0.14787,
            "recall_weighted": 0.183845,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.174642,
            "f1": 0.069529,
            "f1_weighted": 0.173679,
            "precision": 0.101964,
            "precision_weighted": 0.284225,
            "recall": 0.122444,
            "recall_weighted": 0.174642,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.174847,
            "f1": 0.068768,
            "f1_weighted": 0.176417,
            "precision": 0.097978,
            "precision_weighted": 0.275785,
            "recall": 0.127419,
            "recall_weighted": 0.174847,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.231288,
            "f1": 0.091098,
            "f1_weighted": 0.231896,
            "precision": 0.120727,
            "precision_weighted": 0.33409,
            "recall": 0.137777,
            "recall_weighted": 0.231288,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.196319,
            "f1": 0.078398,
            "f1_weighted": 0.199969,
            "precision": 0.105407,
            "precision_weighted": 0.290579,
            "recall": 0.111635,
            "recall_weighted": 0.196319,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.192638,
            "f1": 0.078849,
            "f1_weighted": 0.193066,
            "precision": 0.098052,
            "precision_weighted": 0.266409,
            "recall": 0.140557,
            "recall_weighted": 0.192638,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.210838,
            "f1": 0.080068,
            "f1_weighted": 0.203307,
            "precision": 0.107365,
            "precision_weighted": 0.276763,
            "recall": 0.109191,
            "recall_weighted": 0.210838,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.190429,
        "f1": 0.07602,
        "f1_weighted": 0.190849,
        "precision": 0.105975,
        "precision_weighted": 0.291593,
        "recall": 0.128254,
        "recall_weighted": 0.190429,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.190429,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 839.6844592094421,
  "kg_co2_emissions": null
}