{
  "dataset_revision": "416b34a802308eac30e4192afc0ff99bb8dcc7f2",
  "task_name": "SensitiveTopicsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.282275,
        "f1": 0.300125,
        "lrap": 0.420591,
        "scores_per_experiment": [
          {
            "accuracy": 0.269531,
            "f1": 0.263248,
            "lrap": 0.399807
          },
          {
            "accuracy": 0.286621,
            "f1": 0.325561,
            "lrap": 0.431498
          },
          {
            "accuracy": 0.262695,
            "f1": 0.242297,
            "lrap": 0.38288
          },
          {
            "accuracy": 0.266602,
            "f1": 0.297251,
            "lrap": 0.399685
          },
          {
            "accuracy": 0.261719,
            "f1": 0.296932,
            "lrap": 0.406304
          },
          {
            "accuracy": 0.304688,
            "f1": 0.326872,
            "lrap": 0.452406
          },
          {
            "accuracy": 0.294922,
            "f1": 0.313449,
            "lrap": 0.438734
          },
          {
            "accuracy": 0.288574,
            "f1": 0.303519,
            "lrap": 0.421916
          },
          {
            "accuracy": 0.30127,
            "f1": 0.319664,
            "lrap": 0.440172
          },
          {
            "accuracy": 0.286133,
            "f1": 0.312453,
            "lrap": 0.432509
          }
        ],
        "main_score": 0.282275,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ]
      }
    ]
  },
  "evaluation_time": 6.325873613357544,
  "kg_co2_emissions": 0.00032478824207440523
}