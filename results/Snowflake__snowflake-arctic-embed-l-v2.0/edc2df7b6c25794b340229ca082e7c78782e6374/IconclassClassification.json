{
  "dataset_revision": "1cd02f1579dab39fedc95de8cc15fd620557a9f2",
  "task_name": "IconclassClassification",
  "mteb_version": "2.1.0",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.594059,
            "f1": 0.591619,
            "f1_weighted": 0.59271,
            "precision": 0.59815,
            "precision_weighted": 0.599524,
            "recall": 0.593325,
            "recall_weighted": 0.594059,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.564356,
            "f1": 0.543429,
            "f1_weighted": 0.545912,
            "precision": 0.552045,
            "precision_weighted": 0.553484,
            "recall": 0.561045,
            "recall_weighted": 0.564356,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.559406,
            "f1": 0.554765,
            "f1_weighted": 0.556284,
            "precision": 0.556336,
            "precision_weighted": 0.557714,
            "recall": 0.557751,
            "recall_weighted": 0.559406,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.589109,
            "f1": 0.584105,
            "f1_weighted": 0.585974,
            "precision": 0.586691,
            "precision_weighted": 0.588465,
            "recall": 0.587176,
            "recall_weighted": 0.589109,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.564356,
            "f1": 0.551791,
            "f1_weighted": 0.553077,
            "precision": 0.557374,
            "precision_weighted": 0.558343,
            "recall": 0.562802,
            "recall_weighted": 0.564356,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.559406,
            "f1": 0.547158,
            "f1_weighted": 0.548673,
            "precision": 0.554772,
            "precision_weighted": 0.555328,
            "recall": 0.557093,
            "recall_weighted": 0.559406,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.559406,
            "f1": 0.549395,
            "f1_weighted": 0.551349,
            "precision": 0.550369,
            "precision_weighted": 0.551702,
            "recall": 0.556873,
            "recall_weighted": 0.559406,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.579208,
            "f1": 0.565959,
            "f1_weighted": 0.567431,
            "precision": 0.573859,
            "precision_weighted": 0.574856,
            "recall": 0.577514,
            "recall_weighted": 0.579208,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.613861,
            "f1": 0.608304,
            "f1_weighted": 0.609791,
            "precision": 0.613176,
            "precision_weighted": 0.614312,
            "recall": 0.611989,
            "recall_weighted": 0.613861,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.544554,
            "f1": 0.536623,
            "f1_weighted": 0.538612,
            "precision": 0.540014,
            "precision_weighted": 0.541847,
            "recall": 0.54238,
            "recall_weighted": 0.544554,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.572772,
        "f1": 0.563315,
        "f1_weighted": 0.564981,
        "precision": 0.568279,
        "precision_weighted": 0.569558,
        "recall": 0.570795,
        "recall_weighted": 0.572772,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.563315,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 13.962839841842651,
  "kg_co2_emissions": null
}