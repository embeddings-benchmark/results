{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "map": 0.880485,
        "mrr": 0.880485,
        "nAUC_map_max": 0.650502,
        "nAUC_map_std": 0.271671,
        "nAUC_map_diff1": 0.800675,
        "nAUC_mrr_max": 0.650502,
        "nAUC_mrr_std": 0.271671,
        "nAUC_mrr_diff1": 0.800675,
        "main_score": 0.880485,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.866673,
        "mrr": 0.866673,
        "nAUC_map_max": 0.488356,
        "nAUC_map_std": 0.291583,
        "nAUC_map_diff1": 0.726309,
        "nAUC_mrr_max": 0.488356,
        "nAUC_mrr_std": 0.291583,
        "nAUC_mrr_diff1": 0.726309,
        "main_score": 0.866673,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.89408,
        "mrr": 0.89408,
        "nAUC_map_max": 0.640173,
        "nAUC_map_std": 0.34844,
        "nAUC_map_diff1": 0.836756,
        "nAUC_mrr_max": 0.640173,
        "nAUC_mrr_std": 0.34844,
        "nAUC_mrr_diff1": 0.836756,
        "main_score": 0.89408,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.904553,
        "mrr": 0.904998,
        "nAUC_map_max": 0.56449,
        "nAUC_map_std": 0.321793,
        "nAUC_map_diff1": 0.8031,
        "nAUC_mrr_max": 0.563459,
        "nAUC_mrr_std": 0.318357,
        "nAUC_mrr_diff1": 0.801766,
        "main_score": 0.904553,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.894012,
        "mrr": 0.894012,
        "nAUC_map_max": 0.640812,
        "nAUC_map_std": 0.179723,
        "nAUC_map_diff1": 0.813079,
        "nAUC_mrr_max": 0.640812,
        "nAUC_mrr_std": 0.179723,
        "nAUC_mrr_diff1": 0.813079,
        "main_score": 0.894012,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.914054,
        "mrr": 0.914054,
        "nAUC_map_max": 0.651076,
        "nAUC_map_std": 0.412973,
        "nAUC_map_diff1": 0.862647,
        "nAUC_mrr_max": 0.651076,
        "nAUC_mrr_std": 0.412973,
        "nAUC_mrr_diff1": 0.862647,
        "main_score": 0.914054,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.887126,
        "mrr": 0.887126,
        "nAUC_map_max": 0.613194,
        "nAUC_map_std": 0.303275,
        "nAUC_map_diff1": 0.808782,
        "nAUC_mrr_max": 0.613194,
        "nAUC_mrr_std": 0.303275,
        "nAUC_mrr_diff1": 0.808782,
        "main_score": 0.887126,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.911668,
        "mrr": 0.911668,
        "nAUC_map_max": 0.470887,
        "nAUC_map_std": 0.192428,
        "nAUC_map_diff1": 0.810367,
        "nAUC_mrr_max": 0.470887,
        "nAUC_mrr_std": 0.192428,
        "nAUC_mrr_diff1": 0.810367,
        "main_score": 0.911668,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.870257,
        "mrr": 0.871269,
        "nAUC_map_max": 0.518377,
        "nAUC_map_std": 0.292432,
        "nAUC_map_diff1": 0.770793,
        "nAUC_mrr_max": 0.523975,
        "nAUC_mrr_std": 0.295327,
        "nAUC_mrr_diff1": 0.768081,
        "main_score": 0.870257,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.900841,
        "mrr": 0.900841,
        "nAUC_map_max": 0.63571,
        "nAUC_map_std": 0.288202,
        "nAUC_map_diff1": 0.808395,
        "nAUC_mrr_max": 0.63571,
        "nAUC_mrr_std": 0.288202,
        "nAUC_mrr_diff1": 0.808395,
        "main_score": 0.900841,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.891116,
        "mrr": 0.89145,
        "nAUC_map_max": 0.508077,
        "nAUC_map_std": 0.235921,
        "nAUC_map_diff1": 0.770964,
        "nAUC_mrr_max": 0.510044,
        "nAUC_mrr_std": 0.242162,
        "nAUC_mrr_diff1": 0.769906,
        "main_score": 0.891116,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.881937,
        "mrr": 0.881937,
        "nAUC_map_max": 0.580254,
        "nAUC_map_std": 0.240536,
        "nAUC_map_diff1": 0.799442,
        "nAUC_mrr_max": 0.580254,
        "nAUC_mrr_std": 0.240536,
        "nAUC_mrr_diff1": 0.799442,
        "main_score": 0.881937,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.891598,
        "mrr": 0.891931,
        "nAUC_map_max": 0.519518,
        "nAUC_map_std": 0.269448,
        "nAUC_map_diff1": 0.805664,
        "nAUC_mrr_max": 0.518171,
        "nAUC_mrr_std": 0.269808,
        "nAUC_mrr_diff1": 0.804698,
        "main_score": 0.891598,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.901982,
        "mrr": 0.902316,
        "nAUC_map_max": 0.527632,
        "nAUC_map_std": 0.198356,
        "nAUC_map_diff1": 0.818091,
        "nAUC_mrr_max": 0.529858,
        "nAUC_mrr_std": 0.205114,
        "nAUC_mrr_diff1": 0.81707,
        "main_score": 0.901982,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.868867,
        "mrr": 0.868867,
        "nAUC_map_max": 0.549392,
        "nAUC_map_std": 0.22611,
        "nAUC_map_diff1": 0.783064,
        "nAUC_mrr_max": 0.549392,
        "nAUC_mrr_std": 0.22611,
        "nAUC_mrr_diff1": 0.783064,
        "main_score": 0.868867,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.908811,
        "mrr": 0.908811,
        "nAUC_map_max": 0.555476,
        "nAUC_map_std": 0.242769,
        "nAUC_map_diff1": 0.801424,
        "nAUC_mrr_max": 0.555476,
        "nAUC_mrr_std": 0.242769,
        "nAUC_mrr_diff1": 0.801424,
        "main_score": 0.908811,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 503.5175211429596,
  "kg_co2_emissions": 0.04574609428835897
}