{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.21.3",
  "scores": {
    "test": [
      {
        "accuracy": 0.67039,
        "f1": 0.551806,
        "f1_weighted": 0.734115,
        "ap": 0.179914,
        "ap_weighted": 0.179914,
        "scores_per_experiment": [
          {
            "accuracy": 0.710645,
            "f1": 0.583028,
            "f1_weighted": 0.765634,
            "ap": 0.199046,
            "ap_weighted": 0.199046
          },
          {
            "accuracy": 0.701649,
            "f1": 0.579969,
            "f1_weighted": 0.75893,
            "ap": 0.201681,
            "ap_weighted": 0.201681
          },
          {
            "accuracy": 0.655922,
            "f1": 0.540309,
            "f1_weighted": 0.722801,
            "ap": 0.172089,
            "ap_weighted": 0.172089
          },
          {
            "accuracy": 0.648426,
            "f1": 0.529347,
            "f1_weighted": 0.71675,
            "ap": 0.160665,
            "ap_weighted": 0.160665
          },
          {
            "accuracy": 0.658171,
            "f1": 0.536248,
            "f1_weighted": 0.72448,
            "ap": 0.163951,
            "ap_weighted": 0.163951
          },
          {
            "accuracy": 0.671664,
            "f1": 0.562656,
            "f1_weighted": 0.735498,
            "ap": 0.197847,
            "ap_weighted": 0.197847
          },
          {
            "accuracy": 0.654423,
            "f1": 0.53923,
            "f1_weighted": 0.721604,
            "ap": 0.171539,
            "ap_weighted": 0.171539
          },
          {
            "accuracy": 0.7009,
            "f1": 0.56743,
            "f1_weighted": 0.757637,
            "ap": 0.180583,
            "ap_weighted": 0.180583
          },
          {
            "accuracy": 0.655172,
            "f1": 0.547815,
            "f1_weighted": 0.722229,
            "ap": 0.185826,
            "ap_weighted": 0.185826
          },
          {
            "accuracy": 0.646927,
            "f1": 0.532029,
            "f1_weighted": 0.715587,
            "ap": 0.165917,
            "ap_weighted": 0.165917
          }
        ],
        "main_score": 0.67039,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "accuracy": 0.65597,
        "f1": 0.602443,
        "f1_weighted": 0.689975,
        "ap": 0.297621,
        "ap_weighted": 0.297621,
        "scores_per_experiment": [
          {
            "accuracy": 0.668657,
            "f1": 0.602112,
            "f1_weighted": 0.7012,
            "ap": 0.283704,
            "ap_weighted": 0.283704
          },
          {
            "accuracy": 0.652239,
            "f1": 0.609783,
            "f1_weighted": 0.688163,
            "ap": 0.314323,
            "ap_weighted": 0.314323
          },
          {
            "accuracy": 0.553731,
            "f1": 0.522636,
            "f1_weighted": 0.596828,
            "ap": 0.253703,
            "ap_weighted": 0.253703
          },
          {
            "accuracy": 0.658209,
            "f1": 0.602409,
            "f1_weighted": 0.693112,
            "ap": 0.292944,
            "ap_weighted": 0.292944
          },
          {
            "accuracy": 0.632836,
            "f1": 0.591985,
            "f1_weighted": 0.670603,
            "ap": 0.29961,
            "ap_weighted": 0.29961
          },
          {
            "accuracy": 0.683582,
            "f1": 0.623312,
            "f1_weighted": 0.715066,
            "ap": 0.30795,
            "ap_weighted": 0.30795
          },
          {
            "accuracy": 0.729851,
            "f1": 0.645379,
            "f1_weighted": 0.750775,
            "ap": 0.310872,
            "ap_weighted": 0.310872
          },
          {
            "accuracy": 0.707463,
            "f1": 0.64556,
            "f1_weighted": 0.735761,
            "ap": 0.328061,
            "ap_weighted": 0.328061
          },
          {
            "accuracy": 0.646269,
            "f1": 0.599479,
            "f1_weighted": 0.682842,
            "ap": 0.299477,
            "ap_weighted": 0.299477
          },
          {
            "accuracy": 0.626866,
            "f1": 0.581773,
            "f1_weighted": 0.6654,
            "ap": 0.285566,
            "ap_weighted": 0.285566
          }
        ],
        "main_score": 0.65597,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 52.214282751083374,
  "kg_co2_emissions": null
}