{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.708887,
        "f1": 0.706368,
        "f1_weighted": 0.706434,
        "ap": 0.644215,
        "ap_weighted": 0.644215,
        "scores_per_experiment": [
          {
            "accuracy": 0.701172,
            "f1": 0.692906,
            "f1_weighted": 0.693054,
            "ap": 0.632118,
            "ap_weighted": 0.632118
          },
          {
            "accuracy": 0.727051,
            "f1": 0.722821,
            "f1_weighted": 0.722921,
            "ap": 0.655996,
            "ap_weighted": 0.655996
          },
          {
            "accuracy": 0.662109,
            "f1": 0.661365,
            "f1_weighted": 0.661412,
            "ap": 0.606435,
            "ap_weighted": 0.606435
          },
          {
            "accuracy": 0.70752,
            "f1": 0.706243,
            "f1_weighted": 0.7063,
            "ap": 0.643097,
            "ap_weighted": 0.643097
          },
          {
            "accuracy": 0.73584,
            "f1": 0.735771,
            "f1_weighted": 0.735784,
            "ap": 0.673223,
            "ap_weighted": 0.673223
          },
          {
            "accuracy": 0.69043,
            "f1": 0.690287,
            "f1_weighted": 0.690306,
            "ap": 0.631395,
            "ap_weighted": 0.631395
          },
          {
            "accuracy": 0.744629,
            "f1": 0.742195,
            "f1_weighted": 0.742268,
            "ap": 0.673607,
            "ap_weighted": 0.673607
          },
          {
            "accuracy": 0.711914,
            "f1": 0.704797,
            "f1_weighted": 0.704931,
            "ap": 0.641294,
            "ap_weighted": 0.641294
          },
          {
            "accuracy": 0.679688,
            "f1": 0.679354,
            "f1_weighted": 0.679385,
            "ap": 0.621561,
            "ap_weighted": 0.621561
          },
          {
            "accuracy": 0.728516,
            "f1": 0.727942,
            "f1_weighted": 0.727979,
            "ap": 0.663421,
            "ap_weighted": 0.663421
          }
        ],
        "main_score": 0.708887,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.698584,
        "f1": 0.696166,
        "f1_weighted": 0.696209,
        "ap": 0.634924,
        "ap_weighted": 0.634924,
        "scores_per_experiment": [
          {
            "accuracy": 0.701172,
            "f1": 0.693598,
            "f1_weighted": 0.693692,
            "ap": 0.632091,
            "ap_weighted": 0.632091
          },
          {
            "accuracy": 0.719238,
            "f1": 0.714675,
            "f1_weighted": 0.714745,
            "ap": 0.648735,
            "ap_weighted": 0.648735
          },
          {
            "accuracy": 0.651855,
            "f1": 0.651363,
            "f1_weighted": 0.651388,
            "ap": 0.598293,
            "ap_weighted": 0.598293
          },
          {
            "accuracy": 0.707031,
            "f1": 0.705918,
            "f1_weighted": 0.705953,
            "ap": 0.642547,
            "ap_weighted": 0.642547
          },
          {
            "accuracy": 0.714844,
            "f1": 0.7147,
            "f1_weighted": 0.714712,
            "ap": 0.65253,
            "ap_weighted": 0.65253
          },
          {
            "accuracy": 0.686523,
            "f1": 0.686437,
            "f1_weighted": 0.686447,
            "ap": 0.627883,
            "ap_weighted": 0.627883
          },
          {
            "accuracy": 0.726562,
            "f1": 0.723876,
            "f1_weighted": 0.723929,
            "ap": 0.65695,
            "ap_weighted": 0.65695
          },
          {
            "accuracy": 0.69873,
            "f1": 0.691988,
            "f1_weighted": 0.692077,
            "ap": 0.630573,
            "ap_weighted": 0.630573
          },
          {
            "accuracy": 0.675293,
            "f1": 0.674833,
            "f1_weighted": 0.674857,
            "ap": 0.617139,
            "ap_weighted": 0.617139
          },
          {
            "accuracy": 0.70459,
            "f1": 0.704273,
            "f1_weighted": 0.704292,
            "ap": 0.642499,
            "ap_weighted": 0.642499
          }
        ],
        "main_score": 0.698584,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 21.448643922805786,
  "kg_co2_emissions": 0.001017293687646709
}