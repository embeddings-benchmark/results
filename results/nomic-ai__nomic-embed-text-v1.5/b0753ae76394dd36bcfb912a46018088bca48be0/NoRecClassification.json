{
  "dataset_revision": "5b740b7c42c73d586420812a35745fc37118862f",
  "task_name": "NoRecClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.409619,
        "f1": 0.379851,
        "f1_weighted": 0.419408,
        "scores_per_experiment": [
          {
            "accuracy": 0.390137,
            "f1": 0.382053,
            "f1_weighted": 0.411472
          },
          {
            "accuracy": 0.441406,
            "f1": 0.380035,
            "f1_weighted": 0.441181
          },
          {
            "accuracy": 0.434082,
            "f1": 0.396756,
            "f1_weighted": 0.436255
          },
          {
            "accuracy": 0.430176,
            "f1": 0.400702,
            "f1_weighted": 0.447916
          },
          {
            "accuracy": 0.376953,
            "f1": 0.369185,
            "f1_weighted": 0.39644
          },
          {
            "accuracy": 0.331543,
            "f1": 0.321256,
            "f1_weighted": 0.332123
          },
          {
            "accuracy": 0.415527,
            "f1": 0.397742,
            "f1_weighted": 0.436672
          },
          {
            "accuracy": 0.432617,
            "f1": 0.379098,
            "f1_weighted": 0.429608
          },
          {
            "accuracy": 0.414551,
            "f1": 0.397178,
            "f1_weighted": 0.432556
          },
          {
            "accuracy": 0.429199,
            "f1": 0.374509,
            "f1_weighted": 0.429854
          }
        ],
        "main_score": 0.409619,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 8.06745958328247,
  "kg_co2_emissions": 0.00027022543582278516
}