{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 27.484099864959717,
  "kg_co2_emissions": 0.001124277529571298,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.7622297071936893,
        "cosine_spearman": 0.7665716398273439,
        "euclidean_pearson": 0.7423234546975221,
        "euclidean_spearman": 0.7665716398273439,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.7665716398273439,
        "manhattan_pearson": 0.7409906804917431,
        "manhattan_spearman": 0.7664710844847737,
        "pearson": 0.7622297071936893,
        "spearman": 0.7665716398273439
      },
      {
        "cosine_pearson": -0.019697195776888755,
        "cosine_spearman": 0.0202293277527734,
        "euclidean_pearson": 0.025618585986660093,
        "euclidean_spearman": 0.021990265641641617,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.0202293277527734,
        "manhattan_pearson": 0.02662921918272893,
        "manhattan_spearman": 0.02285710183913372,
        "pearson": -0.019697195776888755,
        "spearman": 0.0202293277527734
      },
      {
        "cosine_pearson": 0.33193710759289224,
        "cosine_spearman": 0.3298718988323122,
        "euclidean_pearson": 0.34557887210273525,
        "euclidean_spearman": 0.3298718988323122,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.3298718988323122,
        "manhattan_pearson": 0.3459578119535282,
        "manhattan_spearman": 0.3288150911805108,
        "pearson": 0.33193710759289224,
        "spearman": 0.3298718988323122
      },
      {
        "cosine_pearson": 0.41621657617662594,
        "cosine_spearman": 0.3997162155520456,
        "euclidean_pearson": 0.419819406054547,
        "euclidean_spearman": 0.3997162155520456,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.3997162155520456,
        "manhattan_pearson": 0.41966366449461073,
        "manhattan_spearman": 0.4008157116637953,
        "pearson": 0.41621657617662594,
        "spearman": 0.3997162155520456
      },
      {
        "cosine_pearson": 0.24526539749011014,
        "cosine_spearman": 0.24329187235842484,
        "euclidean_pearson": 0.26680907342910426,
        "euclidean_spearman": 0.24329187235842484,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.24329187235842484,
        "manhattan_pearson": 0.26596426574521914,
        "manhattan_spearman": 0.2425883836253648,
        "pearson": 0.24526539749011014,
        "spearman": 0.24329187235842484
      },
      {
        "cosine_pearson": 0.7927078631057884,
        "cosine_spearman": 0.7856430770036363,
        "euclidean_pearson": 0.7970369883428536,
        "euclidean_spearman": 0.7856432416792662,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7856430770036363,
        "manhattan_pearson": 0.7970661967503191,
        "manhattan_spearman": 0.7858465707688281,
        "pearson": 0.7927078631057884,
        "spearman": 0.7856430770036363
      },
      {
        "cosine_pearson": 0.4234068763394339,
        "cosine_spearman": 0.3923907430437206,
        "euclidean_pearson": 0.4251198771511189,
        "euclidean_spearman": 0.3923907430437206,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.3923907430437206,
        "manhattan_pearson": 0.4234626222766167,
        "manhattan_spearman": 0.38733361113465836,
        "pearson": 0.4234068763394339,
        "spearman": 0.3923907430437206
      },
      {
        "cosine_pearson": 0.4861812684559458,
        "cosine_spearman": 0.4829792444385533,
        "euclidean_pearson": 0.5096268680908173,
        "euclidean_spearman": 0.4829777955512036,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.4829792444385533,
        "manhattan_pearson": 0.5069131597421936,
        "manhattan_spearman": 0.4808094744987301,
        "pearson": 0.4861812684559458,
        "spearman": 0.4829792444385533
      },
      {
        "cosine_pearson": 0.46564562474062116,
        "cosine_spearman": 0.4700008820458804,
        "euclidean_pearson": 0.49464673295139394,
        "euclidean_spearman": 0.4700008820458804,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.4700008820458804,
        "manhattan_pearson": 0.49468737677984276,
        "manhattan_spearman": 0.4702590581428927,
        "pearson": 0.46564562474062116,
        "spearman": 0.4700008820458804
      },
      {
        "cosine_pearson": 0.5027466147850922,
        "cosine_spearman": 0.4936029107050798,
        "euclidean_pearson": 0.5138711237906443,
        "euclidean_spearman": 0.4936029107050798,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.4936029107050798,
        "manhattan_pearson": 0.5192918294373394,
        "manhattan_spearman": 0.5004283303357085,
        "pearson": 0.5027466147850922,
        "spearman": 0.4936029107050798
      },
      {
        "cosine_pearson": 0.5268752340359245,
        "cosine_spearman": 0.5051319650660778,
        "euclidean_pearson": 0.5454151126247337,
        "euclidean_spearman": 0.5051319650660778,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.5051319650660778,
        "manhattan_pearson": 0.543436813010299,
        "manhattan_spearman": 0.5025599315212972,
        "pearson": 0.5268752340359245,
        "spearman": 0.5051319650660778
      },
      {
        "cosine_pearson": 0.24968206331612733,
        "cosine_spearman": 0.3362894242542299,
        "euclidean_pearson": 0.31575887947027265,
        "euclidean_spearman": 0.3360057930377833,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.3362894242542299,
        "manhattan_pearson": 0.31773227447990393,
        "manhattan_spearman": 0.33871551165111413,
        "pearson": 0.24968206331612733,
        "spearman": 0.3362894242542299
      }
    ]
  },
  "task_name": "SemRel24STS"
}