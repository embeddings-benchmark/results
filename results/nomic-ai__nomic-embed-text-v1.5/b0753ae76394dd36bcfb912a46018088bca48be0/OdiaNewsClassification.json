{
  "dataset_revision": "ffb8a34c9637fb20256e8c7be02504d16af4bd6b",
  "evaluation_time": 21.53956961631775,
  "kg_co2_emissions": 0.000638284189919179,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.59130859375,
        "f1": 0.5892900025601915,
        "f1_weighted": 0.5826215819779202,
        "hf_subset": "default",
        "languages": [
          "ory-Orya"
        ],
        "main_score": 0.5892900025601915,
        "scores_per_experiment": [
          {
            "accuracy": 0.5537109375,
            "f1": 0.5779065515861462,
            "f1_weighted": 0.5590905711565873
          },
          {
            "accuracy": 0.5849609375,
            "f1": 0.5633480898585542,
            "f1_weighted": 0.5650710106805691
          },
          {
            "accuracy": 0.5615234375,
            "f1": 0.5829657083093841,
            "f1_weighted": 0.5653055262825533
          },
          {
            "accuracy": 0.609375,
            "f1": 0.5843986158758135,
            "f1_weighted": 0.5886579266684435
          },
          {
            "accuracy": 0.62939453125,
            "f1": 0.5476433498628481,
            "f1_weighted": 0.5588708341781607
          },
          {
            "accuracy": 0.5732421875,
            "f1": 0.5992101024561726,
            "f1_weighted": 0.581767312789158
          },
          {
            "accuracy": 0.5810546875,
            "f1": 0.6006484787265988,
            "f1_weighted": 0.5851559663310765
          },
          {
            "accuracy": 0.64208984375,
            "f1": 0.6229196670689398,
            "f1_weighted": 0.630499226871677
          },
          {
            "accuracy": 0.58251953125,
            "f1": 0.6030611428534112,
            "f1_weighted": 0.5898717202362784
          },
          {
            "accuracy": 0.59521484375,
            "f1": 0.6107983190040475,
            "f1_weighted": 0.6019257245846981
          }
        ]
      }
    ]
  },
  "task_name": "OdiaNewsClassification"
}