{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 14.379089117050171,
  "kg_co2_emissions": 0.000415072253587021,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.5663461538461538,
        "f1": 0.4430672168755618,
        "f1_weighted": 0.615597863059912,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5663461538461538,
        "scores_per_experiment": [
          {
            "accuracy": 0.5961538461538461,
            "f1": 0.4610127069695803,
            "f1_weighted": 0.6378994994224103
          },
          {
            "accuracy": 0.6538461538461539,
            "f1": 0.49694847020933974,
            "f1_weighted": 0.6775706057227796
          },
          {
            "accuracy": 0.5961538461538461,
            "f1": 0.5015868978634936,
            "f1_weighted": 0.6637084412248078
          },
          {
            "accuracy": 0.625,
            "f1": 0.48366606170598914,
            "f1_weighted": 0.6864093257015218
          },
          {
            "accuracy": 0.6442307692307693,
            "f1": 0.4873697362069455,
            "f1_weighted": 0.6979787952059866
          },
          {
            "accuracy": 0.4807692307692308,
            "f1": 0.3688595118898623,
            "f1_weighted": 0.5202817624594847
          },
          {
            "accuracy": 0.5096153846153846,
            "f1": 0.40991678224687933,
            "f1_weighted": 0.5645044276112237
          },
          {
            "accuracy": 0.5288461538461539,
            "f1": 0.39715440779270567,
            "f1_weighted": 0.6019210327720965
          },
          {
            "accuracy": 0.47115384615384615,
            "f1": 0.3936447733580018,
            "f1_weighted": 0.5079335373229915
          },
          {
            "accuracy": 0.5576923076923077,
            "f1": 0.4305128205128205,
            "f1_weighted": 0.5977712031558186
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5742857142857143,
        "f1": 0.4329607323982092,
        "f1_weighted": 0.6230775743688799,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5742857142857143,
        "scores_per_experiment": [
          {
            "accuracy": 0.580952380952381,
            "f1": 0.46587698326450766,
            "f1_weighted": 0.6372155121557426
          },
          {
            "accuracy": 0.6190476190476191,
            "f1": 0.4662993265431068,
            "f1_weighted": 0.6652937793361904
          },
          {
            "accuracy": 0.5428571428571428,
            "f1": 0.40602621483375956,
            "f1_weighted": 0.6014425770308123
          },
          {
            "accuracy": 0.5619047619047619,
            "f1": 0.4384137426900585,
            "f1_weighted": 0.634676970203286
          },
          {
            "accuracy": 0.638095238095238,
            "f1": 0.46987087517934,
            "f1_weighted": 0.6730848436935749
          },
          {
            "accuracy": 0.6,
            "f1": 0.43734977023683286,
            "f1_weighted": 0.6284281842818428
          },
          {
            "accuracy": 0.6,
            "f1": 0.4848851464705123,
            "f1_weighted": 0.6642350164998249
          },
          {
            "accuracy": 0.5047619047619047,
            "f1": 0.34632708155726055,
            "f1_weighted": 0.5496856520385932
          },
          {
            "accuracy": 0.5047619047619047,
            "f1": 0.3762982251354344,
            "f1_weighted": 0.5543432373997158
          },
          {
            "accuracy": 0.5904761904761905,
            "f1": 0.4382599580712788,
            "f1_weighted": 0.6223699710492162
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}