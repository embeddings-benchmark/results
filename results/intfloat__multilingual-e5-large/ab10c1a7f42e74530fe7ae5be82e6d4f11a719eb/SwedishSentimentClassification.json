{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.38.3",
  "scores": {
    "validation": [
      {
        "accuracy": 0.933057,
        "f1": 0.932969,
        "f1_weighted": 0.932975,
        "ap": 0.896678,
        "ap_weighted": 0.896678,
        "scores_per_experiment": [
          {
            "accuracy": 0.937012,
            "f1": 0.936918,
            "f1_weighted": 0.936925,
            "ap": 0.897093,
            "ap_weighted": 0.897093
          },
          {
            "accuracy": 0.916504,
            "f1": 0.916284,
            "f1_weighted": 0.916296,
            "ap": 0.866834,
            "ap_weighted": 0.866834
          },
          {
            "accuracy": 0.959473,
            "f1": 0.959467,
            "f1_weighted": 0.959468,
            "ap": 0.937228,
            "ap_weighted": 0.937228
          },
          {
            "accuracy": 0.892578,
            "f1": 0.892574,
            "f1_weighted": 0.892573,
            "ap": 0.853734,
            "ap_weighted": 0.853734
          },
          {
            "accuracy": 0.943848,
            "f1": 0.943821,
            "f1_weighted": 0.943824,
            "ap": 0.911994,
            "ap_weighted": 0.911994
          },
          {
            "accuracy": 0.950684,
            "f1": 0.950681,
            "f1_weighted": 0.950682,
            "ap": 0.926959,
            "ap_weighted": 0.926959
          },
          {
            "accuracy": 0.925293,
            "f1": 0.925198,
            "f1_weighted": 0.925206,
            "ap": 0.882788,
            "ap_weighted": 0.882788
          },
          {
            "accuracy": 0.95459,
            "f1": 0.954573,
            "f1_weighted": 0.954576,
            "ap": 0.927739,
            "ap_weighted": 0.927739
          },
          {
            "accuracy": 0.943359,
            "f1": 0.943326,
            "f1_weighted": 0.94333,
            "ap": 0.910446,
            "ap_weighted": 0.910446
          },
          {
            "accuracy": 0.907227,
            "f1": 0.906851,
            "f1_weighted": 0.906869,
            "ap": 0.851961,
            "ap_weighted": 0.851961
          }
        ],
        "main_score": 0.933057,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.930518,
        "f1": 0.930438,
        "f1_weighted": 0.930442,
        "ap": 0.895646,
        "ap_weighted": 0.895646,
        "scores_per_experiment": [
          {
            "accuracy": 0.932129,
            "f1": 0.932052,
            "f1_weighted": 0.932056,
            "ap": 0.891883,
            "ap_weighted": 0.891883
          },
          {
            "accuracy": 0.918945,
            "f1": 0.918788,
            "f1_weighted": 0.918795,
            "ap": 0.871653,
            "ap_weighted": 0.871653
          },
          {
            "accuracy": 0.95752,
            "f1": 0.957519,
            "f1_weighted": 0.95752,
            "ap": 0.938447,
            "ap_weighted": 0.938447
          },
          {
            "accuracy": 0.888184,
            "f1": 0.888176,
            "f1_weighted": 0.888174,
            "ap": 0.848328,
            "ap_weighted": 0.848328
          },
          {
            "accuracy": 0.944336,
            "f1": 0.944331,
            "f1_weighted": 0.944332,
            "ap": 0.916767,
            "ap_weighted": 0.916767
          },
          {
            "accuracy": 0.946289,
            "f1": 0.946289,
            "f1_weighted": 0.946289,
            "ap": 0.923692,
            "ap_weighted": 0.923692
          },
          {
            "accuracy": 0.921875,
            "f1": 0.921821,
            "f1_weighted": 0.921825,
            "ap": 0.880897,
            "ap_weighted": 0.880897
          },
          {
            "accuracy": 0.949707,
            "f1": 0.949706,
            "f1_weighted": 0.949706,
            "ap": 0.925902,
            "ap_weighted": 0.925902
          },
          {
            "accuracy": 0.952637,
            "f1": 0.95262,
            "f1_weighted": 0.952621,
            "ap": 0.924596,
            "ap_weighted": 0.924596
          },
          {
            "accuracy": 0.893555,
            "f1": 0.893083,
            "f1_weighted": 0.893097,
            "ap": 0.834297,
            "ap_weighted": 0.834297
          }
        ],
        "main_score": 0.930518,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 32.784873247146606,
  "kg_co2_emissions": null
}