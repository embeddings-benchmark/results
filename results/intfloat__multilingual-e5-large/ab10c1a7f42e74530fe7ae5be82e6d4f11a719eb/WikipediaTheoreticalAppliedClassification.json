{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.26.4",
  "scores": {
    "test": [
      {
        "accuracy": 0.63156,
        "f1": 0.628731,
        "f1_weighted": 0.629707,
        "ap": 0.556124,
        "ap_weighted": 0.556124,
        "scores_per_experiment": [
          {
            "accuracy": 0.64533,
            "f1": 0.645327,
            "f1_weighted": 0.645388,
            "ap": 0.566366,
            "ap_weighted": 0.566366
          },
          {
            "accuracy": 0.652099,
            "f1": 0.652099,
            "f1_weighted": 0.65211,
            "ap": 0.571806,
            "ap_weighted": 0.571806
          },
          {
            "accuracy": 0.666495,
            "f1": 0.661059,
            "f1_weighted": 0.663531,
            "ap": 0.585777,
            "ap_weighted": 0.585777
          },
          {
            "accuracy": 0.63102,
            "f1": 0.620106,
            "f1_weighted": 0.623814,
            "ap": 0.554977,
            "ap_weighted": 0.554977
          },
          {
            "accuracy": 0.612768,
            "f1": 0.612234,
            "f1_weighted": 0.613062,
            "ap": 0.540958,
            "ap_weighted": 0.540958
          },
          {
            "accuracy": 0.650386,
            "f1": 0.650022,
            "f1_weighted": 0.650672,
            "ap": 0.570402,
            "ap_weighted": 0.570402
          },
          {
            "accuracy": 0.614996,
            "f1": 0.614545,
            "f1_weighted": 0.613786,
            "ap": 0.54378,
            "ap_weighted": 0.54378
          },
          {
            "accuracy": 0.607798,
            "f1": 0.607206,
            "f1_weighted": 0.608084,
            "ap": 0.537267,
            "ap_weighted": 0.537267
          },
          {
            "accuracy": 0.612682,
            "f1": 0.611194,
            "f1_weighted": 0.609809,
            "ap": 0.542646,
            "ap_weighted": 0.542646
          },
          {
            "accuracy": 0.622022,
            "f1": 0.613519,
            "f1_weighted": 0.61682,
            "ap": 0.547264,
            "ap_weighted": 0.547264
          }
        ],
        "main_score": 0.63156,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 393.9196517467499,
  "kg_co2_emissions": null
}