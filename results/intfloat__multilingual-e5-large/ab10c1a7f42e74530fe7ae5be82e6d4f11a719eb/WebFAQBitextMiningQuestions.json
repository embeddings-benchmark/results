{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQuestions",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 0.983306,
        "recall": 0.988506,
        "f1": 0.984948,
        "accuracy": 0.988506,
        "main_score": 0.984948,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.936946,
        "recall": 0.956033,
        "f1": 0.943032,
        "accuracy": 0.956033,
        "main_score": 0.943032,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.975311,
        "recall": 0.982573,
        "f1": 0.977697,
        "accuracy": 0.982573,
        "main_score": 0.977697,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.985005,
        "recall": 0.989676,
        "f1": 0.98648,
        "accuracy": 0.989676,
        "main_score": 0.98648,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.985436,
        "recall": 0.990162,
        "f1": 0.986979,
        "accuracy": 0.990162,
        "main_score": 0.986979,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.976671,
        "recall": 0.984127,
        "f1": 0.979076,
        "accuracy": 0.984127,
        "main_score": 0.979076,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.981447,
        "recall": 0.987121,
        "f1": 0.983287,
        "accuracy": 0.987121,
        "main_score": 0.983287,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.98839,
        "recall": 0.99226,
        "f1": 0.98968,
        "accuracy": 0.99226,
        "main_score": 0.98968,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.926007,
        "recall": 0.936264,
        "f1": 0.929304,
        "accuracy": 0.936264,
        "main_score": 0.929304,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.988095,
        "recall": 0.992063,
        "f1": 0.989418,
        "accuracy": 0.992063,
        "main_score": 0.989418,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.926272,
        "recall": 0.947536,
        "f1": 0.932819,
        "accuracy": 0.947536,
        "main_score": 0.932819,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.981481,
        "recall": 0.987205,
        "f1": 0.983389,
        "accuracy": 0.987205,
        "main_score": 0.983389,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.981455,
        "recall": 0.987324,
        "f1": 0.983333,
        "accuracy": 0.987324,
        "main_score": 0.983333,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.986924,
        "recall": 0.991283,
        "f1": 0.988377,
        "accuracy": 0.991283,
        "main_score": 0.988377,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.984302,
        "recall": 0.988991,
        "f1": 0.985831,
        "accuracy": 0.988991,
        "main_score": 0.985831,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.982159,
        "recall": 0.987805,
        "f1": 0.983966,
        "accuracy": 0.987805,
        "main_score": 0.983966,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.972559,
        "recall": 0.980936,
        "f1": 0.975303,
        "accuracy": 0.980936,
        "main_score": 0.975303,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.981625,
        "recall": 0.987427,
        "f1": 0.983559,
        "accuracy": 0.987427,
        "main_score": 0.983559,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.975788,
        "recall": 0.983108,
        "f1": 0.978041,
        "accuracy": 0.983108,
        "main_score": 0.978041,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.986034,
        "recall": 0.990689,
        "f1": 0.987585,
        "accuracy": 0.990689,
        "main_score": 0.987585,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.986857,
        "recall": 0.990857,
        "f1": 0.98819,
        "accuracy": 0.990857,
        "main_score": 0.98819,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.98503,
        "recall": 0.99002,
        "f1": 0.986693,
        "accuracy": 0.99002,
        "main_score": 0.986693,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.985991,
        "recall": 0.989902,
        "f1": 0.987278,
        "accuracy": 0.989902,
        "main_score": 0.987278,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.980177,
        "recall": 0.986474,
        "f1": 0.982198,
        "accuracy": 0.986474,
        "main_score": 0.982198,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.996472,
        "recall": 0.997648,
        "f1": 0.996864,
        "accuracy": 0.997648,
        "main_score": 0.996864,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.977798,
        "recall": 0.984672,
        "f1": 0.979976,
        "accuracy": 0.984672,
        "main_score": 0.979976,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.979282,
        "recall": 0.986188,
        "f1": 0.981584,
        "accuracy": 0.986188,
        "main_score": 0.981584,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.970687,
        "recall": 0.979767,
        "f1": 0.973671,
        "accuracy": 0.979767,
        "main_score": 0.973671,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.995208,
        "recall": 0.996805,
        "f1": 0.99574,
        "accuracy": 0.996805,
        "main_score": 0.99574,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.994275,
        "recall": 0.996183,
        "f1": 0.994911,
        "accuracy": 0.996183,
        "main_score": 0.994911,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.984449,
        "recall": 0.989632,
        "f1": 0.986177,
        "accuracy": 0.989632,
        "main_score": 0.986177,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.988959,
        "recall": 0.992639,
        "f1": 0.990186,
        "accuracy": 0.992639,
        "main_score": 0.990186,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.981941,
        "recall": 0.98796,
        "f1": 0.983947,
        "accuracy": 0.98796,
        "main_score": 0.983947,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.984791,
        "recall": 0.989861,
        "f1": 0.986481,
        "accuracy": 0.989861,
        "main_score": 0.986481,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.977477,
        "recall": 0.984556,
        "f1": 0.97973,
        "accuracy": 0.984556,
        "main_score": 0.97973,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.994819,
        "recall": 0.996546,
        "f1": 0.995394,
        "accuracy": 0.996546,
        "main_score": 0.995394,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.989766,
        "recall": 0.993177,
        "f1": 0.990903,
        "accuracy": 0.993177,
        "main_score": 0.990903,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.990114,
        "recall": 0.992716,
        "f1": 0.990982,
        "accuracy": 0.992716,
        "main_score": 0.990982,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.982538,
        "recall": 0.988359,
        "f1": 0.984478,
        "accuracy": 0.988359,
        "main_score": 0.984478,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.971993,
        "recall": 0.980231,
        "f1": 0.974739,
        "accuracy": 0.980231,
        "main_score": 0.974739,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.975743,
        "recall": 0.982786,
        "f1": 0.978091,
        "accuracy": 0.982786,
        "main_score": 0.978091,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.976223,
        "recall": 0.983446,
        "f1": 0.97854,
        "accuracy": 0.983446,
        "main_score": 0.97854,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.985923,
        "recall": 0.990094,
        "f1": 0.987313,
        "accuracy": 0.990094,
        "main_score": 0.987313,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.980463,
        "recall": 0.986975,
        "f1": 0.982634,
        "accuracy": 0.986975,
        "main_score": 0.982634,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.95393,
        "recall": 0.96748,
        "f1": 0.958333,
        "accuracy": 0.96748,
        "main_score": 0.958333,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.98263,
        "recall": 0.988186,
        "f1": 0.984459,
        "accuracy": 0.988186,
        "main_score": 0.984459,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.972684,
        "recall": 0.980998,
        "f1": 0.975455,
        "accuracy": 0.980998,
        "main_score": 0.975455,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.982056,
        "recall": 0.987226,
        "f1": 0.983729,
        "accuracy": 0.987226,
        "main_score": 0.983729,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.963736,
        "recall": 0.975824,
        "f1": 0.967766,
        "accuracy": 0.975824,
        "main_score": 0.967766,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.985088,
        "recall": 0.98964,
        "f1": 0.986552,
        "accuracy": 0.98964,
        "main_score": 0.986552,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.977826,
        "recall": 0.984114,
        "f1": 0.979799,
        "accuracy": 0.984114,
        "main_score": 0.979799,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.971182,
        "recall": 0.980392,
        "f1": 0.974153,
        "accuracy": 0.980392,
        "main_score": 0.974153,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.987288,
        "recall": 0.991525,
        "f1": 0.988701,
        "accuracy": 0.991525,
        "main_score": 0.988701,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.96994,
        "recall": 0.97996,
        "f1": 0.97328,
        "accuracy": 0.97996,
        "main_score": 0.97328,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.973397,
        "recall": 0.982265,
        "f1": 0.976353,
        "accuracy": 0.982265,
        "main_score": 0.976353,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.965232,
        "recall": 0.976821,
        "f1": 0.969095,
        "accuracy": 0.976821,
        "main_score": 0.969095,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.989967,
        "recall": 0.993311,
        "f1": 0.991081,
        "accuracy": 0.993311,
        "main_score": 0.991081,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.992823,
        "recall": 0.995215,
        "f1": 0.99362,
        "accuracy": 0.995215,
        "main_score": 0.99362,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.990811,
        "recall": 0.99358,
        "f1": 0.991692,
        "accuracy": 0.99358,
        "main_score": 0.991692,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.979575,
        "recall": 0.986166,
        "f1": 0.981723,
        "accuracy": 0.986166,
        "main_score": 0.981723,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.982597,
        "recall": 0.988164,
        "f1": 0.984438,
        "accuracy": 0.988164,
        "main_score": 0.984438,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.978084,
        "recall": 0.984709,
        "f1": 0.980122,
        "accuracy": 0.984709,
        "main_score": 0.980122,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.97957,
        "recall": 0.985856,
        "f1": 0.981666,
        "accuracy": 0.985856,
        "main_score": 0.981666,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.988371,
        "recall": 0.992193,
        "f1": 0.989632,
        "accuracy": 0.992193,
        "main_score": 0.989632,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.99014,
        "recall": 0.993085,
        "f1": 0.9911,
        "accuracy": 0.993085,
        "main_score": 0.9911,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.982689,
        "recall": 0.988459,
        "f1": 0.984612,
        "accuracy": 0.988459,
        "main_score": 0.984612,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.981888,
        "recall": 0.987817,
        "f1": 0.983837,
        "accuracy": 0.987817,
        "main_score": 0.983837,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.97503,
        "recall": 0.983198,
        "f1": 0.977737,
        "accuracy": 0.983198,
        "main_score": 0.977737,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.986762,
        "recall": 0.990862,
        "f1": 0.988129,
        "accuracy": 0.990862,
        "main_score": 0.988129,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.964592,
        "recall": 0.975547,
        "f1": 0.968153,
        "accuracy": 0.975547,
        "main_score": 0.968153,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.929705,
        "recall": 0.952381,
        "f1": 0.937075,
        "accuracy": 0.952381,
        "main_score": 0.937075,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.971949,
        "recall": 0.980731,
        "f1": 0.974809,
        "accuracy": 0.980731,
        "main_score": 0.974809,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.977686,
        "recall": 0.984589,
        "f1": 0.979906,
        "accuracy": 0.984589,
        "main_score": 0.979906,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.985687,
        "recall": 0.990298,
        "f1": 0.987184,
        "accuracy": 0.990298,
        "main_score": 0.987184,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.974615,
        "recall": 0.982507,
        "f1": 0.977206,
        "accuracy": 0.982507,
        "main_score": 0.977206,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.984227,
        "recall": 0.989161,
        "f1": 0.985844,
        "accuracy": 0.989161,
        "main_score": 0.985844,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.967802,
        "recall": 0.977557,
        "f1": 0.970956,
        "accuracy": 0.977557,
        "main_score": 0.970956,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.985331,
        "recall": 0.990125,
        "f1": 0.98692,
        "accuracy": 0.990125,
        "main_score": 0.98692,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.944765,
        "recall": 0.962536,
        "f1": 0.950528,
        "accuracy": 0.962536,
        "main_score": 0.950528,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.965759,
        "recall": 0.976402,
        "f1": 0.969219,
        "accuracy": 0.976402,
        "main_score": 0.969219,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.948289,
        "recall": 0.963702,
        "f1": 0.953196,
        "accuracy": 0.963702,
        "main_score": 0.953196,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.980258,
        "recall": 0.986708,
        "f1": 0.982408,
        "accuracy": 0.986708,
        "main_score": 0.982408,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.976008,
        "recall": 0.983566,
        "f1": 0.978482,
        "accuracy": 0.983566,
        "main_score": 0.978482,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.97954,
        "recall": 0.986039,
        "f1": 0.981659,
        "accuracy": 0.986039,
        "main_score": 0.981659,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.958299,
        "recall": 0.970615,
        "f1": 0.962178,
        "accuracy": 0.970615,
        "main_score": 0.962178,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.97254,
        "recall": 0.981023,
        "f1": 0.975254,
        "accuracy": 0.981023,
        "main_score": 0.975254,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.952098,
        "recall": 0.966746,
        "f1": 0.956849,
        "accuracy": 0.966746,
        "main_score": 0.956849,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.933548,
        "recall": 0.954984,
        "f1": 0.940514,
        "accuracy": 0.954984,
        "main_score": 0.940514,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.986804,
        "recall": 0.991202,
        "f1": 0.98827,
        "accuracy": 0.991202,
        "main_score": 0.98827,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.967213,
        "recall": 0.978142,
        "f1": 0.970856,
        "accuracy": 0.978142,
        "main_score": 0.970856,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.961538,
        "recall": 0.974359,
        "f1": 0.965812,
        "accuracy": 0.974359,
        "main_score": 0.965812,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.977347,
        "recall": 0.984716,
        "f1": 0.979803,
        "accuracy": 0.984716,
        "main_score": 0.979803,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.978372,
        "recall": 0.985294,
        "f1": 0.980617,
        "accuracy": 0.985294,
        "main_score": 0.980617,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.97787,
        "recall": 0.984896,
        "f1": 0.980172,
        "accuracy": 0.984896,
        "main_score": 0.980172,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.985367,
        "recall": 0.990179,
        "f1": 0.986954,
        "accuracy": 0.990179,
        "main_score": 0.986954,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.967758,
        "recall": 0.977501,
        "f1": 0.970921,
        "accuracy": 0.977501,
        "main_score": 0.970921,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.979083,
        "recall": 0.985868,
        "f1": 0.981298,
        "accuracy": 0.985868,
        "main_score": 0.981298,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.984516,
        "recall": 0.989489,
        "f1": 0.986136,
        "accuracy": 0.989489,
        "main_score": 0.986136,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.979727,
        "recall": 0.986184,
        "f1": 0.98184,
        "accuracy": 0.986184,
        "main_score": 0.98184,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.980609,
        "recall": 0.986842,
        "f1": 0.982629,
        "accuracy": 0.986842,
        "main_score": 0.982629,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.972841,
        "recall": 0.981371,
        "f1": 0.975629,
        "accuracy": 0.981371,
        "main_score": 0.975629,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.985476,
        "recall": 0.989945,
        "f1": 0.986922,
        "accuracy": 0.989945,
        "main_score": 0.986922,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.982983,
        "recall": 0.98855,
        "f1": 0.984812,
        "accuracy": 0.98855,
        "main_score": 0.984812,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.97899,
        "recall": 0.985836,
        "f1": 0.981232,
        "accuracy": 0.985836,
        "main_score": 0.981232,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.985978,
        "recall": 0.990396,
        "f1": 0.98745,
        "accuracy": 0.990396,
        "main_score": 0.98745,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.987994,
        "recall": 0.991785,
        "f1": 0.989258,
        "accuracy": 0.991785,
        "main_score": 0.989258,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.978079,
        "recall": 0.985129,
        "f1": 0.980392,
        "accuracy": 0.985129,
        "main_score": 0.980392,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.96896,
        "recall": 0.978612,
        "f1": 0.972074,
        "accuracy": 0.978612,
        "main_score": 0.972074,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.978532,
        "recall": 0.98536,
        "f1": 0.980732,
        "accuracy": 0.98536,
        "main_score": 0.980732,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.987556,
        "recall": 0.991407,
        "f1": 0.98884,
        "accuracy": 0.991407,
        "main_score": 0.98884,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.981894,
        "recall": 0.987929,
        "f1": 0.983906,
        "accuracy": 0.987929,
        "main_score": 0.983906,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.982767,
        "recall": 0.988329,
        "f1": 0.98461,
        "accuracy": 0.988329,
        "main_score": 0.98461,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.992334,
        "recall": 0.994889,
        "f1": 0.993186,
        "accuracy": 0.994889,
        "main_score": 0.993186,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.99735,
        "recall": 0.998233,
        "f1": 0.997644,
        "accuracy": 0.998233,
        "main_score": 0.997644,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.987705,
        "recall": 0.991803,
        "f1": 0.989071,
        "accuracy": 0.991803,
        "main_score": 0.989071,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.995122,
        "recall": 0.996748,
        "f1": 0.995664,
        "accuracy": 0.996748,
        "main_score": 0.995664,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.994495,
        "recall": 0.99633,
        "f1": 0.995107,
        "accuracy": 0.99633,
        "main_score": 0.995107,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.979012,
        "recall": 0.985185,
        "f1": 0.980864,
        "accuracy": 0.985185,
        "main_score": 0.980864,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.985437,
        "recall": 0.990291,
        "f1": 0.987055,
        "accuracy": 0.990291,
        "main_score": 0.987055,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.985395,
        "recall": 0.989691,
        "f1": 0.986684,
        "accuracy": 0.989691,
        "main_score": 0.986684,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.970098,
        "recall": 0.979412,
        "f1": 0.973039,
        "accuracy": 0.979412,
        "main_score": 0.973039,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.977215,
        "recall": 0.98481,
        "f1": 0.979747,
        "accuracy": 0.98481,
        "main_score": 0.979747,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.988131,
        "recall": 0.991098,
        "f1": 0.98912,
        "accuracy": 0.991098,
        "main_score": 0.98912,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.978815,
        "recall": 0.985733,
        "f1": 0.981085,
        "accuracy": 0.985733,
        "main_score": 0.981085,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.968679,
        "recall": 0.978413,
        "f1": 0.971797,
        "accuracy": 0.978413,
        "main_score": 0.971797,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.995025,
        "recall": 0.996683,
        "f1": 0.995578,
        "accuracy": 0.996683,
        "main_score": 0.995578,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.994514,
        "recall": 0.996342,
        "f1": 0.995123,
        "accuracy": 0.996342,
        "main_score": 0.995123,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.993671,
        "recall": 0.995781,
        "f1": 0.994374,
        "accuracy": 0.995781,
        "main_score": 0.994374,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.987703,
        "recall": 0.991319,
        "f1": 0.98886,
        "accuracy": 0.991319,
        "main_score": 0.98886,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.990375,
        "recall": 0.993377,
        "f1": 0.991347,
        "accuracy": 0.993377,
        "main_score": 0.991347,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.985668,
        "recall": 0.990248,
        "f1": 0.987182,
        "accuracy": 0.990248,
        "main_score": 0.987182,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.97862,
        "recall": 0.98522,
        "f1": 0.980765,
        "accuracy": 0.98522,
        "main_score": 0.980765,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.987366,
        "recall": 0.991398,
        "f1": 0.988674,
        "accuracy": 0.991398,
        "main_score": 0.988674,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.984106,
        "recall": 0.989404,
        "f1": 0.985872,
        "accuracy": 0.989404,
        "main_score": 0.985872,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 0.994604,
        "recall": 0.996403,
        "f1": 0.995204,
        "accuracy": 0.996403,
        "main_score": 0.995204,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.978057,
        "recall": 0.984606,
        "f1": 0.980124,
        "accuracy": 0.984606,
        "main_score": 0.980124,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.967069,
        "recall": 0.977102,
        "f1": 0.970324,
        "accuracy": 0.977102,
        "main_score": 0.970324,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.966742,
        "recall": 0.977324,
        "f1": 0.970144,
        "accuracy": 0.977324,
        "main_score": 0.970144,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.986706,
        "recall": 0.990987,
        "f1": 0.988133,
        "accuracy": 0.990987,
        "main_score": 0.988133,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.991991,
        "recall": 0.994508,
        "f1": 0.99283,
        "accuracy": 0.994508,
        "main_score": 0.99283,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.989143,
        "recall": 0.992762,
        "f1": 0.990349,
        "accuracy": 0.992762,
        "main_score": 0.990349,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.954004,
        "recall": 0.96648,
        "f1": 0.957635,
        "accuracy": 0.96648,
        "main_score": 0.957635,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.973274,
        "recall": 0.981791,
        "f1": 0.976051,
        "accuracy": 0.981791,
        "main_score": 0.976051,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.985991,
        "recall": 0.990281,
        "f1": 0.987392,
        "accuracy": 0.990281,
        "main_score": 0.987392,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.978324,
        "recall": 0.985549,
        "f1": 0.980732,
        "accuracy": 0.985549,
        "main_score": 0.980732,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.982701,
        "recall": 0.988272,
        "f1": 0.984519,
        "accuracy": 0.988272,
        "main_score": 0.984519,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.981928,
        "recall": 0.987952,
        "f1": 0.983936,
        "accuracy": 0.987952,
        "main_score": 0.983936,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.979747,
        "recall": 0.986498,
        "f1": 0.981997,
        "accuracy": 0.986498,
        "main_score": 0.981997,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.993603,
        "recall": 0.995736,
        "f1": 0.994314,
        "accuracy": 0.995736,
        "main_score": 0.994314,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.972213,
        "recall": 0.980913,
        "f1": 0.975038,
        "accuracy": 0.980913,
        "main_score": 0.975038,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.994499,
        "recall": 0.996249,
        "f1": 0.995061,
        "accuracy": 0.996249,
        "main_score": 0.995061,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.982751,
        "recall": 0.988206,
        "f1": 0.984518,
        "accuracy": 0.988206,
        "main_score": 0.984518,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.988303,
        "recall": 0.991939,
        "f1": 0.98948,
        "accuracy": 0.991939,
        "main_score": 0.98948,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.990841,
        "recall": 0.993748,
        "f1": 0.991774,
        "accuracy": 0.993748,
        "main_score": 0.991774,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.97971,
        "recall": 0.986004,
        "f1": 0.981756,
        "accuracy": 0.986004,
        "main_score": 0.981756,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.989578,
        "recall": 0.992869,
        "f1": 0.990675,
        "accuracy": 0.992869,
        "main_score": 0.990675,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.98092,
        "recall": 0.986897,
        "f1": 0.982874,
        "accuracy": 0.986897,
        "main_score": 0.982874,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.966915,
        "recall": 0.976782,
        "f1": 0.970083,
        "accuracy": 0.976782,
        "main_score": 0.970083,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.99505,
        "recall": 0.9967,
        "f1": 0.9956,
        "accuracy": 0.9967,
        "main_score": 0.9956,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.984027,
        "recall": 0.989176,
        "f1": 0.985717,
        "accuracy": 0.989176,
        "main_score": 0.985717,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.983666,
        "recall": 0.989111,
        "f1": 0.985481,
        "accuracy": 0.989111,
        "main_score": 0.985481,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.97973,
        "recall": 0.985258,
        "f1": 0.981572,
        "accuracy": 0.985258,
        "main_score": 0.981572,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.984694,
        "recall": 0.989796,
        "f1": 0.986395,
        "accuracy": 0.989796,
        "main_score": 0.986395,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.979266,
        "recall": 0.985707,
        "f1": 0.981383,
        "accuracy": 0.985707,
        "main_score": 0.981383,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.966418,
        "recall": 0.977612,
        "f1": 0.970149,
        "accuracy": 0.977612,
        "main_score": 0.970149,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.991957,
        "recall": 0.994462,
        "f1": 0.992748,
        "accuracy": 0.994462,
        "main_score": 0.992748,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.974514,
        "recall": 0.982254,
        "f1": 0.976991,
        "accuracy": 0.982254,
        "main_score": 0.976991,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 5056.414281606674,
  "kg_co2_emissions": null
}