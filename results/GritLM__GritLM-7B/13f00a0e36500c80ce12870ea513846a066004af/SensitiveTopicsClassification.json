{
  "dataset_revision": "416b34a802308eac30e4192afc0ff99bb8dcc7f2",
  "evaluation_time": 16.870494842529297,
  "kg_co2_emissions": 0.004086750261287337,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.332421875,
        "f1": 0.4090465744271413,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "lrap": 0.5319118923611074,
        "main_score": 0.332421875,
        "scores_per_experiment": [
          {
            "accuracy": 0.31982421875,
            "f1": 0.36613098043190645,
            "lrap": 0.491075303819437
          },
          {
            "accuracy": 0.31689453125,
            "f1": 0.4136446375785791,
            "lrap": 0.5266113281249959
          },
          {
            "accuracy": 0.31298828125,
            "f1": 0.3686166629177195,
            "lrap": 0.4991590711805484
          },
          {
            "accuracy": 0.33544921875,
            "f1": 0.39899367834536237,
            "lrap": 0.5114746093749939
          },
          {
            "accuracy": 0.33251953125,
            "f1": 0.42638336881965705,
            "lrap": 0.5359768337673576
          },
          {
            "accuracy": 0.35693359375,
            "f1": 0.43454464136665494,
            "lrap": 0.5677354600694441
          },
          {
            "accuracy": 0.35498046875,
            "f1": 0.41620922816949574,
            "lrap": 0.5410427517361083
          },
          {
            "accuracy": 0.32470703125,
            "f1": 0.40743156814065934,
            "lrap": 0.5290052625868018
          },
          {
            "accuracy": 0.34619140625,
            "f1": 0.4354545780082219,
            "lrap": 0.5702175564236106
          },
          {
            "accuracy": 0.32373046875,
            "f1": 0.4230564004931569,
            "lrap": 0.5468207465277756
          }
        ]
      }
    ]
  },
  "task_name": "SensitiveTopicsClassification"
}