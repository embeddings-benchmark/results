{
  "dataset_revision": "5911f26666ac11af46cb9c6849d0dc80a378af24",
  "evaluation_time": 36.761512756347656,
  "kg_co2_emissions": 0.008792799565897578,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.6914666666666667,
        "f1": 0.6642884178770301,
        "f1_weighted": 0.6642884178770301,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.6914666666666667,
        "scores_per_experiment": [
          {
            "accuracy": 0.6733333333333333,
            "f1": 0.642832565001915,
            "f1_weighted": 0.6428325650019151
          },
          {
            "accuracy": 0.6373333333333333,
            "f1": 0.5687524088450674,
            "f1_weighted": 0.5687524088450673
          },
          {
            "accuracy": 0.7093333333333334,
            "f1": 0.6877318611220148,
            "f1_weighted": 0.6877318611220148
          },
          {
            "accuracy": 0.69,
            "f1": 0.6619129578635038,
            "f1_weighted": 0.6619129578635038
          },
          {
            "accuracy": 0.694,
            "f1": 0.6780558926212752,
            "f1_weighted": 0.6780558926212752
          },
          {
            "accuracy": 0.7033333333333334,
            "f1": 0.6837738970762802,
            "f1_weighted": 0.6837738970762801
          },
          {
            "accuracy": 0.684,
            "f1": 0.6547264739229025,
            "f1_weighted": 0.6547264739229025
          },
          {
            "accuracy": 0.7026666666666667,
            "f1": 0.6889107616392005,
            "f1_weighted": 0.6889107616392005
          },
          {
            "accuracy": 0.708,
            "f1": 0.6825875780282934,
            "f1_weighted": 0.6825875780282934
          },
          {
            "accuracy": 0.7126666666666667,
            "f1": 0.6935997826498485,
            "f1_weighted": 0.6935997826498485
          }
        ]
      }
    ]
  },
  "task_name": "KinopoiskClassification"
}