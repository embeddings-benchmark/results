{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "map": 0.687399,
        "mrr": 0.687399,
        "nAUC_map_max": 0.399574,
        "nAUC_map_std": 0.362645,
        "nAUC_map_diff1": 0.575885,
        "nAUC_mrr_max": 0.399574,
        "nAUC_mrr_std": 0.362645,
        "nAUC_mrr_diff1": 0.575885,
        "main_score": 0.687399,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.538338,
        "mrr": 0.538338,
        "nAUC_map_max": 0.282479,
        "nAUC_map_std": 0.061583,
        "nAUC_map_diff1": 0.316646,
        "nAUC_mrr_max": 0.282479,
        "nAUC_mrr_std": 0.061583,
        "nAUC_mrr_diff1": 0.316646,
        "main_score": 0.538338,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.797531,
        "mrr": 0.797531,
        "nAUC_map_max": 0.447663,
        "nAUC_map_std": 0.419069,
        "nAUC_map_diff1": 0.672902,
        "nAUC_mrr_max": 0.447663,
        "nAUC_mrr_std": 0.419069,
        "nAUC_mrr_diff1": 0.672902,
        "main_score": 0.797531,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.824792,
        "mrr": 0.824958,
        "nAUC_map_max": 0.456361,
        "nAUC_map_std": 0.377992,
        "nAUC_map_diff1": 0.720787,
        "nAUC_mrr_max": 0.458002,
        "nAUC_mrr_std": 0.377753,
        "nAUC_mrr_diff1": 0.720863,
        "main_score": 0.824792,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.834812,
        "mrr": 0.834812,
        "nAUC_map_max": 0.479326,
        "nAUC_map_std": 0.376383,
        "nAUC_map_diff1": 0.754229,
        "nAUC_mrr_max": 0.479326,
        "nAUC_mrr_std": 0.376383,
        "nAUC_mrr_diff1": 0.754229,
        "main_score": 0.834812,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.925855,
        "mrr": 0.925855,
        "nAUC_map_max": 0.580145,
        "nAUC_map_std": 0.414041,
        "nAUC_map_diff1": 0.842266,
        "nAUC_mrr_max": 0.580145,
        "nAUC_mrr_std": 0.414041,
        "nAUC_mrr_diff1": 0.842266,
        "main_score": 0.925855,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.671295,
        "mrr": 0.671295,
        "nAUC_map_max": 0.467456,
        "nAUC_map_std": 0.224583,
        "nAUC_map_diff1": 0.52802,
        "nAUC_mrr_max": 0.467456,
        "nAUC_mrr_std": 0.224583,
        "nAUC_mrr_diff1": 0.52802,
        "main_score": 0.671295,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.779968,
        "mrr": 0.779968,
        "nAUC_map_max": 0.407871,
        "nAUC_map_std": 0.346013,
        "nAUC_map_diff1": 0.68875,
        "nAUC_mrr_max": 0.407871,
        "nAUC_mrr_std": 0.346013,
        "nAUC_mrr_diff1": 0.68875,
        "main_score": 0.779968,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.574294,
        "mrr": 0.575303,
        "nAUC_map_max": 0.357196,
        "nAUC_map_std": 0.197689,
        "nAUC_map_diff1": 0.367701,
        "nAUC_mrr_max": 0.356712,
        "nAUC_mrr_std": 0.199019,
        "nAUC_mrr_diff1": 0.363891,
        "main_score": 0.574294,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.848742,
        "mrr": 0.848742,
        "nAUC_map_max": 0.548521,
        "nAUC_map_std": 0.480844,
        "nAUC_map_diff1": 0.781177,
        "nAUC_mrr_max": 0.548521,
        "nAUC_mrr_std": 0.480844,
        "nAUC_mrr_diff1": 0.781177,
        "main_score": 0.848742,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.804877,
        "mrr": 0.805211,
        "nAUC_map_max": 0.374416,
        "nAUC_map_std": 0.391463,
        "nAUC_map_diff1": 0.721923,
        "nAUC_mrr_max": 0.375147,
        "nAUC_mrr_std": 0.395241,
        "nAUC_mrr_diff1": 0.720764,
        "main_score": 0.804877,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.854747,
        "mrr": 0.854747,
        "nAUC_map_max": 0.473251,
        "nAUC_map_std": 0.394114,
        "nAUC_map_diff1": 0.723838,
        "nAUC_mrr_max": 0.473251,
        "nAUC_mrr_std": 0.394114,
        "nAUC_mrr_diff1": 0.723838,
        "main_score": 0.854747,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.836009,
        "mrr": 0.836343,
        "nAUC_map_max": 0.558053,
        "nAUC_map_std": 0.429139,
        "nAUC_map_diff1": 0.78489,
        "nAUC_mrr_max": 0.55701,
        "nAUC_mrr_std": 0.428592,
        "nAUC_mrr_diff1": 0.783921,
        "main_score": 0.836009,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.677454,
        "mrr": 0.677788,
        "nAUC_map_max": 0.301966,
        "nAUC_map_std": 0.337628,
        "nAUC_map_diff1": 0.578096,
        "nAUC_mrr_max": 0.303676,
        "nAUC_mrr_std": 0.338557,
        "nAUC_mrr_diff1": 0.57702,
        "main_score": 0.677454,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.802791,
        "mrr": 0.802791,
        "nAUC_map_max": 0.49325,
        "nAUC_map_std": 0.414389,
        "nAUC_map_diff1": 0.670839,
        "nAUC_mrr_max": 0.49325,
        "nAUC_mrr_std": 0.414389,
        "nAUC_mrr_diff1": 0.670839,
        "main_score": 0.802791,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.835333,
        "mrr": 0.835333,
        "nAUC_map_max": 0.428989,
        "nAUC_map_std": 0.373724,
        "nAUC_map_diff1": 0.695196,
        "nAUC_mrr_max": 0.428989,
        "nAUC_mrr_std": 0.373724,
        "nAUC_mrr_diff1": 0.695196,
        "main_score": 0.835333,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 1262.584585905075,
  "kg_co2_emissions": 0.05660506572238623
}