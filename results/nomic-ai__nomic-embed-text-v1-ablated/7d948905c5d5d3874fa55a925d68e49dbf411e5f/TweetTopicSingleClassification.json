{
  "dataset_revision": "87b7a0d1c402dbb481db649569c556d9aa27ac05",
  "task_name": "TweetTopicSingleClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test_2021": [
      {
        "accuracy": 0.613585,
        "f1": 0.471704,
        "f1_weighted": 0.64943,
        "scores_per_experiment": [
          {
            "accuracy": 0.530419,
            "f1": 0.423743,
            "f1_weighted": 0.580727
          },
          {
            "accuracy": 0.604843,
            "f1": 0.498589,
            "f1_weighted": 0.634088
          },
          {
            "accuracy": 0.606025,
            "f1": 0.477386,
            "f1_weighted": 0.645347
          },
          {
            "accuracy": 0.616066,
            "f1": 0.498604,
            "f1_weighted": 0.654486
          },
          {
            "accuracy": 0.616066,
            "f1": 0.479046,
            "f1_weighted": 0.656526
          },
          {
            "accuracy": 0.633196,
            "f1": 0.483947,
            "f1_weighted": 0.666002
          },
          {
            "accuracy": 0.614294,
            "f1": 0.432323,
            "f1_weighted": 0.654495
          },
          {
            "accuracy": 0.652688,
            "f1": 0.506615,
            "f1_weighted": 0.681478
          },
          {
            "accuracy": 0.607206,
            "f1": 0.44018,
            "f1_weighted": 0.642522
          },
          {
            "accuracy": 0.65505,
            "f1": 0.476608,
            "f1_weighted": 0.678625
          }
        ],
        "main_score": 0.613585,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.067134857177734,
  "kg_co2_emissions": 0.000509687756247594
}