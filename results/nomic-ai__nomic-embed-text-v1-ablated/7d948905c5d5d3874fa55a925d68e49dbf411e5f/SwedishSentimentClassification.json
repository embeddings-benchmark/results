{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.70542,
        "f1": 0.703646,
        "f1_weighted": 0.703671,
        "ap": 0.645219,
        "ap_weighted": 0.645219,
        "scores_per_experiment": [
          {
            "accuracy": 0.729004,
            "f1": 0.727361,
            "f1_weighted": 0.727423,
            "ap": 0.661144,
            "ap_weighted": 0.661144
          },
          {
            "accuracy": 0.700195,
            "f1": 0.699714,
            "f1_weighted": 0.699679,
            "ap": 0.645255,
            "ap_weighted": 0.645255
          },
          {
            "accuracy": 0.675293,
            "f1": 0.674833,
            "f1_weighted": 0.674798,
            "ap": 0.622446,
            "ap_weighted": 0.622446
          },
          {
            "accuracy": 0.70752,
            "f1": 0.707338,
            "f1_weighted": 0.707317,
            "ap": 0.650626,
            "ap_weighted": 0.650626
          },
          {
            "accuracy": 0.744141,
            "f1": 0.744,
            "f1_weighted": 0.743982,
            "ap": 0.686155,
            "ap_weighted": 0.686155
          },
          {
            "accuracy": 0.640137,
            "f1": 0.638064,
            "f1_weighted": 0.638144,
            "ap": 0.588422,
            "ap_weighted": 0.588422
          },
          {
            "accuracy": 0.741699,
            "f1": 0.73962,
            "f1_weighted": 0.739688,
            "ap": 0.67162,
            "ap_weighted": 0.67162
          },
          {
            "accuracy": 0.708984,
            "f1": 0.700332,
            "f1_weighted": 0.700481,
            "ap": 0.638129,
            "ap_weighted": 0.638129
          },
          {
            "accuracy": 0.678223,
            "f1": 0.677342,
            "f1_weighted": 0.677293,
            "ap": 0.6262,
            "ap_weighted": 0.6262
          },
          {
            "accuracy": 0.729004,
            "f1": 0.727856,
            "f1_weighted": 0.727908,
            "ap": 0.662198,
            "ap_weighted": 0.662198
          }
        ],
        "main_score": 0.70542,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.697217,
        "f1": 0.695496,
        "f1_weighted": 0.695512,
        "ap": 0.63779,
        "ap_weighted": 0.63779,
        "scores_per_experiment": [
          {
            "accuracy": 0.717285,
            "f1": 0.7159,
            "f1_weighted": 0.715939,
            "ap": 0.650918,
            "ap_weighted": 0.650918
          },
          {
            "accuracy": 0.721191,
            "f1": 0.720893,
            "f1_weighted": 0.720875,
            "ap": 0.663995,
            "ap_weighted": 0.663995
          },
          {
            "accuracy": 0.66748,
            "f1": 0.666823,
            "f1_weighted": 0.666794,
            "ap": 0.615585,
            "ap_weighted": 0.615585
          },
          {
            "accuracy": 0.698242,
            "f1": 0.697848,
            "f1_weighted": 0.697826,
            "ap": 0.642533,
            "ap_weighted": 0.642533
          },
          {
            "accuracy": 0.73291,
            "f1": 0.732688,
            "f1_weighted": 0.732673,
            "ap": 0.67506,
            "ap_weighted": 0.67506
          },
          {
            "accuracy": 0.637207,
            "f1": 0.634157,
            "f1_weighted": 0.634222,
            "ap": 0.585365,
            "ap_weighted": 0.585365
          },
          {
            "accuracy": 0.724609,
            "f1": 0.722368,
            "f1_weighted": 0.722417,
            "ap": 0.655881,
            "ap_weighted": 0.655881
          },
          {
            "accuracy": 0.708496,
            "f1": 0.700284,
            "f1_weighted": 0.700381,
            "ap": 0.637606,
            "ap_weighted": 0.637606
          },
          {
            "accuracy": 0.656738,
            "f1": 0.656371,
            "f1_weighted": 0.656349,
            "ap": 0.605691,
            "ap_weighted": 0.605691
          },
          {
            "accuracy": 0.708008,
            "f1": 0.707626,
            "f1_weighted": 0.707647,
            "ap": 0.645266,
            "ap_weighted": 0.645266
          }
        ],
        "main_score": 0.697217,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 23.926822900772095,
  "kg_co2_emissions": 0.0011126741507308541
}