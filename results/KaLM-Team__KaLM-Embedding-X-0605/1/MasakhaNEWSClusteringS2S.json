{
  "dataset_revision": "8ccc72e69e65f40c70e117d8b3c08306bb788b60",
  "task_name": "MasakhaNEWSClusteringS2S",
  "mteb_version": "1.38.29",
  "scores": {
    "test": [
      {
        "v_measure": 0.688248,
        "v_measure_std": 0.326657,
        "v_measures": [
          1.0,
          0.147303,
          0.500141,
          0.793798,
          1.0
        ],
        "main_score": 0.688248,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ]
      },
      {
        "v_measure": 0.679466,
        "v_measure_std": 0.344611,
        "v_measures": [
          0.018085,
          0.739939,
          0.746667,
          1.0,
          0.89264
        ],
        "main_score": 0.679466,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "v_measure": 0.69959,
        "v_measure_std": 0.365218,
        "v_measures": [
          1.0,
          0.006489,
          0.715892,
          1.0,
          0.775569
        ],
        "main_score": 0.69959,
        "hf_subset": "fra",
        "languages": [
          "fra-Latn"
        ]
      },
      {
        "v_measure": 0.731849,
        "v_measure_std": 0.163259,
        "v_measures": [
          0.718728,
          0.668878,
          0.469769,
          0.860531,
          0.941337
        ],
        "main_score": 0.731849,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ]
      },
      {
        "v_measure": 0.742433,
        "v_measure_std": 0.216963,
        "v_measures": [
          0.378974,
          0.80738,
          0.88913,
          1.0,
          0.636683
        ],
        "main_score": 0.742433,
        "hf_subset": "ibo",
        "languages": [
          "ibo-Latn"
        ]
      },
      {
        "v_measure": 0.864935,
        "v_measure_std": 0.172212,
        "v_measures": [
          0.738051,
          0.586624,
          1.0,
          1.0,
          1.0
        ],
        "main_score": 0.864935,
        "hf_subset": "lin",
        "languages": [
          "lin-Latn"
        ]
      },
      {
        "v_measure": 0.518788,
        "v_measure_std": 0.407481,
        "v_measures": [
          0.001923,
          0.314235,
          1.0,
          1.0,
          0.277783
        ],
        "main_score": 0.518788,
        "hf_subset": "lug",
        "languages": [
          "lug-Latn"
        ]
      },
      {
        "v_measure": 0.393611,
        "v_measure_std": 0.327953,
        "v_measures": [
          0.41235,
          0.037947,
          1.0,
          0.317641,
          0.200116
        ],
        "main_score": 0.393611,
        "hf_subset": "orm",
        "languages": [
          "orm-Ethi"
        ]
      },
      {
        "v_measure": 0.873701,
        "v_measure_std": 0.187667,
        "v_measures": [
          1.0,
          0.852268,
          0.516238,
          1.0,
          1.0
        ],
        "main_score": 0.873701,
        "hf_subset": "pcm",
        "languages": [
          "pcm-Latn"
        ]
      },
      {
        "v_measure": 0.663344,
        "v_measure_std": 0.278607,
        "v_measures": [
          0.411899,
          0.384493,
          1.0,
          0.52033,
          1.0
        ],
        "main_score": 0.663344,
        "hf_subset": "run",
        "languages": [
          "run-Latn"
        ]
      },
      {
        "v_measure": 0.836319,
        "v_measure_std": 0.153612,
        "v_measures": [
          1.0,
          0.625702,
          0.696625,
          0.859268,
          1.0
        ],
        "main_score": 0.836319,
        "hf_subset": "sna",
        "languages": [
          "sna-Latn"
        ]
      },
      {
        "v_measure": 0.454381,
        "v_measure_std": 0.281492,
        "v_measures": [
          0.304997,
          1.0,
          0.424035,
          0.206954,
          0.335918
        ],
        "main_score": 0.454381,
        "hf_subset": "som",
        "languages": [
          "som-Latn"
        ]
      },
      {
        "v_measure": 0.383525,
        "v_measure_std": 0.289619,
        "v_measures": [
          0.367288,
          0.104579,
          0.027334,
          0.675254,
          0.74317
        ],
        "main_score": 0.383525,
        "hf_subset": "swa",
        "languages": [
          "swa-Latn"
        ]
      },
      {
        "v_measure": 0.581648,
        "v_measure_std": 0.381208,
        "v_measures": [
          0.296465,
          1.0,
          0.038358,
          1.0,
          0.573416
        ],
        "main_score": 0.581648,
        "hf_subset": "tir",
        "languages": [
          "tir-Ethi"
        ]
      },
      {
        "v_measure": 0.33241,
        "v_measure_std": 0.347481,
        "v_measures": [
          0.250649,
          0.108527,
          0.285093,
          0.017782,
          1.0
        ],
        "main_score": 0.33241,
        "hf_subset": "xho",
        "languages": [
          "xho-Latn"
        ]
      },
      {
        "v_measure": 0.760047,
        "v_measure_std": 0.137904,
        "v_measures": [
          1.0,
          0.59862,
          0.812649,
          0.687872,
          0.701095
        ],
        "main_score": 0.760047,
        "hf_subset": "yor",
        "languages": [
          "yor-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 43.73047661781311,
  "kg_co2_emissions": null
}