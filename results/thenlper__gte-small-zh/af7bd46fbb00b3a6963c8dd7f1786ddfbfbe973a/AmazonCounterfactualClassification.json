{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.629614,
        "f1": 0.610452,
        "f1_weighted": 0.643787,
        "ap": 0.769663,
        "ap_weighted": 0.769663,
        "scores_per_experiment": [
          {
            "accuracy": 0.643777,
            "f1": 0.622757,
            "f1_weighted": 0.657918,
            "ap": 0.772681,
            "ap_weighted": 0.772681
          },
          {
            "accuracy": 0.620172,
            "f1": 0.585374,
            "f1_weighted": 0.632802,
            "ap": 0.743537,
            "ap_weighted": 0.743537
          },
          {
            "accuracy": 0.650215,
            "f1": 0.638176,
            "f1_weighted": 0.664236,
            "ap": 0.793519,
            "ap_weighted": 0.793519
          },
          {
            "accuracy": 0.671674,
            "f1": 0.651925,
            "f1_weighted": 0.684662,
            "ap": 0.791256,
            "ap_weighted": 0.791256
          },
          {
            "accuracy": 0.618026,
            "f1": 0.607016,
            "f1_weighted": 0.632988,
            "ap": 0.775237,
            "ap_weighted": 0.775237
          },
          {
            "accuracy": 0.641631,
            "f1": 0.629297,
            "f1_weighted": 0.655996,
            "ap": 0.7873,
            "ap_weighted": 0.7873
          },
          {
            "accuracy": 0.660944,
            "f1": 0.644577,
            "f1_weighted": 0.674693,
            "ap": 0.790981,
            "ap_weighted": 0.790981
          },
          {
            "accuracy": 0.530043,
            "f1": 0.513869,
            "f1_weighted": 0.548881,
            "ap": 0.716368,
            "ap_weighted": 0.716368
          },
          {
            "accuracy": 0.648069,
            "f1": 0.612045,
            "f1_weighted": 0.658724,
            "ap": 0.756871,
            "ap_weighted": 0.756871
          },
          {
            "accuracy": 0.611588,
            "f1": 0.599487,
            "f1_weighted": 0.626975,
            "ap": 0.768879,
            "ap_weighted": 0.768879
          }
        ],
        "main_score": 0.629614,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.613704,
        "f1": 0.596539,
        "f1_weighted": 0.628167,
        "ap": 0.761176,
        "ap_weighted": 0.761176,
        "scores_per_experiment": [
          {
            "accuracy": 0.633833,
            "f1": 0.61511,
            "f1_weighted": 0.648375,
            "ap": 0.768583,
            "ap_weighted": 0.768583
          },
          {
            "accuracy": 0.601713,
            "f1": 0.570976,
            "f1_weighted": 0.615975,
            "ap": 0.736137,
            "ap_weighted": 0.736137
          },
          {
            "accuracy": 0.62848,
            "f1": 0.615595,
            "f1_weighted": 0.643173,
            "ap": 0.775834,
            "ap_weighted": 0.775834
          },
          {
            "accuracy": 0.655246,
            "f1": 0.63689,
            "f1_weighted": 0.668882,
            "ap": 0.781958,
            "ap_weighted": 0.781958
          },
          {
            "accuracy": 0.571734,
            "f1": 0.564051,
            "f1_weighted": 0.586731,
            "ap": 0.751832,
            "ap_weighted": 0.751832
          },
          {
            "accuracy": 0.619914,
            "f1": 0.610791,
            "f1_weighted": 0.634142,
            "ap": 0.778962,
            "ap_weighted": 0.778962
          },
          {
            "accuracy": 0.637045,
            "f1": 0.618675,
            "f1_weighted": 0.651472,
            "ap": 0.771048,
            "ap_weighted": 0.771048
          },
          {
            "accuracy": 0.540685,
            "f1": 0.531753,
            "f1_weighted": 0.557096,
            "ap": 0.730861,
            "ap_weighted": 0.730861
          },
          {
            "accuracy": 0.627409,
            "f1": 0.594521,
            "f1_weighted": 0.639773,
            "ap": 0.747454,
            "ap_weighted": 0.747454
          },
          {
            "accuracy": 0.620985,
            "f1": 0.607031,
            "f1_weighted": 0.636049,
            "ap": 0.769093,
            "ap_weighted": 0.769093
          }
        ],
        "main_score": 0.613704,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 44.11464548110962,
  "kg_co2_emissions": null
}