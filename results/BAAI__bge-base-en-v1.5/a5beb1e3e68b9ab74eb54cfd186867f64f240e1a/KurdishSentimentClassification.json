{
  "dataset_revision": "f334d90a9f68cc3af78cc2a2ece6a3b69408124c",
  "evaluation_time": 11.565770626068115,
  "kg_co2_emissions": 0.0003649799776007703,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.5848515349773529,
        "ap": 0.5876086948904664,
        "ap_weighted": 0.5876086948904664,
        "f1": 0.5783835156992575,
        "f1_weighted": 0.5805601536124365,
        "hf_subset": "default",
        "languages": [
          "kur-Arab"
        ],
        "main_score": 0.5848515349773529,
        "scores_per_experiment": [
          {
            "accuracy": 0.5863110216406643,
            "ap": 0.5973070167834126,
            "ap_weighted": 0.5973070167834126,
            "f1": 0.5806432563556406,
            "f1_weighted": 0.577134639750626
          },
          {
            "accuracy": 0.61852038248616,
            "ap": 0.6140135189364316,
            "ap_weighted": 0.6140135189364316,
            "f1": 0.6181605132074247,
            "f1_weighted": 0.6173168852261272
          },
          {
            "accuracy": 0.41670860593860093,
            "ap": 0.4973292274696004,
            "ap_weighted": 0.4973292274696004,
            "f1": 0.406705988888617,
            "f1_weighted": 0.41225007508298794
          },
          {
            "accuracy": 0.6210367388022144,
            "ap": 0.6138681534441738,
            "ap_weighted": 0.6138681534441738,
            "f1": 0.6210121651616942,
            "f1_weighted": 0.6207925382495459
          },
          {
            "accuracy": 0.5863110216406643,
            "ap": 0.5751465018442781,
            "ap_weighted": 0.5751465018442781,
            "f1": 0.5607869142351901,
            "f1_weighted": 0.5684068460911041
          },
          {
            "accuracy": 0.6532460996477101,
            "ap": 0.6275776459789446,
            "ap_weighted": 0.6275776459789446,
            "f1": 0.648862944149417,
            "f1_weighted": 0.6516863280965156
          },
          {
            "accuracy": 0.6275792652239557,
            "ap": 0.606396889398401,
            "ap_weighted": 0.606396889398401,
            "f1": 0.6188323835120988,
            "f1_weighted": 0.6229878788104228
          },
          {
            "accuracy": 0.6482133870156014,
            "ap": 0.6211856743915636,
            "ap_weighted": 0.6211856743915636,
            "f1": 0.6405568844655725,
            "f1_weighted": 0.6443323322747248
          },
          {
            "accuracy": 0.587820835430297,
            "ap": 0.5847743640671517,
            "ap_weighted": 0.5847743640671517,
            "f1": 0.5855213542641671,
            "f1_weighted": 0.5877431502557655
          },
          {
            "accuracy": 0.5027679919476598,
            "ap": 0.5384879565907067,
            "ap_weighted": 0.5384879565907067,
            "f1": 0.5027527527527528,
            "f1_weighted": 0.5029508622865443
          }
        ]
      }
    ]
  },
  "task_name": "KurdishSentimentClassification"
}