{
  "dataset_revision": "ffb8a34c9637fb20256e8c7be02504d16af4bd6b",
  "evaluation_time": 8.906564235687256,
  "kg_co2_emissions": 0.0002759482275265238,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.53359375,
        "f1": 0.5388313787456811,
        "f1_weighted": 0.5288895513957051,
        "hf_subset": "default",
        "languages": [
          "ory-Orya"
        ],
        "main_score": 0.5388313787456811,
        "scores_per_experiment": [
          {
            "accuracy": 0.59326171875,
            "f1": 0.6070949405146225,
            "f1_weighted": 0.5971883278615395
          },
          {
            "accuracy": 0.509765625,
            "f1": 0.5292700448556209,
            "f1_weighted": 0.5150390317000892
          },
          {
            "accuracy": 0.5625,
            "f1": 0.5851420324240711,
            "f1_weighted": 0.5640589695792236
          },
          {
            "accuracy": 0.556640625,
            "f1": 0.5212799253526152,
            "f1_weighted": 0.5373428293003233
          },
          {
            "accuracy": 0.51025390625,
            "f1": 0.4840954553771521,
            "f1_weighted": 0.49490670614287474
          },
          {
            "accuracy": 0.5361328125,
            "f1": 0.553932275745927,
            "f1_weighted": 0.5315285145654962
          },
          {
            "accuracy": 0.45947265625,
            "f1": 0.4548592818101023,
            "f1_weighted": 0.4407292416506086
          },
          {
            "accuracy": 0.556640625,
            "f1": 0.5733736796772293,
            "f1_weighted": 0.5592108981878146
          },
          {
            "accuracy": 0.5146484375,
            "f1": 0.5310302306136171,
            "f1_weighted": 0.5163499398130511
          },
          {
            "accuracy": 0.53662109375,
            "f1": 0.5482359210858526,
            "f1_weighted": 0.5325410551560298
          }
        ]
      }
    ]
  },
  "task_name": "OdiaNewsClassification"
}