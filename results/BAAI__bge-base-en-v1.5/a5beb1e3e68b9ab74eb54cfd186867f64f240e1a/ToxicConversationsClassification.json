{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 9.719040155410767,
  "kg_co2_emissions": 0.0003409869126562143,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.670361328125,
        "ap": 0.12611495975726106,
        "ap_weighted": 0.12611495975726106,
        "f1": 0.514552476305141,
        "f1_weighted": 0.7409367556435085,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.670361328125,
        "scores_per_experiment": [
          {
            "accuracy": 0.7119140625,
            "ap": 0.1431749501770431,
            "ap_weighted": 0.1431749501770431,
            "f1": 0.5477079206512478,
            "f1_weighted": 0.7771174737689533
          },
          {
            "accuracy": 0.7333984375,
            "ap": 0.12498119127759239,
            "ap_weighted": 0.12498119127759239,
            "f1": 0.5439429928741093,
            "f1_weighted": 0.7913832857036817
          },
          {
            "accuracy": 0.74658203125,
            "ap": 0.1358493109314916,
            "ap_weighted": 0.1358493109314916,
            "f1": 0.5583593540626617,
            "f1_weighted": 0.8010638383341436
          },
          {
            "accuracy": 0.7451171875,
            "ap": 0.1365762720687369,
            "ap_weighted": 0.1365762720687369,
            "f1": 0.558255925423953,
            "f1_weighted": 0.8001093907536115
          },
          {
            "accuracy": 0.52685546875,
            "ap": 0.10617448187905294,
            "ap_weighted": 0.10617448187905294,
            "f1": 0.43197981529795476,
            "f1_weighted": 0.6273987239614267
          },
          {
            "accuracy": 0.451171875,
            "ap": 0.09699566291067238,
            "ap_weighted": 0.09699566291067238,
            "f1": 0.384064764987178,
            "f1_weighted": 0.5552077496944341
          },
          {
            "accuracy": 0.7431640625,
            "ap": 0.11880948546325412,
            "ap_weighted": 0.11880948546325412,
            "f1": 0.5426801518784429,
            "f1_weighted": 0.7975726754120449
          },
          {
            "accuracy": 0.595703125,
            "ap": 0.1158615451388889,
            "ap_weighted": 0.1158615451388889,
            "f1": 0.47371596482799455,
            "f1_weighted": 0.687007916284929
          },
          {
            "accuracy": 0.71337890625,
            "ap": 0.13379492876977161,
            "ap_weighted": 0.13379492876977161,
            "f1": 0.5419051592904,
            "f1_weighted": 0.7778355182356119
          },
          {
            "accuracy": 0.736328125,
            "ap": 0.14893176895610655,
            "ap_weighted": 0.14893176895610655,
            "f1": 0.5629127137574678,
            "f1_weighted": 0.7946709842862473
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}