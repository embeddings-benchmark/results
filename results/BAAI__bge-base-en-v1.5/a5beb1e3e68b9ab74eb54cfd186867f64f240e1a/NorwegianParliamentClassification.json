{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.542333,
        "f1": 0.533367,
        "f1_weighted": 0.533367,
        "ap": 0.522919,
        "ap_weighted": 0.522919,
        "scores_per_experiment": [
          {
            "accuracy": 0.546667,
            "f1": 0.546485,
            "f1_weighted": 0.546485,
            "ap": 0.525427,
            "ap_weighted": 0.525427
          },
          {
            "accuracy": 0.533333,
            "f1": 0.530693,
            "f1_weighted": 0.530693,
            "ap": 0.517633,
            "ap_weighted": 0.517633
          },
          {
            "accuracy": 0.559167,
            "f1": 0.555362,
            "f1_weighted": 0.555362,
            "ap": 0.532538,
            "ap_weighted": 0.532538
          },
          {
            "accuracy": 0.553333,
            "f1": 0.551808,
            "f1_weighted": 0.551808,
            "ap": 0.529214,
            "ap_weighted": 0.529214
          },
          {
            "accuracy": 0.550833,
            "f1": 0.550021,
            "f1_weighted": 0.550021,
            "ap": 0.528241,
            "ap_weighted": 0.528241
          },
          {
            "accuracy": 0.5425,
            "f1": 0.52583,
            "f1_weighted": 0.52583,
            "ap": 0.522564,
            "ap_weighted": 0.522564
          },
          {
            "accuracy": 0.525,
            "f1": 0.512786,
            "f1_weighted": 0.512786,
            "ap": 0.512975,
            "ap_weighted": 0.512975
          },
          {
            "accuracy": 0.519167,
            "f1": 0.497532,
            "f1_weighted": 0.497532,
            "ap": 0.510211,
            "ap_weighted": 0.510211
          },
          {
            "accuracy": 0.563333,
            "f1": 0.535043,
            "f1_weighted": 0.535043,
            "ap": 0.534353,
            "ap_weighted": 0.534353
          },
          {
            "accuracy": 0.53,
            "f1": 0.528107,
            "f1_weighted": 0.528107,
            "ap": 0.516031,
            "ap_weighted": 0.516031
          }
        ],
        "main_score": 0.542333,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.546083,
        "f1": 0.538214,
        "f1_weighted": 0.538214,
        "ap": 0.526001,
        "ap_weighted": 0.526001,
        "scores_per_experiment": [
          {
            "accuracy": 0.556667,
            "f1": 0.556636,
            "f1_weighted": 0.556636,
            "ap": 0.531599,
            "ap_weighted": 0.531599
          },
          {
            "accuracy": 0.530833,
            "f1": 0.529277,
            "f1_weighted": 0.529277,
            "ap": 0.516269,
            "ap_weighted": 0.516269
          },
          {
            "accuracy": 0.569167,
            "f1": 0.567653,
            "f1_weighted": 0.567653,
            "ap": 0.538861,
            "ap_weighted": 0.538861
          },
          {
            "accuracy": 0.579167,
            "f1": 0.576624,
            "f1_weighted": 0.576624,
            "ap": 0.54501,
            "ap_weighted": 0.54501
          },
          {
            "accuracy": 0.581667,
            "f1": 0.5793,
            "f1_weighted": 0.5793,
            "ap": 0.54868,
            "ap_weighted": 0.54868
          },
          {
            "accuracy": 0.535833,
            "f1": 0.519537,
            "f1_weighted": 0.519537,
            "ap": 0.518855,
            "ap_weighted": 0.518855
          },
          {
            "accuracy": 0.5025,
            "f1": 0.49338,
            "f1_weighted": 0.49338,
            "ap": 0.501255,
            "ap_weighted": 0.501255
          },
          {
            "accuracy": 0.4875,
            "f1": 0.464826,
            "f1_weighted": 0.464826,
            "ap": 0.494016,
            "ap_weighted": 0.494016
          },
          {
            "accuracy": 0.5925,
            "f1": 0.572589,
            "f1_weighted": 0.572589,
            "ap": 0.552226,
            "ap_weighted": 0.552226
          },
          {
            "accuracy": 0.525,
            "f1": 0.522313,
            "f1_weighted": 0.522313,
            "ap": 0.513235,
            "ap_weighted": 0.513235
          }
        ],
        "main_score": 0.546083,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 19.824713230133057,
  "kg_co2_emissions": 0.0009413764295840793
}