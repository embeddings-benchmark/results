{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 50.66402459144592,
  "kg_co2_emissions": 0.0021034236440108374,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.0859375,
        "f1": 0.06435541997065435,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.06435541997065435,
        "precision": 0.057507130456349205,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 9.826030927835051e-05,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 9.826030927835051e-05,
        "precision": 5.086263020833333e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013951858632118598,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.0013951858632118598,
        "precision": 0.0012348407322517062,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 8.088699494949496e-05,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 8.088699494949496e-05,
        "precision": 4.149019048455056e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002101052570812808,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.002101052570812808,
        "precision": 0.0017217483037795538,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.001010827850877193,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.001010827850877193,
        "precision": 0.0009940011160714285,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 9.765625e-05,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 9.765625e-05,
        "precision": 5.139802631578947e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0020473802860696516,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0020473802860696516,
        "precision": 0.0017237807765151515,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013546362888220982,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.0013546362888220982,
        "precision": 0.001003274356617647,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007301429059086396,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0007301429059086396,
        "precision": 0.000457647169165662,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00025697741716303743,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.00025697741716303743,
        "precision": 0.00013457758819086942,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0021583446557971015,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0021583446557971015,
        "precision": 0.001812065972222222,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.650297619047619e-05,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 4.650297619047619e-05,
        "precision": 2.381859756097561e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003712607333547897,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0003712607333547897,
        "precision": 0.00021838143824326218,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0024739583333333332,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0024739583333333332,
        "precision": 0.002267020089285714,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00015532249516184144,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.00015532249516184144,
        "precision": 7.997820362186682e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9472831505483548e-06,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 1.9472831505483548e-06,
        "precision": 9.746132734530937e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009964923469387755,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0009964923469387755,
        "precision": 0.0009866301546391752,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 5.425347222222222e-05,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 5.425347222222222e-05,
        "precision": 2.7901785714285713e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019632975260416665,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0019632975260416665,
        "precision": 0.0019582378926701572,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003060616829741066,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.0003060616829741066,
        "precision": 0.0001763798316976584,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.05929269278273971,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.05929269278273971,
        "precision": 0.05138700225498642,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00018791364999268685,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.00018791364999268685,
        "precision": 9.918672769740808e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001614657315340909,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.001614657315340909,
        "precision": 0.0013800883256528417,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 6.498249864359778e-05,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 6.498249864359778e-05,
        "precision": 3.308422695410595e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0033553288369680256,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.0033553288369680256,
        "precision": 0.0029158693420158416,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005335931106792143,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0005335931106792143,
        "precision": 0.00030612873546157594,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0021484927530995546,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.0021484927530995546,
        "precision": 0.002057440841516639,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 9.084302325581395e-06,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 9.084302325581395e-06,
        "precision": 4.563376168224299e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002027928229470951,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.002027928229470951,
        "precision": 0.0019913440452091766,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0002374223378867676,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0002374223378867676,
        "precision": 0.00012997836619329104,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 8.138020833333333e-05,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 8.138020833333333e-05,
        "precision": 4.245923913043478e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0013671875,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0013671875,
        "precision": 0.001220703125,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010799915332512316,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0010799915332512316,
        "precision": 0.001029864156920078,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0028099179466366964,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0028099179466366964,
        "precision": 0.002195190876831502,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000517874053030303,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.000517874053030303,
        "precision": 0.0003405448717948718,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0011541193181818182,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0011541193181818182,
        "precision": 0.00107421875,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011768830128205128,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.0011768830128205128,
        "precision": 0.0010875798878891745,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9054878048780488e-06,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 1.9054878048780488e-06,
        "precision": 9.5367431640625e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001962557705965909,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.001962557705965909,
        "precision": 0.001957852835089835,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011390894010043042,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0011390894010043042,
        "precision": 0.00106201171875,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.98970818134445e-05,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 3.98970818134445e-05,
        "precision": 2.0154587765957447e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010629036533641796,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.0010629036533641796,
        "precision": 0.0007205539279513889,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00046136592393464866,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.00046136592393464866,
        "precision": 0.0002523722757105223,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.2170406813010637,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2170406813010637,
        "precision": 0.21059529121052561,
        "recall": 0.23828125
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.018740255338219332,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.018740255338219332,
        "precision": 0.017787813800056736,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.2451171875,
        "f1": 0.2185026656828415,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2185026656828415,
        "precision": 0.2114150879340488,
        "recall": 0.2451171875
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.0208464004758585,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0208464004758585,
        "precision": 0.01880039741573919,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.2421875,
        "f1": 0.2144136586429207,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2144136586429207,
        "precision": 0.20691251565275004,
        "recall": 0.2421875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.25014400921659e-06,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 2.25014400921659e-06,
        "precision": 1.1263696655132642e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.08761649708319176,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.08761649708319176,
        "precision": 0.08170982196942125,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.049109086352738696,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.049109086352738696,
        "precision": 0.04385473983288977,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.09323776267135642,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.09323776267135642,
        "precision": 0.08794098099331812,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.027372140605784356,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.027372140605784356,
        "precision": 0.02403839864287082,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003333464856902357,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0003333464856902357,
        "precision": 0.00017785694890657517,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03215854049953314,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.03215854049953314,
        "precision": 0.028975423177083334,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003834318430087391,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0003834318430087391,
        "precision": 0.00022465350262928417,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.142578125,
        "f1": 0.1263042904202793,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1263042904202793,
        "precision": 0.12218850186559,
        "recall": 0.142578125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04114391579832059,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.04114391579832059,
        "precision": 0.03652203965219668,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 9.256516587677726e-06,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 9.256516587677726e-06,
        "precision": 4.6502976190476195e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.2412109375,
        "f1": 0.21938281445117383,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.21938281445117383,
        "precision": 0.2118633319805195,
        "recall": 0.2412109375
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.07731803568721916,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.07731803568721916,
        "precision": 0.07156937646734252,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.11812828391356446,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.11812828391356446,
        "precision": 0.11362857344138681,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.09447494492588704,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.09447494492588704,
        "precision": 0.08725517239921536,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0010910547557340322,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0010910547557340322,
        "precision": 0.0006623855744949495,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007325586484593838,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0007325586484593838,
        "precision": 0.00044772907838983055,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.26953125,
        "f1": 0.23872519267958597,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.23872519267958597,
        "precision": 0.23035498743204214,
        "recall": 0.26953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.026720686597939275,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.026720686597939275,
        "precision": 0.025655321083745977,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.3017578125,
        "f1": 0.2656978820173903,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2656978820173903,
        "precision": 0.25347474113343255,
        "recall": 0.3017578125
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.017718821872848636,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.017718821872848636,
        "precision": 0.015532982948701358,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.466796875,
        "f1": 0.41328318762400795,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.41328318762400795,
        "precision": 0.3949864840990972,
        "recall": 0.466796875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.097878625134264e-06,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 2.097878625134264e-06,
        "precision": 1.0500672043010753e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.09562683004298989,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.09562683004298989,
        "precision": 0.08823204802754434,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.2763671875,
        "f1": 0.21923060121302307,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.21923060121302307,
        "precision": 0.20062656798496642,
        "recall": 0.2763671875
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.08572850662442395,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.08572850662442395,
        "precision": 0.08115996484221719,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.1181640625,
        "f1": 0.08808694560647684,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.08808694560647684,
        "precision": 0.07885018105832686,
        "recall": 0.1181640625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00015292324862637363,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00015292324862637363,
        "precision": 8.070190847709505e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.12311437828154281,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.12311437828154281,
        "precision": 0.11069094400755249,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007930581086601307,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0007930581086601307,
        "precision": 0.0005630708076584507,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.12977598036105364,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.12977598036105364,
        "precision": 0.1264990770742518,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.04619838729512408,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.04619838729512408,
        "precision": 0.04101464941308691,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011647583502024292,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0011647583502024292,
        "precision": 0.0010759857437037715,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.3515625,
        "f1": 0.30991140478445167,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.30991140478445167,
        "precision": 0.2971558495631742,
        "recall": 0.3515625
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.08646773202124572,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.08646773202124572,
        "precision": 0.08052837891109628,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.12322728592332846,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.12322728592332846,
        "precision": 0.11930681589030045,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.11613100164573267,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.11613100164573267,
        "precision": 0.11016389588810983,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0005696614583333333,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.0005696614583333333,
        "precision": 0.0003348214285714286,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00490141369047619,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.00490141369047619,
        "precision": 0.003987630208333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.05328153128658394,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.05328153128658394,
        "precision": 0.046841798765776405,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.05768807455302745,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.05768807455302745,
        "precision": 0.049667470417542076,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.05525765058420946,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.05525765058420946,
        "precision": 0.04839424134679998,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008250864214983418,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.008250864214983418,
        "precision": 0.006019258117180724,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.05269575299837961,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.05269575299837961,
        "precision": 0.04642051072956468,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00034989280280869244,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.00034989280280869244,
        "precision": 0.00018412633796006383,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.05310457381605771,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.05310457381605771,
        "precision": 0.048364076010302175,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0030455390066112045,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.0030455390066112045,
        "precision": 0.0023012038559941522,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.04837265827872082,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.04837265827872082,
        "precision": 0.03863931936486011,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0023988924997082163,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.0023988924997082163,
        "precision": 0.0018953450520833334,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003401275373931624,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0003401275373931624,
        "precision": 0.0001812843004049446,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017243561921296295,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.0017243561921296295,
        "precision": 0.001160606971153846,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010730561755952382,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0010730561755952382,
        "precision": 0.0010256465849522048,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.08680242759871053,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.08680242759871053,
        "precision": 0.07493039453617167,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001487273324622722,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.001487273324622722,
        "precision": 0.0012643156210094093,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004520735851158646,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0004520735851158646,
        "precision": 0.00024456337932900435,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.09375,
        "f1": 0.057543424622393466,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.057543424622393466,
        "precision": 0.05027122034324182,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.0391751782299981,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.0391751782299981,
        "precision": 0.03358035725897447,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.06989622711657427,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.06989622711657427,
        "precision": 0.05874076902078695,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.05013464214824597,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.05013464214824597,
        "precision": 0.04505414955056983,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0012350848103478177,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0012350848103478177,
        "precision": 0.0011138013662178542,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00023229269593005804,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00023229269593005804,
        "precision": 0.00012308497667514845,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2431640625,
        "f1": 0.21598649888123572,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.21598649888123572,
        "precision": 0.20824438206338014,
        "recall": 0.2431640625
      },
      {
        "accuracy": 0.291015625,
        "f1": 0.2616980674118946,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2616980674118946,
        "precision": 0.25203483284293826,
        "recall": 0.291015625
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.01948373464897319,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.01948373464897319,
        "precision": 0.018210007651386424,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.02047583364175887,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.02047583364175887,
        "precision": 0.01857016340340694,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.345703125,
        "f1": 0.31467557507596566,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.31467557507596566,
        "precision": 0.3052051908594877,
        "recall": 0.345703125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.341876498800959e-06,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 2.341876498800959e-06,
        "precision": 1.17234393757503e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.08995566416579742,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.08995566416579742,
        "precision": 0.08423583015562996,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.1132843501984127,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.1132843501984127,
        "precision": 0.1027912092133926,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.07861279805286586,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.07861279805286586,
        "precision": 0.07374715518283853,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.2998046875,
        "f1": 0.24736405629960317,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.24736405629960317,
        "precision": 0.22994252654897188,
        "recall": 0.2998046875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 6.23391608934915e-05,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 6.23391608934915e-05,
        "precision": 3.155128779859707e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.07553846341422768,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.07553846341422768,
        "precision": 0.06910948209776335,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0010373024377193594,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0010373024377193594,
        "precision": 0.0006959347052623132,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.12011908409149133,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.12011908409149133,
        "precision": 0.11591259474560255,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.0628587114696798,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.0628587114696798,
        "precision": 0.05716309961484594,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00023372982357357355,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00023372982357357355,
        "precision": 0.00012539443136967934,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2978515625,
        "f1": 0.26486396347621677,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.26486396347621677,
        "precision": 0.2555010268194504,
        "recall": 0.2978515625
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07949963322626989,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.07949963322626989,
        "precision": 0.07316655796422752,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.10605980371040294,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.10605980371040294,
        "precision": 0.10032988700402387,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.08820769074675325,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.08820769074675325,
        "precision": 0.08121635094207158,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00019712814183314148,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.00019712814183314148,
        "precision": 0.00010752041442492882,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.3633402658252056e-05,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 1.3633402658252056e-05,
        "precision": 6.841027130150094e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.009442103271067894,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.009442103271067894,
        "precision": 0.009278344326331968,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.017199520965646652,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.017199520965646652,
        "precision": 0.01675539719310041,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.007051792126661917,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.007051792126661917,
        "precision": 0.006700385466661243,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.013073248860944249,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.013073248860944249,
        "precision": 0.01272181918252412,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.01416015625,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.01416015625,
        "precision": 0.013997395833333334,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.10247395833333334,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.10247395833333334,
        "precision": 0.09453125000000001,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.008791239896878484,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.008791239896878484,
        "precision": 0.008790152413504464,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.918590373280943e-06,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 1.918590373280943e-06,
        "precision": 9.602384464110128e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.06448490203373015,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.06448490203373015,
        "precision": 0.058876643105158735,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.066252180443841e-05,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 6.066252180443841e-05,
        "precision": 3.120429230423042e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03890064539478602,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.03890064539478602,
        "precision": 0.03429366780144861,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9110812133072406e-06,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 1.9110812133072406e-06,
        "precision": 9.564764936336925e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.08068266369047619,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.08068266369047619,
        "precision": 0.0739526952273965,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03981322942879726,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.03981322942879726,
        "precision": 0.03797833086584098,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.6917623737732897e-05,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 2.6917623737732897e-05,
        "precision": 1.3618527551844481e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018236141604167144,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.018236141604167144,
        "precision": 0.015950816977008737,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.012628935202418768,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.012628935202418768,
        "precision": 0.012304261333916188,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.011350353336491443,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.011350353336491443,
        "precision": 0.011087664881310527,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.1064453125,
        "f1": 0.08382683919188612,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.08382683919188612,
        "precision": 0.07709208787089647,
        "recall": 0.1064453125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.008530943627450981,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.008530943627450981,
        "precision": 0.008253103375294463,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0009394011285444639,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0009394011285444639,
        "precision": 0.0005690300494934502,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005888097426470588,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0005888097426470588,
        "precision": 0.00037764900810733243,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.234375,
        "f1": 0.20263807380979404,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.20263807380979404,
        "precision": 0.1942359985376502,
        "recall": 0.234375
      },
      {
        "accuracy": 0.4638671875,
        "f1": 0.41277257898351644,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.41277257898351644,
        "precision": 0.3951071823142136,
        "recall": 0.4638671875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015619911793385708,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.015619911793385708,
        "precision": 0.01474338239658299,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.34765625,
        "f1": 0.3123652044952596,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3123652044952596,
        "precision": 0.30018271794394846,
        "recall": 0.34765625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017740522901959453,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.017740522901959453,
        "precision": 0.016379296895131158,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.951173826173826e-06,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 1.951173826173826e-06,
        "precision": 9.765625e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.08279576976842601,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.08279576976842601,
        "precision": 0.07563465232547845,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.4423828125,
        "f1": 0.3752848307291667,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.3752848307291667,
        "precision": 0.35102465080492423,
        "recall": 0.4423828125
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.0759636080994898,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0759636080994898,
        "precision": 0.07286252674515292,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.1826171875,
        "f1": 0.14464661315247251,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.14464661315247251,
        "precision": 0.13188011532738095,
        "recall": 0.1826171875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011748342803030304,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0011748342803030304,
        "precision": 0.0010834253998316498,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2099609375,
        "f1": 0.157185023178804,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.157185023178804,
        "precision": 0.14265412593049312,
        "recall": 0.2099609375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00030048076923076925,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.00030048076923076925,
        "precision": 0.00016276041666666666,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.09986445242772925,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.09986445242772925,
        "precision": 0.09668425160802185,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.07871823622915075,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.07871823622915075,
        "precision": 0.0729297751593535,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000659570596797671,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.000659570596797671,
        "precision": 0.0004925644188596491,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.396484375,
        "f1": 0.353011723519536,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.353011723519536,
        "precision": 0.3396711695308529,
        "recall": 0.396484375
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.05813524762214195,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.05813524762214195,
        "precision": 0.051632996058728536,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.09154992285903059,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.09154992285903059,
        "precision": 0.08747260980829255,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.10575091614285206,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.10575091614285206,
        "precision": 0.09992758769105502,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0002114434760255551,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.0002114434760255551,
        "precision": 0.00011662323491507194,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.0767524919932347e-05,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 1.0767524919932347e-05,
        "precision": 5.399433709654074e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9318743818001978e-06,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 1.9318743818001978e-06,
        "precision": 9.668935643564357e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011467892112112582,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.0011467892112112582,
        "precision": 0.0010680173170120322,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.5365259740259742e-05,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 2.5365259740259742e-05,
        "precision": 1.2849506578947368e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 4.7110889517927606e-05,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 4.7110889517927606e-05,
        "precision": 2.382038045388784e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.0915953621031746,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.0915953621031746,
        "precision": 0.07908204348762532,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.6303438661710035e-06,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 3.6303438661710035e-06,
        "precision": 1.8185521415270018e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006533153861078773,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0006533153861078773,
        "precision": 0.0004894194347319347,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9299654150197627e-06,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 1.9299654150197627e-06,
        "precision": 9.659371909000989e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.055987913995726495,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.055987913995726495,
        "precision": 0.04803406229187479,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00015383842622193803,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.00015383842622193803,
        "precision": 8.05844782070904e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.03139002382166445,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.03139002382166445,
        "precision": 0.026649425697277258,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9318743818001978e-06,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 1.9318743818001978e-06,
        "precision": 9.668935643564357e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.10642408933320667,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.10642408933320667,
        "precision": 0.09505943251909624,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.013411485823651065,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.013411485823651065,
        "precision": 0.01108884365016595,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016163632374569877,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0016163632374569877,
        "precision": 0.001359090257440073,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.028439562387791318,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.028439562387791318,
        "precision": 0.024268977841447523,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006019270789262142,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.0006019270789262142,
        "precision": 0.0003849587253858644,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006024936800774526,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.0006024936800774526,
        "precision": 0.0003514032751988063,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06912667410714285,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.06912667410714285,
        "precision": 0.05933804237155388,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1798270089285713e-06,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 2.1798270089285713e-06,
        "precision": 1.091131284916201e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009890865399043655,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0009890865399043655,
        "precision": 0.0009828452054639362,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0020007621951219513,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0020007621951219513,
        "precision": 0.0019775390625,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.0707577207883468,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.0707577207883468,
        "precision": 0.067467359453586,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.07605029439936893,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.07605029439936893,
        "precision": 0.07266177699307182,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.007488992697594501,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.007488992697594501,
        "precision": 0.007325226554437564,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.08237556440077945,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.08237556440077945,
        "precision": 0.07825632009048043,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.014062290774865453,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.014062290774865453,
        "precision": 0.012057774141411425,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.07337765512556016,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.07337765512556016,
        "precision": 0.07023906216891085,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.000503338214253457,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.000503338214253457,
        "precision": 0.00027037524107836604,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00016528057795698925,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.00016528057795698925,
        "precision": 9.004011774723984e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.07156238077870689,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.07156238077870689,
        "precision": 0.06675891564623473,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00016276041666666666,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.00016276041666666666,
        "precision": 8.87784090909091e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00037728066770186333,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.00037728066770186333,
        "precision": 0.00020532852564102564,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.6041666666666666e-06,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 2.6041666666666666e-06,
        "precision": 1.3038217623497997e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00038496036557409834,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.00038496036557409834,
        "precision": 0.0002177384023423894,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.11488776190767118,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.11488776190767118,
        "precision": 0.1100402639976007,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000435734326625387,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.000435734326625387,
        "precision": 0.00026710327473380654,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 8.87784090909091e-05,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 8.87784090909091e-05,
        "precision": 4.650297619047619e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.07736253546800421,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.07736253546800421,
        "precision": 0.07459659053368282,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.05022398967186727,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.05022398967186727,
        "precision": 0.046290443990172014,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.09676502457153921,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.09676502457153921,
        "precision": 0.09158860988116961,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.27734375,
        "f1": 0.24726005504325815,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.24726005504325815,
        "precision": 0.2399096862200383,
        "recall": 0.27734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001698503956478734,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.001698503956478734,
        "precision": 0.001501424754977422,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0009795409960792303,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0009795409960792303,
        "precision": 0.0006679472744453171,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.0347100932219843,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.0347100932219843,
        "precision": 0.031156884679065168,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.22265625,
        "f1": 0.170965091765873,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.170965091765873,
        "precision": 0.15618187322545873,
        "recall": 0.22265625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00011732502383746516,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00011732502383746516,
        "precision": 6.225433540106118e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.08498469463542993,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.08498469463542993,
        "precision": 0.07469728351076008,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001197191388704106,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.001197191388704106,
        "precision": 0.0010961726365149643,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.3486328125,
        "f1": 0.2762533779537456,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2762533779537456,
        "precision": 0.2521431040205454,
        "recall": 0.3486328125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009785554846938776,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0009785554846938776,
        "precision": 0.0009775600102145045,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00041232638888888883,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.00041232638888888883,
        "precision": 0.0002236193257611425,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0027557972687303135,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0027557972687303135,
        "precision": 0.0025219534034254627,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.2021484375,
        "f1": 0.1598644210288282,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.1598644210288282,
        "precision": 0.14730394117601148,
        "recall": 0.2021484375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016593799682034975,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0016593799682034975,
        "precision": 0.001480888328889248,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.271484375,
        "f1": 0.21749420284576532,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.21749420284576532,
        "precision": 0.20102435446242892,
        "recall": 0.271484375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0020648056653491433,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0020648056653491433,
        "precision": 0.0017325747511808367,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.09479468285620629,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.09479468285620629,
        "precision": 0.08764501053925575,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009883451366798407,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0009883451366798407,
        "precision": 0.0009824737424033037,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1298828125,
        "f1": 0.08673389387255062,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.08673389387255062,
        "precision": 0.07626068497219692,
        "recall": 0.1298828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009787920947488585,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0009787920947488585,
        "precision": 0.0009776785714285714,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0025147425602122502,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0025147425602122502,
        "precision": 0.0022890971819278664,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00019782294344473009,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.00019782294344473009,
        "precision": 0.00010976378163878164,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 5.501760563380282e-06,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 5.501760563380282e-06,
        "precision": 2.758651129943503e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.03220755974396854,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.03220755974396854,
        "precision": 0.03040950583898252,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.080078125,
        "f1": 0.06741141264698927,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.06741141264698927,
        "precision": 0.06387928096789891,
        "recall": 0.080078125
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.02691296799642154,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.02691296799642154,
        "precision": 0.02493998710745074,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.06457608031677606,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.06457608031677606,
        "precision": 0.061364467913425015,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.055493346427112504,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.055493346427112504,
        "precision": 0.04687015593998016,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.054131299929511274,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.054131299929511274,
        "precision": 0.05075428280822757,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.06578306133970196,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.06578306133970196,
        "precision": 0.060785657070411205,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.03273503004849557,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.03273503004849557,
        "precision": 0.03036881331559066,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.001953125,
        "f1": 7.715469751602565e-05,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 7.715469751602565e-05,
        "precision": 4.0080813347236704e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.90625e-05,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 3.90625e-05,
        "precision": 1.992984693877551e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.016339666193181817,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.016339666193181817,
        "precision": 0.013705456398221344,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9492265469061875e-06,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 1.9492265469061875e-06,
        "precision": 9.75586913086913e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.03162184306673097,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.03162184306673097,
        "precision": 0.029266048314605823,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.14007926159862788,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.14007926159862788,
        "precision": 0.1357137832603701,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 7.611114696919074e-05,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 7.611114696919074e-05,
        "precision": 3.882851201809665e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.010182696391766933,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.010182696391766933,
        "precision": 0.008873872705557204,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04909480738371794,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.04909480738371794,
        "precision": 0.04603286385512949,
        "recall": 0.0625
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.04513148693587396,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.04513148693587396,
        "precision": 0.043819246008043475,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.2158203125,
        "f1": 0.1898424039451153,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.1898424039451153,
        "precision": 0.18127305772569446,
        "recall": 0.2158203125
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.04883069152431011,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.04883069152431011,
        "precision": 0.04606248286732456,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0015607588521519718,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0015607588521519718,
        "precision": 0.0011147894011155923,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0015868738060624758,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0015868738060624758,
        "precision": 0.001324187737145612,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.023508294499641112,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.023508294499641112,
        "precision": 0.020699397891726274,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.06300843253968254,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.06300843253968254,
        "precision": 0.05508869338692708,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008877940114333994,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0008877940114333994,
        "precision": 0.00062029722578427,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.24609375,
        "f1": 0.18638061328748007,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.18638061328748007,
        "precision": 0.16863879122179903,
        "recall": 0.24609375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008325926055028816,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0008325926055028816,
        "precision": 0.0005879386526639345,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.162109375,
        "f1": 0.11811181711084055,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.11811181711084055,
        "precision": 0.10528797555164743,
        "recall": 0.162109375
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.745578006362486e-05,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 1.745578006362486e-05,
        "precision": 8.789201048982053e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0003671684276008276,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0003671684276008276,
        "precision": 0.00019954319373059244,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.15069113312392265,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.15069113312392265,
        "precision": 0.1391568622891865,
        "recall": 0.189453125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001123046875,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.001123046875,
        "precision": 0.0007748811141304348,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006940143240979831,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0006940143240979831,
        "precision": 0.000509955316996403,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.09755490086659663,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.09755490086659663,
        "precision": 0.08779196998017291,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011480813247384154,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0011480813247384154,
        "precision": 0.0008182010135135134,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00030270563143855775,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.00030270563143855775,
        "precision": 0.00016669008813485956,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.08613423929586038,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.08613423929586038,
        "precision": 0.07998777573938645,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014027529983479394,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0014027529983479394,
        "precision": 0.0012386482317498866,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.052923305440523774,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.052923305440523774,
        "precision": 0.04610994451692694,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013693504291251383,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0013693504291251383,
        "precision": 0.001221785788525499,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005681818181818182,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0005681818181818182,
        "precision": 0.0003371465773809524,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.6540743586460066e-05,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 1.6540743586460066e-05,
        "precision": 8.324122425609588e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 7.102272727272727e-06,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 7.102272727272727e-06,
        "precision": 3.564096715328467e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.0489801782096662e-05,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 1.0489801782096662e-05,
        "precision": 5.262263795939836e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 8.491847826086956e-05,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 8.491847826086956e-05,
        "precision": 4.438920454545455e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.2758060774762236e-05,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 1.2758060774762236e-05,
        "precision": 6.402671800283921e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.4804972286028164e-05,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 1.4804972286028164e-05,
        "precision": 7.439296909592239e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.04297595709222708,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.04297595709222708,
        "precision": 0.037243270238875706,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.5995319424481974e-05,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 1.5995319424481974e-05,
        "precision": 8.034093567913533e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.047305420816163,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.047305420816163,
        "precision": 0.04188625630322851,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.9864296636085627e-06,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 2.9864296636085627e-06,
        "precision": 1.4955015313935682e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 4.445425955944398e-05,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 4.445425955944398e-05,
        "precision": 2.269991905248807e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.015347707786365409,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.015347707786365409,
        "precision": 0.013279765344119157,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 8.885233148365199e-05,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 8.885233148365199e-05,
        "precision": 4.5499207052344135e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9110812133072406e-06,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 1.9110812133072406e-06,
        "precision": 9.564764936336925e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.04869473613944826,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.04869473613944826,
        "precision": 0.044375052183737496,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.029288164167242753,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.029288164167242753,
        "precision": 0.024643359299121016,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009880298341087847,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0009880298341087847,
        "precision": 0.0009823163870703764,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06347592836850649,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.06347592836850649,
        "precision": 0.055591982886904756,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 9.650974838212349e-05,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 9.650974838212349e-05,
        "precision": 4.908256047578964e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0002539978725951559,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0002539978725951559,
        "precision": 0.00014445088152133557,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.021629303965881454,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.021629303965881454,
        "precision": 0.018876963162567907,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.6438899253731343e-06,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 3.6438899253731343e-06,
        "precision": 1.8253504672897197e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0007014696182115001,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0007014696182115001,
        "precision": 0.0004068834798783057,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0023008404356060605,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0023008404356060605,
        "precision": 0.002159662356321839,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.024255247790404038,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.024255247790404038,
        "precision": 0.020776352734360546,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.10144061205211252,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.10144061205211252,
        "precision": 0.0924539937601461,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0002836000019570962,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0002836000019570962,
        "precision": 0.00015943135960265828,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.07438965191642358,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.07438965191642358,
        "precision": 0.06631477756822426,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.001953125,
        "f1": 8.871684292649097e-05,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 8.871684292649097e-05,
        "precision": 4.5743123638344224e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.15188228942512544,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.15188228942512544,
        "precision": 0.1407461685288522,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0029317156671858774,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0029317156671858774,
        "precision": 0.0029307026377338877,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0005556303879310345,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0005556303879310345,
        "precision": 0.00036039806547619044,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.279296875,
        "f1": 0.23029271618138805,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.23029271618138805,
        "precision": 0.21374025894974352,
        "recall": 0.279296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0017996651785714287,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0017996651785714287,
        "precision": 0.0014935661764705881,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.11720546705898269,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.11720546705898269,
        "precision": 0.10895695016788767,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004564561362696443,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0004564561362696443,
        "precision": 0.0002777791706782199,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013109611742424241,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0013109611742424241,
        "precision": 0.0009810216894977168,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0005076191212871287,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0005076191212871287,
        "precision": 0.0003352864583333333,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1103515625,
        "f1": 0.08157280815972222,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.08157280815972222,
        "precision": 0.07328330035849567,
        "recall": 0.1103515625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0024675603382602438,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0024675603382602438,
        "precision": 0.0022917896978894574,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04637201855219433,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.04637201855219433,
        "precision": 0.041417635955973905,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0002822839524605829,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0002822839524605829,
        "precision": 0.0001643961997487437,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004904856800225733,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0004904856800225733,
        "precision": 0.0003266242937853107,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010387280421126105,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0010387280421126105,
        "precision": 0.0010084763071895424,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00031474281453667993,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.00031474281453667993,
        "precision": 0.00017143309568305655,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 2.209797859811566e-05,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 2.209797859811566e-05,
        "precision": 1.109586888332688e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.918590373280943e-06,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 1.918590373280943e-06,
        "precision": 9.602384464110128e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006535638473169975,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.0006535638473169975,
        "precision": 0.0004144645875153736,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.1097301136363637e-05,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 1.1097301136363637e-05,
        "precision": 5.580357142857143e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 3.075029549327288e-05,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 3.075029549327288e-05,
        "precision": 1.548734080838015e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1220703125,
        "f1": 0.0830643630649375,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.0830643630649375,
        "precision": 0.07213433539117133,
        "recall": 0.1220703125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00048828125,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.00048828125,
        "precision": 0.0003255208333333333,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.146484375,
        "f1": 0.11707053796897546,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.11707053796897546,
        "precision": 0.10766020275297619,
        "recall": 0.146484375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9092130987292278e-06,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 1.9092130987292278e-06,
        "precision": 9.555406066536203e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.029380365271607048,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.029380365271607048,
        "precision": 0.02508994098349567,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0001450368791016067,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0001450368791016067,
        "precision": 7.598974441471503e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.035750275334286,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.035750275334286,
        "precision": 0.030753400915108177,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9073486328125e-06,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 1.9073486328125e-06,
        "precision": 9.546065493646139e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00869109800794662,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.00869109800794662,
        "precision": 0.007008998221004093,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005979651365172594,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0005979651365172594,
        "precision": 0.00035868617472687456,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02236460872339324,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.02236460872339324,
        "precision": 0.018527461055916065,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.8259389103803996e-05,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 1.8259389103803996e-05,
        "precision": 9.18924484427752e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00034002130681818184,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.00034002130681818184,
        "precision": 0.0001891583217289209,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.078125,
        "f1": 0.04799300614125619,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.04799300614125619,
        "precision": 0.041458759610615084,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.221985210466439e-06,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 2.221985210466439e-06,
        "precision": 1.112257972665148e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00011140475601714474,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.00011140475601714474,
        "precision": 5.889591163359846e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004928234011627907,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.0004928234011627907,
        "precision": 0.00032779720279720276,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.07287126369303375,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.07287126369303375,
        "precision": 0.06717118584365583,
        "recall": 0.09375
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.1124524364296157,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.1124524364296157,
        "precision": 0.10527072482638888,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.046582421484765234,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.046582421484765234,
        "precision": 0.04406275990148355,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.10547505697576254,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.10547505697576254,
        "precision": 0.09806657942233593,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.045841503526822994,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.045841503526822994,
        "precision": 0.038441635532053736,
        "recall": 0.078125
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.08701504113770837,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.08701504113770837,
        "precision": 0.08022557818700397,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.02411348417207792,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.02411348417207792,
        "precision": 0.020583038380889943,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.06608305782248797,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.06608305782248797,
        "precision": 0.062035794495393155,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.122166053921569e-05,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 5.122166053921569e-05,
        "precision": 2.623830029888312e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.152579351616965,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.152579351616965,
        "precision": 0.13951865192099566,
        "recall": 0.189453125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00010850694444444444,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.00010850694444444444,
        "precision": 5.744485294117647e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.03927803424873737,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.03927803424873737,
        "precision": 0.03512486049107143,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009785433569979717,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.0009785433569979717,
        "precision": 0.0009775539340101524,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.022312494856722178,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.022312494856722178,
        "precision": 0.020406810976613964,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 3.154684564704213e-05,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 3.154684564704213e-05,
        "precision": 1.586770734841916e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.02584859476461039,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.02584859476461039,
        "precision": 0.021869257587031024,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.1181640625,
        "f1": 0.09825551972409738,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.09825551972409738,
        "precision": 0.09290292699297614,
        "recall": 0.1181640625
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.04497951364020709,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.04497951364020709,
        "precision": 0.04176393117522341,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.20861885486758108,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.20861885486758108,
        "precision": 0.19827398536453505,
        "recall": 0.23828125
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07864998527582297,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.07864998527582297,
        "precision": 0.07238801064054054,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0020403117862480263,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0020403117862480263,
        "precision": 0.0015816897858256574,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00015341808798840047,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00015341808798840047,
        "precision": 8.012305197474736e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.030902098817160228,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.030902098817160228,
        "precision": 0.027183702256944445,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.080078125,
        "f1": 0.052435497115354446,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.052435497115354446,
        "precision": 0.04640400241991464,
        "recall": 0.080078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00011120648635716001,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00011120648635716001,
        "precision": 5.797829033549232e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.06741564532716422,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.06741564532716422,
        "precision": 0.06010027094564241,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0013148955292299966,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0013148955292299966,
        "precision": 0.0011586536647041064,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07163090992171325,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.07163090992171325,
        "precision": 0.06491728438534505,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019553072625698325,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0019553072625698325,
        "precision": 0.001954217351789709,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003283825549450549,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.003283825549450549,
        "precision": 0.002569247159090909,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.140625,
        "f1": 0.10226091087476658,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.10226091087476658,
        "precision": 0.09043209394771895,
        "recall": 0.140625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00026247529644268775,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.00026247529644268775,
        "precision": 0.00014204545454545454,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.08363327752976189,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.08363327752976189,
        "precision": 0.07386997767857142,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010363632373595506,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0010363632373595506,
        "precision": 0.001007119866362451,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.07929152007255777,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.07929152007255777,
        "precision": 0.07120863890883422,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0033032360615651408,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0033032360615651408,
        "precision": 0.002807953643141688,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00028171323284477016,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.00028171323284477016,
        "precision": 0.00015849626194721391,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0018463313230994154,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0018463313230994154,
        "precision": 0.0015799386160714286,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.04322921623284347,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.04322921623284347,
        "precision": 0.0373084959399326,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 7.512019230769231e-05,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 7.512019230769231e-05,
        "precision": 3.90625e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006543576683644595,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0006543576683644595,
        "precision": 0.0004899420705782312,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008218077786246612,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0008218077786246612,
        "precision": 0.000578233721385046,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00021708100658648338,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.00021708100658648338,
        "precision": 0.00011949112324506533,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009949882075471698,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0009949882075471698,
        "precision": 0.0009858630952380952,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000288037476936057,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.000288037476936057,
        "precision": 0.00016728210343453247,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00105429583589114,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.00105429583589114,
        "precision": 0.0010168277554336246,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010557117991586834,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0010557117991586834,
        "precision": 0.001016889176772584,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004065970411246039,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0004065970411246039,
        "precision": 0.0002521730327519149,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.018438291664203122,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.018438291664203122,
        "precision": 0.01626796656229585,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.2984998111273002e-05,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 1.2984998111273002e-05,
        "precision": 6.514660745328118e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.03270745503226535,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.03270745503226535,
        "precision": 0.029732099464394868,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00028245041426060754,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.00028245041426060754,
        "precision": 0.000164479716842723,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.930813993705254e-05,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 6.930813993705254e-05,
        "precision": 3.5857716580608144e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.011024014627527522,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.011024014627527522,
        "precision": 0.009366547253141847,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00015254799836601307,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.00015254799836601307,
        "precision": 7.985681828040951e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.05370558261183261,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.05370558261183261,
        "precision": 0.04472074962797619,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019550417075564278,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0019550417075564278,
        "precision": 0.001954084295186641,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.026487367677060576,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.026487367677060576,
        "precision": 0.02427999809772284,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019945754651560923,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.019945754651560923,
        "precision": 0.01670039882930508,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019632448186528498,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0019632448186528498,
        "precision": 0.001958211263020833,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009791597406914893,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0009791597406914893,
        "precision": 0.0009778628495339548,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004105449315920398,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0004105449315920398,
        "precision": 0.0002395970895977245,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.018389935393803993,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.018389935393803993,
        "precision": 0.0159779792760298,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.462987588652482e-06,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 3.462987588652482e-06,
        "precision": 1.734569271758437e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0003939540256355046,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0003939540256355046,
        "precision": 0.00021582071525578323,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0017252604166666666,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0017252604166666666,
        "precision": 0.0015162417763157894,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.26171875,
        "f1": 0.23021639655838028,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.23021639655838028,
        "precision": 0.22126481568504594,
        "recall": 0.26171875
      },
      {
        "accuracy": 0.3408203125,
        "f1": 0.30627168413069933,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.30627168413069933,
        "precision": 0.29571512471903094,
        "recall": 0.3408203125
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.015838649373114407,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.015838649373114407,
        "precision": 0.01464639013221241,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.3017578125,
        "f1": 0.26937955165494226,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.26937955165494226,
        "precision": 0.2594374036807765,
        "recall": 0.3017578125
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.015834825887050753,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.015834825887050753,
        "precision": 0.013374211702774688,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.3876953125,
        "f1": 0.342740627066799,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.342740627066799,
        "precision": 0.3283222118508173,
        "recall": 0.3876953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009787570224719102,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0009787570224719102,
        "precision": 0.0009776609955005624,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08555812467156917,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.08555812467156917,
        "precision": 0.0786917262824438,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.1484375,
        "f1": 0.1151697580432905,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.1151697580432905,
        "precision": 0.10555915478580344,
        "recall": 0.1484375
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.0703455856953626,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0703455856953626,
        "precision": 0.0662685629640478,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.06962156988034279,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06962156988034279,
        "precision": 0.062107532424861354,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0010986328125,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0010986328125,
        "precision": 0.0010416666666666667,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.05696684505765025,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.05696684505765025,
        "precision": 0.05162527901785714,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00029178338001867413,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.00029178338001867413,
        "precision": 0.00016918516995614033,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.126953125,
        "f1": 0.11406983985683433,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.11406983985683433,
        "precision": 0.11056795371271208,
        "recall": 0.126953125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.043431078697108175,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.043431078697108175,
        "precision": 0.03919043081895297,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007919490690198932,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0007919490690198932,
        "precision": 0.0005611563087406015,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.06500228417516055,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.06500228417516055,
        "precision": 0.059622423489177234,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.09680113599313281,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.09680113599313281,
        "precision": 0.09244970990037832,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.10026771099212649,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.10026771099212649,
        "precision": 0.09372605178265299,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007821255828250754,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.0007821255828250754,
        "precision": 0.0005579027996386642,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011103091032608696,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0011103091032608696,
        "precision": 0.0010459917686480187,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.05660668765499462,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.05660668765499462,
        "precision": 0.053864361004098846,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.06703409513776973,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.06703409513776973,
        "precision": 0.06498691420685514,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.01769584208296493,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.01769584208296493,
        "precision": 0.016417075375219657,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.05939226246843434,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.05939226246843434,
        "precision": 0.055008512313080724,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.02732858775339244,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.02732858775339244,
        "precision": 0.023892394497863248,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.05872637964524219,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.05872637964524219,
        "precision": 0.056102040840715045,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.0755844845908607e-06,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 2.0755844845908607e-06,
        "precision": 1.0388962765957447e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.05218754604678735,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.05218754604678735,
        "precision": 0.047778219760598255,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00159348185296846,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.00159348185296846,
        "precision": 0.0013689313616071428,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.125,
        "f1": 0.10646533355635085,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.10646533355635085,
        "precision": 0.10006407429306245,
        "recall": 0.125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.992984693877551e-06,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 1.992984693877551e-06,
        "precision": 9.975102145045966e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0019688928965625983,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0019688928965625983,
        "precision": 0.0015641346752811145,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001310087943989071,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.001310087943989071,
        "precision": 0.0009805812757201645,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008649553571428572,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.0008649553571428572,
        "precision": 0.0005154079861111111,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.130859375,
        "f1": 0.11732708277212234,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.11732708277212234,
        "precision": 0.11290575886330409,
        "recall": 0.130859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0008245808095834557,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.0008245808095834557,
        "precision": 0.0005783604416416916,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 4.614462531543284e-05,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 4.614462531543284e-05,
        "precision": 2.338818731552018e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.06044601516445512,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.06044601516445512,
        "precision": 0.05786091097775636,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.1269669728366879,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.1269669728366879,
        "precision": 0.12161352831733,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.053678687064813956,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.053678687064813956,
        "precision": 0.05041794818254748,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00011760993568736687,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.00011760993568736687,
        "precision": 6.239716810495119e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.115497398900667e-05,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 6.115497398900667e-05,
        "precision": 3.13647733029382e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04960029839176483,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.04960029839176483,
        "precision": 0.04664638354438416,
        "recall": 0.0625
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.08890351136029226,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.08890351136029226,
        "precision": 0.08428083772892475,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.03891366754572884,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.03891366754572884,
        "precision": 0.036712964698910694,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.08300342395733311,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.08300342395733311,
        "precision": 0.07805385095075172,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.0645351826992452,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.0645351826992452,
        "precision": 0.054776278409090905,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.062168380230880234,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.062168380230880234,
        "precision": 0.05845968583372102,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.0747438461061508,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.0747438461061508,
        "precision": 0.06566569010416667,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.04653174694911999,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.04653174694911999,
        "precision": 0.04321480124193189,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.632905670681308e-05,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 5.632905670681308e-05,
        "precision": 2.894068199088146e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.220703125,
        "f1": 0.1887718563988095,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.1887718563988095,
        "precision": 0.17674541170634922,
        "recall": 0.220703125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.0517578125e-05,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 3.0517578125e-05,
        "precision": 1.5500992063492063e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.024772269001933522,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.024772269001933522,
        "precision": 0.022018779203361427,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.937624007936508e-06,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 1.937624007936508e-06,
        "precision": 9.6977408142999e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.05348518297994038,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.05348518297994038,
        "precision": 0.04738999765447811,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.2275390625,
        "f1": 0.21012535232052953,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.21012535232052953,
        "precision": 0.20524886213967258,
        "recall": 0.2275390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 5.336893459915612e-05,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 5.336893459915612e-05,
        "precision": 2.702064435417239e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.019349167000534188,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.019349167000534188,
        "precision": 0.0171870518397618,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.07302094884300245,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.07302094884300245,
        "precision": 0.06905025690839826,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.057583311687344346,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.057583311687344346,
        "precision": 0.055242963618552014,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.05812005192016499,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.05812005192016499,
        "precision": 0.05314866421988394,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00022269644406026473,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.00022269644406026473,
        "precision": 0.000122346208639952,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012134298351939375,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0012134298351939375,
        "precision": 0.0011009566681233116,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.09828848168512702,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.09828848168512702,
        "precision": 0.09296786433725698,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.10404062696170746,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.10404062696170746,
        "precision": 0.09857041924202992,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.01330140128968254,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.01330140128968254,
        "precision": 0.012479894301470588,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.09096711379216495,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.09096711379216495,
        "precision": 0.0855419872997998,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.011866241939484127,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.011866241939484127,
        "precision": 0.010433510743561778,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.09199984097702026,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.09199984097702026,
        "precision": 0.08763541249723393,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.523417312661499e-06,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 2.523417312661499e-06,
        "precision": 1.2633408796895214e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.3193359375,
        "f1": 0.2783746353345123,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.2783746353345123,
        "precision": 0.2672286392252886,
        "recall": 0.3193359375
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.7926964793741115e-05,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 5.7926964793741115e-05,
        "precision": 2.9703418169158602e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.07298192382349529,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.07298192382349529,
        "precision": 0.06780642533939804,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.146291208791209e-05,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 2.146291208791209e-05,
        "precision": 1.0850694444444445e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.929828973843059e-06,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 3.929828973843059e-06,
        "precision": 1.968876008064516e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004351821272051535,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0004351821272051535,
        "precision": 0.0002443597190788241,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.249415717207128e-05,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 5.249415717207128e-05,
        "precision": 2.6823405253283304e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.1040801233350162,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.1040801233350162,
        "precision": 0.09908166372647849,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.6258758661702346e-05,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 3.6258758661702346e-05,
        "precision": 1.8368430584826133e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9337871287128713e-05,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 1.9337871287128713e-05,
        "precision": 9.765625e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1162109375,
        "f1": 0.10259206041586043,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.10259206041586043,
        "precision": 0.09863035232401497,
        "recall": 0.1162109375
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.06050715602427354,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.06050715602427354,
        "precision": 0.054924500213560226,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.08877411429307708,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.08877411429307708,
        "precision": 0.08385281995532233,
        "recall": 0.107421875
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}