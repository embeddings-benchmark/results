{
  "dataset_revision": "3d96e36e10a88d5b7a3f617cf8362d997504494b",
  "evaluation_time": 10.857259511947632,
  "kg_co2_emissions": 0.00036406843735979855,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.518798828125,
        "ap": 0.5095399839230128,
        "ap_weighted": 0.5095399839230128,
        "f1": 0.5160500572992767,
        "f1_weighted": 0.5160234875907623,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ],
        "main_score": 0.518798828125,
        "scores_per_experiment": [
          {
            "accuracy": 0.54638671875,
            "ap": 0.5245791818089893,
            "ap_weighted": 0.5245791818089893,
            "f1": 0.5449014080464238,
            "f1_weighted": 0.5449521878995376
          },
          {
            "accuracy": 0.52685546875,
            "ap": 0.513181735053754,
            "ap_weighted": 0.513181735053754,
            "f1": 0.5266657650830995,
            "f1_weighted": 0.5266842727579191
          },
          {
            "accuracy": 0.56884765625,
            "ap": 0.5372064313245056,
            "ap_weighted": 0.5372064313245056,
            "f1": 0.556701589431539,
            "f1_weighted": 0.5565582730089024
          },
          {
            "accuracy": 0.48388671875,
            "ap": 0.4912641050695356,
            "ap_weighted": 0.4912641050695356,
            "f1": 0.48075700230005924,
            "f1_weighted": 0.4806782672950293
          },
          {
            "accuracy": 0.49658203125,
            "ap": 0.49725374978436815,
            "ap_weighted": 0.49725374978436815,
            "f1": 0.49345153744269665,
            "f1_weighted": 0.49352931368635633
          },
          {
            "accuracy": 0.5322265625,
            "ap": 0.5161425810518812,
            "ap_weighted": 0.5161425810518812,
            "f1": 0.5314383098397801,
            "f1_weighted": 0.5314007739988174
          },
          {
            "accuracy": 0.541015625,
            "ap": 0.5211056668609644,
            "ap_weighted": 0.5211056668609644,
            "f1": 0.5394868409091997,
            "f1_weighted": 0.5394350177196809
          },
          {
            "accuracy": 0.51953125,
            "ap": 0.5091837563656377,
            "ap_weighted": 0.5091837563656377,
            "f1": 0.518903139493911,
            "f1_weighted": 0.5188691875746629
          },
          {
            "accuracy": 0.50390625,
            "ap": 0.5010812815646388,
            "ap_weighted": 0.5010812815646388,
            "f1": 0.49969030719218266,
            "f1_weighted": 0.49960060628137803
          },
          {
            "accuracy": 0.46875,
            "ap": 0.48440135034585363,
            "ap_weighted": 0.48440135034585363,
            "f1": 0.4685046732538747,
            "f1_weighted": 0.46852697568534063
          }
        ]
      }
    ]
  },
  "task_name": "KorSarcasmClassification"
}