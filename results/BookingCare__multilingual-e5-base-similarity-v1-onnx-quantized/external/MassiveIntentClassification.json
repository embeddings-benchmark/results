{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.5997646267652992,
                "f1": 0.5726797883561521,
                "main_score": 0.5997646267652992
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.5365501008742435,
                "f1": 0.5041625838217704,
                "main_score": 0.5365501008742435
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.5745796906523201,
                "f1": 0.5330669054742219,
                "main_score": 0.5745796906523201
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.6259246805648957,
                "f1": 0.5981838196905149,
                "main_score": 0.6259246805648957
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.611264290517821,
                "f1": 0.5825993593933027,
                "main_score": 0.611264290517821
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.5005716207128447,
                "f1": 0.4696095728790911,
                "main_score": 0.5005716207128447
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.6664425016812374,
                "f1": 0.6285829169875576,
                "main_score": 0.6664425016812374
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.6608944182918628,
                "f1": 0.6244639030604241,
                "main_score": 0.6608944182918628
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.6468056489576328,
                "f1": 0.6177532675878951,
                "main_score": 0.6468056489576328
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.7211163416274377,
                "f1": 0.6970789096927015,
                "main_score": 0.7211163416274377
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.6840282447881642,
                "f1": 0.6638492065671895,
                "main_score": 0.6840282447881642
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.6724613315400134,
                "f1": 0.6433480195013359,
                "main_score": 0.6724613315400134
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.6578345662407531,
                "f1": 0.6221279452354622,
                "main_score": 0.6578345662407531
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.6794552790854069,
                "f1": 0.6548193124964093,
                "main_score": 0.6794552790854069
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.6205110961667788,
                "f1": 0.5809785656468454,
                "main_score": 0.6205110961667788
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.6495292535305985,
                "f1": 0.6209182174767901,
                "main_score": 0.6495292535305985
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.6497310020174848,
                "f1": 0.6114252567730396,
                "main_score": 0.6497310020174848
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.6008069939475453,
                "f1": 0.5704404174249204,
                "main_score": 0.6008069939475453
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.6663752521856086,
                "f1": 0.6388934090720532,
                "main_score": 0.6663752521856086
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.5638533960995293,
                "f1": 0.534490337500883,
                "main_score": 0.5638533960995293
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.6893073301950234,
                "f1": 0.659884357824104,
                "main_score": 0.6893073301950234
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.6894418291862812,
                "f1": 0.6648740222583132,
                "main_score": 0.6894418291862812
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.5426025554808339,
                "f1": 0.5019562815100793,
                "main_score": 0.5426025554808339
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.4898789509078682,
                "f1": 0.4665788438676836,
                "main_score": 0.4898789509078682
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.4468728984532616,
                "f1": 0.41642419349542,
                "main_score": 0.4468728984532616
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.5919300605245461,
                "f1": 0.558626492442437,
                "main_score": 0.5919300605245461
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.6633826496301277,
                "f1": 0.6389499791648792,
                "main_score": 0.6633826496301277
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.6033960995292535,
                "f1": 0.5715242464180892,
                "main_score": 0.6033960995292535
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.6309347679892402,
                "f1": 0.5964733214063841,
                "main_score": 0.6309347679892402
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.5875924680564896,
                "f1": 0.5596585692366827,
                "main_score": 0.5875924680564896
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.6248486886348352,
                "f1": 0.5945143559032946,
                "main_score": 0.6248486886348352
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.5856422326832549,
                "f1": 0.5496368702901926,
                "main_score": 0.5856422326832549
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.6618022864828512,
                "f1": 0.6305369805040634,
                "main_score": 0.6618022864828512
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.6730329522528581,
                "f1": 0.6406084612020727,
                "main_score": 0.6730329522528581
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.6836919973100202,
                "f1": 0.6512154124788887,
                "main_score": 0.6836919973100202
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.6898117014122395,
                "f1": 0.6641847559806962,
                "main_score": 0.6898117014122395
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.6553799596503026,
                "f1": 0.6217067330740818,
                "main_score": 0.6553799596503026
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.6901815736381977,
                "f1": 0.6624988369607843,
                "main_score": 0.6901815736381977
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.6234700739744452,
                "f1": 0.5995793342494163,
                "main_score": 0.6234700739744452
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.6123402824478815,
                "f1": 0.5798836976018471,
                "main_score": 0.6123402824478815
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.6854068594485541,
                "f1": 0.6543849680666856,
                "main_score": 0.6854068594485541
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.5599865501008743,
                "f1": 0.5283737515406804,
                "main_score": 0.5599865501008743
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.5871217215870882,
                "f1": 0.5505179497783302,
                "main_score": 0.5871217215870882
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.5972427706792199,
                "f1": 0.5633485571838306,
                "main_score": 0.5972427706792199
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.6559515803631473,
                "f1": 0.6496772366193588,
                "main_score": 0.6559515803631473
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.6086079354404841,
                "f1": 0.5814884581911539,
                "main_score": 0.6086079354404841
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.6740753194351043,
                "f1": 0.6318903778054699,
                "main_score": 0.6740753194351043
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.6152320107599194,
                "f1": 0.5835614456339852,
                "main_score": 0.6152320107599194
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.6617014122394083,
                "f1": 0.6391996406263892,
                "main_score": 0.6617014122394083
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.6915601882985878,
                "f1": 0.6701451905761371,
                "main_score": 0.6915601882985878
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.6465030262273034,
                "f1": 0.6414420425129063,
                "main_score": 0.6465030262273034
            }
        ]
    }
}