{
  "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
  "task_name": "NTREXBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.05197,
        "recall": 0.068102,
        "f1": 0.054972,
        "accuracy": 0.068102,
        "main_score": 0.054972,
        "hf_subset": "afr_Latn-dan_Latn",
        "languages": [
          "afr-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.06108,
        "recall": 0.085628,
        "f1": 0.065053,
        "accuracy": 0.085628,
        "main_score": 0.065053,
        "hf_subset": "afr_Latn-deu_Latn",
        "languages": [
          "afr-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.05735,
        "recall": 0.075613,
        "f1": 0.060098,
        "accuracy": 0.075613,
        "main_score": 0.060098,
        "hf_subset": "afr_Latn-eng_Latn",
        "languages": [
          "afr-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027284,
        "recall": 0.036054,
        "f1": 0.028587,
        "accuracy": 0.036054,
        "main_score": 0.028587,
        "hf_subset": "afr_Latn-fao_Latn",
        "languages": [
          "afr-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.021404,
        "recall": 0.032549,
        "f1": 0.022994,
        "accuracy": 0.032549,
        "main_score": 0.022994,
        "hf_subset": "afr_Latn-isl_Latn",
        "languages": [
          "afr-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.06521,
        "recall": 0.083625,
        "f1": 0.068633,
        "accuracy": 0.083625,
        "main_score": 0.068633,
        "hf_subset": "afr_Latn-ltz_Latn",
        "languages": [
          "afr-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.290293,
        "recall": 0.363545,
        "f1": 0.307354,
        "accuracy": 0.363545,
        "main_score": 0.307354,
        "hf_subset": "afr_Latn-nld_Latn",
        "languages": [
          "afr-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.04703,
        "recall": 0.058087,
        "f1": 0.049132,
        "accuracy": 0.058087,
        "main_score": 0.049132,
        "hf_subset": "afr_Latn-nno_Latn",
        "languages": [
          "afr-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.060464,
        "recall": 0.076615,
        "f1": 0.063566,
        "accuracy": 0.076615,
        "main_score": 0.063566,
        "hf_subset": "afr_Latn-nob_Latn",
        "languages": [
          "afr-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.049012,
        "recall": 0.065098,
        "f1": 0.051857,
        "accuracy": 0.065098,
        "main_score": 0.051857,
        "hf_subset": "afr_Latn-swe_Latn",
        "languages": [
          "afr-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.058975,
        "recall": 0.078117,
        "f1": 0.063244,
        "accuracy": 0.078117,
        "main_score": 0.063244,
        "hf_subset": "amh_Ethi-eng_Latn",
        "languages": [
          "amh-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018383,
        "recall": 0.034552,
        "f1": 0.021246,
        "accuracy": 0.034552,
        "main_score": 0.021246,
        "hf_subset": "amh_Ethi-hau_Latn",
        "languages": [
          "amh-Ethi",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.021536,
        "recall": 0.036555,
        "f1": 0.024053,
        "accuracy": 0.036555,
        "main_score": 0.024053,
        "hf_subset": "amh_Ethi-ibo_Latn",
        "languages": [
          "amh-Ethi",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.01812,
        "recall": 0.030045,
        "f1": 0.020392,
        "accuracy": 0.030045,
        "main_score": 0.020392,
        "hf_subset": "amh_Ethi-nso_Latn",
        "languages": [
          "amh-Ethi",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.01464,
        "recall": 0.025538,
        "f1": 0.016293,
        "accuracy": 0.025538,
        "main_score": 0.016293,
        "hf_subset": "amh_Ethi-orm_Ethi",
        "languages": [
          "amh-Ethi",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.017801,
        "recall": 0.02654,
        "f1": 0.01906,
        "accuracy": 0.02654,
        "main_score": 0.01906,
        "hf_subset": "amh_Ethi-som_Latn",
        "languages": [
          "amh-Ethi",
          "som-Latn"
        ]
      },
      {
        "precision": 0.01725,
        "recall": 0.027541,
        "f1": 0.018807,
        "accuracy": 0.027541,
        "main_score": 0.018807,
        "hf_subset": "amh_Ethi-ssw_Latn",
        "languages": [
          "amh-Ethi",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.014917,
        "recall": 0.024036,
        "f1": 0.016571,
        "accuracy": 0.024036,
        "main_score": 0.016571,
        "hf_subset": "amh_Ethi-swa_Latn",
        "languages": [
          "amh-Ethi",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.072287,
        "recall": 0.094642,
        "f1": 0.077811,
        "accuracy": 0.094642,
        "main_score": 0.077811,
        "hf_subset": "amh_Ethi-tir_Ethi",
        "languages": [
          "amh-Ethi",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.015222,
        "recall": 0.027041,
        "f1": 0.017297,
        "accuracy": 0.027041,
        "main_score": 0.017297,
        "hf_subset": "amh_Ethi-tsn_Latn",
        "languages": [
          "amh-Ethi",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.020243,
        "recall": 0.029544,
        "f1": 0.022076,
        "accuracy": 0.029544,
        "main_score": 0.022076,
        "hf_subset": "amh_Ethi-wol_Latn",
        "languages": [
          "amh-Ethi",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.011035,
        "recall": 0.021532,
        "f1": 0.0124,
        "accuracy": 0.021532,
        "main_score": 0.0124,
        "hf_subset": "amh_Ethi-xho_Latn",
        "languages": [
          "amh-Ethi",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.016333,
        "recall": 0.02654,
        "f1": 0.018234,
        "accuracy": 0.02654,
        "main_score": 0.018234,
        "hf_subset": "amh_Ethi-yor_Latn",
        "languages": [
          "amh-Ethi",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.018898,
        "recall": 0.031547,
        "f1": 0.020839,
        "accuracy": 0.031547,
        "main_score": 0.020839,
        "hf_subset": "amh_Ethi-zul_Latn",
        "languages": [
          "amh-Ethi",
          "zul-Latn"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001002,
        "f1": 7e-06,
        "accuracy": 0.001002,
        "main_score": 7e-06,
        "hf_subset": "arb_Arab-ben_Beng",
        "languages": [
          "arb-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 2.8e-05,
        "recall": 0.001502,
        "f1": 5.4e-05,
        "accuracy": 0.001502,
        "main_score": 5.4e-05,
        "hf_subset": "arb_Arab-ckb_Arab",
        "languages": [
          "arb-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "arb_Arab-deu_Latn",
        "languages": [
          "arb-Arab",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-ell_Grek",
        "languages": [
          "arb-Arab",
          "ell-Grek"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001002,
        "f1": 7e-06,
        "accuracy": 0.001002,
        "main_score": 7e-06,
        "hf_subset": "arb_Arab-eng_Latn",
        "languages": [
          "arb-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0012,
        "recall": 0.003505,
        "f1": 0.001479,
        "accuracy": 0.003505,
        "main_score": 0.001479,
        "hf_subset": "arb_Arab-fas_Arab",
        "languages": [
          "arb-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.001002,
        "f1": 1.5e-05,
        "accuracy": 0.001002,
        "main_score": 1.5e-05,
        "hf_subset": "arb_Arab-fin_Latn",
        "languages": [
          "arb-Arab",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "arb_Arab-fra_Latn",
        "languages": [
          "arb-Arab",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000252,
        "recall": 0.001502,
        "f1": 0.000336,
        "accuracy": 0.001502,
        "main_score": 0.000336,
        "hf_subset": "arb_Arab-heb_Hebr",
        "languages": [
          "arb-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001502,
        "f1": 1e-05,
        "accuracy": 0.001502,
        "main_score": 1e-05,
        "hf_subset": "arb_Arab-hin_Deva",
        "languages": [
          "arb-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001002,
        "f1": 8e-06,
        "accuracy": 0.001002,
        "main_score": 8e-06,
        "hf_subset": "arb_Arab-hun_Latn",
        "languages": [
          "arb-Arab",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-ind_Latn",
        "languages": [
          "arb-Arab",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000505,
        "recall": 0.001502,
        "f1": 0.000508,
        "accuracy": 0.001502,
        "main_score": 0.000508,
        "hf_subset": "arb_Arab-jpn_Jpan",
        "languages": [
          "arb-Arab",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 5e-06,
        "accuracy": 0.001002,
        "main_score": 5e-06,
        "hf_subset": "arb_Arab-kmr_Latn",
        "languages": [
          "arb-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "arb_Arab-kor_Hang",
        "languages": [
          "arb-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 8.4e-05,
        "recall": 0.001002,
        "f1": 0.000144,
        "accuracy": 0.001002,
        "main_score": 0.000144,
        "hf_subset": "arb_Arab-lit_Latn",
        "languages": [
          "arb-Arab",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.116113,
        "recall": 0.17977,
        "f1": 0.130277,
        "accuracy": 0.17977,
        "main_score": 0.130277,
        "hf_subset": "arb_Arab-mey_Arab",
        "languages": [
          "arb-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-nld_Latn",
        "languages": [
          "arb-Arab",
          "nld-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "arb_Arab-pol_Latn",
        "languages": [
          "arb-Arab",
          "pol-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-por_Latn",
        "languages": [
          "arb-Arab",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001302,
        "recall": 0.003005,
        "f1": 0.001431,
        "accuracy": 0.003005,
        "main_score": 0.001431,
        "hf_subset": "arb_Arab-prs_Arab",
        "languages": [
          "arb-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.001609,
        "recall": 0.004006,
        "f1": 0.0017,
        "accuracy": 0.004006,
        "main_score": 0.0017,
        "hf_subset": "arb_Arab-pus_Arab",
        "languages": [
          "arb-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 1.6e-05,
        "recall": 0.002003,
        "f1": 3.1e-05,
        "accuracy": 0.002003,
        "main_score": 3.1e-05,
        "hf_subset": "arb_Arab-rus_Cyrl",
        "languages": [
          "arb-Arab",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.016844,
        "recall": 0.031547,
        "f1": 0.018886,
        "accuracy": 0.031547,
        "main_score": 0.018886,
        "hf_subset": "arb_Arab-shi_Arab",
        "languages": [
          "arb-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-spa_Latn",
        "languages": [
          "arb-Arab",
          "spa-Latn"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001002,
        "f1": 1e-05,
        "accuracy": 0.001002,
        "main_score": 1e-05,
        "hf_subset": "arb_Arab-swa_Latn",
        "languages": [
          "arb-Arab",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "arb_Arab-swe_Latn",
        "languages": [
          "arb-Arab",
          "swe-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "arb_Arab-tam_Taml",
        "languages": [
          "arb-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 2.8e-05,
        "recall": 0.000501,
        "f1": 5.3e-05,
        "accuracy": 0.000501,
        "main_score": 5.3e-05,
        "hf_subset": "arb_Arab-tgk_Cyrl",
        "languages": [
          "arb-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 1.9e-05,
        "recall": 0.001002,
        "f1": 3.7e-05,
        "accuracy": 0.001002,
        "main_score": 3.7e-05,
        "hf_subset": "arb_Arab-tur_Latn",
        "languages": [
          "arb-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "arb_Arab-vie_Latn",
        "languages": [
          "arb-Arab",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-zho_Hant",
        "languages": [
          "arb-Arab",
          "zho-Hant"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001002,
        "f1": 7e-06,
        "accuracy": 0.001002,
        "main_score": 7e-06,
        "hf_subset": "arb_Arab-zul_Latn",
        "languages": [
          "arb-Arab",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.001556,
        "recall": 0.004006,
        "f1": 0.001774,
        "accuracy": 0.004006,
        "main_score": 0.001774,
        "hf_subset": "aze_Latn-bak_Cyrl",
        "languages": [
          "aze-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.00763,
        "recall": 0.011517,
        "f1": 0.00813,
        "accuracy": 0.011517,
        "main_score": 0.00813,
        "hf_subset": "aze_Latn-eng_Latn",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00258,
        "recall": 0.005008,
        "f1": 0.002901,
        "accuracy": 0.005008,
        "main_score": 0.002901,
        "hf_subset": "aze_Latn-kaz_Cyrl",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.003152,
        "recall": 0.008513,
        "f1": 0.003729,
        "accuracy": 0.008513,
        "main_score": 0.003729,
        "hf_subset": "aze_Latn-kir_Cyrl",
        "languages": [
          "aze-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.001302,
        "recall": 0.002003,
        "f1": 0.001426,
        "accuracy": 0.002003,
        "main_score": 0.001426,
        "hf_subset": "aze_Latn-tat_Cyrl",
        "languages": [
          "aze-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.01278,
        "recall": 0.020531,
        "f1": 0.013865,
        "accuracy": 0.020531,
        "main_score": 0.013865,
        "hf_subset": "aze_Latn-tuk_Latn",
        "languages": [
          "aze-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.035636,
        "recall": 0.05308,
        "f1": 0.038495,
        "accuracy": 0.05308,
        "main_score": 0.038495,
        "hf_subset": "aze_Latn-tur_Latn",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.00175,
        "recall": 0.005508,
        "f1": 0.00195,
        "accuracy": 0.005508,
        "main_score": 0.00195,
        "hf_subset": "aze_Latn-uig_Arab",
        "languages": [
          "aze-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.016038,
        "recall": 0.024537,
        "f1": 0.016834,
        "accuracy": 0.024537,
        "main_score": 0.016834,
        "hf_subset": "aze_Latn-uzb_Latn",
        "languages": [
          "aze-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.002536,
        "recall": 0.005008,
        "f1": 0.002566,
        "accuracy": 0.005008,
        "main_score": 0.002566,
        "hf_subset": "bak_Cyrl-aze_Latn",
        "languages": [
          "bak-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.004133,
        "recall": 0.00651,
        "f1": 0.004399,
        "accuracy": 0.00651,
        "main_score": 0.004399,
        "hf_subset": "bak_Cyrl-eng_Latn",
        "languages": [
          "bak-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030664,
        "recall": 0.062594,
        "f1": 0.03668,
        "accuracy": 0.062594,
        "main_score": 0.03668,
        "hf_subset": "bak_Cyrl-kaz_Cyrl",
        "languages": [
          "bak-Cyrl",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.027761,
        "recall": 0.056084,
        "f1": 0.033587,
        "accuracy": 0.056084,
        "main_score": 0.033587,
        "hf_subset": "bak_Cyrl-kir_Cyrl",
        "languages": [
          "bak-Cyrl",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.086264,
        "recall": 0.142213,
        "f1": 0.099499,
        "accuracy": 0.142213,
        "main_score": 0.099499,
        "hf_subset": "bak_Cyrl-tat_Cyrl",
        "languages": [
          "bak-Cyrl",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.002574,
        "recall": 0.004507,
        "f1": 0.002632,
        "accuracy": 0.004507,
        "main_score": 0.002632,
        "hf_subset": "bak_Cyrl-tuk_Latn",
        "languages": [
          "bak-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.00281,
        "recall": 0.004507,
        "f1": 0.002944,
        "accuracy": 0.004507,
        "main_score": 0.002944,
        "hf_subset": "bak_Cyrl-tur_Latn",
        "languages": [
          "bak-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000546,
        "recall": 0.001002,
        "f1": 0.000584,
        "accuracy": 0.001002,
        "main_score": 0.000584,
        "hf_subset": "bak_Cyrl-uig_Arab",
        "languages": [
          "bak-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.001531,
        "recall": 0.002504,
        "f1": 0.001556,
        "accuracy": 0.002504,
        "main_score": 0.001556,
        "hf_subset": "bak_Cyrl-uzb_Latn",
        "languages": [
          "bak-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.000752,
        "recall": 0.001502,
        "f1": 0.000836,
        "accuracy": 0.001502,
        "main_score": 0.000836,
        "hf_subset": "bel_Cyrl-bos_Latn",
        "languages": [
          "bel-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.011353,
        "recall": 0.024036,
        "f1": 0.01307,
        "accuracy": 0.024036,
        "main_score": 0.01307,
        "hf_subset": "bel_Cyrl-bul_Cyrl",
        "languages": [
          "bel-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.000526,
        "recall": 0.001502,
        "f1": 0.00055,
        "accuracy": 0.001502,
        "main_score": 0.00055,
        "hf_subset": "bel_Cyrl-ces_Latn",
        "languages": [
          "bel-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 6.3e-05,
        "recall": 0.001002,
        "f1": 0.000113,
        "accuracy": 0.001002,
        "main_score": 0.000113,
        "hf_subset": "bel_Cyrl-eng_Latn",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001003,
        "accuracy": 0.001502,
        "main_score": 0.001003,
        "hf_subset": "bel_Cyrl-hrv_Latn",
        "languages": [
          "bel-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.007605,
        "recall": 0.015523,
        "f1": 0.008753,
        "accuracy": 0.015523,
        "main_score": 0.008753,
        "hf_subset": "bel_Cyrl-mkd_Cyrl",
        "languages": [
          "bel-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "bel_Cyrl-pol_Latn",
        "languages": [
          "bel-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.024804,
        "recall": 0.046069,
        "f1": 0.027912,
        "accuracy": 0.046069,
        "main_score": 0.027912,
        "hf_subset": "bel_Cyrl-rus_Cyrl",
        "languages": [
          "bel-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.000506,
        "recall": 0.002003,
        "f1": 0.000512,
        "accuracy": 0.002003,
        "main_score": 0.000512,
        "hf_subset": "bel_Cyrl-slk_Latn",
        "languages": [
          "bel-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 2e-05,
        "recall": 0.001002,
        "f1": 3.9e-05,
        "accuracy": 0.001002,
        "main_score": 3.9e-05,
        "hf_subset": "bel_Cyrl-slv_Latn",
        "languages": [
          "bel-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.009537,
        "recall": 0.020531,
        "f1": 0.011098,
        "accuracy": 0.020531,
        "main_score": 0.011098,
        "hf_subset": "bel_Cyrl-srp_Cyrl",
        "languages": [
          "bel-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.001011,
        "recall": 0.002504,
        "f1": 0.001021,
        "accuracy": 0.002504,
        "main_score": 0.001021,
        "hf_subset": "bel_Cyrl-srp_Latn",
        "languages": [
          "bel-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.039012,
        "recall": 0.070606,
        "f1": 0.044071,
        "accuracy": 0.070606,
        "main_score": 0.044071,
        "hf_subset": "bel_Cyrl-ukr_Cyrl",
        "languages": [
          "bel-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.026273,
        "recall": 0.039059,
        "f1": 0.027785,
        "accuracy": 0.039059,
        "main_score": 0.027785,
        "hf_subset": "bem_Latn-eng_Latn",
        "languages": [
          "bem-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006763,
        "recall": 0.011017,
        "f1": 0.007483,
        "accuracy": 0.011017,
        "main_score": 0.007483,
        "hf_subset": "bem_Latn-ewe_Latn",
        "languages": [
          "bem-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.009074,
        "recall": 0.01302,
        "f1": 0.009529,
        "accuracy": 0.01302,
        "main_score": 0.009529,
        "hf_subset": "bem_Latn-fuc_Latn",
        "languages": [
          "bem-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.014273,
        "recall": 0.020531,
        "f1": 0.015332,
        "accuracy": 0.020531,
        "main_score": 0.015332,
        "hf_subset": "bem_Latn-kin_Latn",
        "languages": [
          "bem-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.009006,
        "recall": 0.015523,
        "f1": 0.009779,
        "accuracy": 0.015523,
        "main_score": 0.009779,
        "hf_subset": "bem_Latn-nde_Latn",
        "languages": [
          "bem-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.020921,
        "recall": 0.028543,
        "f1": 0.022001,
        "accuracy": 0.028543,
        "main_score": 0.022001,
        "hf_subset": "bem_Latn-nya_Latn",
        "languages": [
          "bem-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.009153,
        "recall": 0.015023,
        "f1": 0.009953,
        "accuracy": 0.015023,
        "main_score": 0.009953,
        "hf_subset": "bem_Latn-sna_Latn",
        "languages": [
          "bem-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.013019,
        "recall": 0.016525,
        "f1": 0.013298,
        "accuracy": 0.016525,
        "main_score": 0.013298,
        "hf_subset": "bem_Latn-ven_Latn",
        "languages": [
          "bem-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 5.9e-05,
        "recall": 0.001002,
        "f1": 0.000108,
        "accuracy": 0.001002,
        "main_score": 0.000108,
        "hf_subset": "ben_Beng-arb_Arab",
        "languages": [
          "ben-Beng",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "ben_Beng-deu_Latn",
        "languages": [
          "ben-Beng",
          "deu-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 5e-06,
        "accuracy": 0.001002,
        "main_score": 5e-06,
        "hf_subset": "ben_Beng-div_Thaa",
        "languages": [
          "ben-Beng",
          "div-Thaa"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-ell_Grek",
        "languages": [
          "ben-Beng",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.001012,
        "recall": 0.002504,
        "f1": 0.001022,
        "accuracy": 0.002504,
        "main_score": 0.001022,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000351,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "ben_Beng-eus_Latn",
        "languages": [
          "ben-Beng",
          "eus-Latn"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 6e-06,
        "accuracy": 0.001002,
        "main_score": 6e-06,
        "hf_subset": "ben_Beng-fas_Arab",
        "languages": [
          "ben-Beng",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000204,
        "recall": 0.001502,
        "f1": 0.00032,
        "accuracy": 0.001502,
        "main_score": 0.00032,
        "hf_subset": "ben_Beng-fin_Latn",
        "languages": [
          "ben-Beng",
          "fin-Latn"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.001002,
        "f1": 2.2e-05,
        "accuracy": 0.001002,
        "main_score": 2.2e-05,
        "hf_subset": "ben_Beng-fra_Latn",
        "languages": [
          "ben-Beng",
          "fra-Latn"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.001502,
        "f1": 1.3e-05,
        "accuracy": 0.001502,
        "main_score": 1.3e-05,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000821,
        "recall": 0.002003,
        "f1": 0.00096,
        "accuracy": 0.002003,
        "main_score": 0.00096,
        "hf_subset": "ben_Beng-heb_Hebr",
        "languages": [
          "ben-Beng",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000125,
        "recall": 0.001002,
        "f1": 0.000201,
        "accuracy": 0.001002,
        "main_score": 0.000201,
        "hf_subset": "ben_Beng-hun_Latn",
        "languages": [
          "ben-Beng",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000335,
        "accuracy": 0.001002,
        "main_score": 0.000335,
        "hf_subset": "ben_Beng-ind_Latn",
        "languages": [
          "ben-Beng",
          "ind-Latn"
        ]
      },
      {
        "precision": 1.8e-05,
        "recall": 0.001502,
        "f1": 3.5e-05,
        "accuracy": 0.001502,
        "main_score": 3.5e-05,
        "hf_subset": "ben_Beng-jpn_Jpan",
        "languages": [
          "ben-Beng",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000573,
        "recall": 0.002504,
        "f1": 0.000634,
        "accuracy": 0.002504,
        "main_score": 0.000634,
        "hf_subset": "ben_Beng-kor_Hang",
        "languages": [
          "ben-Beng",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.000209,
        "recall": 0.001502,
        "f1": 0.000345,
        "accuracy": 0.001502,
        "main_score": 0.000345,
        "hf_subset": "ben_Beng-lit_Latn",
        "languages": [
          "ben-Beng",
          "lit-Latn"
        ]
      },
      {
        "precision": 5.4e-05,
        "recall": 0.001502,
        "f1": 0.000101,
        "accuracy": 0.001502,
        "main_score": 0.000101,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00127,
        "recall": 0.002504,
        "f1": 0.001422,
        "accuracy": 0.002504,
        "main_score": 0.001422,
        "hf_subset": "ben_Beng-nep_Deva",
        "languages": [
          "ben-Beng",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "ben_Beng-nld_Latn",
        "languages": [
          "ben-Beng",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000673,
        "recall": 0.002003,
        "f1": 0.000762,
        "accuracy": 0.002003,
        "main_score": 0.000762,
        "hf_subset": "ben_Beng-pol_Latn",
        "languages": [
          "ben-Beng",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.000604,
        "recall": 0.002504,
        "f1": 0.000682,
        "accuracy": 0.002504,
        "main_score": 0.000682,
        "hf_subset": "ben_Beng-por_Latn",
        "languages": [
          "ben-Beng",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001268,
        "recall": 0.002003,
        "f1": 0.001366,
        "accuracy": 0.002003,
        "main_score": 0.001366,
        "hf_subset": "ben_Beng-rus_Cyrl",
        "languages": [
          "ben-Beng",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-sin_Sinh",
        "languages": [
          "ben-Beng",
          "sin-Sinh"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-snd_Arab",
        "languages": [
          "ben-Beng",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "ben_Beng-spa_Latn",
        "languages": [
          "ben-Beng",
          "spa-Latn"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001002,
        "f1": 9e-06,
        "accuracy": 0.001002,
        "main_score": 9e-06,
        "hf_subset": "ben_Beng-swa_Latn",
        "languages": [
          "ben-Beng",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000257,
        "recall": 0.001502,
        "f1": 0.000346,
        "accuracy": 0.001502,
        "main_score": 0.000346,
        "hf_subset": "ben_Beng-swe_Latn",
        "languages": [
          "ben-Beng",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000585,
        "recall": 0.001502,
        "f1": 0.000646,
        "accuracy": 0.001502,
        "main_score": 0.000646,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001002,
        "f1": 0.000505,
        "accuracy": 0.001002,
        "main_score": 0.000505,
        "hf_subset": "ben_Beng-tur_Latn",
        "languages": [
          "ben-Beng",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.00068,
        "recall": 0.002003,
        "f1": 0.000775,
        "accuracy": 0.002003,
        "main_score": 0.000775,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001002,
        "f1": 0.000506,
        "accuracy": 0.001002,
        "main_score": 0.000506,
        "hf_subset": "ben_Beng-vie_Latn",
        "languages": [
          "ben-Beng",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.000167,
        "recall": 0.000501,
        "f1": 0.00025,
        "accuracy": 0.000501,
        "main_score": 0.00025,
        "hf_subset": "ben_Beng-zho_Hant",
        "languages": [
          "ben-Beng",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.001008,
        "recall": 0.002003,
        "f1": 0.001015,
        "accuracy": 0.002003,
        "main_score": 0.001015,
        "hf_subset": "ben_Beng-zul_Latn",
        "languages": [
          "ben-Beng",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.003276,
        "recall": 0.005508,
        "f1": 0.003817,
        "accuracy": 0.005508,
        "main_score": 0.003817,
        "hf_subset": "bod_Tibt-dzo_Tibt",
        "languages": [
          "bod-Tibt",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.005092,
        "recall": 0.00651,
        "f1": 0.005343,
        "accuracy": 0.00651,
        "main_score": 0.005343,
        "hf_subset": "bod_Tibt-eng_Latn",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003506,
        "recall": 0.004006,
        "f1": 0.003506,
        "accuracy": 0.004006,
        "main_score": 0.003506,
        "hf_subset": "bod_Tibt-khm_Khmr",
        "languages": [
          "bod-Tibt",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.002779,
        "recall": 0.005008,
        "f1": 0.002886,
        "accuracy": 0.005008,
        "main_score": 0.002886,
        "hf_subset": "bod_Tibt-lao_Laoo",
        "languages": [
          "bod-Tibt",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.000673,
        "recall": 0.002003,
        "f1": 0.000763,
        "accuracy": 0.002003,
        "main_score": 0.000763,
        "hf_subset": "bod_Tibt-mon_Mong",
        "languages": [
          "bod-Tibt",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.003005,
        "recall": 0.003505,
        "f1": 0.003005,
        "accuracy": 0.003505,
        "main_score": 0.003005,
        "hf_subset": "bod_Tibt-mya_Mymr",
        "languages": [
          "bod-Tibt",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000503,
        "accuracy": 0.001502,
        "main_score": 0.000503,
        "hf_subset": "bod_Tibt-tha_Thai",
        "languages": [
          "bod-Tibt",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.002578,
        "recall": 0.00651,
        "f1": 0.003046,
        "accuracy": 0.00651,
        "main_score": 0.003046,
        "hf_subset": "bos_Latn-bel_Cyrl",
        "languages": [
          "bos-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.003045,
        "recall": 0.011517,
        "f1": 0.003935,
        "accuracy": 0.011517,
        "main_score": 0.003935,
        "hf_subset": "bos_Latn-bul_Cyrl",
        "languages": [
          "bos-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.050911,
        "recall": 0.070606,
        "f1": 0.054854,
        "accuracy": 0.070606,
        "main_score": 0.054854,
        "hf_subset": "bos_Latn-ces_Latn",
        "languages": [
          "bos-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.01965,
        "recall": 0.024036,
        "f1": 0.020329,
        "accuracy": 0.024036,
        "main_score": 0.020329,
        "hf_subset": "bos_Latn-eng_Latn",
        "languages": [
          "bos-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.751991,
        "recall": 0.817727,
        "f1": 0.771264,
        "accuracy": 0.817727,
        "main_score": 0.771264,
        "hf_subset": "bos_Latn-hrv_Latn",
        "languages": [
          "bos-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.005926,
        "recall": 0.017526,
        "f1": 0.007254,
        "accuracy": 0.017526,
        "main_score": 0.007254,
        "hf_subset": "bos_Latn-mkd_Cyrl",
        "languages": [
          "bos-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.019171,
        "recall": 0.032048,
        "f1": 0.021363,
        "accuracy": 0.032048,
        "main_score": 0.021363,
        "hf_subset": "bos_Latn-pol_Latn",
        "languages": [
          "bos-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.003828,
        "recall": 0.010015,
        "f1": 0.004472,
        "accuracy": 0.010015,
        "main_score": 0.004472,
        "hf_subset": "bos_Latn-rus_Cyrl",
        "languages": [
          "bos-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.064901,
        "recall": 0.089134,
        "f1": 0.068405,
        "accuracy": 0.089134,
        "main_score": 0.068405,
        "hf_subset": "bos_Latn-slk_Latn",
        "languages": [
          "bos-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.182467,
        "recall": 0.240861,
        "f1": 0.194484,
        "accuracy": 0.240861,
        "main_score": 0.194484,
        "hf_subset": "bos_Latn-slv_Latn",
        "languages": [
          "bos-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.010161,
        "recall": 0.024036,
        "f1": 0.011773,
        "accuracy": 0.024036,
        "main_score": 0.011773,
        "hf_subset": "bos_Latn-srp_Cyrl",
        "languages": [
          "bos-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.742774,
        "recall": 0.809214,
        "f1": 0.762408,
        "accuracy": 0.809214,
        "main_score": 0.762408,
        "hf_subset": "bos_Latn-srp_Latn",
        "languages": [
          "bos-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.003184,
        "recall": 0.009514,
        "f1": 0.00366,
        "accuracy": 0.009514,
        "main_score": 0.00366,
        "hf_subset": "bos_Latn-ukr_Cyrl",
        "languages": [
          "bos-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.005795,
        "recall": 0.012519,
        "f1": 0.00648,
        "accuracy": 0.012519,
        "main_score": 0.00648,
        "hf_subset": "bul_Cyrl-bel_Cyrl",
        "languages": [
          "bul-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.001264,
        "recall": 0.003505,
        "f1": 0.001359,
        "accuracy": 0.003505,
        "main_score": 0.001359,
        "hf_subset": "bul_Cyrl-bos_Latn",
        "languages": [
          "bul-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.001018,
        "recall": 0.002003,
        "f1": 0.001034,
        "accuracy": 0.002003,
        "main_score": 0.001034,
        "hf_subset": "bul_Cyrl-ces_Latn",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002003,
        "f1": 0.001504,
        "accuracy": 0.002003,
        "main_score": 0.001504,
        "hf_subset": "bul_Cyrl-eng_Latn",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001772,
        "recall": 0.003505,
        "f1": 0.001925,
        "accuracy": 0.003505,
        "main_score": 0.001925,
        "hf_subset": "bul_Cyrl-hrv_Latn",
        "languages": [
          "bul-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.087045,
        "recall": 0.134201,
        "f1": 0.097261,
        "accuracy": 0.134201,
        "main_score": 0.097261,
        "hf_subset": "bul_Cyrl-mkd_Cyrl",
        "languages": [
          "bul-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.001005,
        "recall": 0.001502,
        "f1": 0.001009,
        "accuracy": 0.001502,
        "main_score": 0.001009,
        "hf_subset": "bul_Cyrl-pol_Latn",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.026765,
        "recall": 0.050075,
        "f1": 0.030577,
        "accuracy": 0.050075,
        "main_score": 0.030577,
        "hf_subset": "bul_Cyrl-rus_Cyrl",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.001056,
        "recall": 0.003005,
        "f1": 0.001105,
        "accuracy": 0.003005,
        "main_score": 0.001105,
        "hf_subset": "bul_Cyrl-slk_Latn",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "bul_Cyrl-slv_Latn",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.016538,
        "recall": 0.027041,
        "f1": 0.018287,
        "accuracy": 0.027041,
        "main_score": 0.018287,
        "hf_subset": "bul_Cyrl-srp_Cyrl",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.001252,
        "recall": 0.002003,
        "f1": 0.001336,
        "accuracy": 0.002003,
        "main_score": 0.001336,
        "hf_subset": "bul_Cyrl-srp_Latn",
        "languages": [
          "bul-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.005484,
        "recall": 0.012018,
        "f1": 0.006256,
        "accuracy": 0.012018,
        "main_score": 0.006256,
        "hf_subset": "bul_Cyrl-ukr_Cyrl",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.059941,
        "recall": 0.076615,
        "f1": 0.062547,
        "accuracy": 0.076615,
        "main_score": 0.062547,
        "hf_subset": "cat_Latn-eng_Latn",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.124326,
        "recall": 0.171758,
        "f1": 0.133537,
        "accuracy": 0.171758,
        "main_score": 0.133537,
        "hf_subset": "cat_Latn-fra_Latn",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.288333,
        "recall": 0.359039,
        "f1": 0.30423,
        "accuracy": 0.359039,
        "main_score": 0.30423,
        "hf_subset": "cat_Latn-glg_Latn",
        "languages": [
          "cat-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.123517,
        "recall": 0.161242,
        "f1": 0.1309,
        "accuracy": 0.161242,
        "main_score": 0.1309,
        "hf_subset": "cat_Latn-ita_Latn",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.038955,
        "recall": 0.05308,
        "f1": 0.041113,
        "accuracy": 0.05308,
        "main_score": 0.041113,
        "hf_subset": "cat_Latn-mlt_Latn",
        "languages": [
          "cat-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.216992,
        "recall": 0.274912,
        "f1": 0.229302,
        "accuracy": 0.274912,
        "main_score": 0.229302,
        "hf_subset": "cat_Latn-por_Latn",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.068312,
        "recall": 0.09364,
        "f1": 0.072829,
        "accuracy": 0.09364,
        "main_score": 0.072829,
        "hf_subset": "cat_Latn-ron_Latn",
        "languages": [
          "cat-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.378376,
        "recall": 0.454181,
        "f1": 0.396285,
        "accuracy": 0.454181,
        "main_score": 0.396285,
        "hf_subset": "cat_Latn-spa_Latn",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.002897,
        "recall": 0.008012,
        "f1": 0.003642,
        "accuracy": 0.008012,
        "main_score": 0.003642,
        "hf_subset": "ces_Latn-bel_Cyrl",
        "languages": [
          "ces-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.08203,
        "recall": 0.107161,
        "f1": 0.087217,
        "accuracy": 0.107161,
        "main_score": 0.087217,
        "hf_subset": "ces_Latn-bos_Latn",
        "languages": [
          "ces-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.003075,
        "recall": 0.009014,
        "f1": 0.003998,
        "accuracy": 0.009014,
        "main_score": 0.003998,
        "hf_subset": "ces_Latn-bul_Cyrl",
        "languages": [
          "ces-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.036223,
        "recall": 0.045068,
        "f1": 0.037858,
        "accuracy": 0.045068,
        "main_score": 0.037858,
        "hf_subset": "ces_Latn-eng_Latn",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.070658,
        "recall": 0.10015,
        "f1": 0.076985,
        "accuracy": 0.10015,
        "main_score": 0.076985,
        "hf_subset": "ces_Latn-hrv_Latn",
        "languages": [
          "ces-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.003755,
        "recall": 0.010516,
        "f1": 0.004659,
        "accuracy": 0.010516,
        "main_score": 0.004659,
        "hf_subset": "ces_Latn-mkd_Cyrl",
        "languages": [
          "ces-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.069942,
        "recall": 0.100651,
        "f1": 0.075686,
        "accuracy": 0.100651,
        "main_score": 0.075686,
        "hf_subset": "ces_Latn-pol_Latn",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001884,
        "recall": 0.007511,
        "f1": 0.002441,
        "accuracy": 0.007511,
        "main_score": 0.002441,
        "hf_subset": "ces_Latn-rus_Cyrl",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.524876,
        "recall": 0.608913,
        "f1": 0.54603,
        "accuracy": 0.608913,
        "main_score": 0.54603,
        "hf_subset": "ces_Latn-slk_Latn",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.087339,
        "recall": 0.118678,
        "f1": 0.093993,
        "accuracy": 0.118678,
        "main_score": 0.093993,
        "hf_subset": "ces_Latn-slv_Latn",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.003503,
        "recall": 0.009514,
        "f1": 0.004095,
        "accuracy": 0.009514,
        "main_score": 0.004095,
        "hf_subset": "ces_Latn-srp_Cyrl",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.055051,
        "recall": 0.079619,
        "f1": 0.059976,
        "accuracy": 0.079619,
        "main_score": 0.059976,
        "hf_subset": "ces_Latn-srp_Latn",
        "languages": [
          "ces-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.003964,
        "recall": 0.011517,
        "f1": 0.005045,
        "accuracy": 0.011517,
        "main_score": 0.005045,
        "hf_subset": "ces_Latn-ukr_Cyrl",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.000597,
        "recall": 0.003005,
        "f1": 0.000683,
        "accuracy": 0.003005,
        "main_score": 0.000683,
        "hf_subset": "ckb_Arab-arb_Arab",
        "languages": [
          "ckb-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001163,
        "recall": 0.004006,
        "f1": 0.001446,
        "accuracy": 0.004006,
        "main_score": 0.001446,
        "hf_subset": "ckb_Arab-eng_Latn",
        "languages": [
          "ckb-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002563,
        "recall": 0.006009,
        "f1": 0.002922,
        "accuracy": 0.006009,
        "main_score": 0.002922,
        "hf_subset": "ckb_Arab-fas_Arab",
        "languages": [
          "ckb-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000232,
        "recall": 0.002504,
        "f1": 0.000409,
        "accuracy": 0.002504,
        "main_score": 0.000409,
        "hf_subset": "ckb_Arab-heb_Hebr",
        "languages": [
          "ckb-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000549,
        "recall": 0.002003,
        "f1": 0.000593,
        "accuracy": 0.002003,
        "main_score": 0.000593,
        "hf_subset": "ckb_Arab-kmr_Latn",
        "languages": [
          "ckb-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000591,
        "recall": 0.002504,
        "f1": 0.000875,
        "accuracy": 0.002504,
        "main_score": 0.000875,
        "hf_subset": "ckb_Arab-mey_Arab",
        "languages": [
          "ckb-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.002213,
        "recall": 0.008012,
        "f1": 0.002917,
        "accuracy": 0.008012,
        "main_score": 0.002917,
        "hf_subset": "ckb_Arab-prs_Arab",
        "languages": [
          "ckb-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000654,
        "recall": 0.003505,
        "f1": 0.000792,
        "accuracy": 0.003505,
        "main_score": 0.000792,
        "hf_subset": "ckb_Arab-pus_Arab",
        "languages": [
          "ckb-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.000724,
        "recall": 0.003505,
        "f1": 0.00091,
        "accuracy": 0.003505,
        "main_score": 0.00091,
        "hf_subset": "ckb_Arab-shi_Arab",
        "languages": [
          "ckb-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.000603,
        "recall": 0.002003,
        "f1": 0.000691,
        "accuracy": 0.002003,
        "main_score": 0.000691,
        "hf_subset": "ckb_Arab-tgk_Cyrl",
        "languages": [
          "ckb-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.025611,
        "recall": 0.03305,
        "f1": 0.02643,
        "accuracy": 0.03305,
        "main_score": 0.02643,
        "hf_subset": "cym_Latn-eng_Latn",
        "languages": [
          "cym-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013202,
        "recall": 0.019529,
        "f1": 0.014121,
        "accuracy": 0.019529,
        "main_score": 0.014121,
        "hf_subset": "cym_Latn-gle_Latn",
        "languages": [
          "cym-Latn",
          "gle-Latn"
        ]
      },
      {
        "precision": 0.063923,
        "recall": 0.081622,
        "f1": 0.067086,
        "accuracy": 0.081622,
        "main_score": 0.067086,
        "hf_subset": "dan_Latn-afr_Latn",
        "languages": [
          "dan-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.062367,
        "recall": 0.083125,
        "f1": 0.066156,
        "accuracy": 0.083125,
        "main_score": 0.066156,
        "hf_subset": "dan_Latn-deu_Latn",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.066018,
        "recall": 0.088132,
        "f1": 0.069622,
        "accuracy": 0.088132,
        "main_score": 0.069622,
        "hf_subset": "dan_Latn-eng_Latn",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.072884,
        "recall": 0.094141,
        "f1": 0.077578,
        "accuracy": 0.094141,
        "main_score": 0.077578,
        "hf_subset": "dan_Latn-fao_Latn",
        "languages": [
          "dan-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.048541,
        "recall": 0.067601,
        "f1": 0.051709,
        "accuracy": 0.067601,
        "main_score": 0.051709,
        "hf_subset": "dan_Latn-isl_Latn",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.064917,
        "recall": 0.084627,
        "f1": 0.068358,
        "accuracy": 0.084627,
        "main_score": 0.068358,
        "hf_subset": "dan_Latn-ltz_Latn",
        "languages": [
          "dan-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.067864,
        "recall": 0.091637,
        "f1": 0.072187,
        "accuracy": 0.091637,
        "main_score": 0.072187,
        "hf_subset": "dan_Latn-nld_Latn",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.325345,
        "recall": 0.390586,
        "f1": 0.340164,
        "accuracy": 0.390586,
        "main_score": 0.340164,
        "hf_subset": "dan_Latn-nno_Latn",
        "languages": [
          "dan-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.554166,
        "recall": 0.629444,
        "f1": 0.573681,
        "accuracy": 0.629444,
        "main_score": 0.573681,
        "hf_subset": "dan_Latn-nob_Latn",
        "languages": [
          "dan-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.233764,
        "recall": 0.285428,
        "f1": 0.245453,
        "accuracy": 0.285428,
        "main_score": 0.245453,
        "hf_subset": "dan_Latn-swe_Latn",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.067116,
        "recall": 0.087131,
        "f1": 0.070799,
        "accuracy": 0.087131,
        "main_score": 0.070799,
        "hf_subset": "deu_Latn-afr_Latn",
        "languages": [
          "deu-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 7.8e-05,
        "recall": 0.001002,
        "f1": 0.000138,
        "accuracy": 0.001002,
        "main_score": 0.000138,
        "hf_subset": "deu_Latn-arb_Arab",
        "languages": [
          "deu-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000658,
        "recall": 0.002504,
        "f1": 0.000764,
        "accuracy": 0.002504,
        "main_score": 0.000764,
        "hf_subset": "deu_Latn-ben_Beng",
        "languages": [
          "deu-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.052434,
        "recall": 0.067101,
        "f1": 0.055034,
        "accuracy": 0.067101,
        "main_score": 0.055034,
        "hf_subset": "deu_Latn-dan_Latn",
        "languages": [
          "deu-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.001701,
        "recall": 0.003005,
        "f1": 0.001831,
        "accuracy": 0.003005,
        "main_score": 0.001831,
        "hf_subset": "deu_Latn-ell_Grek",
        "languages": [
          "deu-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.049307,
        "recall": 0.067101,
        "f1": 0.052053,
        "accuracy": 0.067101,
        "main_score": 0.052053,
        "hf_subset": "deu_Latn-eng_Latn",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027299,
        "recall": 0.037556,
        "f1": 0.028767,
        "accuracy": 0.037556,
        "main_score": 0.028767,
        "hf_subset": "deu_Latn-fao_Latn",
        "languages": [
          "deu-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.000721,
        "recall": 0.003005,
        "f1": 0.000866,
        "accuracy": 0.003005,
        "main_score": 0.000866,
        "hf_subset": "deu_Latn-fas_Arab",
        "languages": [
          "deu-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.01587,
        "recall": 0.023535,
        "f1": 0.01682,
        "accuracy": 0.023535,
        "main_score": 0.01682,
        "hf_subset": "deu_Latn-fin_Latn",
        "languages": [
          "deu-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.031894,
        "recall": 0.04657,
        "f1": 0.033883,
        "accuracy": 0.04657,
        "main_score": 0.033883,
        "hf_subset": "deu_Latn-fra_Latn",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.001752,
        "recall": 0.004507,
        "f1": 0.001949,
        "accuracy": 0.004507,
        "main_score": 0.001949,
        "hf_subset": "deu_Latn-heb_Hebr",
        "languages": [
          "deu-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.001037,
        "recall": 0.002504,
        "f1": 0.00107,
        "accuracy": 0.002504,
        "main_score": 0.00107,
        "hf_subset": "deu_Latn-hin_Deva",
        "languages": [
          "deu-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.018063,
        "recall": 0.025538,
        "f1": 0.019336,
        "accuracy": 0.025538,
        "main_score": 0.019336,
        "hf_subset": "deu_Latn-hun_Latn",
        "languages": [
          "deu-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.027088,
        "recall": 0.035053,
        "f1": 0.028392,
        "accuracy": 0.035053,
        "main_score": 0.028392,
        "hf_subset": "deu_Latn-ind_Latn",
        "languages": [
          "deu-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.022055,
        "recall": 0.028543,
        "f1": 0.023142,
        "accuracy": 0.028543,
        "main_score": 0.023142,
        "hf_subset": "deu_Latn-isl_Latn",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.001471,
        "recall": 0.005008,
        "f1": 0.001719,
        "accuracy": 0.005008,
        "main_score": 0.001719,
        "hf_subset": "deu_Latn-jpn_Jpan",
        "languages": [
          "deu-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000572,
        "recall": 0.004006,
        "f1": 0.000889,
        "accuracy": 0.004006,
        "main_score": 0.000889,
        "hf_subset": "deu_Latn-kor_Hang",
        "languages": [
          "deu-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.012309,
        "recall": 0.018027,
        "f1": 0.013372,
        "accuracy": 0.018027,
        "main_score": 0.013372,
        "hf_subset": "deu_Latn-lit_Latn",
        "languages": [
          "deu-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.143693,
        "recall": 0.183275,
        "f1": 0.15184,
        "accuracy": 0.183275,
        "main_score": 0.15184,
        "hf_subset": "deu_Latn-ltz_Latn",
        "languages": [
          "deu-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.071567,
        "recall": 0.089134,
        "f1": 0.074744,
        "accuracy": 0.089134,
        "main_score": 0.074744,
        "hf_subset": "deu_Latn-nld_Latn",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.052657,
        "recall": 0.066099,
        "f1": 0.05454,
        "accuracy": 0.066099,
        "main_score": 0.05454,
        "hf_subset": "deu_Latn-nno_Latn",
        "languages": [
          "deu-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.055344,
        "recall": 0.071607,
        "f1": 0.057835,
        "accuracy": 0.071607,
        "main_score": 0.057835,
        "hf_subset": "deu_Latn-nob_Latn",
        "languages": [
          "deu-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.018059,
        "recall": 0.024537,
        "f1": 0.019056,
        "accuracy": 0.024537,
        "main_score": 0.019056,
        "hf_subset": "deu_Latn-pol_Latn",
        "languages": [
          "deu-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.026046,
        "recall": 0.039559,
        "f1": 0.02786,
        "accuracy": 0.039559,
        "main_score": 0.02786,
        "hf_subset": "deu_Latn-por_Latn",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000987,
        "recall": 0.003505,
        "f1": 0.001275,
        "accuracy": 0.003505,
        "main_score": 0.001275,
        "hf_subset": "deu_Latn-rus_Cyrl",
        "languages": [
          "deu-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.028306,
        "recall": 0.043065,
        "f1": 0.030486,
        "accuracy": 0.043065,
        "main_score": 0.030486,
        "hf_subset": "deu_Latn-spa_Latn",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.012211,
        "recall": 0.018027,
        "f1": 0.013209,
        "accuracy": 0.018027,
        "main_score": 0.013209,
        "hf_subset": "deu_Latn-swa_Latn",
        "languages": [
          "deu-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.046744,
        "recall": 0.056585,
        "f1": 0.04874,
        "accuracy": 0.056585,
        "main_score": 0.04874,
        "hf_subset": "deu_Latn-swe_Latn",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000978,
        "recall": 0.003505,
        "f1": 0.001198,
        "accuracy": 0.003505,
        "main_score": 0.001198,
        "hf_subset": "deu_Latn-tam_Taml",
        "languages": [
          "deu-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.013111,
        "recall": 0.016024,
        "f1": 0.013679,
        "accuracy": 0.016024,
        "main_score": 0.013679,
        "hf_subset": "deu_Latn-tur_Latn",
        "languages": [
          "deu-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.013758,
        "recall": 0.022033,
        "f1": 0.015208,
        "accuracy": 0.022033,
        "main_score": 0.015208,
        "hf_subset": "deu_Latn-vie_Latn",
        "languages": [
          "deu-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.029935,
        "recall": 0.043565,
        "f1": 0.031741,
        "accuracy": 0.043565,
        "main_score": 0.031741,
        "hf_subset": "deu_Latn-zho_Hant",
        "languages": [
          "deu-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.018739,
        "recall": 0.028543,
        "f1": 0.020108,
        "accuracy": 0.028543,
        "main_score": 0.020108,
        "hf_subset": "deu_Latn-zul_Latn",
        "languages": [
          "deu-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000126,
        "recall": 0.001002,
        "f1": 0.000201,
        "accuracy": 0.001002,
        "main_score": 0.000201,
        "hf_subset": "div_Thaa-ben_Beng",
        "languages": [
          "div-Thaa",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.016467,
        "recall": 0.029544,
        "f1": 0.01853,
        "accuracy": 0.029544,
        "main_score": 0.01853,
        "hf_subset": "div_Thaa-eng_Latn",
        "languages": [
          "div-Thaa",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003019,
        "recall": 0.009514,
        "f1": 0.003651,
        "accuracy": 0.009514,
        "main_score": 0.003651,
        "hf_subset": "div_Thaa-eus_Latn",
        "languages": [
          "div-Thaa",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.099862,
        "recall": 0.130195,
        "f1": 0.107081,
        "accuracy": 0.130195,
        "main_score": 0.107081,
        "hf_subset": "div_Thaa-guj_Gujr",
        "languages": [
          "div-Thaa",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.002074,
        "recall": 0.005508,
        "f1": 0.002416,
        "accuracy": 0.005508,
        "main_score": 0.002416,
        "hf_subset": "div_Thaa-hin_Deva",
        "languages": [
          "div-Thaa",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.094942,
        "recall": 0.127191,
        "f1": 0.102667,
        "accuracy": 0.127191,
        "main_score": 0.102667,
        "hf_subset": "div_Thaa-kan_Knda",
        "languages": [
          "div-Thaa",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001712,
        "recall": 0.004507,
        "f1": 0.001863,
        "accuracy": 0.004507,
        "main_score": 0.001863,
        "hf_subset": "div_Thaa-mar_Deva",
        "languages": [
          "div-Thaa",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002486,
        "recall": 0.004507,
        "f1": 0.00273,
        "accuracy": 0.004507,
        "main_score": 0.00273,
        "hf_subset": "div_Thaa-nep_Deva",
        "languages": [
          "div-Thaa",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.071204,
        "recall": 0.098648,
        "f1": 0.077564,
        "accuracy": 0.098648,
        "main_score": 0.077564,
        "hf_subset": "div_Thaa-pan_Guru",
        "languages": [
          "div-Thaa",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.060335,
        "recall": 0.089134,
        "f1": 0.066872,
        "accuracy": 0.089134,
        "main_score": 0.066872,
        "hf_subset": "div_Thaa-sin_Sinh",
        "languages": [
          "div-Thaa",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.003283,
        "recall": 0.009014,
        "f1": 0.003817,
        "accuracy": 0.009014,
        "main_score": 0.003817,
        "hf_subset": "div_Thaa-snd_Arab",
        "languages": [
          "div-Thaa",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.000687,
        "recall": 0.00651,
        "f1": 0.000849,
        "accuracy": 0.00651,
        "main_score": 0.000849,
        "hf_subset": "div_Thaa-tam_Taml",
        "languages": [
          "div-Thaa",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.092207,
        "recall": 0.11968,
        "f1": 0.099107,
        "accuracy": 0.11968,
        "main_score": 0.099107,
        "hf_subset": "div_Thaa-tel_Telu",
        "languages": [
          "div-Thaa",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003693,
        "recall": 0.007511,
        "f1": 0.004201,
        "accuracy": 0.007511,
        "main_score": 0.004201,
        "hf_subset": "div_Thaa-urd_Arab",
        "languages": [
          "div-Thaa",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.003797,
        "recall": 0.005008,
        "f1": 0.004123,
        "accuracy": 0.005008,
        "main_score": 0.004123,
        "hf_subset": "dzo_Tibt-bod_Tibt",
        "languages": [
          "dzo-Tibt",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "dzo_Tibt-eng_Latn",
        "languages": [
          "dzo-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "dzo_Tibt-khm_Khmr",
        "languages": [
          "dzo-Tibt",
          "khm-Khmr"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "dzo_Tibt-lao_Laoo",
        "languages": [
          "dzo-Tibt",
          "lao-Laoo"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "dzo_Tibt-mon_Mong",
        "languages": [
          "dzo-Tibt",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "dzo_Tibt-mya_Mymr",
        "languages": [
          "dzo-Tibt",
          "mya-Mymr"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 6e-06,
        "accuracy": 0.001002,
        "main_score": 6e-06,
        "hf_subset": "dzo_Tibt-tha_Thai",
        "languages": [
          "dzo-Tibt",
          "tha-Thai"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.000501,
        "f1": 8e-06,
        "accuracy": 0.000501,
        "main_score": 8e-06,
        "hf_subset": "ell_Grek-arb_Arab",
        "languages": [
          "ell-Grek",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "ell_Grek-ben_Beng",
        "languages": [
          "ell-Grek",
          "ben-Beng"
        ]
      },
      {
        "precision": 7.5e-05,
        "recall": 0.002003,
        "f1": 0.000131,
        "accuracy": 0.002003,
        "main_score": 0.000131,
        "hf_subset": "ell_Grek-deu_Latn",
        "languages": [
          "ell-Grek",
          "deu-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 4e-06,
        "accuracy": 0.000501,
        "main_score": 4e-06,
        "hf_subset": "ell_Grek-eng_Latn",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.001502,
        "f1": 1.3e-05,
        "accuracy": 0.001502,
        "main_score": 1.3e-05,
        "hf_subset": "ell_Grek-fas_Arab",
        "languages": [
          "ell-Grek",
          "fas-Arab"
        ]
      },
      {
        "precision": 2.5e-05,
        "recall": 0.002003,
        "f1": 4.9e-05,
        "accuracy": 0.002003,
        "main_score": 4.9e-05,
        "hf_subset": "ell_Grek-fin_Latn",
        "languages": [
          "ell-Grek",
          "fin-Latn"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.000501,
        "f1": 7e-06,
        "accuracy": 0.000501,
        "main_score": 7e-06,
        "hf_subset": "ell_Grek-fra_Latn",
        "languages": [
          "ell-Grek",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-heb_Hebr",
        "languages": [
          "ell-Grek",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "ell_Grek-hin_Deva",
        "languages": [
          "ell-Grek",
          "hin-Deva"
        ]
      },
      {
        "precision": 2.9e-05,
        "recall": 0.001002,
        "f1": 5.6e-05,
        "accuracy": 0.001002,
        "main_score": 5.6e-05,
        "hf_subset": "ell_Grek-hun_Latn",
        "languages": [
          "ell-Grek",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "ell_Grek-hye_Armn",
        "languages": [
          "ell-Grek",
          "hye-Armn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "ell_Grek-ind_Latn",
        "languages": [
          "ell-Grek",
          "ind-Latn"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001502,
        "f1": 1.3e-05,
        "accuracy": 0.001502,
        "main_score": 1.3e-05,
        "hf_subset": "ell_Grek-jpn_Jpan",
        "languages": [
          "ell-Grek",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-kat_Geor",
        "languages": [
          "ell-Grek",
          "kat-Geor"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 5e-06,
        "accuracy": 0.001002,
        "main_score": 5e-06,
        "hf_subset": "ell_Grek-kor_Hang",
        "languages": [
          "ell-Grek",
          "kor-Hang"
        ]
      },
      {
        "precision": 1.9e-05,
        "recall": 0.001002,
        "f1": 3.6e-05,
        "accuracy": 0.001002,
        "main_score": 3.6e-05,
        "hf_subset": "ell_Grek-lit_Latn",
        "languages": [
          "ell-Grek",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "ell_Grek-nld_Latn",
        "languages": [
          "ell-Grek",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-pol_Latn",
        "languages": [
          "ell-Grek",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "ell_Grek-por_Latn",
        "languages": [
          "ell-Grek",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000188,
        "recall": 0.002003,
        "f1": 0.000291,
        "accuracy": 0.002003,
        "main_score": 0.000291,
        "hf_subset": "ell_Grek-rus_Cyrl",
        "languages": [
          "ell-Grek",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001002,
        "f1": 1.1e-05,
        "accuracy": 0.001002,
        "main_score": 1.1e-05,
        "hf_subset": "ell_Grek-spa_Latn",
        "languages": [
          "ell-Grek",
          "spa-Latn"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001002,
        "f1": 8e-06,
        "accuracy": 0.001002,
        "main_score": 8e-06,
        "hf_subset": "ell_Grek-sqi_Latn",
        "languages": [
          "ell-Grek",
          "sqi-Latn"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.000501,
        "f1": 1.2e-05,
        "accuracy": 0.000501,
        "main_score": 1.2e-05,
        "hf_subset": "ell_Grek-swa_Latn",
        "languages": [
          "ell-Grek",
          "swa-Latn"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.001502,
        "f1": 2e-05,
        "accuracy": 0.001502,
        "main_score": 2e-05,
        "hf_subset": "ell_Grek-swe_Latn",
        "languages": [
          "ell-Grek",
          "swe-Latn"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.000501,
        "f1": 2.1e-05,
        "accuracy": 0.000501,
        "main_score": 2.1e-05,
        "hf_subset": "ell_Grek-tam_Taml",
        "languages": [
          "ell-Grek",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001002,
        "f1": 0.001002,
        "accuracy": 0.001002,
        "main_score": 0.001002,
        "hf_subset": "ell_Grek-tur_Latn",
        "languages": [
          "ell-Grek",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-vie_Latn",
        "languages": [
          "ell-Grek",
          "vie-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 2e-06,
        "accuracy": 0.001002,
        "main_score": 2e-06,
        "hf_subset": "ell_Grek-zho_Hant",
        "languages": [
          "ell-Grek",
          "zho-Hant"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 2e-06,
        "accuracy": 0.001002,
        "main_score": 2e-06,
        "hf_subset": "ell_Grek-zul_Latn",
        "languages": [
          "ell-Grek",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.089029,
        "recall": 0.115173,
        "f1": 0.094412,
        "accuracy": 0.115173,
        "main_score": 0.094412,
        "hf_subset": "eng_Latn-afr_Latn",
        "languages": [
          "eng-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.045485,
        "recall": 0.079119,
        "f1": 0.052181,
        "accuracy": 0.079119,
        "main_score": 0.052181,
        "hf_subset": "eng_Latn-amh_Ethi",
        "languages": [
          "eng-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.001258,
        "recall": 0.002003,
        "f1": 0.001348,
        "accuracy": 0.002003,
        "main_score": 0.001348,
        "hf_subset": "eng_Latn-arb_Arab",
        "languages": [
          "eng-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.014626,
        "recall": 0.023535,
        "f1": 0.015868,
        "accuracy": 0.023535,
        "main_score": 0.015868,
        "hf_subset": "eng_Latn-aze_Latn",
        "languages": [
          "eng-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.005118,
        "recall": 0.01302,
        "f1": 0.005805,
        "accuracy": 0.01302,
        "main_score": 0.005805,
        "hf_subset": "eng_Latn-bak_Cyrl",
        "languages": [
          "eng-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.0033,
        "recall": 0.011517,
        "f1": 0.004089,
        "accuracy": 0.011517,
        "main_score": 0.004089,
        "hf_subset": "eng_Latn-bel_Cyrl",
        "languages": [
          "eng-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.052079,
        "recall": 0.077616,
        "f1": 0.056806,
        "accuracy": 0.077616,
        "main_score": 0.056806,
        "hf_subset": "eng_Latn-bem_Latn",
        "languages": [
          "eng-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.000517,
        "recall": 0.002504,
        "f1": 0.000534,
        "accuracy": 0.002504,
        "main_score": 0.000534,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.00644,
        "recall": 0.011017,
        "f1": 0.006955,
        "accuracy": 0.011017,
        "main_score": 0.006955,
        "hf_subset": "eng_Latn-bod_Tibt",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.045942,
        "recall": 0.068102,
        "f1": 0.049727,
        "accuracy": 0.068102,
        "main_score": 0.049727,
        "hf_subset": "eng_Latn-bos_Latn",
        "languages": [
          "eng-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.002286,
        "recall": 0.008012,
        "f1": 0.002725,
        "accuracy": 0.008012,
        "main_score": 0.002725,
        "hf_subset": "eng_Latn-bul_Cyrl",
        "languages": [
          "eng-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.12297,
        "recall": 0.164246,
        "f1": 0.130842,
        "accuracy": 0.164246,
        "main_score": 0.130842,
        "hf_subset": "eng_Latn-cat_Latn",
        "languages": [
          "eng-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.060325,
        "recall": 0.084126,
        "f1": 0.064896,
        "accuracy": 0.084126,
        "main_score": 0.064896,
        "hf_subset": "eng_Latn-ces_Latn",
        "languages": [
          "eng-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.000785,
        "recall": 0.003505,
        "f1": 0.000961,
        "accuracy": 0.003505,
        "main_score": 0.000961,
        "hf_subset": "eng_Latn-ckb_Arab",
        "languages": [
          "eng-Latn",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.065919,
        "recall": 0.095643,
        "f1": 0.071866,
        "accuracy": 0.095643,
        "main_score": 0.071866,
        "hf_subset": "eng_Latn-cym_Latn",
        "languages": [
          "eng-Latn",
          "cym-Latn"
        ]
      },
      {
        "precision": 0.105888,
        "recall": 0.134201,
        "f1": 0.112746,
        "accuracy": 0.134201,
        "main_score": 0.112746,
        "hf_subset": "eng_Latn-dan_Latn",
        "languages": [
          "eng-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.067112,
        "recall": 0.09314,
        "f1": 0.071751,
        "accuracy": 0.09314,
        "main_score": 0.071751,
        "hf_subset": "eng_Latn-deu_Latn",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.015839,
        "recall": 0.03355,
        "f1": 0.018353,
        "accuracy": 0.03355,
        "main_score": 0.018353,
        "hf_subset": "eng_Latn-div_Thaa",
        "languages": [
          "eng-Latn",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "eng_Latn-dzo_Tibt",
        "languages": [
          "eng-Latn",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.002831,
        "recall": 0.008513,
        "f1": 0.003224,
        "accuracy": 0.008513,
        "main_score": 0.003224,
        "hf_subset": "eng_Latn-ell_Grek",
        "languages": [
          "eng-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.046216,
        "recall": 0.069604,
        "f1": 0.050019,
        "accuracy": 0.069604,
        "main_score": 0.050019,
        "hf_subset": "eng_Latn-eus_Latn",
        "languages": [
          "eng-Latn",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.061259,
        "recall": 0.099149,
        "f1": 0.067771,
        "accuracy": 0.099149,
        "main_score": 0.067771,
        "hf_subset": "eng_Latn-ewe_Latn",
        "languages": [
          "eng-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.053577,
        "recall": 0.078618,
        "f1": 0.05751,
        "accuracy": 0.078618,
        "main_score": 0.05751,
        "hf_subset": "eng_Latn-fao_Latn",
        "languages": [
          "eng-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.004799,
        "recall": 0.009514,
        "f1": 0.005624,
        "accuracy": 0.009514,
        "main_score": 0.005624,
        "hf_subset": "eng_Latn-fas_Arab",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.023617,
        "recall": 0.03355,
        "f1": 0.025184,
        "accuracy": 0.03355,
        "main_score": 0.025184,
        "hf_subset": "eng_Latn-fij_Latn",
        "languages": [
          "eng-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.075351,
        "recall": 0.096144,
        "f1": 0.079599,
        "accuracy": 0.096144,
        "main_score": 0.079599,
        "hf_subset": "eng_Latn-fil_Latn",
        "languages": [
          "eng-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.039851,
        "recall": 0.060591,
        "f1": 0.043915,
        "accuracy": 0.060591,
        "main_score": 0.043915,
        "hf_subset": "eng_Latn-fin_Latn",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.130543,
        "recall": 0.163245,
        "f1": 0.137516,
        "accuracy": 0.163245,
        "main_score": 0.137516,
        "hf_subset": "eng_Latn-fra_Latn",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.068036,
        "recall": 0.096144,
        "f1": 0.073645,
        "accuracy": 0.096144,
        "main_score": 0.073645,
        "hf_subset": "eng_Latn-fuc_Latn",
        "languages": [
          "eng-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.047831,
        "recall": 0.076114,
        "f1": 0.052762,
        "accuracy": 0.076114,
        "main_score": 0.052762,
        "hf_subset": "eng_Latn-gle_Latn",
        "languages": [
          "eng-Latn",
          "gle-Latn"
        ]
      },
      {
        "precision": 0.096058,
        "recall": 0.126189,
        "f1": 0.102156,
        "accuracy": 0.126189,
        "main_score": 0.102156,
        "hf_subset": "eng_Latn-glg_Latn",
        "languages": [
          "eng-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.021505,
        "recall": 0.043565,
        "f1": 0.024962,
        "accuracy": 0.043565,
        "main_score": 0.024962,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.060086,
        "recall": 0.078618,
        "f1": 0.06445,
        "accuracy": 0.078618,
        "main_score": 0.06445,
        "hf_subset": "eng_Latn-hau_Latn",
        "languages": [
          "eng-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.003305,
        "recall": 0.009014,
        "f1": 0.00387,
        "accuracy": 0.009014,
        "main_score": 0.00387,
        "hf_subset": "eng_Latn-heb_Hebr",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.003172,
        "recall": 0.007511,
        "f1": 0.003647,
        "accuracy": 0.007511,
        "main_score": 0.003647,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.035479,
        "recall": 0.055583,
        "f1": 0.03852,
        "accuracy": 0.055583,
        "main_score": 0.03852,
        "hf_subset": "eng_Latn-hmn_Latn",
        "languages": [
          "eng-Latn",
          "hmn-Latn"
        ]
      },
      {
        "precision": 0.048603,
        "recall": 0.067101,
        "f1": 0.052074,
        "accuracy": 0.067101,
        "main_score": 0.052074,
        "hf_subset": "eng_Latn-hrv_Latn",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.041214,
        "recall": 0.057586,
        "f1": 0.04437,
        "accuracy": 0.057586,
        "main_score": 0.04437,
        "hf_subset": "eng_Latn-hun_Latn",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.000499,
        "recall": 0.005008,
        "f1": 0.000827,
        "accuracy": 0.005008,
        "main_score": 0.000827,
        "hf_subset": "eng_Latn-hye_Armn",
        "languages": [
          "eng-Latn",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.059546,
        "recall": 0.09364,
        "f1": 0.066006,
        "accuracy": 0.09364,
        "main_score": 0.066006,
        "hf_subset": "eng_Latn-ibo_Latn",
        "languages": [
          "eng-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.062799,
        "recall": 0.087131,
        "f1": 0.067235,
        "accuracy": 0.087131,
        "main_score": 0.067235,
        "hf_subset": "eng_Latn-ind_Latn",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.040782,
        "recall": 0.058588,
        "f1": 0.044367,
        "accuracy": 0.058588,
        "main_score": 0.044367,
        "hf_subset": "eng_Latn-isl_Latn",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.083969,
        "recall": 0.110165,
        "f1": 0.088575,
        "accuracy": 0.110165,
        "main_score": 0.088575,
        "hf_subset": "eng_Latn-ita_Latn",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.006541,
        "recall": 0.016525,
        "f1": 0.008041,
        "accuracy": 0.016525,
        "main_score": 0.008041,
        "hf_subset": "eng_Latn-jpn_Jpan",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.025566,
        "recall": 0.049574,
        "f1": 0.029933,
        "accuracy": 0.049574,
        "main_score": 0.029933,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.00214,
        "recall": 0.007511,
        "f1": 0.002594,
        "accuracy": 0.007511,
        "main_score": 0.002594,
        "hf_subset": "eng_Latn-kat_Geor",
        "languages": [
          "eng-Latn",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.003807,
        "recall": 0.008012,
        "f1": 0.00439,
        "accuracy": 0.008012,
        "main_score": 0.00439,
        "hf_subset": "eng_Latn-kaz_Cyrl",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.228645,
        "recall": 0.268403,
        "f1": 0.239095,
        "accuracy": 0.268403,
        "main_score": 0.239095,
        "hf_subset": "eng_Latn-khm_Khmr",
        "languages": [
          "eng-Latn",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.042969,
        "recall": 0.060591,
        "f1": 0.046204,
        "accuracy": 0.060591,
        "main_score": 0.046204,
        "hf_subset": "eng_Latn-kin_Latn",
        "languages": [
          "eng-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.001353,
        "recall": 0.005008,
        "f1": 0.001597,
        "accuracy": 0.005008,
        "main_score": 0.001597,
        "hf_subset": "eng_Latn-kir_Cyrl",
        "languages": [
          "eng-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.049898,
        "recall": 0.076615,
        "f1": 0.054907,
        "accuracy": 0.076615,
        "main_score": 0.054907,
        "hf_subset": "eng_Latn-kmr_Latn",
        "languages": [
          "eng-Latn",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.002643,
        "recall": 0.006009,
        "f1": 0.002913,
        "accuracy": 0.006009,
        "main_score": 0.002913,
        "hf_subset": "eng_Latn-kor_Hang",
        "languages": [
          "eng-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.315376,
        "recall": 0.370556,
        "f1": 0.328047,
        "accuracy": 0.370556,
        "main_score": 0.328047,
        "hf_subset": "eng_Latn-lao_Laoo",
        "languages": [
          "eng-Latn",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.038053,
        "recall": 0.058588,
        "f1": 0.041722,
        "accuracy": 0.058588,
        "main_score": 0.041722,
        "hf_subset": "eng_Latn-lav_Latn",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.033643,
        "recall": 0.06009,
        "f1": 0.038027,
        "accuracy": 0.06009,
        "main_score": 0.038027,
        "hf_subset": "eng_Latn-lit_Latn",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.086056,
        "recall": 0.118678,
        "f1": 0.092812,
        "accuracy": 0.118678,
        "main_score": 0.092812,
        "hf_subset": "eng_Latn-ltz_Latn",
        "languages": [
          "eng-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.021197,
        "recall": 0.039559,
        "f1": 0.024069,
        "accuracy": 0.039559,
        "main_score": 0.024069,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000988,
        "recall": 0.004006,
        "f1": 0.001236,
        "accuracy": 0.004006,
        "main_score": 0.001236,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.4e-05,
        "recall": 0.001502,
        "f1": 2.8e-05,
        "accuracy": 0.001502,
        "main_score": 2.8e-05,
        "hf_subset": "eng_Latn-mey_Arab",
        "languages": [
          "eng-Latn",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.00159,
        "recall": 0.007511,
        "f1": 0.002151,
        "accuracy": 0.007511,
        "main_score": 0.002151,
        "hf_subset": "eng_Latn-mkd_Cyrl",
        "languages": [
          "eng-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.045785,
        "recall": 0.072609,
        "f1": 0.050854,
        "accuracy": 0.072609,
        "main_score": 0.050854,
        "hf_subset": "eng_Latn-mlg_Latn",
        "languages": [
          "eng-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.05713,
        "recall": 0.079119,
        "f1": 0.061422,
        "accuracy": 0.079119,
        "main_score": 0.061422,
        "hf_subset": "eng_Latn-mlt_Latn",
        "languages": [
          "eng-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.002115,
        "recall": 0.00651,
        "f1": 0.002468,
        "accuracy": 0.00651,
        "main_score": 0.002468,
        "hf_subset": "eng_Latn-mon_Mong",
        "languages": [
          "eng-Latn",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.041428,
        "recall": 0.06009,
        "f1": 0.044886,
        "accuracy": 0.06009,
        "main_score": 0.044886,
        "hf_subset": "eng_Latn-mri_Latn",
        "languages": [
          "eng-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.063901,
        "recall": 0.087631,
        "f1": 0.068542,
        "accuracy": 0.087631,
        "main_score": 0.068542,
        "hf_subset": "eng_Latn-msa_Latn",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.104781,
        "recall": 0.149224,
        "f1": 0.114233,
        "accuracy": 0.149224,
        "main_score": 0.114233,
        "hf_subset": "eng_Latn-mya_Mymr",
        "languages": [
          "eng-Latn",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.017744,
        "recall": 0.032549,
        "f1": 0.019642,
        "accuracy": 0.032549,
        "main_score": 0.019642,
        "hf_subset": "eng_Latn-nde_Latn",
        "languages": [
          "eng-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.004605,
        "recall": 0.009514,
        "f1": 0.005389,
        "accuracy": 0.009514,
        "main_score": 0.005389,
        "hf_subset": "eng_Latn-nep_Deva",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.092118,
        "recall": 0.124687,
        "f1": 0.098949,
        "accuracy": 0.124687,
        "main_score": 0.098949,
        "hf_subset": "eng_Latn-nld_Latn",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.106242,
        "recall": 0.136204,
        "f1": 0.112748,
        "accuracy": 0.136204,
        "main_score": 0.112748,
        "hf_subset": "eng_Latn-nno_Latn",
        "languages": [
          "eng-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.101395,
        "recall": 0.134201,
        "f1": 0.108404,
        "accuracy": 0.134201,
        "main_score": 0.108404,
        "hf_subset": "eng_Latn-nob_Latn",
        "languages": [
          "eng-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.050495,
        "recall": 0.072609,
        "f1": 0.054743,
        "accuracy": 0.072609,
        "main_score": 0.054743,
        "hf_subset": "eng_Latn-nso_Latn",
        "languages": [
          "eng-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.045235,
        "recall": 0.071607,
        "f1": 0.049721,
        "accuracy": 0.071607,
        "main_score": 0.049721,
        "hf_subset": "eng_Latn-nya_Latn",
        "languages": [
          "eng-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.023801,
        "recall": 0.04006,
        "f1": 0.026526,
        "accuracy": 0.04006,
        "main_score": 0.026526,
        "hf_subset": "eng_Latn-orm_Ethi",
        "languages": [
          "eng-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.034373,
        "recall": 0.061592,
        "f1": 0.03995,
        "accuracy": 0.061592,
        "main_score": 0.03995,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.038577,
        "recall": 0.057586,
        "f1": 0.041588,
        "accuracy": 0.057586,
        "main_score": 0.041588,
        "hf_subset": "eng_Latn-pol_Latn",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.101855,
        "recall": 0.131197,
        "f1": 0.108122,
        "accuracy": 0.131197,
        "main_score": 0.108122,
        "hf_subset": "eng_Latn-por_Latn",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000965,
        "recall": 0.003005,
        "f1": 0.001198,
        "accuracy": 0.003005,
        "main_score": 0.001198,
        "hf_subset": "eng_Latn-prs_Arab",
        "languages": [
          "eng-Latn",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.001727,
        "recall": 0.004507,
        "f1": 0.001883,
        "accuracy": 0.004507,
        "main_score": 0.001883,
        "hf_subset": "eng_Latn-pus_Arab",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.086318,
        "recall": 0.114171,
        "f1": 0.092221,
        "accuracy": 0.114171,
        "main_score": 0.092221,
        "hf_subset": "eng_Latn-ron_Latn",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.001242,
        "recall": 0.007011,
        "f1": 0.001711,
        "accuracy": 0.007011,
        "main_score": 0.001711,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.001455,
        "recall": 0.004006,
        "f1": 0.001681,
        "accuracy": 0.004006,
        "main_score": 0.001681,
        "hf_subset": "eng_Latn-shi_Arab",
        "languages": [
          "eng-Latn",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.021559,
        "recall": 0.044567,
        "f1": 0.0251,
        "accuracy": 0.044567,
        "main_score": 0.0251,
        "hf_subset": "eng_Latn-sin_Sinh",
        "languages": [
          "eng-Latn",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.054293,
        "recall": 0.072609,
        "f1": 0.05746,
        "accuracy": 0.072609,
        "main_score": 0.05746,
        "hf_subset": "eng_Latn-slk_Latn",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.041564,
        "recall": 0.068102,
        "f1": 0.046568,
        "accuracy": 0.068102,
        "main_score": 0.046568,
        "hf_subset": "eng_Latn-slv_Latn",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.031107,
        "recall": 0.041062,
        "f1": 0.032269,
        "accuracy": 0.041062,
        "main_score": 0.032269,
        "hf_subset": "eng_Latn-smo_Latn",
        "languages": [
          "eng-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.024186,
        "recall": 0.044066,
        "f1": 0.027149,
        "accuracy": 0.044066,
        "main_score": 0.027149,
        "hf_subset": "eng_Latn-sna_Latn",
        "languages": [
          "eng-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.001936,
        "recall": 0.005008,
        "f1": 0.002169,
        "accuracy": 0.005008,
        "main_score": 0.002169,
        "hf_subset": "eng_Latn-snd_Arab",
        "languages": [
          "eng-Latn",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.038934,
        "recall": 0.052579,
        "f1": 0.041763,
        "accuracy": 0.052579,
        "main_score": 0.041763,
        "hf_subset": "eng_Latn-som_Latn",
        "languages": [
          "eng-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.095021,
        "recall": 0.116174,
        "f1": 0.099616,
        "accuracy": 0.116174,
        "main_score": 0.099616,
        "hf_subset": "eng_Latn-spa_Latn",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.058356,
        "recall": 0.084627,
        "f1": 0.062789,
        "accuracy": 0.084627,
        "main_score": 0.062789,
        "hf_subset": "eng_Latn-sqi_Latn",
        "languages": [
          "eng-Latn",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.001741,
        "recall": 0.00651,
        "f1": 0.001935,
        "accuracy": 0.00651,
        "main_score": 0.001935,
        "hf_subset": "eng_Latn-srp_Cyrl",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.017438,
        "recall": 0.029544,
        "f1": 0.019319,
        "accuracy": 0.029544,
        "main_score": 0.019319,
        "hf_subset": "eng_Latn-srp_Latn",
        "languages": [
          "eng-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.038083,
        "recall": 0.065098,
        "f1": 0.042411,
        "accuracy": 0.065098,
        "main_score": 0.042411,
        "hf_subset": "eng_Latn-ssw_Latn",
        "languages": [
          "eng-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.030848,
        "recall": 0.047071,
        "f1": 0.034073,
        "accuracy": 0.047071,
        "main_score": 0.034073,
        "hf_subset": "eng_Latn-swa_Latn",
        "languages": [
          "eng-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.114438,
        "recall": 0.152729,
        "f1": 0.12163,
        "accuracy": 0.152729,
        "main_score": 0.12163,
        "hf_subset": "eng_Latn-swe_Latn",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.023534,
        "recall": 0.032549,
        "f1": 0.024976,
        "accuracy": 0.032549,
        "main_score": 0.024976,
        "hf_subset": "eng_Latn-tah_Latn",
        "languages": [
          "eng-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.003278,
        "recall": 0.009014,
        "f1": 0.003676,
        "accuracy": 0.009014,
        "main_score": 0.003676,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.002851,
        "recall": 0.007511,
        "f1": 0.003416,
        "accuracy": 0.007511,
        "main_score": 0.003416,
        "hf_subset": "eng_Latn-tat_Cyrl",
        "languages": [
          "eng-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.034152,
        "recall": 0.067101,
        "f1": 0.040241,
        "accuracy": 0.067101,
        "main_score": 0.040241,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001765,
        "recall": 0.006009,
        "f1": 0.002176,
        "accuracy": 0.006009,
        "main_score": 0.002176,
        "hf_subset": "eng_Latn-tgk_Cyrl",
        "languages": [
          "eng-Latn",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.179883,
        "recall": 0.21983,
        "f1": 0.18861,
        "accuracy": 0.21983,
        "main_score": 0.18861,
        "hf_subset": "eng_Latn-tha_Thai",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.039673,
        "recall": 0.069104,
        "f1": 0.044901,
        "accuracy": 0.069104,
        "main_score": 0.044901,
        "hf_subset": "eng_Latn-tir_Ethi",
        "languages": [
          "eng-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.025311,
        "recall": 0.047571,
        "f1": 0.0288,
        "accuracy": 0.047571,
        "main_score": 0.0288,
        "hf_subset": "eng_Latn-ton_Latn",
        "languages": [
          "eng-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.049214,
        "recall": 0.074612,
        "f1": 0.053429,
        "accuracy": 0.074612,
        "main_score": 0.053429,
        "hf_subset": "eng_Latn-tsn_Latn",
        "languages": [
          "eng-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.037408,
        "recall": 0.056585,
        "f1": 0.04048,
        "accuracy": 0.056585,
        "main_score": 0.04048,
        "hf_subset": "eng_Latn-tuk_Latn",
        "languages": [
          "eng-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.034643,
        "recall": 0.057086,
        "f1": 0.037854,
        "accuracy": 0.057086,
        "main_score": 0.037854,
        "hf_subset": "eng_Latn-tur_Latn",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000894,
        "recall": 0.004006,
        "f1": 0.001097,
        "accuracy": 0.004006,
        "main_score": 0.001097,
        "hf_subset": "eng_Latn-uig_Arab",
        "languages": [
          "eng-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.004106,
        "recall": 0.009514,
        "f1": 0.004615,
        "accuracy": 0.009514,
        "main_score": 0.004615,
        "hf_subset": "eng_Latn-ukr_Cyrl",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.001299,
        "recall": 0.003505,
        "f1": 0.001476,
        "accuracy": 0.003505,
        "main_score": 0.001476,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.012256,
        "recall": 0.02003,
        "f1": 0.013383,
        "accuracy": 0.02003,
        "main_score": 0.013383,
        "hf_subset": "eng_Latn-uzb_Latn",
        "languages": [
          "eng-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.047618,
        "recall": 0.076615,
        "f1": 0.052628,
        "accuracy": 0.076615,
        "main_score": 0.052628,
        "hf_subset": "eng_Latn-ven_Latn",
        "languages": [
          "eng-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.053647,
        "recall": 0.075613,
        "f1": 0.057255,
        "accuracy": 0.075613,
        "main_score": 0.057255,
        "hf_subset": "eng_Latn-vie_Latn",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.044648,
        "recall": 0.066099,
        "f1": 0.048514,
        "accuracy": 0.066099,
        "main_score": 0.048514,
        "hf_subset": "eng_Latn-wol_Latn",
        "languages": [
          "eng-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.028906,
        "recall": 0.048072,
        "f1": 0.031371,
        "accuracy": 0.048072,
        "main_score": 0.031371,
        "hf_subset": "eng_Latn-xho_Latn",
        "languages": [
          "eng-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.04054,
        "recall": 0.061092,
        "f1": 0.044047,
        "accuracy": 0.061092,
        "main_score": 0.044047,
        "hf_subset": "eng_Latn-yor_Latn",
        "languages": [
          "eng-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.013682,
        "recall": 0.030045,
        "f1": 0.015751,
        "accuracy": 0.030045,
        "main_score": 0.015751,
        "hf_subset": "eng_Latn-yue_Hant",
        "languages": [
          "eng-Latn",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.052214,
        "recall": 0.083625,
        "f1": 0.05804,
        "accuracy": 0.083625,
        "main_score": 0.05804,
        "hf_subset": "eng_Latn-zho_Hans",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.112994,
        "recall": 0.155734,
        "f1": 0.121758,
        "accuracy": 0.155734,
        "main_score": 0.121758,
        "hf_subset": "eng_Latn-zho_Hant",
        "languages": [
          "eng-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.049098,
        "recall": 0.072108,
        "f1": 0.05343,
        "accuracy": 0.072108,
        "main_score": 0.05343,
        "hf_subset": "eng_Latn-zul_Latn",
        "languages": [
          "eng-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000532,
        "recall": 0.002504,
        "f1": 0.000562,
        "accuracy": 0.002504,
        "main_score": 0.000562,
        "hf_subset": "eus_Latn-ben_Beng",
        "languages": [
          "eus-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001085,
        "recall": 0.002504,
        "f1": 0.001155,
        "accuracy": 0.002504,
        "main_score": 0.001155,
        "hf_subset": "eus_Latn-div_Thaa",
        "languages": [
          "eus-Latn",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.018481,
        "recall": 0.029044,
        "f1": 0.019848,
        "accuracy": 0.029044,
        "main_score": 0.019848,
        "hf_subset": "eus_Latn-eng_Latn",
        "languages": [
          "eus-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002003,
        "f1": 0.001504,
        "accuracy": 0.002003,
        "main_score": 0.001504,
        "hf_subset": "eus_Latn-guj_Gujr",
        "languages": [
          "eus-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.001007,
        "recall": 0.002003,
        "f1": 0.001012,
        "accuracy": 0.002003,
        "main_score": 0.001012,
        "hf_subset": "eus_Latn-hin_Deva",
        "languages": [
          "eus-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001921,
        "recall": 0.004006,
        "f1": 0.002256,
        "accuracy": 0.004006,
        "main_score": 0.002256,
        "hf_subset": "eus_Latn-kan_Knda",
        "languages": [
          "eus-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001189,
        "recall": 0.003005,
        "f1": 0.001293,
        "accuracy": 0.003005,
        "main_score": 0.001293,
        "hf_subset": "eus_Latn-mar_Deva",
        "languages": [
          "eus-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001084,
        "recall": 0.005008,
        "f1": 0.001391,
        "accuracy": 0.005008,
        "main_score": 0.001391,
        "hf_subset": "eus_Latn-nep_Deva",
        "languages": [
          "eus-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.002898,
        "recall": 0.008513,
        "f1": 0.00342,
        "accuracy": 0.008513,
        "main_score": 0.00342,
        "hf_subset": "eus_Latn-pan_Guru",
        "languages": [
          "eus-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.003428,
        "recall": 0.007511,
        "f1": 0.003632,
        "accuracy": 0.007511,
        "main_score": 0.003632,
        "hf_subset": "eus_Latn-sin_Sinh",
        "languages": [
          "eus-Latn",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000918,
        "recall": 0.001502,
        "f1": 0.001085,
        "accuracy": 0.001502,
        "main_score": 0.001085,
        "hf_subset": "eus_Latn-snd_Arab",
        "languages": [
          "eus-Latn",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.000755,
        "recall": 0.002504,
        "f1": 0.000842,
        "accuracy": 0.002504,
        "main_score": 0.000842,
        "hf_subset": "eus_Latn-tam_Taml",
        "languages": [
          "eus-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.004789,
        "recall": 0.007511,
        "f1": 0.004903,
        "accuracy": 0.007511,
        "main_score": 0.004903,
        "hf_subset": "eus_Latn-tel_Telu",
        "languages": [
          "eus-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000307,
        "recall": 0.002003,
        "f1": 0.000441,
        "accuracy": 0.002003,
        "main_score": 0.000441,
        "hf_subset": "eus_Latn-urd_Arab",
        "languages": [
          "eus-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.012432,
        "recall": 0.018027,
        "f1": 0.013201,
        "accuracy": 0.018027,
        "main_score": 0.013201,
        "hf_subset": "ewe_Latn-bem_Latn",
        "languages": [
          "ewe-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.035335,
        "recall": 0.043565,
        "f1": 0.036468,
        "accuracy": 0.043565,
        "main_score": 0.036468,
        "hf_subset": "ewe_Latn-eng_Latn",
        "languages": [
          "ewe-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014516,
        "recall": 0.019529,
        "f1": 0.015201,
        "accuracy": 0.019529,
        "main_score": 0.015201,
        "hf_subset": "ewe_Latn-fuc_Latn",
        "languages": [
          "ewe-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.009294,
        "recall": 0.01352,
        "f1": 0.01003,
        "accuracy": 0.01352,
        "main_score": 0.01003,
        "hf_subset": "ewe_Latn-kin_Latn",
        "languages": [
          "ewe-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.007879,
        "recall": 0.011017,
        "f1": 0.008227,
        "accuracy": 0.011017,
        "main_score": 0.008227,
        "hf_subset": "ewe_Latn-nde_Latn",
        "languages": [
          "ewe-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.009753,
        "recall": 0.011517,
        "f1": 0.010224,
        "accuracy": 0.011517,
        "main_score": 0.010224,
        "hf_subset": "ewe_Latn-nya_Latn",
        "languages": [
          "ewe-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.006278,
        "recall": 0.010015,
        "f1": 0.006964,
        "accuracy": 0.010015,
        "main_score": 0.006964,
        "hf_subset": "ewe_Latn-sna_Latn",
        "languages": [
          "ewe-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.0084,
        "recall": 0.011517,
        "f1": 0.008948,
        "accuracy": 0.011517,
        "main_score": 0.008948,
        "hf_subset": "ewe_Latn-ven_Latn",
        "languages": [
          "ewe-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.023397,
        "recall": 0.030546,
        "f1": 0.024661,
        "accuracy": 0.030546,
        "main_score": 0.024661,
        "hf_subset": "fao_Latn-afr_Latn",
        "languages": [
          "fao-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.063361,
        "recall": 0.085128,
        "f1": 0.066842,
        "accuracy": 0.085128,
        "main_score": 0.066842,
        "hf_subset": "fao_Latn-dan_Latn",
        "languages": [
          "fao-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.030402,
        "recall": 0.042564,
        "f1": 0.032346,
        "accuracy": 0.042564,
        "main_score": 0.032346,
        "hf_subset": "fao_Latn-deu_Latn",
        "languages": [
          "fao-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.034212,
        "recall": 0.048072,
        "f1": 0.035976,
        "accuracy": 0.048072,
        "main_score": 0.035976,
        "hf_subset": "fao_Latn-eng_Latn",
        "languages": [
          "fao-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.165993,
        "recall": 0.216825,
        "f1": 0.176625,
        "accuracy": 0.216825,
        "main_score": 0.176625,
        "hf_subset": "fao_Latn-isl_Latn",
        "languages": [
          "fao-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.032081,
        "recall": 0.045068,
        "f1": 0.033633,
        "accuracy": 0.045068,
        "main_score": 0.033633,
        "hf_subset": "fao_Latn-ltz_Latn",
        "languages": [
          "fao-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.026999,
        "recall": 0.035553,
        "f1": 0.028207,
        "accuracy": 0.035553,
        "main_score": 0.028207,
        "hf_subset": "fao_Latn-nld_Latn",
        "languages": [
          "fao-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.0873,
        "recall": 0.103155,
        "f1": 0.090138,
        "accuracy": 0.103155,
        "main_score": 0.090138,
        "hf_subset": "fao_Latn-nno_Latn",
        "languages": [
          "fao-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.071106,
        "recall": 0.094141,
        "f1": 0.075305,
        "accuracy": 0.094141,
        "main_score": 0.075305,
        "hf_subset": "fao_Latn-nob_Latn",
        "languages": [
          "fao-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.071299,
        "recall": 0.091137,
        "f1": 0.07434,
        "accuracy": 0.091137,
        "main_score": 0.07434,
        "hf_subset": "fao_Latn-swe_Latn",
        "languages": [
          "fao-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000464,
        "recall": 0.004507,
        "f1": 0.000738,
        "accuracy": 0.004507,
        "main_score": 0.000738,
        "hf_subset": "fas_Arab-arb_Arab",
        "languages": [
          "fas-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.00025,
        "recall": 0.000501,
        "f1": 0.000334,
        "accuracy": 0.000501,
        "main_score": 0.000334,
        "hf_subset": "fas_Arab-ben_Beng",
        "languages": [
          "fas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000231,
        "recall": 0.002504,
        "f1": 0.000392,
        "accuracy": 0.002504,
        "main_score": 0.000392,
        "hf_subset": "fas_Arab-ckb_Arab",
        "languages": [
          "fas-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.001005,
        "recall": 0.002003,
        "f1": 0.001008,
        "accuracy": 0.002003,
        "main_score": 0.001008,
        "hf_subset": "fas_Arab-deu_Latn",
        "languages": [
          "fas-Arab",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "fas_Arab-ell_Grek",
        "languages": [
          "fas-Arab",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.00308,
        "recall": 0.005508,
        "f1": 0.003147,
        "accuracy": 0.005508,
        "main_score": 0.003147,
        "hf_subset": "fas_Arab-eng_Latn",
        "languages": [
          "fas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "fas_Arab-fin_Latn",
        "languages": [
          "fas-Arab",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002003,
        "f1": 0.001503,
        "accuracy": 0.002003,
        "main_score": 0.001503,
        "hf_subset": "fas_Arab-fra_Latn",
        "languages": [
          "fas-Arab",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000503,
        "accuracy": 0.001002,
        "main_score": 0.000503,
        "hf_subset": "fas_Arab-heb_Hebr",
        "languages": [
          "fas-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000636,
        "recall": 0.002003,
        "f1": 0.000721,
        "accuracy": 0.002003,
        "main_score": 0.000721,
        "hf_subset": "fas_Arab-hin_Deva",
        "languages": [
          "fas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001224,
        "recall": 0.003005,
        "f1": 0.001354,
        "accuracy": 0.003005,
        "main_score": 0.001354,
        "hf_subset": "fas_Arab-hun_Latn",
        "languages": [
          "fas-Arab",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "fas_Arab-ind_Latn",
        "languages": [
          "fas-Arab",
          "ind-Latn"
        ]
      },
      {
        "precision": 9.1e-05,
        "recall": 0.002003,
        "f1": 0.000168,
        "accuracy": 0.002003,
        "main_score": 0.000168,
        "hf_subset": "fas_Arab-jpn_Jpan",
        "languages": [
          "fas-Arab",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000584,
        "recall": 0.002003,
        "f1": 0.000652,
        "accuracy": 0.002003,
        "main_score": 0.000652,
        "hf_subset": "fas_Arab-kmr_Latn",
        "languages": [
          "fas-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000672,
        "recall": 0.001502,
        "f1": 0.000759,
        "accuracy": 0.001502,
        "main_score": 0.000759,
        "hf_subset": "fas_Arab-kor_Hang",
        "languages": [
          "fas-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.000514,
        "recall": 0.001002,
        "f1": 0.000526,
        "accuracy": 0.001002,
        "main_score": 0.000526,
        "hf_subset": "fas_Arab-lit_Latn",
        "languages": [
          "fas-Arab",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001502,
        "f1": 0.000508,
        "accuracy": 0.001502,
        "main_score": 0.000508,
        "hf_subset": "fas_Arab-mey_Arab",
        "languages": [
          "fas-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001003,
        "accuracy": 0.001502,
        "main_score": 0.001003,
        "hf_subset": "fas_Arab-nld_Latn",
        "languages": [
          "fas-Arab",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.001008,
        "recall": 0.002504,
        "f1": 0.001015,
        "accuracy": 0.002504,
        "main_score": 0.001015,
        "hf_subset": "fas_Arab-pol_Latn",
        "languages": [
          "fas-Arab",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.000719,
        "recall": 0.002003,
        "f1": 0.000846,
        "accuracy": 0.002003,
        "main_score": 0.000846,
        "hf_subset": "fas_Arab-por_Latn",
        "languages": [
          "fas-Arab",
          "por-Latn"
        ]
      },
      {
        "precision": 0.175172,
        "recall": 0.240361,
        "f1": 0.192013,
        "accuracy": 0.240361,
        "main_score": 0.192013,
        "hf_subset": "fas_Arab-prs_Arab",
        "languages": [
          "fas-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.001747,
        "recall": 0.005508,
        "f1": 0.00193,
        "accuracy": 0.005508,
        "main_score": 0.00193,
        "hf_subset": "fas_Arab-pus_Arab",
        "languages": [
          "fas-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.001362,
        "recall": 0.003005,
        "f1": 0.001522,
        "accuracy": 0.003005,
        "main_score": 0.001522,
        "hf_subset": "fas_Arab-rus_Cyrl",
        "languages": [
          "fas-Arab",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.000532,
        "recall": 0.002003,
        "f1": 0.000561,
        "accuracy": 0.002003,
        "main_score": 0.000561,
        "hf_subset": "fas_Arab-shi_Arab",
        "languages": [
          "fas-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002003,
        "f1": 0.001503,
        "accuracy": 0.002003,
        "main_score": 0.001503,
        "hf_subset": "fas_Arab-spa_Latn",
        "languages": [
          "fas-Arab",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.000505,
        "recall": 0.001502,
        "f1": 0.000509,
        "accuracy": 0.001502,
        "main_score": 0.000509,
        "hf_subset": "fas_Arab-swa_Latn",
        "languages": [
          "fas-Arab",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "fas_Arab-swe_Latn",
        "languages": [
          "fas-Arab",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.00051,
        "recall": 0.002003,
        "f1": 0.000519,
        "accuracy": 0.002003,
        "main_score": 0.000519,
        "hf_subset": "fas_Arab-tam_Taml",
        "languages": [
          "fas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001993,
        "recall": 0.00651,
        "f1": 0.002332,
        "accuracy": 0.00651,
        "main_score": 0.002332,
        "hf_subset": "fas_Arab-tgk_Cyrl",
        "languages": [
          "fas-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.001504,
        "recall": 0.002504,
        "f1": 0.001507,
        "accuracy": 0.002504,
        "main_score": 0.001507,
        "hf_subset": "fas_Arab-tur_Latn",
        "languages": [
          "fas-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.002079,
        "recall": 0.003505,
        "f1": 0.002136,
        "accuracy": 0.003505,
        "main_score": 0.002136,
        "hf_subset": "fas_Arab-vie_Latn",
        "languages": [
          "fas-Arab",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.001102,
        "recall": 0.002003,
        "f1": 0.001169,
        "accuracy": 0.002003,
        "main_score": 0.001169,
        "hf_subset": "fas_Arab-zho_Hant",
        "languages": [
          "fas-Arab",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.001022,
        "recall": 0.002504,
        "f1": 0.001042,
        "accuracy": 0.002504,
        "main_score": 0.001042,
        "hf_subset": "fas_Arab-zul_Latn",
        "languages": [
          "fas-Arab",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.015149,
        "recall": 0.021032,
        "f1": 0.015721,
        "accuracy": 0.021032,
        "main_score": 0.015721,
        "hf_subset": "fij_Latn-eng_Latn",
        "languages": [
          "fij-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008557,
        "recall": 0.012519,
        "f1": 0.008985,
        "accuracy": 0.012519,
        "main_score": 0.008985,
        "hf_subset": "fij_Latn-fil_Latn",
        "languages": [
          "fij-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.002743,
        "recall": 0.005008,
        "f1": 0.003214,
        "accuracy": 0.005008,
        "main_score": 0.003214,
        "hf_subset": "fij_Latn-ind_Latn",
        "languages": [
          "fij-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.00103,
        "recall": 0.003505,
        "f1": 0.001224,
        "accuracy": 0.003505,
        "main_score": 0.001224,
        "hf_subset": "fij_Latn-mal_Mlym",
        "languages": [
          "fij-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.003583,
        "recall": 0.005008,
        "f1": 0.003652,
        "accuracy": 0.005008,
        "main_score": 0.003652,
        "hf_subset": "fij_Latn-mlg_Latn",
        "languages": [
          "fij-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.007468,
        "recall": 0.011517,
        "f1": 0.008072,
        "accuracy": 0.011517,
        "main_score": 0.008072,
        "hf_subset": "fij_Latn-mri_Latn",
        "languages": [
          "fij-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.006066,
        "recall": 0.009014,
        "f1": 0.006338,
        "accuracy": 0.009014,
        "main_score": 0.006338,
        "hf_subset": "fij_Latn-msa_Latn",
        "languages": [
          "fij-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.009499,
        "recall": 0.01302,
        "f1": 0.009918,
        "accuracy": 0.01302,
        "main_score": 0.009918,
        "hf_subset": "fij_Latn-smo_Latn",
        "languages": [
          "fij-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.005411,
        "recall": 0.008012,
        "f1": 0.005623,
        "accuracy": 0.008012,
        "main_score": 0.005623,
        "hf_subset": "fij_Latn-tah_Latn",
        "languages": [
          "fij-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.007264,
        "recall": 0.01352,
        "f1": 0.00798,
        "accuracy": 0.01352,
        "main_score": 0.00798,
        "hf_subset": "fij_Latn-ton_Latn",
        "languages": [
          "fij-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.044627,
        "recall": 0.055083,
        "f1": 0.046223,
        "accuracy": 0.055083,
        "main_score": 0.046223,
        "hf_subset": "fil_Latn-eng_Latn",
        "languages": [
          "fil-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014754,
        "recall": 0.021032,
        "f1": 0.015529,
        "accuracy": 0.021032,
        "main_score": 0.015529,
        "hf_subset": "fil_Latn-fij_Latn",
        "languages": [
          "fil-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.020344,
        "recall": 0.025538,
        "f1": 0.020974,
        "accuracy": 0.025538,
        "main_score": 0.020974,
        "hf_subset": "fil_Latn-ind_Latn",
        "languages": [
          "fil-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001992,
        "recall": 0.004507,
        "f1": 0.002223,
        "accuracy": 0.004507,
        "main_score": 0.002223,
        "hf_subset": "fil_Latn-mal_Mlym",
        "languages": [
          "fil-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.017485,
        "recall": 0.026039,
        "f1": 0.018565,
        "accuracy": 0.026039,
        "main_score": 0.018565,
        "hf_subset": "fil_Latn-mlg_Latn",
        "languages": [
          "fil-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.01286,
        "recall": 0.017026,
        "f1": 0.013605,
        "accuracy": 0.017026,
        "main_score": 0.013605,
        "hf_subset": "fil_Latn-mri_Latn",
        "languages": [
          "fil-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.021912,
        "recall": 0.027541,
        "f1": 0.022783,
        "accuracy": 0.027541,
        "main_score": 0.022783,
        "hf_subset": "fil_Latn-msa_Latn",
        "languages": [
          "fil-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.015628,
        "recall": 0.023535,
        "f1": 0.017127,
        "accuracy": 0.023535,
        "main_score": 0.017127,
        "hf_subset": "fil_Latn-smo_Latn",
        "languages": [
          "fil-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.009278,
        "recall": 0.014522,
        "f1": 0.010167,
        "accuracy": 0.014522,
        "main_score": 0.010167,
        "hf_subset": "fil_Latn-tah_Latn",
        "languages": [
          "fil-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.006943,
        "recall": 0.012018,
        "f1": 0.007625,
        "accuracy": 0.012018,
        "main_score": 0.007625,
        "hf_subset": "fil_Latn-ton_Latn",
        "languages": [
          "fil-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.000139,
        "recall": 0.001002,
        "f1": 0.000227,
        "accuracy": 0.001002,
        "main_score": 0.000227,
        "hf_subset": "fin_Latn-arb_Arab",
        "languages": [
          "fin-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000519,
        "recall": 0.002504,
        "f1": 0.000813,
        "accuracy": 0.002504,
        "main_score": 0.000813,
        "hf_subset": "fin_Latn-ben_Beng",
        "languages": [
          "fin-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.013947,
        "recall": 0.019029,
        "f1": 0.014636,
        "accuracy": 0.019029,
        "main_score": 0.014636,
        "hf_subset": "fin_Latn-deu_Latn",
        "languages": [
          "fin-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000872,
        "recall": 0.003005,
        "f1": 0.001056,
        "accuracy": 0.003005,
        "main_score": 0.001056,
        "hf_subset": "fin_Latn-ell_Grek",
        "languages": [
          "fin-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.024555,
        "recall": 0.03305,
        "f1": 0.025639,
        "accuracy": 0.03305,
        "main_score": 0.025639,
        "hf_subset": "fin_Latn-eng_Latn",
        "languages": [
          "fin-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000635,
        "recall": 0.004507,
        "f1": 0.000753,
        "accuracy": 0.004507,
        "main_score": 0.000753,
        "hf_subset": "fin_Latn-fas_Arab",
        "languages": [
          "fin-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.016653,
        "recall": 0.023035,
        "f1": 0.017546,
        "accuracy": 0.023035,
        "main_score": 0.017546,
        "hf_subset": "fin_Latn-fra_Latn",
        "languages": [
          "fin-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.001104,
        "recall": 0.002003,
        "f1": 0.001174,
        "accuracy": 0.002003,
        "main_score": 0.001174,
        "hf_subset": "fin_Latn-heb_Hebr",
        "languages": [
          "fin-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000889,
        "recall": 0.003005,
        "f1": 0.001072,
        "accuracy": 0.003005,
        "main_score": 0.001072,
        "hf_subset": "fin_Latn-hin_Deva",
        "languages": [
          "fin-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.013708,
        "recall": 0.019029,
        "f1": 0.014662,
        "accuracy": 0.019029,
        "main_score": 0.014662,
        "hf_subset": "fin_Latn-hun_Latn",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.010541,
        "recall": 0.014021,
        "f1": 0.011232,
        "accuracy": 0.014021,
        "main_score": 0.011232,
        "hf_subset": "fin_Latn-ind_Latn",
        "languages": [
          "fin-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.00194,
        "recall": 0.005508,
        "f1": 0.002174,
        "accuracy": 0.005508,
        "main_score": 0.002174,
        "hf_subset": "fin_Latn-jpn_Jpan",
        "languages": [
          "fin-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000847,
        "recall": 0.004006,
        "f1": 0.001018,
        "accuracy": 0.004006,
        "main_score": 0.001018,
        "hf_subset": "fin_Latn-kor_Hang",
        "languages": [
          "fin-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.009168,
        "recall": 0.015023,
        "f1": 0.009988,
        "accuracy": 0.015023,
        "main_score": 0.009988,
        "hf_subset": "fin_Latn-lav_Latn",
        "languages": [
          "fin-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.006663,
        "recall": 0.011017,
        "f1": 0.007027,
        "accuracy": 0.011017,
        "main_score": 0.007027,
        "hf_subset": "fin_Latn-lit_Latn",
        "languages": [
          "fin-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.016625,
        "recall": 0.022033,
        "f1": 0.017132,
        "accuracy": 0.022033,
        "main_score": 0.017132,
        "hf_subset": "fin_Latn-nld_Latn",
        "languages": [
          "fin-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.010069,
        "recall": 0.014522,
        "f1": 0.01075,
        "accuracy": 0.014522,
        "main_score": 0.01075,
        "hf_subset": "fin_Latn-pol_Latn",
        "languages": [
          "fin-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.0147,
        "recall": 0.019029,
        "f1": 0.015434,
        "accuracy": 0.019029,
        "main_score": 0.015434,
        "hf_subset": "fin_Latn-por_Latn",
        "languages": [
          "fin-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000557,
        "recall": 0.003005,
        "f1": 0.000776,
        "accuracy": 0.003005,
        "main_score": 0.000776,
        "hf_subset": "fin_Latn-rus_Cyrl",
        "languages": [
          "fin-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.013771,
        "recall": 0.02003,
        "f1": 0.014249,
        "accuracy": 0.02003,
        "main_score": 0.014249,
        "hf_subset": "fin_Latn-spa_Latn",
        "languages": [
          "fin-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.010853,
        "recall": 0.015023,
        "f1": 0.011251,
        "accuracy": 0.015023,
        "main_score": 0.011251,
        "hf_subset": "fin_Latn-swa_Latn",
        "languages": [
          "fin-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.015688,
        "recall": 0.022534,
        "f1": 0.016547,
        "accuracy": 0.022534,
        "main_score": 0.016547,
        "hf_subset": "fin_Latn-swe_Latn",
        "languages": [
          "fin-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001108,
        "recall": 0.004006,
        "f1": 0.00119,
        "accuracy": 0.004006,
        "main_score": 0.00119,
        "hf_subset": "fin_Latn-tam_Taml",
        "languages": [
          "fin-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.012716,
        "recall": 0.019529,
        "f1": 0.013487,
        "accuracy": 0.019529,
        "main_score": 0.013487,
        "hf_subset": "fin_Latn-tur_Latn",
        "languages": [
          "fin-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.008064,
        "recall": 0.014021,
        "f1": 0.008644,
        "accuracy": 0.014021,
        "main_score": 0.008644,
        "hf_subset": "fin_Latn-vie_Latn",
        "languages": [
          "fin-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.015608,
        "recall": 0.026039,
        "f1": 0.016588,
        "accuracy": 0.026039,
        "main_score": 0.016588,
        "hf_subset": "fin_Latn-zho_Hant",
        "languages": [
          "fin-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.010117,
        "recall": 0.016024,
        "f1": 0.011023,
        "accuracy": 0.016024,
        "main_score": 0.011023,
        "hf_subset": "fin_Latn-zul_Latn",
        "languages": [
          "fin-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 7.3e-05,
        "recall": 0.001002,
        "f1": 0.000136,
        "accuracy": 0.001002,
        "main_score": 0.000136,
        "hf_subset": "fra_Latn-arb_Arab",
        "languages": [
          "fra-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000613,
        "recall": 0.002003,
        "f1": 0.000702,
        "accuracy": 0.002003,
        "main_score": 0.000702,
        "hf_subset": "fra_Latn-ben_Beng",
        "languages": [
          "fra-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.078876,
        "recall": 0.108162,
        "f1": 0.083609,
        "accuracy": 0.108162,
        "main_score": 0.083609,
        "hf_subset": "fra_Latn-cat_Latn",
        "languages": [
          "fra-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.028588,
        "recall": 0.035053,
        "f1": 0.029307,
        "accuracy": 0.035053,
        "main_score": 0.029307,
        "hf_subset": "fra_Latn-deu_Latn",
        "languages": [
          "fra-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.001826,
        "recall": 0.004507,
        "f1": 0.002041,
        "accuracy": 0.004507,
        "main_score": 0.002041,
        "hf_subset": "fra_Latn-ell_Grek",
        "languages": [
          "fra-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.048841,
        "recall": 0.055083,
        "f1": 0.049799,
        "accuracy": 0.055083,
        "main_score": 0.049799,
        "hf_subset": "fra_Latn-eng_Latn",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00124,
        "recall": 0.004006,
        "f1": 0.001389,
        "accuracy": 0.004006,
        "main_score": 0.001389,
        "hf_subset": "fra_Latn-fas_Arab",
        "languages": [
          "fra-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.014743,
        "recall": 0.019529,
        "f1": 0.015098,
        "accuracy": 0.019529,
        "main_score": 0.015098,
        "hf_subset": "fra_Latn-fin_Latn",
        "languages": [
          "fra-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.066595,
        "recall": 0.083625,
        "f1": 0.069463,
        "accuracy": 0.083625,
        "main_score": 0.069463,
        "hf_subset": "fra_Latn-glg_Latn",
        "languages": [
          "fra-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.000823,
        "recall": 0.002504,
        "f1": 0.001031,
        "accuracy": 0.002504,
        "main_score": 0.001031,
        "hf_subset": "fra_Latn-heb_Hebr",
        "languages": [
          "fra-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "fra_Latn-hin_Deva",
        "languages": [
          "fra-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016562,
        "recall": 0.02003,
        "f1": 0.016999,
        "accuracy": 0.02003,
        "main_score": 0.016999,
        "hf_subset": "fra_Latn-hun_Latn",
        "languages": [
          "fra-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.016134,
        "recall": 0.021532,
        "f1": 0.016988,
        "accuracy": 0.021532,
        "main_score": 0.016988,
        "hf_subset": "fra_Latn-ind_Latn",
        "languages": [
          "fra-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.049218,
        "recall": 0.063595,
        "f1": 0.051418,
        "accuracy": 0.063595,
        "main_score": 0.051418,
        "hf_subset": "fra_Latn-ita_Latn",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.001336,
        "recall": 0.002504,
        "f1": 0.001479,
        "accuracy": 0.002504,
        "main_score": 0.001479,
        "hf_subset": "fra_Latn-jpn_Jpan",
        "languages": [
          "fra-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001398,
        "recall": 0.003005,
        "f1": 0.00159,
        "accuracy": 0.003005,
        "main_score": 0.00159,
        "hf_subset": "fra_Latn-kor_Hang",
        "languages": [
          "fra-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.01041,
        "recall": 0.016024,
        "f1": 0.011238,
        "accuracy": 0.016024,
        "main_score": 0.011238,
        "hf_subset": "fra_Latn-lit_Latn",
        "languages": [
          "fra-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.022232,
        "recall": 0.028543,
        "f1": 0.023197,
        "accuracy": 0.028543,
        "main_score": 0.023197,
        "hf_subset": "fra_Latn-mlt_Latn",
        "languages": [
          "fra-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.031981,
        "recall": 0.047071,
        "f1": 0.033882,
        "accuracy": 0.047071,
        "main_score": 0.033882,
        "hf_subset": "fra_Latn-nld_Latn",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.018836,
        "recall": 0.024036,
        "f1": 0.019657,
        "accuracy": 0.024036,
        "main_score": 0.019657,
        "hf_subset": "fra_Latn-pol_Latn",
        "languages": [
          "fra-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.049338,
        "recall": 0.062594,
        "f1": 0.050979,
        "accuracy": 0.062594,
        "main_score": 0.050979,
        "hf_subset": "fra_Latn-por_Latn",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.044294,
        "recall": 0.062594,
        "f1": 0.046666,
        "accuracy": 0.062594,
        "main_score": 0.046666,
        "hf_subset": "fra_Latn-ron_Latn",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.001377,
        "recall": 0.003005,
        "f1": 0.001596,
        "accuracy": 0.003005,
        "main_score": 0.001596,
        "hf_subset": "fra_Latn-rus_Cyrl",
        "languages": [
          "fra-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.061591,
        "recall": 0.081622,
        "f1": 0.06515,
        "accuracy": 0.081622,
        "main_score": 0.06515,
        "hf_subset": "fra_Latn-spa_Latn",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.008132,
        "recall": 0.010015,
        "f1": 0.008414,
        "accuracy": 0.010015,
        "main_score": 0.008414,
        "hf_subset": "fra_Latn-swa_Latn",
        "languages": [
          "fra-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.026995,
        "recall": 0.035053,
        "f1": 0.028126,
        "accuracy": 0.035053,
        "main_score": 0.028126,
        "hf_subset": "fra_Latn-swe_Latn",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.00137,
        "recall": 0.003005,
        "f1": 0.001537,
        "accuracy": 0.003005,
        "main_score": 0.001537,
        "hf_subset": "fra_Latn-tam_Taml",
        "languages": [
          "fra-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.01161,
        "recall": 0.016024,
        "f1": 0.012156,
        "accuracy": 0.016024,
        "main_score": 0.012156,
        "hf_subset": "fra_Latn-tur_Latn",
        "languages": [
          "fra-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.01703,
        "recall": 0.022534,
        "f1": 0.017727,
        "accuracy": 0.022534,
        "main_score": 0.017727,
        "hf_subset": "fra_Latn-vie_Latn",
        "languages": [
          "fra-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.022108,
        "recall": 0.024537,
        "f1": 0.022335,
        "accuracy": 0.024537,
        "main_score": 0.022335,
        "hf_subset": "fra_Latn-zho_Hant",
        "languages": [
          "fra-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.016927,
        "recall": 0.023035,
        "f1": 0.017539,
        "accuracy": 0.023035,
        "main_score": 0.017539,
        "hf_subset": "fra_Latn-zul_Latn",
        "languages": [
          "fra-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.020628,
        "recall": 0.02654,
        "f1": 0.021684,
        "accuracy": 0.02654,
        "main_score": 0.021684,
        "hf_subset": "fuc_Latn-bem_Latn",
        "languages": [
          "fuc-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.038025,
        "recall": 0.051577,
        "f1": 0.03979,
        "accuracy": 0.051577,
        "main_score": 0.03979,
        "hf_subset": "fuc_Latn-eng_Latn",
        "languages": [
          "fuc-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019076,
        "recall": 0.023035,
        "f1": 0.019955,
        "accuracy": 0.023035,
        "main_score": 0.019955,
        "hf_subset": "fuc_Latn-ewe_Latn",
        "languages": [
          "fuc-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.01303,
        "recall": 0.021532,
        "f1": 0.014423,
        "accuracy": 0.021532,
        "main_score": 0.014423,
        "hf_subset": "fuc_Latn-kin_Latn",
        "languages": [
          "fuc-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.010105,
        "recall": 0.015023,
        "f1": 0.010657,
        "accuracy": 0.015023,
        "main_score": 0.010657,
        "hf_subset": "fuc_Latn-nde_Latn",
        "languages": [
          "fuc-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.014136,
        "recall": 0.023035,
        "f1": 0.015427,
        "accuracy": 0.023035,
        "main_score": 0.015427,
        "hf_subset": "fuc_Latn-nya_Latn",
        "languages": [
          "fuc-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.011051,
        "recall": 0.014522,
        "f1": 0.01153,
        "accuracy": 0.014522,
        "main_score": 0.01153,
        "hf_subset": "fuc_Latn-sna_Latn",
        "languages": [
          "fuc-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.016867,
        "recall": 0.021532,
        "f1": 0.017838,
        "accuracy": 0.021532,
        "main_score": 0.017838,
        "hf_subset": "fuc_Latn-ven_Latn",
        "languages": [
          "fuc-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.015425,
        "recall": 0.024036,
        "f1": 0.016707,
        "accuracy": 0.024036,
        "main_score": 0.016707,
        "hf_subset": "gle_Latn-cym_Latn",
        "languages": [
          "gle-Latn",
          "cym-Latn"
        ]
      },
      {
        "precision": 0.025396,
        "recall": 0.035053,
        "f1": 0.026481,
        "accuracy": 0.035053,
        "main_score": 0.026481,
        "hf_subset": "gle_Latn-eng_Latn",
        "languages": [
          "gle-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.248569,
        "recall": 0.304457,
        "f1": 0.259363,
        "accuracy": 0.304457,
        "main_score": 0.259363,
        "hf_subset": "glg_Latn-cat_Latn",
        "languages": [
          "glg-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.048362,
        "recall": 0.063095,
        "f1": 0.050833,
        "accuracy": 0.063095,
        "main_score": 0.050833,
        "hf_subset": "glg_Latn-eng_Latn",
        "languages": [
          "glg-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.071985,
        "recall": 0.102153,
        "f1": 0.077135,
        "accuracy": 0.102153,
        "main_score": 0.077135,
        "hf_subset": "glg_Latn-fra_Latn",
        "languages": [
          "glg-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.102868,
        "recall": 0.134201,
        "f1": 0.108641,
        "accuracy": 0.134201,
        "main_score": 0.108641,
        "hf_subset": "glg_Latn-ita_Latn",
        "languages": [
          "glg-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.02596,
        "recall": 0.040561,
        "f1": 0.02819,
        "accuracy": 0.040561,
        "main_score": 0.02819,
        "hf_subset": "glg_Latn-mlt_Latn",
        "languages": [
          "glg-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.475389,
        "recall": 0.557336,
        "f1": 0.495524,
        "accuracy": 0.557336,
        "main_score": 0.495524,
        "hf_subset": "glg_Latn-por_Latn",
        "languages": [
          "glg-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.052815,
        "recall": 0.074612,
        "f1": 0.056433,
        "accuracy": 0.074612,
        "main_score": 0.056433,
        "hf_subset": "glg_Latn-ron_Latn",
        "languages": [
          "glg-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.548917,
        "recall": 0.628943,
        "f1": 0.569161,
        "accuracy": 0.628943,
        "main_score": 0.569161,
        "hf_subset": "glg_Latn-spa_Latn",
        "languages": [
          "glg-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 2.3e-05,
        "recall": 0.001002,
        "f1": 4.4e-05,
        "accuracy": 0.001002,
        "main_score": 4.4e-05,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.093313,
        "recall": 0.119179,
        "f1": 0.099761,
        "accuracy": 0.119179,
        "main_score": 0.099761,
        "hf_subset": "guj_Gujr-div_Thaa",
        "languages": [
          "guj-Gujr",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.020178,
        "recall": 0.037056,
        "f1": 0.022785,
        "accuracy": 0.037056,
        "main_score": 0.022785,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003038,
        "recall": 0.009514,
        "f1": 0.003791,
        "accuracy": 0.009514,
        "main_score": 0.003791,
        "hf_subset": "guj_Gujr-eus_Latn",
        "languages": [
          "guj-Gujr",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.001493,
        "recall": 0.005508,
        "f1": 0.001976,
        "accuracy": 0.005508,
        "main_score": 0.001976,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.104323,
        "recall": 0.131197,
        "f1": 0.111227,
        "accuracy": 0.131197,
        "main_score": 0.111227,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000548,
        "recall": 0.003505,
        "f1": 0.000758,
        "accuracy": 0.003505,
        "main_score": 0.000758,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001494,
        "recall": 0.003505,
        "f1": 0.001766,
        "accuracy": 0.003505,
        "main_score": 0.001766,
        "hf_subset": "guj_Gujr-nep_Deva",
        "languages": [
          "guj-Gujr",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.093169,
        "recall": 0.123185,
        "f1": 0.100184,
        "accuracy": 0.123185,
        "main_score": 0.100184,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.065237,
        "recall": 0.097646,
        "f1": 0.071992,
        "accuracy": 0.097646,
        "main_score": 0.071992,
        "hf_subset": "guj_Gujr-sin_Sinh",
        "languages": [
          "guj-Gujr",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.00446,
        "recall": 0.011017,
        "f1": 0.00524,
        "accuracy": 0.011017,
        "main_score": 0.00524,
        "hf_subset": "guj_Gujr-snd_Arab",
        "languages": [
          "guj-Gujr",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.000887,
        "recall": 0.006009,
        "f1": 0.001139,
        "accuracy": 0.006009,
        "main_score": 0.001139,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.114458,
        "recall": 0.145719,
        "f1": 0.122682,
        "accuracy": 0.145719,
        "main_score": 0.122682,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002676,
        "recall": 0.00651,
        "f1": 0.003027,
        "accuracy": 0.00651,
        "main_score": 0.003027,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.009212,
        "recall": 0.018027,
        "f1": 0.010054,
        "accuracy": 0.018027,
        "main_score": 0.010054,
        "hf_subset": "hau_Latn-amh_Ethi",
        "languages": [
          "hau-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.027982,
        "recall": 0.042063,
        "f1": 0.029477,
        "accuracy": 0.042063,
        "main_score": 0.029477,
        "hf_subset": "hau_Latn-eng_Latn",
        "languages": [
          "hau-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013499,
        "recall": 0.02003,
        "f1": 0.014297,
        "accuracy": 0.02003,
        "main_score": 0.014297,
        "hf_subset": "hau_Latn-ibo_Latn",
        "languages": [
          "hau-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.011018,
        "recall": 0.016024,
        "f1": 0.011703,
        "accuracy": 0.016024,
        "main_score": 0.011703,
        "hf_subset": "hau_Latn-nso_Latn",
        "languages": [
          "hau-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.008608,
        "recall": 0.01302,
        "f1": 0.009464,
        "accuracy": 0.01302,
        "main_score": 0.009464,
        "hf_subset": "hau_Latn-orm_Ethi",
        "languages": [
          "hau-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.012275,
        "recall": 0.015523,
        "f1": 0.012823,
        "accuracy": 0.015523,
        "main_score": 0.012823,
        "hf_subset": "hau_Latn-som_Latn",
        "languages": [
          "hau-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.00875,
        "recall": 0.014021,
        "f1": 0.00959,
        "accuracy": 0.014021,
        "main_score": 0.00959,
        "hf_subset": "hau_Latn-ssw_Latn",
        "languages": [
          "hau-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.018491,
        "recall": 0.024537,
        "f1": 0.019434,
        "accuracy": 0.024537,
        "main_score": 0.019434,
        "hf_subset": "hau_Latn-swa_Latn",
        "languages": [
          "hau-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.005304,
        "recall": 0.009014,
        "f1": 0.005681,
        "accuracy": 0.009014,
        "main_score": 0.005681,
        "hf_subset": "hau_Latn-tir_Ethi",
        "languages": [
          "hau-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.011041,
        "recall": 0.017026,
        "f1": 0.011973,
        "accuracy": 0.017026,
        "main_score": 0.011973,
        "hf_subset": "hau_Latn-tsn_Latn",
        "languages": [
          "hau-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.012275,
        "recall": 0.017026,
        "f1": 0.012968,
        "accuracy": 0.017026,
        "main_score": 0.012968,
        "hf_subset": "hau_Latn-wol_Latn",
        "languages": [
          "hau-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.007362,
        "recall": 0.010015,
        "f1": 0.007945,
        "accuracy": 0.010015,
        "main_score": 0.007945,
        "hf_subset": "hau_Latn-xho_Latn",
        "languages": [
          "hau-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.011392,
        "recall": 0.015023,
        "f1": 0.011959,
        "accuracy": 0.015023,
        "main_score": 0.011959,
        "hf_subset": "hau_Latn-yor_Latn",
        "languages": [
          "hau-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.009575,
        "recall": 0.015523,
        "f1": 0.010349,
        "accuracy": 0.015523,
        "main_score": 0.010349,
        "hf_subset": "hau_Latn-zul_Latn",
        "languages": [
          "hau-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000418,
        "recall": 0.001502,
        "f1": 0.000585,
        "accuracy": 0.001502,
        "main_score": 0.000585,
        "hf_subset": "heb_Hebr-arb_Arab",
        "languages": [
          "heb-Hebr",
          "arb-Arab"
        ]
      },
      {
        "precision": 3.2e-05,
        "recall": 0.001502,
        "f1": 6e-05,
        "accuracy": 0.001502,
        "main_score": 6e-05,
        "hf_subset": "heb_Hebr-ben_Beng",
        "languages": [
          "heb-Hebr",
          "ben-Beng"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.001002,
        "f1": 1.3e-05,
        "accuracy": 0.001002,
        "main_score": 1.3e-05,
        "hf_subset": "heb_Hebr-ckb_Arab",
        "languages": [
          "heb-Hebr",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.001553,
        "recall": 0.002504,
        "f1": 0.001596,
        "accuracy": 0.002504,
        "main_score": 0.001596,
        "hf_subset": "heb_Hebr-deu_Latn",
        "languages": [
          "heb-Hebr",
          "deu-Latn"
        ]
      },
      {
        "precision": 8e-06,
        "recall": 0.001002,
        "f1": 1.5e-05,
        "accuracy": 0.001002,
        "main_score": 1.5e-05,
        "hf_subset": "heb_Hebr-ell_Grek",
        "languages": [
          "heb-Hebr",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.001325,
        "recall": 0.004006,
        "f1": 0.001473,
        "accuracy": 0.004006,
        "main_score": 0.001473,
        "hf_subset": "heb_Hebr-eng_Latn",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001002,
        "f1": 0.000508,
        "accuracy": 0.001002,
        "main_score": 0.000508,
        "hf_subset": "heb_Hebr-fas_Arab",
        "languages": [
          "heb-Hebr",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "heb_Hebr-fin_Latn",
        "languages": [
          "heb-Hebr",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.000505,
        "recall": 0.002003,
        "f1": 0.000509,
        "accuracy": 0.002003,
        "main_score": 0.000509,
        "hf_subset": "heb_Hebr-fra_Latn",
        "languages": [
          "heb-Hebr",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000755,
        "recall": 0.001502,
        "f1": 0.000841,
        "accuracy": 0.001502,
        "main_score": 0.000841,
        "hf_subset": "heb_Hebr-hin_Deva",
        "languages": [
          "heb-Hebr",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.8e-05,
        "recall": 0.002003,
        "f1": 3.6e-05,
        "accuracy": 0.002003,
        "main_score": 3.6e-05,
        "hf_subset": "heb_Hebr-hun_Latn",
        "languages": [
          "heb-Hebr",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "heb_Hebr-ind_Latn",
        "languages": [
          "heb-Hebr",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000256,
        "recall": 0.001002,
        "f1": 0.000345,
        "accuracy": 0.001002,
        "main_score": 0.000345,
        "hf_subset": "heb_Hebr-jpn_Jpan",
        "languages": [
          "heb-Hebr",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.001002,
        "f1": 2e-05,
        "accuracy": 0.001002,
        "main_score": 2e-05,
        "hf_subset": "heb_Hebr-kmr_Latn",
        "languages": [
          "heb-Hebr",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000511,
        "recall": 0.002003,
        "f1": 0.00052,
        "accuracy": 0.002003,
        "main_score": 0.00052,
        "hf_subset": "heb_Hebr-kor_Hang",
        "languages": [
          "heb-Hebr",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.000156,
        "recall": 0.001502,
        "f1": 0.00027,
        "accuracy": 0.001502,
        "main_score": 0.00027,
        "hf_subset": "heb_Hebr-lit_Latn",
        "languages": [
          "heb-Hebr",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.001062,
        "recall": 0.002003,
        "f1": 0.001116,
        "accuracy": 0.002003,
        "main_score": 0.001116,
        "hf_subset": "heb_Hebr-mey_Arab",
        "languages": [
          "heb-Hebr",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.000607,
        "recall": 0.002504,
        "f1": 0.00068,
        "accuracy": 0.002504,
        "main_score": 0.00068,
        "hf_subset": "heb_Hebr-nld_Latn",
        "languages": [
          "heb-Hebr",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.000626,
        "recall": 0.001502,
        "f1": 0.000702,
        "accuracy": 0.001502,
        "main_score": 0.000702,
        "hf_subset": "heb_Hebr-pol_Latn",
        "languages": [
          "heb-Hebr",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "heb_Hebr-por_Latn",
        "languages": [
          "heb-Hebr",
          "por-Latn"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.001502,
        "f1": 1.5e-05,
        "accuracy": 0.001502,
        "main_score": 1.5e-05,
        "hf_subset": "heb_Hebr-prs_Arab",
        "languages": [
          "heb-Hebr",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000125,
        "recall": 0.000501,
        "f1": 0.0002,
        "accuracy": 0.000501,
        "main_score": 0.0002,
        "hf_subset": "heb_Hebr-pus_Arab",
        "languages": [
          "heb-Hebr",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.002003,
        "recall": 0.002504,
        "f1": 0.002004,
        "accuracy": 0.002504,
        "main_score": 0.002004,
        "hf_subset": "heb_Hebr-rus_Cyrl",
        "languages": [
          "heb-Hebr",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "heb_Hebr-shi_Arab",
        "languages": [
          "heb-Hebr",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "heb_Hebr-spa_Latn",
        "languages": [
          "heb-Hebr",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001002,
        "f1": 0.001002,
        "accuracy": 0.001002,
        "main_score": 0.001002,
        "hf_subset": "heb_Hebr-swa_Latn",
        "languages": [
          "heb-Hebr",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.00069,
        "recall": 0.002003,
        "f1": 0.000794,
        "accuracy": 0.002003,
        "main_score": 0.000794,
        "hf_subset": "heb_Hebr-swe_Latn",
        "languages": [
          "heb-Hebr",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000505,
        "recall": 0.002003,
        "f1": 0.00051,
        "accuracy": 0.002003,
        "main_score": 0.00051,
        "hf_subset": "heb_Hebr-tam_Taml",
        "languages": [
          "heb-Hebr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001494,
        "recall": 0.003505,
        "f1": 0.001724,
        "accuracy": 0.003505,
        "main_score": 0.001724,
        "hf_subset": "heb_Hebr-tgk_Cyrl",
        "languages": [
          "heb-Hebr",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.001514,
        "recall": 0.002504,
        "f1": 0.001525,
        "accuracy": 0.002504,
        "main_score": 0.001525,
        "hf_subset": "heb_Hebr-tur_Latn",
        "languages": [
          "heb-Hebr",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000603,
        "recall": 0.002003,
        "f1": 0.000671,
        "accuracy": 0.002003,
        "main_score": 0.000671,
        "hf_subset": "heb_Hebr-vie_Latn",
        "languages": [
          "heb-Hebr",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.001169,
        "recall": 0.002003,
        "f1": 0.001253,
        "accuracy": 0.002003,
        "main_score": 0.001253,
        "hf_subset": "heb_Hebr-zho_Hant",
        "languages": [
          "heb-Hebr",
          "zho-Hant"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "heb_Hebr-zul_Latn",
        "languages": [
          "heb-Hebr",
          "zul-Latn"
        ]
      },
      {
        "precision": 6e-05,
        "recall": 0.001502,
        "f1": 0.000111,
        "accuracy": 0.001502,
        "main_score": 0.000111,
        "hf_subset": "hin_Deva-arb_Arab",
        "languages": [
          "hin-Deva",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000332,
        "recall": 0.003005,
        "f1": 0.000487,
        "accuracy": 0.003005,
        "main_score": 0.000487,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001502,
        "recall": 0.001502,
        "f1": 0.001502,
        "accuracy": 0.001502,
        "main_score": 0.001502,
        "hf_subset": "hin_Deva-deu_Latn",
        "languages": [
          "hin-Deva",
          "deu-Latn"
        ]
      },
      {
        "precision": 2.4e-05,
        "recall": 0.001002,
        "f1": 4.6e-05,
        "accuracy": 0.001002,
        "main_score": 4.6e-05,
        "hf_subset": "hin_Deva-div_Thaa",
        "languages": [
          "hin-Deva",
          "div-Thaa"
        ]
      },
      {
        "precision": 5.6e-05,
        "recall": 0.000501,
        "f1": 0.0001,
        "accuracy": 0.000501,
        "main_score": 0.0001,
        "hf_subset": "hin_Deva-ell_Grek",
        "languages": [
          "hin-Deva",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.001182,
        "recall": 0.003005,
        "f1": 0.001278,
        "accuracy": 0.003005,
        "main_score": 0.001278,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "hin_Deva-eus_Latn",
        "languages": [
          "hin-Deva",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.000693,
        "recall": 0.002003,
        "f1": 0.0008,
        "accuracy": 0.002003,
        "main_score": 0.0008,
        "hf_subset": "hin_Deva-fas_Arab",
        "languages": [
          "hin-Deva",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.00102,
        "recall": 0.003005,
        "f1": 0.001204,
        "accuracy": 0.003005,
        "main_score": 0.001204,
        "hf_subset": "hin_Deva-fin_Latn",
        "languages": [
          "hin-Deva",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "hin_Deva-fra_Latn",
        "languages": [
          "hin-Deva",
          "fra-Latn"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001502,
        "f1": 7e-06,
        "accuracy": 0.001502,
        "main_score": 7e-06,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.001253,
        "recall": 0.002003,
        "f1": 0.001338,
        "accuracy": 0.002003,
        "main_score": 0.001338,
        "hf_subset": "hin_Deva-heb_Hebr",
        "languages": [
          "hin-Deva",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.001168,
        "recall": 0.003505,
        "f1": 0.001292,
        "accuracy": 0.003505,
        "main_score": 0.001292,
        "hf_subset": "hin_Deva-hun_Latn",
        "languages": [
          "hin-Deva",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "hin_Deva-ind_Latn",
        "languages": [
          "hin-Deva",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001013,
        "recall": 0.002003,
        "f1": 0.001025,
        "accuracy": 0.002003,
        "main_score": 0.001025,
        "hf_subset": "hin_Deva-jpn_Jpan",
        "languages": [
          "hin-Deva",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000697,
        "recall": 0.002003,
        "f1": 0.000835,
        "accuracy": 0.002003,
        "main_score": 0.000835,
        "hf_subset": "hin_Deva-kor_Hang",
        "languages": [
          "hin-Deva",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.00052,
        "recall": 0.001502,
        "f1": 0.000539,
        "accuracy": 0.001502,
        "main_score": 0.000539,
        "hf_subset": "hin_Deva-lit_Latn",
        "languages": [
          "hin-Deva",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.021997,
        "recall": 0.034552,
        "f1": 0.023871,
        "accuracy": 0.034552,
        "main_score": 0.023871,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.028785,
        "recall": 0.048072,
        "f1": 0.032493,
        "accuracy": 0.048072,
        "main_score": 0.032493,
        "hf_subset": "hin_Deva-nep_Deva",
        "languages": [
          "hin-Deva",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.001107,
        "recall": 0.002504,
        "f1": 0.001179,
        "accuracy": 0.002504,
        "main_score": 0.001179,
        "hf_subset": "hin_Deva-nld_Latn",
        "languages": [
          "hin-Deva",
          "nld-Latn"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.001502,
        "f1": 2.1e-05,
        "accuracy": 0.001502,
        "main_score": 2.1e-05,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000505,
        "recall": 0.001502,
        "f1": 0.00051,
        "accuracy": 0.001502,
        "main_score": 0.00051,
        "hf_subset": "hin_Deva-pol_Latn",
        "languages": [
          "hin-Deva",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.000556,
        "recall": 0.001502,
        "f1": 0.000606,
        "accuracy": 0.001502,
        "main_score": 0.000606,
        "hf_subset": "hin_Deva-por_Latn",
        "languages": [
          "hin-Deva",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "hin_Deva-rus_Cyrl",
        "languages": [
          "hin-Deva",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 2.2e-05,
        "recall": 0.001002,
        "f1": 4.2e-05,
        "accuracy": 0.001002,
        "main_score": 4.2e-05,
        "hf_subset": "hin_Deva-sin_Sinh",
        "languages": [
          "hin-Deva",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000353,
        "recall": 0.002003,
        "f1": 0.00052,
        "accuracy": 0.002003,
        "main_score": 0.00052,
        "hf_subset": "hin_Deva-snd_Arab",
        "languages": [
          "hin-Deva",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "hin_Deva-spa_Latn",
        "languages": [
          "hin-Deva",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001169,
        "recall": 0.002003,
        "f1": 0.001253,
        "accuracy": 0.002003,
        "main_score": 0.001253,
        "hf_subset": "hin_Deva-swa_Latn",
        "languages": [
          "hin-Deva",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001052,
        "recall": 0.002003,
        "f1": 0.001093,
        "accuracy": 0.002003,
        "main_score": 0.001093,
        "hf_subset": "hin_Deva-swe_Latn",
        "languages": [
          "hin-Deva",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000506,
        "accuracy": 0.001502,
        "main_score": 0.000506,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.002003,
        "f1": 0.000506,
        "accuracy": 0.002003,
        "main_score": 0.000506,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "hin_Deva-tur_Latn",
        "languages": [
          "hin-Deva",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000762,
        "recall": 0.003005,
        "f1": 0.000915,
        "accuracy": 0.003005,
        "main_score": 0.000915,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "hin_Deva-vie_Latn",
        "languages": [
          "hin-Deva",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "hin_Deva-zho_Hant",
        "languages": [
          "hin-Deva",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.002003,
        "f1": 0.001169,
        "accuracy": 0.002003,
        "main_score": 0.001169,
        "hf_subset": "hin_Deva-zul_Latn",
        "languages": [
          "hin-Deva",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.018344,
        "recall": 0.02654,
        "f1": 0.019466,
        "accuracy": 0.02654,
        "main_score": 0.019466,
        "hf_subset": "hmn_Latn-eng_Latn",
        "languages": [
          "hmn-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001949,
        "recall": 0.005508,
        "f1": 0.002384,
        "accuracy": 0.005508,
        "main_score": 0.002384,
        "hf_subset": "hrv_Latn-bel_Cyrl",
        "languages": [
          "hrv-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.743963,
        "recall": 0.805208,
        "f1": 0.761734,
        "accuracy": 0.805208,
        "main_score": 0.761734,
        "hf_subset": "hrv_Latn-bos_Latn",
        "languages": [
          "hrv-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.004737,
        "recall": 0.012519,
        "f1": 0.005791,
        "accuracy": 0.012519,
        "main_score": 0.005791,
        "hf_subset": "hrv_Latn-bul_Cyrl",
        "languages": [
          "hrv-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.057029,
        "recall": 0.075113,
        "f1": 0.060245,
        "accuracy": 0.075113,
        "main_score": 0.060245,
        "hf_subset": "hrv_Latn-ces_Latn",
        "languages": [
          "hrv-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.018365,
        "recall": 0.023035,
        "f1": 0.019211,
        "accuracy": 0.023035,
        "main_score": 0.019211,
        "hf_subset": "hrv_Latn-eng_Latn",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004685,
        "recall": 0.015523,
        "f1": 0.005846,
        "accuracy": 0.015523,
        "main_score": 0.005846,
        "hf_subset": "hrv_Latn-mkd_Cyrl",
        "languages": [
          "hrv-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.023576,
        "recall": 0.03305,
        "f1": 0.025313,
        "accuracy": 0.03305,
        "main_score": 0.025313,
        "hf_subset": "hrv_Latn-pol_Latn",
        "languages": [
          "hrv-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.004905,
        "recall": 0.011017,
        "f1": 0.005764,
        "accuracy": 0.011017,
        "main_score": 0.005764,
        "hf_subset": "hrv_Latn-rus_Cyrl",
        "languages": [
          "hrv-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.055035,
        "recall": 0.076114,
        "f1": 0.058513,
        "accuracy": 0.076114,
        "main_score": 0.058513,
        "hf_subset": "hrv_Latn-slk_Latn",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.187561,
        "recall": 0.243866,
        "f1": 0.199474,
        "accuracy": 0.243866,
        "main_score": 0.199474,
        "hf_subset": "hrv_Latn-slv_Latn",
        "languages": [
          "hrv-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.008181,
        "recall": 0.022534,
        "f1": 0.009705,
        "accuracy": 0.022534,
        "main_score": 0.009705,
        "hf_subset": "hrv_Latn-srp_Cyrl",
        "languages": [
          "hrv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.550807,
        "recall": 0.636455,
        "f1": 0.573821,
        "accuracy": 0.636455,
        "main_score": 0.573821,
        "hf_subset": "hrv_Latn-srp_Latn",
        "languages": [
          "hrv-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.00188,
        "recall": 0.00651,
        "f1": 0.002394,
        "accuracy": 0.00651,
        "main_score": 0.002394,
        "hf_subset": "hrv_Latn-ukr_Cyrl",
        "languages": [
          "hrv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.000524,
        "recall": 0.001502,
        "f1": 0.000546,
        "accuracy": 0.001502,
        "main_score": 0.000546,
        "hf_subset": "hun_Latn-arb_Arab",
        "languages": [
          "hun-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001106,
        "recall": 0.003005,
        "f1": 0.001353,
        "accuracy": 0.003005,
        "main_score": 0.001353,
        "hf_subset": "hun_Latn-ben_Beng",
        "languages": [
          "hun-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.018349,
        "recall": 0.02654,
        "f1": 0.019685,
        "accuracy": 0.02654,
        "main_score": 0.019685,
        "hf_subset": "hun_Latn-deu_Latn",
        "languages": [
          "hun-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.0012,
        "recall": 0.003005,
        "f1": 0.001313,
        "accuracy": 0.003005,
        "main_score": 0.001313,
        "hf_subset": "hun_Latn-ell_Grek",
        "languages": [
          "hun-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.026091,
        "recall": 0.037556,
        "f1": 0.027679,
        "accuracy": 0.037556,
        "main_score": 0.027679,
        "hf_subset": "hun_Latn-eng_Latn",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002666,
        "recall": 0.007011,
        "f1": 0.003009,
        "accuracy": 0.007011,
        "main_score": 0.003009,
        "hf_subset": "hun_Latn-fas_Arab",
        "languages": [
          "hun-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.012343,
        "recall": 0.016024,
        "f1": 0.013076,
        "accuracy": 0.016024,
        "main_score": 0.013076,
        "hf_subset": "hun_Latn-fin_Latn",
        "languages": [
          "hun-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.018282,
        "recall": 0.029044,
        "f1": 0.019406,
        "accuracy": 0.029044,
        "main_score": 0.019406,
        "hf_subset": "hun_Latn-fra_Latn",
        "languages": [
          "hun-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.003092,
        "recall": 0.005008,
        "f1": 0.003346,
        "accuracy": 0.005008,
        "main_score": 0.003346,
        "hf_subset": "hun_Latn-heb_Hebr",
        "languages": [
          "hun-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000225,
        "recall": 0.001502,
        "f1": 0.000355,
        "accuracy": 0.001502,
        "main_score": 0.000355,
        "hf_subset": "hun_Latn-hin_Deva",
        "languages": [
          "hun-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015934,
        "recall": 0.022033,
        "f1": 0.016907,
        "accuracy": 0.022033,
        "main_score": 0.016907,
        "hf_subset": "hun_Latn-ind_Latn",
        "languages": [
          "hun-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001079,
        "recall": 0.005508,
        "f1": 0.001381,
        "accuracy": 0.005508,
        "main_score": 0.001381,
        "hf_subset": "hun_Latn-jpn_Jpan",
        "languages": [
          "hun-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.00219,
        "recall": 0.005008,
        "f1": 0.002551,
        "accuracy": 0.005008,
        "main_score": 0.002551,
        "hf_subset": "hun_Latn-kor_Hang",
        "languages": [
          "hun-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.009366,
        "recall": 0.014021,
        "f1": 0.009986,
        "accuracy": 0.014021,
        "main_score": 0.009986,
        "hf_subset": "hun_Latn-lav_Latn",
        "languages": [
          "hun-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.009262,
        "recall": 0.015023,
        "f1": 0.00999,
        "accuracy": 0.015023,
        "main_score": 0.00999,
        "hf_subset": "hun_Latn-lit_Latn",
        "languages": [
          "hun-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.018186,
        "recall": 0.025538,
        "f1": 0.019531,
        "accuracy": 0.025538,
        "main_score": 0.019531,
        "hf_subset": "hun_Latn-nld_Latn",
        "languages": [
          "hun-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.011575,
        "recall": 0.019529,
        "f1": 0.012728,
        "accuracy": 0.019529,
        "main_score": 0.012728,
        "hf_subset": "hun_Latn-pol_Latn",
        "languages": [
          "hun-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.018612,
        "recall": 0.02654,
        "f1": 0.019968,
        "accuracy": 0.02654,
        "main_score": 0.019968,
        "hf_subset": "hun_Latn-por_Latn",
        "languages": [
          "hun-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001211,
        "recall": 0.003005,
        "f1": 0.001552,
        "accuracy": 0.003005,
        "main_score": 0.001552,
        "hf_subset": "hun_Latn-rus_Cyrl",
        "languages": [
          "hun-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.017625,
        "recall": 0.027041,
        "f1": 0.019314,
        "accuracy": 0.027041,
        "main_score": 0.019314,
        "hf_subset": "hun_Latn-spa_Latn",
        "languages": [
          "hun-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.010088,
        "recall": 0.01352,
        "f1": 0.010629,
        "accuracy": 0.01352,
        "main_score": 0.010629,
        "hf_subset": "hun_Latn-swa_Latn",
        "languages": [
          "hun-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.02536,
        "recall": 0.032048,
        "f1": 0.026358,
        "accuracy": 0.032048,
        "main_score": 0.026358,
        "hf_subset": "hun_Latn-swe_Latn",
        "languages": [
          "hun-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001508,
        "recall": 0.003005,
        "f1": 0.001513,
        "accuracy": 0.003005,
        "main_score": 0.001513,
        "hf_subset": "hun_Latn-tam_Taml",
        "languages": [
          "hun-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.010079,
        "recall": 0.014021,
        "f1": 0.010769,
        "accuracy": 0.014021,
        "main_score": 0.010769,
        "hf_subset": "hun_Latn-tur_Latn",
        "languages": [
          "hun-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.007668,
        "recall": 0.014522,
        "f1": 0.008804,
        "accuracy": 0.014522,
        "main_score": 0.008804,
        "hf_subset": "hun_Latn-vie_Latn",
        "languages": [
          "hun-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.019577,
        "recall": 0.036054,
        "f1": 0.022154,
        "accuracy": 0.036054,
        "main_score": 0.022154,
        "hf_subset": "hun_Latn-zho_Hant",
        "languages": [
          "hun-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.012787,
        "recall": 0.015023,
        "f1": 0.013222,
        "accuracy": 0.015023,
        "main_score": 0.013222,
        "hf_subset": "hun_Latn-zul_Latn",
        "languages": [
          "hun-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.001257,
        "recall": 0.002504,
        "f1": 0.001345,
        "accuracy": 0.002504,
        "main_score": 0.001345,
        "hf_subset": "hye_Armn-ell_Grek",
        "languages": [
          "hye-Armn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.003274,
        "recall": 0.006009,
        "f1": 0.003436,
        "accuracy": 0.006009,
        "main_score": 0.003436,
        "hf_subset": "hye_Armn-eng_Latn",
        "languages": [
          "hye-Armn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003205,
        "recall": 0.004507,
        "f1": 0.003354,
        "accuracy": 0.004507,
        "main_score": 0.003354,
        "hf_subset": "hye_Armn-kat_Geor",
        "languages": [
          "hye-Armn",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001168,
        "accuracy": 0.001502,
        "main_score": 0.001168,
        "hf_subset": "hye_Armn-sqi_Latn",
        "languages": [
          "hye-Armn",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.013797,
        "recall": 0.019529,
        "f1": 0.014565,
        "accuracy": 0.019529,
        "main_score": 0.014565,
        "hf_subset": "ibo_Latn-amh_Ethi",
        "languages": [
          "ibo-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.040007,
        "recall": 0.052579,
        "f1": 0.042158,
        "accuracy": 0.052579,
        "main_score": 0.042158,
        "hf_subset": "ibo_Latn-eng_Latn",
        "languages": [
          "ibo-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018046,
        "recall": 0.027041,
        "f1": 0.019382,
        "accuracy": 0.027041,
        "main_score": 0.019382,
        "hf_subset": "ibo_Latn-hau_Latn",
        "languages": [
          "ibo-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.016935,
        "recall": 0.02003,
        "f1": 0.017356,
        "accuracy": 0.02003,
        "main_score": 0.017356,
        "hf_subset": "ibo_Latn-nso_Latn",
        "languages": [
          "ibo-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.007414,
        "recall": 0.011517,
        "f1": 0.008047,
        "accuracy": 0.011517,
        "main_score": 0.008047,
        "hf_subset": "ibo_Latn-orm_Ethi",
        "languages": [
          "ibo-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.014369,
        "recall": 0.020531,
        "f1": 0.015405,
        "accuracy": 0.020531,
        "main_score": 0.015405,
        "hf_subset": "ibo_Latn-som_Latn",
        "languages": [
          "ibo-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.01726,
        "recall": 0.025038,
        "f1": 0.018363,
        "accuracy": 0.025038,
        "main_score": 0.018363,
        "hf_subset": "ibo_Latn-ssw_Latn",
        "languages": [
          "ibo-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.019214,
        "recall": 0.022033,
        "f1": 0.019899,
        "accuracy": 0.022033,
        "main_score": 0.019899,
        "hf_subset": "ibo_Latn-swa_Latn",
        "languages": [
          "ibo-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.007586,
        "recall": 0.011017,
        "f1": 0.007875,
        "accuracy": 0.011017,
        "main_score": 0.007875,
        "hf_subset": "ibo_Latn-tir_Ethi",
        "languages": [
          "ibo-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.016432,
        "recall": 0.023035,
        "f1": 0.017454,
        "accuracy": 0.023035,
        "main_score": 0.017454,
        "hf_subset": "ibo_Latn-tsn_Latn",
        "languages": [
          "ibo-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.012005,
        "recall": 0.017026,
        "f1": 0.012742,
        "accuracy": 0.017026,
        "main_score": 0.012742,
        "hf_subset": "ibo_Latn-wol_Latn",
        "languages": [
          "ibo-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.011315,
        "recall": 0.016024,
        "f1": 0.01189,
        "accuracy": 0.016024,
        "main_score": 0.01189,
        "hf_subset": "ibo_Latn-xho_Latn",
        "languages": [
          "ibo-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.013687,
        "recall": 0.015523,
        "f1": 0.014271,
        "accuracy": 0.015523,
        "main_score": 0.014271,
        "hf_subset": "ibo_Latn-yor_Latn",
        "languages": [
          "ibo-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.021108,
        "recall": 0.027041,
        "f1": 0.022017,
        "accuracy": 0.027041,
        "main_score": 0.022017,
        "hf_subset": "ibo_Latn-zul_Latn",
        "languages": [
          "ibo-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 8.3e-05,
        "recall": 0.000501,
        "f1": 0.000143,
        "accuracy": 0.000501,
        "main_score": 0.000143,
        "hf_subset": "ind_Latn-arb_Arab",
        "languages": [
          "ind-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001002,
        "f1": 0.000835,
        "accuracy": 0.001002,
        "main_score": 0.000835,
        "hf_subset": "ind_Latn-ben_Beng",
        "languages": [
          "ind-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.021078,
        "recall": 0.030045,
        "f1": 0.022038,
        "accuracy": 0.030045,
        "main_score": 0.022038,
        "hf_subset": "ind_Latn-deu_Latn",
        "languages": [
          "ind-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.00062,
        "recall": 0.003005,
        "f1": 0.000873,
        "accuracy": 0.003005,
        "main_score": 0.000873,
        "hf_subset": "ind_Latn-ell_Grek",
        "languages": [
          "ind-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.02427,
        "recall": 0.035053,
        "f1": 0.025704,
        "accuracy": 0.035053,
        "main_score": 0.025704,
        "hf_subset": "ind_Latn-eng_Latn",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001429,
        "recall": 0.005008,
        "f1": 0.001656,
        "accuracy": 0.005008,
        "main_score": 0.001656,
        "hf_subset": "ind_Latn-fas_Arab",
        "languages": [
          "ind-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.01161,
        "recall": 0.018528,
        "f1": 0.01236,
        "accuracy": 0.018528,
        "main_score": 0.01236,
        "hf_subset": "ind_Latn-fij_Latn",
        "languages": [
          "ind-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.021398,
        "recall": 0.02654,
        "f1": 0.022412,
        "accuracy": 0.02654,
        "main_score": 0.022412,
        "hf_subset": "ind_Latn-fil_Latn",
        "languages": [
          "ind-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.019156,
        "recall": 0.026039,
        "f1": 0.020067,
        "accuracy": 0.026039,
        "main_score": 0.020067,
        "hf_subset": "ind_Latn-fin_Latn",
        "languages": [
          "ind-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.017213,
        "recall": 0.025038,
        "f1": 0.018357,
        "accuracy": 0.025038,
        "main_score": 0.018357,
        "hf_subset": "ind_Latn-fra_Latn",
        "languages": [
          "ind-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.001485,
        "recall": 0.003505,
        "f1": 0.001719,
        "accuracy": 0.003505,
        "main_score": 0.001719,
        "hf_subset": "ind_Latn-heb_Hebr",
        "languages": [
          "ind-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.001724,
        "recall": 0.004507,
        "f1": 0.002058,
        "accuracy": 0.004507,
        "main_score": 0.002058,
        "hf_subset": "ind_Latn-hin_Deva",
        "languages": [
          "ind-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.01791,
        "recall": 0.025538,
        "f1": 0.019183,
        "accuracy": 0.025538,
        "main_score": 0.019183,
        "hf_subset": "ind_Latn-hun_Latn",
        "languages": [
          "ind-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.001209,
        "recall": 0.006009,
        "f1": 0.001594,
        "accuracy": 0.006009,
        "main_score": 0.001594,
        "hf_subset": "ind_Latn-jpn_Jpan",
        "languages": [
          "ind-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001986,
        "recall": 0.00651,
        "f1": 0.002463,
        "accuracy": 0.00651,
        "main_score": 0.002463,
        "hf_subset": "ind_Latn-kor_Hang",
        "languages": [
          "ind-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.012069,
        "recall": 0.016525,
        "f1": 0.012768,
        "accuracy": 0.016525,
        "main_score": 0.012768,
        "hf_subset": "ind_Latn-lit_Latn",
        "languages": [
          "ind-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.002515,
        "recall": 0.004006,
        "f1": 0.002692,
        "accuracy": 0.004006,
        "main_score": 0.002692,
        "hf_subset": "ind_Latn-mal_Mlym",
        "languages": [
          "ind-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.012935,
        "recall": 0.018027,
        "f1": 0.01371,
        "accuracy": 0.018027,
        "main_score": 0.01371,
        "hf_subset": "ind_Latn-mlg_Latn",
        "languages": [
          "ind-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.028093,
        "recall": 0.038558,
        "f1": 0.029883,
        "accuracy": 0.038558,
        "main_score": 0.029883,
        "hf_subset": "ind_Latn-mri_Latn",
        "languages": [
          "ind-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.442056,
        "recall": 0.532799,
        "f1": 0.465094,
        "accuracy": 0.532799,
        "main_score": 0.465094,
        "hf_subset": "ind_Latn-msa_Latn",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.020154,
        "recall": 0.025038,
        "f1": 0.020993,
        "accuracy": 0.025038,
        "main_score": 0.020993,
        "hf_subset": "ind_Latn-nld_Latn",
        "languages": [
          "ind-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.014979,
        "recall": 0.025538,
        "f1": 0.016727,
        "accuracy": 0.025538,
        "main_score": 0.016727,
        "hf_subset": "ind_Latn-pol_Latn",
        "languages": [
          "ind-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.018864,
        "recall": 0.026039,
        "f1": 0.019905,
        "accuracy": 0.026039,
        "main_score": 0.019905,
        "hf_subset": "ind_Latn-por_Latn",
        "languages": [
          "ind-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001404,
        "recall": 0.003505,
        "f1": 0.001607,
        "accuracy": 0.003505,
        "main_score": 0.001607,
        "hf_subset": "ind_Latn-rus_Cyrl",
        "languages": [
          "ind-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.019502,
        "recall": 0.029544,
        "f1": 0.020817,
        "accuracy": 0.029544,
        "main_score": 0.020817,
        "hf_subset": "ind_Latn-smo_Latn",
        "languages": [
          "ind-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.020864,
        "recall": 0.028543,
        "f1": 0.021898,
        "accuracy": 0.028543,
        "main_score": 0.021898,
        "hf_subset": "ind_Latn-spa_Latn",
        "languages": [
          "ind-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.019932,
        "recall": 0.029044,
        "f1": 0.021199,
        "accuracy": 0.029044,
        "main_score": 0.021199,
        "hf_subset": "ind_Latn-swa_Latn",
        "languages": [
          "ind-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.026633,
        "recall": 0.036054,
        "f1": 0.028034,
        "accuracy": 0.036054,
        "main_score": 0.028034,
        "hf_subset": "ind_Latn-swe_Latn",
        "languages": [
          "ind-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.015407,
        "recall": 0.028042,
        "f1": 0.017008,
        "accuracy": 0.028042,
        "main_score": 0.017008,
        "hf_subset": "ind_Latn-tah_Latn",
        "languages": [
          "ind-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.001833,
        "recall": 0.005008,
        "f1": 0.001986,
        "accuracy": 0.005008,
        "main_score": 0.001986,
        "hf_subset": "ind_Latn-tam_Taml",
        "languages": [
          "ind-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009018,
        "recall": 0.017526,
        "f1": 0.010256,
        "accuracy": 0.017526,
        "main_score": 0.010256,
        "hf_subset": "ind_Latn-ton_Latn",
        "languages": [
          "ind-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.015345,
        "recall": 0.020531,
        "f1": 0.016282,
        "accuracy": 0.020531,
        "main_score": 0.016282,
        "hf_subset": "ind_Latn-tur_Latn",
        "languages": [
          "ind-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.013266,
        "recall": 0.02003,
        "f1": 0.014363,
        "accuracy": 0.02003,
        "main_score": 0.014363,
        "hf_subset": "ind_Latn-vie_Latn",
        "languages": [
          "ind-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.016439,
        "recall": 0.02654,
        "f1": 0.017827,
        "accuracy": 0.02654,
        "main_score": 0.017827,
        "hf_subset": "ind_Latn-zho_Hant",
        "languages": [
          "ind-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.014157,
        "recall": 0.021532,
        "f1": 0.01508,
        "accuracy": 0.021532,
        "main_score": 0.01508,
        "hf_subset": "ind_Latn-zul_Latn",
        "languages": [
          "ind-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.017865,
        "recall": 0.023535,
        "f1": 0.018524,
        "accuracy": 0.023535,
        "main_score": 0.018524,
        "hf_subset": "isl_Latn-afr_Latn",
        "languages": [
          "isl-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.034436,
        "recall": 0.045568,
        "f1": 0.036313,
        "accuracy": 0.045568,
        "main_score": 0.036313,
        "hf_subset": "isl_Latn-dan_Latn",
        "languages": [
          "isl-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.02166,
        "recall": 0.028543,
        "f1": 0.022731,
        "accuracy": 0.028543,
        "main_score": 0.022731,
        "hf_subset": "isl_Latn-deu_Latn",
        "languages": [
          "isl-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.022792,
        "recall": 0.035053,
        "f1": 0.024286,
        "accuracy": 0.035053,
        "main_score": 0.024286,
        "hf_subset": "isl_Latn-eng_Latn",
        "languages": [
          "isl-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.111158,
        "recall": 0.145719,
        "f1": 0.116851,
        "accuracy": 0.145719,
        "main_score": 0.116851,
        "hf_subset": "isl_Latn-fao_Latn",
        "languages": [
          "isl-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.01596,
        "recall": 0.020531,
        "f1": 0.01642,
        "accuracy": 0.020531,
        "main_score": 0.01642,
        "hf_subset": "isl_Latn-ltz_Latn",
        "languages": [
          "isl-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.012906,
        "recall": 0.017526,
        "f1": 0.013651,
        "accuracy": 0.017526,
        "main_score": 0.013651,
        "hf_subset": "isl_Latn-nld_Latn",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.040879,
        "recall": 0.050075,
        "f1": 0.04222,
        "accuracy": 0.050075,
        "main_score": 0.04222,
        "hf_subset": "isl_Latn-nno_Latn",
        "languages": [
          "isl-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.032539,
        "recall": 0.044567,
        "f1": 0.034497,
        "accuracy": 0.044567,
        "main_score": 0.034497,
        "hf_subset": "isl_Latn-nob_Latn",
        "languages": [
          "isl-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.0304,
        "recall": 0.042564,
        "f1": 0.032272,
        "accuracy": 0.042564,
        "main_score": 0.032272,
        "hf_subset": "isl_Latn-swe_Latn",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.092557,
        "recall": 0.124186,
        "f1": 0.098403,
        "accuracy": 0.124186,
        "main_score": 0.098403,
        "hf_subset": "ita_Latn-cat_Latn",
        "languages": [
          "ita-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.043028,
        "recall": 0.055083,
        "f1": 0.044689,
        "accuracy": 0.055083,
        "main_score": 0.044689,
        "hf_subset": "ita_Latn-eng_Latn",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.062336,
        "recall": 0.092138,
        "f1": 0.06677,
        "accuracy": 0.092138,
        "main_score": 0.06677,
        "hf_subset": "ita_Latn-fra_Latn",
        "languages": [
          "ita-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.107709,
        "recall": 0.144216,
        "f1": 0.114543,
        "accuracy": 0.144216,
        "main_score": 0.114543,
        "hf_subset": "ita_Latn-glg_Latn",
        "languages": [
          "ita-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.045433,
        "recall": 0.061592,
        "f1": 0.048405,
        "accuracy": 0.061592,
        "main_score": 0.048405,
        "hf_subset": "ita_Latn-mlt_Latn",
        "languages": [
          "ita-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.094707,
        "recall": 0.121683,
        "f1": 0.099446,
        "accuracy": 0.121683,
        "main_score": 0.099446,
        "hf_subset": "ita_Latn-por_Latn",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.06397,
        "recall": 0.082123,
        "f1": 0.066682,
        "accuracy": 0.082123,
        "main_score": 0.066682,
        "hf_subset": "ita_Latn-ron_Latn",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.105469,
        "recall": 0.145719,
        "f1": 0.112889,
        "accuracy": 0.145719,
        "main_score": 0.112889,
        "hf_subset": "ita_Latn-spa_Latn",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 2e-05,
        "recall": 0.001002,
        "f1": 3.9e-05,
        "accuracy": 0.001002,
        "main_score": 3.9e-05,
        "hf_subset": "jpn_Jpan-arb_Arab",
        "languages": [
          "jpn-Jpan",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000508,
        "recall": 0.002504,
        "f1": 0.000516,
        "accuracy": 0.002504,
        "main_score": 0.000516,
        "hf_subset": "jpn_Jpan-ben_Beng",
        "languages": [
          "jpn-Jpan",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001139,
        "recall": 0.002504,
        "f1": 0.001245,
        "accuracy": 0.002504,
        "main_score": 0.001245,
        "hf_subset": "jpn_Jpan-deu_Latn",
        "languages": [
          "jpn-Jpan",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000312,
        "recall": 0.001502,
        "f1": 0.000449,
        "accuracy": 0.001502,
        "main_score": 0.000449,
        "hf_subset": "jpn_Jpan-ell_Grek",
        "languages": [
          "jpn-Jpan",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.00093,
        "recall": 0.002504,
        "f1": 0.001109,
        "accuracy": 0.002504,
        "main_score": 0.001109,
        "hf_subset": "jpn_Jpan-eng_Latn",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000171,
        "recall": 0.001502,
        "f1": 0.000258,
        "accuracy": 0.001502,
        "main_score": 0.000258,
        "hf_subset": "jpn_Jpan-fas_Arab",
        "languages": [
          "jpn-Jpan",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.001283,
        "recall": 0.002003,
        "f1": 0.001394,
        "accuracy": 0.002003,
        "main_score": 0.001394,
        "hf_subset": "jpn_Jpan-fin_Latn",
        "languages": [
          "jpn-Jpan",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.001511,
        "recall": 0.002504,
        "f1": 0.00152,
        "accuracy": 0.002504,
        "main_score": 0.00152,
        "hf_subset": "jpn_Jpan-fra_Latn",
        "languages": [
          "jpn-Jpan",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000168,
        "recall": 0.001002,
        "f1": 0.000252,
        "accuracy": 0.001002,
        "main_score": 0.000252,
        "hf_subset": "jpn_Jpan-heb_Hebr",
        "languages": [
          "jpn-Jpan",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.001273,
        "recall": 0.003505,
        "f1": 0.001595,
        "accuracy": 0.003505,
        "main_score": 0.001595,
        "hf_subset": "jpn_Jpan-hin_Deva",
        "languages": [
          "jpn-Jpan",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.002082,
        "recall": 0.004507,
        "f1": 0.002151,
        "accuracy": 0.004507,
        "main_score": 0.002151,
        "hf_subset": "jpn_Jpan-hun_Latn",
        "languages": [
          "jpn-Jpan",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.00076,
        "recall": 0.002504,
        "f1": 0.000912,
        "accuracy": 0.002504,
        "main_score": 0.000912,
        "hf_subset": "jpn_Jpan-ind_Latn",
        "languages": [
          "jpn-Jpan",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.0008,
        "recall": 0.003005,
        "f1": 0.001014,
        "accuracy": 0.003005,
        "main_score": 0.001014,
        "hf_subset": "jpn_Jpan-kor_Hang",
        "languages": [
          "jpn-Jpan",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.001203,
        "recall": 0.004507,
        "f1": 0.001319,
        "accuracy": 0.004507,
        "main_score": 0.001319,
        "hf_subset": "jpn_Jpan-lit_Latn",
        "languages": [
          "jpn-Jpan",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.002015,
        "recall": 0.003005,
        "f1": 0.002028,
        "accuracy": 0.003005,
        "main_score": 0.002028,
        "hf_subset": "jpn_Jpan-nld_Latn",
        "languages": [
          "jpn-Jpan",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.001504,
        "recall": 0.002504,
        "f1": 0.001506,
        "accuracy": 0.002504,
        "main_score": 0.001506,
        "hf_subset": "jpn_Jpan-pol_Latn",
        "languages": [
          "jpn-Jpan",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001616,
        "recall": 0.003005,
        "f1": 0.001706,
        "accuracy": 0.003005,
        "main_score": 0.001706,
        "hf_subset": "jpn_Jpan-por_Latn",
        "languages": [
          "jpn-Jpan",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001627,
        "recall": 0.004006,
        "f1": 0.001914,
        "accuracy": 0.004006,
        "main_score": 0.001914,
        "hf_subset": "jpn_Jpan-rus_Cyrl",
        "languages": [
          "jpn-Jpan",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.001076,
        "recall": 0.002003,
        "f1": 0.001133,
        "accuracy": 0.002003,
        "main_score": 0.001133,
        "hf_subset": "jpn_Jpan-spa_Latn",
        "languages": [
          "jpn-Jpan",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001502,
        "recall": 0.001502,
        "f1": 0.001502,
        "accuracy": 0.001502,
        "main_score": 0.001502,
        "hf_subset": "jpn_Jpan-swa_Latn",
        "languages": [
          "jpn-Jpan",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002003,
        "f1": 0.001504,
        "accuracy": 0.002003,
        "main_score": 0.001504,
        "hf_subset": "jpn_Jpan-swe_Latn",
        "languages": [
          "jpn-Jpan",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "jpn_Jpan-tam_Taml",
        "languages": [
          "jpn-Jpan",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001179,
        "recall": 0.003005,
        "f1": 0.001308,
        "accuracy": 0.003005,
        "main_score": 0.001308,
        "hf_subset": "jpn_Jpan-tur_Latn",
        "languages": [
          "jpn-Jpan",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000581,
        "recall": 0.002003,
        "f1": 0.000647,
        "accuracy": 0.002003,
        "main_score": 0.000647,
        "hf_subset": "jpn_Jpan-vie_Latn",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.003287,
        "recall": 0.005508,
        "f1": 0.003566,
        "accuracy": 0.005508,
        "main_score": 0.003566,
        "hf_subset": "jpn_Jpan-yue_Hant",
        "languages": [
          "jpn-Jpan",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.00513,
        "recall": 0.008513,
        "f1": 0.005642,
        "accuracy": 0.008513,
        "main_score": 0.005642,
        "hf_subset": "jpn_Jpan-zho_Hans",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.003704,
        "recall": 0.007011,
        "f1": 0.003818,
        "accuracy": 0.007011,
        "main_score": 0.003818,
        "hf_subset": "jpn_Jpan-zho_Hant",
        "languages": [
          "jpn-Jpan",
          "zho-Hant"
        ]
      },
      {
        "precision": 4.3e-05,
        "recall": 0.002003,
        "f1": 8.1e-05,
        "accuracy": 0.002003,
        "main_score": 8.1e-05,
        "hf_subset": "jpn_Jpan-zul_Latn",
        "languages": [
          "jpn-Jpan",
          "zul-Latn"
        ]
      },
      {
        "precision": 4.6e-05,
        "recall": 0.001502,
        "f1": 8.7e-05,
        "accuracy": 0.001502,
        "main_score": 8.7e-05,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.098631,
        "recall": 0.127191,
        "f1": 0.105727,
        "accuracy": 0.127191,
        "main_score": 0.105727,
        "hf_subset": "kan_Knda-div_Thaa",
        "languages": [
          "kan-Knda",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.027312,
        "recall": 0.044567,
        "f1": 0.030255,
        "accuracy": 0.044567,
        "main_score": 0.030255,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004644,
        "recall": 0.012018,
        "f1": 0.00555,
        "accuracy": 0.012018,
        "main_score": 0.00555,
        "hf_subset": "kan_Knda-eus_Latn",
        "languages": [
          "kan-Knda",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.108032,
        "recall": 0.134702,
        "f1": 0.114556,
        "accuracy": 0.134702,
        "main_score": 0.114556,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.002923,
        "recall": 0.007511,
        "f1": 0.003593,
        "accuracy": 0.007511,
        "main_score": 0.003593,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000632,
        "recall": 0.003505,
        "f1": 0.000735,
        "accuracy": 0.003505,
        "main_score": 0.000735,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001395,
        "recall": 0.004006,
        "f1": 0.001671,
        "accuracy": 0.004006,
        "main_score": 0.001671,
        "hf_subset": "kan_Knda-nep_Deva",
        "languages": [
          "kan-Knda",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.085332,
        "recall": 0.115173,
        "f1": 0.091992,
        "accuracy": 0.115173,
        "main_score": 0.091992,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.07318,
        "recall": 0.111668,
        "f1": 0.081422,
        "accuracy": 0.111668,
        "main_score": 0.081422,
        "hf_subset": "kan_Knda-sin_Sinh",
        "languages": [
          "kan-Knda",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.003906,
        "recall": 0.010516,
        "f1": 0.004694,
        "accuracy": 0.010516,
        "main_score": 0.004694,
        "hf_subset": "kan_Knda-snd_Arab",
        "languages": [
          "kan-Knda",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.002528,
        "recall": 0.009514,
        "f1": 0.003005,
        "accuracy": 0.009514,
        "main_score": 0.003005,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.128144,
        "recall": 0.15974,
        "f1": 0.135347,
        "accuracy": 0.15974,
        "main_score": 0.135347,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.00278,
        "recall": 0.00651,
        "f1": 0.003202,
        "accuracy": 0.00651,
        "main_score": 0.003202,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001302,
        "recall": 0.003005,
        "f1": 0.001431,
        "accuracy": 0.003005,
        "main_score": 0.001431,
        "hf_subset": "kat_Geor-ell_Grek",
        "languages": [
          "kat-Geor",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.003548,
        "recall": 0.005008,
        "f1": 0.003587,
        "accuracy": 0.005008,
        "main_score": 0.003587,
        "hf_subset": "kat_Geor-eng_Latn",
        "languages": [
          "kat-Geor",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00148,
        "recall": 0.004006,
        "f1": 0.001701,
        "accuracy": 0.004006,
        "main_score": 0.001701,
        "hf_subset": "kat_Geor-hye_Armn",
        "languages": [
          "kat-Geor",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.001007,
        "recall": 0.002504,
        "f1": 0.001013,
        "accuracy": 0.002504,
        "main_score": 0.001013,
        "hf_subset": "kat_Geor-sqi_Latn",
        "languages": [
          "kat-Geor",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.001884,
        "recall": 0.004507,
        "f1": 0.002094,
        "accuracy": 0.004507,
        "main_score": 0.002094,
        "hf_subset": "kaz_Cyrl-aze_Latn",
        "languages": [
          "kaz-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.027808,
        "recall": 0.052579,
        "f1": 0.03218,
        "accuracy": 0.052579,
        "main_score": 0.03218,
        "hf_subset": "kaz_Cyrl-bak_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.002335,
        "recall": 0.004507,
        "f1": 0.002552,
        "accuracy": 0.004507,
        "main_score": 0.002552,
        "hf_subset": "kaz_Cyrl-eng_Latn",
        "languages": [
          "kaz-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031429,
        "recall": 0.051077,
        "f1": 0.035623,
        "accuracy": 0.051077,
        "main_score": 0.035623,
        "hf_subset": "kaz_Cyrl-kir_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.028708,
        "recall": 0.051077,
        "f1": 0.032753,
        "accuracy": 0.051077,
        "main_score": 0.032753,
        "hf_subset": "kaz_Cyrl-tat_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.00065,
        "recall": 0.002504,
        "f1": 0.000757,
        "accuracy": 0.002504,
        "main_score": 0.000757,
        "hf_subset": "kaz_Cyrl-tuk_Latn",
        "languages": [
          "kaz-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.001025,
        "recall": 0.002504,
        "f1": 0.001047,
        "accuracy": 0.002504,
        "main_score": 0.001047,
        "hf_subset": "kaz_Cyrl-tur_Latn",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.00318,
        "recall": 0.006009,
        "f1": 0.00367,
        "accuracy": 0.006009,
        "main_score": 0.00367,
        "hf_subset": "kaz_Cyrl-uig_Arab",
        "languages": [
          "kaz-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.000104,
        "recall": 0.001502,
        "f1": 0.000183,
        "accuracy": 0.001502,
        "main_score": 0.000183,
        "hf_subset": "kaz_Cyrl-uzb_Latn",
        "languages": [
          "kaz-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.01322,
        "recall": 0.025038,
        "f1": 0.015158,
        "accuracy": 0.025038,
        "main_score": 0.015158,
        "hf_subset": "khm_Khmr-bod_Tibt",
        "languages": [
          "khm-Khmr",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.001064,
        "recall": 0.002504,
        "f1": 0.001339,
        "accuracy": 0.002504,
        "main_score": 0.001339,
        "hf_subset": "khm_Khmr-dzo_Tibt",
        "languages": [
          "khm-Khmr",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.246945,
        "recall": 0.302454,
        "f1": 0.260962,
        "accuracy": 0.302454,
        "main_score": 0.260962,
        "hf_subset": "khm_Khmr-eng_Latn",
        "languages": [
          "khm-Khmr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.370022,
        "recall": 0.408112,
        "f1": 0.380733,
        "accuracy": 0.408112,
        "main_score": 0.380733,
        "hf_subset": "khm_Khmr-lao_Laoo",
        "languages": [
          "khm-Khmr",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.005379,
        "recall": 0.012018,
        "f1": 0.006136,
        "accuracy": 0.012018,
        "main_score": 0.006136,
        "hf_subset": "khm_Khmr-mon_Mong",
        "languages": [
          "khm-Khmr",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.129187,
        "recall": 0.190786,
        "f1": 0.144038,
        "accuracy": 0.190786,
        "main_score": 0.144038,
        "hf_subset": "khm_Khmr-mya_Mymr",
        "languages": [
          "khm-Khmr",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.235348,
        "recall": 0.288433,
        "f1": 0.249081,
        "accuracy": 0.288433,
        "main_score": 0.249081,
        "hf_subset": "khm_Khmr-tha_Thai",
        "languages": [
          "khm-Khmr",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.017218,
        "recall": 0.027041,
        "f1": 0.018568,
        "accuracy": 0.027041,
        "main_score": 0.018568,
        "hf_subset": "kin_Latn-bem_Latn",
        "languages": [
          "kin-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.016545,
        "recall": 0.025038,
        "f1": 0.017315,
        "accuracy": 0.025038,
        "main_score": 0.017315,
        "hf_subset": "kin_Latn-eng_Latn",
        "languages": [
          "kin-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004794,
        "recall": 0.007011,
        "f1": 0.004913,
        "accuracy": 0.007011,
        "main_score": 0.004913,
        "hf_subset": "kin_Latn-ewe_Latn",
        "languages": [
          "kin-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.007103,
        "recall": 0.010516,
        "f1": 0.007393,
        "accuracy": 0.010516,
        "main_score": 0.007393,
        "hf_subset": "kin_Latn-fuc_Latn",
        "languages": [
          "kin-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.00539,
        "recall": 0.008513,
        "f1": 0.005754,
        "accuracy": 0.008513,
        "main_score": 0.005754,
        "hf_subset": "kin_Latn-nde_Latn",
        "languages": [
          "kin-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.005991,
        "recall": 0.011017,
        "f1": 0.006511,
        "accuracy": 0.011017,
        "main_score": 0.006511,
        "hf_subset": "kin_Latn-nya_Latn",
        "languages": [
          "kin-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.006878,
        "recall": 0.010015,
        "f1": 0.007434,
        "accuracy": 0.010015,
        "main_score": 0.007434,
        "hf_subset": "kin_Latn-sna_Latn",
        "languages": [
          "kin-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.008078,
        "recall": 0.011017,
        "f1": 0.008365,
        "accuracy": 0.011017,
        "main_score": 0.008365,
        "hf_subset": "kin_Latn-ven_Latn",
        "languages": [
          "kin-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.000518,
        "recall": 0.002003,
        "f1": 0.000535,
        "accuracy": 0.002003,
        "main_score": 0.000535,
        "hf_subset": "kir_Cyrl-aze_Latn",
        "languages": [
          "kir-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.013467,
        "recall": 0.027041,
        "f1": 0.01537,
        "accuracy": 0.027041,
        "main_score": 0.01537,
        "hf_subset": "kir_Cyrl-bak_Cyrl",
        "languages": [
          "kir-Cyrl",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "kir_Cyrl-eng_Latn",
        "languages": [
          "kir-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01251,
        "recall": 0.027041,
        "f1": 0.014698,
        "accuracy": 0.027041,
        "main_score": 0.014698,
        "hf_subset": "kir_Cyrl-kaz_Cyrl",
        "languages": [
          "kir-Cyrl",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.027101,
        "recall": 0.047071,
        "f1": 0.031246,
        "accuracy": 0.047071,
        "main_score": 0.031246,
        "hf_subset": "kir_Cyrl-tat_Cyrl",
        "languages": [
          "kir-Cyrl",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.001003,
        "recall": 0.002003,
        "f1": 0.001004,
        "accuracy": 0.002003,
        "main_score": 0.001004,
        "hf_subset": "kir_Cyrl-tuk_Latn",
        "languages": [
          "kir-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.001306,
        "recall": 0.003505,
        "f1": 0.001505,
        "accuracy": 0.003505,
        "main_score": 0.001505,
        "hf_subset": "kir_Cyrl-tur_Latn",
        "languages": [
          "kir-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000746,
        "recall": 0.003505,
        "f1": 0.000896,
        "accuracy": 0.003505,
        "main_score": 0.000896,
        "hf_subset": "kir_Cyrl-uig_Arab",
        "languages": [
          "kir-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.000509,
        "recall": 0.002003,
        "f1": 0.000517,
        "accuracy": 0.002003,
        "main_score": 0.000517,
        "hf_subset": "kir_Cyrl-uzb_Latn",
        "languages": [
          "kir-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.00025,
        "recall": 0.000501,
        "f1": 0.000334,
        "accuracy": 0.000501,
        "main_score": 0.000334,
        "hf_subset": "kmr_Latn-arb_Arab",
        "languages": [
          "kmr-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001808,
        "recall": 0.003505,
        "f1": 0.001942,
        "accuracy": 0.003505,
        "main_score": 0.001942,
        "hf_subset": "kmr_Latn-ckb_Arab",
        "languages": [
          "kmr-Latn",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.02757,
        "recall": 0.037056,
        "f1": 0.029008,
        "accuracy": 0.037056,
        "main_score": 0.029008,
        "hf_subset": "kmr_Latn-eng_Latn",
        "languages": [
          "kmr-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0053,
        "recall": 0.008513,
        "f1": 0.005508,
        "accuracy": 0.008513,
        "main_score": 0.005508,
        "hf_subset": "kmr_Latn-fas_Arab",
        "languages": [
          "kmr-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.001955,
        "recall": 0.005508,
        "f1": 0.002392,
        "accuracy": 0.005508,
        "main_score": 0.002392,
        "hf_subset": "kmr_Latn-heb_Hebr",
        "languages": [
          "kmr-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000489,
        "recall": 0.002504,
        "f1": 0.000739,
        "accuracy": 0.002504,
        "main_score": 0.000739,
        "hf_subset": "kmr_Latn-mey_Arab",
        "languages": [
          "kmr-Latn",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.003049,
        "recall": 0.006009,
        "f1": 0.003559,
        "accuracy": 0.006009,
        "main_score": 0.003559,
        "hf_subset": "kmr_Latn-prs_Arab",
        "languages": [
          "kmr-Latn",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000574,
        "recall": 0.002504,
        "f1": 0.000853,
        "accuracy": 0.002504,
        "main_score": 0.000853,
        "hf_subset": "kmr_Latn-pus_Arab",
        "languages": [
          "kmr-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.001042,
        "recall": 0.002003,
        "f1": 0.001079,
        "accuracy": 0.002003,
        "main_score": 0.001079,
        "hf_subset": "kmr_Latn-shi_Arab",
        "languages": [
          "kmr-Latn",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.001415,
        "recall": 0.005508,
        "f1": 0.001688,
        "accuracy": 0.005508,
        "main_score": 0.001688,
        "hf_subset": "kmr_Latn-tgk_Cyrl",
        "languages": [
          "kmr-Latn",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.000501,
        "f1": 9e-06,
        "accuracy": 0.000501,
        "main_score": 9e-06,
        "hf_subset": "kor_Hang-arb_Arab",
        "languages": [
          "kor-Hang",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000505,
        "recall": 0.001502,
        "f1": 0.000508,
        "accuracy": 0.001502,
        "main_score": 0.000508,
        "hf_subset": "kor_Hang-ben_Beng",
        "languages": [
          "kor-Hang",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "kor_Hang-deu_Latn",
        "languages": [
          "kor-Hang",
          "deu-Latn"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.001002,
        "f1": 3.4e-05,
        "accuracy": 0.001002,
        "main_score": 3.4e-05,
        "hf_subset": "kor_Hang-ell_Grek",
        "languages": [
          "kor-Hang",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002003,
        "f1": 0.001503,
        "accuracy": 0.002003,
        "main_score": 0.001503,
        "hf_subset": "kor_Hang-eng_Latn",
        "languages": [
          "kor-Hang",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000351,
        "recall": 0.001502,
        "f1": 0.000502,
        "accuracy": 0.001502,
        "main_score": 0.000502,
        "hf_subset": "kor_Hang-fas_Arab",
        "languages": [
          "kor-Hang",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "kor_Hang-fin_Latn",
        "languages": [
          "kor-Hang",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.00152,
        "recall": 0.003505,
        "f1": 0.001537,
        "accuracy": 0.003505,
        "main_score": 0.001537,
        "hf_subset": "kor_Hang-fra_Latn",
        "languages": [
          "kor-Hang",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000517,
        "recall": 0.001502,
        "f1": 0.000533,
        "accuracy": 0.001502,
        "main_score": 0.000533,
        "hf_subset": "kor_Hang-heb_Hebr",
        "languages": [
          "kor-Hang",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "kor_Hang-hin_Deva",
        "languages": [
          "kor-Hang",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "kor_Hang-hun_Latn",
        "languages": [
          "kor-Hang",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "kor_Hang-ind_Latn",
        "languages": [
          "kor-Hang",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001002,
        "f1": 0.001002,
        "accuracy": 0.001002,
        "main_score": 0.001002,
        "hf_subset": "kor_Hang-jpn_Jpan",
        "languages": [
          "kor-Hang",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "kor_Hang-lit_Latn",
        "languages": [
          "kor-Hang",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.001007,
        "recall": 0.002003,
        "f1": 0.001013,
        "accuracy": 0.002003,
        "main_score": 0.001013,
        "hf_subset": "kor_Hang-nld_Latn",
        "languages": [
          "kor-Hang",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.001008,
        "recall": 0.002003,
        "f1": 0.001014,
        "accuracy": 0.002003,
        "main_score": 0.001014,
        "hf_subset": "kor_Hang-pol_Latn",
        "languages": [
          "kor-Hang",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "kor_Hang-por_Latn",
        "languages": [
          "kor-Hang",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000752,
        "recall": 0.001502,
        "f1": 0.000837,
        "accuracy": 0.001502,
        "main_score": 0.000837,
        "hf_subset": "kor_Hang-rus_Cyrl",
        "languages": [
          "kor-Hang",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.001895,
        "recall": 0.003005,
        "f1": 0.00212,
        "accuracy": 0.003005,
        "main_score": 0.00212,
        "hf_subset": "kor_Hang-spa_Latn",
        "languages": [
          "kor-Hang",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002003,
        "f1": 0.001503,
        "accuracy": 0.002003,
        "main_score": 0.001503,
        "hf_subset": "kor_Hang-swa_Latn",
        "languages": [
          "kor-Hang",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "kor_Hang-swe_Latn",
        "languages": [
          "kor-Hang",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001006,
        "recall": 0.002003,
        "f1": 0.001011,
        "accuracy": 0.002003,
        "main_score": 0.001011,
        "hf_subset": "kor_Hang-tam_Taml",
        "languages": [
          "kor-Hang",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "kor_Hang-tur_Latn",
        "languages": [
          "kor-Hang",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "kor_Hang-vie_Latn",
        "languages": [
          "kor-Hang",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001002,
        "f1": 0.001002,
        "accuracy": 0.001002,
        "main_score": 0.001002,
        "hf_subset": "kor_Hang-yue_Hant",
        "languages": [
          "kor-Hang",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.002005,
        "recall": 0.003005,
        "f1": 0.002006,
        "accuracy": 0.003005,
        "main_score": 0.002006,
        "hf_subset": "kor_Hang-zho_Hans",
        "languages": [
          "kor-Hang",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.002004,
        "recall": 0.002504,
        "f1": 0.002004,
        "accuracy": 0.002504,
        "main_score": 0.002004,
        "hf_subset": "kor_Hang-zho_Hant",
        "languages": [
          "kor-Hang",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "kor_Hang-zul_Latn",
        "languages": [
          "kor-Hang",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.016298,
        "recall": 0.032549,
        "f1": 0.01899,
        "accuracy": 0.032549,
        "main_score": 0.01899,
        "hf_subset": "lao_Laoo-bod_Tibt",
        "languages": [
          "lao-Laoo",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.000861,
        "recall": 0.003505,
        "f1": 0.001266,
        "accuracy": 0.003505,
        "main_score": 0.001266,
        "hf_subset": "lao_Laoo-dzo_Tibt",
        "languages": [
          "lao-Laoo",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.297566,
        "recall": 0.372058,
        "f1": 0.316357,
        "accuracy": 0.372058,
        "main_score": 0.316357,
        "hf_subset": "lao_Laoo-eng_Latn",
        "languages": [
          "lao-Laoo",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.361003,
        "recall": 0.424637,
        "f1": 0.378073,
        "accuracy": 0.424637,
        "main_score": 0.378073,
        "hf_subset": "lao_Laoo-khm_Khmr",
        "languages": [
          "lao-Laoo",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.005746,
        "recall": 0.015023,
        "f1": 0.006981,
        "accuracy": 0.015023,
        "main_score": 0.006981,
        "hf_subset": "lao_Laoo-mon_Mong",
        "languages": [
          "lao-Laoo",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.148268,
        "recall": 0.223335,
        "f1": 0.16626,
        "accuracy": 0.223335,
        "main_score": 0.16626,
        "hf_subset": "lao_Laoo-mya_Mymr",
        "languages": [
          "lao-Laoo",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.289276,
        "recall": 0.360541,
        "f1": 0.308171,
        "accuracy": 0.360541,
        "main_score": 0.308171,
        "hf_subset": "lao_Laoo-tha_Thai",
        "languages": [
          "lao-Laoo",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.02013,
        "recall": 0.028042,
        "f1": 0.020945,
        "accuracy": 0.028042,
        "main_score": 0.020945,
        "hf_subset": "lav_Latn-eng_Latn",
        "languages": [
          "lav-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012932,
        "recall": 0.015523,
        "f1": 0.01319,
        "accuracy": 0.015523,
        "main_score": 0.01319,
        "hf_subset": "lav_Latn-fin_Latn",
        "languages": [
          "lav-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.012162,
        "recall": 0.017526,
        "f1": 0.012982,
        "accuracy": 0.017526,
        "main_score": 0.012982,
        "hf_subset": "lav_Latn-hun_Latn",
        "languages": [
          "lav-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.049711,
        "recall": 0.074612,
        "f1": 0.054394,
        "accuracy": 0.074612,
        "main_score": 0.054394,
        "hf_subset": "lav_Latn-lit_Latn",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.001502,
        "f1": 1.9e-05,
        "accuracy": 0.001502,
        "main_score": 1.9e-05,
        "hf_subset": "lit_Latn-arb_Arab",
        "languages": [
          "lit-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.00066,
        "recall": 0.003005,
        "f1": 0.000767,
        "accuracy": 0.003005,
        "main_score": 0.000767,
        "hf_subset": "lit_Latn-ben_Beng",
        "languages": [
          "lit-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.010265,
        "recall": 0.016525,
        "f1": 0.011047,
        "accuracy": 0.016525,
        "main_score": 0.011047,
        "hf_subset": "lit_Latn-deu_Latn",
        "languages": [
          "lit-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.001408,
        "recall": 0.004006,
        "f1": 0.00162,
        "accuracy": 0.004006,
        "main_score": 0.00162,
        "hf_subset": "lit_Latn-ell_Grek",
        "languages": [
          "lit-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.014677,
        "recall": 0.021032,
        "f1": 0.015775,
        "accuracy": 0.021032,
        "main_score": 0.015775,
        "hf_subset": "lit_Latn-eng_Latn",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001132,
        "recall": 0.004006,
        "f1": 0.001247,
        "accuracy": 0.004006,
        "main_score": 0.001247,
        "hf_subset": "lit_Latn-fas_Arab",
        "languages": [
          "lit-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.008532,
        "recall": 0.011517,
        "f1": 0.00917,
        "accuracy": 0.011517,
        "main_score": 0.00917,
        "hf_subset": "lit_Latn-fin_Latn",
        "languages": [
          "lit-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.007251,
        "recall": 0.010516,
        "f1": 0.007629,
        "accuracy": 0.010516,
        "main_score": 0.007629,
        "hf_subset": "lit_Latn-fra_Latn",
        "languages": [
          "lit-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.00194,
        "recall": 0.006009,
        "f1": 0.00217,
        "accuracy": 0.006009,
        "main_score": 0.00217,
        "hf_subset": "lit_Latn-heb_Hebr",
        "languages": [
          "lit-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000388,
        "recall": 0.002003,
        "f1": 0.000604,
        "accuracy": 0.002003,
        "main_score": 0.000604,
        "hf_subset": "lit_Latn-hin_Deva",
        "languages": [
          "lit-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.013832,
        "recall": 0.021532,
        "f1": 0.014923,
        "accuracy": 0.021532,
        "main_score": 0.014923,
        "hf_subset": "lit_Latn-hun_Latn",
        "languages": [
          "lit-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.009,
        "recall": 0.015023,
        "f1": 0.009922,
        "accuracy": 0.015023,
        "main_score": 0.009922,
        "hf_subset": "lit_Latn-ind_Latn",
        "languages": [
          "lit-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000998,
        "recall": 0.004507,
        "f1": 0.001326,
        "accuracy": 0.004507,
        "main_score": 0.001326,
        "hf_subset": "lit_Latn-jpn_Jpan",
        "languages": [
          "lit-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000355,
        "recall": 0.003505,
        "f1": 0.000533,
        "accuracy": 0.003505,
        "main_score": 0.000533,
        "hf_subset": "lit_Latn-kor_Hang",
        "languages": [
          "lit-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.037993,
        "recall": 0.05308,
        "f1": 0.0407,
        "accuracy": 0.05308,
        "main_score": 0.0407,
        "hf_subset": "lit_Latn-lav_Latn",
        "languages": [
          "lit-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.010119,
        "recall": 0.01352,
        "f1": 0.010376,
        "accuracy": 0.01352,
        "main_score": 0.010376,
        "hf_subset": "lit_Latn-nld_Latn",
        "languages": [
          "lit-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.01269,
        "recall": 0.018528,
        "f1": 0.013255,
        "accuracy": 0.018528,
        "main_score": 0.013255,
        "hf_subset": "lit_Latn-pol_Latn",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.008592,
        "recall": 0.014522,
        "f1": 0.009363,
        "accuracy": 0.014522,
        "main_score": 0.009363,
        "hf_subset": "lit_Latn-por_Latn",
        "languages": [
          "lit-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000883,
        "recall": 0.003505,
        "f1": 0.001114,
        "accuracy": 0.003505,
        "main_score": 0.001114,
        "hf_subset": "lit_Latn-rus_Cyrl",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.01107,
        "recall": 0.017026,
        "f1": 0.011816,
        "accuracy": 0.017026,
        "main_score": 0.011816,
        "hf_subset": "lit_Latn-spa_Latn",
        "languages": [
          "lit-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.006952,
        "recall": 0.011017,
        "f1": 0.00757,
        "accuracy": 0.011017,
        "main_score": 0.00757,
        "hf_subset": "lit_Latn-swa_Latn",
        "languages": [
          "lit-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.01466,
        "recall": 0.022534,
        "f1": 0.015769,
        "accuracy": 0.022534,
        "main_score": 0.015769,
        "hf_subset": "lit_Latn-swe_Latn",
        "languages": [
          "lit-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000674,
        "recall": 0.002504,
        "f1": 0.000763,
        "accuracy": 0.002504,
        "main_score": 0.000763,
        "hf_subset": "lit_Latn-tam_Taml",
        "languages": [
          "lit-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.008038,
        "recall": 0.01352,
        "f1": 0.008885,
        "accuracy": 0.01352,
        "main_score": 0.008885,
        "hf_subset": "lit_Latn-tur_Latn",
        "languages": [
          "lit-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.006231,
        "recall": 0.010015,
        "f1": 0.006805,
        "accuracy": 0.010015,
        "main_score": 0.006805,
        "hf_subset": "lit_Latn-vie_Latn",
        "languages": [
          "lit-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.008929,
        "recall": 0.015523,
        "f1": 0.009701,
        "accuracy": 0.015523,
        "main_score": 0.009701,
        "hf_subset": "lit_Latn-zho_Hant",
        "languages": [
          "lit-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.009191,
        "recall": 0.01352,
        "f1": 0.009755,
        "accuracy": 0.01352,
        "main_score": 0.009755,
        "hf_subset": "lit_Latn-zul_Latn",
        "languages": [
          "lit-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.074467,
        "recall": 0.094141,
        "f1": 0.07772,
        "accuracy": 0.094141,
        "main_score": 0.07772,
        "hf_subset": "ltz_Latn-afr_Latn",
        "languages": [
          "ltz-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.055687,
        "recall": 0.076114,
        "f1": 0.058953,
        "accuracy": 0.076114,
        "main_score": 0.058953,
        "hf_subset": "ltz_Latn-dan_Latn",
        "languages": [
          "ltz-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.183741,
        "recall": 0.230846,
        "f1": 0.193404,
        "accuracy": 0.230846,
        "main_score": 0.193404,
        "hf_subset": "ltz_Latn-deu_Latn",
        "languages": [
          "ltz-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.05466,
        "recall": 0.072609,
        "f1": 0.057587,
        "accuracy": 0.072609,
        "main_score": 0.057587,
        "hf_subset": "ltz_Latn-eng_Latn",
        "languages": [
          "ltz-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.03322,
        "recall": 0.047571,
        "f1": 0.0352,
        "accuracy": 0.047571,
        "main_score": 0.0352,
        "hf_subset": "ltz_Latn-fao_Latn",
        "languages": [
          "ltz-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.021729,
        "recall": 0.029544,
        "f1": 0.022942,
        "accuracy": 0.029544,
        "main_score": 0.022942,
        "hf_subset": "ltz_Latn-isl_Latn",
        "languages": [
          "ltz-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.072546,
        "recall": 0.09364,
        "f1": 0.076321,
        "accuracy": 0.09364,
        "main_score": 0.076321,
        "hf_subset": "ltz_Latn-nld_Latn",
        "languages": [
          "ltz-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.052134,
        "recall": 0.074111,
        "f1": 0.056121,
        "accuracy": 0.074111,
        "main_score": 0.056121,
        "hf_subset": "ltz_Latn-nno_Latn",
        "languages": [
          "ltz-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.057233,
        "recall": 0.075613,
        "f1": 0.060697,
        "accuracy": 0.075613,
        "main_score": 0.060697,
        "hf_subset": "ltz_Latn-nob_Latn",
        "languages": [
          "ltz-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.051409,
        "recall": 0.074111,
        "f1": 0.055229,
        "accuracy": 0.074111,
        "main_score": 0.055229,
        "hf_subset": "ltz_Latn-swe_Latn",
        "languages": [
          "ltz-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.019802,
        "recall": 0.03355,
        "f1": 0.022189,
        "accuracy": 0.03355,
        "main_score": 0.022189,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004071,
        "recall": 0.008513,
        "f1": 0.004525,
        "accuracy": 0.008513,
        "main_score": 0.004525,
        "hf_subset": "mal_Mlym-fij_Latn",
        "languages": [
          "mal-Mlym",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.004895,
        "recall": 0.011017,
        "f1": 0.005775,
        "accuracy": 0.011017,
        "main_score": 0.005775,
        "hf_subset": "mal_Mlym-fil_Latn",
        "languages": [
          "mal-Mlym",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.007329,
        "recall": 0.01352,
        "f1": 0.008338,
        "accuracy": 0.01352,
        "main_score": 0.008338,
        "hf_subset": "mal_Mlym-ind_Latn",
        "languages": [
          "mal-Mlym",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.005712,
        "recall": 0.011017,
        "f1": 0.006284,
        "accuracy": 0.011017,
        "main_score": 0.006284,
        "hf_subset": "mal_Mlym-mlg_Latn",
        "languages": [
          "mal-Mlym",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.003261,
        "recall": 0.007511,
        "f1": 0.003855,
        "accuracy": 0.007511,
        "main_score": 0.003855,
        "hf_subset": "mal_Mlym-mri_Latn",
        "languages": [
          "mal-Mlym",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.005723,
        "recall": 0.01352,
        "f1": 0.007077,
        "accuracy": 0.01352,
        "main_score": 0.007077,
        "hf_subset": "mal_Mlym-msa_Latn",
        "languages": [
          "mal-Mlym",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.003816,
        "recall": 0.007011,
        "f1": 0.004391,
        "accuracy": 0.007011,
        "main_score": 0.004391,
        "hf_subset": "mal_Mlym-smo_Latn",
        "languages": [
          "mal-Mlym",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.002791,
        "recall": 0.005508,
        "f1": 0.002987,
        "accuracy": 0.005508,
        "main_score": 0.002987,
        "hf_subset": "mal_Mlym-tah_Latn",
        "languages": [
          "mal-Mlym",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.003236,
        "recall": 0.007011,
        "f1": 0.003712,
        "accuracy": 0.007011,
        "main_score": 0.003712,
        "hf_subset": "mal_Mlym-ton_Latn",
        "languages": [
          "mal-Mlym",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.000693,
        "recall": 0.002504,
        "f1": 0.000801,
        "accuracy": 0.002504,
        "main_score": 0.000801,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mar_Deva-div_Thaa",
        "languages": [
          "mar-Deva",
          "div-Thaa"
        ]
      },
      {
        "precision": 1.3e-05,
        "recall": 0.002003,
        "f1": 2.6e-05,
        "accuracy": 0.002003,
        "main_score": 2.6e-05,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 4.2e-05,
        "recall": 0.001002,
        "f1": 7.8e-05,
        "accuracy": 0.001002,
        "main_score": 7.8e-05,
        "hf_subset": "mar_Deva-eus_Latn",
        "languages": [
          "mar-Deva",
          "eus-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.01382,
        "recall": 0.02654,
        "f1": 0.015781,
        "accuracy": 0.02654,
        "main_score": 0.015781,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.010026,
        "recall": 0.017526,
        "f1": 0.011008,
        "accuracy": 0.017526,
        "main_score": 0.011008,
        "hf_subset": "mar_Deva-nep_Deva",
        "languages": [
          "mar-Deva",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "mar_Deva-sin_Sinh",
        "languages": [
          "mar-Deva",
          "sin-Sinh"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.001502,
        "f1": 2e-05,
        "accuracy": 0.001502,
        "main_score": 2e-05,
        "hf_subset": "mar_Deva-snd_Arab",
        "languages": [
          "mar-Deva",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.000515,
        "recall": 0.001002,
        "f1": 0.000529,
        "accuracy": 0.001002,
        "main_score": 0.000529,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 2e-06,
        "accuracy": 0.001002,
        "main_score": 2e-06,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 5e-06,
        "accuracy": 0.001002,
        "main_score": 5e-06,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.142103,
        "recall": 0.206309,
        "f1": 0.157693,
        "accuracy": 0.206309,
        "main_score": 0.157693,
        "hf_subset": "mey_Arab-arb_Arab",
        "languages": [
          "mey-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 5.1e-05,
        "recall": 0.001002,
        "f1": 9.2e-05,
        "accuracy": 0.001002,
        "main_score": 9.2e-05,
        "hf_subset": "mey_Arab-ckb_Arab",
        "languages": [
          "mey-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.000505,
        "recall": 0.001502,
        "f1": 0.000509,
        "accuracy": 0.001502,
        "main_score": 0.000509,
        "hf_subset": "mey_Arab-eng_Latn",
        "languages": [
          "mey-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001338,
        "recall": 0.005008,
        "f1": 0.00156,
        "accuracy": 0.005008,
        "main_score": 0.00156,
        "hf_subset": "mey_Arab-fas_Arab",
        "languages": [
          "mey-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "mey_Arab-heb_Hebr",
        "languages": [
          "mey-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000506,
        "recall": 0.001502,
        "f1": 0.000511,
        "accuracy": 0.001502,
        "main_score": 0.000511,
        "hf_subset": "mey_Arab-kmr_Latn",
        "languages": [
          "mey-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000369,
        "recall": 0.004006,
        "f1": 0.000618,
        "accuracy": 0.004006,
        "main_score": 0.000618,
        "hf_subset": "mey_Arab-prs_Arab",
        "languages": [
          "mey-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.001271,
        "recall": 0.002504,
        "f1": 0.001373,
        "accuracy": 0.002504,
        "main_score": 0.001373,
        "hf_subset": "mey_Arab-pus_Arab",
        "languages": [
          "mey-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.019221,
        "recall": 0.037056,
        "f1": 0.022245,
        "accuracy": 0.037056,
        "main_score": 0.022245,
        "hf_subset": "mey_Arab-shi_Arab",
        "languages": [
          "mey-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.001086,
        "recall": 0.002504,
        "f1": 0.001161,
        "accuracy": 0.002504,
        "main_score": 0.001161,
        "hf_subset": "mey_Arab-tgk_Cyrl",
        "languages": [
          "mey-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.003626,
        "recall": 0.008012,
        "f1": 0.004211,
        "accuracy": 0.008012,
        "main_score": 0.004211,
        "hf_subset": "mkd_Cyrl-bel_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.001296,
        "recall": 0.003005,
        "f1": 0.001417,
        "accuracy": 0.003005,
        "main_score": 0.001417,
        "hf_subset": "mkd_Cyrl-bos_Latn",
        "languages": [
          "mkd-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.076804,
        "recall": 0.118177,
        "f1": 0.085397,
        "accuracy": 0.118177,
        "main_score": 0.085397,
        "hf_subset": "mkd_Cyrl-bul_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.001217,
        "recall": 0.003005,
        "f1": 0.001344,
        "accuracy": 0.003005,
        "main_score": 0.001344,
        "hf_subset": "mkd_Cyrl-ces_Latn",
        "languages": [
          "mkd-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.001512,
        "recall": 0.003005,
        "f1": 0.001521,
        "accuracy": 0.003005,
        "main_score": 0.001521,
        "hf_subset": "mkd_Cyrl-eng_Latn",
        "languages": [
          "mkd-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002546,
        "recall": 0.004006,
        "f1": 0.002585,
        "accuracy": 0.004006,
        "main_score": 0.002585,
        "hf_subset": "mkd_Cyrl-hrv_Latn",
        "languages": [
          "mkd-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.001003,
        "recall": 0.002003,
        "f1": 0.001005,
        "accuracy": 0.002003,
        "main_score": 0.001005,
        "hf_subset": "mkd_Cyrl-pol_Latn",
        "languages": [
          "mkd-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.017407,
        "recall": 0.032048,
        "f1": 0.019585,
        "accuracy": 0.032048,
        "main_score": 0.019585,
        "hf_subset": "mkd_Cyrl-rus_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.001522,
        "recall": 0.002504,
        "f1": 0.001539,
        "accuracy": 0.002504,
        "main_score": 0.001539,
        "hf_subset": "mkd_Cyrl-slk_Latn",
        "languages": [
          "mkd-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.000547,
        "recall": 0.001502,
        "f1": 0.000585,
        "accuracy": 0.001502,
        "main_score": 0.000585,
        "hf_subset": "mkd_Cyrl-slv_Latn",
        "languages": [
          "mkd-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.048589,
        "recall": 0.080621,
        "f1": 0.054675,
        "accuracy": 0.080621,
        "main_score": 0.054675,
        "hf_subset": "mkd_Cyrl-srp_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.00165,
        "recall": 0.003005,
        "f1": 0.001747,
        "accuracy": 0.003005,
        "main_score": 0.001747,
        "hf_subset": "mkd_Cyrl-srp_Latn",
        "languages": [
          "mkd-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.003927,
        "recall": 0.008012,
        "f1": 0.004196,
        "accuracy": 0.008012,
        "main_score": 0.004196,
        "hf_subset": "mkd_Cyrl-ukr_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.014093,
        "recall": 0.021032,
        "f1": 0.014832,
        "accuracy": 0.021032,
        "main_score": 0.014832,
        "hf_subset": "mlg_Latn-eng_Latn",
        "languages": [
          "mlg-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009093,
        "recall": 0.015523,
        "f1": 0.009841,
        "accuracy": 0.015523,
        "main_score": 0.009841,
        "hf_subset": "mlg_Latn-fij_Latn",
        "languages": [
          "mlg-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.009397,
        "recall": 0.014021,
        "f1": 0.010026,
        "accuracy": 0.014021,
        "main_score": 0.010026,
        "hf_subset": "mlg_Latn-fil_Latn",
        "languages": [
          "mlg-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.012241,
        "recall": 0.017526,
        "f1": 0.013025,
        "accuracy": 0.017526,
        "main_score": 0.013025,
        "hf_subset": "mlg_Latn-ind_Latn",
        "languages": [
          "mlg-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001003,
        "recall": 0.002003,
        "f1": 0.001004,
        "accuracy": 0.002003,
        "main_score": 0.001004,
        "hf_subset": "mlg_Latn-mal_Mlym",
        "languages": [
          "mlg-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.012895,
        "recall": 0.019029,
        "f1": 0.013454,
        "accuracy": 0.019029,
        "main_score": 0.013454,
        "hf_subset": "mlg_Latn-mri_Latn",
        "languages": [
          "mlg-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.013057,
        "recall": 0.019529,
        "f1": 0.014124,
        "accuracy": 0.019529,
        "main_score": 0.014124,
        "hf_subset": "mlg_Latn-msa_Latn",
        "languages": [
          "mlg-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.012317,
        "recall": 0.02003,
        "f1": 0.01322,
        "accuracy": 0.02003,
        "main_score": 0.01322,
        "hf_subset": "mlg_Latn-smo_Latn",
        "languages": [
          "mlg-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.006851,
        "recall": 0.012018,
        "f1": 0.007327,
        "accuracy": 0.012018,
        "main_score": 0.007327,
        "hf_subset": "mlg_Latn-tah_Latn",
        "languages": [
          "mlg-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.007707,
        "recall": 0.014021,
        "f1": 0.008461,
        "accuracy": 0.014021,
        "main_score": 0.008461,
        "hf_subset": "mlg_Latn-ton_Latn",
        "languages": [
          "mlg-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.023107,
        "recall": 0.035053,
        "f1": 0.024794,
        "accuracy": 0.035053,
        "main_score": 0.024794,
        "hf_subset": "mlt_Latn-cat_Latn",
        "languages": [
          "mlt-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.033364,
        "recall": 0.045568,
        "f1": 0.035392,
        "accuracy": 0.045568,
        "main_score": 0.035392,
        "hf_subset": "mlt_Latn-eng_Latn",
        "languages": [
          "mlt-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021767,
        "recall": 0.028042,
        "f1": 0.022564,
        "accuracy": 0.028042,
        "main_score": 0.022564,
        "hf_subset": "mlt_Latn-fra_Latn",
        "languages": [
          "mlt-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.02383,
        "recall": 0.037556,
        "f1": 0.025832,
        "accuracy": 0.037556,
        "main_score": 0.025832,
        "hf_subset": "mlt_Latn-glg_Latn",
        "languages": [
          "mlt-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.047199,
        "recall": 0.067101,
        "f1": 0.050682,
        "accuracy": 0.067101,
        "main_score": 0.050682,
        "hf_subset": "mlt_Latn-ita_Latn",
        "languages": [
          "mlt-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.030347,
        "recall": 0.045068,
        "f1": 0.03267,
        "accuracy": 0.045068,
        "main_score": 0.03267,
        "hf_subset": "mlt_Latn-por_Latn",
        "languages": [
          "mlt-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.027572,
        "recall": 0.037056,
        "f1": 0.028756,
        "accuracy": 0.037056,
        "main_score": 0.028756,
        "hf_subset": "mlt_Latn-ron_Latn",
        "languages": [
          "mlt-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.024201,
        "recall": 0.037056,
        "f1": 0.025741,
        "accuracy": 0.037056,
        "main_score": 0.025741,
        "hf_subset": "mlt_Latn-spa_Latn",
        "languages": [
          "mlt-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "mon_Mong-bod_Tibt",
        "languages": [
          "mon-Mong",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mon_Mong-dzo_Tibt",
        "languages": [
          "mon-Mong",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mon_Mong-eng_Latn",
        "languages": [
          "mon-Mong",
          "eng-Latn"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 6e-06,
        "accuracy": 0.001002,
        "main_score": 6e-06,
        "hf_subset": "mon_Mong-khm_Khmr",
        "languages": [
          "mon-Mong",
          "khm-Khmr"
        ]
      },
      {
        "precision": 1.9e-05,
        "recall": 0.001502,
        "f1": 3.7e-05,
        "accuracy": 0.001502,
        "main_score": 3.7e-05,
        "hf_subset": "mon_Mong-lao_Laoo",
        "languages": [
          "mon-Mong",
          "lao-Laoo"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mon_Mong-mya_Mymr",
        "languages": [
          "mon-Mong",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.000259,
        "recall": 0.001502,
        "f1": 0.000352,
        "accuracy": 0.001502,
        "main_score": 0.000352,
        "hf_subset": "mon_Mong-tha_Thai",
        "languages": [
          "mon-Mong",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.021167,
        "recall": 0.031047,
        "f1": 0.02203,
        "accuracy": 0.031047,
        "main_score": 0.02203,
        "hf_subset": "mri_Latn-eng_Latn",
        "languages": [
          "mri-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009752,
        "recall": 0.012519,
        "f1": 0.010156,
        "accuracy": 0.012519,
        "main_score": 0.010156,
        "hf_subset": "mri_Latn-fij_Latn",
        "languages": [
          "mri-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.010172,
        "recall": 0.01302,
        "f1": 0.010456,
        "accuracy": 0.01302,
        "main_score": 0.010456,
        "hf_subset": "mri_Latn-fil_Latn",
        "languages": [
          "mri-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.008705,
        "recall": 0.011517,
        "f1": 0.008979,
        "accuracy": 0.011517,
        "main_score": 0.008979,
        "hf_subset": "mri_Latn-ind_Latn",
        "languages": [
          "mri-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001007,
        "recall": 0.002003,
        "f1": 0.001013,
        "accuracy": 0.002003,
        "main_score": 0.001013,
        "hf_subset": "mri_Latn-mal_Mlym",
        "languages": [
          "mri-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.006317,
        "recall": 0.009514,
        "f1": 0.006749,
        "accuracy": 0.009514,
        "main_score": 0.006749,
        "hf_subset": "mri_Latn-mlg_Latn",
        "languages": [
          "mri-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.008501,
        "recall": 0.012519,
        "f1": 0.008772,
        "accuracy": 0.012519,
        "main_score": 0.008772,
        "hf_subset": "mri_Latn-msa_Latn",
        "languages": [
          "mri-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.013131,
        "recall": 0.017026,
        "f1": 0.013631,
        "accuracy": 0.017026,
        "main_score": 0.013631,
        "hf_subset": "mri_Latn-smo_Latn",
        "languages": [
          "mri-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.021315,
        "recall": 0.032549,
        "f1": 0.023069,
        "accuracy": 0.032549,
        "main_score": 0.023069,
        "hf_subset": "mri_Latn-tah_Latn",
        "languages": [
          "mri-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.012215,
        "recall": 0.020531,
        "f1": 0.013275,
        "accuracy": 0.020531,
        "main_score": 0.013275,
        "hf_subset": "mri_Latn-ton_Latn",
        "languages": [
          "mri-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.02643,
        "recall": 0.037056,
        "f1": 0.027914,
        "accuracy": 0.037056,
        "main_score": 0.027914,
        "hf_subset": "msa_Latn-eng_Latn",
        "languages": [
          "msa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012643,
        "recall": 0.019529,
        "f1": 0.013602,
        "accuracy": 0.019529,
        "main_score": 0.013602,
        "hf_subset": "msa_Latn-fij_Latn",
        "languages": [
          "msa-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.01972,
        "recall": 0.025538,
        "f1": 0.020886,
        "accuracy": 0.025538,
        "main_score": 0.020886,
        "hf_subset": "msa_Latn-fil_Latn",
        "languages": [
          "msa-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.458965,
        "recall": 0.548322,
        "f1": 0.481949,
        "accuracy": 0.548322,
        "main_score": 0.481949,
        "hf_subset": "msa_Latn-ind_Latn",
        "languages": [
          "msa-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.003294,
        "recall": 0.005008,
        "f1": 0.003413,
        "accuracy": 0.005008,
        "main_score": 0.003413,
        "hf_subset": "msa_Latn-mal_Mlym",
        "languages": [
          "msa-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.013122,
        "recall": 0.020531,
        "f1": 0.014219,
        "accuracy": 0.020531,
        "main_score": 0.014219,
        "hf_subset": "msa_Latn-mlg_Latn",
        "languages": [
          "msa-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.024711,
        "recall": 0.038558,
        "f1": 0.027226,
        "accuracy": 0.038558,
        "main_score": 0.027226,
        "hf_subset": "msa_Latn-mri_Latn",
        "languages": [
          "msa-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.018259,
        "recall": 0.028543,
        "f1": 0.019848,
        "accuracy": 0.028543,
        "main_score": 0.019848,
        "hf_subset": "msa_Latn-smo_Latn",
        "languages": [
          "msa-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.01568,
        "recall": 0.027041,
        "f1": 0.017263,
        "accuracy": 0.027041,
        "main_score": 0.017263,
        "hf_subset": "msa_Latn-tah_Latn",
        "languages": [
          "msa-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.010056,
        "recall": 0.017026,
        "f1": 0.01081,
        "accuracy": 0.017026,
        "main_score": 0.01081,
        "hf_subset": "msa_Latn-ton_Latn",
        "languages": [
          "msa-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.005201,
        "recall": 0.011017,
        "f1": 0.006341,
        "accuracy": 0.011017,
        "main_score": 0.006341,
        "hf_subset": "mya_Mymr-bod_Tibt",
        "languages": [
          "mya-Mymr",
          "bod-Tibt"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 5e-06,
        "accuracy": 0.001002,
        "main_score": 5e-06,
        "hf_subset": "mya_Mymr-dzo_Tibt",
        "languages": [
          "mya-Mymr",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.128973,
        "recall": 0.161242,
        "f1": 0.137254,
        "accuracy": 0.161242,
        "main_score": 0.137254,
        "hf_subset": "mya_Mymr-eng_Latn",
        "languages": [
          "mya-Mymr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.150861,
        "recall": 0.178267,
        "f1": 0.158127,
        "accuracy": 0.178267,
        "main_score": 0.158127,
        "hf_subset": "mya_Mymr-khm_Khmr",
        "languages": [
          "mya-Mymr",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.184735,
        "recall": 0.207812,
        "f1": 0.191068,
        "accuracy": 0.207812,
        "main_score": 0.191068,
        "hf_subset": "mya_Mymr-lao_Laoo",
        "languages": [
          "mya-Mymr",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.002853,
        "recall": 0.007011,
        "f1": 0.003461,
        "accuracy": 0.007011,
        "main_score": 0.003461,
        "hf_subset": "mya_Mymr-mon_Mong",
        "languages": [
          "mya-Mymr",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.145302,
        "recall": 0.175764,
        "f1": 0.153284,
        "accuracy": 0.175764,
        "main_score": 0.153284,
        "hf_subset": "mya_Mymr-tha_Thai",
        "languages": [
          "mya-Mymr",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.005514,
        "recall": 0.008012,
        "f1": 0.005759,
        "accuracy": 0.008012,
        "main_score": 0.005759,
        "hf_subset": "nde_Latn-bem_Latn",
        "languages": [
          "nde-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.009481,
        "recall": 0.016024,
        "f1": 0.009979,
        "accuracy": 0.016024,
        "main_score": 0.009979,
        "hf_subset": "nde_Latn-eng_Latn",
        "languages": [
          "nde-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006226,
        "recall": 0.008513,
        "f1": 0.006541,
        "accuracy": 0.008513,
        "main_score": 0.006541,
        "hf_subset": "nde_Latn-ewe_Latn",
        "languages": [
          "nde-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.004302,
        "recall": 0.006009,
        "f1": 0.004426,
        "accuracy": 0.006009,
        "main_score": 0.004426,
        "hf_subset": "nde_Latn-fuc_Latn",
        "languages": [
          "nde-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.005376,
        "recall": 0.007011,
        "f1": 0.005608,
        "accuracy": 0.007011,
        "main_score": 0.005608,
        "hf_subset": "nde_Latn-kin_Latn",
        "languages": [
          "nde-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.004771,
        "recall": 0.007511,
        "f1": 0.005143,
        "accuracy": 0.007511,
        "main_score": 0.005143,
        "hf_subset": "nde_Latn-nya_Latn",
        "languages": [
          "nde-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.011184,
        "recall": 0.017026,
        "f1": 0.011984,
        "accuracy": 0.017026,
        "main_score": 0.011984,
        "hf_subset": "nde_Latn-sna_Latn",
        "languages": [
          "nde-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.006093,
        "recall": 0.011017,
        "f1": 0.006665,
        "accuracy": 0.011017,
        "main_score": 0.006665,
        "hf_subset": "nde_Latn-ven_Latn",
        "languages": [
          "nde-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.000864,
        "recall": 0.002504,
        "f1": 0.001025,
        "accuracy": 0.002504,
        "main_score": 0.001025,
        "hf_subset": "nep_Deva-ben_Beng",
        "languages": [
          "nep-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.001002,
        "f1": 1.8e-05,
        "accuracy": 0.001002,
        "main_score": 1.8e-05,
        "hf_subset": "nep_Deva-div_Thaa",
        "languages": [
          "nep-Deva",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.001632,
        "recall": 0.005508,
        "f1": 0.001739,
        "accuracy": 0.005508,
        "main_score": 0.001739,
        "hf_subset": "nep_Deva-eng_Latn",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001009,
        "recall": 0.002003,
        "f1": 0.001017,
        "accuracy": 0.002003,
        "main_score": 0.001017,
        "hf_subset": "nep_Deva-eus_Latn",
        "languages": [
          "nep-Deva",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "nep_Deva-guj_Gujr",
        "languages": [
          "nep-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.029748,
        "recall": 0.048573,
        "f1": 0.03352,
        "accuracy": 0.048573,
        "main_score": 0.03352,
        "hf_subset": "nep_Deva-hin_Deva",
        "languages": [
          "nep-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "nep_Deva-kan_Knda",
        "languages": [
          "nep-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.013362,
        "recall": 0.024036,
        "f1": 0.015276,
        "accuracy": 0.024036,
        "main_score": 0.015276,
        "hf_subset": "nep_Deva-mar_Deva",
        "languages": [
          "nep-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "nep_Deva-pan_Guru",
        "languages": [
          "nep-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 3e-06,
        "accuracy": 0.000501,
        "main_score": 3e-06,
        "hf_subset": "nep_Deva-sin_Sinh",
        "languages": [
          "nep-Deva",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.001055,
        "recall": 0.003005,
        "f1": 0.001103,
        "accuracy": 0.003005,
        "main_score": 0.001103,
        "hf_subset": "nep_Deva-snd_Arab",
        "languages": [
          "nep-Deva",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.001073,
        "recall": 0.001502,
        "f1": 0.001127,
        "accuracy": 0.001502,
        "main_score": 0.001127,
        "hf_subset": "nep_Deva-tam_Taml",
        "languages": [
          "nep-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "nep_Deva-tel_Telu",
        "languages": [
          "nep-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 6.1e-05,
        "recall": 0.001502,
        "f1": 0.000111,
        "accuracy": 0.001502,
        "main_score": 0.000111,
        "hf_subset": "nep_Deva-urd_Arab",
        "languages": [
          "nep-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.250477,
        "recall": 0.312469,
        "f1": 0.264082,
        "accuracy": 0.312469,
        "main_score": 0.264082,
        "hf_subset": "nld_Latn-afr_Latn",
        "languages": [
          "nld-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.000931,
        "recall": 0.002504,
        "f1": 0.001111,
        "accuracy": 0.002504,
        "main_score": 0.001111,
        "hf_subset": "nld_Latn-arb_Arab",
        "languages": [
          "nld-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001038,
        "recall": 0.002504,
        "f1": 0.001236,
        "accuracy": 0.002504,
        "main_score": 0.001236,
        "hf_subset": "nld_Latn-ben_Beng",
        "languages": [
          "nld-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.046514,
        "recall": 0.057586,
        "f1": 0.048676,
        "accuracy": 0.057586,
        "main_score": 0.048676,
        "hf_subset": "nld_Latn-dan_Latn",
        "languages": [
          "nld-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.07547,
        "recall": 0.101152,
        "f1": 0.079756,
        "accuracy": 0.101152,
        "main_score": 0.079756,
        "hf_subset": "nld_Latn-deu_Latn",
        "languages": [
          "nld-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.001176,
        "recall": 0.003505,
        "f1": 0.001296,
        "accuracy": 0.003505,
        "main_score": 0.001296,
        "hf_subset": "nld_Latn-ell_Grek",
        "languages": [
          "nld-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.057302,
        "recall": 0.072108,
        "f1": 0.060115,
        "accuracy": 0.072108,
        "main_score": 0.060115,
        "hf_subset": "nld_Latn-eng_Latn",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021979,
        "recall": 0.030546,
        "f1": 0.023324,
        "accuracy": 0.030546,
        "main_score": 0.023324,
        "hf_subset": "nld_Latn-fao_Latn",
        "languages": [
          "nld-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.001931,
        "recall": 0.004507,
        "f1": 0.002135,
        "accuracy": 0.004507,
        "main_score": 0.002135,
        "hf_subset": "nld_Latn-fas_Arab",
        "languages": [
          "nld-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.013753,
        "recall": 0.019529,
        "f1": 0.014519,
        "accuracy": 0.019529,
        "main_score": 0.014519,
        "hf_subset": "nld_Latn-fin_Latn",
        "languages": [
          "nld-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.035921,
        "recall": 0.051077,
        "f1": 0.038314,
        "accuracy": 0.051077,
        "main_score": 0.038314,
        "hf_subset": "nld_Latn-fra_Latn",
        "languages": [
          "nld-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.002294,
        "recall": 0.005008,
        "f1": 0.002717,
        "accuracy": 0.005008,
        "main_score": 0.002717,
        "hf_subset": "nld_Latn-heb_Hebr",
        "languages": [
          "nld-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000506,
        "recall": 0.002003,
        "f1": 0.000678,
        "accuracy": 0.002003,
        "main_score": 0.000678,
        "hf_subset": "nld_Latn-hin_Deva",
        "languages": [
          "nld-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015317,
        "recall": 0.021532,
        "f1": 0.016011,
        "accuracy": 0.021532,
        "main_score": 0.016011,
        "hf_subset": "nld_Latn-hun_Latn",
        "languages": [
          "nld-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.019443,
        "recall": 0.027041,
        "f1": 0.02097,
        "accuracy": 0.027041,
        "main_score": 0.02097,
        "hf_subset": "nld_Latn-ind_Latn",
        "languages": [
          "nld-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.018929,
        "recall": 0.028042,
        "f1": 0.02022,
        "accuracy": 0.028042,
        "main_score": 0.02022,
        "hf_subset": "nld_Latn-isl_Latn",
        "languages": [
          "nld-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.000838,
        "recall": 0.003505,
        "f1": 0.001071,
        "accuracy": 0.003505,
        "main_score": 0.001071,
        "hf_subset": "nld_Latn-jpn_Jpan",
        "languages": [
          "nld-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000972,
        "recall": 0.004006,
        "f1": 0.001221,
        "accuracy": 0.004006,
        "main_score": 0.001221,
        "hf_subset": "nld_Latn-kor_Hang",
        "languages": [
          "nld-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.009666,
        "recall": 0.015523,
        "f1": 0.010387,
        "accuracy": 0.015523,
        "main_score": 0.010387,
        "hf_subset": "nld_Latn-lit_Latn",
        "languages": [
          "nld-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.068328,
        "recall": 0.09364,
        "f1": 0.073074,
        "accuracy": 0.09364,
        "main_score": 0.073074,
        "hf_subset": "nld_Latn-ltz_Latn",
        "languages": [
          "nld-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.033318,
        "recall": 0.046069,
        "f1": 0.035214,
        "accuracy": 0.046069,
        "main_score": 0.035214,
        "hf_subset": "nld_Latn-nno_Latn",
        "languages": [
          "nld-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.041373,
        "recall": 0.052579,
        "f1": 0.043146,
        "accuracy": 0.052579,
        "main_score": 0.043146,
        "hf_subset": "nld_Latn-nob_Latn",
        "languages": [
          "nld-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.016337,
        "recall": 0.025038,
        "f1": 0.017745,
        "accuracy": 0.025038,
        "main_score": 0.017745,
        "hf_subset": "nld_Latn-pol_Latn",
        "languages": [
          "nld-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.031041,
        "recall": 0.043565,
        "f1": 0.033035,
        "accuracy": 0.043565,
        "main_score": 0.033035,
        "hf_subset": "nld_Latn-por_Latn",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001518,
        "recall": 0.004507,
        "f1": 0.001794,
        "accuracy": 0.004507,
        "main_score": 0.001794,
        "hf_subset": "nld_Latn-rus_Cyrl",
        "languages": [
          "nld-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.036207,
        "recall": 0.051577,
        "f1": 0.038431,
        "accuracy": 0.051577,
        "main_score": 0.038431,
        "hf_subset": "nld_Latn-spa_Latn",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.011601,
        "recall": 0.015523,
        "f1": 0.012393,
        "accuracy": 0.015523,
        "main_score": 0.012393,
        "hf_subset": "nld_Latn-swa_Latn",
        "languages": [
          "nld-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.039169,
        "recall": 0.051077,
        "f1": 0.041065,
        "accuracy": 0.051077,
        "main_score": 0.041065,
        "hf_subset": "nld_Latn-swe_Latn",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001023,
        "recall": 0.002504,
        "f1": 0.001042,
        "accuracy": 0.002504,
        "main_score": 0.001042,
        "hf_subset": "nld_Latn-tam_Taml",
        "languages": [
          "nld-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.013757,
        "recall": 0.02003,
        "f1": 0.014914,
        "accuracy": 0.02003,
        "main_score": 0.014914,
        "hf_subset": "nld_Latn-tur_Latn",
        "languages": [
          "nld-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.013169,
        "recall": 0.021032,
        "f1": 0.014686,
        "accuracy": 0.021032,
        "main_score": 0.014686,
        "hf_subset": "nld_Latn-vie_Latn",
        "languages": [
          "nld-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.018651,
        "recall": 0.029544,
        "f1": 0.020474,
        "accuracy": 0.029544,
        "main_score": 0.020474,
        "hf_subset": "nld_Latn-zho_Hant",
        "languages": [
          "nld-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.018134,
        "recall": 0.024537,
        "f1": 0.019254,
        "accuracy": 0.024537,
        "main_score": 0.019254,
        "hf_subset": "nld_Latn-zul_Latn",
        "languages": [
          "nld-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.076204,
        "recall": 0.103155,
        "f1": 0.081627,
        "accuracy": 0.103155,
        "main_score": 0.081627,
        "hf_subset": "nno_Latn-afr_Latn",
        "languages": [
          "nno-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.427923,
        "recall": 0.516775,
        "f1": 0.450567,
        "accuracy": 0.516775,
        "main_score": 0.450567,
        "hf_subset": "nno_Latn-dan_Latn",
        "languages": [
          "nno-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.069664,
        "recall": 0.100651,
        "f1": 0.075822,
        "accuracy": 0.100651,
        "main_score": 0.075822,
        "hf_subset": "nno_Latn-deu_Latn",
        "languages": [
          "nno-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.076181,
        "recall": 0.10015,
        "f1": 0.079771,
        "accuracy": 0.10015,
        "main_score": 0.079771,
        "hf_subset": "nno_Latn-eng_Latn",
        "languages": [
          "nno-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.104582,
        "recall": 0.137707,
        "f1": 0.110919,
        "accuracy": 0.137707,
        "main_score": 0.110919,
        "hf_subset": "nno_Latn-fao_Latn",
        "languages": [
          "nno-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.051746,
        "recall": 0.075113,
        "f1": 0.05599,
        "accuracy": 0.075113,
        "main_score": 0.05599,
        "hf_subset": "nno_Latn-isl_Latn",
        "languages": [
          "nno-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.0674,
        "recall": 0.099149,
        "f1": 0.073263,
        "accuracy": 0.099149,
        "main_score": 0.073263,
        "hf_subset": "nno_Latn-ltz_Latn",
        "languages": [
          "nno-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.071643,
        "recall": 0.099149,
        "f1": 0.077015,
        "accuracy": 0.099149,
        "main_score": 0.077015,
        "hf_subset": "nno_Latn-nld_Latn",
        "languages": [
          "nno-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.648381,
        "recall": 0.730095,
        "f1": 0.671659,
        "accuracy": 0.730095,
        "main_score": 0.671659,
        "hf_subset": "nno_Latn-nob_Latn",
        "languages": [
          "nno-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.328609,
        "recall": 0.397596,
        "f1": 0.344729,
        "accuracy": 0.397596,
        "main_score": 0.344729,
        "hf_subset": "nno_Latn-swe_Latn",
        "languages": [
          "nno-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.071787,
        "recall": 0.092639,
        "f1": 0.075688,
        "accuracy": 0.092639,
        "main_score": 0.075688,
        "hf_subset": "nob_Latn-afr_Latn",
        "languages": [
          "nob-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.609368,
        "recall": 0.684026,
        "f1": 0.62928,
        "accuracy": 0.684026,
        "main_score": 0.62928,
        "hf_subset": "nob_Latn-dan_Latn",
        "languages": [
          "nob-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.067997,
        "recall": 0.09314,
        "f1": 0.072508,
        "accuracy": 0.09314,
        "main_score": 0.072508,
        "hf_subset": "nob_Latn-deu_Latn",
        "languages": [
          "nob-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.072179,
        "recall": 0.095143,
        "f1": 0.075908,
        "accuracy": 0.095143,
        "main_score": 0.075908,
        "hf_subset": "nob_Latn-eng_Latn",
        "languages": [
          "nob-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.07863,
        "recall": 0.102654,
        "f1": 0.083262,
        "accuracy": 0.102654,
        "main_score": 0.083262,
        "hf_subset": "nob_Latn-fao_Latn",
        "languages": [
          "nob-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.047376,
        "recall": 0.065598,
        "f1": 0.050467,
        "accuracy": 0.065598,
        "main_score": 0.050467,
        "hf_subset": "nob_Latn-isl_Latn",
        "languages": [
          "nob-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.068005,
        "recall": 0.084126,
        "f1": 0.07085,
        "accuracy": 0.084126,
        "main_score": 0.07085,
        "hf_subset": "nob_Latn-ltz_Latn",
        "languages": [
          "nob-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.066854,
        "recall": 0.085128,
        "f1": 0.070639,
        "accuracy": 0.085128,
        "main_score": 0.070639,
        "hf_subset": "nob_Latn-nld_Latn",
        "languages": [
          "nob-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.579119,
        "recall": 0.655483,
        "f1": 0.598619,
        "accuracy": 0.655483,
        "main_score": 0.598619,
        "hf_subset": "nob_Latn-nno_Latn",
        "languages": [
          "nob-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.294949,
        "recall": 0.356535,
        "f1": 0.307738,
        "accuracy": 0.356535,
        "main_score": 0.307738,
        "hf_subset": "nob_Latn-swe_Latn",
        "languages": [
          "nob-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.005969,
        "recall": 0.011017,
        "f1": 0.006452,
        "accuracy": 0.011017,
        "main_score": 0.006452,
        "hf_subset": "nso_Latn-amh_Ethi",
        "languages": [
          "nso-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.026945,
        "recall": 0.035053,
        "f1": 0.027937,
        "accuracy": 0.035053,
        "main_score": 0.027937,
        "hf_subset": "nso_Latn-eng_Latn",
        "languages": [
          "nso-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007712,
        "recall": 0.012018,
        "f1": 0.008086,
        "accuracy": 0.012018,
        "main_score": 0.008086,
        "hf_subset": "nso_Latn-hau_Latn",
        "languages": [
          "nso-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.016777,
        "recall": 0.02003,
        "f1": 0.017202,
        "accuracy": 0.02003,
        "main_score": 0.017202,
        "hf_subset": "nso_Latn-ibo_Latn",
        "languages": [
          "nso-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.005067,
        "recall": 0.007011,
        "f1": 0.005363,
        "accuracy": 0.007011,
        "main_score": 0.005363,
        "hf_subset": "nso_Latn-orm_Ethi",
        "languages": [
          "nso-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.007215,
        "recall": 0.010015,
        "f1": 0.007575,
        "accuracy": 0.010015,
        "main_score": 0.007575,
        "hf_subset": "nso_Latn-som_Latn",
        "languages": [
          "nso-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.011635,
        "recall": 0.017026,
        "f1": 0.012625,
        "accuracy": 0.017026,
        "main_score": 0.012625,
        "hf_subset": "nso_Latn-ssw_Latn",
        "languages": [
          "nso-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.008449,
        "recall": 0.011017,
        "f1": 0.008675,
        "accuracy": 0.011017,
        "main_score": 0.008675,
        "hf_subset": "nso_Latn-swa_Latn",
        "languages": [
          "nso-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.00361,
        "recall": 0.006009,
        "f1": 0.003694,
        "accuracy": 0.006009,
        "main_score": 0.003694,
        "hf_subset": "nso_Latn-tir_Ethi",
        "languages": [
          "nso-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.122993,
        "recall": 0.159239,
        "f1": 0.130553,
        "accuracy": 0.159239,
        "main_score": 0.130553,
        "hf_subset": "nso_Latn-tsn_Latn",
        "languages": [
          "nso-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.007829,
        "recall": 0.011517,
        "f1": 0.008142,
        "accuracy": 0.011517,
        "main_score": 0.008142,
        "hf_subset": "nso_Latn-wol_Latn",
        "languages": [
          "nso-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.007589,
        "recall": 0.011517,
        "f1": 0.007927,
        "accuracy": 0.011517,
        "main_score": 0.007927,
        "hf_subset": "nso_Latn-xho_Latn",
        "languages": [
          "nso-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.006497,
        "recall": 0.009014,
        "f1": 0.006735,
        "accuracy": 0.009014,
        "main_score": 0.006735,
        "hf_subset": "nso_Latn-yor_Latn",
        "languages": [
          "nso-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.016656,
        "recall": 0.025038,
        "f1": 0.017928,
        "accuracy": 0.025038,
        "main_score": 0.017928,
        "hf_subset": "nso_Latn-zul_Latn",
        "languages": [
          "nso-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.020514,
        "recall": 0.030546,
        "f1": 0.022281,
        "accuracy": 0.030546,
        "main_score": 0.022281,
        "hf_subset": "nya_Latn-bem_Latn",
        "languages": [
          "nya-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.021589,
        "recall": 0.034051,
        "f1": 0.023577,
        "accuracy": 0.034051,
        "main_score": 0.023577,
        "hf_subset": "nya_Latn-eng_Latn",
        "languages": [
          "nya-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009174,
        "recall": 0.01302,
        "f1": 0.009554,
        "accuracy": 0.01302,
        "main_score": 0.009554,
        "hf_subset": "nya_Latn-ewe_Latn",
        "languages": [
          "nya-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.008786,
        "recall": 0.011517,
        "f1": 0.009144,
        "accuracy": 0.011517,
        "main_score": 0.009144,
        "hf_subset": "nya_Latn-fuc_Latn",
        "languages": [
          "nya-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.007431,
        "recall": 0.01302,
        "f1": 0.00813,
        "accuracy": 0.01302,
        "main_score": 0.00813,
        "hf_subset": "nya_Latn-kin_Latn",
        "languages": [
          "nya-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.008436,
        "recall": 0.01302,
        "f1": 0.009109,
        "accuracy": 0.01302,
        "main_score": 0.009109,
        "hf_subset": "nya_Latn-nde_Latn",
        "languages": [
          "nya-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.019781,
        "recall": 0.029544,
        "f1": 0.021153,
        "accuracy": 0.029544,
        "main_score": 0.021153,
        "hf_subset": "nya_Latn-sna_Latn",
        "languages": [
          "nya-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.011129,
        "recall": 0.014522,
        "f1": 0.011665,
        "accuracy": 0.014522,
        "main_score": 0.011665,
        "hf_subset": "nya_Latn-ven_Latn",
        "languages": [
          "nya-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.004265,
        "recall": 0.009514,
        "f1": 0.004856,
        "accuracy": 0.009514,
        "main_score": 0.004856,
        "hf_subset": "orm_Ethi-amh_Ethi",
        "languages": [
          "orm-Ethi",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.009621,
        "recall": 0.016525,
        "f1": 0.010197,
        "accuracy": 0.016525,
        "main_score": 0.010197,
        "hf_subset": "orm_Ethi-eng_Latn",
        "languages": [
          "orm-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006754,
        "recall": 0.009014,
        "f1": 0.007102,
        "accuracy": 0.009014,
        "main_score": 0.007102,
        "hf_subset": "orm_Ethi-hau_Latn",
        "languages": [
          "orm-Ethi",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.005806,
        "recall": 0.007511,
        "f1": 0.006014,
        "accuracy": 0.007511,
        "main_score": 0.006014,
        "hf_subset": "orm_Ethi-ibo_Latn",
        "languages": [
          "orm-Ethi",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.004533,
        "recall": 0.008012,
        "f1": 0.004822,
        "accuracy": 0.008012,
        "main_score": 0.004822,
        "hf_subset": "orm_Ethi-nso_Latn",
        "languages": [
          "orm-Ethi",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.007895,
        "recall": 0.011517,
        "f1": 0.008374,
        "accuracy": 0.011517,
        "main_score": 0.008374,
        "hf_subset": "orm_Ethi-som_Latn",
        "languages": [
          "orm-Ethi",
          "som-Latn"
        ]
      },
      {
        "precision": 0.00551,
        "recall": 0.012018,
        "f1": 0.006279,
        "accuracy": 0.012018,
        "main_score": 0.006279,
        "hf_subset": "orm_Ethi-ssw_Latn",
        "languages": [
          "orm-Ethi",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.006723,
        "recall": 0.011017,
        "f1": 0.007305,
        "accuracy": 0.011017,
        "main_score": 0.007305,
        "hf_subset": "orm_Ethi-swa_Latn",
        "languages": [
          "orm-Ethi",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.002809,
        "recall": 0.005508,
        "f1": 0.003002,
        "accuracy": 0.005508,
        "main_score": 0.003002,
        "hf_subset": "orm_Ethi-tir_Ethi",
        "languages": [
          "orm-Ethi",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.005545,
        "recall": 0.007511,
        "f1": 0.005579,
        "accuracy": 0.007511,
        "main_score": 0.005579,
        "hf_subset": "orm_Ethi-tsn_Latn",
        "languages": [
          "orm-Ethi",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.007561,
        "recall": 0.009014,
        "f1": 0.007936,
        "accuracy": 0.009014,
        "main_score": 0.007936,
        "hf_subset": "orm_Ethi-wol_Latn",
        "languages": [
          "orm-Ethi",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.00305,
        "recall": 0.006009,
        "f1": 0.003325,
        "accuracy": 0.006009,
        "main_score": 0.003325,
        "hf_subset": "orm_Ethi-xho_Latn",
        "languages": [
          "orm-Ethi",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.007033,
        "recall": 0.009014,
        "f1": 0.007301,
        "accuracy": 0.009014,
        "main_score": 0.007301,
        "hf_subset": "orm_Ethi-yor_Latn",
        "languages": [
          "orm-Ethi",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.006809,
        "recall": 0.010015,
        "f1": 0.007007,
        "accuracy": 0.010015,
        "main_score": 0.007007,
        "hf_subset": "orm_Ethi-zul_Latn",
        "languages": [
          "orm-Ethi",
          "zul-Latn"
        ]
      },
      {
        "precision": 2.2e-05,
        "recall": 0.001002,
        "f1": 4.2e-05,
        "accuracy": 0.001002,
        "main_score": 4.2e-05,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.065683,
        "recall": 0.094141,
        "f1": 0.072016,
        "accuracy": 0.094141,
        "main_score": 0.072016,
        "hf_subset": "pan_Guru-div_Thaa",
        "languages": [
          "pan-Guru",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.040818,
        "recall": 0.05358,
        "f1": 0.042999,
        "accuracy": 0.05358,
        "main_score": 0.042999,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011902,
        "recall": 0.018528,
        "f1": 0.013006,
        "accuracy": 0.018528,
        "main_score": 0.013006,
        "hf_subset": "pan_Guru-eus_Latn",
        "languages": [
          "pan-Guru",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.108366,
        "recall": 0.14021,
        "f1": 0.116027,
        "accuracy": 0.14021,
        "main_score": 0.116027,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.002487,
        "recall": 0.005508,
        "f1": 0.002881,
        "accuracy": 0.005508,
        "main_score": 0.002881,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.085214,
        "recall": 0.115173,
        "f1": 0.092258,
        "accuracy": 0.115173,
        "main_score": 0.092258,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001489,
        "recall": 0.005008,
        "f1": 0.001719,
        "accuracy": 0.005008,
        "main_score": 0.001719,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001789,
        "recall": 0.003005,
        "f1": 0.001903,
        "accuracy": 0.003005,
        "main_score": 0.001903,
        "hf_subset": "pan_Guru-nep_Deva",
        "languages": [
          "pan-Guru",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.049136,
        "recall": 0.079119,
        "f1": 0.055488,
        "accuracy": 0.079119,
        "main_score": 0.055488,
        "hf_subset": "pan_Guru-sin_Sinh",
        "languages": [
          "pan-Guru",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.0034,
        "recall": 0.008012,
        "f1": 0.003992,
        "accuracy": 0.008012,
        "main_score": 0.003992,
        "hf_subset": "pan_Guru-snd_Arab",
        "languages": [
          "pan-Guru",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.002083,
        "recall": 0.008012,
        "f1": 0.002413,
        "accuracy": 0.008012,
        "main_score": 0.002413,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.088462,
        "recall": 0.114672,
        "f1": 0.094922,
        "accuracy": 0.114672,
        "main_score": 0.094922,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002026,
        "recall": 0.004507,
        "f1": 0.00232,
        "accuracy": 0.004507,
        "main_score": 0.00232,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000125,
        "recall": 0.000501,
        "f1": 0.0002,
        "accuracy": 0.000501,
        "main_score": 0.0002,
        "hf_subset": "pol_Latn-arb_Arab",
        "languages": [
          "pol-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.002141,
        "recall": 0.004507,
        "f1": 0.002628,
        "accuracy": 0.004507,
        "main_score": 0.002628,
        "hf_subset": "pol_Latn-bel_Cyrl",
        "languages": [
          "pol-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.00102,
        "recall": 0.003005,
        "f1": 0.001206,
        "accuracy": 0.003005,
        "main_score": 0.001206,
        "hf_subset": "pol_Latn-ben_Beng",
        "languages": [
          "pol-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.030354,
        "recall": 0.042063,
        "f1": 0.032412,
        "accuracy": 0.042063,
        "main_score": 0.032412,
        "hf_subset": "pol_Latn-bos_Latn",
        "languages": [
          "pol-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.003729,
        "recall": 0.009014,
        "f1": 0.00437,
        "accuracy": 0.009014,
        "main_score": 0.00437,
        "hf_subset": "pol_Latn-bul_Cyrl",
        "languages": [
          "pol-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.041396,
        "recall": 0.056585,
        "f1": 0.043816,
        "accuracy": 0.056585,
        "main_score": 0.043816,
        "hf_subset": "pol_Latn-ces_Latn",
        "languages": [
          "pol-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.015916,
        "recall": 0.025038,
        "f1": 0.016784,
        "accuracy": 0.025038,
        "main_score": 0.016784,
        "hf_subset": "pol_Latn-deu_Latn",
        "languages": [
          "pol-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000382,
        "recall": 0.002003,
        "f1": 0.000612,
        "accuracy": 0.002003,
        "main_score": 0.000612,
        "hf_subset": "pol_Latn-ell_Grek",
        "languages": [
          "pol-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.019819,
        "recall": 0.025538,
        "f1": 0.020633,
        "accuracy": 0.025538,
        "main_score": 0.020633,
        "hf_subset": "pol_Latn-eng_Latn",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000687,
        "recall": 0.003005,
        "f1": 0.000841,
        "accuracy": 0.003005,
        "main_score": 0.000841,
        "hf_subset": "pol_Latn-fas_Arab",
        "languages": [
          "pol-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.00959,
        "recall": 0.014522,
        "f1": 0.010499,
        "accuracy": 0.014522,
        "main_score": 0.010499,
        "hf_subset": "pol_Latn-fin_Latn",
        "languages": [
          "pol-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.016224,
        "recall": 0.026039,
        "f1": 0.017543,
        "accuracy": 0.026039,
        "main_score": 0.017543,
        "hf_subset": "pol_Latn-fra_Latn",
        "languages": [
          "pol-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.002258,
        "recall": 0.003005,
        "f1": 0.002346,
        "accuracy": 0.003005,
        "main_score": 0.002346,
        "hf_subset": "pol_Latn-heb_Hebr",
        "languages": [
          "pol-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000668,
        "recall": 0.001002,
        "f1": 0.000751,
        "accuracy": 0.001002,
        "main_score": 0.000751,
        "hf_subset": "pol_Latn-hin_Deva",
        "languages": [
          "pol-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.03071,
        "recall": 0.041562,
        "f1": 0.032657,
        "accuracy": 0.041562,
        "main_score": 0.032657,
        "hf_subset": "pol_Latn-hrv_Latn",
        "languages": [
          "pol-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.009529,
        "recall": 0.01302,
        "f1": 0.009967,
        "accuracy": 0.01302,
        "main_score": 0.009967,
        "hf_subset": "pol_Latn-hun_Latn",
        "languages": [
          "pol-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.013525,
        "recall": 0.019529,
        "f1": 0.014239,
        "accuracy": 0.019529,
        "main_score": 0.014239,
        "hf_subset": "pol_Latn-ind_Latn",
        "languages": [
          "pol-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.002737,
        "recall": 0.006009,
        "f1": 0.003048,
        "accuracy": 0.006009,
        "main_score": 0.003048,
        "hf_subset": "pol_Latn-jpn_Jpan",
        "languages": [
          "pol-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.002312,
        "recall": 0.006009,
        "f1": 0.002758,
        "accuracy": 0.006009,
        "main_score": 0.002758,
        "hf_subset": "pol_Latn-kor_Hang",
        "languages": [
          "pol-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.009873,
        "recall": 0.014021,
        "f1": 0.010752,
        "accuracy": 0.014021,
        "main_score": 0.010752,
        "hf_subset": "pol_Latn-lit_Latn",
        "languages": [
          "pol-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.002715,
        "recall": 0.007011,
        "f1": 0.00321,
        "accuracy": 0.007011,
        "main_score": 0.00321,
        "hf_subset": "pol_Latn-mkd_Cyrl",
        "languages": [
          "pol-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.012776,
        "recall": 0.017026,
        "f1": 0.013557,
        "accuracy": 0.017026,
        "main_score": 0.013557,
        "hf_subset": "pol_Latn-nld_Latn",
        "languages": [
          "pol-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.016943,
        "recall": 0.022033,
        "f1": 0.017685,
        "accuracy": 0.022033,
        "main_score": 0.017685,
        "hf_subset": "pol_Latn-por_Latn",
        "languages": [
          "pol-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000901,
        "recall": 0.003505,
        "f1": 0.001108,
        "accuracy": 0.003505,
        "main_score": 0.001108,
        "hf_subset": "pol_Latn-rus_Cyrl",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.046512,
        "recall": 0.063095,
        "f1": 0.049504,
        "accuracy": 0.063095,
        "main_score": 0.049504,
        "hf_subset": "pol_Latn-slk_Latn",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.025652,
        "recall": 0.036555,
        "f1": 0.027376,
        "accuracy": 0.036555,
        "main_score": 0.027376,
        "hf_subset": "pol_Latn-slv_Latn",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.019029,
        "recall": 0.028042,
        "f1": 0.020369,
        "accuracy": 0.028042,
        "main_score": 0.020369,
        "hf_subset": "pol_Latn-spa_Latn",
        "languages": [
          "pol-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.002917,
        "recall": 0.007011,
        "f1": 0.003211,
        "accuracy": 0.007011,
        "main_score": 0.003211,
        "hf_subset": "pol_Latn-srp_Cyrl",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.018613,
        "recall": 0.030045,
        "f1": 0.020415,
        "accuracy": 0.030045,
        "main_score": 0.020415,
        "hf_subset": "pol_Latn-srp_Latn",
        "languages": [
          "pol-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.010033,
        "recall": 0.01352,
        "f1": 0.010359,
        "accuracy": 0.01352,
        "main_score": 0.010359,
        "hf_subset": "pol_Latn-swa_Latn",
        "languages": [
          "pol-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.018115,
        "recall": 0.025038,
        "f1": 0.018834,
        "accuracy": 0.025038,
        "main_score": 0.018834,
        "hf_subset": "pol_Latn-swe_Latn",
        "languages": [
          "pol-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001511,
        "recall": 0.002504,
        "f1": 0.00152,
        "accuracy": 0.002504,
        "main_score": 0.00152,
        "hf_subset": "pol_Latn-tam_Taml",
        "languages": [
          "pol-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009202,
        "recall": 0.012519,
        "f1": 0.00972,
        "accuracy": 0.012519,
        "main_score": 0.00972,
        "hf_subset": "pol_Latn-tur_Latn",
        "languages": [
          "pol-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.003031,
        "recall": 0.009514,
        "f1": 0.003852,
        "accuracy": 0.009514,
        "main_score": 0.003852,
        "hf_subset": "pol_Latn-ukr_Cyrl",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.010679,
        "recall": 0.017026,
        "f1": 0.011497,
        "accuracy": 0.017026,
        "main_score": 0.011497,
        "hf_subset": "pol_Latn-vie_Latn",
        "languages": [
          "pol-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.012271,
        "recall": 0.020531,
        "f1": 0.013131,
        "accuracy": 0.020531,
        "main_score": 0.013131,
        "hf_subset": "pol_Latn-zho_Hant",
        "languages": [
          "pol-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.009014,
        "recall": 0.009514,
        "f1": 0.009015,
        "accuracy": 0.009514,
        "main_score": 0.009015,
        "hf_subset": "pol_Latn-zul_Latn",
        "languages": [
          "pol-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 5.8e-05,
        "recall": 0.001502,
        "f1": 0.000106,
        "accuracy": 0.001502,
        "main_score": 0.000106,
        "hf_subset": "por_Latn-arb_Arab",
        "languages": [
          "por-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000757,
        "recall": 0.002003,
        "f1": 0.000847,
        "accuracy": 0.002003,
        "main_score": 0.000847,
        "hf_subset": "por_Latn-ben_Beng",
        "languages": [
          "por-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.175017,
        "recall": 0.22033,
        "f1": 0.183759,
        "accuracy": 0.22033,
        "main_score": 0.183759,
        "hf_subset": "por_Latn-cat_Latn",
        "languages": [
          "por-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.023386,
        "recall": 0.03305,
        "f1": 0.024764,
        "accuracy": 0.03305,
        "main_score": 0.024764,
        "hf_subset": "por_Latn-deu_Latn",
        "languages": [
          "por-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.001083,
        "recall": 0.003005,
        "f1": 0.001152,
        "accuracy": 0.003005,
        "main_score": 0.001152,
        "hf_subset": "por_Latn-ell_Grek",
        "languages": [
          "por-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.044491,
        "recall": 0.057586,
        "f1": 0.046679,
        "accuracy": 0.057586,
        "main_score": 0.046679,
        "hf_subset": "por_Latn-eng_Latn",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001428,
        "recall": 0.006009,
        "f1": 0.001886,
        "accuracy": 0.006009,
        "main_score": 0.001886,
        "hf_subset": "por_Latn-fas_Arab",
        "languages": [
          "por-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.013968,
        "recall": 0.018027,
        "f1": 0.014608,
        "accuracy": 0.018027,
        "main_score": 0.014608,
        "hf_subset": "por_Latn-fin_Latn",
        "languages": [
          "por-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.062436,
        "recall": 0.087131,
        "f1": 0.06607,
        "accuracy": 0.087131,
        "main_score": 0.06607,
        "hf_subset": "por_Latn-fra_Latn",
        "languages": [
          "por-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.464461,
        "recall": 0.545819,
        "f1": 0.484649,
        "accuracy": 0.545819,
        "main_score": 0.484649,
        "hf_subset": "por_Latn-glg_Latn",
        "languages": [
          "por-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.003005,
        "recall": 0.003505,
        "f1": 0.003171,
        "accuracy": 0.003505,
        "main_score": 0.003171,
        "hf_subset": "por_Latn-heb_Hebr",
        "languages": [
          "por-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.001066,
        "recall": 0.002504,
        "f1": 0.001117,
        "accuracy": 0.002504,
        "main_score": 0.001117,
        "hf_subset": "por_Latn-hin_Deva",
        "languages": [
          "por-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015006,
        "recall": 0.021032,
        "f1": 0.015765,
        "accuracy": 0.021032,
        "main_score": 0.015765,
        "hf_subset": "por_Latn-hun_Latn",
        "languages": [
          "por-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.019919,
        "recall": 0.028543,
        "f1": 0.021397,
        "accuracy": 0.028543,
        "main_score": 0.021397,
        "hf_subset": "por_Latn-ind_Latn",
        "languages": [
          "por-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.087389,
        "recall": 0.112669,
        "f1": 0.091666,
        "accuracy": 0.112669,
        "main_score": 0.091666,
        "hf_subset": "por_Latn-ita_Latn",
        "languages": [
          "por-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.002189,
        "recall": 0.00651,
        "f1": 0.002487,
        "accuracy": 0.00651,
        "main_score": 0.002487,
        "hf_subset": "por_Latn-jpn_Jpan",
        "languages": [
          "por-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000806,
        "recall": 0.004006,
        "f1": 0.001029,
        "accuracy": 0.004006,
        "main_score": 0.001029,
        "hf_subset": "por_Latn-kor_Hang",
        "languages": [
          "por-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.01178,
        "recall": 0.019029,
        "f1": 0.012777,
        "accuracy": 0.019029,
        "main_score": 0.012777,
        "hf_subset": "por_Latn-lit_Latn",
        "languages": [
          "por-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.028051,
        "recall": 0.039559,
        "f1": 0.029909,
        "accuracy": 0.039559,
        "main_score": 0.029909,
        "hf_subset": "por_Latn-mlt_Latn",
        "languages": [
          "por-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.038581,
        "recall": 0.049574,
        "f1": 0.040177,
        "accuracy": 0.049574,
        "main_score": 0.040177,
        "hf_subset": "por_Latn-nld_Latn",
        "languages": [
          "por-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.011741,
        "recall": 0.019529,
        "f1": 0.012967,
        "accuracy": 0.019529,
        "main_score": 0.012967,
        "hf_subset": "por_Latn-pol_Latn",
        "languages": [
          "por-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.052375,
        "recall": 0.072609,
        "f1": 0.055147,
        "accuracy": 0.072609,
        "main_score": 0.055147,
        "hf_subset": "por_Latn-ron_Latn",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.000977,
        "recall": 0.003505,
        "f1": 0.001198,
        "accuracy": 0.003505,
        "main_score": 0.001198,
        "hf_subset": "por_Latn-rus_Cyrl",
        "languages": [
          "por-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.306302,
        "recall": 0.37356,
        "f1": 0.321195,
        "accuracy": 0.37356,
        "main_score": 0.321195,
        "hf_subset": "por_Latn-spa_Latn",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.011813,
        "recall": 0.017026,
        "f1": 0.012584,
        "accuracy": 0.017026,
        "main_score": 0.012584,
        "hf_subset": "por_Latn-swa_Latn",
        "languages": [
          "por-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.025195,
        "recall": 0.032048,
        "f1": 0.026371,
        "accuracy": 0.032048,
        "main_score": 0.026371,
        "hf_subset": "por_Latn-swe_Latn",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001297,
        "recall": 0.003505,
        "f1": 0.001459,
        "accuracy": 0.003505,
        "main_score": 0.001459,
        "hf_subset": "por_Latn-tam_Taml",
        "languages": [
          "por-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009486,
        "recall": 0.016525,
        "f1": 0.010522,
        "accuracy": 0.016525,
        "main_score": 0.010522,
        "hf_subset": "por_Latn-tur_Latn",
        "languages": [
          "por-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.012424,
        "recall": 0.021032,
        "f1": 0.013484,
        "accuracy": 0.021032,
        "main_score": 0.013484,
        "hf_subset": "por_Latn-vie_Latn",
        "languages": [
          "por-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.016435,
        "recall": 0.025538,
        "f1": 0.017853,
        "accuracy": 0.025538,
        "main_score": 0.017853,
        "hf_subset": "por_Latn-zho_Hant",
        "languages": [
          "por-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.016123,
        "recall": 0.023035,
        "f1": 0.017388,
        "accuracy": 0.023035,
        "main_score": 0.017388,
        "hf_subset": "por_Latn-zul_Latn",
        "languages": [
          "por-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000542,
        "recall": 0.002504,
        "f1": 0.00058,
        "accuracy": 0.002504,
        "main_score": 0.00058,
        "hf_subset": "prs_Arab-arb_Arab",
        "languages": [
          "prs-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001278,
        "recall": 0.003505,
        "f1": 0.00145,
        "accuracy": 0.003505,
        "main_score": 0.00145,
        "hf_subset": "prs_Arab-ckb_Arab",
        "languages": [
          "prs-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.000543,
        "recall": 0.002504,
        "f1": 0.00058,
        "accuracy": 0.002504,
        "main_score": 0.00058,
        "hf_subset": "prs_Arab-eng_Latn",
        "languages": [
          "prs-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.171864,
        "recall": 0.236355,
        "f1": 0.187561,
        "accuracy": 0.236355,
        "main_score": 0.187561,
        "hf_subset": "prs_Arab-fas_Arab",
        "languages": [
          "prs-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.002003,
        "f1": 0.000507,
        "accuracy": 0.002003,
        "main_score": 0.000507,
        "hf_subset": "prs_Arab-heb_Hebr",
        "languages": [
          "prs-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001002,
        "f1": 1.2e-05,
        "accuracy": 0.001002,
        "main_score": 1.2e-05,
        "hf_subset": "prs_Arab-kmr_Latn",
        "languages": [
          "prs-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.00104,
        "recall": 0.002003,
        "f1": 0.00124,
        "accuracy": 0.002003,
        "main_score": 0.00124,
        "hf_subset": "prs_Arab-mey_Arab",
        "languages": [
          "prs-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.004536,
        "recall": 0.010015,
        "f1": 0.005065,
        "accuracy": 0.010015,
        "main_score": 0.005065,
        "hf_subset": "prs_Arab-pus_Arab",
        "languages": [
          "prs-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.000168,
        "recall": 0.001002,
        "f1": 0.000253,
        "accuracy": 0.001002,
        "main_score": 0.000253,
        "hf_subset": "prs_Arab-shi_Arab",
        "languages": [
          "prs-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.002309,
        "recall": 0.006009,
        "f1": 0.002537,
        "accuracy": 0.006009,
        "main_score": 0.002537,
        "hf_subset": "prs_Arab-tgk_Cyrl",
        "languages": [
          "prs-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.002274,
        "recall": 0.005008,
        "f1": 0.002449,
        "accuracy": 0.005008,
        "main_score": 0.002449,
        "hf_subset": "pus_Arab-arb_Arab",
        "languages": [
          "pus-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000255,
        "recall": 0.001002,
        "f1": 0.000343,
        "accuracy": 0.001002,
        "main_score": 0.000343,
        "hf_subset": "pus_Arab-ckb_Arab",
        "languages": [
          "pus-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.001029,
        "recall": 0.002504,
        "f1": 0.001054,
        "accuracy": 0.002504,
        "main_score": 0.001054,
        "hf_subset": "pus_Arab-eng_Latn",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006037,
        "recall": 0.010516,
        "f1": 0.006762,
        "accuracy": 0.010516,
        "main_score": 0.006762,
        "hf_subset": "pus_Arab-fas_Arab",
        "languages": [
          "pus-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001502,
        "f1": 0.000508,
        "accuracy": 0.001502,
        "main_score": 0.000508,
        "hf_subset": "pus_Arab-heb_Hebr",
        "languages": [
          "pus-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001002,
        "f1": 0.001002,
        "accuracy": 0.001002,
        "main_score": 0.001002,
        "hf_subset": "pus_Arab-kmr_Latn",
        "languages": [
          "pus-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.001526,
        "recall": 0.002504,
        "f1": 0.001548,
        "accuracy": 0.002504,
        "main_score": 0.001548,
        "hf_subset": "pus_Arab-mey_Arab",
        "languages": [
          "pus-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.007359,
        "recall": 0.014522,
        "f1": 0.008159,
        "accuracy": 0.014522,
        "main_score": 0.008159,
        "hf_subset": "pus_Arab-prs_Arab",
        "languages": [
          "pus-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.001767,
        "recall": 0.003005,
        "f1": 0.001864,
        "accuracy": 0.003005,
        "main_score": 0.001864,
        "hf_subset": "pus_Arab-shi_Arab",
        "languages": [
          "pus-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.000594,
        "recall": 0.002504,
        "f1": 0.000664,
        "accuracy": 0.002504,
        "main_score": 0.000664,
        "hf_subset": "pus_Arab-tgk_Cyrl",
        "languages": [
          "pus-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.051871,
        "recall": 0.067601,
        "f1": 0.054348,
        "accuracy": 0.067601,
        "main_score": 0.054348,
        "hf_subset": "ron_Latn-cat_Latn",
        "languages": [
          "ron-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.031644,
        "recall": 0.04006,
        "f1": 0.032798,
        "accuracy": 0.04006,
        "main_score": 0.032798,
        "hf_subset": "ron_Latn-eng_Latn",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.037305,
        "recall": 0.052078,
        "f1": 0.039605,
        "accuracy": 0.052078,
        "main_score": 0.039605,
        "hf_subset": "ron_Latn-fra_Latn",
        "languages": [
          "ron-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.042709,
        "recall": 0.058087,
        "f1": 0.045105,
        "accuracy": 0.058087,
        "main_score": 0.045105,
        "hf_subset": "ron_Latn-glg_Latn",
        "languages": [
          "ron-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.050991,
        "recall": 0.071107,
        "f1": 0.054243,
        "accuracy": 0.071107,
        "main_score": 0.054243,
        "hf_subset": "ron_Latn-ita_Latn",
        "languages": [
          "ron-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.026693,
        "recall": 0.044066,
        "f1": 0.029419,
        "accuracy": 0.044066,
        "main_score": 0.029419,
        "hf_subset": "ron_Latn-mlt_Latn",
        "languages": [
          "ron-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.042669,
        "recall": 0.058087,
        "f1": 0.044994,
        "accuracy": 0.058087,
        "main_score": 0.044994,
        "hf_subset": "ron_Latn-por_Latn",
        "languages": [
          "ron-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.04952,
        "recall": 0.065598,
        "f1": 0.051716,
        "accuracy": 0.065598,
        "main_score": 0.051716,
        "hf_subset": "ron_Latn-spa_Latn",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 8.5e-05,
        "recall": 0.001502,
        "f1": 0.000146,
        "accuracy": 0.001502,
        "main_score": 0.000146,
        "hf_subset": "rus_Cyrl-arb_Arab",
        "languages": [
          "rus-Cyrl",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.014294,
        "recall": 0.030546,
        "f1": 0.016146,
        "accuracy": 0.030546,
        "main_score": 0.016146,
        "hf_subset": "rus_Cyrl-bel_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 3.8e-05,
        "recall": 0.002003,
        "f1": 7.1e-05,
        "accuracy": 0.002003,
        "main_score": 7.1e-05,
        "hf_subset": "rus_Cyrl-ben_Beng",
        "languages": [
          "rus-Cyrl",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001252,
        "recall": 0.002003,
        "f1": 0.001336,
        "accuracy": 0.002003,
        "main_score": 0.001336,
        "hf_subset": "rus_Cyrl-bos_Latn",
        "languages": [
          "rus-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.027133,
        "recall": 0.04657,
        "f1": 0.030937,
        "accuracy": 0.04657,
        "main_score": 0.030937,
        "hf_subset": "rus_Cyrl-bul_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.000547,
        "recall": 0.001502,
        "f1": 0.000585,
        "accuracy": 0.001502,
        "main_score": 0.000585,
        "hf_subset": "rus_Cyrl-ces_Latn",
        "languages": [
          "rus-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001003,
        "accuracy": 0.001502,
        "main_score": 0.001003,
        "hf_subset": "rus_Cyrl-deu_Latn",
        "languages": [
          "rus-Cyrl",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "rus_Cyrl-ell_Grek",
        "languages": [
          "rus-Cyrl",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.001035,
        "recall": 0.002504,
        "f1": 0.001066,
        "accuracy": 0.002504,
        "main_score": 0.001066,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "rus_Cyrl-fas_Arab",
        "languages": [
          "rus-Cyrl",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.001006,
        "recall": 0.002003,
        "f1": 0.00101,
        "accuracy": 0.002003,
        "main_score": 0.00101,
        "hf_subset": "rus_Cyrl-fin_Latn",
        "languages": [
          "rus-Cyrl",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001003,
        "accuracy": 0.001502,
        "main_score": 0.001003,
        "hf_subset": "rus_Cyrl-fra_Latn",
        "languages": [
          "rus-Cyrl",
          "fra-Latn"
        ]
      },
      {
        "precision": 2.5e-05,
        "recall": 0.001002,
        "f1": 4.8e-05,
        "accuracy": 0.001002,
        "main_score": 4.8e-05,
        "hf_subset": "rus_Cyrl-heb_Hebr",
        "languages": [
          "rus-Cyrl",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "rus_Cyrl-hin_Deva",
        "languages": [
          "rus-Cyrl",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000505,
        "recall": 0.001502,
        "f1": 0.00051,
        "accuracy": 0.001502,
        "main_score": 0.00051,
        "hf_subset": "rus_Cyrl-hrv_Latn",
        "languages": [
          "rus-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001003,
        "accuracy": 0.001502,
        "main_score": 0.001003,
        "hf_subset": "rus_Cyrl-hun_Latn",
        "languages": [
          "rus-Cyrl",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "rus_Cyrl-ind_Latn",
        "languages": [
          "rus-Cyrl",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001008,
        "recall": 0.001502,
        "f1": 0.001014,
        "accuracy": 0.001502,
        "main_score": 0.001014,
        "hf_subset": "rus_Cyrl-jpn_Jpan",
        "languages": [
          "rus-Cyrl",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "rus_Cyrl-kor_Hang",
        "languages": [
          "rus-Cyrl",
          "kor-Hang"
        ]
      },
      {
        "precision": 5.6e-05,
        "recall": 0.001002,
        "f1": 0.000102,
        "accuracy": 0.001002,
        "main_score": 0.000102,
        "hf_subset": "rus_Cyrl-lit_Latn",
        "languages": [
          "rus-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.017894,
        "recall": 0.03355,
        "f1": 0.01991,
        "accuracy": 0.03355,
        "main_score": 0.01991,
        "hf_subset": "rus_Cyrl-mkd_Cyrl",
        "languages": [
          "rus-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.000511,
        "recall": 0.002003,
        "f1": 0.000521,
        "accuracy": 0.002003,
        "main_score": 0.000521,
        "hf_subset": "rus_Cyrl-nld_Latn",
        "languages": [
          "rus-Cyrl",
          "nld-Latn"
        ]
      },
      {
        "precision": 7.6e-05,
        "recall": 0.001502,
        "f1": 0.000138,
        "accuracy": 0.001502,
        "main_score": 0.000138,
        "hf_subset": "rus_Cyrl-pol_Latn",
        "languages": [
          "rus-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.00101,
        "recall": 0.003005,
        "f1": 0.001019,
        "accuracy": 0.003005,
        "main_score": 0.001019,
        "hf_subset": "rus_Cyrl-por_Latn",
        "languages": [
          "rus-Cyrl",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000505,
        "accuracy": 0.001502,
        "main_score": 0.000505,
        "hf_subset": "rus_Cyrl-slk_Latn",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "rus_Cyrl-slv_Latn",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.001014,
        "recall": 0.002003,
        "f1": 0.001025,
        "accuracy": 0.002003,
        "main_score": 0.001025,
        "hf_subset": "rus_Cyrl-spa_Latn",
        "languages": [
          "rus-Cyrl",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.014808,
        "recall": 0.026039,
        "f1": 0.016204,
        "accuracy": 0.026039,
        "main_score": 0.016204,
        "hf_subset": "rus_Cyrl-srp_Cyrl",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.000507,
        "recall": 0.001502,
        "f1": 0.000513,
        "accuracy": 0.001502,
        "main_score": 0.000513,
        "hf_subset": "rus_Cyrl-srp_Latn",
        "languages": [
          "rus-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.001509,
        "recall": 0.002003,
        "f1": 0.001515,
        "accuracy": 0.002003,
        "main_score": 0.001515,
        "hf_subset": "rus_Cyrl-swa_Latn",
        "languages": [
          "rus-Cyrl",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "rus_Cyrl-swe_Latn",
        "languages": [
          "rus-Cyrl",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000509,
        "recall": 0.001002,
        "f1": 0.000517,
        "accuracy": 0.001002,
        "main_score": 0.000517,
        "hf_subset": "rus_Cyrl-tam_Taml",
        "languages": [
          "rus-Cyrl",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001505,
        "recall": 0.002504,
        "f1": 0.001508,
        "accuracy": 0.002504,
        "main_score": 0.001508,
        "hf_subset": "rus_Cyrl-tur_Latn",
        "languages": [
          "rus-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.016679,
        "recall": 0.031547,
        "f1": 0.01929,
        "accuracy": 0.031547,
        "main_score": 0.01929,
        "hf_subset": "rus_Cyrl-ukr_Cyrl",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "rus_Cyrl-vie_Latn",
        "languages": [
          "rus-Cyrl",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.000853,
        "recall": 0.002504,
        "f1": 0.001005,
        "accuracy": 0.002504,
        "main_score": 0.001005,
        "hf_subset": "rus_Cyrl-zho_Hant",
        "languages": [
          "rus-Cyrl",
          "zho-Hant"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001002,
        "f1": 8e-06,
        "accuracy": 0.001002,
        "main_score": 8e-06,
        "hf_subset": "rus_Cyrl-zul_Latn",
        "languages": [
          "rus-Cyrl",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.016341,
        "recall": 0.031047,
        "f1": 0.01837,
        "accuracy": 0.031047,
        "main_score": 0.01837,
        "hf_subset": "shi_Arab-arb_Arab",
        "languages": [
          "shi-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 1.4e-05,
        "recall": 0.000501,
        "f1": 2.6e-05,
        "accuracy": 0.000501,
        "main_score": 2.6e-05,
        "hf_subset": "shi_Arab-ckb_Arab",
        "languages": [
          "shi-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 6.5e-05,
        "recall": 0.002003,
        "f1": 0.000122,
        "accuracy": 0.002003,
        "main_score": 0.000122,
        "hf_subset": "shi_Arab-eng_Latn",
        "languages": [
          "shi-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000524,
        "recall": 0.001502,
        "f1": 0.000545,
        "accuracy": 0.001502,
        "main_score": 0.000545,
        "hf_subset": "shi_Arab-fas_Arab",
        "languages": [
          "shi-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.002003,
        "f1": 0.000506,
        "accuracy": 0.002003,
        "main_score": 0.000506,
        "hf_subset": "shi_Arab-heb_Hebr",
        "languages": [
          "shi-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 1.6e-05,
        "recall": 0.001002,
        "f1": 3.2e-05,
        "accuracy": 0.001002,
        "main_score": 3.2e-05,
        "hf_subset": "shi_Arab-kmr_Latn",
        "languages": [
          "shi-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.019901,
        "recall": 0.03355,
        "f1": 0.022305,
        "accuracy": 0.03355,
        "main_score": 0.022305,
        "hf_subset": "shi_Arab-mey_Arab",
        "languages": [
          "shi-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 2e-05,
        "recall": 0.001002,
        "f1": 3.9e-05,
        "accuracy": 0.001002,
        "main_score": 3.9e-05,
        "hf_subset": "shi_Arab-prs_Arab",
        "languages": [
          "shi-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 8.1e-05,
        "recall": 0.002504,
        "f1": 0.000153,
        "accuracy": 0.002504,
        "main_score": 0.000153,
        "hf_subset": "shi_Arab-pus_Arab",
        "languages": [
          "shi-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.000121,
        "recall": 0.002003,
        "f1": 0.000221,
        "accuracy": 0.002003,
        "main_score": 0.000221,
        "hf_subset": "shi_Arab-tgk_Cyrl",
        "languages": [
          "shi-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.000525,
        "recall": 0.002504,
        "f1": 0.000549,
        "accuracy": 0.002504,
        "main_score": 0.000549,
        "hf_subset": "sin_Sinh-ben_Beng",
        "languages": [
          "sin-Sinh",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.072884,
        "recall": 0.09314,
        "f1": 0.077966,
        "accuracy": 0.09314,
        "main_score": 0.077966,
        "hf_subset": "sin_Sinh-div_Thaa",
        "languages": [
          "sin-Sinh",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.027708,
        "recall": 0.043565,
        "f1": 0.030455,
        "accuracy": 0.043565,
        "main_score": 0.030455,
        "hf_subset": "sin_Sinh-eng_Latn",
        "languages": [
          "sin-Sinh",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009482,
        "recall": 0.016024,
        "f1": 0.010443,
        "accuracy": 0.016024,
        "main_score": 0.010443,
        "hf_subset": "sin_Sinh-eus_Latn",
        "languages": [
          "sin-Sinh",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.092307,
        "recall": 0.11317,
        "f1": 0.097479,
        "accuracy": 0.11317,
        "main_score": 0.097479,
        "hf_subset": "sin_Sinh-guj_Gujr",
        "languages": [
          "sin-Sinh",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.002986,
        "recall": 0.00651,
        "f1": 0.003406,
        "accuracy": 0.00651,
        "main_score": 0.003406,
        "hf_subset": "sin_Sinh-hin_Deva",
        "languages": [
          "sin-Sinh",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.090211,
        "recall": 0.111668,
        "f1": 0.095774,
        "accuracy": 0.111668,
        "main_score": 0.095774,
        "hf_subset": "sin_Sinh-kan_Knda",
        "languages": [
          "sin-Sinh",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001832,
        "recall": 0.005508,
        "f1": 0.002055,
        "accuracy": 0.005508,
        "main_score": 0.002055,
        "hf_subset": "sin_Sinh-mar_Deva",
        "languages": [
          "sin-Sinh",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003648,
        "recall": 0.006009,
        "f1": 0.003977,
        "accuracy": 0.006009,
        "main_score": 0.003977,
        "hf_subset": "sin_Sinh-nep_Deva",
        "languages": [
          "sin-Sinh",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.07341,
        "recall": 0.097646,
        "f1": 0.079554,
        "accuracy": 0.097646,
        "main_score": 0.079554,
        "hf_subset": "sin_Sinh-pan_Guru",
        "languages": [
          "sin-Sinh",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.003079,
        "recall": 0.010015,
        "f1": 0.003746,
        "accuracy": 0.010015,
        "main_score": 0.003746,
        "hf_subset": "sin_Sinh-snd_Arab",
        "languages": [
          "sin-Sinh",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.003716,
        "recall": 0.011017,
        "f1": 0.004302,
        "accuracy": 0.011017,
        "main_score": 0.004302,
        "hf_subset": "sin_Sinh-tam_Taml",
        "languages": [
          "sin-Sinh",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.091006,
        "recall": 0.115674,
        "f1": 0.097364,
        "accuracy": 0.115674,
        "main_score": 0.097364,
        "hf_subset": "sin_Sinh-tel_Telu",
        "languages": [
          "sin-Sinh",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002771,
        "recall": 0.006009,
        "f1": 0.002965,
        "accuracy": 0.006009,
        "main_score": 0.002965,
        "hf_subset": "sin_Sinh-urd_Arab",
        "languages": [
          "sin-Sinh",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.004376,
        "recall": 0.010015,
        "f1": 0.005046,
        "accuracy": 0.010015,
        "main_score": 0.005046,
        "hf_subset": "slk_Latn-bel_Cyrl",
        "languages": [
          "slk-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.086743,
        "recall": 0.120681,
        "f1": 0.093906,
        "accuracy": 0.120681,
        "main_score": 0.093906,
        "hf_subset": "slk_Latn-bos_Latn",
        "languages": [
          "slk-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.004176,
        "recall": 0.01352,
        "f1": 0.005339,
        "accuracy": 0.01352,
        "main_score": 0.005339,
        "hf_subset": "slk_Latn-bul_Cyrl",
        "languages": [
          "slk-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.517122,
        "recall": 0.599399,
        "f1": 0.538215,
        "accuracy": 0.599399,
        "main_score": 0.538215,
        "hf_subset": "slk_Latn-ces_Latn",
        "languages": [
          "slk-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.026982,
        "recall": 0.034552,
        "f1": 0.028227,
        "accuracy": 0.034552,
        "main_score": 0.028227,
        "hf_subset": "slk_Latn-eng_Latn",
        "languages": [
          "slk-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.08585,
        "recall": 0.115173,
        "f1": 0.092002,
        "accuracy": 0.115173,
        "main_score": 0.092002,
        "hf_subset": "slk_Latn-hrv_Latn",
        "languages": [
          "slk-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.003834,
        "recall": 0.011017,
        "f1": 0.004772,
        "accuracy": 0.011017,
        "main_score": 0.004772,
        "hf_subset": "slk_Latn-mkd_Cyrl",
        "languages": [
          "slk-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.071464,
        "recall": 0.10015,
        "f1": 0.076777,
        "accuracy": 0.10015,
        "main_score": 0.076777,
        "hf_subset": "slk_Latn-pol_Latn",
        "languages": [
          "slk-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001809,
        "recall": 0.008513,
        "f1": 0.00251,
        "accuracy": 0.008513,
        "main_score": 0.00251,
        "hf_subset": "slk_Latn-rus_Cyrl",
        "languages": [
          "slk-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.094207,
        "recall": 0.128192,
        "f1": 0.100838,
        "accuracy": 0.128192,
        "main_score": 0.100838,
        "hf_subset": "slk_Latn-slv_Latn",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.004616,
        "recall": 0.009014,
        "f1": 0.005223,
        "accuracy": 0.009014,
        "main_score": 0.005223,
        "hf_subset": "slk_Latn-srp_Cyrl",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.061082,
        "recall": 0.087631,
        "f1": 0.065735,
        "accuracy": 0.087631,
        "main_score": 0.065735,
        "hf_subset": "slk_Latn-srp_Latn",
        "languages": [
          "slk-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.004853,
        "recall": 0.012519,
        "f1": 0.005794,
        "accuracy": 0.012519,
        "main_score": 0.005794,
        "hf_subset": "slk_Latn-ukr_Cyrl",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.003465,
        "recall": 0.008012,
        "f1": 0.004,
        "accuracy": 0.008012,
        "main_score": 0.004,
        "hf_subset": "slv_Latn-bel_Cyrl",
        "languages": [
          "slv-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.194991,
        "recall": 0.257887,
        "f1": 0.209303,
        "accuracy": 0.257887,
        "main_score": 0.209303,
        "hf_subset": "slv_Latn-bos_Latn",
        "languages": [
          "slv-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.004815,
        "recall": 0.011517,
        "f1": 0.005902,
        "accuracy": 0.011517,
        "main_score": 0.005902,
        "hf_subset": "slv_Latn-bul_Cyrl",
        "languages": [
          "slv-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.069763,
        "recall": 0.09364,
        "f1": 0.073834,
        "accuracy": 0.09364,
        "main_score": 0.073834,
        "hf_subset": "slv_Latn-ces_Latn",
        "languages": [
          "slv-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.016758,
        "recall": 0.022534,
        "f1": 0.017787,
        "accuracy": 0.022534,
        "main_score": 0.017787,
        "hf_subset": "slv_Latn-eng_Latn",
        "languages": [
          "slv-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.198767,
        "recall": 0.263896,
        "f1": 0.213464,
        "accuracy": 0.263896,
        "main_score": 0.213464,
        "hf_subset": "slv_Latn-hrv_Latn",
        "languages": [
          "slv-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.004038,
        "recall": 0.010516,
        "f1": 0.005073,
        "accuracy": 0.010516,
        "main_score": 0.005073,
        "hf_subset": "slv_Latn-mkd_Cyrl",
        "languages": [
          "slv-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.02153,
        "recall": 0.03355,
        "f1": 0.023344,
        "accuracy": 0.03355,
        "main_score": 0.023344,
        "hf_subset": "slv_Latn-pol_Latn",
        "languages": [
          "slv-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.003418,
        "recall": 0.009514,
        "f1": 0.003987,
        "accuracy": 0.009514,
        "main_score": 0.003987,
        "hf_subset": "slv_Latn-rus_Cyrl",
        "languages": [
          "slv-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.06864,
        "recall": 0.099149,
        "f1": 0.073679,
        "accuracy": 0.099149,
        "main_score": 0.073679,
        "hf_subset": "slv_Latn-slk_Latn",
        "languages": [
          "slv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.002268,
        "recall": 0.008012,
        "f1": 0.002758,
        "accuracy": 0.008012,
        "main_score": 0.002758,
        "hf_subset": "slv_Latn-srp_Cyrl",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.141638,
        "recall": 0.2003,
        "f1": 0.154652,
        "accuracy": 0.2003,
        "main_score": 0.154652,
        "hf_subset": "slv_Latn-srp_Latn",
        "languages": [
          "slv-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.002554,
        "recall": 0.008012,
        "f1": 0.003328,
        "accuracy": 0.008012,
        "main_score": 0.003328,
        "hf_subset": "slv_Latn-ukr_Cyrl",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.020346,
        "recall": 0.026039,
        "f1": 0.020978,
        "accuracy": 0.026039,
        "main_score": 0.020978,
        "hf_subset": "smo_Latn-eng_Latn",
        "languages": [
          "smo-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009099,
        "recall": 0.01302,
        "f1": 0.00957,
        "accuracy": 0.01302,
        "main_score": 0.00957,
        "hf_subset": "smo_Latn-fij_Latn",
        "languages": [
          "smo-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.00887,
        "recall": 0.01352,
        "f1": 0.009507,
        "accuracy": 0.01352,
        "main_score": 0.009507,
        "hf_subset": "smo_Latn-fil_Latn",
        "languages": [
          "smo-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.01289,
        "recall": 0.016525,
        "f1": 0.013629,
        "accuracy": 0.016525,
        "main_score": 0.013629,
        "hf_subset": "smo_Latn-ind_Latn",
        "languages": [
          "smo-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.002777,
        "recall": 0.004507,
        "f1": 0.002932,
        "accuracy": 0.004507,
        "main_score": 0.002932,
        "hf_subset": "smo_Latn-mal_Mlym",
        "languages": [
          "smo-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.005964,
        "recall": 0.008513,
        "f1": 0.006391,
        "accuracy": 0.008513,
        "main_score": 0.006391,
        "hf_subset": "smo_Latn-mlg_Latn",
        "languages": [
          "smo-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.021997,
        "recall": 0.029544,
        "f1": 0.023352,
        "accuracy": 0.029544,
        "main_score": 0.023352,
        "hf_subset": "smo_Latn-mri_Latn",
        "languages": [
          "smo-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.009065,
        "recall": 0.01302,
        "f1": 0.009513,
        "accuracy": 0.01302,
        "main_score": 0.009513,
        "hf_subset": "smo_Latn-msa_Latn",
        "languages": [
          "smo-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.017712,
        "recall": 0.027541,
        "f1": 0.01913,
        "accuracy": 0.027541,
        "main_score": 0.01913,
        "hf_subset": "smo_Latn-tah_Latn",
        "languages": [
          "smo-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.018018,
        "recall": 0.029544,
        "f1": 0.019961,
        "accuracy": 0.029544,
        "main_score": 0.019961,
        "hf_subset": "smo_Latn-ton_Latn",
        "languages": [
          "smo-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.012282,
        "recall": 0.018528,
        "f1": 0.013222,
        "accuracy": 0.018528,
        "main_score": 0.013222,
        "hf_subset": "sna_Latn-bem_Latn",
        "languages": [
          "sna-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.010257,
        "recall": 0.019029,
        "f1": 0.011195,
        "accuracy": 0.019029,
        "main_score": 0.011195,
        "hf_subset": "sna_Latn-eng_Latn",
        "languages": [
          "sna-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006445,
        "recall": 0.008513,
        "f1": 0.006655,
        "accuracy": 0.008513,
        "main_score": 0.006655,
        "hf_subset": "sna_Latn-ewe_Latn",
        "languages": [
          "sna-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.005346,
        "recall": 0.009014,
        "f1": 0.005715,
        "accuracy": 0.009014,
        "main_score": 0.005715,
        "hf_subset": "sna_Latn-fuc_Latn",
        "languages": [
          "sna-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.006956,
        "recall": 0.009014,
        "f1": 0.007369,
        "accuracy": 0.009014,
        "main_score": 0.007369,
        "hf_subset": "sna_Latn-kin_Latn",
        "languages": [
          "sna-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.010664,
        "recall": 0.015523,
        "f1": 0.011243,
        "accuracy": 0.015523,
        "main_score": 0.011243,
        "hf_subset": "sna_Latn-nde_Latn",
        "languages": [
          "sna-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.012231,
        "recall": 0.02003,
        "f1": 0.013486,
        "accuracy": 0.02003,
        "main_score": 0.013486,
        "hf_subset": "sna_Latn-nya_Latn",
        "languages": [
          "sna-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.009641,
        "recall": 0.015523,
        "f1": 0.010407,
        "accuracy": 0.015523,
        "main_score": 0.010407,
        "hf_subset": "sna_Latn-ven_Latn",
        "languages": [
          "sna-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.000753,
        "recall": 0.002003,
        "f1": 0.000838,
        "accuracy": 0.002003,
        "main_score": 0.000838,
        "hf_subset": "snd_Arab-ben_Beng",
        "languages": [
          "snd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "snd_Arab-div_Thaa",
        "languages": [
          "snd-Arab",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.001511,
        "recall": 0.003005,
        "f1": 0.001519,
        "accuracy": 0.003005,
        "main_score": 0.001519,
        "hf_subset": "snd_Arab-eng_Latn",
        "languages": [
          "snd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000261,
        "recall": 0.002003,
        "f1": 0.000354,
        "accuracy": 0.002003,
        "main_score": 0.000354,
        "hf_subset": "snd_Arab-eus_Latn",
        "languages": [
          "snd-Arab",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002504,
        "f1": 0.001504,
        "accuracy": 0.002504,
        "main_score": 0.001504,
        "hf_subset": "snd_Arab-guj_Gujr",
        "languages": [
          "snd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.001484,
        "recall": 0.004507,
        "f1": 0.001747,
        "accuracy": 0.004507,
        "main_score": 0.001747,
        "hf_subset": "snd_Arab-hin_Deva",
        "languages": [
          "snd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002003,
        "f1": 0.001006,
        "accuracy": 0.002003,
        "main_score": 0.001006,
        "hf_subset": "snd_Arab-kan_Knda",
        "languages": [
          "snd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000601,
        "recall": 0.001002,
        "f1": 0.000668,
        "accuracy": 0.001002,
        "main_score": 0.000668,
        "hf_subset": "snd_Arab-mar_Deva",
        "languages": [
          "snd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000631,
        "recall": 0.002003,
        "f1": 0.000711,
        "accuracy": 0.002003,
        "main_score": 0.000711,
        "hf_subset": "snd_Arab-nep_Deva",
        "languages": [
          "snd-Arab",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "snd_Arab-pan_Guru",
        "languages": [
          "snd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000753,
        "recall": 0.002003,
        "f1": 0.000839,
        "accuracy": 0.002003,
        "main_score": 0.000839,
        "hf_subset": "snd_Arab-sin_Sinh",
        "languages": [
          "snd-Arab",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "snd_Arab-tam_Taml",
        "languages": [
          "snd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000752,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "snd_Arab-tel_Telu",
        "languages": [
          "snd-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003396,
        "recall": 0.011017,
        "f1": 0.004132,
        "accuracy": 0.011017,
        "main_score": 0.004132,
        "hf_subset": "snd_Arab-urd_Arab",
        "languages": [
          "snd-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.006275,
        "recall": 0.010516,
        "f1": 0.006796,
        "accuracy": 0.010516,
        "main_score": 0.006796,
        "hf_subset": "som_Latn-amh_Ethi",
        "languages": [
          "som-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.014497,
        "recall": 0.024036,
        "f1": 0.015604,
        "accuracy": 0.024036,
        "main_score": 0.015604,
        "hf_subset": "som_Latn-eng_Latn",
        "languages": [
          "som-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012173,
        "recall": 0.015523,
        "f1": 0.012511,
        "accuracy": 0.015523,
        "main_score": 0.012511,
        "hf_subset": "som_Latn-hau_Latn",
        "languages": [
          "som-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.009413,
        "recall": 0.01352,
        "f1": 0.010029,
        "accuracy": 0.01352,
        "main_score": 0.010029,
        "hf_subset": "som_Latn-ibo_Latn",
        "languages": [
          "som-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.007534,
        "recall": 0.009514,
        "f1": 0.007781,
        "accuracy": 0.009514,
        "main_score": 0.007781,
        "hf_subset": "som_Latn-nso_Latn",
        "languages": [
          "som-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.00517,
        "recall": 0.007011,
        "f1": 0.005297,
        "accuracy": 0.007011,
        "main_score": 0.005297,
        "hf_subset": "som_Latn-orm_Ethi",
        "languages": [
          "som-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.008645,
        "recall": 0.01352,
        "f1": 0.009385,
        "accuracy": 0.01352,
        "main_score": 0.009385,
        "hf_subset": "som_Latn-ssw_Latn",
        "languages": [
          "som-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.011541,
        "recall": 0.015023,
        "f1": 0.012027,
        "accuracy": 0.015023,
        "main_score": 0.012027,
        "hf_subset": "som_Latn-swa_Latn",
        "languages": [
          "som-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.003868,
        "recall": 0.00651,
        "f1": 0.004045,
        "accuracy": 0.00651,
        "main_score": 0.004045,
        "hf_subset": "som_Latn-tir_Ethi",
        "languages": [
          "som-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.006177,
        "recall": 0.010015,
        "f1": 0.006485,
        "accuracy": 0.010015,
        "main_score": 0.006485,
        "hf_subset": "som_Latn-tsn_Latn",
        "languages": [
          "som-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.006757,
        "recall": 0.009014,
        "f1": 0.006911,
        "accuracy": 0.009014,
        "main_score": 0.006911,
        "hf_subset": "som_Latn-wol_Latn",
        "languages": [
          "som-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.007267,
        "recall": 0.008513,
        "f1": 0.007357,
        "accuracy": 0.008513,
        "main_score": 0.007357,
        "hf_subset": "som_Latn-xho_Latn",
        "languages": [
          "som-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.008286,
        "recall": 0.012018,
        "f1": 0.009034,
        "accuracy": 0.012018,
        "main_score": 0.009034,
        "hf_subset": "som_Latn-yor_Latn",
        "languages": [
          "som-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.009174,
        "recall": 0.015023,
        "f1": 0.009953,
        "accuracy": 0.015023,
        "main_score": 0.009953,
        "hf_subset": "som_Latn-zul_Latn",
        "languages": [
          "som-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 4.7e-05,
        "recall": 0.001002,
        "f1": 8.7e-05,
        "accuracy": 0.001002,
        "main_score": 8.7e-05,
        "hf_subset": "spa_Latn-arb_Arab",
        "languages": [
          "spa-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.00074,
        "recall": 0.003005,
        "f1": 0.000922,
        "accuracy": 0.003005,
        "main_score": 0.000922,
        "hf_subset": "spa_Latn-ben_Beng",
        "languages": [
          "spa-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.274331,
        "recall": 0.342514,
        "f1": 0.288646,
        "accuracy": 0.342514,
        "main_score": 0.288646,
        "hf_subset": "spa_Latn-cat_Latn",
        "languages": [
          "spa-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.027459,
        "recall": 0.04006,
        "f1": 0.029288,
        "accuracy": 0.04006,
        "main_score": 0.029288,
        "hf_subset": "spa_Latn-deu_Latn",
        "languages": [
          "spa-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.002003,
        "f1": 0.001169,
        "accuracy": 0.002003,
        "main_score": 0.001169,
        "hf_subset": "spa_Latn-ell_Grek",
        "languages": [
          "spa-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.038445,
        "recall": 0.049574,
        "f1": 0.040221,
        "accuracy": 0.049574,
        "main_score": 0.040221,
        "hf_subset": "spa_Latn-eng_Latn",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002477,
        "recall": 0.006009,
        "f1": 0.002764,
        "accuracy": 0.006009,
        "main_score": 0.002764,
        "hf_subset": "spa_Latn-fas_Arab",
        "languages": [
          "spa-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.013548,
        "recall": 0.018528,
        "f1": 0.014311,
        "accuracy": 0.018528,
        "main_score": 0.014311,
        "hf_subset": "spa_Latn-fin_Latn",
        "languages": [
          "spa-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.075566,
        "recall": 0.110165,
        "f1": 0.08108,
        "accuracy": 0.110165,
        "main_score": 0.08108,
        "hf_subset": "spa_Latn-fra_Latn",
        "languages": [
          "spa-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.532229,
        "recall": 0.611417,
        "f1": 0.551804,
        "accuracy": 0.611417,
        "main_score": 0.551804,
        "hf_subset": "spa_Latn-glg_Latn",
        "languages": [
          "spa-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.001522,
        "recall": 0.003005,
        "f1": 0.00176,
        "accuracy": 0.003005,
        "main_score": 0.00176,
        "hf_subset": "spa_Latn-heb_Hebr",
        "languages": [
          "spa-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000503,
        "accuracy": 0.001502,
        "main_score": 0.000503,
        "hf_subset": "spa_Latn-hin_Deva",
        "languages": [
          "spa-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015899,
        "recall": 0.024537,
        "f1": 0.017063,
        "accuracy": 0.024537,
        "main_score": 0.017063,
        "hf_subset": "spa_Latn-hun_Latn",
        "languages": [
          "spa-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.018098,
        "recall": 0.025538,
        "f1": 0.019246,
        "accuracy": 0.025538,
        "main_score": 0.019246,
        "hf_subset": "spa_Latn-ind_Latn",
        "languages": [
          "spa-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.102004,
        "recall": 0.129695,
        "f1": 0.107724,
        "accuracy": 0.129695,
        "main_score": 0.107724,
        "hf_subset": "spa_Latn-ita_Latn",
        "languages": [
          "spa-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.001208,
        "recall": 0.005508,
        "f1": 0.001576,
        "accuracy": 0.005508,
        "main_score": 0.001576,
        "hf_subset": "spa_Latn-jpn_Jpan",
        "languages": [
          "spa-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.002165,
        "recall": 0.006009,
        "f1": 0.002586,
        "accuracy": 0.006009,
        "main_score": 0.002586,
        "hf_subset": "spa_Latn-kor_Hang",
        "languages": [
          "spa-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.009266,
        "recall": 0.017026,
        "f1": 0.010125,
        "accuracy": 0.017026,
        "main_score": 0.010125,
        "hf_subset": "spa_Latn-lit_Latn",
        "languages": [
          "spa-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.021407,
        "recall": 0.032549,
        "f1": 0.02311,
        "accuracy": 0.032549,
        "main_score": 0.02311,
        "hf_subset": "spa_Latn-mlt_Latn",
        "languages": [
          "spa-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.030669,
        "recall": 0.046069,
        "f1": 0.032753,
        "accuracy": 0.046069,
        "main_score": 0.032753,
        "hf_subset": "spa_Latn-nld_Latn",
        "languages": [
          "spa-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.016149,
        "recall": 0.024537,
        "f1": 0.017677,
        "accuracy": 0.024537,
        "main_score": 0.017677,
        "hf_subset": "spa_Latn-pol_Latn",
        "languages": [
          "spa-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.295314,
        "recall": 0.367051,
        "f1": 0.310887,
        "accuracy": 0.367051,
        "main_score": 0.310887,
        "hf_subset": "spa_Latn-por_Latn",
        "languages": [
          "spa-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.046096,
        "recall": 0.064597,
        "f1": 0.04955,
        "accuracy": 0.064597,
        "main_score": 0.04955,
        "hf_subset": "spa_Latn-ron_Latn",
        "languages": [
          "spa-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.000447,
        "recall": 0.003005,
        "f1": 0.000677,
        "accuracy": 0.003005,
        "main_score": 0.000677,
        "hf_subset": "spa_Latn-rus_Cyrl",
        "languages": [
          "spa-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.007365,
        "recall": 0.012018,
        "f1": 0.00798,
        "accuracy": 0.012018,
        "main_score": 0.00798,
        "hf_subset": "spa_Latn-swa_Latn",
        "languages": [
          "spa-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.025031,
        "recall": 0.034552,
        "f1": 0.026381,
        "accuracy": 0.034552,
        "main_score": 0.026381,
        "hf_subset": "spa_Latn-swe_Latn",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001062,
        "recall": 0.003005,
        "f1": 0.001111,
        "accuracy": 0.003005,
        "main_score": 0.001111,
        "hf_subset": "spa_Latn-tam_Taml",
        "languages": [
          "spa-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.011128,
        "recall": 0.015523,
        "f1": 0.011818,
        "accuracy": 0.015523,
        "main_score": 0.011818,
        "hf_subset": "spa_Latn-tur_Latn",
        "languages": [
          "spa-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.012271,
        "recall": 0.020531,
        "f1": 0.013129,
        "accuracy": 0.020531,
        "main_score": 0.013129,
        "hf_subset": "spa_Latn-vie_Latn",
        "languages": [
          "spa-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.018786,
        "recall": 0.027541,
        "f1": 0.019829,
        "accuracy": 0.027541,
        "main_score": 0.019829,
        "hf_subset": "spa_Latn-zho_Hant",
        "languages": [
          "spa-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.014617,
        "recall": 0.020531,
        "f1": 0.015314,
        "accuracy": 0.020531,
        "main_score": 0.015314,
        "hf_subset": "spa_Latn-zul_Latn",
        "languages": [
          "spa-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000556,
        "recall": 0.002003,
        "f1": 0.000604,
        "accuracy": 0.002003,
        "main_score": 0.000604,
        "hf_subset": "sqi_Latn-ell_Grek",
        "languages": [
          "sqi-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.024185,
        "recall": 0.036555,
        "f1": 0.025931,
        "accuracy": 0.036555,
        "main_score": 0.025931,
        "hf_subset": "sqi_Latn-eng_Latn",
        "languages": [
          "sqi-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000856,
        "recall": 0.004507,
        "f1": 0.001274,
        "accuracy": 0.004507,
        "main_score": 0.001274,
        "hf_subset": "sqi_Latn-hye_Armn",
        "languages": [
          "sqi-Latn",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.000761,
        "recall": 0.002504,
        "f1": 0.000853,
        "accuracy": 0.002504,
        "main_score": 0.000853,
        "hf_subset": "sqi_Latn-kat_Geor",
        "languages": [
          "sqi-Latn",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.007495,
        "recall": 0.017026,
        "f1": 0.008653,
        "accuracy": 0.017026,
        "main_score": 0.008653,
        "hf_subset": "srp_Cyrl-bel_Cyrl",
        "languages": [
          "srp-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.008268,
        "recall": 0.01352,
        "f1": 0.008812,
        "accuracy": 0.01352,
        "main_score": 0.008812,
        "hf_subset": "srp_Cyrl-bos_Latn",
        "languages": [
          "srp-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.023171,
        "recall": 0.036555,
        "f1": 0.025617,
        "accuracy": 0.036555,
        "main_score": 0.025617,
        "hf_subset": "srp_Cyrl-bul_Cyrl",
        "languages": [
          "srp-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.00235,
        "recall": 0.005008,
        "f1": 0.002516,
        "accuracy": 0.005008,
        "main_score": 0.002516,
        "hf_subset": "srp_Cyrl-ces_Latn",
        "languages": [
          "srp-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.001057,
        "recall": 0.002003,
        "f1": 0.001102,
        "accuracy": 0.002003,
        "main_score": 0.001102,
        "hf_subset": "srp_Cyrl-eng_Latn",
        "languages": [
          "srp-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004226,
        "recall": 0.009014,
        "f1": 0.004417,
        "accuracy": 0.009014,
        "main_score": 0.004417,
        "hf_subset": "srp_Cyrl-hrv_Latn",
        "languages": [
          "srp-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.067899,
        "recall": 0.099649,
        "f1": 0.074313,
        "accuracy": 0.099649,
        "main_score": 0.074313,
        "hf_subset": "srp_Cyrl-mkd_Cyrl",
        "languages": [
          "srp-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.002066,
        "recall": 0.003505,
        "f1": 0.002117,
        "accuracy": 0.003505,
        "main_score": 0.002117,
        "hf_subset": "srp_Cyrl-pol_Latn",
        "languages": [
          "srp-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.022714,
        "recall": 0.041062,
        "f1": 0.025203,
        "accuracy": 0.041062,
        "main_score": 0.025203,
        "hf_subset": "srp_Cyrl-rus_Cyrl",
        "languages": [
          "srp-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.002516,
        "recall": 0.004006,
        "f1": 0.002527,
        "accuracy": 0.004006,
        "main_score": 0.002527,
        "hf_subset": "srp_Cyrl-slk_Latn",
        "languages": [
          "srp-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.001661,
        "recall": 0.003505,
        "f1": 0.001776,
        "accuracy": 0.003505,
        "main_score": 0.001776,
        "hf_subset": "srp_Cyrl-slv_Latn",
        "languages": [
          "srp-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.012528,
        "recall": 0.020531,
        "f1": 0.013494,
        "accuracy": 0.020531,
        "main_score": 0.013494,
        "hf_subset": "srp_Cyrl-srp_Latn",
        "languages": [
          "srp-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.007202,
        "recall": 0.014522,
        "f1": 0.007933,
        "accuracy": 0.014522,
        "main_score": 0.007933,
        "hf_subset": "srp_Cyrl-ukr_Cyrl",
        "languages": [
          "srp-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.00309,
        "recall": 0.008513,
        "f1": 0.00378,
        "accuracy": 0.008513,
        "main_score": 0.00378,
        "hf_subset": "srp_Latn-bel_Cyrl",
        "languages": [
          "srp-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.739411,
        "recall": 0.807211,
        "f1": 0.759121,
        "accuracy": 0.807211,
        "main_score": 0.759121,
        "hf_subset": "srp_Latn-bos_Latn",
        "languages": [
          "srp-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.00282,
        "recall": 0.011017,
        "f1": 0.003621,
        "accuracy": 0.011017,
        "main_score": 0.003621,
        "hf_subset": "srp_Latn-bul_Cyrl",
        "languages": [
          "srp-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.036891,
        "recall": 0.051577,
        "f1": 0.039455,
        "accuracy": 0.051577,
        "main_score": 0.039455,
        "hf_subset": "srp_Latn-ces_Latn",
        "languages": [
          "srp-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.005753,
        "recall": 0.008513,
        "f1": 0.006152,
        "accuracy": 0.008513,
        "main_score": 0.006152,
        "hf_subset": "srp_Latn-eng_Latn",
        "languages": [
          "srp-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.569045,
        "recall": 0.652979,
        "f1": 0.591926,
        "accuracy": 0.652979,
        "main_score": 0.591926,
        "hf_subset": "srp_Latn-hrv_Latn",
        "languages": [
          "srp-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.005029,
        "recall": 0.018528,
        "f1": 0.006263,
        "accuracy": 0.018528,
        "main_score": 0.006263,
        "hf_subset": "srp_Latn-mkd_Cyrl",
        "languages": [
          "srp-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.009524,
        "recall": 0.015523,
        "f1": 0.010309,
        "accuracy": 0.015523,
        "main_score": 0.010309,
        "hf_subset": "srp_Latn-pol_Latn",
        "languages": [
          "srp-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.002695,
        "recall": 0.008513,
        "f1": 0.003328,
        "accuracy": 0.008513,
        "main_score": 0.003328,
        "hf_subset": "srp_Latn-rus_Cyrl",
        "languages": [
          "srp-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.035309,
        "recall": 0.049574,
        "f1": 0.037412,
        "accuracy": 0.049574,
        "main_score": 0.037412,
        "hf_subset": "srp_Latn-slk_Latn",
        "languages": [
          "srp-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.136217,
        "recall": 0.185278,
        "f1": 0.146123,
        "accuracy": 0.185278,
        "main_score": 0.146123,
        "hf_subset": "srp_Latn-slv_Latn",
        "languages": [
          "srp-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.027881,
        "recall": 0.061592,
        "f1": 0.032464,
        "accuracy": 0.061592,
        "main_score": 0.032464,
        "hf_subset": "srp_Latn-srp_Cyrl",
        "languages": [
          "srp-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.001764,
        "recall": 0.007511,
        "f1": 0.00225,
        "accuracy": 0.007511,
        "main_score": 0.00225,
        "hf_subset": "srp_Latn-ukr_Cyrl",
        "languages": [
          "srp-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.006871,
        "recall": 0.01352,
        "f1": 0.007661,
        "accuracy": 0.01352,
        "main_score": 0.007661,
        "hf_subset": "ssw_Latn-amh_Ethi",
        "languages": [
          "ssw-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.018896,
        "recall": 0.02654,
        "f1": 0.019656,
        "accuracy": 0.02654,
        "main_score": 0.019656,
        "hf_subset": "ssw_Latn-eng_Latn",
        "languages": [
          "ssw-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008916,
        "recall": 0.014021,
        "f1": 0.009738,
        "accuracy": 0.014021,
        "main_score": 0.009738,
        "hf_subset": "ssw_Latn-hau_Latn",
        "languages": [
          "ssw-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.011615,
        "recall": 0.016024,
        "f1": 0.012183,
        "accuracy": 0.016024,
        "main_score": 0.012183,
        "hf_subset": "ssw_Latn-ibo_Latn",
        "languages": [
          "ssw-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.015901,
        "recall": 0.021532,
        "f1": 0.016817,
        "accuracy": 0.021532,
        "main_score": 0.016817,
        "hf_subset": "ssw_Latn-nso_Latn",
        "languages": [
          "ssw-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.006151,
        "recall": 0.008513,
        "f1": 0.006482,
        "accuracy": 0.008513,
        "main_score": 0.006482,
        "hf_subset": "ssw_Latn-orm_Ethi",
        "languages": [
          "ssw-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.007275,
        "recall": 0.009514,
        "f1": 0.007539,
        "accuracy": 0.009514,
        "main_score": 0.007539,
        "hf_subset": "ssw_Latn-som_Latn",
        "languages": [
          "ssw-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.014045,
        "recall": 0.019029,
        "f1": 0.014886,
        "accuracy": 0.019029,
        "main_score": 0.014886,
        "hf_subset": "ssw_Latn-swa_Latn",
        "languages": [
          "ssw-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.003077,
        "recall": 0.005508,
        "f1": 0.003139,
        "accuracy": 0.005508,
        "main_score": 0.003139,
        "hf_subset": "ssw_Latn-tir_Ethi",
        "languages": [
          "ssw-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.013276,
        "recall": 0.017026,
        "f1": 0.013695,
        "accuracy": 0.017026,
        "main_score": 0.013695,
        "hf_subset": "ssw_Latn-tsn_Latn",
        "languages": [
          "ssw-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.006509,
        "recall": 0.009014,
        "f1": 0.006777,
        "accuracy": 0.009014,
        "main_score": 0.006777,
        "hf_subset": "ssw_Latn-wol_Latn",
        "languages": [
          "ssw-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.060808,
        "recall": 0.086129,
        "f1": 0.065557,
        "accuracy": 0.086129,
        "main_score": 0.065557,
        "hf_subset": "ssw_Latn-xho_Latn",
        "languages": [
          "ssw-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.010457,
        "recall": 0.014522,
        "f1": 0.011158,
        "accuracy": 0.014522,
        "main_score": 0.011158,
        "hf_subset": "ssw_Latn-yor_Latn",
        "languages": [
          "ssw-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.126664,
        "recall": 0.176264,
        "f1": 0.136329,
        "accuracy": 0.176264,
        "main_score": 0.136329,
        "hf_subset": "ssw_Latn-zul_Latn",
        "languages": [
          "ssw-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.004238,
        "recall": 0.009514,
        "f1": 0.004669,
        "accuracy": 0.009514,
        "main_score": 0.004669,
        "hf_subset": "swa_Latn-amh_Ethi",
        "languages": [
          "swa-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.000272,
        "recall": 0.001002,
        "f1": 0.000376,
        "accuracy": 0.001002,
        "main_score": 0.000376,
        "hf_subset": "swa_Latn-arb_Arab",
        "languages": [
          "swa-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001502,
        "recall": 0.001502,
        "f1": 0.001502,
        "accuracy": 0.001502,
        "main_score": 0.001502,
        "hf_subset": "swa_Latn-ben_Beng",
        "languages": [
          "swa-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.01038,
        "recall": 0.014522,
        "f1": 0.010937,
        "accuracy": 0.014522,
        "main_score": 0.010937,
        "hf_subset": "swa_Latn-deu_Latn",
        "languages": [
          "swa-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 3.2e-05,
        "recall": 0.001502,
        "f1": 6.2e-05,
        "accuracy": 0.001502,
        "main_score": 6.2e-05,
        "hf_subset": "swa_Latn-ell_Grek",
        "languages": [
          "swa-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.013304,
        "recall": 0.024036,
        "f1": 0.014533,
        "accuracy": 0.024036,
        "main_score": 0.014533,
        "hf_subset": "swa_Latn-eng_Latn",
        "languages": [
          "swa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002414,
        "recall": 0.007011,
        "f1": 0.00269,
        "accuracy": 0.007011,
        "main_score": 0.00269,
        "hf_subset": "swa_Latn-fas_Arab",
        "languages": [
          "swa-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.006723,
        "recall": 0.009014,
        "f1": 0.007014,
        "accuracy": 0.009014,
        "main_score": 0.007014,
        "hf_subset": "swa_Latn-fin_Latn",
        "languages": [
          "swa-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.006115,
        "recall": 0.012018,
        "f1": 0.006471,
        "accuracy": 0.012018,
        "main_score": 0.006471,
        "hf_subset": "swa_Latn-fra_Latn",
        "languages": [
          "swa-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.006349,
        "recall": 0.008513,
        "f1": 0.006674,
        "accuracy": 0.008513,
        "main_score": 0.006674,
        "hf_subset": "swa_Latn-hau_Latn",
        "languages": [
          "swa-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.000512,
        "recall": 0.001502,
        "f1": 0.000523,
        "accuracy": 0.001502,
        "main_score": 0.000523,
        "hf_subset": "swa_Latn-heb_Hebr",
        "languages": [
          "swa-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000636,
        "recall": 0.002504,
        "f1": 0.000736,
        "accuracy": 0.002504,
        "main_score": 0.000736,
        "hf_subset": "swa_Latn-hin_Deva",
        "languages": [
          "swa-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.007142,
        "recall": 0.009514,
        "f1": 0.007578,
        "accuracy": 0.009514,
        "main_score": 0.007578,
        "hf_subset": "swa_Latn-hun_Latn",
        "languages": [
          "swa-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.008891,
        "recall": 0.012018,
        "f1": 0.009327,
        "accuracy": 0.012018,
        "main_score": 0.009327,
        "hf_subset": "swa_Latn-ibo_Latn",
        "languages": [
          "swa-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.006645,
        "recall": 0.011017,
        "f1": 0.007174,
        "accuracy": 0.011017,
        "main_score": 0.007174,
        "hf_subset": "swa_Latn-ind_Latn",
        "languages": [
          "swa-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001034,
        "recall": 0.002003,
        "f1": 0.001062,
        "accuracy": 0.002003,
        "main_score": 0.001062,
        "hf_subset": "swa_Latn-jpn_Jpan",
        "languages": [
          "swa-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000769,
        "recall": 0.004006,
        "f1": 0.000973,
        "accuracy": 0.004006,
        "main_score": 0.000973,
        "hf_subset": "swa_Latn-kor_Hang",
        "languages": [
          "swa-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.003236,
        "recall": 0.006009,
        "f1": 0.003411,
        "accuracy": 0.006009,
        "main_score": 0.003411,
        "hf_subset": "swa_Latn-lit_Latn",
        "languages": [
          "swa-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.005044,
        "recall": 0.007511,
        "f1": 0.005245,
        "accuracy": 0.007511,
        "main_score": 0.005245,
        "hf_subset": "swa_Latn-nld_Latn",
        "languages": [
          "swa-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.008174,
        "recall": 0.012018,
        "f1": 0.008638,
        "accuracy": 0.012018,
        "main_score": 0.008638,
        "hf_subset": "swa_Latn-nso_Latn",
        "languages": [
          "swa-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.005134,
        "recall": 0.006009,
        "f1": 0.00521,
        "accuracy": 0.006009,
        "main_score": 0.00521,
        "hf_subset": "swa_Latn-orm_Ethi",
        "languages": [
          "swa-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.005467,
        "recall": 0.007511,
        "f1": 0.005877,
        "accuracy": 0.007511,
        "main_score": 0.005877,
        "hf_subset": "swa_Latn-pol_Latn",
        "languages": [
          "swa-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.010344,
        "recall": 0.01302,
        "f1": 0.010713,
        "accuracy": 0.01302,
        "main_score": 0.010713,
        "hf_subset": "swa_Latn-por_Latn",
        "languages": [
          "swa-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000655,
        "recall": 0.002003,
        "f1": 0.000757,
        "accuracy": 0.002003,
        "main_score": 0.000757,
        "hf_subset": "swa_Latn-rus_Cyrl",
        "languages": [
          "swa-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.006204,
        "recall": 0.009514,
        "f1": 0.006535,
        "accuracy": 0.009514,
        "main_score": 0.006535,
        "hf_subset": "swa_Latn-som_Latn",
        "languages": [
          "swa-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.009022,
        "recall": 0.012519,
        "f1": 0.009565,
        "accuracy": 0.012519,
        "main_score": 0.009565,
        "hf_subset": "swa_Latn-spa_Latn",
        "languages": [
          "swa-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.006866,
        "recall": 0.010015,
        "f1": 0.007206,
        "accuracy": 0.010015,
        "main_score": 0.007206,
        "hf_subset": "swa_Latn-ssw_Latn",
        "languages": [
          "swa-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.006894,
        "recall": 0.01302,
        "f1": 0.007167,
        "accuracy": 0.01302,
        "main_score": 0.007167,
        "hf_subset": "swa_Latn-swe_Latn",
        "languages": [
          "swa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000507,
        "recall": 0.002003,
        "f1": 0.000514,
        "accuracy": 0.002003,
        "main_score": 0.000514,
        "hf_subset": "swa_Latn-tam_Taml",
        "languages": [
          "swa-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001947,
        "recall": 0.007511,
        "f1": 0.002192,
        "accuracy": 0.007511,
        "main_score": 0.002192,
        "hf_subset": "swa_Latn-tir_Ethi",
        "languages": [
          "swa-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.008569,
        "recall": 0.01352,
        "f1": 0.009241,
        "accuracy": 0.01352,
        "main_score": 0.009241,
        "hf_subset": "swa_Latn-tsn_Latn",
        "languages": [
          "swa-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.008052,
        "recall": 0.011517,
        "f1": 0.008549,
        "accuracy": 0.011517,
        "main_score": 0.008549,
        "hf_subset": "swa_Latn-tur_Latn",
        "languages": [
          "swa-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.005497,
        "recall": 0.009514,
        "f1": 0.00578,
        "accuracy": 0.009514,
        "main_score": 0.00578,
        "hf_subset": "swa_Latn-vie_Latn",
        "languages": [
          "swa-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.004271,
        "recall": 0.005508,
        "f1": 0.004369,
        "accuracy": 0.005508,
        "main_score": 0.004369,
        "hf_subset": "swa_Latn-wol_Latn",
        "languages": [
          "swa-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.007885,
        "recall": 0.010015,
        "f1": 0.008137,
        "accuracy": 0.010015,
        "main_score": 0.008137,
        "hf_subset": "swa_Latn-xho_Latn",
        "languages": [
          "swa-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.006426,
        "recall": 0.007011,
        "f1": 0.006593,
        "accuracy": 0.007011,
        "main_score": 0.006593,
        "hf_subset": "swa_Latn-yor_Latn",
        "languages": [
          "swa-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.010772,
        "recall": 0.018528,
        "f1": 0.011556,
        "accuracy": 0.018528,
        "main_score": 0.011556,
        "hf_subset": "swa_Latn-zho_Hant",
        "languages": [
          "swa-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.010936,
        "recall": 0.014021,
        "f1": 0.011163,
        "accuracy": 0.014021,
        "main_score": 0.011163,
        "hf_subset": "swa_Latn-zul_Latn",
        "languages": [
          "swa-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.072811,
        "recall": 0.100651,
        "f1": 0.077758,
        "accuracy": 0.100651,
        "main_score": 0.077758,
        "hf_subset": "swe_Latn-afr_Latn",
        "languages": [
          "swe-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 6.8e-05,
        "recall": 0.001002,
        "f1": 0.000121,
        "accuracy": 0.001002,
        "main_score": 0.000121,
        "hf_subset": "swe_Latn-arb_Arab",
        "languages": [
          "swe-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000641,
        "recall": 0.002003,
        "f1": 0.000743,
        "accuracy": 0.002003,
        "main_score": 0.000743,
        "hf_subset": "swe_Latn-ben_Beng",
        "languages": [
          "swe-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.290858,
        "recall": 0.354532,
        "f1": 0.304817,
        "accuracy": 0.354532,
        "main_score": 0.304817,
        "hf_subset": "swe_Latn-dan_Latn",
        "languages": [
          "swe-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.073067,
        "recall": 0.103155,
        "f1": 0.079334,
        "accuracy": 0.103155,
        "main_score": 0.079334,
        "hf_subset": "swe_Latn-deu_Latn",
        "languages": [
          "swe-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.001386,
        "recall": 0.005508,
        "f1": 0.001807,
        "accuracy": 0.005508,
        "main_score": 0.001807,
        "hf_subset": "swe_Latn-ell_Grek",
        "languages": [
          "swe-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.074322,
        "recall": 0.097146,
        "f1": 0.077261,
        "accuracy": 0.097146,
        "main_score": 0.077261,
        "hf_subset": "swe_Latn-eng_Latn",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.086047,
        "recall": 0.114171,
        "f1": 0.091231,
        "accuracy": 0.114171,
        "main_score": 0.091231,
        "hf_subset": "swe_Latn-fao_Latn",
        "languages": [
          "swe-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.002523,
        "recall": 0.005508,
        "f1": 0.002772,
        "accuracy": 0.005508,
        "main_score": 0.002772,
        "hf_subset": "swe_Latn-fas_Arab",
        "languages": [
          "swe-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.037954,
        "recall": 0.05308,
        "f1": 0.040988,
        "accuracy": 0.05308,
        "main_score": 0.040988,
        "hf_subset": "swe_Latn-fin_Latn",
        "languages": [
          "swe-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.044992,
        "recall": 0.066099,
        "f1": 0.047952,
        "accuracy": 0.066099,
        "main_score": 0.047952,
        "hf_subset": "swe_Latn-fra_Latn",
        "languages": [
          "swe-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.001154,
        "recall": 0.004006,
        "f1": 0.001518,
        "accuracy": 0.004006,
        "main_score": 0.001518,
        "hf_subset": "swe_Latn-heb_Hebr",
        "languages": [
          "swe-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000803,
        "recall": 0.003505,
        "f1": 0.001012,
        "accuracy": 0.003505,
        "main_score": 0.001012,
        "hf_subset": "swe_Latn-hin_Deva",
        "languages": [
          "swe-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.033429,
        "recall": 0.044066,
        "f1": 0.035717,
        "accuracy": 0.044066,
        "main_score": 0.035717,
        "hf_subset": "swe_Latn-hun_Latn",
        "languages": [
          "swe-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.033331,
        "recall": 0.046069,
        "f1": 0.035473,
        "accuracy": 0.046069,
        "main_score": 0.035473,
        "hf_subset": "swe_Latn-ind_Latn",
        "languages": [
          "swe-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.047766,
        "recall": 0.072609,
        "f1": 0.051778,
        "accuracy": 0.072609,
        "main_score": 0.051778,
        "hf_subset": "swe_Latn-isl_Latn",
        "languages": [
          "swe-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.001898,
        "recall": 0.006009,
        "f1": 0.002189,
        "accuracy": 0.006009,
        "main_score": 0.002189,
        "hf_subset": "swe_Latn-jpn_Jpan",
        "languages": [
          "swe-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001823,
        "recall": 0.007011,
        "f1": 0.00227,
        "accuracy": 0.007011,
        "main_score": 0.00227,
        "hf_subset": "swe_Latn-kor_Hang",
        "languages": [
          "swe-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.024838,
        "recall": 0.038558,
        "f1": 0.026767,
        "accuracy": 0.038558,
        "main_score": 0.026767,
        "hf_subset": "swe_Latn-lit_Latn",
        "languages": [
          "swe-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.074788,
        "recall": 0.103655,
        "f1": 0.080075,
        "accuracy": 0.103655,
        "main_score": 0.080075,
        "hf_subset": "swe_Latn-ltz_Latn",
        "languages": [
          "swe-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.070108,
        "recall": 0.096144,
        "f1": 0.074818,
        "accuracy": 0.096144,
        "main_score": 0.074818,
        "hf_subset": "swe_Latn-nld_Latn",
        "languages": [
          "swe-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.314222,
        "recall": 0.395093,
        "f1": 0.332795,
        "accuracy": 0.395093,
        "main_score": 0.332795,
        "hf_subset": "swe_Latn-nno_Latn",
        "languages": [
          "swe-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.349277,
        "recall": 0.431147,
        "f1": 0.368089,
        "accuracy": 0.431147,
        "main_score": 0.368089,
        "hf_subset": "swe_Latn-nob_Latn",
        "languages": [
          "swe-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.024651,
        "recall": 0.037056,
        "f1": 0.026673,
        "accuracy": 0.037056,
        "main_score": 0.026673,
        "hf_subset": "swe_Latn-pol_Latn",
        "languages": [
          "swe-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.041419,
        "recall": 0.061092,
        "f1": 0.045144,
        "accuracy": 0.061092,
        "main_score": 0.045144,
        "hf_subset": "swe_Latn-por_Latn",
        "languages": [
          "swe-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000814,
        "recall": 0.005008,
        "f1": 0.001064,
        "accuracy": 0.005008,
        "main_score": 0.001064,
        "hf_subset": "swe_Latn-rus_Cyrl",
        "languages": [
          "swe-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.037251,
        "recall": 0.05308,
        "f1": 0.039774,
        "accuracy": 0.05308,
        "main_score": 0.039774,
        "hf_subset": "swe_Latn-spa_Latn",
        "languages": [
          "swe-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.017336,
        "recall": 0.028042,
        "f1": 0.019026,
        "accuracy": 0.028042,
        "main_score": 0.019026,
        "hf_subset": "swe_Latn-swa_Latn",
        "languages": [
          "swe-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001952,
        "recall": 0.005008,
        "f1": 0.002227,
        "accuracy": 0.005008,
        "main_score": 0.002227,
        "hf_subset": "swe_Latn-tam_Taml",
        "languages": [
          "swe-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.016379,
        "recall": 0.02654,
        "f1": 0.018255,
        "accuracy": 0.02654,
        "main_score": 0.018255,
        "hf_subset": "swe_Latn-tur_Latn",
        "languages": [
          "swe-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.019236,
        "recall": 0.029044,
        "f1": 0.020531,
        "accuracy": 0.029044,
        "main_score": 0.020531,
        "hf_subset": "swe_Latn-vie_Latn",
        "languages": [
          "swe-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.028203,
        "recall": 0.049074,
        "f1": 0.031425,
        "accuracy": 0.049074,
        "main_score": 0.031425,
        "hf_subset": "swe_Latn-zho_Hant",
        "languages": [
          "swe-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.025679,
        "recall": 0.042063,
        "f1": 0.028255,
        "accuracy": 0.042063,
        "main_score": 0.028255,
        "hf_subset": "swe_Latn-zul_Latn",
        "languages": [
          "swe-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.018,
        "recall": 0.024036,
        "f1": 0.018439,
        "accuracy": 0.024036,
        "main_score": 0.018439,
        "hf_subset": "tah_Latn-eng_Latn",
        "languages": [
          "tah-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00457,
        "recall": 0.007011,
        "f1": 0.004794,
        "accuracy": 0.007011,
        "main_score": 0.004794,
        "hf_subset": "tah_Latn-fij_Latn",
        "languages": [
          "tah-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.004793,
        "recall": 0.007011,
        "f1": 0.004987,
        "accuracy": 0.007011,
        "main_score": 0.004987,
        "hf_subset": "tah_Latn-fil_Latn",
        "languages": [
          "tah-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.004571,
        "recall": 0.007511,
        "f1": 0.005002,
        "accuracy": 0.007511,
        "main_score": 0.005002,
        "hf_subset": "tah_Latn-ind_Latn",
        "languages": [
          "tah-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001169,
        "recall": 0.002504,
        "f1": 0.001254,
        "accuracy": 0.002504,
        "main_score": 0.001254,
        "hf_subset": "tah_Latn-mal_Mlym",
        "languages": [
          "tah-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.006771,
        "recall": 0.008012,
        "f1": 0.006924,
        "accuracy": 0.008012,
        "main_score": 0.006924,
        "hf_subset": "tah_Latn-mlg_Latn",
        "languages": [
          "tah-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.011778,
        "recall": 0.018027,
        "f1": 0.012429,
        "accuracy": 0.018027,
        "main_score": 0.012429,
        "hf_subset": "tah_Latn-mri_Latn",
        "languages": [
          "tah-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.004737,
        "recall": 0.00651,
        "f1": 0.005037,
        "accuracy": 0.00651,
        "main_score": 0.005037,
        "hf_subset": "tah_Latn-msa_Latn",
        "languages": [
          "tah-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.004804,
        "recall": 0.00651,
        "f1": 0.004928,
        "accuracy": 0.00651,
        "main_score": 0.004928,
        "hf_subset": "tah_Latn-smo_Latn",
        "languages": [
          "tah-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.007995,
        "recall": 0.011517,
        "f1": 0.008315,
        "accuracy": 0.011517,
        "main_score": 0.008315,
        "hf_subset": "tah_Latn-ton_Latn",
        "languages": [
          "tah-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "tam_Taml-arb_Arab",
        "languages": [
          "tam-Taml",
          "arb-Arab"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.001502,
        "f1": 3.4e-05,
        "accuracy": 0.001502,
        "main_score": 3.4e-05,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.002107,
        "recall": 0.003505,
        "f1": 0.002398,
        "accuracy": 0.003505,
        "main_score": 0.002398,
        "hf_subset": "tam_Taml-deu_Latn",
        "languages": [
          "tam-Taml",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.004495,
        "recall": 0.005508,
        "f1": 0.004715,
        "accuracy": 0.005508,
        "main_score": 0.004715,
        "hf_subset": "tam_Taml-div_Thaa",
        "languages": [
          "tam-Taml",
          "div-Thaa"
        ]
      },
      {
        "precision": 4.4e-05,
        "recall": 0.002003,
        "f1": 8.5e-05,
        "accuracy": 0.002003,
        "main_score": 8.5e-05,
        "hf_subset": "tam_Taml-ell_Grek",
        "languages": [
          "tam-Taml",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.004997,
        "recall": 0.008012,
        "f1": 0.005249,
        "accuracy": 0.008012,
        "main_score": 0.005249,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001755,
        "recall": 0.003005,
        "f1": 0.00184,
        "accuracy": 0.003005,
        "main_score": 0.00184,
        "hf_subset": "tam_Taml-eus_Latn",
        "languages": [
          "tam-Taml",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.000127,
        "recall": 0.001502,
        "f1": 0.000204,
        "accuracy": 0.001502,
        "main_score": 0.000204,
        "hf_subset": "tam_Taml-fas_Arab",
        "languages": [
          "tam-Taml",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.002669,
        "recall": 0.005008,
        "f1": 0.002796,
        "accuracy": 0.005008,
        "main_score": 0.002796,
        "hf_subset": "tam_Taml-fin_Latn",
        "languages": [
          "tam-Taml",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.002504,
        "recall": 0.003005,
        "f1": 0.002505,
        "accuracy": 0.003005,
        "main_score": 0.002505,
        "hf_subset": "tam_Taml-fra_Latn",
        "languages": [
          "tam-Taml",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.004507,
        "recall": 0.00651,
        "f1": 0.004744,
        "accuracy": 0.00651,
        "main_score": 0.004744,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000608,
        "recall": 0.002504,
        "f1": 0.000691,
        "accuracy": 0.002504,
        "main_score": 0.000691,
        "hf_subset": "tam_Taml-heb_Hebr",
        "languages": [
          "tam-Taml",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.002853,
        "recall": 0.004507,
        "f1": 0.00301,
        "accuracy": 0.004507,
        "main_score": 0.00301,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.002352,
        "recall": 0.004507,
        "f1": 0.002515,
        "accuracy": 0.004507,
        "main_score": 0.002515,
        "hf_subset": "tam_Taml-hun_Latn",
        "languages": [
          "tam-Taml",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.002567,
        "recall": 0.004507,
        "f1": 0.002622,
        "accuracy": 0.004507,
        "main_score": 0.002622,
        "hf_subset": "tam_Taml-ind_Latn",
        "languages": [
          "tam-Taml",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001029,
        "recall": 0.002504,
        "f1": 0.001055,
        "accuracy": 0.002504,
        "main_score": 0.001055,
        "hf_subset": "tam_Taml-jpn_Jpan",
        "languages": [
          "tam-Taml",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.003506,
        "recall": 0.004006,
        "f1": 0.003507,
        "accuracy": 0.004006,
        "main_score": 0.003507,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001483,
        "recall": 0.003505,
        "f1": 0.001699,
        "accuracy": 0.003505,
        "main_score": 0.001699,
        "hf_subset": "tam_Taml-kor_Hang",
        "languages": [
          "tam-Taml",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.000732,
        "recall": 0.003005,
        "f1": 0.000901,
        "accuracy": 0.003005,
        "main_score": 0.000901,
        "hf_subset": "tam_Taml-lit_Latn",
        "languages": [
          "tam-Taml",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.000282,
        "recall": 0.002003,
        "f1": 0.000469,
        "accuracy": 0.002003,
        "main_score": 0.000469,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00179,
        "recall": 0.003005,
        "f1": 0.001908,
        "accuracy": 0.003005,
        "main_score": 0.001908,
        "hf_subset": "tam_Taml-nep_Deva",
        "languages": [
          "tam-Taml",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.003522,
        "recall": 0.004006,
        "f1": 0.003538,
        "accuracy": 0.004006,
        "main_score": 0.003538,
        "hf_subset": "tam_Taml-nld_Latn",
        "languages": [
          "tam-Taml",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.004581,
        "recall": 0.008012,
        "f1": 0.00481,
        "accuracy": 0.008012,
        "main_score": 0.00481,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000988,
        "recall": 0.003505,
        "f1": 0.001211,
        "accuracy": 0.003505,
        "main_score": 0.001211,
        "hf_subset": "tam_Taml-pol_Latn",
        "languages": [
          "tam-Taml",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.002655,
        "recall": 0.004006,
        "f1": 0.002754,
        "accuracy": 0.004006,
        "main_score": 0.002754,
        "hf_subset": "tam_Taml-por_Latn",
        "languages": [
          "tam-Taml",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000351,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "tam_Taml-rus_Cyrl",
        "languages": [
          "tam-Taml",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.003532,
        "recall": 0.005008,
        "f1": 0.003557,
        "accuracy": 0.005008,
        "main_score": 0.003557,
        "hf_subset": "tam_Taml-sin_Sinh",
        "languages": [
          "tam-Taml",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000867,
        "recall": 0.002504,
        "f1": 0.001092,
        "accuracy": 0.002504,
        "main_score": 0.001092,
        "hf_subset": "tam_Taml-snd_Arab",
        "languages": [
          "tam-Taml",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.002003,
        "recall": 0.002003,
        "f1": 0.002003,
        "accuracy": 0.002003,
        "main_score": 0.002003,
        "hf_subset": "tam_Taml-spa_Latn",
        "languages": [
          "tam-Taml",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.002047,
        "recall": 0.003505,
        "f1": 0.002086,
        "accuracy": 0.003505,
        "main_score": 0.002086,
        "hf_subset": "tam_Taml-swa_Latn",
        "languages": [
          "tam-Taml",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.003094,
        "recall": 0.004507,
        "f1": 0.003167,
        "accuracy": 0.004507,
        "main_score": 0.003167,
        "hf_subset": "tam_Taml-swe_Latn",
        "languages": [
          "tam-Taml",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.004823,
        "recall": 0.007011,
        "f1": 0.004965,
        "accuracy": 0.007011,
        "main_score": 0.004965,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002257,
        "recall": 0.004507,
        "f1": 0.002417,
        "accuracy": 0.004507,
        "main_score": 0.002417,
        "hf_subset": "tam_Taml-tur_Latn",
        "languages": [
          "tam-Taml",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000769,
        "recall": 0.002003,
        "f1": 0.00087,
        "accuracy": 0.002003,
        "main_score": 0.00087,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001695,
        "recall": 0.003005,
        "f1": 0.001801,
        "accuracy": 0.003005,
        "main_score": 0.001801,
        "hf_subset": "tam_Taml-vie_Latn",
        "languages": [
          "tam-Taml",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.005274,
        "recall": 0.008513,
        "f1": 0.005626,
        "accuracy": 0.008513,
        "main_score": 0.005626,
        "hf_subset": "tam_Taml-zho_Hant",
        "languages": [
          "tam-Taml",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.001383,
        "recall": 0.003505,
        "f1": 0.001613,
        "accuracy": 0.003505,
        "main_score": 0.001613,
        "hf_subset": "tam_Taml-zul_Latn",
        "languages": [
          "tam-Taml",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.001399,
        "recall": 0.004006,
        "f1": 0.001655,
        "accuracy": 0.004006,
        "main_score": 0.001655,
        "hf_subset": "tat_Cyrl-aze_Latn",
        "languages": [
          "tat-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.067806,
        "recall": 0.098648,
        "f1": 0.074115,
        "accuracy": 0.098648,
        "main_score": 0.074115,
        "hf_subset": "tat_Cyrl-bak_Cyrl",
        "languages": [
          "tat-Cyrl",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.000949,
        "recall": 0.003005,
        "f1": 0.001144,
        "accuracy": 0.003005,
        "main_score": 0.001144,
        "hf_subset": "tat_Cyrl-eng_Latn",
        "languages": [
          "tat-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022057,
        "recall": 0.041562,
        "f1": 0.025159,
        "accuracy": 0.041562,
        "main_score": 0.025159,
        "hf_subset": "tat_Cyrl-kaz_Cyrl",
        "languages": [
          "tat-Cyrl",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.037609,
        "recall": 0.057586,
        "f1": 0.042389,
        "accuracy": 0.057586,
        "main_score": 0.042389,
        "hf_subset": "tat_Cyrl-kir_Cyrl",
        "languages": [
          "tat-Cyrl",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.001048,
        "recall": 0.002504,
        "f1": 0.001253,
        "accuracy": 0.002504,
        "main_score": 0.001253,
        "hf_subset": "tat_Cyrl-tuk_Latn",
        "languages": [
          "tat-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.000547,
        "recall": 0.002003,
        "f1": 0.000589,
        "accuracy": 0.002003,
        "main_score": 0.000589,
        "hf_subset": "tat_Cyrl-tur_Latn",
        "languages": [
          "tat-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.001516,
        "recall": 0.002504,
        "f1": 0.001529,
        "accuracy": 0.002504,
        "main_score": 0.001529,
        "hf_subset": "tat_Cyrl-uig_Arab",
        "languages": [
          "tat-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 5.2e-05,
        "recall": 0.002504,
        "f1": 0.000102,
        "accuracy": 0.002504,
        "main_score": 0.000102,
        "hf_subset": "tat_Cyrl-uzb_Latn",
        "languages": [
          "tat-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 6e-05,
        "recall": 0.002003,
        "f1": 0.000113,
        "accuracy": 0.002003,
        "main_score": 0.000113,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.088164,
        "recall": 0.117176,
        "f1": 0.094706,
        "accuracy": 0.117176,
        "main_score": 0.094706,
        "hf_subset": "tel_Telu-div_Thaa",
        "languages": [
          "tel-Telu",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.030789,
        "recall": 0.049574,
        "f1": 0.034097,
        "accuracy": 0.049574,
        "main_score": 0.034097,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006154,
        "recall": 0.014021,
        "f1": 0.00702,
        "accuracy": 0.014021,
        "main_score": 0.00702,
        "hf_subset": "tel_Telu-eus_Latn",
        "languages": [
          "tel-Telu",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.121457,
        "recall": 0.147722,
        "f1": 0.12789,
        "accuracy": 0.147722,
        "main_score": 0.12789,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.002196,
        "recall": 0.007511,
        "f1": 0.002826,
        "accuracy": 0.007511,
        "main_score": 0.002826,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.118345,
        "recall": 0.150726,
        "f1": 0.125778,
        "accuracy": 0.150726,
        "main_score": 0.125778,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000342,
        "recall": 0.004006,
        "f1": 0.000566,
        "accuracy": 0.004006,
        "main_score": 0.000566,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001356,
        "recall": 0.003005,
        "f1": 0.001524,
        "accuracy": 0.003005,
        "main_score": 0.001524,
        "hf_subset": "tel_Telu-nep_Deva",
        "languages": [
          "tel-Telu",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.079375,
        "recall": 0.105158,
        "f1": 0.085856,
        "accuracy": 0.105158,
        "main_score": 0.085856,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.064173,
        "recall": 0.098648,
        "f1": 0.070717,
        "accuracy": 0.098648,
        "main_score": 0.070717,
        "hf_subset": "tel_Telu-sin_Sinh",
        "languages": [
          "tel-Telu",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.003666,
        "recall": 0.011017,
        "f1": 0.004558,
        "accuracy": 0.011017,
        "main_score": 0.004558,
        "hf_subset": "tel_Telu-snd_Arab",
        "languages": [
          "tel-Telu",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.002786,
        "recall": 0.012018,
        "f1": 0.003575,
        "accuracy": 0.012018,
        "main_score": 0.003575,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.002021,
        "recall": 0.005508,
        "f1": 0.002277,
        "accuracy": 0.005508,
        "main_score": 0.002277,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 3.2e-05,
        "recall": 0.001002,
        "f1": 6e-05,
        "accuracy": 0.001002,
        "main_score": 6e-05,
        "hf_subset": "tgk_Cyrl-arb_Arab",
        "languages": [
          "tgk-Cyrl",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.00051,
        "recall": 0.002003,
        "f1": 0.000519,
        "accuracy": 0.002003,
        "main_score": 0.000519,
        "hf_subset": "tgk_Cyrl-ckb_Arab",
        "languages": [
          "tgk-Cyrl",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.001005,
        "recall": 0.002003,
        "f1": 0.001008,
        "accuracy": 0.002003,
        "main_score": 0.001008,
        "hf_subset": "tgk_Cyrl-eng_Latn",
        "languages": [
          "tgk-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001609,
        "recall": 0.004507,
        "f1": 0.001698,
        "accuracy": 0.004507,
        "main_score": 0.001698,
        "hf_subset": "tgk_Cyrl-fas_Arab",
        "languages": [
          "tgk-Cyrl",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001002,
        "f1": 0.000506,
        "accuracy": 0.001002,
        "main_score": 0.000506,
        "hf_subset": "tgk_Cyrl-heb_Hebr",
        "languages": [
          "tgk-Cyrl",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000504,
        "accuracy": 0.001002,
        "main_score": 0.000504,
        "hf_subset": "tgk_Cyrl-kmr_Latn",
        "languages": [
          "tgk-Cyrl",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000505,
        "accuracy": 0.001502,
        "main_score": 0.000505,
        "hf_subset": "tgk_Cyrl-mey_Arab",
        "languages": [
          "tgk-Cyrl",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.000705,
        "recall": 0.003005,
        "f1": 0.000824,
        "accuracy": 0.003005,
        "main_score": 0.000824,
        "hf_subset": "tgk_Cyrl-prs_Arab",
        "languages": [
          "tgk-Cyrl",
          "prs-Arab"
        ]
      },
      {
        "precision": 4.6e-05,
        "recall": 0.001002,
        "f1": 8.5e-05,
        "accuracy": 0.001002,
        "main_score": 8.5e-05,
        "hf_subset": "tgk_Cyrl-pus_Arab",
        "languages": [
          "tgk-Cyrl",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "tgk_Cyrl-shi_Arab",
        "languages": [
          "tgk-Cyrl",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.009399,
        "recall": 0.018528,
        "f1": 0.0108,
        "accuracy": 0.018528,
        "main_score": 0.0108,
        "hf_subset": "tha_Thai-bod_Tibt",
        "languages": [
          "tha-Thai",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.001732,
        "recall": 0.003005,
        "f1": 0.00189,
        "accuracy": 0.003005,
        "main_score": 0.00189,
        "hf_subset": "tha_Thai-dzo_Tibt",
        "languages": [
          "tha-Thai",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.20707,
        "recall": 0.258388,
        "f1": 0.219255,
        "accuracy": 0.258388,
        "main_score": 0.219255,
        "hf_subset": "tha_Thai-eng_Latn",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.263169,
        "recall": 0.317476,
        "f1": 0.277554,
        "accuracy": 0.317476,
        "main_score": 0.277554,
        "hf_subset": "tha_Thai-khm_Khmr",
        "languages": [
          "tha-Thai",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.341152,
        "recall": 0.385078,
        "f1": 0.352732,
        "accuracy": 0.385078,
        "main_score": 0.352732,
        "hf_subset": "tha_Thai-lao_Laoo",
        "languages": [
          "tha-Thai",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.005601,
        "recall": 0.012018,
        "f1": 0.006398,
        "accuracy": 0.012018,
        "main_score": 0.006398,
        "hf_subset": "tha_Thai-mon_Mong",
        "languages": [
          "tha-Thai",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.141658,
        "recall": 0.198798,
        "f1": 0.155349,
        "accuracy": 0.198798,
        "main_score": 0.155349,
        "hf_subset": "tha_Thai-mya_Mymr",
        "languages": [
          "tha-Thai",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.064122,
        "recall": 0.10015,
        "f1": 0.072805,
        "accuracy": 0.10015,
        "main_score": 0.072805,
        "hf_subset": "tir_Ethi-amh_Ethi",
        "languages": [
          "tir-Ethi",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.041657,
        "recall": 0.066099,
        "f1": 0.045962,
        "accuracy": 0.066099,
        "main_score": 0.045962,
        "hf_subset": "tir_Ethi-eng_Latn",
        "languages": [
          "tir-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008144,
        "recall": 0.02003,
        "f1": 0.009593,
        "accuracy": 0.02003,
        "main_score": 0.009593,
        "hf_subset": "tir_Ethi-hau_Latn",
        "languages": [
          "tir-Ethi",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.008607,
        "recall": 0.025038,
        "f1": 0.010886,
        "accuracy": 0.025038,
        "main_score": 0.010886,
        "hf_subset": "tir_Ethi-ibo_Latn",
        "languages": [
          "tir-Ethi",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.006094,
        "recall": 0.017526,
        "f1": 0.007771,
        "accuracy": 0.017526,
        "main_score": 0.007771,
        "hf_subset": "tir_Ethi-nso_Latn",
        "languages": [
          "tir-Ethi",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.008172,
        "recall": 0.021032,
        "f1": 0.010094,
        "accuracy": 0.021032,
        "main_score": 0.010094,
        "hf_subset": "tir_Ethi-orm_Ethi",
        "languages": [
          "tir-Ethi",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.007772,
        "recall": 0.019529,
        "f1": 0.009501,
        "accuracy": 0.019529,
        "main_score": 0.009501,
        "hf_subset": "tir_Ethi-som_Latn",
        "languages": [
          "tir-Ethi",
          "som-Latn"
        ]
      },
      {
        "precision": 0.008461,
        "recall": 0.019529,
        "f1": 0.009724,
        "accuracy": 0.019529,
        "main_score": 0.009724,
        "hf_subset": "tir_Ethi-ssw_Latn",
        "languages": [
          "tir-Ethi",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.007172,
        "recall": 0.017526,
        "f1": 0.008559,
        "accuracy": 0.017526,
        "main_score": 0.008559,
        "hf_subset": "tir_Ethi-swa_Latn",
        "languages": [
          "tir-Ethi",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.007348,
        "recall": 0.019029,
        "f1": 0.008936,
        "accuracy": 0.019029,
        "main_score": 0.008936,
        "hf_subset": "tir_Ethi-tsn_Latn",
        "languages": [
          "tir-Ethi",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.008027,
        "recall": 0.018528,
        "f1": 0.009506,
        "accuracy": 0.018528,
        "main_score": 0.009506,
        "hf_subset": "tir_Ethi-wol_Latn",
        "languages": [
          "tir-Ethi",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.008569,
        "recall": 0.018027,
        "f1": 0.009775,
        "accuracy": 0.018027,
        "main_score": 0.009775,
        "hf_subset": "tir_Ethi-xho_Latn",
        "languages": [
          "tir-Ethi",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.004821,
        "recall": 0.015523,
        "f1": 0.006372,
        "accuracy": 0.015523,
        "main_score": 0.006372,
        "hf_subset": "tir_Ethi-yor_Latn",
        "languages": [
          "tir-Ethi",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.00843,
        "recall": 0.023035,
        "f1": 0.010287,
        "accuracy": 0.023035,
        "main_score": 0.010287,
        "hf_subset": "tir_Ethi-zul_Latn",
        "languages": [
          "tir-Ethi",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.006085,
        "recall": 0.010015,
        "f1": 0.006321,
        "accuracy": 0.010015,
        "main_score": 0.006321,
        "hf_subset": "ton_Latn-eng_Latn",
        "languages": [
          "ton-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001753,
        "recall": 0.002504,
        "f1": 0.001838,
        "accuracy": 0.002504,
        "main_score": 0.001838,
        "hf_subset": "ton_Latn-fij_Latn",
        "languages": [
          "ton-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.003339,
        "recall": 0.004507,
        "f1": 0.003506,
        "accuracy": 0.004507,
        "main_score": 0.003506,
        "hf_subset": "ton_Latn-fil_Latn",
        "languages": [
          "ton-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.003015,
        "recall": 0.004006,
        "f1": 0.003025,
        "accuracy": 0.004006,
        "main_score": 0.003025,
        "hf_subset": "ton_Latn-ind_Latn",
        "languages": [
          "ton-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000686,
        "recall": 0.002003,
        "f1": 0.000786,
        "accuracy": 0.002003,
        "main_score": 0.000786,
        "hf_subset": "ton_Latn-mal_Mlym",
        "languages": [
          "ton-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.00201,
        "recall": 0.003005,
        "f1": 0.002016,
        "accuracy": 0.003005,
        "main_score": 0.002016,
        "hf_subset": "ton_Latn-mlg_Latn",
        "languages": [
          "ton-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.00492,
        "recall": 0.008513,
        "f1": 0.005461,
        "accuracy": 0.008513,
        "main_score": 0.005461,
        "hf_subset": "ton_Latn-mri_Latn",
        "languages": [
          "ton-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.001515,
        "recall": 0.002504,
        "f1": 0.001527,
        "accuracy": 0.002504,
        "main_score": 0.001527,
        "hf_subset": "ton_Latn-msa_Latn",
        "languages": [
          "ton-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.006059,
        "recall": 0.010015,
        "f1": 0.006274,
        "accuracy": 0.010015,
        "main_score": 0.006274,
        "hf_subset": "ton_Latn-smo_Latn",
        "languages": [
          "ton-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.005019,
        "recall": 0.005508,
        "f1": 0.00503,
        "accuracy": 0.005508,
        "main_score": 0.00503,
        "hf_subset": "ton_Latn-tah_Latn",
        "languages": [
          "ton-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.004425,
        "recall": 0.009014,
        "f1": 0.00488,
        "accuracy": 0.009014,
        "main_score": 0.00488,
        "hf_subset": "tsn_Latn-amh_Ethi",
        "languages": [
          "tsn-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.020548,
        "recall": 0.029544,
        "f1": 0.021706,
        "accuracy": 0.029544,
        "main_score": 0.021706,
        "hf_subset": "tsn_Latn-eng_Latn",
        "languages": [
          "tsn-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007109,
        "recall": 0.012018,
        "f1": 0.007643,
        "accuracy": 0.012018,
        "main_score": 0.007643,
        "hf_subset": "tsn_Latn-hau_Latn",
        "languages": [
          "tsn-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.012713,
        "recall": 0.017026,
        "f1": 0.0133,
        "accuracy": 0.017026,
        "main_score": 0.0133,
        "hf_subset": "tsn_Latn-ibo_Latn",
        "languages": [
          "tsn-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.107249,
        "recall": 0.147221,
        "f1": 0.114991,
        "accuracy": 0.147221,
        "main_score": 0.114991,
        "hf_subset": "tsn_Latn-nso_Latn",
        "languages": [
          "tsn-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.005163,
        "recall": 0.007011,
        "f1": 0.00561,
        "accuracy": 0.007011,
        "main_score": 0.00561,
        "hf_subset": "tsn_Latn-orm_Ethi",
        "languages": [
          "tsn-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.007822,
        "recall": 0.01302,
        "f1": 0.00839,
        "accuracy": 0.01302,
        "main_score": 0.00839,
        "hf_subset": "tsn_Latn-som_Latn",
        "languages": [
          "tsn-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.009494,
        "recall": 0.01352,
        "f1": 0.01,
        "accuracy": 0.01352,
        "main_score": 0.01,
        "hf_subset": "tsn_Latn-ssw_Latn",
        "languages": [
          "tsn-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.008623,
        "recall": 0.011517,
        "f1": 0.009086,
        "accuracy": 0.011517,
        "main_score": 0.009086,
        "hf_subset": "tsn_Latn-swa_Latn",
        "languages": [
          "tsn-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.002426,
        "recall": 0.005008,
        "f1": 0.002627,
        "accuracy": 0.005008,
        "main_score": 0.002627,
        "hf_subset": "tsn_Latn-tir_Ethi",
        "languages": [
          "tsn-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.005927,
        "recall": 0.007011,
        "f1": 0.006095,
        "accuracy": 0.007011,
        "main_score": 0.006095,
        "hf_subset": "tsn_Latn-wol_Latn",
        "languages": [
          "tsn-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.006516,
        "recall": 0.009514,
        "f1": 0.006834,
        "accuracy": 0.009514,
        "main_score": 0.006834,
        "hf_subset": "tsn_Latn-xho_Latn",
        "languages": [
          "tsn-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.005483,
        "recall": 0.007011,
        "f1": 0.005724,
        "accuracy": 0.007011,
        "main_score": 0.005724,
        "hf_subset": "tsn_Latn-yor_Latn",
        "languages": [
          "tsn-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.013606,
        "recall": 0.018027,
        "f1": 0.013921,
        "accuracy": 0.018027,
        "main_score": 0.013921,
        "hf_subset": "tsn_Latn-zul_Latn",
        "languages": [
          "tsn-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.015164,
        "recall": 0.027541,
        "f1": 0.017102,
        "accuracy": 0.027541,
        "main_score": 0.017102,
        "hf_subset": "tuk_Latn-aze_Latn",
        "languages": [
          "tuk-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.002889,
        "recall": 0.006009,
        "f1": 0.003141,
        "accuracy": 0.006009,
        "main_score": 0.003141,
        "hf_subset": "tuk_Latn-bak_Cyrl",
        "languages": [
          "tuk-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.019105,
        "recall": 0.02654,
        "f1": 0.020227,
        "accuracy": 0.02654,
        "main_score": 0.020227,
        "hf_subset": "tuk_Latn-eng_Latn",
        "languages": [
          "tuk-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003138,
        "recall": 0.011517,
        "f1": 0.004084,
        "accuracy": 0.011517,
        "main_score": 0.004084,
        "hf_subset": "tuk_Latn-kaz_Cyrl",
        "languages": [
          "tuk-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.002311,
        "recall": 0.004507,
        "f1": 0.002667,
        "accuracy": 0.004507,
        "main_score": 0.002667,
        "hf_subset": "tuk_Latn-kir_Cyrl",
        "languages": [
          "tuk-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.003322,
        "recall": 0.008012,
        "f1": 0.003969,
        "accuracy": 0.008012,
        "main_score": 0.003969,
        "hf_subset": "tuk_Latn-tat_Cyrl",
        "languages": [
          "tuk-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.038886,
        "recall": 0.055583,
        "f1": 0.041646,
        "accuracy": 0.055583,
        "main_score": 0.041646,
        "hf_subset": "tuk_Latn-tur_Latn",
        "languages": [
          "tuk-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.00112,
        "recall": 0.002003,
        "f1": 0.001213,
        "accuracy": 0.002003,
        "main_score": 0.001213,
        "hf_subset": "tuk_Latn-uig_Arab",
        "languages": [
          "tuk-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.020247,
        "recall": 0.03355,
        "f1": 0.021979,
        "accuracy": 0.03355,
        "main_score": 0.021979,
        "hf_subset": "tuk_Latn-uzb_Latn",
        "languages": [
          "tuk-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "tur_Latn-arb_Arab",
        "languages": [
          "tur-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.020052,
        "recall": 0.035053,
        "f1": 0.022468,
        "accuracy": 0.035053,
        "main_score": 0.022468,
        "hf_subset": "tur_Latn-aze_Latn",
        "languages": [
          "tur-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.001297,
        "recall": 0.002504,
        "f1": 0.001459,
        "accuracy": 0.002504,
        "main_score": 0.001459,
        "hf_subset": "tur_Latn-bak_Cyrl",
        "languages": [
          "tur-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.000607,
        "recall": 0.002003,
        "f1": 0.00068,
        "accuracy": 0.002003,
        "main_score": 0.00068,
        "hf_subset": "tur_Latn-ben_Beng",
        "languages": [
          "tur-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.011585,
        "recall": 0.019029,
        "f1": 0.012376,
        "accuracy": 0.019029,
        "main_score": 0.012376,
        "hf_subset": "tur_Latn-deu_Latn",
        "languages": [
          "tur-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.001439,
        "recall": 0.004006,
        "f1": 0.001625,
        "accuracy": 0.004006,
        "main_score": 0.001625,
        "hf_subset": "tur_Latn-ell_Grek",
        "languages": [
          "tur-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.015105,
        "recall": 0.022033,
        "f1": 0.016097,
        "accuracy": 0.022033,
        "main_score": 0.016097,
        "hf_subset": "tur_Latn-eng_Latn",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000974,
        "recall": 0.005008,
        "f1": 0.001194,
        "accuracy": 0.005008,
        "main_score": 0.001194,
        "hf_subset": "tur_Latn-fas_Arab",
        "languages": [
          "tur-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.008329,
        "recall": 0.015523,
        "f1": 0.008833,
        "accuracy": 0.015523,
        "main_score": 0.008833,
        "hf_subset": "tur_Latn-fin_Latn",
        "languages": [
          "tur-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.01109,
        "recall": 0.016525,
        "f1": 0.01193,
        "accuracy": 0.016525,
        "main_score": 0.01193,
        "hf_subset": "tur_Latn-fra_Latn",
        "languages": [
          "tur-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.001112,
        "recall": 0.003005,
        "f1": 0.001206,
        "accuracy": 0.003005,
        "main_score": 0.001206,
        "hf_subset": "tur_Latn-heb_Hebr",
        "languages": [
          "tur-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000466,
        "recall": 0.003505,
        "f1": 0.000706,
        "accuracy": 0.003505,
        "main_score": 0.000706,
        "hf_subset": "tur_Latn-hin_Deva",
        "languages": [
          "tur-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.011289,
        "recall": 0.014522,
        "f1": 0.011998,
        "accuracy": 0.014522,
        "main_score": 0.011998,
        "hf_subset": "tur_Latn-hun_Latn",
        "languages": [
          "tur-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.011121,
        "recall": 0.014021,
        "f1": 0.011624,
        "accuracy": 0.014021,
        "main_score": 0.011624,
        "hf_subset": "tur_Latn-ind_Latn",
        "languages": [
          "tur-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000602,
        "recall": 0.004507,
        "f1": 0.000945,
        "accuracy": 0.004507,
        "main_score": 0.000945,
        "hf_subset": "tur_Latn-jpn_Jpan",
        "languages": [
          "tur-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.002707,
        "recall": 0.007011,
        "f1": 0.003108,
        "accuracy": 0.007011,
        "main_score": 0.003108,
        "hf_subset": "tur_Latn-kaz_Cyrl",
        "languages": [
          "tur-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.002893,
        "recall": 0.007011,
        "f1": 0.00363,
        "accuracy": 0.007011,
        "main_score": 0.00363,
        "hf_subset": "tur_Latn-kir_Cyrl",
        "languages": [
          "tur-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.001248,
        "recall": 0.004507,
        "f1": 0.001564,
        "accuracy": 0.004507,
        "main_score": 0.001564,
        "hf_subset": "tur_Latn-kor_Hang",
        "languages": [
          "tur-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.007323,
        "recall": 0.009514,
        "f1": 0.007627,
        "accuracy": 0.009514,
        "main_score": 0.007627,
        "hf_subset": "tur_Latn-lit_Latn",
        "languages": [
          "tur-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.011264,
        "recall": 0.014522,
        "f1": 0.011615,
        "accuracy": 0.014522,
        "main_score": 0.011615,
        "hf_subset": "tur_Latn-nld_Latn",
        "languages": [
          "tur-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.008421,
        "recall": 0.01352,
        "f1": 0.009109,
        "accuracy": 0.01352,
        "main_score": 0.009109,
        "hf_subset": "tur_Latn-pol_Latn",
        "languages": [
          "tur-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.01151,
        "recall": 0.017026,
        "f1": 0.012167,
        "accuracy": 0.017026,
        "main_score": 0.012167,
        "hf_subset": "tur_Latn-por_Latn",
        "languages": [
          "tur-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001323,
        "recall": 0.002003,
        "f1": 0.001461,
        "accuracy": 0.002003,
        "main_score": 0.001461,
        "hf_subset": "tur_Latn-rus_Cyrl",
        "languages": [
          "tur-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.011033,
        "recall": 0.015523,
        "f1": 0.011536,
        "accuracy": 0.015523,
        "main_score": 0.011536,
        "hf_subset": "tur_Latn-spa_Latn",
        "languages": [
          "tur-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.008685,
        "recall": 0.01352,
        "f1": 0.00946,
        "accuracy": 0.01352,
        "main_score": 0.00946,
        "hf_subset": "tur_Latn-swa_Latn",
        "languages": [
          "tur-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.013274,
        "recall": 0.018528,
        "f1": 0.01373,
        "accuracy": 0.018528,
        "main_score": 0.01373,
        "hf_subset": "tur_Latn-swe_Latn",
        "languages": [
          "tur-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001076,
        "recall": 0.004507,
        "f1": 0.001427,
        "accuracy": 0.004507,
        "main_score": 0.001427,
        "hf_subset": "tur_Latn-tam_Taml",
        "languages": [
          "tur-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000608,
        "recall": 0.001502,
        "f1": 0.000693,
        "accuracy": 0.001502,
        "main_score": 0.000693,
        "hf_subset": "tur_Latn-tat_Cyrl",
        "languages": [
          "tur-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.021782,
        "recall": 0.029044,
        "f1": 0.022898,
        "accuracy": 0.029044,
        "main_score": 0.022898,
        "hf_subset": "tur_Latn-tuk_Latn",
        "languages": [
          "tur-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.001502,
        "recall": 0.002003,
        "f1": 0.001669,
        "accuracy": 0.002003,
        "main_score": 0.001669,
        "hf_subset": "tur_Latn-uig_Arab",
        "languages": [
          "tur-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.008219,
        "recall": 0.015523,
        "f1": 0.008882,
        "accuracy": 0.015523,
        "main_score": 0.008882,
        "hf_subset": "tur_Latn-uzb_Latn",
        "languages": [
          "tur-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.007558,
        "recall": 0.012519,
        "f1": 0.008263,
        "accuracy": 0.012519,
        "main_score": 0.008263,
        "hf_subset": "tur_Latn-vie_Latn",
        "languages": [
          "tur-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.012209,
        "recall": 0.020531,
        "f1": 0.013252,
        "accuracy": 0.020531,
        "main_score": 0.013252,
        "hf_subset": "tur_Latn-zho_Hant",
        "languages": [
          "tur-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.007918,
        "recall": 0.011017,
        "f1": 0.008507,
        "accuracy": 0.011017,
        "main_score": 0.008507,
        "hf_subset": "tur_Latn-zul_Latn",
        "languages": [
          "tur-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.001171,
        "recall": 0.002003,
        "f1": 0.001257,
        "accuracy": 0.002003,
        "main_score": 0.001257,
        "hf_subset": "uig_Arab-aze_Latn",
        "languages": [
          "uig-Arab",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.000254,
        "recall": 0.001502,
        "f1": 0.000342,
        "accuracy": 0.001502,
        "main_score": 0.000342,
        "hf_subset": "uig_Arab-bak_Cyrl",
        "languages": [
          "uig-Arab",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.000516,
        "recall": 0.002003,
        "f1": 0.00053,
        "accuracy": 0.002003,
        "main_score": 0.00053,
        "hf_subset": "uig_Arab-eng_Latn",
        "languages": [
          "uig-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000697,
        "recall": 0.003005,
        "f1": 0.001069,
        "accuracy": 0.003005,
        "main_score": 0.001069,
        "hf_subset": "uig_Arab-kaz_Cyrl",
        "languages": [
          "uig-Arab",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.000946,
        "recall": 0.004507,
        "f1": 0.001198,
        "accuracy": 0.004507,
        "main_score": 0.001198,
        "hf_subset": "uig_Arab-kir_Cyrl",
        "languages": [
          "uig-Arab",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.00136,
        "recall": 0.003505,
        "f1": 0.001518,
        "accuracy": 0.003505,
        "main_score": 0.001518,
        "hf_subset": "uig_Arab-tat_Cyrl",
        "languages": [
          "uig-Arab",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 5.8e-05,
        "recall": 0.002504,
        "f1": 0.000108,
        "accuracy": 0.002504,
        "main_score": 0.000108,
        "hf_subset": "uig_Arab-tuk_Latn",
        "languages": [
          "uig-Arab",
          "tuk-Latn"
        ]
      },
      {
        "precision": 8.3e-05,
        "recall": 0.001502,
        "f1": 0.000147,
        "accuracy": 0.001502,
        "main_score": 0.000147,
        "hf_subset": "uig_Arab-tur_Latn",
        "languages": [
          "uig-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000514,
        "recall": 0.001502,
        "f1": 0.000526,
        "accuracy": 0.001502,
        "main_score": 0.000526,
        "hf_subset": "uig_Arab-uzb_Latn",
        "languages": [
          "uig-Arab",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.042836,
        "recall": 0.069604,
        "f1": 0.047519,
        "accuracy": 0.069604,
        "main_score": 0.047519,
        "hf_subset": "ukr_Cyrl-bel_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.000509,
        "recall": 0.001502,
        "f1": 0.000517,
        "accuracy": 0.001502,
        "main_score": 0.000517,
        "hf_subset": "ukr_Cyrl-bos_Latn",
        "languages": [
          "ukr-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.01624,
        "recall": 0.032048,
        "f1": 0.018637,
        "accuracy": 0.032048,
        "main_score": 0.018637,
        "hf_subset": "ukr_Cyrl-bul_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.001058,
        "recall": 0.002003,
        "f1": 0.001104,
        "accuracy": 0.002003,
        "main_score": 0.001104,
        "hf_subset": "ukr_Cyrl-ces_Latn",
        "languages": [
          "ukr-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.001326,
        "recall": 0.003005,
        "f1": 0.001466,
        "accuracy": 0.003005,
        "main_score": 0.001466,
        "hf_subset": "ukr_Cyrl-eng_Latn",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000764,
        "recall": 0.002504,
        "f1": 0.00086,
        "accuracy": 0.002504,
        "main_score": 0.00086,
        "hf_subset": "ukr_Cyrl-hrv_Latn",
        "languages": [
          "ukr-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.012458,
        "recall": 0.021532,
        "f1": 0.01419,
        "accuracy": 0.021532,
        "main_score": 0.01419,
        "hf_subset": "ukr_Cyrl-mkd_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.001002,
        "f1": 1.9e-05,
        "accuracy": 0.001002,
        "main_score": 1.9e-05,
        "hf_subset": "ukr_Cyrl-pol_Latn",
        "languages": [
          "ukr-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.056604,
        "recall": 0.084126,
        "f1": 0.062286,
        "accuracy": 0.084126,
        "main_score": 0.062286,
        "hf_subset": "ukr_Cyrl-rus_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "ukr_Cyrl-slk_Latn",
        "languages": [
          "ukr-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.000524,
        "recall": 0.001502,
        "f1": 0.000545,
        "accuracy": 0.001502,
        "main_score": 0.000545,
        "hf_subset": "ukr_Cyrl-slv_Latn",
        "languages": [
          "ukr-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.011718,
        "recall": 0.022033,
        "f1": 0.013253,
        "accuracy": 0.022033,
        "main_score": 0.013253,
        "hf_subset": "ukr_Cyrl-srp_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.001074,
        "recall": 0.002504,
        "f1": 0.00113,
        "accuracy": 0.002504,
        "main_score": 0.00113,
        "hf_subset": "ukr_Cyrl-srp_Latn",
        "languages": [
          "ukr-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "urd_Arab-div_Thaa",
        "languages": [
          "urd-Arab",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.002003,
        "f1": 0.000506,
        "accuracy": 0.002003,
        "main_score": 0.000506,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000581,
        "recall": 0.003505,
        "f1": 0.000646,
        "accuracy": 0.003505,
        "main_score": 0.000646,
        "hf_subset": "urd_Arab-eus_Latn",
        "languages": [
          "urd-Arab",
          "eus-Latn"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001002,
        "f1": 9e-06,
        "accuracy": 0.001002,
        "main_score": 9e-06,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000542,
        "recall": 0.002504,
        "f1": 0.00058,
        "accuracy": 0.002504,
        "main_score": 0.00058,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000128,
        "recall": 0.002504,
        "f1": 0.000235,
        "accuracy": 0.002504,
        "main_score": 0.000235,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.001002,
        "f1": 3e-05,
        "accuracy": 0.001002,
        "main_score": 3e-05,
        "hf_subset": "urd_Arab-nep_Deva",
        "languages": [
          "urd-Arab",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "urd_Arab-sin_Sinh",
        "languages": [
          "urd-Arab",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.002485,
        "recall": 0.006009,
        "f1": 0.002738,
        "accuracy": 0.006009,
        "main_score": 0.002738,
        "hf_subset": "urd_Arab-snd_Arab",
        "languages": [
          "urd-Arab",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.000542,
        "recall": 0.002003,
        "f1": 0.000579,
        "accuracy": 0.002003,
        "main_score": 0.000579,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000526,
        "recall": 0.001502,
        "f1": 0.000549,
        "accuracy": 0.001502,
        "main_score": 0.000549,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.015342,
        "recall": 0.025038,
        "f1": 0.016699,
        "accuracy": 0.025038,
        "main_score": 0.016699,
        "hf_subset": "uzb_Latn-aze_Latn",
        "languages": [
          "uzb-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.003195,
        "recall": 0.007011,
        "f1": 0.003747,
        "accuracy": 0.007011,
        "main_score": 0.003747,
        "hf_subset": "uzb_Latn-bak_Cyrl",
        "languages": [
          "uzb-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.00498,
        "recall": 0.009514,
        "f1": 0.005271,
        "accuracy": 0.009514,
        "main_score": 0.005271,
        "hf_subset": "uzb_Latn-eng_Latn",
        "languages": [
          "uzb-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00135,
        "recall": 0.004507,
        "f1": 0.001689,
        "accuracy": 0.004507,
        "main_score": 0.001689,
        "hf_subset": "uzb_Latn-kaz_Cyrl",
        "languages": [
          "uzb-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.001411,
        "recall": 0.003505,
        "f1": 0.001653,
        "accuracy": 0.003505,
        "main_score": 0.001653,
        "hf_subset": "uzb_Latn-kir_Cyrl",
        "languages": [
          "uzb-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.003507,
        "recall": 0.007011,
        "f1": 0.003831,
        "accuracy": 0.007011,
        "main_score": 0.003831,
        "hf_subset": "uzb_Latn-tat_Cyrl",
        "languages": [
          "uzb-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.016846,
        "recall": 0.030546,
        "f1": 0.018465,
        "accuracy": 0.030546,
        "main_score": 0.018465,
        "hf_subset": "uzb_Latn-tuk_Latn",
        "languages": [
          "uzb-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.007263,
        "recall": 0.015523,
        "f1": 0.008323,
        "accuracy": 0.015523,
        "main_score": 0.008323,
        "hf_subset": "uzb_Latn-tur_Latn",
        "languages": [
          "uzb-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000467,
        "recall": 0.003005,
        "f1": 0.000763,
        "accuracy": 0.003005,
        "main_score": 0.000763,
        "hf_subset": "uzb_Latn-uig_Arab",
        "languages": [
          "uzb-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.01311,
        "recall": 0.018528,
        "f1": 0.014206,
        "accuracy": 0.018528,
        "main_score": 0.014206,
        "hf_subset": "ven_Latn-bem_Latn",
        "languages": [
          "ven-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.024431,
        "recall": 0.036054,
        "f1": 0.026174,
        "accuracy": 0.036054,
        "main_score": 0.026174,
        "hf_subset": "ven_Latn-eng_Latn",
        "languages": [
          "ven-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00697,
        "recall": 0.011017,
        "f1": 0.007642,
        "accuracy": 0.011017,
        "main_score": 0.007642,
        "hf_subset": "ven_Latn-ewe_Latn",
        "languages": [
          "ven-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.009101,
        "recall": 0.01352,
        "f1": 0.009815,
        "accuracy": 0.01352,
        "main_score": 0.009815,
        "hf_subset": "ven_Latn-fuc_Latn",
        "languages": [
          "ven-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.009216,
        "recall": 0.014021,
        "f1": 0.009999,
        "accuracy": 0.014021,
        "main_score": 0.009999,
        "hf_subset": "ven_Latn-kin_Latn",
        "languages": [
          "ven-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.007998,
        "recall": 0.01302,
        "f1": 0.008725,
        "accuracy": 0.01302,
        "main_score": 0.008725,
        "hf_subset": "ven_Latn-nde_Latn",
        "languages": [
          "ven-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.016918,
        "recall": 0.025038,
        "f1": 0.0179,
        "accuracy": 0.025038,
        "main_score": 0.0179,
        "hf_subset": "ven_Latn-nya_Latn",
        "languages": [
          "ven-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.009871,
        "recall": 0.015023,
        "f1": 0.010151,
        "accuracy": 0.015023,
        "main_score": 0.010151,
        "hf_subset": "ven_Latn-sna_Latn",
        "languages": [
          "ven-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 2.9e-05,
        "recall": 0.001002,
        "f1": 5.6e-05,
        "accuracy": 0.001002,
        "main_score": 5.6e-05,
        "hf_subset": "vie_Latn-arb_Arab",
        "languages": [
          "vie-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.00019,
        "recall": 0.001502,
        "f1": 0.000296,
        "accuracy": 0.001502,
        "main_score": 0.000296,
        "hf_subset": "vie_Latn-ben_Beng",
        "languages": [
          "vie-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.01159,
        "recall": 0.017026,
        "f1": 0.012518,
        "accuracy": 0.017026,
        "main_score": 0.012518,
        "hf_subset": "vie_Latn-deu_Latn",
        "languages": [
          "vie-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000845,
        "recall": 0.003005,
        "f1": 0.001011,
        "accuracy": 0.003005,
        "main_score": 0.001011,
        "hf_subset": "vie_Latn-ell_Grek",
        "languages": [
          "vie-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.020632,
        "recall": 0.02654,
        "f1": 0.021591,
        "accuracy": 0.02654,
        "main_score": 0.021591,
        "hf_subset": "vie_Latn-eng_Latn",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002212,
        "recall": 0.004507,
        "f1": 0.002498,
        "accuracy": 0.004507,
        "main_score": 0.002498,
        "hf_subset": "vie_Latn-fas_Arab",
        "languages": [
          "vie-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.01123,
        "recall": 0.016024,
        "f1": 0.011894,
        "accuracy": 0.016024,
        "main_score": 0.011894,
        "hf_subset": "vie_Latn-fin_Latn",
        "languages": [
          "vie-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.012552,
        "recall": 0.019529,
        "f1": 0.013766,
        "accuracy": 0.019529,
        "main_score": 0.013766,
        "hf_subset": "vie_Latn-fra_Latn",
        "languages": [
          "vie-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.00117,
        "recall": 0.002504,
        "f1": 0.001422,
        "accuracy": 0.002504,
        "main_score": 0.001422,
        "hf_subset": "vie_Latn-heb_Hebr",
        "languages": [
          "vie-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000877,
        "recall": 0.002003,
        "f1": 0.001036,
        "accuracy": 0.002003,
        "main_score": 0.001036,
        "hf_subset": "vie_Latn-hin_Deva",
        "languages": [
          "vie-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.006482,
        "recall": 0.009014,
        "f1": 0.006864,
        "accuracy": 0.009014,
        "main_score": 0.006864,
        "hf_subset": "vie_Latn-hun_Latn",
        "languages": [
          "vie-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.011457,
        "recall": 0.016525,
        "f1": 0.012163,
        "accuracy": 0.016525,
        "main_score": 0.012163,
        "hf_subset": "vie_Latn-ind_Latn",
        "languages": [
          "vie-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000851,
        "recall": 0.003505,
        "f1": 0.001033,
        "accuracy": 0.003505,
        "main_score": 0.001033,
        "hf_subset": "vie_Latn-jpn_Jpan",
        "languages": [
          "vie-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.002915,
        "recall": 0.004507,
        "f1": 0.003119,
        "accuracy": 0.004507,
        "main_score": 0.003119,
        "hf_subset": "vie_Latn-kor_Hang",
        "languages": [
          "vie-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.003368,
        "recall": 0.007011,
        "f1": 0.003715,
        "accuracy": 0.007011,
        "main_score": 0.003715,
        "hf_subset": "vie_Latn-lit_Latn",
        "languages": [
          "vie-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.015481,
        "recall": 0.020531,
        "f1": 0.015977,
        "accuracy": 0.020531,
        "main_score": 0.015977,
        "hf_subset": "vie_Latn-nld_Latn",
        "languages": [
          "vie-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.009063,
        "recall": 0.011517,
        "f1": 0.009441,
        "accuracy": 0.011517,
        "main_score": 0.009441,
        "hf_subset": "vie_Latn-pol_Latn",
        "languages": [
          "vie-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.010726,
        "recall": 0.014021,
        "f1": 0.011262,
        "accuracy": 0.014021,
        "main_score": 0.011262,
        "hf_subset": "vie_Latn-por_Latn",
        "languages": [
          "vie-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001553,
        "recall": 0.003005,
        "f1": 0.001761,
        "accuracy": 0.003005,
        "main_score": 0.001761,
        "hf_subset": "vie_Latn-rus_Cyrl",
        "languages": [
          "vie-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.013493,
        "recall": 0.019029,
        "f1": 0.014482,
        "accuracy": 0.019029,
        "main_score": 0.014482,
        "hf_subset": "vie_Latn-spa_Latn",
        "languages": [
          "vie-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.006409,
        "recall": 0.011017,
        "f1": 0.007112,
        "accuracy": 0.011017,
        "main_score": 0.007112,
        "hf_subset": "vie_Latn-swa_Latn",
        "languages": [
          "vie-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.011875,
        "recall": 0.018027,
        "f1": 0.012895,
        "accuracy": 0.018027,
        "main_score": 0.012895,
        "hf_subset": "vie_Latn-swe_Latn",
        "languages": [
          "vie-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.003332,
        "recall": 0.007511,
        "f1": 0.003736,
        "accuracy": 0.007511,
        "main_score": 0.003736,
        "hf_subset": "vie_Latn-tam_Taml",
        "languages": [
          "vie-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009056,
        "recall": 0.01352,
        "f1": 0.010003,
        "accuracy": 0.01352,
        "main_score": 0.010003,
        "hf_subset": "vie_Latn-tur_Latn",
        "languages": [
          "vie-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.004159,
        "recall": 0.012519,
        "f1": 0.005026,
        "accuracy": 0.012519,
        "main_score": 0.005026,
        "hf_subset": "vie_Latn-yue_Hant",
        "languages": [
          "vie-Latn",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.008296,
        "recall": 0.014522,
        "f1": 0.008955,
        "accuracy": 0.014522,
        "main_score": 0.008955,
        "hf_subset": "vie_Latn-zho_Hans",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.018868,
        "recall": 0.027041,
        "f1": 0.019973,
        "accuracy": 0.027041,
        "main_score": 0.019973,
        "hf_subset": "vie_Latn-zho_Hant",
        "languages": [
          "vie-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.011081,
        "recall": 0.016024,
        "f1": 0.011914,
        "accuracy": 0.016024,
        "main_score": 0.011914,
        "hf_subset": "vie_Latn-zul_Latn",
        "languages": [
          "vie-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.006324,
        "recall": 0.014021,
        "f1": 0.007034,
        "accuracy": 0.014021,
        "main_score": 0.007034,
        "hf_subset": "wol_Latn-amh_Ethi",
        "languages": [
          "wol-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.023867,
        "recall": 0.03355,
        "f1": 0.025254,
        "accuracy": 0.03355,
        "main_score": 0.025254,
        "hf_subset": "wol_Latn-eng_Latn",
        "languages": [
          "wol-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015068,
        "recall": 0.019029,
        "f1": 0.015762,
        "accuracy": 0.019029,
        "main_score": 0.015762,
        "hf_subset": "wol_Latn-hau_Latn",
        "languages": [
          "wol-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.014183,
        "recall": 0.020531,
        "f1": 0.015273,
        "accuracy": 0.020531,
        "main_score": 0.015273,
        "hf_subset": "wol_Latn-ibo_Latn",
        "languages": [
          "wol-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.01259,
        "recall": 0.017026,
        "f1": 0.013404,
        "accuracy": 0.017026,
        "main_score": 0.013404,
        "hf_subset": "wol_Latn-nso_Latn",
        "languages": [
          "wol-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.007472,
        "recall": 0.010516,
        "f1": 0.007987,
        "accuracy": 0.010516,
        "main_score": 0.007987,
        "hf_subset": "wol_Latn-orm_Ethi",
        "languages": [
          "wol-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.011268,
        "recall": 0.016525,
        "f1": 0.012236,
        "accuracy": 0.016525,
        "main_score": 0.012236,
        "hf_subset": "wol_Latn-som_Latn",
        "languages": [
          "wol-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.009605,
        "recall": 0.016525,
        "f1": 0.010656,
        "accuracy": 0.016525,
        "main_score": 0.010656,
        "hf_subset": "wol_Latn-ssw_Latn",
        "languages": [
          "wol-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.011426,
        "recall": 0.018528,
        "f1": 0.012305,
        "accuracy": 0.018528,
        "main_score": 0.012305,
        "hf_subset": "wol_Latn-swa_Latn",
        "languages": [
          "wol-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.006288,
        "recall": 0.010516,
        "f1": 0.006567,
        "accuracy": 0.010516,
        "main_score": 0.006567,
        "hf_subset": "wol_Latn-tir_Ethi",
        "languages": [
          "wol-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.010648,
        "recall": 0.016024,
        "f1": 0.011373,
        "accuracy": 0.016024,
        "main_score": 0.011373,
        "hf_subset": "wol_Latn-tsn_Latn",
        "languages": [
          "wol-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.007682,
        "recall": 0.01352,
        "f1": 0.008425,
        "accuracy": 0.01352,
        "main_score": 0.008425,
        "hf_subset": "wol_Latn-xho_Latn",
        "languages": [
          "wol-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.013692,
        "recall": 0.015023,
        "f1": 0.013979,
        "accuracy": 0.015023,
        "main_score": 0.013979,
        "hf_subset": "wol_Latn-yor_Latn",
        "languages": [
          "wol-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.013073,
        "recall": 0.021532,
        "f1": 0.014196,
        "accuracy": 0.021532,
        "main_score": 0.014196,
        "hf_subset": "wol_Latn-zul_Latn",
        "languages": [
          "wol-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.00388,
        "recall": 0.009514,
        "f1": 0.004309,
        "accuracy": 0.009514,
        "main_score": 0.004309,
        "hf_subset": "xho_Latn-amh_Ethi",
        "languages": [
          "xho-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.013839,
        "recall": 0.021532,
        "f1": 0.015115,
        "accuracy": 0.021532,
        "main_score": 0.015115,
        "hf_subset": "xho_Latn-eng_Latn",
        "languages": [
          "xho-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009961,
        "recall": 0.01352,
        "f1": 0.0106,
        "accuracy": 0.01352,
        "main_score": 0.0106,
        "hf_subset": "xho_Latn-hau_Latn",
        "languages": [
          "xho-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.008218,
        "recall": 0.011517,
        "f1": 0.008746,
        "accuracy": 0.011517,
        "main_score": 0.008746,
        "hf_subset": "xho_Latn-ibo_Latn",
        "languages": [
          "xho-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.010534,
        "recall": 0.015523,
        "f1": 0.011204,
        "accuracy": 0.015523,
        "main_score": 0.011204,
        "hf_subset": "xho_Latn-nso_Latn",
        "languages": [
          "xho-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.005571,
        "recall": 0.007511,
        "f1": 0.005999,
        "accuracy": 0.007511,
        "main_score": 0.005999,
        "hf_subset": "xho_Latn-orm_Ethi",
        "languages": [
          "xho-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.007002,
        "recall": 0.009514,
        "f1": 0.007243,
        "accuracy": 0.009514,
        "main_score": 0.007243,
        "hf_subset": "xho_Latn-som_Latn",
        "languages": [
          "xho-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.059627,
        "recall": 0.084126,
        "f1": 0.064658,
        "accuracy": 0.084126,
        "main_score": 0.064658,
        "hf_subset": "xho_Latn-ssw_Latn",
        "languages": [
          "xho-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.007259,
        "recall": 0.010516,
        "f1": 0.007647,
        "accuracy": 0.010516,
        "main_score": 0.007647,
        "hf_subset": "xho_Latn-swa_Latn",
        "languages": [
          "xho-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.004342,
        "recall": 0.008513,
        "f1": 0.004506,
        "accuracy": 0.008513,
        "main_score": 0.004506,
        "hf_subset": "xho_Latn-tir_Ethi",
        "languages": [
          "xho-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.009471,
        "recall": 0.011517,
        "f1": 0.009839,
        "accuracy": 0.011517,
        "main_score": 0.009839,
        "hf_subset": "xho_Latn-tsn_Latn",
        "languages": [
          "xho-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.005809,
        "recall": 0.007511,
        "f1": 0.005939,
        "accuracy": 0.007511,
        "main_score": 0.005939,
        "hf_subset": "xho_Latn-wol_Latn",
        "languages": [
          "xho-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.007042,
        "recall": 0.010015,
        "f1": 0.007521,
        "accuracy": 0.010015,
        "main_score": 0.007521,
        "hf_subset": "xho_Latn-yor_Latn",
        "languages": [
          "xho-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.131276,
        "recall": 0.184276,
        "f1": 0.143273,
        "accuracy": 0.184276,
        "main_score": 0.143273,
        "hf_subset": "xho_Latn-zul_Latn",
        "languages": [
          "xho-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.007074,
        "recall": 0.01302,
        "f1": 0.007911,
        "accuracy": 0.01302,
        "main_score": 0.007911,
        "hf_subset": "yor_Latn-amh_Ethi",
        "languages": [
          "yor-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.018789,
        "recall": 0.02654,
        "f1": 0.019604,
        "accuracy": 0.02654,
        "main_score": 0.019604,
        "hf_subset": "yor_Latn-eng_Latn",
        "languages": [
          "yor-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013434,
        "recall": 0.017526,
        "f1": 0.014089,
        "accuracy": 0.017526,
        "main_score": 0.014089,
        "hf_subset": "yor_Latn-hau_Latn",
        "languages": [
          "yor-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.010866,
        "recall": 0.015523,
        "f1": 0.011522,
        "accuracy": 0.015523,
        "main_score": 0.011522,
        "hf_subset": "yor_Latn-ibo_Latn",
        "languages": [
          "yor-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.010591,
        "recall": 0.016525,
        "f1": 0.011304,
        "accuracy": 0.016525,
        "main_score": 0.011304,
        "hf_subset": "yor_Latn-nso_Latn",
        "languages": [
          "yor-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.00461,
        "recall": 0.008513,
        "f1": 0.005114,
        "accuracy": 0.008513,
        "main_score": 0.005114,
        "hf_subset": "yor_Latn-orm_Ethi",
        "languages": [
          "yor-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.010168,
        "recall": 0.012519,
        "f1": 0.010615,
        "accuracy": 0.012519,
        "main_score": 0.010615,
        "hf_subset": "yor_Latn-som_Latn",
        "languages": [
          "yor-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.008243,
        "recall": 0.012018,
        "f1": 0.008907,
        "accuracy": 0.012018,
        "main_score": 0.008907,
        "hf_subset": "yor_Latn-ssw_Latn",
        "languages": [
          "yor-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.00906,
        "recall": 0.012519,
        "f1": 0.009541,
        "accuracy": 0.012519,
        "main_score": 0.009541,
        "hf_subset": "yor_Latn-swa_Latn",
        "languages": [
          "yor-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.003681,
        "recall": 0.005508,
        "f1": 0.003773,
        "accuracy": 0.005508,
        "main_score": 0.003773,
        "hf_subset": "yor_Latn-tir_Ethi",
        "languages": [
          "yor-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.006781,
        "recall": 0.010516,
        "f1": 0.007342,
        "accuracy": 0.010516,
        "main_score": 0.007342,
        "hf_subset": "yor_Latn-tsn_Latn",
        "languages": [
          "yor-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.007028,
        "recall": 0.010516,
        "f1": 0.00763,
        "accuracy": 0.010516,
        "main_score": 0.00763,
        "hf_subset": "yor_Latn-wol_Latn",
        "languages": [
          "yor-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.007782,
        "recall": 0.012519,
        "f1": 0.008378,
        "accuracy": 0.012519,
        "main_score": 0.008378,
        "hf_subset": "yor_Latn-xho_Latn",
        "languages": [
          "yor-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.011891,
        "recall": 0.015523,
        "f1": 0.012466,
        "accuracy": 0.015523,
        "main_score": 0.012466,
        "hf_subset": "yor_Latn-zul_Latn",
        "languages": [
          "yor-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.019578,
        "recall": 0.025538,
        "f1": 0.020551,
        "accuracy": 0.025538,
        "main_score": 0.020551,
        "hf_subset": "yue_Hant-eng_Latn",
        "languages": [
          "yue-Hant",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015584,
        "recall": 0.030546,
        "f1": 0.017519,
        "accuracy": 0.030546,
        "main_score": 0.017519,
        "hf_subset": "yue_Hant-jpn_Jpan",
        "languages": [
          "yue-Hant",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.00082,
        "recall": 0.003005,
        "f1": 0.001038,
        "accuracy": 0.003005,
        "main_score": 0.001038,
        "hf_subset": "yue_Hant-kor_Hang",
        "languages": [
          "yue-Hant",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.003421,
        "recall": 0.007011,
        "f1": 0.003845,
        "accuracy": 0.007011,
        "main_score": 0.003845,
        "hf_subset": "yue_Hant-vie_Latn",
        "languages": [
          "yue-Hant",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.379229,
        "recall": 0.470706,
        "f1": 0.403196,
        "accuracy": 0.470706,
        "main_score": 0.403196,
        "hf_subset": "yue_Hant-zho_Hans",
        "languages": [
          "yue-Hant",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.315916,
        "recall": 0.407111,
        "f1": 0.338549,
        "accuracy": 0.407111,
        "main_score": 0.338549,
        "hf_subset": "yue_Hant-zho_Hant",
        "languages": [
          "yue-Hant",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.057237,
        "recall": 0.067601,
        "f1": 0.05935,
        "accuracy": 0.067601,
        "main_score": 0.05935,
        "hf_subset": "zho_Hans-eng_Latn",
        "languages": [
          "zho-Hans",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015156,
        "recall": 0.028543,
        "f1": 0.016871,
        "accuracy": 0.028543,
        "main_score": 0.016871,
        "hf_subset": "zho_Hans-jpn_Jpan",
        "languages": [
          "zho-Hans",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.005162,
        "recall": 0.009514,
        "f1": 0.005815,
        "accuracy": 0.009514,
        "main_score": 0.005815,
        "hf_subset": "zho_Hans-kor_Hang",
        "languages": [
          "zho-Hans",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.016409,
        "recall": 0.022033,
        "f1": 0.01727,
        "accuracy": 0.022033,
        "main_score": 0.01727,
        "hf_subset": "zho_Hans-vie_Latn",
        "languages": [
          "zho-Hans",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.352549,
        "recall": 0.410616,
        "f1": 0.36627,
        "accuracy": 0.410616,
        "main_score": 0.36627,
        "hf_subset": "zho_Hans-yue_Hant",
        "languages": [
          "zho-Hans",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.367462,
        "recall": 0.452178,
        "f1": 0.388929,
        "accuracy": 0.452178,
        "main_score": 0.388929,
        "hf_subset": "zho_Hans-zho_Hant",
        "languages": [
          "zho-Hans",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.00227,
        "recall": 0.005008,
        "f1": 0.002663,
        "accuracy": 0.005008,
        "main_score": 0.002663,
        "hf_subset": "zho_Hant-arb_Arab",
        "languages": [
          "zho-Hant",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001005,
        "recall": 0.002003,
        "f1": 0.001008,
        "accuracy": 0.002003,
        "main_score": 0.001008,
        "hf_subset": "zho_Hant-ben_Beng",
        "languages": [
          "zho-Hant",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.050806,
        "recall": 0.065098,
        "f1": 0.05365,
        "accuracy": 0.065098,
        "main_score": 0.05365,
        "hf_subset": "zho_Hant-deu_Latn",
        "languages": [
          "zho-Hant",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.001999,
        "recall": 0.004507,
        "f1": 0.002264,
        "accuracy": 0.004507,
        "main_score": 0.002264,
        "hf_subset": "zho_Hant-ell_Grek",
        "languages": [
          "zho-Hant",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.126115,
        "recall": 0.143215,
        "f1": 0.130201,
        "accuracy": 0.143215,
        "main_score": 0.130201,
        "hf_subset": "zho_Hant-eng_Latn",
        "languages": [
          "zho-Hant",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006411,
        "recall": 0.011017,
        "f1": 0.007041,
        "accuracy": 0.011017,
        "main_score": 0.007041,
        "hf_subset": "zho_Hant-fas_Arab",
        "languages": [
          "zho-Hant",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.0401,
        "recall": 0.047071,
        "f1": 0.041672,
        "accuracy": 0.047071,
        "main_score": 0.041672,
        "hf_subset": "zho_Hant-fin_Latn",
        "languages": [
          "zho-Hant",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.063557,
        "recall": 0.079119,
        "f1": 0.066877,
        "accuracy": 0.079119,
        "main_score": 0.066877,
        "hf_subset": "zho_Hant-fra_Latn",
        "languages": [
          "zho-Hant",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.004815,
        "recall": 0.008012,
        "f1": 0.005281,
        "accuracy": 0.008012,
        "main_score": 0.005281,
        "hf_subset": "zho_Hant-heb_Hebr",
        "languages": [
          "zho-Hant",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.004422,
        "recall": 0.008012,
        "f1": 0.004698,
        "accuracy": 0.008012,
        "main_score": 0.004698,
        "hf_subset": "zho_Hant-hin_Deva",
        "languages": [
          "zho-Hant",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.040506,
        "recall": 0.052078,
        "f1": 0.042572,
        "accuracy": 0.052078,
        "main_score": 0.042572,
        "hf_subset": "zho_Hant-hun_Latn",
        "languages": [
          "zho-Hant",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.047367,
        "recall": 0.059589,
        "f1": 0.049992,
        "accuracy": 0.059589,
        "main_score": 0.049992,
        "hf_subset": "zho_Hant-ind_Latn",
        "languages": [
          "zho-Hant",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.01659,
        "recall": 0.036054,
        "f1": 0.019153,
        "accuracy": 0.036054,
        "main_score": 0.019153,
        "hf_subset": "zho_Hant-jpn_Jpan",
        "languages": [
          "zho-Hant",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.008398,
        "recall": 0.015523,
        "f1": 0.009759,
        "accuracy": 0.015523,
        "main_score": 0.009759,
        "hf_subset": "zho_Hant-kor_Hang",
        "languages": [
          "zho-Hant",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.026769,
        "recall": 0.037056,
        "f1": 0.029013,
        "accuracy": 0.037056,
        "main_score": 0.029013,
        "hf_subset": "zho_Hant-lit_Latn",
        "languages": [
          "zho-Hant",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.054611,
        "recall": 0.068102,
        "f1": 0.057373,
        "accuracy": 0.068102,
        "main_score": 0.057373,
        "hf_subset": "zho_Hant-nld_Latn",
        "languages": [
          "zho-Hant",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.041547,
        "recall": 0.052078,
        "f1": 0.043979,
        "accuracy": 0.052078,
        "main_score": 0.043979,
        "hf_subset": "zho_Hant-pol_Latn",
        "languages": [
          "zho-Hant",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.060399,
        "recall": 0.078618,
        "f1": 0.063781,
        "accuracy": 0.078618,
        "main_score": 0.063781,
        "hf_subset": "zho_Hant-por_Latn",
        "languages": [
          "zho-Hant",
          "por-Latn"
        ]
      },
      {
        "precision": 0.005844,
        "recall": 0.008012,
        "f1": 0.006006,
        "accuracy": 0.008012,
        "main_score": 0.006006,
        "hf_subset": "zho_Hant-rus_Cyrl",
        "languages": [
          "zho-Hant",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.048517,
        "recall": 0.058588,
        "f1": 0.050782,
        "accuracy": 0.058588,
        "main_score": 0.050782,
        "hf_subset": "zho_Hant-spa_Latn",
        "languages": [
          "zho-Hant",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.023977,
        "recall": 0.031547,
        "f1": 0.025665,
        "accuracy": 0.031547,
        "main_score": 0.025665,
        "hf_subset": "zho_Hant-swa_Latn",
        "languages": [
          "zho-Hant",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.066905,
        "recall": 0.078117,
        "f1": 0.0695,
        "accuracy": 0.078117,
        "main_score": 0.0695,
        "hf_subset": "zho_Hant-swe_Latn",
        "languages": [
          "zho-Hant",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.004985,
        "recall": 0.009014,
        "f1": 0.005515,
        "accuracy": 0.009014,
        "main_score": 0.005515,
        "hf_subset": "zho_Hant-tam_Taml",
        "languages": [
          "zho-Hant",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.041887,
        "recall": 0.055083,
        "f1": 0.04467,
        "accuracy": 0.055083,
        "main_score": 0.04467,
        "hf_subset": "zho_Hant-tur_Latn",
        "languages": [
          "zho-Hant",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.038856,
        "recall": 0.047571,
        "f1": 0.040493,
        "accuracy": 0.047571,
        "main_score": 0.040493,
        "hf_subset": "zho_Hant-vie_Latn",
        "languages": [
          "zho-Hant",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.313837,
        "recall": 0.371557,
        "f1": 0.327389,
        "accuracy": 0.371557,
        "main_score": 0.327389,
        "hf_subset": "zho_Hant-yue_Hant",
        "languages": [
          "zho-Hant",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.387186,
        "recall": 0.468202,
        "f1": 0.408832,
        "accuracy": 0.468202,
        "main_score": 0.408832,
        "hf_subset": "zho_Hant-zho_Hans",
        "languages": [
          "zho-Hant",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.0451,
        "recall": 0.06009,
        "f1": 0.048385,
        "accuracy": 0.06009,
        "main_score": 0.048385,
        "hf_subset": "zho_Hant-zul_Latn",
        "languages": [
          "zho-Hant",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.006359,
        "recall": 0.01352,
        "f1": 0.007184,
        "accuracy": 0.01352,
        "main_score": 0.007184,
        "hf_subset": "zul_Latn-amh_Ethi",
        "languages": [
          "zul-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.001041,
        "recall": 0.003005,
        "f1": 0.001078,
        "accuracy": 0.003005,
        "main_score": 0.001078,
        "hf_subset": "zul_Latn-arb_Arab",
        "languages": [
          "zul-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001753,
        "recall": 0.002003,
        "f1": 0.001836,
        "accuracy": 0.002003,
        "main_score": 0.001836,
        "hf_subset": "zul_Latn-ben_Beng",
        "languages": [
          "zul-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.016387,
        "recall": 0.021032,
        "f1": 0.017013,
        "accuracy": 0.021032,
        "main_score": 0.017013,
        "hf_subset": "zul_Latn-deu_Latn",
        "languages": [
          "zul-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000533,
        "recall": 0.004507,
        "f1": 0.000837,
        "accuracy": 0.004507,
        "main_score": 0.000837,
        "hf_subset": "zul_Latn-ell_Grek",
        "languages": [
          "zul-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.031486,
        "recall": 0.041562,
        "f1": 0.032726,
        "accuracy": 0.041562,
        "main_score": 0.032726,
        "hf_subset": "zul_Latn-eng_Latn",
        "languages": [
          "zul-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002253,
        "recall": 0.005508,
        "f1": 0.002408,
        "accuracy": 0.005508,
        "main_score": 0.002408,
        "hf_subset": "zul_Latn-fas_Arab",
        "languages": [
          "zul-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.011651,
        "recall": 0.015023,
        "f1": 0.012351,
        "accuracy": 0.015023,
        "main_score": 0.012351,
        "hf_subset": "zul_Latn-fin_Latn",
        "languages": [
          "zul-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.019169,
        "recall": 0.024537,
        "f1": 0.019749,
        "accuracy": 0.024537,
        "main_score": 0.019749,
        "hf_subset": "zul_Latn-fra_Latn",
        "languages": [
          "zul-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.012014,
        "recall": 0.015023,
        "f1": 0.01258,
        "accuracy": 0.015023,
        "main_score": 0.01258,
        "hf_subset": "zul_Latn-hau_Latn",
        "languages": [
          "zul-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.000759,
        "recall": 0.001502,
        "f1": 0.000849,
        "accuracy": 0.001502,
        "main_score": 0.000849,
        "hf_subset": "zul_Latn-heb_Hebr",
        "languages": [
          "zul-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000639,
        "recall": 0.002003,
        "f1": 0.000727,
        "accuracy": 0.002003,
        "main_score": 0.000727,
        "hf_subset": "zul_Latn-hin_Deva",
        "languages": [
          "zul-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015189,
        "recall": 0.019529,
        "f1": 0.016089,
        "accuracy": 0.019529,
        "main_score": 0.016089,
        "hf_subset": "zul_Latn-hun_Latn",
        "languages": [
          "zul-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.020076,
        "recall": 0.026039,
        "f1": 0.020962,
        "accuracy": 0.026039,
        "main_score": 0.020962,
        "hf_subset": "zul_Latn-ibo_Latn",
        "languages": [
          "zul-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.013184,
        "recall": 0.015523,
        "f1": 0.013497,
        "accuracy": 0.015523,
        "main_score": 0.013497,
        "hf_subset": "zul_Latn-ind_Latn",
        "languages": [
          "zul-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001077,
        "recall": 0.003505,
        "f1": 0.001309,
        "accuracy": 0.003505,
        "main_score": 0.001309,
        "hf_subset": "zul_Latn-jpn_Jpan",
        "languages": [
          "zul-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001037,
        "recall": 0.003505,
        "f1": 0.001303,
        "accuracy": 0.003505,
        "main_score": 0.001303,
        "hf_subset": "zul_Latn-kor_Hang",
        "languages": [
          "zul-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.006328,
        "recall": 0.010516,
        "f1": 0.007039,
        "accuracy": 0.010516,
        "main_score": 0.007039,
        "hf_subset": "zul_Latn-lit_Latn",
        "languages": [
          "zul-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.013388,
        "recall": 0.016024,
        "f1": 0.013612,
        "accuracy": 0.016024,
        "main_score": 0.013612,
        "hf_subset": "zul_Latn-nld_Latn",
        "languages": [
          "zul-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.023956,
        "recall": 0.031547,
        "f1": 0.025082,
        "accuracy": 0.031547,
        "main_score": 0.025082,
        "hf_subset": "zul_Latn-nso_Latn",
        "languages": [
          "zul-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.006968,
        "recall": 0.011517,
        "f1": 0.00766,
        "accuracy": 0.011517,
        "main_score": 0.00766,
        "hf_subset": "zul_Latn-orm_Ethi",
        "languages": [
          "zul-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.012186,
        "recall": 0.016525,
        "f1": 0.012747,
        "accuracy": 0.016525,
        "main_score": 0.012747,
        "hf_subset": "zul_Latn-pol_Latn",
        "languages": [
          "zul-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.018294,
        "recall": 0.024036,
        "f1": 0.0193,
        "accuracy": 0.024036,
        "main_score": 0.0193,
        "hf_subset": "zul_Latn-por_Latn",
        "languages": [
          "zul-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000185,
        "recall": 0.001002,
        "f1": 0.000285,
        "accuracy": 0.001002,
        "main_score": 0.000285,
        "hf_subset": "zul_Latn-rus_Cyrl",
        "languages": [
          "zul-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.012595,
        "recall": 0.015023,
        "f1": 0.012892,
        "accuracy": 0.015023,
        "main_score": 0.012892,
        "hf_subset": "zul_Latn-som_Latn",
        "languages": [
          "zul-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.024002,
        "recall": 0.031547,
        "f1": 0.025243,
        "accuracy": 0.031547,
        "main_score": 0.025243,
        "hf_subset": "zul_Latn-spa_Latn",
        "languages": [
          "zul-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.149074,
        "recall": 0.205308,
        "f1": 0.161347,
        "accuracy": 0.205308,
        "main_score": 0.161347,
        "hf_subset": "zul_Latn-ssw_Latn",
        "languages": [
          "zul-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.01337,
        "recall": 0.021032,
        "f1": 0.014313,
        "accuracy": 0.021032,
        "main_score": 0.014313,
        "hf_subset": "zul_Latn-swa_Latn",
        "languages": [
          "zul-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.016837,
        "recall": 0.023035,
        "f1": 0.017593,
        "accuracy": 0.023035,
        "main_score": 0.017593,
        "hf_subset": "zul_Latn-swe_Latn",
        "languages": [
          "zul-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.002112,
        "recall": 0.005008,
        "f1": 0.002355,
        "accuracy": 0.005008,
        "main_score": 0.002355,
        "hf_subset": "zul_Latn-tam_Taml",
        "languages": [
          "zul-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.006517,
        "recall": 0.012018,
        "f1": 0.006816,
        "accuracy": 0.012018,
        "main_score": 0.006816,
        "hf_subset": "zul_Latn-tir_Ethi",
        "languages": [
          "zul-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.016074,
        "recall": 0.022534,
        "f1": 0.016849,
        "accuracy": 0.022534,
        "main_score": 0.016849,
        "hf_subset": "zul_Latn-tsn_Latn",
        "languages": [
          "zul-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.011246,
        "recall": 0.017026,
        "f1": 0.012246,
        "accuracy": 0.017026,
        "main_score": 0.012246,
        "hf_subset": "zul_Latn-tur_Latn",
        "languages": [
          "zul-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.010137,
        "recall": 0.014021,
        "f1": 0.010818,
        "accuracy": 0.014021,
        "main_score": 0.010818,
        "hf_subset": "zul_Latn-vie_Latn",
        "languages": [
          "zul-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.012354,
        "recall": 0.016525,
        "f1": 0.01295,
        "accuracy": 0.016525,
        "main_score": 0.01295,
        "hf_subset": "zul_Latn-wol_Latn",
        "languages": [
          "zul-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.146266,
        "recall": 0.201302,
        "f1": 0.158194,
        "accuracy": 0.201302,
        "main_score": 0.158194,
        "hf_subset": "zul_Latn-xho_Latn",
        "languages": [
          "zul-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.013721,
        "recall": 0.019529,
        "f1": 0.014879,
        "accuracy": 0.019529,
        "main_score": 0.014879,
        "hf_subset": "zul_Latn-yor_Latn",
        "languages": [
          "zul-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.021913,
        "recall": 0.035553,
        "f1": 0.02358,
        "accuracy": 0.035553,
        "main_score": 0.02358,
        "hf_subset": "zul_Latn-zho_Hant",
        "languages": [
          "zul-Latn",
          "zho-Hant"
        ]
      }
    ]
  },
  "evaluation_time": 110.01297378540039,
  "kg_co2_emissions": 0.002464619184143091
}