{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.089752,
        "mrr": 0.074171,
        "nAUC_map_max": 0.063351,
        "nAUC_map_std": -0.151531,
        "nAUC_map_diff1": 0.208964,
        "nAUC_mrr_max": 0.067384,
        "nAUC_mrr_std": -0.147242,
        "nAUC_mrr_diff1": 0.220716,
        "main_score": 0.074171,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.066916,
        "mrr": 0.049486,
        "nAUC_map_max": -0.056853,
        "nAUC_map_std": -0.27687,
        "nAUC_map_diff1": 0.069138,
        "nAUC_mrr_max": -0.056384,
        "nAUC_mrr_std": -0.269053,
        "nAUC_mrr_diff1": 0.068967,
        "main_score": 0.049486,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.081207,
        "mrr": 0.067124,
        "nAUC_map_max": -0.068004,
        "nAUC_map_std": -0.2198,
        "nAUC_map_diff1": 0.005164,
        "nAUC_mrr_max": -0.058649,
        "nAUC_mrr_std": -0.222891,
        "nAUC_mrr_diff1": 0.011555,
        "main_score": 0.067124,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.086202,
        "mrr": 0.067247,
        "nAUC_map_max": -0.06874,
        "nAUC_map_std": -0.094761,
        "nAUC_map_diff1": 0.166386,
        "nAUC_mrr_max": -0.078668,
        "nAUC_mrr_std": -0.092047,
        "nAUC_mrr_diff1": 0.155912,
        "main_score": 0.067247,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.087667,
        "mrr": 0.070692,
        "nAUC_map_max": -0.15366,
        "nAUC_map_std": -0.19994,
        "nAUC_map_diff1": 0.097744,
        "nAUC_mrr_max": -0.159782,
        "nAUC_mrr_std": -0.187882,
        "nAUC_mrr_diff1": 0.10363,
        "main_score": 0.070692,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.065313,
        "mrr": 0.050392,
        "nAUC_map_max": 0.059408,
        "nAUC_map_std": -0.248905,
        "nAUC_map_diff1": 0.111785,
        "nAUC_mrr_max": 0.066485,
        "nAUC_mrr_std": -0.240134,
        "nAUC_mrr_diff1": 0.123677,
        "main_score": 0.050392,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 442.3140482902527,
  "kg_co2_emissions": 0.010221303522434368
}