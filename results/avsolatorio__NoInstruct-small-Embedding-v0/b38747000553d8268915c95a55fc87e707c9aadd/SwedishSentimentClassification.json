{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.697412,
        "f1": 0.6963,
        "f1_weighted": 0.696315,
        "ap": 0.638006,
        "ap_weighted": 0.638006,
        "scores_per_experiment": [
          {
            "accuracy": 0.695312,
            "f1": 0.691421,
            "f1_weighted": 0.691522,
            "ap": 0.629989,
            "ap_weighted": 0.629989
          },
          {
            "accuracy": 0.672852,
            "f1": 0.671725,
            "f1_weighted": 0.671668,
            "ap": 0.621905,
            "ap_weighted": 0.621905
          },
          {
            "accuracy": 0.666992,
            "f1": 0.666981,
            "f1_weighted": 0.666986,
            "ap": 0.612513,
            "ap_weighted": 0.612513
          },
          {
            "accuracy": 0.698242,
            "f1": 0.697021,
            "f1_weighted": 0.696965,
            "ap": 0.645802,
            "ap_weighted": 0.645802
          },
          {
            "accuracy": 0.703613,
            "f1": 0.703399,
            "f1_weighted": 0.703423,
            "ap": 0.642545,
            "ap_weighted": 0.642545
          },
          {
            "accuracy": 0.716309,
            "f1": 0.715722,
            "f1_weighted": 0.71576,
            "ap": 0.652387,
            "ap_weighted": 0.652387
          },
          {
            "accuracy": 0.725586,
            "f1": 0.722142,
            "f1_weighted": 0.722233,
            "ap": 0.655578,
            "ap_weighted": 0.655578
          },
          {
            "accuracy": 0.711426,
            "f1": 0.710996,
            "f1_weighted": 0.711028,
            "ap": 0.648572,
            "ap_weighted": 0.648572
          },
          {
            "accuracy": 0.679199,
            "f1": 0.679,
            "f1_weighted": 0.678977,
            "ap": 0.624933,
            "ap_weighted": 0.624933
          },
          {
            "accuracy": 0.70459,
            "f1": 0.704588,
            "f1_weighted": 0.704586,
            "ap": 0.645834,
            "ap_weighted": 0.645834
          }
        ],
        "main_score": 0.697412,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.698828,
        "f1": 0.697618,
        "f1_weighted": 0.697628,
        "ap": 0.639123,
        "ap_weighted": 0.639123,
        "scores_per_experiment": [
          {
            "accuracy": 0.689453,
            "f1": 0.684124,
            "f1_weighted": 0.684205,
            "ap": 0.623982,
            "ap_weighted": 0.623982
          },
          {
            "accuracy": 0.69043,
            "f1": 0.689748,
            "f1_weighted": 0.68972,
            "ap": 0.636301,
            "ap_weighted": 0.636301
          },
          {
            "accuracy": 0.672852,
            "f1": 0.67282,
            "f1_weighted": 0.672814,
            "ap": 0.617894,
            "ap_weighted": 0.617894
          },
          {
            "accuracy": 0.706055,
            "f1": 0.704828,
            "f1_weighted": 0.704791,
            "ap": 0.652884,
            "ap_weighted": 0.652884
          },
          {
            "accuracy": 0.716309,
            "f1": 0.7163,
            "f1_weighted": 0.716303,
            "ap": 0.655414,
            "ap_weighted": 0.655414
          },
          {
            "accuracy": 0.716797,
            "f1": 0.71612,
            "f1_weighted": 0.716147,
            "ap": 0.652103,
            "ap_weighted": 0.652103
          },
          {
            "accuracy": 0.709473,
            "f1": 0.706356,
            "f1_weighted": 0.706415,
            "ap": 0.641914,
            "ap_weighted": 0.641914
          },
          {
            "accuracy": 0.729004,
            "f1": 0.728395,
            "f1_weighted": 0.72842,
            "ap": 0.663292,
            "ap_weighted": 0.663292
          },
          {
            "accuracy": 0.664551,
            "f1": 0.664124,
            "f1_weighted": 0.664101,
            "ap": 0.612473,
            "ap_weighted": 0.612473
          },
          {
            "accuracy": 0.693359,
            "f1": 0.693359,
            "f1_weighted": 0.69336,
            "ap": 0.634971,
            "ap_weighted": 0.634971
          }
        ],
        "main_score": 0.698828,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 19.662450790405273,
  "kg_co2_emissions": 0.0007034149843934557
}