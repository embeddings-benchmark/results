{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.34.7",
  "scores": {
    "test": [
      {
        "map": 0.923209,
        "mrr": 0.923209,
        "nAUC_map_max": 0.525842,
        "nAUC_map_std": 0.457204,
        "nAUC_map_diff1": 0.824218,
        "nAUC_mrr_max": 0.525842,
        "nAUC_mrr_std": 0.457204,
        "nAUC_mrr_diff1": 0.824218,
        "main_score": 0.923209,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.885629,
        "mrr": 0.885629,
        "nAUC_map_max": 0.48838,
        "nAUC_map_std": 0.431724,
        "nAUC_map_diff1": 0.811389,
        "nAUC_mrr_max": 0.48838,
        "nAUC_mrr_std": 0.431724,
        "nAUC_mrr_diff1": 0.811389,
        "main_score": 0.885629,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.935884,
        "mrr": 0.935884,
        "nAUC_map_max": 0.509284,
        "nAUC_map_std": 0.432981,
        "nAUC_map_diff1": 0.83423,
        "nAUC_mrr_max": 0.509284,
        "nAUC_mrr_std": 0.432981,
        "nAUC_mrr_diff1": 0.83423,
        "main_score": 0.935884,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.924933,
        "mrr": 0.925377,
        "nAUC_map_max": 0.486331,
        "nAUC_map_std": 0.433005,
        "nAUC_map_diff1": 0.845003,
        "nAUC_mrr_max": 0.486822,
        "nAUC_mrr_std": 0.430986,
        "nAUC_mrr_diff1": 0.843555,
        "main_score": 0.924933,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.928147,
        "mrr": 0.928147,
        "nAUC_map_max": 0.547465,
        "nAUC_map_std": 0.454538,
        "nAUC_map_diff1": 0.85261,
        "nAUC_mrr_max": 0.547465,
        "nAUC_mrr_std": 0.454538,
        "nAUC_mrr_diff1": 0.85261,
        "main_score": 0.928147,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.94677,
        "mrr": 0.94677,
        "nAUC_map_max": 0.578168,
        "nAUC_map_std": 0.429495,
        "nAUC_map_diff1": 0.897533,
        "nAUC_mrr_max": 0.578168,
        "nAUC_mrr_std": 0.429495,
        "nAUC_mrr_diff1": 0.897533,
        "main_score": 0.94677,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.912046,
        "mrr": 0.912046,
        "nAUC_map_max": 0.510515,
        "nAUC_map_std": 0.41596,
        "nAUC_map_diff1": 0.852103,
        "nAUC_mrr_max": 0.510515,
        "nAUC_mrr_std": 0.41596,
        "nAUC_mrr_diff1": 0.852103,
        "main_score": 0.912046,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.931903,
        "mrr": 0.931903,
        "nAUC_map_max": 0.416707,
        "nAUC_map_std": 0.348459,
        "nAUC_map_diff1": 0.828237,
        "nAUC_mrr_max": 0.416707,
        "nAUC_mrr_std": 0.348459,
        "nAUC_mrr_diff1": 0.828237,
        "main_score": 0.931903,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.900124,
        "mrr": 0.900822,
        "nAUC_map_max": 0.431956,
        "nAUC_map_std": 0.345488,
        "nAUC_map_diff1": 0.81944,
        "nAUC_mrr_max": 0.440057,
        "nAUC_mrr_std": 0.359617,
        "nAUC_mrr_diff1": 0.817401,
        "main_score": 0.900124,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.933635,
        "mrr": 0.933635,
        "nAUC_map_max": 0.598122,
        "nAUC_map_std": 0.434696,
        "nAUC_map_diff1": 0.870143,
        "nAUC_mrr_max": 0.598122,
        "nAUC_mrr_std": 0.434696,
        "nAUC_mrr_diff1": 0.870143,
        "main_score": 0.933635,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.9267,
        "mrr": 0.927034,
        "nAUC_map_max": 0.390691,
        "nAUC_map_std": 0.384074,
        "nAUC_map_diff1": 0.797249,
        "nAUC_mrr_max": 0.391698,
        "nAUC_mrr_std": 0.390972,
        "nAUC_mrr_diff1": 0.795823,
        "main_score": 0.9267,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.920441,
        "mrr": 0.920441,
        "nAUC_map_max": 0.464375,
        "nAUC_map_std": 0.353333,
        "nAUC_map_diff1": 0.832309,
        "nAUC_mrr_max": 0.464375,
        "nAUC_mrr_std": 0.353333,
        "nAUC_mrr_diff1": 0.832309,
        "main_score": 0.920441,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.922966,
        "mrr": 0.923299,
        "nAUC_map_max": 0.476462,
        "nAUC_map_std": 0.419306,
        "nAUC_map_diff1": 0.881699,
        "nAUC_mrr_max": 0.47584,
        "nAUC_mrr_std": 0.421689,
        "nAUC_mrr_diff1": 0.88066,
        "main_score": 0.922966,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.922052,
        "mrr": 0.922385,
        "nAUC_map_max": 0.5183,
        "nAUC_map_std": 0.385684,
        "nAUC_map_diff1": 0.872236,
        "nAUC_mrr_max": 0.527935,
        "nAUC_mrr_std": 0.394812,
        "nAUC_mrr_diff1": 0.871173,
        "main_score": 0.922052,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.907329,
        "mrr": 0.907329,
        "nAUC_map_max": 0.531941,
        "nAUC_map_std": 0.350571,
        "nAUC_map_diff1": 0.830632,
        "nAUC_mrr_max": 0.531941,
        "nAUC_mrr_std": 0.350571,
        "nAUC_mrr_diff1": 0.830632,
        "main_score": 0.907329,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.93651,
        "mrr": 0.93651,
        "nAUC_map_max": 0.406171,
        "nAUC_map_std": 0.41378,
        "nAUC_map_diff1": 0.836553,
        "nAUC_mrr_max": 0.406171,
        "nAUC_mrr_std": 0.41378,
        "nAUC_mrr_diff1": 0.836553,
        "main_score": 0.93651,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 735.3436892032623,
  "kg_co2_emissions": null
}