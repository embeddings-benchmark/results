{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.34.7",
  "scores": {
    "validation": [
      {
        "accuracy": 0.43667,
        "f1": 0.370916,
        "f1_weighted": 0.437128,
        "scores_per_experiment": [
          {
            "accuracy": 0.44043,
            "f1": 0.377734,
            "f1_weighted": 0.444028
          },
          {
            "accuracy": 0.420898,
            "f1": 0.352315,
            "f1_weighted": 0.418354
          },
          {
            "accuracy": 0.437012,
            "f1": 0.362281,
            "f1_weighted": 0.43418
          },
          {
            "accuracy": 0.434082,
            "f1": 0.369501,
            "f1_weighted": 0.434988
          },
          {
            "accuracy": 0.437012,
            "f1": 0.371934,
            "f1_weighted": 0.439801
          },
          {
            "accuracy": 0.437988,
            "f1": 0.377901,
            "f1_weighted": 0.444384
          },
          {
            "accuracy": 0.453125,
            "f1": 0.380428,
            "f1_weighted": 0.455816
          },
          {
            "accuracy": 0.439941,
            "f1": 0.376406,
            "f1_weighted": 0.439358
          },
          {
            "accuracy": 0.433105,
            "f1": 0.375308,
            "f1_weighted": 0.430991
          },
          {
            "accuracy": 0.433105,
            "f1": 0.365355,
            "f1_weighted": 0.429378
          }
        ],
        "main_score": 0.43667,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.438477,
        "f1": 0.391904,
        "f1_weighted": 0.438693,
        "scores_per_experiment": [
          {
            "accuracy": 0.445801,
            "f1": 0.390905,
            "f1_weighted": 0.448084
          },
          {
            "accuracy": 0.435059,
            "f1": 0.39512,
            "f1_weighted": 0.430665
          },
          {
            "accuracy": 0.423828,
            "f1": 0.380912,
            "f1_weighted": 0.420085
          },
          {
            "accuracy": 0.434082,
            "f1": 0.384341,
            "f1_weighted": 0.433707
          },
          {
            "accuracy": 0.427246,
            "f1": 0.389854,
            "f1_weighted": 0.42397
          },
          {
            "accuracy": 0.430664,
            "f1": 0.385652,
            "f1_weighted": 0.435292
          },
          {
            "accuracy": 0.450684,
            "f1": 0.400123,
            "f1_weighted": 0.455926
          },
          {
            "accuracy": 0.445801,
            "f1": 0.392052,
            "f1_weighted": 0.442597
          },
          {
            "accuracy": 0.448242,
            "f1": 0.403567,
            "f1_weighted": 0.452044
          },
          {
            "accuracy": 0.443359,
            "f1": 0.396512,
            "f1_weighted": 0.444562
          }
        ],
        "main_score": 0.438477,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 529.1284005641937,
  "kg_co2_emissions": null
}