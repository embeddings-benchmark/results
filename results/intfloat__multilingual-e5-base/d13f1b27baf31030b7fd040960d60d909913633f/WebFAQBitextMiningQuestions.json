{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQuestions",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 0.977833,
        "recall": 0.985222,
        "f1": 0.980296,
        "accuracy": 0.985222,
        "main_score": 0.980296,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.863599,
        "recall": 0.902863,
        "f1": 0.875767,
        "accuracy": 0.902863,
        "main_score": 0.875767,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.955176,
        "recall": 0.968672,
        "f1": 0.95955,
        "accuracy": 0.968672,
        "main_score": 0.95955,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.963188,
        "recall": 0.974926,
        "f1": 0.966986,
        "accuracy": 0.974926,
        "main_score": 0.966986,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.979552,
        "recall": 0.986111,
        "f1": 0.981674,
        "accuracy": 0.986111,
        "main_score": 0.981674,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.965608,
        "recall": 0.976912,
        "f1": 0.969336,
        "accuracy": 0.976912,
        "main_score": 0.969336,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.970101,
        "recall": 0.978841,
        "f1": 0.972861,
        "accuracy": 0.978841,
        "main_score": 0.972861,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.979102,
        "recall": 0.986068,
        "f1": 0.981424,
        "accuracy": 0.986068,
        "main_score": 0.981424,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.929011,
        "recall": 0.938462,
        "f1": 0.931868,
        "accuracy": 0.938462,
        "main_score": 0.931868,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.972222,
        "recall": 0.981481,
        "f1": 0.975309,
        "accuracy": 0.981481,
        "main_score": 0.975309,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.897549,
        "recall": 0.926868,
        "f1": 0.906518,
        "accuracy": 0.926868,
        "main_score": 0.906518,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.967901,
        "recall": 0.978451,
        "f1": 0.97138,
        "accuracy": 0.978451,
        "main_score": 0.97138,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.974648,
        "recall": 0.983099,
        "f1": 0.977465,
        "accuracy": 0.983099,
        "main_score": 0.977465,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.941885,
        "recall": 0.960149,
        "f1": 0.947904,
        "accuracy": 0.960149,
        "main_score": 0.947904,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.965443,
        "recall": 0.976147,
        "f1": 0.968909,
        "accuracy": 0.976147,
        "main_score": 0.968909,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.978207,
        "recall": 0.985095,
        "f1": 0.980465,
        "accuracy": 0.985095,
        "main_score": 0.980465,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.959705,
        "recall": 0.973137,
        "f1": 0.964183,
        "accuracy": 0.973137,
        "main_score": 0.964183,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.934377,
        "recall": 0.950677,
        "f1": 0.93925,
        "accuracy": 0.950677,
        "main_score": 0.93925,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.940315,
        "recall": 0.959459,
        "f1": 0.946509,
        "accuracy": 0.959459,
        "main_score": 0.946509,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.966015,
        "recall": 0.976723,
        "f1": 0.969584,
        "accuracy": 0.976723,
        "main_score": 0.969584,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.970857,
        "recall": 0.980571,
        "f1": 0.974095,
        "accuracy": 0.980571,
        "main_score": 0.974095,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.943446,
        "recall": 0.962076,
        "f1": 0.949601,
        "accuracy": 0.962076,
        "main_score": 0.949601,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.978022,
        "recall": 0.984556,
        "f1": 0.98015,
        "accuracy": 0.984556,
        "main_score": 0.98015,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.962041,
        "recall": 0.973414,
        "f1": 0.965594,
        "accuracy": 0.973414,
        "main_score": 0.965594,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.99412,
        "recall": 0.99608,
        "f1": 0.994773,
        "accuracy": 0.99608,
        "main_score": 0.994773,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.952623,
        "recall": 0.965693,
        "f1": 0.956679,
        "accuracy": 0.965693,
        "main_score": 0.956679,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.951197,
        "recall": 0.966851,
        "f1": 0.956262,
        "accuracy": 0.966851,
        "main_score": 0.956262,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.939818,
        "recall": 0.957977,
        "f1": 0.945655,
        "accuracy": 0.957977,
        "main_score": 0.945655,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.966454,
        "recall": 0.977636,
        "f1": 0.970181,
        "accuracy": 0.977636,
        "main_score": 0.970181,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.972646,
        "recall": 0.980916,
        "f1": 0.975191,
        "accuracy": 0.980916,
        "main_score": 0.975191,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.939208,
        "recall": 0.957587,
        "f1": 0.945178,
        "accuracy": 0.957587,
        "main_score": 0.945178,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.971959,
        "recall": 0.981073,
        "f1": 0.974939,
        "accuracy": 0.981073,
        "main_score": 0.974939,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.959042,
        "recall": 0.97238,
        "f1": 0.963409,
        "accuracy": 0.97238,
        "main_score": 0.963409,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.971483,
        "recall": 0.980989,
        "f1": 0.974651,
        "accuracy": 0.980989,
        "main_score": 0.974651,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.946589,
        "recall": 0.96332,
        "f1": 0.952059,
        "accuracy": 0.96332,
        "main_score": 0.952059,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.964594,
        "recall": 0.97582,
        "f1": 0.968336,
        "accuracy": 0.97582,
        "main_score": 0.968336,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.968161,
        "recall": 0.978558,
        "f1": 0.971572,
        "accuracy": 0.978558,
        "main_score": 0.971572,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.971904,
        "recall": 0.98127,
        "f1": 0.975026,
        "accuracy": 0.98127,
        "main_score": 0.975026,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.953046,
        "recall": 0.967404,
        "f1": 0.957703,
        "accuracy": 0.967404,
        "main_score": 0.957703,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.948105,
        "recall": 0.965404,
        "f1": 0.953871,
        "accuracy": 0.965404,
        "main_score": 0.953871,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.949139,
        "recall": 0.965571,
        "f1": 0.954617,
        "accuracy": 0.965571,
        "main_score": 0.954617,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.951678,
        "recall": 0.966095,
        "f1": 0.956259,
        "accuracy": 0.966095,
        "main_score": 0.956259,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.976538,
        "recall": 0.983837,
        "f1": 0.978971,
        "accuracy": 0.983837,
        "main_score": 0.978971,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.957911,
        "recall": 0.970333,
        "f1": 0.961857,
        "accuracy": 0.970333,
        "main_score": 0.961857,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.896003,
        "recall": 0.924797,
        "f1": 0.904617,
        "accuracy": 0.924797,
        "main_score": 0.904617,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.950281,
        "recall": 0.965823,
        "f1": 0.955345,
        "accuracy": 0.965823,
        "main_score": 0.955345,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.95925,
        "recall": 0.971496,
        "f1": 0.963183,
        "accuracy": 0.971496,
        "main_score": 0.963183,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.941606,
        "recall": 0.958942,
        "f1": 0.947189,
        "accuracy": 0.958942,
        "main_score": 0.947189,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.922344,
        "recall": 0.947253,
        "f1": 0.930403,
        "accuracy": 0.947253,
        "main_score": 0.930403,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.982078,
        "recall": 0.987476,
        "f1": 0.983846,
        "accuracy": 0.987476,
        "main_score": 0.983846,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.96212,
        "recall": 0.972994,
        "f1": 0.965515,
        "accuracy": 0.972994,
        "main_score": 0.965515,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.862631,
        "recall": 0.896613,
        "f1": 0.872351,
        "accuracy": 0.896613,
        "main_score": 0.872351,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.957804,
        "recall": 0.971398,
        "f1": 0.962218,
        "accuracy": 0.971398,
        "main_score": 0.962218,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.878713,
        "recall": 0.911824,
        "f1": 0.888844,
        "accuracy": 0.911824,
        "main_score": 0.888844,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.943838,
        "recall": 0.960437,
        "f1": 0.949022,
        "accuracy": 0.960437,
        "main_score": 0.949022,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.952263,
        "recall": 0.963576,
        "f1": 0.955519,
        "accuracy": 0.963576,
        "main_score": 0.955519,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.977982,
        "recall": 0.98495,
        "f1": 0.980212,
        "accuracy": 0.98495,
        "main_score": 0.980212,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.979266,
        "recall": 0.985646,
        "f1": 0.98126,
        "accuracy": 0.985646,
        "main_score": 0.98126,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.991892,
        "recall": 0.994595,
        "f1": 0.992793,
        "accuracy": 0.994595,
        "main_score": 0.992793,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.987727,
        "recall": 0.991692,
        "f1": 0.989048,
        "accuracy": 0.991692,
        "main_score": 0.989048,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.973446,
        "recall": 0.982015,
        "f1": 0.976251,
        "accuracy": 0.982015,
        "main_score": 0.976251,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.969534,
        "recall": 0.979221,
        "f1": 0.97269,
        "accuracy": 0.979221,
        "main_score": 0.97269,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.889399,
        "recall": 0.923547,
        "f1": 0.900102,
        "accuracy": 0.923547,
        "main_score": 0.900102,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.967282,
        "recall": 0.977475,
        "f1": 0.970595,
        "accuracy": 0.977475,
        "main_score": 0.970595,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.977515,
        "recall": 0.98463,
        "f1": 0.979832,
        "accuracy": 0.98463,
        "main_score": 0.979832,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.987899,
        "recall": 0.991932,
        "f1": 0.989243,
        "accuracy": 0.991932,
        "main_score": 0.989243,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.968497,
        "recall": 0.978478,
        "f1": 0.971772,
        "accuracy": 0.978478,
        "main_score": 0.971772,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.97569,
        "recall": 0.982943,
        "f1": 0.97794,
        "accuracy": 0.982943,
        "main_score": 0.97794,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.966466,
        "recall": 0.977037,
        "f1": 0.969915,
        "accuracy": 0.977037,
        "main_score": 0.969915,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.975437,
        "recall": 0.983365,
        "f1": 0.978054,
        "accuracy": 0.983365,
        "main_score": 0.978054,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.942632,
        "recall": 0.959354,
        "f1": 0.947981,
        "accuracy": 0.959354,
        "main_score": 0.947981,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.806973,
        "recall": 0.867347,
        "f1": 0.82619,
        "accuracy": 0.867347,
        "main_score": 0.82619,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.95079,
        "recall": 0.965934,
        "f1": 0.955699,
        "accuracy": 0.965934,
        "main_score": 0.955699,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.959236,
        "recall": 0.971782,
        "f1": 0.963287,
        "accuracy": 0.971782,
        "main_score": 0.963287,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.981435,
        "recall": 0.987424,
        "f1": 0.983411,
        "accuracy": 0.987424,
        "main_score": 0.983411,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.958683,
        "recall": 0.971464,
        "f1": 0.962847,
        "accuracy": 0.971464,
        "main_score": 0.962847,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.969659,
        "recall": 0.979433,
        "f1": 0.972855,
        "accuracy": 0.979433,
        "main_score": 0.972855,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.948695,
        "recall": 0.963828,
        "f1": 0.953551,
        "accuracy": 0.963828,
        "main_score": 0.953551,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.96714,
        "recall": 0.977651,
        "f1": 0.970605,
        "accuracy": 0.977651,
        "main_score": 0.970605,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.880163,
        "recall": 0.916427,
        "f1": 0.891643,
        "accuracy": 0.916427,
        "main_score": 0.891643,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.953173,
        "recall": 0.967203,
        "f1": 0.957663,
        "accuracy": 0.967203,
        "main_score": 0.957663,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.927591,
        "recall": 0.94872,
        "f1": 0.934216,
        "accuracy": 0.94872,
        "main_score": 0.934216,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.965468,
        "recall": 0.976544,
        "f1": 0.969051,
        "accuracy": 0.976544,
        "main_score": 0.969051,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.96966,
        "recall": 0.979193,
        "f1": 0.972786,
        "accuracy": 0.979193,
        "main_score": 0.972786,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.972661,
        "recall": 0.981184,
        "f1": 0.975438,
        "accuracy": 0.981184,
        "main_score": 0.975438,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.952304,
        "recall": 0.966582,
        "f1": 0.95689,
        "accuracy": 0.966582,
        "main_score": 0.95689,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.955304,
        "recall": 0.969237,
        "f1": 0.959795,
        "accuracy": 0.969237,
        "main_score": 0.959795,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.890143,
        "recall": 0.921615,
        "f1": 0.9,
        "accuracy": 0.921615,
        "main_score": 0.9,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.914255,
        "recall": 0.942122,
        "f1": 0.923365,
        "accuracy": 0.942122,
        "main_score": 0.923365,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.927175,
        "recall": 0.950147,
        "f1": 0.934506,
        "accuracy": 0.950147,
        "main_score": 0.934506,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.891621,
        "recall": 0.923497,
        "f1": 0.901509,
        "accuracy": 0.923497,
        "main_score": 0.901509,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.916667,
        "recall": 0.942308,
        "f1": 0.924679,
        "accuracy": 0.942308,
        "main_score": 0.924679,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.960529,
        "recall": 0.972817,
        "f1": 0.964527,
        "accuracy": 0.972817,
        "main_score": 0.964527,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.966282,
        "recall": 0.976948,
        "f1": 0.969727,
        "accuracy": 0.976948,
        "main_score": 0.969727,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.971176,
        "recall": 0.980044,
        "f1": 0.974053,
        "accuracy": 0.980044,
        "main_score": 0.974053,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.976935,
        "recall": 0.984226,
        "f1": 0.979315,
        "accuracy": 0.984226,
        "main_score": 0.979315,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.958391,
        "recall": 0.971211,
        "f1": 0.96257,
        "accuracy": 0.971211,
        "main_score": 0.96257,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.963088,
        "recall": 0.974689,
        "f1": 0.966849,
        "accuracy": 0.974689,
        "main_score": 0.966849,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.97704,
        "recall": 0.98461,
        "f1": 0.979542,
        "accuracy": 0.98461,
        "main_score": 0.979542,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.967336,
        "recall": 0.977781,
        "f1": 0.970778,
        "accuracy": 0.977781,
        "main_score": 0.970778,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.973049,
        "recall": 0.981302,
        "f1": 0.975704,
        "accuracy": 0.981302,
        "main_score": 0.975704,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.95764,
        "recall": 0.970801,
        "f1": 0.961926,
        "accuracy": 0.970801,
        "main_score": 0.961926,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.970416,
        "recall": 0.979495,
        "f1": 0.973298,
        "accuracy": 0.979495,
        "main_score": 0.973298,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.969267,
        "recall": 0.979008,
        "f1": 0.97244,
        "accuracy": 0.979008,
        "main_score": 0.97244,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.975567,
        "recall": 0.983711,
        "f1": 0.978281,
        "accuracy": 0.983711,
        "main_score": 0.978281,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.973748,
        "recall": 0.981944,
        "f1": 0.976373,
        "accuracy": 0.981944,
        "main_score": 0.976373,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.982517,
        "recall": 0.987994,
        "f1": 0.984308,
        "accuracy": 0.987994,
        "main_score": 0.984308,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.961401,
        "recall": 0.972902,
        "f1": 0.965069,
        "accuracy": 0.972902,
        "main_score": 0.965069,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.963211,
        "recall": 0.974509,
        "f1": 0.966881,
        "accuracy": 0.974509,
        "main_score": 0.966881,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.958625,
        "recall": 0.971429,
        "f1": 0.962778,
        "accuracy": 0.971429,
        "main_score": 0.962778,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.981936,
        "recall": 0.987556,
        "f1": 0.983753,
        "accuracy": 0.987556,
        "main_score": 0.983753,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.965181,
        "recall": 0.975859,
        "f1": 0.968641,
        "accuracy": 0.975859,
        "main_score": 0.968641,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.96752,
        "recall": 0.977477,
        "f1": 0.970721,
        "accuracy": 0.977477,
        "main_score": 0.970721,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.985945,
        "recall": 0.99063,
        "f1": 0.987507,
        "accuracy": 0.99063,
        "main_score": 0.987507,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.986749,
        "recall": 0.991166,
        "f1": 0.988221,
        "accuracy": 0.991166,
        "main_score": 0.988221,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.987705,
        "recall": 0.991803,
        "f1": 0.989071,
        "accuracy": 0.991803,
        "main_score": 0.989071,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.987805,
        "recall": 0.99187,
        "f1": 0.98916,
        "accuracy": 0.99187,
        "main_score": 0.98916,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.991743,
        "recall": 0.994495,
        "f1": 0.992661,
        "accuracy": 0.994495,
        "main_score": 0.992661,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.961111,
        "recall": 0.974074,
        "f1": 0.965432,
        "accuracy": 0.974074,
        "main_score": 0.965432,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.971683,
        "recall": 0.980583,
        "f1": 0.974515,
        "accuracy": 0.980583,
        "main_score": 0.974515,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.954897,
        "recall": 0.969072,
        "f1": 0.959622,
        "accuracy": 0.969072,
        "main_score": 0.959622,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.960392,
        "recall": 0.970588,
        "f1": 0.963235,
        "accuracy": 0.970588,
        "main_score": 0.963235,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.938819,
        "recall": 0.958228,
        "f1": 0.945148,
        "accuracy": 0.958228,
        "main_score": 0.945148,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.940158,
        "recall": 0.958457,
        "f1": 0.946093,
        "accuracy": 0.958457,
        "main_score": 0.946093,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.946714,
        "recall": 0.963035,
        "f1": 0.951989,
        "accuracy": 0.963035,
        "main_score": 0.951989,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.942448,
        "recall": 0.958055,
        "f1": 0.947289,
        "accuracy": 0.958055,
        "main_score": 0.947289,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.997512,
        "recall": 0.998342,
        "f1": 0.997789,
        "accuracy": 0.998342,
        "main_score": 0.997789,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.986832,
        "recall": 0.991222,
        "f1": 0.988296,
        "accuracy": 0.991222,
        "main_score": 0.988296,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.982458,
        "recall": 0.987811,
        "f1": 0.984169,
        "accuracy": 0.987811,
        "main_score": 0.984169,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.965712,
        "recall": 0.976562,
        "f1": 0.969184,
        "accuracy": 0.976562,
        "main_score": 0.969184,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.976247,
        "recall": 0.983841,
        "f1": 0.97872,
        "accuracy": 0.983841,
        "main_score": 0.97872,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.981309,
        "recall": 0.987367,
        "f1": 0.983304,
        "accuracy": 0.987367,
        "main_score": 0.983304,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.961891,
        "recall": 0.972555,
        "f1": 0.965302,
        "accuracy": 0.972555,
        "main_score": 0.965302,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.957904,
        "recall": 0.965591,
        "f1": 0.960288,
        "accuracy": 0.965591,
        "main_score": 0.960288,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.933996,
        "recall": 0.953642,
        "f1": 0.940132,
        "accuracy": 0.953642,
        "main_score": 0.940132,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 0.973621,
        "recall": 0.982014,
        "f1": 0.976319,
        "accuracy": 0.982014,
        "main_score": 0.976319,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.937769,
        "recall": 0.956433,
        "f1": 0.943731,
        "accuracy": 0.956433,
        "main_score": 0.943731,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.95055,
        "recall": 0.965518,
        "f1": 0.955335,
        "accuracy": 0.965518,
        "main_score": 0.955335,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.887217,
        "recall": 0.9161,
        "f1": 0.895609,
        "accuracy": 0.9161,
        "main_score": 0.895609,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.985279,
        "recall": 0.990086,
        "f1": 0.986856,
        "accuracy": 0.990086,
        "main_score": 0.986856,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.991071,
        "recall": 0.994048,
        "f1": 0.992063,
        "accuracy": 0.994048,
        "main_score": 0.992063,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.972006,
        "recall": 0.981236,
        "f1": 0.975057,
        "accuracy": 0.981236,
        "main_score": 0.975057,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.979155,
        "recall": 0.986103,
        "f1": 0.981471,
        "accuracy": 0.986103,
        "main_score": 0.981471,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.897812,
        "recall": 0.927374,
        "f1": 0.906611,
        "accuracy": 0.927374,
        "main_score": 0.906611,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.953393,
        "recall": 0.967499,
        "f1": 0.957892,
        "accuracy": 0.967499,
        "main_score": 0.957892,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.969574,
        "recall": 0.978986,
        "f1": 0.972638,
        "accuracy": 0.978986,
        "main_score": 0.972638,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.973988,
        "recall": 0.982659,
        "f1": 0.976879,
        "accuracy": 0.982659,
        "main_score": 0.976879,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.96221,
        "recall": 0.973808,
        "f1": 0.965892,
        "accuracy": 0.973808,
        "main_score": 0.965892,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.949722,
        "recall": 0.965709,
        "f1": 0.954958,
        "accuracy": 0.965709,
        "main_score": 0.954958,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.939522,
        "recall": 0.95865,
        "f1": 0.94571,
        "accuracy": 0.95865,
        "main_score": 0.94571,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.994643,
        "recall": 0.996429,
        "f1": 0.995238,
        "accuracy": 0.996429,
        "main_score": 0.995238,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.968322,
        "recall": 0.974414,
        "f1": 0.969972,
        "accuracy": 0.974414,
        "main_score": 0.969972,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.956914,
        "recall": 0.970025,
        "f1": 0.961082,
        "accuracy": 0.970025,
        "main_score": 0.961082,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.98162,
        "recall": 0.987622,
        "f1": 0.983621,
        "accuracy": 0.987622,
        "main_score": 0.983621,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.96709,
        "recall": 0.97714,
        "f1": 0.970304,
        "accuracy": 0.97714,
        "main_score": 0.970304,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.979472,
        "recall": 0.985733,
        "f1": 0.981489,
        "accuracy": 0.985733,
        "main_score": 0.981489,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.983081,
        "recall": 0.988483,
        "f1": 0.984831,
        "accuracy": 0.988483,
        "main_score": 0.984831,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.96786,
        "recall": 0.977778,
        "f1": 0.971061,
        "accuracy": 0.977778,
        "main_score": 0.971061,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.97111,
        "recall": 0.980252,
        "f1": 0.974127,
        "accuracy": 0.980252,
        "main_score": 0.974127,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.94592,
        "recall": 0.962759,
        "f1": 0.95131,
        "accuracy": 0.962759,
        "main_score": 0.95131,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.957718,
        "recall": 0.970265,
        "f1": 0.961735,
        "accuracy": 0.970265,
        "main_score": 0.961735,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.956546,
        "recall": 0.970297,
        "f1": 0.960946,
        "accuracy": 0.970297,
        "main_score": 0.960946,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.964807,
        "recall": 0.975853,
        "f1": 0.96836,
        "accuracy": 0.975853,
        "main_score": 0.96836,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.989111,
        "recall": 0.99274,
        "f1": 0.990321,
        "accuracy": 0.99274,
        "main_score": 0.990321,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.937043,
        "recall": 0.949631,
        "f1": 0.940745,
        "accuracy": 0.949631,
        "main_score": 0.940745,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.964449,
        "recall": 0.975684,
        "f1": 0.968056,
        "accuracy": 0.975684,
        "main_score": 0.968056,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.949907,
        "recall": 0.965061,
        "f1": 0.954699,
        "accuracy": 0.965061,
        "main_score": 0.954699,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.972015,
        "recall": 0.981343,
        "f1": 0.975124,
        "accuracy": 0.981343,
        "main_score": 0.975124,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.98866,
        "recall": 0.992089,
        "f1": 0.989715,
        "accuracy": 0.992089,
        "main_score": 0.989715,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.969685,
        "recall": 0.97923,
        "f1": 0.97281,
        "accuracy": 0.97923,
        "main_score": 0.97281,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 3283.431492328644,
  "kg_co2_emissions": null
}