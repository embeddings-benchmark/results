{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQAs",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 0.997537,
        "recall": 0.998358,
        "f1": 0.997811,
        "accuracy": 0.998358,
        "main_score": 0.997811,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.932413,
        "recall": 0.951943,
        "f1": 0.93848,
        "accuracy": 0.951943,
        "main_score": 0.93848,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.992358,
        "recall": 0.994813,
        "f1": 0.993154,
        "accuracy": 0.994813,
        "main_score": 0.993154,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.995575,
        "recall": 0.99705,
        "f1": 0.996067,
        "accuracy": 0.99705,
        "main_score": 0.996067,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.989632,
        "recall": 0.992477,
        "f1": 0.99049,
        "accuracy": 0.992477,
        "main_score": 0.99049,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.99026,
        "recall": 0.992785,
        "f1": 0.991101,
        "accuracy": 0.992785,
        "main_score": 0.991101,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.986201,
        "recall": 0.9908,
        "f1": 0.987734,
        "accuracy": 0.9908,
        "main_score": 0.987734,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.991228,
        "recall": 0.993808,
        "f1": 0.992002,
        "accuracy": 0.993808,
        "main_score": 0.992002,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.932967,
        "recall": 0.945055,
        "f1": 0.93663,
        "accuracy": 0.945055,
        "main_score": 0.93663,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.94376,
        "recall": 0.960254,
        "f1": 0.948914,
        "accuracy": 0.960254,
        "main_score": 0.948914,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.991919,
        "recall": 0.994613,
        "f1": 0.992817,
        "accuracy": 0.994613,
        "main_score": 0.992817,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.997887,
        "recall": 0.998592,
        "f1": 0.998122,
        "accuracy": 0.998592,
        "main_score": 0.998122,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.986924,
        "recall": 0.991283,
        "f1": 0.988377,
        "accuracy": 0.991283,
        "main_score": 0.988377,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.990112,
        "recall": 0.993272,
        "f1": 0.991131,
        "accuracy": 0.993272,
        "main_score": 0.991131,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.992886,
        "recall": 0.995257,
        "f1": 0.993677,
        "accuracy": 0.995257,
        "main_score": 0.993677,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.990901,
        "recall": 0.993934,
        "f1": 0.991912,
        "accuracy": 0.993934,
        "main_score": 0.991912,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.981786,
        "recall": 0.987427,
        "f1": 0.983559,
        "accuracy": 0.987427,
        "main_score": 0.983559,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.984797,
        "recall": 0.989865,
        "f1": 0.986486,
        "accuracy": 0.989865,
        "main_score": 0.986486,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.990223,
        "recall": 0.993482,
        "f1": 0.99131,
        "accuracy": 0.993482,
        "main_score": 0.99131,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.993143,
        "recall": 0.995429,
        "f1": 0.993905,
        "accuracy": 0.995429,
        "main_score": 0.993905,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.989854,
        "recall": 0.993014,
        "f1": 0.990852,
        "accuracy": 0.993014,
        "main_score": 0.990852,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.994307,
        "recall": 0.996139,
        "f1": 0.994901,
        "accuracy": 0.996139,
        "main_score": 0.994901,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.978713,
        "recall": 0.984142,
        "f1": 0.980302,
        "accuracy": 0.984142,
        "main_score": 0.980302,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.998824,
        "recall": 0.999216,
        "f1": 0.998955,
        "accuracy": 0.999216,
        "main_score": 0.998955,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.980012,
        "recall": 0.985401,
        "f1": 0.981557,
        "accuracy": 0.985401,
        "main_score": 0.981557,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.987569,
        "recall": 0.991713,
        "f1": 0.98895,
        "accuracy": 0.991713,
        "main_score": 0.98895,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.969196,
        "recall": 0.97821,
        "f1": 0.972036,
        "accuracy": 0.97821,
        "main_score": 0.972036,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.990415,
        "recall": 0.99361,
        "f1": 0.99148,
        "accuracy": 0.99361,
        "main_score": 0.99148,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.995759,
        "recall": 0.997172,
        "f1": 0.99623,
        "accuracy": 0.997172,
        "main_score": 0.99623,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.994688,
        "recall": 0.996459,
        "f1": 0.995279,
        "accuracy": 0.996459,
        "main_score": 0.995279,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.99269,
        "recall": 0.995127,
        "f1": 0.993502,
        "accuracy": 0.995127,
        "main_score": 0.993502,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.992196,
        "recall": 0.994797,
        "f1": 0.993063,
        "accuracy": 0.994797,
        "main_score": 0.993063,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.998254,
        "recall": 0.998836,
        "f1": 0.998448,
        "accuracy": 0.998836,
        "main_score": 0.998448,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.985173,
        "recall": 0.990115,
        "f1": 0.98682,
        "accuracy": 0.990115,
        "main_score": 0.98682,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.997653,
        "recall": 0.998435,
        "f1": 0.997913,
        "accuracy": 0.998435,
        "main_score": 0.997913,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.98387,
        "recall": 0.988233,
        "f1": 0.985208,
        "accuracy": 0.988233,
        "main_score": 0.985208,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.995308,
        "recall": 0.996872,
        "f1": 0.995829,
        "accuracy": 0.996872,
        "main_score": 0.995829,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.978558,
        "recall": 0.984081,
        "f1": 0.980187,
        "accuracy": 0.984081,
        "main_score": 0.980187,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.924458,
        "recall": 0.949187,
        "f1": 0.932588,
        "accuracy": 0.949187,
        "main_score": 0.932588,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.984951,
        "recall": 0.989873,
        "f1": 0.986568,
        "accuracy": 0.989873,
        "main_score": 0.986568,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.995249,
        "recall": 0.996833,
        "f1": 0.995777,
        "accuracy": 0.996833,
        "main_score": 0.995777,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.959626,
        "recall": 0.971715,
        "f1": 0.963412,
        "accuracy": 0.971715,
        "main_score": 0.963412,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.957875,
        "recall": 0.971429,
        "f1": 0.962271,
        "accuracy": 0.971429,
        "main_score": 0.962271,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.994194,
        "recall": 0.995607,
        "f1": 0.994635,
        "accuracy": 0.995607,
        "main_score": 0.994635,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.994996,
        "recall": 0.996029,
        "f1": 0.995234,
        "accuracy": 0.996029,
        "main_score": 0.995234,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.916429,
        "recall": 0.941176,
        "f1": 0.924064,
        "accuracy": 0.941176,
        "main_score": 0.924064,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.990466,
        "recall": 0.993644,
        "f1": 0.991525,
        "accuracy": 0.993644,
        "main_score": 0.991525,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.919673,
        "recall": 0.943888,
        "f1": 0.927321,
        "accuracy": 0.943888,
        "main_score": 0.927321,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.953956,
        "recall": 0.967258,
        "f1": 0.958026,
        "accuracy": 0.967258,
        "main_score": 0.958026,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.994983,
        "recall": 0.996656,
        "f1": 0.995541,
        "accuracy": 0.996656,
        "main_score": 0.995541,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.998867,
        "recall": 0.999245,
        "f1": 0.998993,
        "accuracy": 0.999245,
        "main_score": 0.998993,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.995754,
        "recall": 0.997003,
        "f1": 0.996134,
        "accuracy": 0.997003,
        "main_score": 0.996134,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.994214,
        "recall": 0.996055,
        "f1": 0.994827,
        "accuracy": 0.996055,
        "main_score": 0.994827,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.964322,
        "recall": 0.975535,
        "f1": 0.96789,
        "accuracy": 0.975535,
        "main_score": 0.96789,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.993308,
        "recall": 0.995024,
        "f1": 0.993819,
        "accuracy": 0.995024,
        "main_score": 0.993819,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.996056,
        "recall": 0.997316,
        "f1": 0.996463,
        "accuracy": 0.997316,
        "main_score": 0.996463,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.997119,
        "recall": 0.998079,
        "f1": 0.997439,
        "accuracy": 0.998079,
        "main_score": 0.997439,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.992618,
        "recall": 0.995009,
        "f1": 0.993398,
        "accuracy": 0.995009,
        "main_score": 0.993398,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.994314,
        "recall": 0.996101,
        "f1": 0.994883,
        "accuracy": 0.996101,
        "main_score": 0.994883,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.993489,
        "recall": 0.995519,
        "f1": 0.994138,
        "accuracy": 0.995519,
        "main_score": 0.994138,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.997891,
        "recall": 0.998594,
        "f1": 0.998126,
        "accuracy": 0.998594,
        "main_score": 0.998126,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.996039,
        "recall": 0.997331,
        "f1": 0.996466,
        "accuracy": 0.997331,
        "main_score": 0.996466,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.950113,
        "recall": 0.965986,
        "f1": 0.955215,
        "accuracy": 0.965986,
        "main_score": 0.955215,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.995387,
        "recall": 0.99686,
        "f1": 0.995875,
        "accuracy": 0.99686,
        "main_score": 0.995875,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.996845,
        "recall": 0.997819,
        "f1": 0.997162,
        "accuracy": 0.997819,
        "main_score": 0.997162,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.997305,
        "recall": 0.998203,
        "f1": 0.997605,
        "accuracy": 0.998203,
        "main_score": 0.997605,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.996157,
        "recall": 0.997438,
        "f1": 0.996584,
        "accuracy": 0.997438,
        "main_score": 0.996584,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.995831,
        "recall": 0.997221,
        "f1": 0.996294,
        "accuracy": 0.997221,
        "main_score": 0.996294,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.995626,
        "recall": 0.99691,
        "f1": 0.996046,
        "accuracy": 0.99691,
        "main_score": 0.996046,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.998701,
        "recall": 0.999134,
        "f1": 0.998845,
        "accuracy": 0.999134,
        "main_score": 0.998845,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.957733,
        "recall": 0.971182,
        "f1": 0.962056,
        "accuracy": 0.971182,
        "main_score": 0.962056,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.994476,
        "recall": 0.99625,
        "f1": 0.995067,
        "accuracy": 0.99625,
        "main_score": 0.995067,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.995063,
        "recall": 0.996663,
        "f1": 0.995585,
        "accuracy": 0.996663,
        "main_score": 0.995585,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.995309,
        "recall": 0.996873,
        "f1": 0.99583,
        "accuracy": 0.996873,
        "main_score": 0.99583,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.993906,
        "recall": 0.995854,
        "f1": 0.994547,
        "accuracy": 0.995854,
        "main_score": 0.994547,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.995448,
        "recall": 0.996965,
        "f1": 0.995953,
        "accuracy": 0.996965,
        "main_score": 0.995953,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.994809,
        "recall": 0.996397,
        "f1": 0.995323,
        "accuracy": 0.996397,
        "main_score": 0.995323,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.996771,
        "recall": 0.997803,
        "f1": 0.997103,
        "accuracy": 0.997803,
        "main_score": 0.997103,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.986936,
        "recall": 0.990499,
        "f1": 0.988124,
        "accuracy": 0.990499,
        "main_score": 0.988124,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.956592,
        "recall": 0.971061,
        "f1": 0.961415,
        "accuracy": 0.971061,
        "main_score": 0.961415,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.991803,
        "recall": 0.994536,
        "f1": 0.992714,
        "accuracy": 0.994536,
        "main_score": 0.992714,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.990385,
        "recall": 0.99359,
        "f1": 0.991453,
        "accuracy": 0.99359,
        "main_score": 0.991453,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.995579,
        "recall": 0.997052,
        "f1": 0.99607,
        "accuracy": 0.997052,
        "main_score": 0.99607,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.994038,
        "recall": 0.996025,
        "f1": 0.994701,
        "accuracy": 0.996025,
        "main_score": 0.994701,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.994353,
        "recall": 0.996064,
        "f1": 0.994897,
        "accuracy": 0.996064,
        "main_score": 0.994897,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.992609,
        "recall": 0.99494,
        "f1": 0.993353,
        "accuracy": 0.99494,
        "main_score": 0.993353,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.993508,
        "recall": 0.995524,
        "f1": 0.994174,
        "accuracy": 0.995524,
        "main_score": 0.994174,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.995096,
        "recall": 0.996625,
        "f1": 0.995585,
        "accuracy": 0.996625,
        "main_score": 0.995585,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.996059,
        "recall": 0.997372,
        "f1": 0.996496,
        "accuracy": 0.997372,
        "main_score": 0.996496,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.994659,
        "recall": 0.996297,
        "f1": 0.995181,
        "accuracy": 0.996297,
        "main_score": 0.995181,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.994922,
        "recall": 0.996537,
        "f1": 0.995441,
        "accuracy": 0.996537,
        "main_score": 0.995441,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.994732,
        "recall": 0.996442,
        "f1": 0.99529,
        "accuracy": 0.996442,
        "main_score": 0.99529,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.995958,
        "recall": 0.997043,
        "f1": 0.996277,
        "accuracy": 0.997043,
        "main_score": 0.996277,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.99499,
        "recall": 0.99666,
        "f1": 0.995547,
        "accuracy": 0.99666,
        "main_score": 0.995547,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.995987,
        "recall": 0.997167,
        "f1": 0.996341,
        "accuracy": 0.997167,
        "main_score": 0.996341,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.99539,
        "recall": 0.996927,
        "f1": 0.995902,
        "accuracy": 0.996927,
        "main_score": 0.995902,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.998684,
        "recall": 0.999052,
        "f1": 0.998789,
        "accuracy": 0.999052,
        "main_score": 0.998789,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.990141,
        "recall": 0.99306,
        "f1": 0.991077,
        "accuracy": 0.99306,
        "main_score": 0.991077,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.995013,
        "recall": 0.996456,
        "f1": 0.995475,
        "accuracy": 0.996456,
        "main_score": 0.995475,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.993664,
        "recall": 0.995514,
        "f1": 0.994243,
        "accuracy": 0.995514,
        "main_score": 0.994243,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.993802,
        "recall": 0.995556,
        "f1": 0.994341,
        "accuracy": 0.995556,
        "main_score": 0.994341,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.990599,
        "recall": 0.9935,
        "f1": 0.99152,
        "accuracy": 0.9935,
        "main_score": 0.99152,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.996349,
        "recall": 0.997338,
        "f1": 0.996646,
        "accuracy": 0.997338,
        "main_score": 0.996646,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.998722,
        "recall": 0.999148,
        "f1": 0.998864,
        "accuracy": 0.999148,
        "main_score": 0.998864,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.997248,
        "recall": 0.998165,
        "f1": 0.997554,
        "accuracy": 0.998165,
        "main_score": 0.997554,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.996359,
        "recall": 0.997573,
        "f1": 0.996764,
        "accuracy": 0.997573,
        "main_score": 0.996764,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.996134,
        "recall": 0.997423,
        "f1": 0.996564,
        "accuracy": 0.997423,
        "main_score": 0.996564,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.996203,
        "recall": 0.997468,
        "f1": 0.996624,
        "accuracy": 0.997468,
        "main_score": 0.996624,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.993323,
        "recall": 0.995549,
        "f1": 0.994065,
        "accuracy": 0.995549,
        "main_score": 0.994065,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.991786,
        "recall": 0.994163,
        "f1": 0.992542,
        "accuracy": 0.994163,
        "main_score": 0.992542,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.983964,
        "recall": 0.987539,
        "f1": 0.984983,
        "accuracy": 0.987539,
        "main_score": 0.984983,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.997512,
        "recall": 0.998342,
        "f1": 0.997789,
        "accuracy": 0.998342,
        "main_score": 0.997789,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.993124,
        "recall": 0.995312,
        "f1": 0.993827,
        "accuracy": 0.995312,
        "main_score": 0.993827,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.998698,
        "recall": 0.999132,
        "f1": 0.998843,
        "accuracy": 0.999132,
        "main_score": 0.998843,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.997219,
        "recall": 0.998146,
        "f1": 0.997528,
        "accuracy": 0.998146,
        "main_score": 0.997528,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.995678,
        "recall": 0.997119,
        "f1": 0.996158,
        "accuracy": 0.997119,
        "main_score": 0.996158,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.997317,
        "recall": 0.998099,
        "f1": 0.997565,
        "accuracy": 0.998099,
        "main_score": 0.997565,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.981729,
        "recall": 0.983154,
        "f1": 0.982096,
        "accuracy": 0.983154,
        "main_score": 0.982096,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 0.994604,
        "recall": 0.996403,
        "f1": 0.995204,
        "accuracy": 0.996403,
        "main_score": 0.995204,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.993901,
        "recall": 0.995934,
        "f1": 0.994578,
        "accuracy": 0.995934,
        "main_score": 0.994578,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.994837,
        "recall": 0.996237,
        "f1": 0.995272,
        "accuracy": 0.996237,
        "main_score": 0.995272,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.941837,
        "recall": 0.954649,
        "f1": 0.945011,
        "accuracy": 0.954649,
        "main_score": 0.945011,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.995944,
        "recall": 0.997296,
        "f1": 0.996395,
        "accuracy": 0.997296,
        "main_score": 0.996395,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.996568,
        "recall": 0.997712,
        "f1": 0.996949,
        "accuracy": 0.997712,
        "main_score": 0.996949,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.996526,
        "recall": 0.997684,
        "f1": 0.996912,
        "accuracy": 0.997684,
        "main_score": 0.996912,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.97486,
        "recall": 0.98324,
        "f1": 0.977654,
        "accuracy": 0.98324,
        "main_score": 0.977654,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.996111,
        "recall": 0.997304,
        "f1": 0.996491,
        "accuracy": 0.997304,
        "main_score": 0.996491,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.994834,
        "recall": 0.996323,
        "f1": 0.995316,
        "accuracy": 0.996323,
        "main_score": 0.995316,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.995665,
        "recall": 0.99711,
        "f1": 0.996146,
        "accuracy": 0.99711,
        "main_score": 0.996146,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.994266,
        "recall": 0.996091,
        "f1": 0.994853,
        "accuracy": 0.996091,
        "main_score": 0.994853,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.993049,
        "recall": 0.995366,
        "f1": 0.993821,
        "accuracy": 0.995366,
        "main_score": 0.993821,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.990155,
        "recall": 0.993249,
        "f1": 0.991139,
        "accuracy": 0.993249,
        "main_score": 0.991139,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.982942,
        "recall": 0.987207,
        "f1": 0.984364,
        "accuracy": 0.987207,
        "main_score": 0.984364,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.996202,
        "recall": 0.99731,
        "f1": 0.996549,
        "accuracy": 0.99731,
        "main_score": 0.996549,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.999437,
        "recall": 0.999625,
        "f1": 0.9995,
        "accuracy": 0.999625,
        "main_score": 0.9995,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.996384,
        "recall": 0.997525,
        "f1": 0.996748,
        "accuracy": 0.997525,
        "main_score": 0.996748,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.996568,
        "recall": 0.997421,
        "f1": 0.996829,
        "accuracy": 0.997421,
        "main_score": 0.996829,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.997779,
        "recall": 0.998355,
        "f1": 0.997938,
        "accuracy": 0.998355,
        "main_score": 0.997938,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.993178,
        "recall": 0.994979,
        "f1": 0.99372,
        "accuracy": 0.994979,
        "main_score": 0.99372,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.990115,
        "recall": 0.993103,
        "f1": 0.991034,
        "accuracy": 0.993103,
        "main_score": 0.991034,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.993605,
        "recall": 0.995317,
        "f1": 0.99414,
        "accuracy": 0.995317,
        "main_score": 0.99414,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.990099,
        "recall": 0.993399,
        "f1": 0.991199,
        "accuracy": 0.993399,
        "main_score": 0.991199,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.998751,
        "recall": 0.999167,
        "f1": 0.99889,
        "accuracy": 0.999167,
        "main_score": 0.99889,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.956224,
        "recall": 0.968059,
        "f1": 0.959664,
        "accuracy": 0.968059,
        "main_score": 0.959664,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.995513,
        "recall": 0.99696,
        "f1": 0.995983,
        "accuracy": 0.99696,
        "main_score": 0.995983,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.988863,
        "recall": 0.99153,
        "f1": 0.989633,
        "accuracy": 0.99153,
        "main_score": 0.989633,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.988806,
        "recall": 0.992537,
        "f1": 0.99005,
        "accuracy": 0.992537,
        "main_score": 0.99005,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.996704,
        "recall": 0.997627,
        "f1": 0.996967,
        "accuracy": 0.997627,
        "main_score": 0.996967,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.994085,
        "recall": 0.995564,
        "f1": 0.994555,
        "accuracy": 0.995564,
        "main_score": 0.994555,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 5200.0571665763855,
  "kg_co2_emissions": null
}