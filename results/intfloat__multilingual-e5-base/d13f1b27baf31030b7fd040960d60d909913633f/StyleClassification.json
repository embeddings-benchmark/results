{
  "dataset_revision": "41a0848f718a28b9a6333b2be47b6dc93d5c1803",
  "task_name": "StyleClassification",
  "mteb_version": "1.38.38",
  "scores": {
    "test": [
      {
        "accuracy": 0.617188,
        "f1": 0.616689,
        "f1_weighted": 0.616705,
        "ap": 0.568571,
        "ap_weighted": 0.568571,
        "scores_per_experiment": [
          {
            "accuracy": 0.622396,
            "f1": 0.622373,
            "f1_weighted": 0.622404,
            "ap": 0.571187,
            "ap_weighted": 0.571187
          },
          {
            "accuracy": 0.658854,
            "f1": 0.658852,
            "f1_weighted": 0.658861,
            "ap": 0.599609,
            "ap_weighted": 0.599609
          },
          {
            "accuracy": 0.651042,
            "f1": 0.65089,
            "f1_weighted": 0.650814,
            "ap": 0.592439,
            "ap_weighted": 0.592439
          },
          {
            "accuracy": 0.552083,
            "f1": 0.551889,
            "f1_weighted": 0.551986,
            "ap": 0.523564,
            "ap_weighted": 0.523564
          },
          {
            "accuracy": 0.611979,
            "f1": 0.611027,
            "f1_weighted": 0.610826,
            "ap": 0.562605,
            "ap_weighted": 0.562605
          },
          {
            "accuracy": 0.658854,
            "f1": 0.658017,
            "f1_weighted": 0.658193,
            "ap": 0.601803,
            "ap_weighted": 0.601803
          },
          {
            "accuracy": 0.596354,
            "f1": 0.596132,
            "f1_weighted": 0.596231,
            "ap": 0.552572,
            "ap_weighted": 0.552572
          },
          {
            "accuracy": 0.609375,
            "f1": 0.608696,
            "f1_weighted": 0.608526,
            "ap": 0.560875,
            "ap_weighted": 0.560875
          },
          {
            "accuracy": 0.632812,
            "f1": 0.630988,
            "f1_weighted": 0.631258,
            "ap": 0.581143,
            "ap_weighted": 0.581143
          },
          {
            "accuracy": 0.578125,
            "f1": 0.578022,
            "f1_weighted": 0.577953,
            "ap": 0.539917,
            "ap_weighted": 0.539917
          }
        ],
        "main_score": 0.617188,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 24.26787495613098,
  "kg_co2_emissions": null
}