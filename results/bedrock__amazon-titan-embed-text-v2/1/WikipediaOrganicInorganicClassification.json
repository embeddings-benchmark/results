{
  "dataset_revision": "96d1d9b37c4693f74c46c83d63a290573f78d511",
  "task_name": "WikipediaOrganicInorganicClassification",
  "mteb_version": "1.25.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.853612,
        "f1": 0.851199,
        "f1_weighted": 0.853173,
        "ap": 0.769174,
        "ap_weighted": 0.769174,
        "scores_per_experiment": [
          {
            "accuracy": 0.844106,
            "f1": 0.834294,
            "f1_weighted": 0.839353,
            "ap": 0.782948,
            "ap_weighted": 0.782948
          },
          {
            "accuracy": 0.878327,
            "f1": 0.876381,
            "f1_weighted": 0.878327,
            "ap": 0.801933,
            "ap_weighted": 0.801933
          },
          {
            "accuracy": 0.882129,
            "f1": 0.878068,
            "f1_weighted": 0.88086,
            "ap": 0.823452,
            "ap_weighted": 0.823452
          },
          {
            "accuracy": 0.790875,
            "f1": 0.790572,
            "f1_weighted": 0.791571,
            "ap": 0.678417,
            "ap_weighted": 0.678417
          },
          {
            "accuracy": 0.86692,
            "f1": 0.86193,
            "f1_weighted": 0.865223,
            "ap": 0.801699,
            "ap_weighted": 0.801699
          },
          {
            "accuracy": 0.920152,
            "f1": 0.919589,
            "f1_weighted": 0.920433,
            "ap": 0.85407,
            "ap_weighted": 0.85407
          },
          {
            "accuracy": 0.847909,
            "f1": 0.847111,
            "f1_weighted": 0.848497,
            "ap": 0.750744,
            "ap_weighted": 0.750744
          },
          {
            "accuracy": 0.836502,
            "f1": 0.83635,
            "f1_weighted": 0.836975,
            "ap": 0.732109,
            "ap_weighted": 0.732109
          },
          {
            "accuracy": 0.81749,
            "f1": 0.816533,
            "f1_weighted": 0.818196,
            "ap": 0.712027,
            "ap_weighted": 0.712027
          },
          {
            "accuracy": 0.851711,
            "f1": 0.85116,
            "f1_weighted": 0.852296,
            "ap": 0.754342,
            "ap_weighted": 0.754342
          }
        ],
        "main_score": 0.853612,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.729666233062744,
  "kg_co2_emissions": null
}