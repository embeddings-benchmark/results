{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.25.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.614122,
        "f1": 0.612728,
        "f1_weighted": 0.613565,
        "ap": 0.542122,
        "ap_weighted": 0.542122,
        "scores_per_experiment": [
          {
            "accuracy": 0.609169,
            "f1": 0.609151,
            "f1_weighted": 0.608999,
            "ap": 0.53907,
            "ap_weighted": 0.53907
          },
          {
            "accuracy": 0.605398,
            "f1": 0.605398,
            "f1_weighted": 0.605377,
            "ap": 0.536254,
            "ap_weighted": 0.536254
          },
          {
            "accuracy": 0.633419,
            "f1": 0.633289,
            "f1_weighted": 0.633687,
            "ap": 0.556883,
            "ap_weighted": 0.556883
          },
          {
            "accuracy": 0.627763,
            "f1": 0.627723,
            "f1_weighted": 0.627499,
            "ap": 0.552853,
            "ap_weighted": 0.552853
          },
          {
            "accuracy": 0.62605,
            "f1": 0.625912,
            "f1_weighted": 0.626325,
            "ap": 0.551197,
            "ap_weighted": 0.551197
          },
          {
            "accuracy": 0.600171,
            "f1": 0.596428,
            "f1_weighted": 0.598666,
            "ap": 0.530723,
            "ap_weighted": 0.530723
          },
          {
            "accuracy": 0.601799,
            "f1": 0.601799,
            "f1_weighted": 0.601809,
            "ap": 0.533667,
            "ap_weighted": 0.533667
          },
          {
            "accuracy": 0.623308,
            "f1": 0.620942,
            "f1_weighted": 0.622666,
            "ap": 0.54852,
            "ap_weighted": 0.54852
          },
          {
            "accuracy": 0.608997,
            "f1": 0.608234,
            "f1_weighted": 0.60923,
            "ap": 0.538061,
            "ap_weighted": 0.538061
          },
          {
            "accuracy": 0.605141,
            "f1": 0.5984,
            "f1_weighted": 0.601396,
            "ap": 0.533992,
            "ap_weighted": 0.533992
          }
        ],
        "main_score": 0.614122,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 1579.1592454910278,
  "kg_co2_emissions": null
}