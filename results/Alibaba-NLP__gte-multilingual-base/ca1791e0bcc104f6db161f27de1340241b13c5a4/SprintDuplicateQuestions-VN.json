{
    "dataset_revision": "2552beae0e4fe7fe05d088814f78a4c309ad2219",
    "mteb_dataset_name": "SprintDuplicateQuestions-VN",
    "mteb_version": null,
    "task_name": "SprintDuplicateQuestions-VN",
    "scores": {
        "test": [
            {
                "evaluation_time": 8.33,
                "hf_subset": "default",
                "dot_accuracy": 0.998467993643317,
                "dot_ap": 0.970755644475227,
                "dot_f1": 0.9232531500572738,
                "dot_accuracy_threshold": 0.8461461663246155,
                "dot_f1_threshold": 0.8432698249816895,
                "dot_precision": 0.9361207897793263,
                "dot_recall": 0.9107344632768362,
                "euclidean_accuracy": 0.998467993643317,
                "euclidean_ap": 0.9707556444752269,
                "euclidean_f1": 0.9232531500572738,
                "euclidean_accuracy_threshold": 0.5547134280204773,
                "euclidean_f1_threshold": 0.5598752498626709,
                "euclidean_precision": 0.9361207897793263,
                "euclidean_recall": 0.9107344632768362,
                "manhattan_accuracy": 0.9985137251763522,
                "manhattan_ap": 0.9710532303606388,
                "manhattan_f1": 0.925287356321839,
                "manhattan_accuracy_threshold": 11.913902282714844,
                "manhattan_f1_threshold": 11.952629089355469,
                "manhattan_precision": 0.9415204678362573,
                "manhattan_recall": 0.9096045197740112,
                "max_accuracy": 0.9985137251763522,
                "max_ap": 0.9710532303606388,
                "max_f1": 0.925287356321839,
                "main_score": 0.9710532303606388,
                "languages": [
                    "vie-Latn"
                ]
            }
        ],
        "validation": [
            {
                "evaluation_time": 9.06,
                "hf_subset": "default",
                "dot_accuracy": 0.9985473300150898,
                "dot_ap": 0.9757359091855266,
                "dot_f1": 0.9272419627749576,
                "dot_accuracy_threshold": 0.8379189968109131,
                "dot_f1_threshold": 0.8379189968109131,
                "dot_precision": 0.9330306469920545,
                "dot_recall": 0.92152466367713,
                "euclidean_accuracy": 0.9985473300150898,
                "euclidean_ap": 0.9757359091855266,
                "euclidean_f1": 0.9272419627749576,
                "euclidean_accuracy_threshold": 0.5693521499633789,
                "euclidean_f1_threshold": 0.5693521499633789,
                "euclidean_precision": 0.9330306469920545,
                "euclidean_recall": 0.92152466367713,
                "manhattan_accuracy": 0.9985360690074548,
                "manhattan_ap": 0.9755602152195404,
                "manhattan_f1": 0.9263873159682899,
                "manhattan_accuracy_threshold": 12.179816246032715,
                "manhattan_f1_threshold": 12.204233169555664,
                "manhattan_precision": 0.9359267734553776,
                "manhattan_recall": 0.9170403587443946,
                "max_accuracy": 0.9985473300150898,
                "max_ap": 0.9757359091855267,
                "max_f1": 0.9272419627749576,
                "main_score": 0.9757359091855267,
                "languages": [
                    "vie-Latn"
                ]
            }
        ]
    },
    "evaluation_time": null
}