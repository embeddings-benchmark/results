{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQAs",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 0.995074,
        "recall": 0.996716,
        "f1": 0.995621,
        "accuracy": 0.996716,
        "main_score": 0.995621,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.907209,
        "recall": 0.93047,
        "f1": 0.914471,
        "accuracy": 0.93047,
        "main_score": 0.914471,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.990111,
        "recall": 0.993361,
        "f1": 0.991183,
        "accuracy": 0.993361,
        "main_score": 0.991183,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.99115,
        "recall": 0.9941,
        "f1": 0.992134,
        "accuracy": 0.9941,
        "main_score": 0.992134,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.990066,
        "recall": 0.993056,
        "f1": 0.99103,
        "accuracy": 0.993056,
        "main_score": 0.99103,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.991582,
        "recall": 0.994228,
        "f1": 0.992424,
        "accuracy": 0.994228,
        "main_score": 0.992424,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.99172,
        "recall": 0.99448,
        "f1": 0.99264,
        "accuracy": 0.99448,
        "main_score": 0.99264,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.986584,
        "recall": 0.990712,
        "f1": 0.987874,
        "accuracy": 0.990712,
        "main_score": 0.987874,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.858974,
        "recall": 0.887912,
        "f1": 0.868132,
        "accuracy": 0.887912,
        "main_score": 0.868132,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.996032,
        "recall": 0.997354,
        "f1": 0.996473,
        "accuracy": 0.997354,
        "main_score": 0.996473,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.960917,
        "recall": 0.972973,
        "f1": 0.964759,
        "accuracy": 0.972973,
        "main_score": 0.964759,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.989899,
        "recall": 0.993266,
        "f1": 0.991021,
        "accuracy": 0.993266,
        "main_score": 0.991021,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.995775,
        "recall": 0.997183,
        "f1": 0.996244,
        "accuracy": 0.997183,
        "main_score": 0.996244,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.998132,
        "recall": 0.998755,
        "f1": 0.99834,
        "accuracy": 0.998755,
        "main_score": 0.99834,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.989602,
        "recall": 0.992661,
        "f1": 0.990622,
        "accuracy": 0.992661,
        "main_score": 0.990622,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.988031,
        "recall": 0.99187,
        "f1": 0.989273,
        "accuracy": 0.99187,
        "main_score": 0.989273,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.988302,
        "recall": 0.992201,
        "f1": 0.989601,
        "accuracy": 0.992201,
        "main_score": 0.989601,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.975661,
        "recall": 0.982592,
        "f1": 0.977917,
        "accuracy": 0.982592,
        "main_score": 0.977917,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.975788,
        "recall": 0.983108,
        "f1": 0.978041,
        "accuracy": 0.983108,
        "main_score": 0.978041,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.982154,
        "recall": 0.987896,
        "f1": 0.984016,
        "accuracy": 0.987896,
        "main_score": 0.984016,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.993143,
        "recall": 0.995429,
        "f1": 0.993905,
        "accuracy": 0.995429,
        "main_score": 0.993905,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.997006,
        "recall": 0.998004,
        "f1": 0.997339,
        "accuracy": 0.998004,
        "main_score": 0.997339,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.995545,
        "recall": 0.99703,
        "f1": 0.99604,
        "accuracy": 0.99703,
        "main_score": 0.99604,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.985308,
        "recall": 0.990205,
        "f1": 0.98694,
        "accuracy": 0.990205,
        "main_score": 0.98694,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.998824,
        "recall": 0.999216,
        "f1": 0.998955,
        "accuracy": 0.999216,
        "main_score": 0.998955,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.983942,
        "recall": 0.988321,
        "f1": 0.985245,
        "accuracy": 0.988321,
        "main_score": 0.985245,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.983425,
        "recall": 0.98895,
        "f1": 0.985267,
        "accuracy": 0.98895,
        "main_score": 0.985267,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.980674,
        "recall": 0.985992,
        "f1": 0.982361,
        "accuracy": 0.985992,
        "main_score": 0.982361,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.995208,
        "recall": 0.996805,
        "f1": 0.99574,
        "accuracy": 0.996805,
        "main_score": 0.99574,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.994275,
        "recall": 0.996183,
        "f1": 0.994911,
        "accuracy": 0.996183,
        "main_score": 0.994911,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.992931,
        "recall": 0.995287,
        "f1": 0.993717,
        "accuracy": 0.995287,
        "main_score": 0.993717,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.993691,
        "recall": 0.995794,
        "f1": 0.994392,
        "accuracy": 0.995794,
        "main_score": 0.994392,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.990439,
        "recall": 0.993626,
        "f1": 0.991501,
        "accuracy": 0.993626,
        "main_score": 0.991501,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.990494,
        "recall": 0.993663,
        "f1": 0.99155,
        "accuracy": 0.993663,
        "main_score": 0.99155,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.997104,
        "recall": 0.998069,
        "f1": 0.997426,
        "accuracy": 0.998069,
        "main_score": 0.997426,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.994819,
        "recall": 0.996546,
        "f1": 0.995394,
        "accuracy": 0.996546,
        "main_score": 0.995394,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.991228,
        "recall": 0.994152,
        "f1": 0.992203,
        "accuracy": 0.994152,
        "main_score": 0.992203,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.98786,
        "recall": 0.991675,
        "f1": 0.989074,
        "accuracy": 0.991675,
        "main_score": 0.989074,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.993015,
        "recall": 0.995343,
        "f1": 0.993791,
        "accuracy": 0.995343,
        "main_score": 0.993791,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.982702,
        "recall": 0.988468,
        "f1": 0.984624,
        "accuracy": 0.988468,
        "main_score": 0.984624,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.99061,
        "recall": 0.99374,
        "f1": 0.991654,
        "accuracy": 0.99374,
        "main_score": 0.991654,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.983679,
        "recall": 0.988432,
        "f1": 0.985241,
        "accuracy": 0.988432,
        "main_score": 0.985241,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.995308,
        "recall": 0.996872,
        "f1": 0.995829,
        "accuracy": 0.996872,
        "main_score": 0.995829,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.974916,
        "recall": 0.98191,
        "f1": 0.977086,
        "accuracy": 0.98191,
        "main_score": 0.977086,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.972561,
        "recall": 0.981707,
        "f1": 0.97561,
        "accuracy": 0.981707,
        "main_score": 0.97561,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.979606,
        "recall": 0.985654,
        "f1": 0.981575,
        "accuracy": 0.985654,
        "main_score": 0.981575,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.98753,
        "recall": 0.991291,
        "f1": 0.988704,
        "accuracy": 0.991291,
        "main_score": 0.988704,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.972019,
        "recall": 0.980839,
        "f1": 0.974909,
        "accuracy": 0.980839,
        "main_score": 0.974909,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.976923,
        "recall": 0.984615,
        "f1": 0.979487,
        "accuracy": 0.984615,
        "main_score": 0.979487,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.992031,
        "recall": 0.994099,
        "f1": 0.992689,
        "accuracy": 0.994099,
        "main_score": 0.992689,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.990469,
        "recall": 0.993646,
        "f1": 0.991528,
        "accuracy": 0.993646,
        "main_score": 0.991528,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.974153,
        "recall": 0.982175,
        "f1": 0.976827,
        "accuracy": 0.982175,
        "main_score": 0.976827,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.992585,
        "recall": 0.994703,
        "f1": 0.993291,
        "accuracy": 0.994703,
        "main_score": 0.993291,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.975952,
        "recall": 0.983968,
        "f1": 0.978624,
        "accuracy": 0.983968,
        "main_score": 0.978624,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.96055,
        "recall": 0.972715,
        "f1": 0.964393,
        "accuracy": 0.972715,
        "main_score": 0.964393,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.992475,
        "recall": 0.994983,
        "f1": 0.993311,
        "accuracy": 0.994983,
        "main_score": 0.993311,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.995946,
        "recall": 0.997297,
        "f1": 0.996396,
        "accuracy": 0.997297,
        "main_score": 0.996396,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.997168,
        "recall": 0.998112,
        "f1": 0.997482,
        "accuracy": 0.998112,
        "main_score": 0.997482,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.99412,
        "recall": 0.99608,
        "f1": 0.994774,
        "accuracy": 0.99608,
        "main_score": 0.994774,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.989698,
        "recall": 0.992898,
        "f1": 0.99075,
        "accuracy": 0.992898,
        "main_score": 0.99075,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.958716,
        "recall": 0.972477,
        "f1": 0.963303,
        "accuracy": 0.972477,
        "main_score": 0.963303,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.987952,
        "recall": 0.991619,
        "f1": 0.98913,
        "accuracy": 0.991619,
        "main_score": 0.98913,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.991461,
        "recall": 0.994145,
        "f1": 0.992356,
        "accuracy": 0.994145,
        "main_score": 0.992356,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.99174,
        "recall": 0.994237,
        "f1": 0.992573,
        "accuracy": 0.994237,
        "main_score": 0.992573,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.982871,
        "recall": 0.987835,
        "f1": 0.984477,
        "accuracy": 0.987835,
        "main_score": 0.984477,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.981319,
        "recall": 0.986842,
        "f1": 0.983106,
        "accuracy": 0.986842,
        "main_score": 0.983106,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.986092,
        "recall": 0.990479,
        "f1": 0.987539,
        "accuracy": 0.990479,
        "main_score": 0.987539,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.995783,
        "recall": 0.997188,
        "f1": 0.996251,
        "accuracy": 0.997188,
        "main_score": 0.996251,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.992201,
        "recall": 0.994698,
        "f1": 0.993024,
        "accuracy": 0.994698,
        "main_score": 0.993024,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.938776,
        "recall": 0.959184,
        "f1": 0.945578,
        "accuracy": 0.959184,
        "main_score": 0.945578,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.992823,
        "recall": 0.995103,
        "f1": 0.993568,
        "accuracy": 0.995103,
        "main_score": 0.993568,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.995074,
        "recall": 0.996622,
        "f1": 0.995579,
        "accuracy": 0.996622,
        "main_score": 0.995579,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.991376,
        "recall": 0.994251,
        "f1": 0.992334,
        "accuracy": 0.994251,
        "main_score": 0.992334,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.992947,
        "recall": 0.995229,
        "f1": 0.993698,
        "accuracy": 0.995229,
        "main_score": 0.993698,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.988975,
        "recall": 0.992496,
        "f1": 0.990133,
        "accuracy": 0.992496,
        "main_score": 0.990133,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.992582,
        "recall": 0.994883,
        "f1": 0.993341,
        "accuracy": 0.994883,
        "main_score": 0.993341,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.995062,
        "recall": 0.996708,
        "f1": 0.995611,
        "accuracy": 0.996708,
        "main_score": 0.995611,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.95341,
        "recall": 0.9683,
        "f1": 0.958213,
        "accuracy": 0.9683,
        "main_score": 0.958213,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.990726,
        "recall": 0.993501,
        "f1": 0.991626,
        "accuracy": 0.993501,
        "main_score": 0.991626,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.991845,
        "recall": 0.994211,
        "f1": 0.992616,
        "accuracy": 0.994211,
        "main_score": 0.992616,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.986057,
        "recall": 0.990618,
        "f1": 0.987555,
        "accuracy": 0.990618,
        "main_score": 0.987555,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.988981,
        "recall": 0.991934,
        "f1": 0.98992,
        "accuracy": 0.991934,
        "main_score": 0.98992,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.973192,
        "recall": 0.980577,
        "f1": 0.97562,
        "accuracy": 0.980577,
        "main_score": 0.97562,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.99132,
        "recall": 0.99378,
        "f1": 0.992128,
        "accuracy": 0.99378,
        "main_score": 0.992128,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.990511,
        "recall": 0.993608,
        "f1": 0.991543,
        "accuracy": 0.993608,
        "main_score": 0.991543,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.976247,
        "recall": 0.983373,
        "f1": 0.978622,
        "accuracy": 0.983373,
        "main_score": 0.978622,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.961415,
        "recall": 0.974277,
        "f1": 0.965702,
        "accuracy": 0.974277,
        "main_score": 0.965702,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.95259,
        "recall": 0.967742,
        "f1": 0.957478,
        "accuracy": 0.967742,
        "main_score": 0.957478,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.968124,
        "recall": 0.978142,
        "f1": 0.971311,
        "accuracy": 0.978142,
        "main_score": 0.971311,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.985577,
        "recall": 0.990385,
        "f1": 0.987179,
        "accuracy": 0.990385,
        "main_score": 0.987179,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.99264,
        "recall": 0.99476,
        "f1": 0.99333,
        "accuracy": 0.99476,
        "main_score": 0.99333,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.984036,
        "recall": 0.988871,
        "f1": 0.985559,
        "accuracy": 0.988871,
        "main_score": 0.985559,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.989702,
        "recall": 0.992494,
        "f1": 0.990602,
        "accuracy": 0.992494,
        "main_score": 0.990602,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.976389,
        "recall": 0.983036,
        "f1": 0.978512,
        "accuracy": 0.983036,
        "main_score": 0.978512,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.989426,
        "recall": 0.9925,
        "f1": 0.990444,
        "accuracy": 0.9925,
        "main_score": 0.990444,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.991,
        "recall": 0.993883,
        "f1": 0.99195,
        "accuracy": 0.993883,
        "main_score": 0.99195,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.985423,
        "recall": 0.989489,
        "f1": 0.986737,
        "accuracy": 0.989489,
        "main_score": 0.986737,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.983086,
        "recall": 0.987324,
        "f1": 0.984437,
        "accuracy": 0.987324,
        "main_score": 0.984437,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.970135,
        "recall": 0.977839,
        "f1": 0.972415,
        "accuracy": 0.977839,
        "main_score": 0.972415,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.988435,
        "recall": 0.991732,
        "f1": 0.989499,
        "accuracy": 0.991732,
        "main_score": 0.989499,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.98978,
        "recall": 0.992902,
        "f1": 0.990799,
        "accuracy": 0.992902,
        "main_score": 0.990799,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.980507,
        "recall": 0.985687,
        "f1": 0.982149,
        "accuracy": 0.985687,
        "main_score": 0.982149,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.977007,
        "recall": 0.983711,
        "f1": 0.979108,
        "accuracy": 0.983711,
        "main_score": 0.979108,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.985914,
        "recall": 0.990396,
        "f1": 0.987386,
        "accuracy": 0.990396,
        "main_score": 0.987386,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.99455,
        "recall": 0.996209,
        "f1": 0.995071,
        "accuracy": 0.996209,
        "main_score": 0.995071,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.967917,
        "recall": 0.976537,
        "f1": 0.97072,
        "accuracy": 0.976537,
        "main_score": 0.97072,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.991254,
        "recall": 0.993658,
        "f1": 0.992042,
        "accuracy": 0.993658,
        "main_score": 0.992042,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.987328,
        "recall": 0.991263,
        "f1": 0.988627,
        "accuracy": 0.991263,
        "main_score": 0.988627,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.97484,
        "recall": 0.981333,
        "f1": 0.976859,
        "accuracy": 0.981333,
        "main_score": 0.976859,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.979341,
        "recall": 0.986072,
        "f1": 0.981585,
        "accuracy": 0.986072,
        "main_score": 0.981585,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.989865,
        "recall": 0.993243,
        "f1": 0.990991,
        "accuracy": 0.993243,
        "main_score": 0.990991,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.992334,
        "recall": 0.994889,
        "f1": 0.993186,
        "accuracy": 0.994889,
        "main_score": 0.993186,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.99735,
        "recall": 0.998233,
        "f1": 0.997644,
        "accuracy": 0.998233,
        "main_score": 0.997644,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.996926,
        "recall": 0.997951,
        "f1": 0.997268,
        "accuracy": 0.997951,
        "main_score": 0.997268,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.995122,
        "recall": 0.996748,
        "f1": 0.995664,
        "accuracy": 0.996748,
        "main_score": 0.995664,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.996359,
        "recall": 0.997573,
        "f1": 0.996764,
        "accuracy": 0.997573,
        "main_score": 0.996764,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.996134,
        "recall": 0.997423,
        "f1": 0.996564,
        "accuracy": 0.997423,
        "main_score": 0.996564,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.995588,
        "recall": 0.997059,
        "f1": 0.996078,
        "accuracy": 0.997059,
        "main_score": 0.996078,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.98481,
        "recall": 0.989873,
        "f1": 0.986498,
        "accuracy": 0.989873,
        "main_score": 0.986498,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.993323,
        "recall": 0.995549,
        "f1": 0.994065,
        "accuracy": 0.995549,
        "main_score": 0.994065,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.987678,
        "recall": 0.991569,
        "f1": 0.988975,
        "accuracy": 0.991569,
        "main_score": 0.988975,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.981412,
        "recall": 0.98596,
        "f1": 0.982769,
        "accuracy": 0.98596,
        "main_score": 0.982769,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.995025,
        "recall": 0.996683,
        "f1": 0.995578,
        "accuracy": 0.996683,
        "main_score": 0.995578,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.990124,
        "recall": 0.993416,
        "f1": 0.991222,
        "accuracy": 0.993416,
        "main_score": 0.991222,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.994374,
        "recall": 0.996249,
        "f1": 0.994999,
        "accuracy": 0.996249,
        "main_score": 0.994999,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.996094,
        "recall": 0.997396,
        "f1": 0.996528,
        "accuracy": 0.997396,
        "main_score": 0.996528,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.997616,
        "recall": 0.998411,
        "f1": 0.997881,
        "accuracy": 0.998411,
        "main_score": 0.997881,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.994755,
        "recall": 0.996454,
        "f1": 0.995309,
        "accuracy": 0.996454,
        "main_score": 0.995309,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.990565,
        "recall": 0.993574,
        "f1": 0.991544,
        "accuracy": 0.993574,
        "main_score": 0.991544,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.995699,
        "recall": 0.997133,
        "f1": 0.996177,
        "accuracy": 0.997133,
        "main_score": 0.996177,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.988079,
        "recall": 0.992053,
        "f1": 0.989404,
        "accuracy": 0.992053,
        "main_score": 0.989404,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 0.994604,
        "recall": 0.996403,
        "f1": 0.995204,
        "accuracy": 0.996403,
        "main_score": 0.995204,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.990076,
        "recall": 0.99332,
        "f1": 0.991141,
        "accuracy": 0.99332,
        "main_score": 0.991141,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.992543,
        "recall": 0.994867,
        "f1": 0.993298,
        "accuracy": 0.994867,
        "main_score": 0.993298,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.932445,
        "recall": 0.951247,
        "f1": 0.938246,
        "accuracy": 0.951247,
        "main_score": 0.938246,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.995268,
        "recall": 0.996845,
        "f1": 0.995794,
        "accuracy": 0.996845,
        "main_score": 0.995794,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.986607,
        "recall": 0.991071,
        "f1": 0.988095,
        "accuracy": 0.991071,
        "main_score": 0.988095,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.991304,
        "recall": 0.99405,
        "f1": 0.99222,
        "accuracy": 0.99405,
        "main_score": 0.99222,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.992617,
        "recall": 0.995078,
        "f1": 0.993438,
        "accuracy": 0.995078,
        "main_score": 0.993438,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.97067,
        "recall": 0.980447,
        "f1": 0.973929,
        "accuracy": 0.980447,
        "main_score": 0.973929,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.990052,
        "recall": 0.993235,
        "f1": 0.991086,
        "accuracy": 0.993235,
        "main_score": 0.991086,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.990894,
        "recall": 0.993696,
        "f1": 0.991813,
        "accuracy": 0.993696,
        "main_score": 0.991813,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.979287,
        "recall": 0.985549,
        "f1": 0.981214,
        "accuracy": 0.985549,
        "main_score": 0.981214,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.990162,
        "recall": 0.993354,
        "f1": 0.991204,
        "accuracy": 0.993354,
        "main_score": 0.991204,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.980538,
        "recall": 0.987025,
        "f1": 0.9827,
        "accuracy": 0.987025,
        "main_score": 0.9827,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.981013,
        "recall": 0.987342,
        "f1": 0.983122,
        "accuracy": 0.987342,
        "main_score": 0.983122,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.971926,
        "recall": 0.98081,
        "f1": 0.974769,
        "accuracy": 0.98081,
        "main_score": 0.974769,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.990318,
        "recall": 0.993467,
        "f1": 0.991353,
        "accuracy": 0.993467,
        "main_score": 0.991353,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.995499,
        "recall": 0.996999,
        "f1": 0.995999,
        "accuracy": 0.996999,
        "main_score": 0.995999,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.988243,
        "recall": 0.991992,
        "f1": 0.989454,
        "accuracy": 0.991992,
        "main_score": 0.989454,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.992127,
        "recall": 0.994519,
        "f1": 0.992891,
        "accuracy": 0.994519,
        "main_score": 0.992891,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.990622,
        "recall": 0.993748,
        "f1": 0.991664,
        "accuracy": 0.993748,
        "main_score": 0.991664,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.993415,
        "recall": 0.995406,
        "f1": 0.994053,
        "accuracy": 0.995406,
        "main_score": 0.994053,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.99424,
        "recall": 0.99616,
        "f1": 0.99488,
        "accuracy": 0.99616,
        "main_score": 0.99488,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.97931,
        "recall": 0.986207,
        "f1": 0.981609,
        "accuracy": 0.986207,
        "main_score": 0.981609,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.992024,
        "recall": 0.994329,
        "f1": 0.99277,
        "accuracy": 0.994329,
        "main_score": 0.99277,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.990099,
        "recall": 0.993399,
        "f1": 0.991199,
        "accuracy": 0.993399,
        "main_score": 0.991199,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.994255,
        "recall": 0.99617,
        "f1": 0.994893,
        "accuracy": 0.99617,
        "main_score": 0.994893,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.994555,
        "recall": 0.99637,
        "f1": 0.99516,
        "accuracy": 0.99637,
        "main_score": 0.99516,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.963145,
        "recall": 0.974201,
        "f1": 0.966626,
        "accuracy": 0.974201,
        "main_score": 0.966626,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.989434,
        "recall": 0.992835,
        "f1": 0.990556,
        "accuracy": 0.992835,
        "main_score": 0.990556,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.987112,
        "recall": 0.990736,
        "f1": 0.988243,
        "accuracy": 0.990736,
        "main_score": 0.988243,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.983209,
        "recall": 0.988806,
        "f1": 0.985075,
        "accuracy": 0.988806,
        "main_score": 0.985075,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.995253,
        "recall": 0.996835,
        "f1": 0.995781,
        "accuracy": 0.996835,
        "main_score": 0.995781,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.994623,
        "recall": 0.996169,
        "f1": 0.995127,
        "accuracy": 0.996169,
        "main_score": 0.995127,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 6464.992875576019,
  "kg_co2_emissions": null
}