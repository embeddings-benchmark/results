{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQuestions",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 0.932129,
        "recall": 0.954023,
        "f1": 0.939245,
        "accuracy": 0.954023,
        "main_score": 0.939245,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.799506,
        "recall": 0.855828,
        "f1": 0.817519,
        "accuracy": 0.855828,
        "main_score": 0.817519,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.943067,
        "recall": 0.960581,
        "f1": 0.948728,
        "accuracy": 0.960581,
        "main_score": 0.948728,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.966568,
        "recall": 0.976401,
        "f1": 0.969764,
        "accuracy": 0.976401,
        "main_score": 0.969764,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.968171,
        "recall": 0.978588,
        "f1": 0.971644,
        "accuracy": 0.978588,
        "main_score": 0.971644,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.954425,
        "recall": 0.968975,
        "f1": 0.959115,
        "accuracy": 0.968975,
        "main_score": 0.959115,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.974701,
        "recall": 0.982521,
        "f1": 0.977308,
        "accuracy": 0.982521,
        "main_score": 0.977308,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.97291,
        "recall": 0.981424,
        "f1": 0.975748,
        "accuracy": 0.981424,
        "main_score": 0.975748,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.717033,
        "recall": 0.773626,
        "f1": 0.7337,
        "accuracy": 0.773626,
        "main_score": 0.7337,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.936508,
        "recall": 0.957672,
        "f1": 0.943563,
        "accuracy": 0.957672,
        "main_score": 0.943563,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.918256,
        "recall": 0.942766,
        "f1": 0.926073,
        "accuracy": 0.942766,
        "main_score": 0.926073,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.955892,
        "recall": 0.969024,
        "f1": 0.960157,
        "accuracy": 0.969024,
        "main_score": 0.960157,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.935915,
        "recall": 0.956338,
        "f1": 0.942723,
        "accuracy": 0.956338,
        "main_score": 0.942723,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.919261,
        "recall": 0.94396,
        "f1": 0.927148,
        "accuracy": 0.94396,
        "main_score": 0.927148,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.951172,
        "recall": 0.966972,
        "f1": 0.956371,
        "accuracy": 0.966972,
        "main_score": 0.956371,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.92561,
        "recall": 0.946477,
        "f1": 0.932249,
        "accuracy": 0.946477,
        "main_score": 0.932249,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.938764,
        "recall": 0.958406,
        "f1": 0.945263,
        "accuracy": 0.958406,
        "main_score": 0.945263,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.93206,
        "recall": 0.951644,
        "f1": 0.93833,
        "accuracy": 0.951644,
        "main_score": 0.93833,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.916667,
        "recall": 0.942568,
        "f1": 0.925113,
        "accuracy": 0.942568,
        "main_score": 0.925113,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.943358,
        "recall": 0.959963,
        "f1": 0.94879,
        "accuracy": 0.959963,
        "main_score": 0.94879,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.928381,
        "recall": 0.949714,
        "f1": 0.935238,
        "accuracy": 0.949714,
        "main_score": 0.935238,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.932136,
        "recall": 0.954092,
        "f1": 0.939288,
        "accuracy": 0.954092,
        "main_score": 0.939288,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.960152,
        "recall": 0.972973,
        "f1": 0.96436,
        "accuracy": 0.972973,
        "main_score": 0.96436,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.956856,
        "recall": 0.970149,
        "f1": 0.96121,
        "accuracy": 0.970149,
        "main_score": 0.96121,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.980727,
        "recall": 0.986672,
        "f1": 0.982687,
        "accuracy": 0.986672,
        "main_score": 0.982687,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.930049,
        "recall": 0.951825,
        "f1": 0.937105,
        "accuracy": 0.951825,
        "main_score": 0.937105,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.928407,
        "recall": 0.947514,
        "f1": 0.934346,
        "accuracy": 0.947514,
        "main_score": 0.934346,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.931777,
        "recall": 0.953307,
        "f1": 0.938911,
        "accuracy": 0.953307,
        "main_score": 0.938911,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.976038,
        "recall": 0.984026,
        "f1": 0.978701,
        "accuracy": 0.984026,
        "main_score": 0.978701,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.934478,
        "recall": 0.954198,
        "f1": 0.94084,
        "accuracy": 0.954198,
        "main_score": 0.94084,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.896199,
        "recall": 0.926484,
        "f1": 0.905718,
        "accuracy": 0.926484,
        "main_score": 0.905718,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.932177,
        "recall": 0.953733,
        "f1": 0.939187,
        "accuracy": 0.953733,
        "main_score": 0.939187,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.934608,
        "recall": 0.954674,
        "f1": 0.9411,
        "accuracy": 0.954674,
        "main_score": 0.9411,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.933249,
        "recall": 0.953105,
        "f1": 0.939797,
        "accuracy": 0.953105,
        "main_score": 0.939797,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.926963,
        "recall": 0.949807,
        "f1": 0.934363,
        "accuracy": 0.949807,
        "main_score": 0.934363,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.94099,
        "recall": 0.960276,
        "f1": 0.947323,
        "accuracy": 0.960276,
        "main_score": 0.947323,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.923652,
        "recall": 0.947368,
        "f1": 0.931287,
        "accuracy": 0.947368,
        "main_score": 0.931287,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.939993,
        "recall": 0.958377,
        "f1": 0.94589,
        "accuracy": 0.958377,
        "main_score": 0.94589,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.931704,
        "recall": 0.953434,
        "f1": 0.938882,
        "accuracy": 0.953434,
        "main_score": 0.938882,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.912411,
        "recall": 0.939044,
        "f1": 0.921197,
        "accuracy": 0.939044,
        "main_score": 0.921197,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.922535,
        "recall": 0.946792,
        "f1": 0.930621,
        "accuracy": 0.946792,
        "main_score": 0.930621,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.937857,
        "recall": 0.955724,
        "f1": 0.943664,
        "accuracy": 0.955724,
        "main_score": 0.943664,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.95955,
        "recall": 0.972367,
        "f1": 0.963712,
        "accuracy": 0.972367,
        "main_score": 0.963712,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.919621,
        "recall": 0.94356,
        "f1": 0.927328,
        "accuracy": 0.94356,
        "main_score": 0.927328,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.929878,
        "recall": 0.95122,
        "f1": 0.936992,
        "accuracy": 0.95122,
        "main_score": 0.936992,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.939944,
        "recall": 0.958228,
        "f1": 0.945851,
        "accuracy": 0.958228,
        "main_score": 0.945851,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.954342,
        "recall": 0.967538,
        "f1": 0.958696,
        "accuracy": 0.967538,
        "main_score": 0.958696,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.930961,
        "recall": 0.95073,
        "f1": 0.937348,
        "accuracy": 0.95073,
        "main_score": 0.937348,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.915751,
        "recall": 0.942857,
        "f1": 0.924542,
        "accuracy": 0.942857,
        "main_score": 0.924542,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.963994,
        "recall": 0.97469,
        "f1": 0.967462,
        "accuracy": 0.97469,
        "main_score": 0.967462,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.942507,
        "recall": 0.959492,
        "f1": 0.947895,
        "accuracy": 0.959492,
        "main_score": 0.947895,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.930778,
        "recall": 0.951872,
        "f1": 0.937611,
        "accuracy": 0.951872,
        "main_score": 0.937611,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.950212,
        "recall": 0.965042,
        "f1": 0.954979,
        "accuracy": 0.965042,
        "main_score": 0.954979,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.94656,
        "recall": 0.963928,
        "f1": 0.952238,
        "accuracy": 0.963928,
        "main_score": 0.952238,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.904843,
        "recall": 0.933151,
        "f1": 0.913915,
        "accuracy": 0.933151,
        "main_score": 0.913915,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.971302,
        "recall": 0.980132,
        "f1": 0.974062,
        "accuracy": 0.980132,
        "main_score": 0.974062,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.970457,
        "recall": 0.979933,
        "f1": 0.973523,
        "accuracy": 0.979933,
        "main_score": 0.973523,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.982057,
        "recall": 0.988038,
        "f1": 0.984051,
        "accuracy": 0.988038,
        "main_score": 0.984051,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.983784,
        "recall": 0.989189,
        "f1": 0.985586,
        "accuracy": 0.989189,
        "main_score": 0.985586,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.989426,
        "recall": 0.992825,
        "f1": 0.990559,
        "accuracy": 0.992825,
        "main_score": 0.990559,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.94862,
        "recall": 0.964722,
        "f1": 0.953924,
        "accuracy": 0.964722,
        "main_score": 0.953924,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.916557,
        "recall": 0.940295,
        "f1": 0.924215,
        "accuracy": 0.940295,
        "main_score": 0.924215,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.880224,
        "recall": 0.917431,
        "f1": 0.892457,
        "accuracy": 0.917431,
        "main_score": 0.892457,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.923018,
        "recall": 0.944997,
        "f1": 0.930042,
        "accuracy": 0.944997,
        "main_score": 0.930042,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.940392,
        "recall": 0.957307,
        "f1": 0.945832,
        "accuracy": 0.957307,
        "main_score": 0.945832,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.954796,
        "recall": 0.967345,
        "f1": 0.958894,
        "accuracy": 0.967345,
        "main_score": 0.958894,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.922422,
        "recall": 0.943855,
        "f1": 0.929268,
        "accuracy": 0.943855,
        "main_score": 0.929268,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.917649,
        "recall": 0.939571,
        "f1": 0.92448,
        "accuracy": 0.939571,
        "main_score": 0.92448,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.924858,
        "recall": 0.944833,
        "f1": 0.931285,
        "accuracy": 0.944833,
        "main_score": 0.931285,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.94451,
        "recall": 0.960403,
        "f1": 0.949664,
        "accuracy": 0.960403,
        "main_score": 0.949664,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.907767,
        "recall": 0.934324,
        "f1": 0.916216,
        "accuracy": 0.934324,
        "main_score": 0.916216,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.811621,
        "recall": 0.863946,
        "f1": 0.827891,
        "accuracy": 0.863946,
        "main_score": 0.827891,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.921477,
        "recall": 0.944376,
        "f1": 0.928761,
        "accuracy": 0.944376,
        "main_score": 0.928761,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.934099,
        "recall": 0.953487,
        "f1": 0.940307,
        "accuracy": 0.953487,
        "main_score": 0.940307,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.952419,
        "recall": 0.966942,
        "f1": 0.957145,
        "accuracy": 0.966942,
        "main_score": 0.957145,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.936515,
        "recall": 0.955915,
        "f1": 0.942779,
        "accuracy": 0.955915,
        "main_score": 0.942779,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.950204,
        "recall": 0.966092,
        "f1": 0.955392,
        "accuracy": 0.966092,
        "main_score": 0.955392,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.929979,
        "recall": 0.950859,
        "f1": 0.936677,
        "accuracy": 0.950859,
        "main_score": 0.936677,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.949093,
        "recall": 0.96483,
        "f1": 0.954204,
        "accuracy": 0.96483,
        "main_score": 0.954204,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.85879,
        "recall": 0.902017,
        "f1": 0.872719,
        "accuracy": 0.902017,
        "main_score": 0.872719,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.93265,
        "recall": 0.952255,
        "f1": 0.938966,
        "accuracy": 0.952255,
        "main_score": 0.938966,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.920037,
        "recall": 0.943476,
        "f1": 0.927565,
        "accuracy": 0.943476,
        "main_score": 0.927565,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.933151,
        "recall": 0.953088,
        "f1": 0.939523,
        "accuracy": 0.953088,
        "main_score": 0.939523,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.952601,
        "recall": 0.966227,
        "f1": 0.956992,
        "accuracy": 0.966227,
        "main_score": 0.956992,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.931285,
        "recall": 0.949621,
        "f1": 0.936985,
        "accuracy": 0.949621,
        "main_score": 0.936985,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.941795,
        "recall": 0.958946,
        "f1": 0.947335,
        "accuracy": 0.958946,
        "main_score": 0.947335,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.931582,
        "recall": 0.951658,
        "f1": 0.938041,
        "accuracy": 0.951658,
        "main_score": 0.938041,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.854711,
        "recall": 0.897862,
        "f1": 0.868171,
        "accuracy": 0.897862,
        "main_score": 0.868171,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.897106,
        "recall": 0.92926,
        "f1": 0.907824,
        "accuracy": 0.92926,
        "main_score": 0.907824,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.860704,
        "recall": 0.903226,
        "f1": 0.874389,
        "accuracy": 0.903226,
        "main_score": 0.874389,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.900501,
        "recall": 0.931694,
        "f1": 0.910474,
        "accuracy": 0.931694,
        "main_score": 0.910474,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.917735,
        "recall": 0.942308,
        "f1": 0.925748,
        "accuracy": 0.942308,
        "main_score": 0.925748,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.94016,
        "recall": 0.957969,
        "f1": 0.945862,
        "accuracy": 0.957969,
        "main_score": 0.945862,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.926007,
        "recall": 0.947138,
        "f1": 0.93283,
        "accuracy": 0.947138,
        "main_score": 0.93283,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.954534,
        "recall": 0.967686,
        "f1": 0.958834,
        "accuracy": 0.967686,
        "main_score": 0.958834,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.937748,
        "recall": 0.954464,
        "f1": 0.943046,
        "accuracy": 0.954464,
        "main_score": 0.943046,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.94094,
        "recall": 0.958147,
        "f1": 0.946462,
        "accuracy": 0.958147,
        "main_score": 0.946462,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.935552,
        "recall": 0.954018,
        "f1": 0.941482,
        "accuracy": 0.954018,
        "main_score": 0.941482,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.946603,
        "recall": 0.961712,
        "f1": 0.951476,
        "accuracy": 0.961712,
        "main_score": 0.951476,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.942522,
        "recall": 0.959123,
        "f1": 0.947928,
        "accuracy": 0.959123,
        "main_score": 0.947928,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.930517,
        "recall": 0.950139,
        "f1": 0.936652,
        "accuracy": 0.950139,
        "main_score": 0.936652,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.938701,
        "recall": 0.956986,
        "f1": 0.944622,
        "accuracy": 0.956986,
        "main_score": 0.944622,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.939291,
        "recall": 0.957216,
        "f1": 0.945071,
        "accuracy": 0.957216,
        "main_score": 0.945071,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.928793,
        "recall": 0.949427,
        "f1": 0.935464,
        "accuracy": 0.949427,
        "main_score": 0.935464,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.915132,
        "recall": 0.936969,
        "f1": 0.921779,
        "accuracy": 0.936969,
        "main_score": 0.921779,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.929729,
        "recall": 0.949673,
        "f1": 0.936189,
        "accuracy": 0.949673,
        "main_score": 0.936189,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.953923,
        "recall": 0.967773,
        "f1": 0.958452,
        "accuracy": 0.967773,
        "main_score": 0.958452,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.917823,
        "recall": 0.940185,
        "f1": 0.924972,
        "accuracy": 0.940185,
        "main_score": 0.924972,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.959059,
        "recall": 0.971027,
        "f1": 0.962963,
        "accuracy": 0.971027,
        "main_score": 0.962963,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.926867,
        "recall": 0.948052,
        "f1": 0.933656,
        "accuracy": 0.948052,
        "main_score": 0.933656,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.943235,
        "recall": 0.958519,
        "f1": 0.948119,
        "accuracy": 0.958519,
        "main_score": 0.948119,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.914918,
        "recall": 0.938719,
        "f1": 0.922532,
        "accuracy": 0.938719,
        "main_score": 0.922532,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.931921,
        "recall": 0.951679,
        "f1": 0.938295,
        "accuracy": 0.951679,
        "main_score": 0.938295,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.93356,
        "recall": 0.954855,
        "f1": 0.940517,
        "accuracy": 0.954855,
        "main_score": 0.940517,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.942874,
        "recall": 0.961131,
        "f1": 0.948763,
        "accuracy": 0.961131,
        "main_score": 0.948763,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.949112,
        "recall": 0.965164,
        "f1": 0.954235,
        "accuracy": 0.965164,
        "main_score": 0.954235,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.963415,
        "recall": 0.97561,
        "f1": 0.96748,
        "accuracy": 0.97561,
        "main_score": 0.96748,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.925535,
        "recall": 0.948624,
        "f1": 0.932844,
        "accuracy": 0.948624,
        "main_score": 0.932844,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.899383,
        "recall": 0.925926,
        "f1": 0.907284,
        "accuracy": 0.925926,
        "main_score": 0.907284,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.903803,
        "recall": 0.932039,
        "f1": 0.912621,
        "accuracy": 0.932039,
        "main_score": 0.912621,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.929768,
        "recall": 0.951031,
        "f1": 0.936598,
        "accuracy": 0.951031,
        "main_score": 0.936598,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.943627,
        "recall": 0.961765,
        "f1": 0.94951,
        "accuracy": 0.961765,
        "main_score": 0.94951,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.914346,
        "recall": 0.940506,
        "f1": 0.922574,
        "accuracy": 0.940506,
        "main_score": 0.922574,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.938427,
        "recall": 0.958457,
        "f1": 0.945104,
        "accuracy": 0.958457,
        "main_score": 0.945104,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.925259,
        "recall": 0.946822,
        "f1": 0.932144,
        "accuracy": 0.946822,
        "main_score": 0.932144,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.917364,
        "recall": 0.941032,
        "f1": 0.92491,
        "accuracy": 0.941032,
        "main_score": 0.92491,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.950802,
        "recall": 0.966833,
        "f1": 0.956053,
        "accuracy": 0.966833,
        "main_score": 0.956053,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.935504,
        "recall": 0.95684,
        "f1": 0.942575,
        "accuracy": 0.95684,
        "main_score": 0.942575,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.97609,
        "recall": 0.98406,
        "f1": 0.978747,
        "accuracy": 0.98406,
        "main_score": 0.978747,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.961372,
        "recall": 0.973958,
        "f1": 0.965567,
        "accuracy": 0.973958,
        "main_score": 0.965567,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.959161,
        "recall": 0.972185,
        "f1": 0.963444,
        "accuracy": 0.972185,
        "main_score": 0.963444,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.945567,
        "recall": 0.960328,
        "f1": 0.95031,
        "accuracy": 0.960328,
        "main_score": 0.95031,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.930856,
        "recall": 0.950975,
        "f1": 0.937247,
        "accuracy": 0.950975,
        "main_score": 0.937247,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.954659,
        "recall": 0.9681,
        "f1": 0.958944,
        "accuracy": 0.9681,
        "main_score": 0.958944,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.913576,
        "recall": 0.941722,
        "f1": 0.922826,
        "accuracy": 0.941722,
        "main_score": 0.922826,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 0.932554,
        "recall": 0.953237,
        "f1": 0.939089,
        "accuracy": 0.953237,
        "main_score": 0.939089,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.916797,
        "recall": 0.943363,
        "f1": 0.925501,
        "accuracy": 0.943363,
        "main_score": 0.925501,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.936166,
        "recall": 0.95466,
        "f1": 0.942022,
        "accuracy": 0.95466,
        "main_score": 0.942022,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.848488,
        "recall": 0.89229,
        "f1": 0.862191,
        "accuracy": 0.89229,
        "main_score": 0.862191,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.968154,
        "recall": 0.978369,
        "f1": 0.971534,
        "accuracy": 0.978369,
        "main_score": 0.971534,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.955357,
        "recall": 0.970238,
        "f1": 0.960317,
        "accuracy": 0.970238,
        "main_score": 0.960317,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.961175,
        "recall": 0.973455,
        "f1": 0.965217,
        "accuracy": 0.973455,
        "main_score": 0.965217,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.940885,
        "recall": 0.956862,
        "f1": 0.945763,
        "accuracy": 0.956862,
        "main_score": 0.945763,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.863128,
        "recall": 0.905028,
        "f1": 0.876164,
        "accuracy": 0.905028,
        "main_score": 0.876164,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.935497,
        "recall": 0.954428,
        "f1": 0.941478,
        "accuracy": 0.954428,
        "main_score": 0.941478,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.973426,
        "recall": 0.98135,
        "f1": 0.976009,
        "accuracy": 0.98135,
        "main_score": 0.976009,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.922929,
        "recall": 0.947977,
        "f1": 0.931118,
        "accuracy": 0.947977,
        "main_score": 0.931118,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.966719,
        "recall": 0.976935,
        "f1": 0.970029,
        "accuracy": 0.976935,
        "main_score": 0.970029,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.922073,
        "recall": 0.947173,
        "f1": 0.930244,
        "accuracy": 0.947173,
        "main_score": 0.930244,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.912518,
        "recall": 0.940928,
        "f1": 0.921941,
        "accuracy": 0.940928,
        "main_score": 0.921941,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.989286,
        "recall": 0.992857,
        "f1": 0.990476,
        "accuracy": 0.992857,
        "main_score": 0.990476,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.799929,
        "recall": 0.840085,
        "f1": 0.811483,
        "accuracy": 0.840085,
        "main_score": 0.811483,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.934858,
        "recall": 0.954269,
        "f1": 0.940971,
        "accuracy": 0.954269,
        "main_score": 0.940971,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.952613,
        "recall": 0.966992,
        "f1": 0.957152,
        "accuracy": 0.966992,
        "main_score": 0.957152,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.947944,
        "recall": 0.963162,
        "f1": 0.952766,
        "accuracy": 0.963162,
        "main_score": 0.952766,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.964946,
        "recall": 0.974931,
        "f1": 0.968095,
        "accuracy": 0.974931,
        "main_score": 0.968095,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.961465,
        "recall": 0.973017,
        "f1": 0.965115,
        "accuracy": 0.973017,
        "main_score": 0.965115,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.95591,
        "recall": 0.96859,
        "f1": 0.959979,
        "accuracy": 0.96859,
        "main_score": 0.959979,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.957396,
        "recall": 0.970378,
        "f1": 0.961602,
        "accuracy": 0.970378,
        "main_score": 0.961602,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.902667,
        "recall": 0.931724,
        "f1": 0.911816,
        "accuracy": 0.931724,
        "main_score": 0.911816,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.952094,
        "recall": 0.966428,
        "f1": 0.9567,
        "accuracy": 0.966428,
        "main_score": 0.9567,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.956546,
        "recall": 0.970297,
        "f1": 0.960946,
        "accuracy": 0.970297,
        "main_score": 0.960946,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.943747,
        "recall": 0.961199,
        "f1": 0.94932,
        "accuracy": 0.961199,
        "main_score": 0.94932,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.978221,
        "recall": 0.985481,
        "f1": 0.980641,
        "accuracy": 0.985481,
        "main_score": 0.980641,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.956798,
        "recall": 0.970516,
        "f1": 0.961302,
        "accuracy": 0.970516,
        "main_score": 0.961302,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.952616,
        "recall": 0.967434,
        "f1": 0.957389,
        "accuracy": 0.967434,
        "main_score": 0.957389,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.939902,
        "recall": 0.958444,
        "f1": 0.9458,
        "accuracy": 0.958444,
        "main_score": 0.9458,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.89801,
        "recall": 0.929104,
        "f1": 0.90796,
        "accuracy": 0.929104,
        "main_score": 0.90796,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.982463,
        "recall": 0.988133,
        "f1": 0.984309,
        "accuracy": 0.988133,
        "main_score": 0.984309,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.970592,
        "recall": 0.979835,
        "f1": 0.973617,
        "accuracy": 0.979835,
        "main_score": 0.973617,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 4295.618368387222,
  "kg_co2_emissions": null
}