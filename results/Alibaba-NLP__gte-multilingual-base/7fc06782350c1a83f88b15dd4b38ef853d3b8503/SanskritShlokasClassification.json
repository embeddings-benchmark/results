{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.783551,
        "f1": 0.778334,
        "f1_weighted": 0.77967,
        "scores_per_experiment": [
          {
            "accuracy": 0.788512,
            "f1": 0.77626,
            "f1_weighted": 0.779317
          },
          {
            "accuracy": 0.798956,
            "f1": 0.792522,
            "f1_weighted": 0.794724
          },
          {
            "accuracy": 0.741514,
            "f1": 0.739947,
            "f1_weighted": 0.738728
          },
          {
            "accuracy": 0.751958,
            "f1": 0.751342,
            "f1_weighted": 0.751247
          },
          {
            "accuracy": 0.819843,
            "f1": 0.812006,
            "f1_weighted": 0.814582
          },
          {
            "accuracy": 0.809399,
            "f1": 0.807127,
            "f1_weighted": 0.807758
          },
          {
            "accuracy": 0.843342,
            "f1": 0.841922,
            "f1_weighted": 0.84246
          },
          {
            "accuracy": 0.772846,
            "f1": 0.770054,
            "f1_weighted": 0.770289
          },
          {
            "accuracy": 0.754569,
            "f1": 0.746057,
            "f1_weighted": 0.749109
          },
          {
            "accuracy": 0.754569,
            "f1": 0.746105,
            "f1_weighted": 0.748491
          }
        ],
        "main_score": 0.783551,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.772917,
        "f1": 0.773071,
        "f1_weighted": 0.769629,
        "scores_per_experiment": [
          {
            "accuracy": 0.729167,
            "f1": 0.726058,
            "f1_weighted": 0.724451
          },
          {
            "accuracy": 0.822917,
            "f1": 0.829478,
            "f1_weighted": 0.82411
          },
          {
            "accuracy": 0.6875,
            "f1": 0.688749,
            "f1_weighted": 0.676112
          },
          {
            "accuracy": 0.760417,
            "f1": 0.767895,
            "f1_weighted": 0.76072
          },
          {
            "accuracy": 0.802083,
            "f1": 0.80021,
            "f1_weighted": 0.799997
          },
          {
            "accuracy": 0.822917,
            "f1": 0.820924,
            "f1_weighted": 0.820639
          },
          {
            "accuracy": 0.802083,
            "f1": 0.794734,
            "f1_weighted": 0.796216
          },
          {
            "accuracy": 0.75,
            "f1": 0.755095,
            "f1_weighted": 0.749349
          },
          {
            "accuracy": 0.78125,
            "f1": 0.779365,
            "f1_weighted": 0.778323
          },
          {
            "accuracy": 0.770833,
            "f1": 0.768206,
            "f1_weighted": 0.766374
          }
        ],
        "main_score": 0.772917,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 13.719995498657227,
  "kg_co2_emissions": 0.0003940306543337327
}