{
  "dataset_revision": "1beac1b941da76a9c51e3e5b39d230fde9a80983",
  "evaluation_time": 8.557047605514526,
  "kg_co2_emissions": 0.0002707471819536187,
  "mteb_version": "1.12.75",
  "scores": {
    "train": [
      {
        "accuracy": 0.598193359375,
        "f1": 0.5930940613684815,
        "f1_weighted": 0.5970218488301086,
        "hf_subset": "default",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.5930940613684815,
        "scores_per_experiment": [
          {
            "accuracy": 0.63037109375,
            "f1": 0.6265671326732596,
            "f1_weighted": 0.6316040551913376
          },
          {
            "accuracy": 0.6640625,
            "f1": 0.6532902499018752,
            "f1_weighted": 0.666241713755517
          },
          {
            "accuracy": 0.5791015625,
            "f1": 0.5700777782593955,
            "f1_weighted": 0.5825341674490809
          },
          {
            "accuracy": 0.544921875,
            "f1": 0.5488843206746515,
            "f1_weighted": 0.54079021534471
          },
          {
            "accuracy": 0.59912109375,
            "f1": 0.5970837882591833,
            "f1_weighted": 0.5933112653065888
          },
          {
            "accuracy": 0.5517578125,
            "f1": 0.5452130467906593,
            "f1_weighted": 0.5478242406656919
          },
          {
            "accuracy": 0.56201171875,
            "f1": 0.5551792676785127,
            "f1_weighted": 0.552911334815086
          },
          {
            "accuracy": 0.62158203125,
            "f1": 0.6063785058670415,
            "f1_weighted": 0.6247692576028394
          },
          {
            "accuracy": 0.58447265625,
            "f1": 0.5789854590933473,
            "f1_weighted": 0.5870070118859517
          },
          {
            "accuracy": 0.64453125,
            "f1": 0.6492810644868899,
            "f1_weighted": 0.6432252262842831
          }
        ]
      }
    ]
  },
  "task_name": "SentimentAnalysisHindi"
}