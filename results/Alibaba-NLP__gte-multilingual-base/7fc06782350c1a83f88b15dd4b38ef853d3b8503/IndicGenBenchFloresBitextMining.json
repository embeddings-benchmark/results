{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 149.4014880657196,
  "kg_co2_emissions": 0.008644489616315428,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167324,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167324,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9861660079051383,
        "f1": 0.9818840579710143,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9818840579710143,
        "precision": 0.9799077733860342,
        "recall": 0.9861660079051383
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167324,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167324,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9871541501976284,
        "f1": 0.9834321475625823,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9834321475625823,
        "precision": 0.9818017127799736,
        "recall": 0.9871541501976284
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167324,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9934123847167324,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9907773386034255,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9907773386034255,
        "precision": 0.9896245059288538,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.983201581027668,
        "f1": 0.9777667984189723,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9777667984189723,
        "precision": 0.9751317523056654,
        "recall": 0.983201581027668
      },
      {
        "accuracy": 0.9782608695652174,
        "f1": 0.972068511198946,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.972068511198946,
        "precision": 0.9692852437417655,
        "recall": 0.9782608695652174
      },
      {
        "accuracy": 0.9644268774703557,
        "f1": 0.954298418972332,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.954298418972332,
        "precision": 0.9497459062676453,
        "recall": 0.9644268774703557
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9888010540184454,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9888010540184454,
        "precision": 0.9878458498023716,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.994729907773386,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.994729907773386,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9843544137022397,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9843544137022397,
        "precision": 0.9825428194993412,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.9973649538866931,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9973649538866931,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9843544137022399,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9843544137022399,
        "precision": 0.9825428194993413,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9930830039525692,
        "f1": 0.9907773386034255,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9907773386034255,
        "precision": 0.9896245059288538,
        "recall": 0.9930830039525692
      },
      {
        "accuracy": 0.974308300395257,
        "f1": 0.9664031620553359,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9664031620553359,
        "precision": 0.9626152832674572,
        "recall": 0.974308300395257
      },
      {
        "accuracy": 0.9644268774703557,
        "f1": 0.9540513833992095,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9540513833992095,
        "precision": 0.9492753623188406,
        "recall": 0.9644268774703557
      },
      {
        "accuracy": 0.9486166007905138,
        "f1": 0.9331357048748352,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9331357048748352,
        "precision": 0.9260540184453229,
        "recall": 0.9486166007905138
      },
      {
        "accuracy": 0.9357707509881423,
        "f1": 0.9161396574440053,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9161396574440053,
        "precision": 0.9071146245059288,
        "recall": 0.9357707509881423
      },
      {
        "accuracy": 0.9802371541501976,
        "f1": 0.974308300395257,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.974308300395257,
        "precision": 0.9715085638998682,
        "recall": 0.9802371541501976
      },
      {
        "accuracy": 0.974308300395257,
        "f1": 0.9667325428194993,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9667325428194993,
        "precision": 0.9631093544137022,
        "recall": 0.974308300395257
      },
      {
        "accuracy": 0.9733201581027668,
        "f1": 0.965250329380764,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.965250329380764,
        "precision": 0.9614624505928854,
        "recall": 0.9733201581027668
      },
      {
        "accuracy": 0.9515810276679841,
        "f1": 0.9375823451910409,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9375823451910409,
        "precision": 0.9310276679841898,
        "recall": 0.9515810276679841
      },
      {
        "accuracy": 0.9851778656126482,
        "f1": 0.9804018445322793,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9804018445322793,
        "precision": 0.9780961791831357,
        "recall": 0.9851778656126482
      },
      {
        "accuracy": 0.9772727272727273,
        "f1": 0.9698616600790514,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9698616600790514,
        "precision": 0.9662384716732543,
        "recall": 0.9772727272727273
      },
      {
        "accuracy": 0.9733201581027668,
        "f1": 0.9649209486166008,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9649209486166008,
        "precision": 0.9609683794466403,
        "recall": 0.9733201581027668
      },
      {
        "accuracy": 0.967391304347826,
        "f1": 0.9570158102766798,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.9570158102766798,
        "precision": 0.9520750988142292,
        "recall": 0.967391304347826
      },
      {
        "accuracy": 0.9565217391304348,
        "f1": 0.9430171277997365,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9430171277997365,
        "precision": 0.9367588932806324,
        "recall": 0.9565217391304348
      },
      {
        "accuracy": 0.9347826086956522,
        "f1": 0.9169489930359496,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9169489930359496,
        "precision": 0.9089920948616601,
        "recall": 0.9347826086956522
      },
      {
        "accuracy": 0.9752964426877471,
        "f1": 0.9679512516469038,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9679512516469038,
        "precision": 0.9645092226613966,
        "recall": 0.9752964426877471
      },
      {
        "accuracy": 0.9624505928853755,
        "f1": 0.9517457180500659,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9517457180500659,
        "precision": 0.9468050065876152,
        "recall": 0.9624505928853755
      },
      {
        "accuracy": 0.983201581027668,
        "f1": 0.9777667984189723,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9777667984189723,
        "precision": 0.9751317523056653,
        "recall": 0.983201581027668
      },
      {
        "accuracy": 0.9664031620553359,
        "f1": 0.9555335968379447,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9555335968379447,
        "precision": 0.9502635046113307,
        "recall": 0.9664031620553359
      },
      {
        "accuracy": 0.12845849802371542,
        "f1": 0.10925277014281166,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.10925277014281166,
        "precision": 0.10334746670633169,
        "recall": 0.12845849802371542
      },
      {
        "accuracy": 0.18280632411067194,
        "f1": 0.11928418508834324,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.11928418508834324,
        "precision": 0.10367904082083926,
        "recall": 0.18280632411067194
      },
      {
        "accuracy": 0.39723320158102765,
        "f1": 0.3420402198811289,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.3420402198811289,
        "precision": 0.3248051195373966,
        "recall": 0.39723320158102765
      },
      {
        "accuracy": 0.40810276679841895,
        "f1": 0.32751748142064346,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.32751748142064346,
        "precision": 0.3016884757947883,
        "recall": 0.40810276679841895
      },
      {
        "accuracy": 0.9772727272727273,
        "f1": 0.9703557312252964,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9703557312252964,
        "precision": 0.9670619235836628,
        "recall": 0.9772727272727273
      },
      {
        "accuracy": 0.9644268774703557,
        "f1": 0.953227931488801,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.953227931488801,
        "precision": 0.9479578392621871,
        "recall": 0.9644268774703557
      },
      {
        "accuracy": 0.8932806324110671,
        "f1": 0.8636034255599473,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8636034255599473,
        "precision": 0.8503293807641633,
        "recall": 0.8932806324110671
      },
      {
        "accuracy": 0.8764822134387352,
        "f1": 0.8405467720685111,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8405467720685111,
        "precision": 0.8241436100131752,
        "recall": 0.8764822134387352
      },
      {
        "accuracy": 0.9723320158102767,
        "f1": 0.9640645586297759,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9640645586297759,
        "precision": 0.9603096179183135,
        "recall": 0.9723320158102767
      },
      {
        "accuracy": 0.9486166007905138,
        "f1": 0.9334180312441183,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9334180312441183,
        "precision": 0.926548089591568,
        "recall": 0.9486166007905138
      },
      {
        "accuracy": 0.983201581027668,
        "f1": 0.9782608695652174,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9782608695652174,
        "precision": 0.9759552042160737,
        "recall": 0.983201581027668
      },
      {
        "accuracy": 0.9693675889328063,
        "f1": 0.9598155467720685,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.9598155467720685,
        "precision": 0.9552371541501977,
        "recall": 0.9693675889328063
      },
      {
        "accuracy": 0.908102766798419,
        "f1": 0.8837435621032459,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8837435621032459,
        "precision": 0.8729578392621872,
        "recall": 0.908102766798419
      },
      {
        "accuracy": 0.8656126482213439,
        "f1": 0.8283126293995859,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8283126293995859,
        "precision": 0.8123847167325429,
        "recall": 0.8656126482213439
      },
      {
        "accuracy": 0.7924901185770751,
        "f1": 0.7397123407992974,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.7397123407992974,
        "precision": 0.7174489459815546,
        "recall": 0.7924901185770751
      },
      {
        "accuracy": 0.8013833992094862,
        "f1": 0.7486824769433466,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.7486824769433466,
        "precision": 0.7254117259552042,
        "recall": 0.8013833992094862
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9841897233201581,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9841897233201581,
        "precision": 0.9822134387351779,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.9703557312252964,
        "f1": 0.961627140974967,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.961627140974967,
        "precision": 0.9575428194993412,
        "recall": 0.9703557312252964
      },
      {
        "accuracy": 0.9861660079051383,
        "f1": 0.9823781291172595,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9823781291172595,
        "precision": 0.980566534914361,
        "recall": 0.9861660079051383
      },
      {
        "accuracy": 0.9713438735177866,
        "f1": 0.9629446640316206,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9629446640316206,
        "precision": 0.9590250329380764,
        "recall": 0.9713438735177866
      },
      {
        "accuracy": 0.03557312252964427,
        "f1": 0.02496892391680052,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.02496892391680052,
        "precision": 0.023038056245050193,
        "recall": 0.03557312252964427
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.01564837413820162,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.01564837413820162,
        "precision": 0.011935062476894331,
        "recall": 0.037549407114624504
      }
    ],
    "validation": [
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.9852892009361418,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9852892009361418,
        "precision": 0.9834503510531595,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.9779338014042126,
        "f1": 0.970912738214644,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.970912738214644,
        "precision": 0.9675693747910399,
        "recall": 0.9779338014042126
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9829488465396189,
        "f1": 0.9772651287194918,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9772651287194918,
        "precision": 0.9744232698094283,
        "recall": 0.9829488465396189
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9859578736208626,
        "f1": 0.9812771648278167,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9812771648278167,
        "precision": 0.9789368104312939,
        "recall": 0.9859578736208626
      },
      {
        "accuracy": 0.9809428284854563,
        "f1": 0.9747576061517886,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9747576061517886,
        "precision": 0.971748579070545,
        "recall": 0.9809428284854563
      },
      {
        "accuracy": 0.9749247743229689,
        "f1": 0.9675693747910398,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9675693747910398,
        "precision": 0.9640588431962555,
        "recall": 0.9749247743229689
      },
      {
        "accuracy": 0.958876629889669,
        "f1": 0.9456703443664326,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9456703443664326,
        "precision": 0.9393179538615848,
        "recall": 0.958876629889669
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.9854563691073219,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9854563691073219,
        "precision": 0.9837846873955199,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9933132731527916,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9933132731527916,
        "precision": 0.9924774322968907,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9859578736208626,
        "f1": 0.981444332998997,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.981444332998997,
        "precision": 0.9792711467736543,
        "recall": 0.9859578736208626
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9893012370444668,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9893012370444668,
        "precision": 0.9879638916750251,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9859578736208626,
        "f1": 0.9812771648278167,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9812771648278167,
        "precision": 0.9789368104312939,
        "recall": 0.9859578736208626
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9889669007021064,
        "f1": 0.9852892009361417,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9852892009361417,
        "precision": 0.9834503510531595,
        "recall": 0.9889669007021064
      },
      {
        "accuracy": 0.970912738214644,
        "f1": 0.9617184887997325,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9617184887997325,
        "precision": 0.9573721163490472,
        "recall": 0.970912738214644
      },
      {
        "accuracy": 0.9578736208625878,
        "f1": 0.945068538950184,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.945068538950184,
        "precision": 0.9390672016048145,
        "recall": 0.9578736208625878
      },
      {
        "accuracy": 0.9488465396188566,
        "f1": 0.933032430625209,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.933032430625209,
        "precision": 0.9255265797392177,
        "recall": 0.9488465396188566
      },
      {
        "accuracy": 0.9107321965897693,
        "f1": 0.8852223336676697,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.8852223336676697,
        "precision": 0.8736041457706453,
        "recall": 0.9107321965897693
      },
      {
        "accuracy": 0.9809428284854563,
        "f1": 0.9750919424941491,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9750919424941491,
        "precision": 0.9722500835840855,
        "recall": 0.9809428284854563
      },
      {
        "accuracy": 0.9689067201604814,
        "f1": 0.9590437980608493,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9590437980608493,
        "precision": 0.9543630892678034,
        "recall": 0.9689067201604814
      },
      {
        "accuracy": 0.9739217652958877,
        "f1": 0.9659645603477097,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9659645603477097,
        "precision": 0.9621364092276831,
        "recall": 0.9739217652958877
      },
      {
        "accuracy": 0.9458375125376128,
        "f1": 0.9286191909060514,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9286191909060514,
        "precision": 0.9202607823470411,
        "recall": 0.9458375125376128
      },
      {
        "accuracy": 0.9819458375125376,
        "f1": 0.9762621196924105,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9762621196924105,
        "precision": 0.973420260782347,
        "recall": 0.9819458375125376
      },
      {
        "accuracy": 0.9648946840521565,
        "f1": 0.9536944165830825,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9536944165830825,
        "precision": 0.948345035105316,
        "recall": 0.9648946840521565
      },
      {
        "accuracy": 0.9739217652958877,
        "f1": 0.965229020394517,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.965229020394517,
        "precision": 0.9608826479438315,
        "recall": 0.9739217652958877
      },
      {
        "accuracy": 0.9568706118355065,
        "f1": 0.9430625208960213,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.9430625208960213,
        "precision": 0.936392510865931,
        "recall": 0.9568706118355065
      },
      {
        "accuracy": 0.9358074222668004,
        "f1": 0.9154129053828151,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9154129053828151,
        "precision": 0.9055499832831828,
        "recall": 0.9358074222668004
      },
      {
        "accuracy": 0.9307923771313942,
        "f1": 0.9092276830491475,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9092276830491475,
        "precision": 0.8990304246071548,
        "recall": 0.9307923771313942
      },
      {
        "accuracy": 0.9739217652958877,
        "f1": 0.9671347375459712,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9671347375459712,
        "precision": 0.9639752591106653,
        "recall": 0.9739217652958877
      },
      {
        "accuracy": 0.9568706118355065,
        "f1": 0.9442995653627548,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9442995653627548,
        "precision": 0.9384821130056836,
        "recall": 0.9568706118355065
      },
      {
        "accuracy": 0.9859578736208626,
        "f1": 0.9812771648278167,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9812771648278167,
        "precision": 0.9789368104312939,
        "recall": 0.9859578736208626
      },
      {
        "accuracy": 0.970912738214644,
        "f1": 0.9619525242393847,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9619525242393847,
        "precision": 0.9577900367769976,
        "recall": 0.970912738214644
      },
      {
        "accuracy": 0.1444332998996991,
        "f1": 0.12321183258426603,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.12321183258426603,
        "precision": 0.11695629088573045,
        "recall": 0.1444332998996991
      },
      {
        "accuracy": 0.18254764292878636,
        "f1": 0.1173866510726937,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.1173866510726937,
        "precision": 0.0997695791533186,
        "recall": 0.18254764292878636
      },
      {
        "accuracy": 0.40421263791374124,
        "f1": 0.33984380992906565,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.33984380992906565,
        "precision": 0.3193505480366062,
        "recall": 0.40421263791374124
      },
      {
        "accuracy": 0.4172517552657974,
        "f1": 0.33611330696968417,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.33611330696968417,
        "precision": 0.3089093296263721,
        "recall": 0.4172517552657974
      },
      {
        "accuracy": 0.9799398194583752,
        "f1": 0.9739217652958877,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9739217652958877,
        "precision": 0.9710799063858242,
        "recall": 0.9799398194583752
      },
      {
        "accuracy": 0.9538615847542627,
        "f1": 0.9391507856904044,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9391507856904044,
        "precision": 0.9321297225008358,
        "recall": 0.9538615847542627
      },
      {
        "accuracy": 0.8916750250752257,
        "f1": 0.861250417920428,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.861250417920428,
        "precision": 0.8470745570043463,
        "recall": 0.8916750250752257
      },
      {
        "accuracy": 0.8645937813440321,
        "f1": 0.8243396857238381,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8243396857238381,
        "precision": 0.8061685055165496,
        "recall": 0.8645937813440321
      },
      {
        "accuracy": 0.954864593781344,
        "f1": 0.9407221664994984,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9407221664994984,
        "precision": 0.9340521564694082,
        "recall": 0.954864593781344
      },
      {
        "accuracy": 0.9348044132397192,
        "f1": 0.9148779672350383,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9148779672350383,
        "precision": 0.9055499832831829,
        "recall": 0.9348044132397192
      },
      {
        "accuracy": 0.9719157472417251,
        "f1": 0.9627214978268138,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9627214978268138,
        "precision": 0.9582079572049482,
        "recall": 0.9719157472417251
      },
      {
        "accuracy": 0.958876629889669,
        "f1": 0.9453360080240722,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.9453360080240722,
        "precision": 0.938649281176864,
        "recall": 0.958876629889669
      },
      {
        "accuracy": 0.8906720160481444,
        "f1": 0.8590963366289344,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8590963366289344,
        "precision": 0.8450183884988298,
        "recall": 0.8906720160481444
      },
      {
        "accuracy": 0.8425275827482447,
        "f1": 0.7976787505373262,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.7976787505373262,
        "precision": 0.7781176863925109,
        "recall": 0.8425275827482447
      },
      {
        "accuracy": 0.7773319959879639,
        "f1": 0.7202154081291493,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.7202154081291493,
        "precision": 0.6969002244829726,
        "recall": 0.7773319959879639
      },
      {
        "accuracy": 0.7963891675025075,
        "f1": 0.7400534938147777,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.7400534938147777,
        "precision": 0.7156803744567035,
        "recall": 0.7963891675025075
      },
      {
        "accuracy": 0.9839518555667001,
        "f1": 0.9789368104312939,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9789368104312939,
        "precision": 0.9764292878635907,
        "recall": 0.9839518555667001
      },
      {
        "accuracy": 0.9689067201604814,
        "f1": 0.9587094617184888,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9587094617184888,
        "precision": 0.9536944165830825,
        "recall": 0.9689067201604814
      },
      {
        "accuracy": 0.9829488465396189,
        "f1": 0.9772651287194918,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9772651287194918,
        "precision": 0.9744232698094283,
        "recall": 0.9829488465396189
      },
      {
        "accuracy": 0.9699097291875627,
        "f1": 0.9602139752591107,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9602139752591107,
        "precision": 0.9555332664660648,
        "recall": 0.9699097291875627
      },
      {
        "accuracy": 0.02708124373119358,
        "f1": 0.018845325537793813,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.018845325537793813,
        "precision": 0.01770861990725649,
        "recall": 0.02708124373119358
      },
      {
        "accuracy": 0.024072216649949848,
        "f1": 0.007311291077702955,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.007311291077702955,
        "precision": 0.005266642593569026,
        "recall": 0.024072216649949848
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}