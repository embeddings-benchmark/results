{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "evaluation_time": 1071.4071300029755,
  "kg_co2_emissions": 0.08963246324644233,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.383203125,
        "f1": 0.3391984081885905,
        "f1_weighted": 0.37520991714742447,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.383203125,
        "scores_per_experiment": [
          {
            "accuracy": 0.37939453125,
            "f1": 0.3308987324649169,
            "f1_weighted": 0.3683162267912403
          },
          {
            "accuracy": 0.39599609375,
            "f1": 0.36036772292269775,
            "f1_weighted": 0.38671002171577507
          },
          {
            "accuracy": 0.37158203125,
            "f1": 0.33475379664563953,
            "f1_weighted": 0.3638140682263029
          },
          {
            "accuracy": 0.38427734375,
            "f1": 0.3358027401176293,
            "f1_weighted": 0.371551401983715
          },
          {
            "accuracy": 0.384765625,
            "f1": 0.3502641121290901,
            "f1_weighted": 0.37503665204139447
          },
          {
            "accuracy": 0.375,
            "f1": 0.32794723319262653,
            "f1_weighted": 0.3660861141123535
          },
          {
            "accuracy": 0.38037109375,
            "f1": 0.33796221846120034,
            "f1_weighted": 0.3827332568276366
          },
          {
            "accuracy": 0.3876953125,
            "f1": 0.33541706361535534,
            "f1_weighted": 0.382618421713433
          },
          {
            "accuracy": 0.3857421875,
            "f1": 0.3422207090147696,
            "f1_weighted": 0.38239049970365024
          },
          {
            "accuracy": 0.38720703125,
            "f1": 0.3363497533219791,
            "f1_weighted": 0.3728425083587439
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.38525390625,
        "f1": 0.31792173453091,
        "f1_weighted": 0.37546083326884594,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.38525390625,
        "scores_per_experiment": [
          {
            "accuracy": 0.3681640625,
            "f1": 0.3035575213660245,
            "f1_weighted": 0.3585180456318162
          },
          {
            "accuracy": 0.3935546875,
            "f1": 0.33061903397388276,
            "f1_weighted": 0.3800376600702504
          },
          {
            "accuracy": 0.3837890625,
            "f1": 0.30726866268623976,
            "f1_weighted": 0.3710300363825968
          },
          {
            "accuracy": 0.37158203125,
            "f1": 0.3040606956653981,
            "f1_weighted": 0.3556131136784332
          },
          {
            "accuracy": 0.38232421875,
            "f1": 0.3036491499620793,
            "f1_weighted": 0.37000934068251773
          },
          {
            "accuracy": 0.37890625,
            "f1": 0.3165219312720889,
            "f1_weighted": 0.3770746510287172
          },
          {
            "accuracy": 0.3857421875,
            "f1": 0.32887878507916535,
            "f1_weighted": 0.3789440539946909
          },
          {
            "accuracy": 0.4033203125,
            "f1": 0.3390519222955755,
            "f1_weighted": 0.39164311444332744
          },
          {
            "accuracy": 0.3916015625,
            "f1": 0.32335855497461585,
            "f1_weighted": 0.38393077853094826
          },
          {
            "accuracy": 0.3935546875,
            "f1": 0.32225108803402985,
            "f1_weighted": 0.3878075382451614
          }
        ]
      }
    ]
  },
  "task_name": "GreekLegalCodeClassification"
}