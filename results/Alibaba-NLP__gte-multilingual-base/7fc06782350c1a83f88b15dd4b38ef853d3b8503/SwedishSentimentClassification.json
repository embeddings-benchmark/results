{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.908301,
        "f1": 0.90798,
        "f1_weighted": 0.907993,
        "ap": 0.860629,
        "ap_weighted": 0.860629,
        "scores_per_experiment": [
          {
            "accuracy": 0.888672,
            "f1": 0.887766,
            "f1_weighted": 0.887795,
            "ap": 0.8235,
            "ap_weighted": 0.8235
          },
          {
            "accuracy": 0.914551,
            "f1": 0.91455,
            "f1_weighted": 0.91455,
            "ap": 0.881455,
            "ap_weighted": 0.881455
          },
          {
            "accuracy": 0.932617,
            "f1": 0.932577,
            "f1_weighted": 0.932582,
            "ap": 0.896106,
            "ap_weighted": 0.896106
          },
          {
            "accuracy": 0.901367,
            "f1": 0.90133,
            "f1_weighted": 0.901335,
            "ap": 0.857105,
            "ap_weighted": 0.857105
          },
          {
            "accuracy": 0.923828,
            "f1": 0.923805,
            "f1_weighted": 0.923809,
            "ap": 0.88683,
            "ap_weighted": 0.88683
          },
          {
            "accuracy": 0.920898,
            "f1": 0.920765,
            "f1_weighted": 0.920775,
            "ap": 0.875456,
            "ap_weighted": 0.875456
          },
          {
            "accuracy": 0.888672,
            "f1": 0.888447,
            "f1_weighted": 0.888461,
            "ap": 0.834226,
            "ap_weighted": 0.834226
          },
          {
            "accuracy": 0.92334,
            "f1": 0.923231,
            "f1_weighted": 0.92324,
            "ap": 0.879649,
            "ap_weighted": 0.879649
          },
          {
            "accuracy": 0.924805,
            "f1": 0.924659,
            "f1_weighted": 0.924669,
            "ap": 0.87955,
            "ap_weighted": 0.87955
          },
          {
            "accuracy": 0.864258,
            "f1": 0.862673,
            "f1_weighted": 0.862716,
            "ap": 0.792416,
            "ap_weighted": 0.792416
          }
        ],
        "main_score": 0.908301,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.907178,
        "f1": 0.906871,
        "f1_weighted": 0.90688,
        "ap": 0.859132,
        "ap_weighted": 0.859132,
        "scores_per_experiment": [
          {
            "accuracy": 0.895508,
            "f1": 0.894817,
            "f1_weighted": 0.894833,
            "ap": 0.833115,
            "ap_weighted": 0.833115
          },
          {
            "accuracy": 0.914062,
            "f1": 0.914062,
            "f1_weighted": 0.914062,
            "ap": 0.878785,
            "ap_weighted": 0.878785
          },
          {
            "accuracy": 0.922852,
            "f1": 0.922816,
            "f1_weighted": 0.922819,
            "ap": 0.883774,
            "ap_weighted": 0.883774
          },
          {
            "accuracy": 0.901367,
            "f1": 0.90134,
            "f1_weighted": 0.901343,
            "ap": 0.857531,
            "ap_weighted": 0.857531
          },
          {
            "accuracy": 0.928711,
            "f1": 0.928701,
            "f1_weighted": 0.928703,
            "ap": 0.894881,
            "ap_weighted": 0.894881
          },
          {
            "accuracy": 0.921875,
            "f1": 0.92175,
            "f1_weighted": 0.921756,
            "ap": 0.876576,
            "ap_weighted": 0.876576
          },
          {
            "accuracy": 0.89502,
            "f1": 0.894803,
            "f1_weighted": 0.894812,
            "ap": 0.841406,
            "ap_weighted": 0.841406
          },
          {
            "accuracy": 0.923828,
            "f1": 0.923749,
            "f1_weighted": 0.923754,
            "ap": 0.881546,
            "ap_weighted": 0.881546
          },
          {
            "accuracy": 0.908203,
            "f1": 0.907957,
            "f1_weighted": 0.907966,
            "ap": 0.855927,
            "ap_weighted": 0.855927
          },
          {
            "accuracy": 0.860352,
            "f1": 0.858721,
            "f1_weighted": 0.858751,
            "ap": 0.787777,
            "ap_weighted": 0.787777
          }
        ],
        "main_score": 0.907178,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 17.96569585800171,
  "kg_co2_emissions": 0.000724663206173687
}