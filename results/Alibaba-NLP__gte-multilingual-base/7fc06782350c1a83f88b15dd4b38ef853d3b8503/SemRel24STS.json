{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 7.651536464691162,
  "kg_co2_emissions": 0.00040135413217136064,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.7864856951395557,
        "cosine_spearman": 0.779826154976936,
        "euclidean_pearson": 0.7670348956046805,
        "euclidean_spearman": 0.779826154976936,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.779826154976936,
        "manhattan_pearson": 0.7629950996756317,
        "manhattan_spearman": 0.7756730940616549,
        "pearson": 0.7864856951395557,
        "spearman": 0.779826154976936
      },
      {
        "cosine_pearson": 0.7903101316013527,
        "cosine_spearman": 0.7626866938877179,
        "euclidean_pearson": 0.7936360508534922,
        "euclidean_spearman": 0.7626866938877179,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.7626866938877179,
        "manhattan_pearson": 0.789232321985885,
        "manhattan_spearman": 0.7580316785364134,
        "pearson": 0.7903101316013527,
        "spearman": 0.7626866938877179
      },
      {
        "cosine_pearson": 0.6028769008902535,
        "cosine_spearman": 0.6030197060788784,
        "euclidean_pearson": 0.5942007069173629,
        "euclidean_spearman": 0.6030197060788784,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.6030197060788784,
        "manhattan_pearson": 0.5953210195895072,
        "manhattan_spearman": 0.6013283978260817,
        "pearson": 0.6028769008902535,
        "spearman": 0.6030197060788784
      },
      {
        "cosine_pearson": 0.5109179749903481,
        "cosine_spearman": 0.4426991119881071,
        "euclidean_pearson": 0.5172825039522025,
        "euclidean_spearman": 0.4426991119881071,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.4426991119881071,
        "manhattan_pearson": 0.5215839383181544,
        "manhattan_spearman": 0.4503627463409398,
        "pearson": 0.5109179749903481,
        "spearman": 0.4426991119881071
      },
      {
        "cosine_pearson": 0.5233116707828208,
        "cosine_spearman": 0.4990745521168163,
        "euclidean_pearson": 0.5257798868926311,
        "euclidean_spearman": 0.4990745521168163,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.4990745521168163,
        "manhattan_pearson": 0.5315457486794606,
        "manhattan_spearman": 0.5061333549584299,
        "pearson": 0.5233116707828208,
        "spearman": 0.4990745521168163
      },
      {
        "cosine_pearson": 0.8047206874731091,
        "cosine_spearman": 0.7931499251357025,
        "euclidean_pearson": 0.8060042229817729,
        "euclidean_spearman": 0.7931499251357025,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7931499251357025,
        "manhattan_pearson": 0.8040659657134452,
        "manhattan_spearman": 0.7901032808018947,
        "pearson": 0.8047206874731091,
        "spearman": 0.7931499251357025
      },
      {
        "cosine_pearson": 0.5540841403049408,
        "cosine_spearman": 0.5322722447610121,
        "euclidean_pearson": 0.553133268498376,
        "euclidean_spearman": 0.5322722447610121,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.5322722447610121,
        "manhattan_pearson": 0.5529633218237091,
        "manhattan_spearman": 0.5343509712280377,
        "pearson": 0.5540841403049408,
        "spearman": 0.5322722447610121
      },
      {
        "cosine_pearson": 0.8059409273685576,
        "cosine_spearman": 0.8164822827519996,
        "euclidean_pearson": 0.7811492891884968,
        "euclidean_spearman": 0.8164822827519996,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.8164822827519996,
        "manhattan_pearson": 0.7773197092404805,
        "manhattan_spearman": 0.8113131356676503,
        "pearson": 0.8059409273685576,
        "spearman": 0.8164822827519996
      },
      {
        "cosine_pearson": 0.3709712315571596,
        "cosine_spearman": 0.3698309298319327,
        "euclidean_pearson": 0.3999657488164998,
        "euclidean_spearman": 0.3698309298319327,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.3698309298319327,
        "manhattan_pearson": 0.39999204093586865,
        "manhattan_spearman": 0.36749415925417356,
        "pearson": 0.3709712315571596,
        "spearman": 0.3698309298319327
      },
      {
        "cosine_pearson": 0.5363862867316243,
        "cosine_spearman": 0.533173551297414,
        "euclidean_pearson": 0.5332197313302453,
        "euclidean_spearman": 0.533173551297414,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.533173551297414,
        "manhattan_pearson": 0.5332738584570662,
        "manhattan_spearman": 0.5351442903738463,
        "pearson": 0.5363862867316243,
        "spearman": 0.533173551297414
      },
      {
        "cosine_pearson": 0.8578932918564507,
        "cosine_spearman": 0.8449025861674018,
        "euclidean_pearson": 0.8432304637243561,
        "euclidean_spearman": 0.8449025861674018,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.8449025861674018,
        "manhattan_pearson": 0.8424378070717413,
        "manhattan_spearman": 0.8450019292619884,
        "pearson": 0.8578932918564507,
        "spearman": 0.8449025861674018
      },
      {
        "cosine_pearson": 0.8624807019852228,
        "cosine_spearman": 0.8502655218346152,
        "euclidean_pearson": 0.8356488125855007,
        "euclidean_spearman": 0.8502655218346152,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.8502655218346152,
        "manhattan_pearson": 0.8345636846316571,
        "manhattan_spearman": 0.8495824035759377,
        "pearson": 0.8624807019852228,
        "spearman": 0.8502655218346152
      }
    ]
  },
  "task_name": "SemRel24STS"
}