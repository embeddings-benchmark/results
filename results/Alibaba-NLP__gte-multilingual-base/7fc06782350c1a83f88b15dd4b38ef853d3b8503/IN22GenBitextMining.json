{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 25.82373070716858,
  "kg_co2_emissions": 0.0013695625033069388,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.478515625,
        "f1": 0.4184974042884199,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.4184974042884199,
        "precision": 0.3954791356646825,
        "recall": 0.478515625
      },
      {
        "accuracy": 0.8984375,
        "f1": 0.8724609375,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.8724609375,
        "precision": 0.8599446614583333,
        "recall": 0.8984375
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9627278645833333,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9627278645833333,
        "precision": 0.9583333333333334,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8475911458333334,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.8475911458333334,
        "precision": 0.8338216145833334,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9821614583333333,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9821614583333333,
        "precision": 0.980224609375,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9794921875,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.9794921875,
        "precision": 0.97705078125,
        "recall": 0.984375
      },
      {
        "accuracy": 0.8369140625,
        "f1": 0.7972330729166666,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.7972330729166666,
        "precision": 0.779248046875,
        "recall": 0.8369140625
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.978515625,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.978515625,
        "precision": 0.97607421875,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.9666341145833333,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.9666341145833333,
        "precision": 0.9627278645833334,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9742838541666666,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9742838541666666,
        "precision": 0.97119140625,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.007047816685267857,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.007047816685267857,
        "precision": 0.006533663295516744,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.97314453125,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.97314453125,
        "precision": 0.9700520833333333,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9622395833333333,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.9622395833333333,
        "precision": 0.95751953125,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.9322916666666667,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.9322916666666667,
        "precision": 0.9244791666666667,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9203125,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.9203125,
        "precision": 0.9115397135416666,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005738467261904762,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.005738467261904762,
        "precision": 0.004456823035082734,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.8034830729166667,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.8034830729166667,
        "precision": 0.7877604166666667,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9700520833333333,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.9700520833333333,
        "precision": 0.9669596354166667,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9650065104166666,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.9650065104166666,
        "precision": 0.9607747395833334,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.98974609375,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.98974609375,
        "precision": 0.9886067708333333,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.482421875,
        "f1": 0.4213099888392857,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.4213099888392857,
        "precision": 0.3973911830357143,
        "recall": 0.482421875
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9060872395833333,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9060872395833333,
        "precision": 0.8963216145833333,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.87294921875,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.87294921875,
        "precision": 0.8604329427083333,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.98974609375,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.98974609375,
        "precision": 0.9886067708333333,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.8515625,
        "f1": 0.81337890625,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.81337890625,
        "precision": 0.795849609375,
        "recall": 0.8515625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9814453125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0031384522213775074,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0031384522213775074,
        "precision": 0.002476996880073052,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666667,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9869791666666667,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9729817708333333,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.9729817708333333,
        "precision": 0.9697265625,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9567057291666666,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.9567057291666666,
        "precision": 0.9519856770833334,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.9347330729166666,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.9347330729166666,
        "precision": 0.9275716145833333,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0062996736336580084,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0062996736336580084,
        "precision": 0.005127375879329004,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.8818359375,
        "f1": 0.8550130208333333,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.8550130208333333,
        "precision": 0.842724609375,
        "recall": 0.8818359375
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9866536458333333,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.9866536458333333,
        "precision": 0.9853515625,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.4638671875,
        "f1": 0.40274690722688766,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.40274690722688766,
        "precision": 0.38167290206573223,
        "recall": 0.4638671875
      },
      {
        "accuracy": 0.4599609375,
        "f1": 0.40243488878742784,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.40243488878742784,
        "precision": 0.38305864504164133,
        "recall": 0.4599609375
      },
      {
        "accuracy": 0.5166015625,
        "f1": 0.46045430977328594,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.46045430977328594,
        "precision": 0.4424153998128607,
        "recall": 0.5166015625
      },
      {
        "accuracy": 0.41015625,
        "f1": 0.36478141987965057,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.36478141987965057,
        "precision": 0.35022482528778787,
        "recall": 0.41015625
      },
      {
        "accuracy": 0.51171875,
        "f1": 0.46228952525339245,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.46228952525339245,
        "precision": 0.4445639312582672,
        "recall": 0.51171875
      },
      {
        "accuracy": 0.4375,
        "f1": 0.37418859352453104,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.37418859352453104,
        "precision": 0.3526459118024702,
        "recall": 0.4375
      },
      {
        "accuracy": 0.5107421875,
        "f1": 0.45515140241702745,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.45515140241702745,
        "precision": 0.4356909373449901,
        "recall": 0.5107421875
      },
      {
        "accuracy": 0.416015625,
        "f1": 0.3553284660218254,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.3553284660218254,
        "precision": 0.3353652522798892,
        "recall": 0.416015625
      },
      {
        "accuracy": 0.443359375,
        "f1": 0.38973984457382893,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.38973984457382893,
        "precision": 0.3720038785969604,
        "recall": 0.443359375
      },
      {
        "accuracy": 0.5126953125,
        "f1": 0.4543287946633958,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4543287946633958,
        "precision": 0.4333984638095192,
        "recall": 0.5126953125
      },
      {
        "accuracy": 0.484375,
        "f1": 0.42916668834637584,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.42916668834637584,
        "precision": 0.411382026176948,
        "recall": 0.484375
      },
      {
        "accuracy": 0.4951171875,
        "f1": 0.43696756260232816,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.43696756260232816,
        "precision": 0.41735020079746643,
        "recall": 0.4951171875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.01196177859730849,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.01196177859730849,
        "precision": 0.01061206046557609,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.4833984375,
        "f1": 0.42234408115755767,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.42234408115755767,
        "precision": 0.4026254434470409,
        "recall": 0.4833984375
      },
      {
        "accuracy": 0.4189453125,
        "f1": 0.3599671595765346,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.3599671595765346,
        "precision": 0.3396039073773449,
        "recall": 0.4189453125
      },
      {
        "accuracy": 0.4609375,
        "f1": 0.4036006066044729,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.4036006066044729,
        "precision": 0.38526515523632665,
        "recall": 0.4609375
      },
      {
        "accuracy": 0.478515625,
        "f1": 0.42012011155077555,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.42012011155077555,
        "precision": 0.3993047805059524,
        "recall": 0.478515625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.010658886516563146,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.010658886516563146,
        "precision": 0.008820822240534144,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.5458984375,
        "f1": 0.49958231139010095,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.49958231139010095,
        "precision": 0.4827917078039149,
        "recall": 0.5458984375
      },
      {
        "accuracy": 0.4443359375,
        "f1": 0.3955607686966832,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.3955607686966832,
        "precision": 0.37854164966459036,
        "recall": 0.4443359375
      },
      {
        "accuracy": 0.4833984375,
        "f1": 0.43118743235930734,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.43118743235930734,
        "precision": 0.4145890865861569,
        "recall": 0.4833984375
      },
      {
        "accuracy": 0.458984375,
        "f1": 0.4070752208130062,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.4070752208130062,
        "precision": 0.3905579737872661,
        "recall": 0.458984375
      },
      {
        "accuracy": 0.90625,
        "f1": 0.8815755208333333,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8815755208333333,
        "precision": 0.869873046875,
        "recall": 0.90625
      },
      {
        "accuracy": 0.921875,
        "f1": 0.9013346354166667,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9013346354166667,
        "precision": 0.8919270833333333,
        "recall": 0.921875
      },
      {
        "accuracy": 0.5419921875,
        "f1": 0.4917193700396826,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.4917193700396826,
        "precision": 0.47223307291666666,
        "recall": 0.5419921875
      },
      {
        "accuracy": 0.9306640625,
        "f1": 0.9107282366071427,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9107282366071427,
        "precision": 0.9016927083333333,
        "recall": 0.9306640625
      },
      {
        "accuracy": 0.87109375,
        "f1": 0.8423177083333333,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8423177083333333,
        "precision": 0.829345703125,
        "recall": 0.87109375
      },
      {
        "accuracy": 0.9287109375,
        "f1": 0.9103841145833333,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9103841145833333,
        "precision": 0.902099609375,
        "recall": 0.9287109375
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.96826171875,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.96826171875,
        "precision": 0.96484375,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.9228515625,
        "f1": 0.9020833333333333,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9020833333333333,
        "precision": 0.8924967447916667,
        "recall": 0.9228515625
      },
      {
        "accuracy": 0.814453125,
        "f1": 0.7754448784722222,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7754448784722222,
        "precision": 0.7590901692708333,
        "recall": 0.814453125
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9410807291666666,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9410807291666666,
        "precision": 0.9348958333333334,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.9248046875,
        "f1": 0.9045247395833333,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9045247395833333,
        "precision": 0.8949381510416667,
        "recall": 0.9248046875
      },
      {
        "accuracy": 0.947265625,
        "f1": 0.9331705729166666,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9331705729166666,
        "precision": 0.9263509114583333,
        "recall": 0.947265625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0041651182624840525,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0041651182624840525,
        "precision": 0.0037928789511494252,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.9443359375,
        "f1": 0.9281901041666667,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9281901041666667,
        "precision": 0.9207356770833333,
        "recall": 0.9443359375
      },
      {
        "accuracy": 0.890625,
        "f1": 0.8638346354166666,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8638346354166666,
        "precision": 0.8516438802083333,
        "recall": 0.890625
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8794596354166666,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8794596354166666,
        "precision": 0.8682779947916666,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.8662109375,
        "f1": 0.8335937499999999,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.8335937499999999,
        "precision": 0.8190104166666667,
        "recall": 0.8662109375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00713898189484127,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00713898189484127,
        "precision": 0.006310841393849206,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.869140625,
        "f1": 0.8422061011904762,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8422061011904762,
        "precision": 0.82978515625,
        "recall": 0.869140625
      },
      {
        "accuracy": 0.9287109375,
        "f1": 0.9080403645833333,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9080403645833333,
        "precision": 0.8982747395833333,
        "recall": 0.9287109375
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9064127604166667,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9064127604166667,
        "precision": 0.896484375,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.951171875,
        "f1": 0.9376813616071428,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9376813616071428,
        "precision": 0.9315592447916667,
        "recall": 0.951171875
      },
      {
        "accuracy": 0.9619140625,
        "f1": 0.9504231770833333,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9504231770833333,
        "precision": 0.9449055989583334,
        "recall": 0.9619140625
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9845377604166667,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9845377604166667,
        "precision": 0.9827473958333334,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.44140625,
        "f1": 0.38060285526105836,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.38060285526105836,
        "precision": 0.35933922847985345,
        "recall": 0.44140625
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.9088541666666666,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.9088541666666666,
        "precision": 0.89892578125,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.888671875,
        "f1": 0.8578125,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8578125,
        "precision": 0.843701171875,
        "recall": 0.888671875
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9769531250000001,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9769531250000001,
        "precision": 0.974365234375,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9759114583333334,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9759114583333334,
        "precision": 0.9733072916666667,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.80078125,
        "f1": 0.7549014136904761,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.7549014136904761,
        "precision": 0.7358072916666667,
        "recall": 0.80078125
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9817708333333333,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9817708333333333,
        "precision": 0.9794921875,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.978515625,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.978515625,
        "precision": 0.9762369791666667,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002278645833333333,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.002278645833333333,
        "precision": 0.0017510913188562645,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9560546875,
        "f1": 0.9420572916666666,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9420572916666666,
        "precision": 0.93505859375,
        "recall": 0.9560546875
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9493815104166666,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9493815104166666,
        "precision": 0.9440104166666666,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9025065104166666,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9025065104166666,
        "precision": 0.8924153645833334,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002218967013888889,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.002218967013888889,
        "precision": 0.001359472233495671,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.849609375,
        "f1": 0.8119977678571428,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.8119977678571428,
        "precision": 0.7950032552083333,
        "recall": 0.849609375
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9814453125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333334,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9856770833333334,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.875,
        "f1": 0.848848157051282,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.848848157051282,
        "precision": 0.8380045572916666,
        "recall": 0.875
      },
      {
        "accuracy": 0.9033203125,
        "f1": 0.8795572916666666,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8795572916666666,
        "precision": 0.8683919270833333,
        "recall": 0.9033203125
      },
      {
        "accuracy": 0.5390625,
        "f1": 0.48021530877976193,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.48021530877976193,
        "precision": 0.45696114324044,
        "recall": 0.5390625
      },
      {
        "accuracy": 0.8701171875,
        "f1": 0.8418619791666667,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8418619791666667,
        "precision": 0.8291178385416667,
        "recall": 0.8701171875
      },
      {
        "accuracy": 0.88671875,
        "f1": 0.8546875,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8546875,
        "precision": 0.840087890625,
        "recall": 0.88671875
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.8795247395833333,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8795247395833333,
        "precision": 0.8678385416666667,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9132324218750001,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9132324218750001,
        "precision": 0.9048432849702381,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.8727864583333333,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8727864583333333,
        "precision": 0.8602701822916666,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.76171875,
        "f1": 0.7144205729166666,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7144205729166666,
        "precision": 0.6943305121527777,
        "recall": 0.76171875
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8958519345238096,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8958519345238096,
        "precision": 0.885693359375,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8669456845238095,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8669456845238095,
        "precision": 0.85498046875,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9216959635416667,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9216959635416667,
        "precision": 0.9141206287202381,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0050564236111111105,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0050564236111111105,
        "precision": 0.0036085536456430395,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8944521949404762,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8944521949404762,
        "precision": 0.884765625,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.859375,
        "f1": 0.8262881324404762,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8262881324404762,
        "precision": 0.8116699218750001,
        "recall": 0.859375
      },
      {
        "accuracy": 0.833984375,
        "f1": 0.7958984375,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7958984375,
        "precision": 0.779638671875,
        "recall": 0.833984375
      },
      {
        "accuracy": 0.8466796875,
        "f1": 0.8125511532738096,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.8125511532738096,
        "precision": 0.7983072916666667,
        "recall": 0.8466796875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.008365497891865078,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.008365497891865078,
        "precision": 0.0066237929444875766,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.83984375,
        "f1": 0.8068684895833333,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8068684895833333,
        "precision": 0.7915852864583334,
        "recall": 0.83984375
      },
      {
        "accuracy": 0.87890625,
        "f1": 0.8486653645833333,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8486653645833333,
        "precision": 0.835400390625,
        "recall": 0.87890625
      },
      {
        "accuracy": 0.90625,
        "f1": 0.8822916666666667,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8822916666666667,
        "precision": 0.8716471354166667,
        "recall": 0.90625
      },
      {
        "accuracy": 0.90234375,
        "f1": 0.8764369419642857,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8764369419642857,
        "precision": 0.8652180989583333,
        "recall": 0.90234375
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9767252604166667,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.9767252604166667,
        "precision": 0.9739583333333334,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.98974609375,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.98974609375,
        "precision": 0.9886067708333333,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.47265625,
        "f1": 0.4102089533730159,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.4102089533730159,
        "precision": 0.38669394841269844,
        "recall": 0.47265625
      },
      {
        "accuracy": 0.9267578125,
        "f1": 0.9067057291666667,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.9067057291666667,
        "precision": 0.8972981770833334,
        "recall": 0.9267578125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.8896484375,
        "f1": 0.8612955729166667,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.8612955729166667,
        "precision": 0.8486328125,
        "recall": 0.8896484375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9817708333333333,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.9817708333333333,
        "precision": 0.9794921875,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.8486328125,
        "f1": 0.81044921875,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.81044921875,
        "precision": 0.7923990885416666,
        "recall": 0.8486328125
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.98486328125,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.98486328125,
        "precision": 0.9832356770833333,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98876953125,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.98876953125,
        "precision": 0.9876302083333334,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0035498342005380627,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.0035498342005380627,
        "precision": 0.002984588175305087,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9910481770833333,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.9910481770833333,
        "precision": 0.9900716145833333,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9651692708333333,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.9651692708333333,
        "precision": 0.9611002604166666,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.9619140625,
        "f1": 0.9498697916666666,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.9498697916666666,
        "precision": 0.9440104166666666,
        "recall": 0.9619140625
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.9256184895833334,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.9256184895833334,
        "precision": 0.9181315104166667,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004453266530797102,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.004453266530797102,
        "precision": 0.0031707983856421353,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.8623046875,
        "f1": 0.8278971354166667,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.8278971354166667,
        "precision": 0.8123697916666667,
        "recall": 0.8623046875
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9781901041666666,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.9781901041666666,
        "precision": 0.9755859375,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.98193359375,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.98193359375,
        "precision": 0.9798177083333334,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.5302734375,
        "f1": 0.47255524694489537,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.47255524694489537,
        "precision": 0.4506157769097222,
        "recall": 0.5302734375
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9568684895833333,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9568684895833333,
        "precision": 0.9521484375,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9037109375000001,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9037109375000001,
        "precision": 0.8934733072916666,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.8740234375,
        "f1": 0.8418619791666666,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.8418619791666666,
        "precision": 0.8272623697916666,
        "recall": 0.8740234375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9899088541666666,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9899088541666666,
        "precision": 0.98876953125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003524047194938928,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003524047194938928,
        "precision": 0.0023978224653399757,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9739583333333334,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9739583333333334,
        "precision": 0.970703125,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9676106770833333,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9676106770833333,
        "precision": 0.9637044270833333,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.9619140625,
        "f1": 0.9501953125,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.9501953125,
        "precision": 0.9444986979166667,
        "recall": 0.9619140625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004553416418650794,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004553416418650794,
        "precision": 0.003886531826272175,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.90234375,
        "f1": 0.8765299479166666,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8765299479166666,
        "precision": 0.8643717447916667,
        "recall": 0.90234375
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9864908854166667,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9864908854166667,
        "precision": 0.9851888020833334,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9759114583333334,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.9759114583333334,
        "precision": 0.97314453125,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.4423828125,
        "f1": 0.3810167805284993,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.3810167805284993,
        "precision": 0.3571230933779762,
        "recall": 0.4423828125
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9078776041666666,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.9078776041666666,
        "precision": 0.8981119791666667,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.88671875,
        "f1": 0.85498046875,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.85498046875,
        "precision": 0.8400065104166666,
        "recall": 0.88671875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8055338541666667,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.8055338541666667,
        "precision": 0.7870279947916666,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9791666666666667,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.9791666666666667,
        "precision": 0.9765625,
        "recall": 0.984375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333333,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.9886067708333333,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006786861652440697,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.006786861652440697,
        "precision": 0.006093343098958333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9781901041666666,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.9781901041666666,
        "precision": 0.9755859375,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9794921875,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.9794921875,
        "precision": 0.9772135416666666,
        "recall": 0.984375
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9388671875,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.9388671875,
        "precision": 0.9320475260416666,
        "recall": 0.953125
      },
      {
        "accuracy": 0.9375,
        "f1": 0.9186197916666666,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.9186197916666666,
        "precision": 0.9095052083333333,
        "recall": 0.9375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006938895046875339,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.006938895046875339,
        "precision": 0.005273626403155632,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.8583984375,
        "f1": 0.8255859375,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.8255859375,
        "precision": 0.8108235677083333,
        "recall": 0.8583984375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9807942708333333,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.9807942708333333,
        "precision": 0.978515625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666667,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.9869791666666667,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8091548859126984,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.8091548859126984,
        "precision": 0.7930419921875,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.85546875,
        "f1": 0.8230329241071428,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.8230329241071428,
        "precision": 0.8092610677083334,
        "recall": 0.85546875
      },
      {
        "accuracy": 0.4609375,
        "f1": 0.4102096796432734,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.4102096796432734,
        "precision": 0.39159194483901516,
        "recall": 0.4609375
      },
      {
        "accuracy": 0.806640625,
        "f1": 0.7707682291666667,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.7707682291666667,
        "precision": 0.755078125,
        "recall": 0.806640625
      },
      {
        "accuracy": 0.8291015625,
        "f1": 0.7905436197916667,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.7905436197916667,
        "precision": 0.7737994481646826,
        "recall": 0.8291015625
      },
      {
        "accuracy": 0.7578125,
        "f1": 0.7106631324404762,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.7106631324404762,
        "precision": 0.6910016741071429,
        "recall": 0.7578125
      },
      {
        "accuracy": 0.8623046875,
        "f1": 0.8294596354166667,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.8294596354166667,
        "precision": 0.8140462239583334,
        "recall": 0.8623046875
      },
      {
        "accuracy": 0.8671875,
        "f1": 0.8349934895833333,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.8349934895833333,
        "precision": 0.8204264322916667,
        "recall": 0.8671875
      },
      {
        "accuracy": 0.849609375,
        "f1": 0.8140485491071429,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.8140485491071429,
        "precision": 0.7982747395833334,
        "recall": 0.849609375
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8470703125000001,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.8470703125000001,
        "precision": 0.8327962239583333,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.8515625,
        "f1": 0.8158714657738095,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.8158714657738095,
        "precision": 0.8007649739583333,
        "recall": 0.8515625
      },
      {
        "accuracy": 0.876953125,
        "f1": 0.8480468750000001,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.8480468750000001,
        "precision": 0.8349446614583333,
        "recall": 0.876953125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.008228701636904761,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.008228701636904761,
        "precision": 0.007130022497910454,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.8505859375,
        "f1": 0.8148437500000001,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.8148437500000001,
        "precision": 0.798291015625,
        "recall": 0.8505859375
      },
      {
        "accuracy": 0.82421875,
        "f1": 0.785693359375,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.785693359375,
        "precision": 0.7684012276785714,
        "recall": 0.82421875
      },
      {
        "accuracy": 0.8193359375,
        "f1": 0.780229259672619,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.780229259672619,
        "precision": 0.7631928943452382,
        "recall": 0.8193359375
      },
      {
        "accuracy": 0.79296875,
        "f1": 0.7523297991071429,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.7523297991071429,
        "precision": 0.7348958333333333,
        "recall": 0.79296875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007843270699732306,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.007843270699732306,
        "precision": 0.006386294297991901,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.75,
        "f1": 0.7064639136904762,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.7064639136904762,
        "precision": 0.687939453125,
        "recall": 0.75
      },
      {
        "accuracy": 0.837890625,
        "f1": 0.8024274553571429,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.8024274553571429,
        "precision": 0.78681640625,
        "recall": 0.837890625
      },
      {
        "accuracy": 0.84765625,
        "f1": 0.8147786458333333,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.8147786458333333,
        "precision": 0.8010114397321428,
        "recall": 0.84765625
      },
      {
        "accuracy": 0.921875,
        "f1": 0.8999348958333333,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.8999348958333333,
        "precision": 0.8902180989583333,
        "recall": 0.921875
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.9661458333333334,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9661458333333334,
        "precision": 0.9619140625,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.517578125,
        "f1": 0.4646430826118326,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.4646430826118326,
        "precision": 0.4444599806660353,
        "recall": 0.517578125
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9466145833333333,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9466145833333333,
        "precision": 0.9404296875,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.8820312499999999,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8820312499999999,
        "precision": 0.870556640625,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9817708333333334,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9817708333333334,
        "precision": 0.9794921875,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9910481770833333,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9910481770833333,
        "precision": 0.9900716145833334,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9778645833333333,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9778645833333333,
        "precision": 0.97509765625,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.8681640625,
        "f1": 0.837109375,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.837109375,
        "precision": 0.8226725260416667,
        "recall": 0.8681640625
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9645182291666666,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9645182291666666,
        "precision": 0.96044921875,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004976399739583333,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004976399739583333,
        "precision": 0.00420514412922427,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333333,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9886067708333333,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9462890625,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9462890625,
        "precision": 0.9402669270833334,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.93310546875,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.93310546875,
        "precision": 0.92529296875,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.947265625,
        "f1": 0.9314778645833333,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.9314778645833333,
        "precision": 0.923828125,
        "recall": 0.947265625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005107576884920634,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.005107576884920634,
        "precision": 0.004258897569444444,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.8876953125,
        "f1": 0.8609049479166666,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8609049479166666,
        "precision": 0.848876953125,
        "recall": 0.8876953125
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9755859375,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9755859375,
        "precision": 0.97265625,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9767252604166666,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9767252604166666,
        "precision": 0.9739583333333333,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9860026041666666,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9860026041666666,
        "precision": 0.984375,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9703776041666666,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.9703776041666666,
        "precision": 0.966796875,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.49609375,
        "f1": 0.43898978625541124,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.43898978625541124,
        "precision": 0.41769205729166664,
        "recall": 0.49609375
      },
      {
        "accuracy": 0.9169921875,
        "f1": 0.89453125,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.89453125,
        "precision": 0.8837890625,
        "recall": 0.9169921875
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9806315104166666,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9806315104166666,
        "precision": 0.9783528645833333,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.890625,
        "f1": 0.8606770833333333,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.8606770833333333,
        "precision": 0.8463541666666667,
        "recall": 0.890625
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9820963541666666,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.9820963541666666,
        "precision": 0.97998046875,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.84765625,
        "f1": 0.8100260416666667,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.8100260416666667,
        "precision": 0.79248046875,
        "recall": 0.84765625
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.9661458333333334,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.9661458333333334,
        "precision": 0.9619140625,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004984352156432748,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.004984352156432748,
        "precision": 0.004276336185515874,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9627278645833334,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.9627278645833334,
        "precision": 0.9583333333333333,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.9326822916666666,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.9326822916666666,
        "precision": 0.9252115885416667,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.9293619791666666,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.9293619791666666,
        "precision": 0.9215494791666666,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004763038980836237,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.004763038980836237,
        "precision": 0.0041197165464743595,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.845703125,
        "f1": 0.8092308407738096,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.8092308407738096,
        "precision": 0.7925618489583334,
        "recall": 0.845703125
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9825846354166667,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.9825846354166667,
        "precision": 0.9807942708333333,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9794921875,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.9794921875,
        "precision": 0.97705078125,
        "recall": 0.984375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9729817708333333,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9729817708333333,
        "precision": 0.9697265625,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.5224609375,
        "f1": 0.46463300696699134,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.46463300696699134,
        "precision": 0.4420038132440476,
        "recall": 0.5224609375
      },
      {
        "accuracy": 0.9521484375,
        "f1": 0.9384765625,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9384765625,
        "precision": 0.9318033854166667,
        "recall": 0.9521484375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.927734375,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.927734375,
        "precision": 0.9202473958333333,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.8642578125,
        "f1": 0.8294921875000001,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.8294921875000001,
        "precision": 0.8133951822916667,
        "recall": 0.8642578125
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9816080729166667,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9845377604166666,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9845377604166666,
        "precision": 0.9827473958333333,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0036980256529489264,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0036980256529489264,
        "precision": 0.003376773102114899,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9925130208333333,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9925130208333333,
        "precision": 0.99169921875,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9694010416666666,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9694010416666666,
        "precision": 0.9658203125,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9534505208333333,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9534505208333333,
        "precision": 0.9479166666666667,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.94970703125,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.94970703125,
        "precision": 0.9443359375,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0038835856706950457,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0038835856706950457,
        "precision": 0.002845657611927512,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.8916015625,
        "f1": 0.8653971354166667,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8653971354166667,
        "precision": 0.853759765625,
        "recall": 0.8916015625
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9874674479166666,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9874674479166666,
        "precision": 0.9861653645833334,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9820963541666667,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9820963541666667,
        "precision": 0.97998046875,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.0032297102922583484,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0032297102922583484,
        "precision": 0.0020299524029183426,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002696121411181011,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.002696121411181011,
        "precision": 0.0020550719467978392,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006335118332188644,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.006335118332188644,
        "precision": 0.004744441538704456,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0016441041108642507,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0016441041108642507,
        "precision": 0.0009299393628682193,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012438323683385782,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0012438323683385782,
        "precision": 0.0011243075326051635,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003071046798278011,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.003071046798278011,
        "precision": 0.0019702925469327224,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0028445782266437987,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0028445782266437987,
        "precision": 0.0024936972006885513,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003589871944058825,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.003589871944058825,
        "precision": 0.0026861040155202152,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.003835471403115601,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.003835471403115601,
        "precision": 0.002598594203922511,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005839302896882278,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.005839302896882278,
        "precision": 0.00434140839996365,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0040083223710894525,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0040083223710894525,
        "precision": 0.002911451198158459,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002046455687657502,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.002046455687657502,
        "precision": 0.0012692971445442494,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.004343857019069549,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.004343857019069549,
        "precision": 0.003011708267916588,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.004729892864658489,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.004729892864658489,
        "precision": 0.003022770571063049,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004583916770133997,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.004583916770133997,
        "precision": 0.003599408004541076,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005001136233840948,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.005001136233840948,
        "precision": 0.004032289614943845,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0029066413740126977,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0029066413740126977,
        "precision": 0.002489178914003737,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.07193145938263126,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.07193145938263126,
        "precision": 0.0639445555343793,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.004606064649797665,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.004606064649797665,
        "precision": 0.003253385205289502,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003196863320182724,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.003196863320182724,
        "precision": 0.002484345677145349,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0015089365262987379,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0015089365262987379,
        "precision": 0.0009669001402242177,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00248467610502185,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.00248467610502185,
        "precision": 0.0019142660342108873,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9703776041666666,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9703776041666666,
        "precision": 0.966796875,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9845377604166666,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9845377604166666,
        "precision": 0.9827473958333333,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.529296875,
        "f1": 0.47359962628517316,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.47359962628517316,
        "precision": 0.4525863405257936,
        "recall": 0.529296875
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.9256184895833333,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9256184895833333,
        "precision": 0.9171549479166666,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666667,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9869791666666667,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.8813151041666666,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8813151041666666,
        "precision": 0.8694661458333333,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9873046875,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9873046875,
        "precision": 0.98583984375,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.86328125,
        "f1": 0.8296875,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.8296875,
        "precision": 0.8142903645833333,
        "recall": 0.86328125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9873046875,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9873046875,
        "precision": 0.98583984375,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006145367474641372,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006145367474641372,
        "precision": 0.005034985185480442,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9654947916666666,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9654947916666666,
        "precision": 0.96142578125,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.9560546875,
        "f1": 0.9435221354166666,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9435221354166666,
        "precision": 0.9375,
        "recall": 0.9560546875
      },
      {
        "accuracy": 0.9521484375,
        "f1": 0.9388020833333334,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9388020833333334,
        "precision": 0.9324544270833334,
        "recall": 0.9521484375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0066569010416666664,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0066569010416666664,
        "precision": 0.005673363095238095,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.8876953125,
        "f1": 0.8618815104166666,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8618815104166666,
        "precision": 0.8504231770833333,
        "recall": 0.8876953125
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9814453125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.96240234375,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.96240234375,
        "precision": 0.95849609375,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9783528645833333,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9783528645833333,
        "precision": 0.9759114583333333,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.443359375,
        "f1": 0.3833510402358058,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.3833510402358058,
        "precision": 0.3609297847334957,
        "recall": 0.443359375
      },
      {
        "accuracy": 0.8828125,
        "f1": 0.8527669270833333,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.8527669270833333,
        "precision": 0.8384602864583334,
        "recall": 0.8828125
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9563802083333333,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9563802083333333,
        "precision": 0.9513346354166667,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.85546875,
        "f1": 0.8173363095238095,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.8173363095238095,
        "precision": 0.800048828125,
        "recall": 0.85546875
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9716796875,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.9716796875,
        "precision": 0.96826171875,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9778645833333334,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.9778645833333334,
        "precision": 0.97509765625,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9791666666666667,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.9791666666666667,
        "precision": 0.9765625,
        "recall": 0.984375
      },
      {
        "accuracy": 0.822265625,
        "f1": 0.78447265625,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.78447265625,
        "precision": 0.7669270833333334,
        "recall": 0.822265625
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9554036458333333,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.9554036458333333,
        "precision": 0.9501953125,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.96337890625,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.96337890625,
        "precision": 0.9593098958333334,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9742838541666666,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9742838541666666,
        "precision": 0.97119140625,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007722995448179271,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.007722995448179271,
        "precision": 0.006743566453387881,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9752604166666667,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.9752604166666667,
        "precision": 0.97216796875,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.9326171875,
        "f1": 0.9134114583333333,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.9134114583333333,
        "precision": 0.904296875,
        "recall": 0.9326171875
      },
      {
        "accuracy": 0.9228515625,
        "f1": 0.90322265625,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.90322265625,
        "precision": 0.8939615885416666,
        "recall": 0.9228515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006458758701980209,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.006458758701980209,
        "precision": 0.004872076726703613,
        "recall": 0.015625
      },
      {
        "accuracy": 0.81640625,
        "f1": 0.775,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.775,
        "precision": 0.7562174479166666,
        "recall": 0.81640625
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.9619140625,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.9619140625,
        "precision": 0.9576822916666666,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.966796875,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.966796875,
        "precision": 0.9630533854166666,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9755859375,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.9755859375,
        "precision": 0.97265625,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.9345703125,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.9345703125,
        "precision": 0.927734375,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9680989583333333,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.9680989583333333,
        "precision": 0.9645182291666666,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.4921875,
        "f1": 0.4367978755185786,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.4367978755185786,
        "precision": 0.4161497085813492,
        "recall": 0.4921875
      },
      {
        "accuracy": 0.8974609375,
        "f1": 0.8696940104166666,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.8696940104166666,
        "precision": 0.8565266927083334,
        "recall": 0.8974609375
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9547526041666667,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9547526041666667,
        "precision": 0.9498697916666667,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.7971354166666667,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.7971354166666667,
        "precision": 0.7779947916666666,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.9638671875,
        "f1": 0.9529622395833333,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.9529622395833333,
        "precision": 0.94775390625,
        "recall": 0.9638671875
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9710286458333334,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.9710286458333334,
        "precision": 0.9677734375,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9485677083333333,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.9485677083333333,
        "precision": 0.9425455729166666,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.822265625,
        "f1": 0.7800130208333333,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.7800130208333333,
        "precision": 0.7606608072916667,
        "recall": 0.822265625
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.9616536458333333,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.9616536458333333,
        "precision": 0.957275390625,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9552408854166666,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.9552408854166666,
        "precision": 0.9500325520833333,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.9616536458333333,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.9616536458333333,
        "precision": 0.9574381510416666,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005308008317183463,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.005308008317183463,
        "precision": 0.004542422951911028,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.9638671875,
        "f1": 0.9523111979166666,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9523111979166666,
        "precision": 0.9466145833333333,
        "recall": 0.9638671875
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.9172200520833332,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.9172200520833332,
        "precision": 0.9092610677083333,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.8806966145833334,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.8806966145833334,
        "precision": 0.8689778645833333,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005116947939213564,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.005116947939213564,
        "precision": 0.004596263182582816,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.83203125,
        "f1": 0.794921875,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.794921875,
        "precision": 0.77783203125,
        "recall": 0.83203125
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9518229166666666,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.9518229166666666,
        "precision": 0.9464518229166667,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9501953125,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.9501953125,
        "precision": 0.9451822916666666,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9715169270833333,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.9715169270833333,
        "precision": 0.9680989583333333,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.9143880208333333,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9143880208333333,
        "precision": 0.9051106770833333,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.9346354166666666,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9346354166666666,
        "precision": 0.9276529947916667,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.5107421875,
        "f1": 0.4494326636904762,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.4494326636904762,
        "precision": 0.425879329004329,
        "recall": 0.5107421875
      },
      {
        "accuracy": 0.87109375,
        "f1": 0.8396019345238095,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8396019345238095,
        "precision": 0.8248697916666666,
        "recall": 0.87109375
      },
      {
        "accuracy": 0.9365234375,
        "f1": 0.9173177083333333,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9173177083333333,
        "precision": 0.908203125,
        "recall": 0.9365234375
      },
      {
        "accuracy": 0.8330078125,
        "f1": 0.7914713541666666,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7914713541666666,
        "precision": 0.77236328125,
        "recall": 0.8330078125
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.9246419270833333,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9246419270833333,
        "precision": 0.91650390625,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9554036458333334,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9554036458333334,
        "precision": 0.9503580729166667,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.9253580729166666,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9253580729166666,
        "precision": 0.9170735677083333,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.8037109375,
        "f1": 0.7587425595238095,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7587425595238095,
        "precision": 0.738525390625,
        "recall": 0.8037109375
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9381510416666666,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9381510416666666,
        "precision": 0.9308268229166667,
        "recall": 0.953125
      },
      {
        "accuracy": 0.9443359375,
        "f1": 0.92822265625,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.92822265625,
        "precision": 0.9205729166666667,
        "recall": 0.9443359375
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9523763020833333,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9523763020833333,
        "precision": 0.947705078125,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.00432329714556277,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00432329714556277,
        "precision": 0.002930110254329004,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.9560546875,
        "f1": 0.9430013020833333,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9430013020833333,
        "precision": 0.9368489583333334,
        "recall": 0.9560546875
      },
      {
        "accuracy": 0.9150390625,
        "f1": 0.8929036458333333,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8929036458333333,
        "precision": 0.88232421875,
        "recall": 0.9150390625
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8646158854166667,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8646158854166667,
        "precision": 0.8516438802083333,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004988031355218855,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004988031355218855,
        "precision": 0.003959940464491615,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.8017578125,
        "f1": 0.7584821428571429,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.7584821428571429,
        "precision": 0.7395833333333334,
        "recall": 0.8017578125
      },
      {
        "accuracy": 0.9296875,
        "f1": 0.90908203125,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.90908203125,
        "precision": 0.8993326822916667,
        "recall": 0.9296875
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.927734375,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.927734375,
        "precision": 0.9200846354166666,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9443359375,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9443359375,
        "precision": 0.9376627604166667,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0030644770834813394,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0030644770834813394,
        "precision": 0.002684912076127386,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006290187071416546,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.006290187071416546,
        "precision": 0.005760508912929157,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.00670943410695016,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.00670943410695016,
        "precision": 0.0052097652701541715,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005221264776941878,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.005221264776941878,
        "precision": 0.004399553529982069,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002606060299399435,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.002606060299399435,
        "precision": 0.002339070668628705,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007564636324142443,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.007564636324142443,
        "precision": 0.006443507337225955,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0037178392991812107,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0037178392991812107,
        "precision": 0.003387284728596323,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0031856362336601307,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0031856362336601307,
        "precision": 0.00266326419890873,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004437565413030893,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.004437565413030893,
        "precision": 0.003905730086203102,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.004451943739878098,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.004451943739878098,
        "precision": 0.003534481084871876,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004707396296120367,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.004707396296120367,
        "precision": 0.003771106775652725,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.002525860080155593,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.002525860080155593,
        "precision": 0.00189053955528861,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004317717976952193,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.004317717976952193,
        "precision": 0.004127848631393242,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.054079086061507936,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.054079086061507936,
        "precision": 0.04494653381500627,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005923877335010147,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.005923877335010147,
        "precision": 0.005210148626987578,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004120020171680265,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.004120020171680265,
        "precision": 0.0037124482850960433,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0016107744103321742,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.0016107744103321742,
        "precision": 0.0013184062369231107,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008586046497551946,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.008586046497551946,
        "precision": 0.007697464086872432,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.006731444559444433,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.006731444559444433,
        "precision": 0.005758712774682808,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0029057334815627027,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0029057334815627027,
        "precision": 0.0022333400967543765,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.00490412622797938,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.00490412622797938,
        "precision": 0.004475208753134412,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0030278224571078432,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0030278224571078432,
        "precision": 0.0026870894785622178,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.8369140625,
        "f1": 0.80068359375,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.80068359375,
        "precision": 0.7851182725694444,
        "recall": 0.8369140625
      },
      {
        "accuracy": 0.8642578125,
        "f1": 0.8312499999999999,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8312499999999999,
        "precision": 0.8163248697916667,
        "recall": 0.8642578125
      },
      {
        "accuracy": 0.55078125,
        "f1": 0.4993102058531746,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.4993102058531746,
        "precision": 0.47884385850694444,
        "recall": 0.55078125
      },
      {
        "accuracy": 0.8642578125,
        "f1": 0.8347330729166667,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8347330729166667,
        "precision": 0.8212890625,
        "recall": 0.8642578125
      },
      {
        "accuracy": 0.8427734375,
        "f1": 0.8019911024305556,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8019911024305556,
        "precision": 0.7839855375744048,
        "recall": 0.8427734375
      },
      {
        "accuracy": 0.83984375,
        "f1": 0.8048688616071429,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8048688616071429,
        "precision": 0.7901692708333333,
        "recall": 0.83984375
      },
      {
        "accuracy": 0.849609375,
        "f1": 0.8150716145833332,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8150716145833332,
        "precision": 0.7995117187499999,
        "recall": 0.849609375
      },
      {
        "accuracy": 0.90234375,
        "f1": 0.8761067708333333,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8761067708333333,
        "precision": 0.8642903645833333,
        "recall": 0.90234375
      },
      {
        "accuracy": 0.853515625,
        "f1": 0.816796875,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.816796875,
        "precision": 0.7999186197916666,
        "recall": 0.853515625
      },
      {
        "accuracy": 0.7578125,
        "f1": 0.7135463169642857,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.7135463169642857,
        "precision": 0.6952962239583333,
        "recall": 0.7578125
      },
      {
        "accuracy": 0.8876953125,
        "f1": 0.8586263020833333,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8586263020833333,
        "precision": 0.8453287760416667,
        "recall": 0.8876953125
      },
      {
        "accuracy": 0.849609375,
        "f1": 0.8145693824404762,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8145693824404762,
        "precision": 0.7994303385416667,
        "recall": 0.849609375
      },
      {
        "accuracy": 0.8798828125,
        "f1": 0.8534505208333333,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8534505208333333,
        "precision": 0.8416666666666667,
        "recall": 0.8798828125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006663532893230673,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006663532893230673,
        "precision": 0.005751195961156899,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.8857421875,
        "f1": 0.8571289062499999,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8571289062499999,
        "precision": 0.8441569010416666,
        "recall": 0.8857421875
      },
      {
        "accuracy": 0.814453125,
        "f1": 0.7757486979166667,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.7757486979166667,
        "precision": 0.7581217447916667,
        "recall": 0.814453125
      },
      {
        "accuracy": 0.828125,
        "f1": 0.7874860491071429,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.7874860491071429,
        "precision": 0.7698079427083333,
        "recall": 0.828125
      },
      {
        "accuracy": 0.8037109375,
        "f1": 0.7629216974431818,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.7629216974431818,
        "precision": 0.7459891183035714,
        "recall": 0.8037109375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.009276048151727499,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009276048151727499,
        "precision": 0.008026681976877288,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.8291015625,
        "f1": 0.7895670572916667,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.7895670572916667,
        "precision": 0.7728771391369047,
        "recall": 0.8291015625
      },
      {
        "accuracy": 0.8603515625,
        "f1": 0.8257998511904762,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8257998511904762,
        "precision": 0.810302734375,
        "recall": 0.8603515625
      },
      {
        "accuracy": 0.8701171875,
        "f1": 0.8390625,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8390625,
        "precision": 0.8256673177083333,
        "recall": 0.8701171875
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.96533203125,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.96533203125,
        "precision": 0.96142578125,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9835611979166666,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.9835611979166666,
        "precision": 0.9817708333333333,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.47265625,
        "f1": 0.41558748055330086,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.41558748055330086,
        "precision": 0.3938050285218254,
        "recall": 0.47265625
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9021809895833333,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.9021809895833333,
        "precision": 0.8917643229166666,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9871419270833334,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9871419270833334,
        "precision": 0.9856770833333333,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8461588541666667,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.8461588541666667,
        "precision": 0.8314127604166667,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9778645833333333,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.9778645833333333,
        "precision": 0.97509765625,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9873046875,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.9873046875,
        "precision": 0.98583984375,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333334,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.9895833333333334,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8049153645833333,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.8049153645833333,
        "precision": 0.786962890625,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9720052083333333,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.9720052083333333,
        "precision": 0.9689127604166666,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9807942708333334,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.9807942708333334,
        "precision": 0.978515625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0025584092442645073,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0025584092442645073,
        "precision": 0.002296901393581081,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9781901041666667,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.9781901041666667,
        "precision": 0.9755859375,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9625651041666667,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.9625651041666667,
        "precision": 0.9581705729166666,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.9265625,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.9265625,
        "precision": 0.91845703125,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.9153645833333334,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.9153645833333334,
        "precision": 0.9064127604166666,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0028290148407335907,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0028290148407335907,
        "precision": 0.0018728829763986013,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.8000651041666667,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.8000651041666667,
        "precision": 0.7828125,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.98583984375,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.98583984375,
        "precision": 0.9842122395833333,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9861653645833334,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.9861653645833334,
        "precision": 0.9847005208333333,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9728190104166667,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.9728190104166667,
        "precision": 0.9695638020833333,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666667,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.9869791666666667,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.5078125,
        "f1": 0.4516105530753969,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.4516105530753969,
        "precision": 0.4304242198773449,
        "recall": 0.5078125
      },
      {
        "accuracy": 0.9375,
        "f1": 0.9187825520833334,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.9187825520833334,
        "precision": 0.90966796875,
        "recall": 0.9375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9914388020833333,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9914388020833333,
        "precision": 0.9908040364583333,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.8974609375,
        "f1": 0.8696940104166666,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.8696940104166666,
        "precision": 0.8568522135416667,
        "recall": 0.8974609375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666667,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.9869791666666667,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333333,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.9886067708333333,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.8564453125,
        "f1": 0.8208658854166666,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.8208658854166666,
        "precision": 0.804443359375,
        "recall": 0.8564453125
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9796549479166666,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.9796549479166666,
        "precision": 0.9773763020833333,
        "recall": 0.984375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9807942708333334,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.9807942708333334,
        "precision": 0.978515625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98876953125,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.98876953125,
        "precision": 0.9876302083333334,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0036877274584076053,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.0036877274584076053,
        "precision": 0.0028251203910383597,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333334,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.9856770833333334,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9641927083333334,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.9641927083333334,
        "precision": 0.9599609375,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9456380208333333,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.9456380208333333,
        "precision": 0.9391276041666667,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.9288736979166667,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.9288736979166667,
        "precision": 0.9210611979166667,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004602244543650793,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.004602244543650793,
        "precision": 0.003567201028138528,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.8583984375,
        "f1": 0.8263346354166667,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.8263346354166667,
        "precision": 0.81171875,
        "recall": 0.8583984375
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9814453125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.486328125,
        "f1": 0.42727716619318185,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.42727716619318185,
        "precision": 0.40445498511904765,
        "recall": 0.486328125
      },
      {
        "accuracy": 0.9443359375,
        "f1": 0.9278971354166667,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.9278971354166667,
        "precision": 0.919921875,
        "recall": 0.9443359375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9013671875,
        "f1": 0.8733723958333334,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.8733723958333334,
        "precision": 0.8601888020833334,
        "recall": 0.9013671875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333334,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.9856770833333334,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9248046875,
        "f1": 0.9039713541666666,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.9039713541666666,
        "precision": 0.89404296875,
        "recall": 0.9248046875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333333,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.9886067708333333,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003365286419054801,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.003365286419054801,
        "precision": 0.0028737737899436093,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9755859375,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.9755859375,
        "precision": 0.97265625,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9676106770833334,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.9676106770833334,
        "precision": 0.9637044270833333,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9435221354166666,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.9435221354166666,
        "precision": 0.9368489583333334,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003868879601301476,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.003868879601301476,
        "precision": 0.0028657459077380955,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.876953125,
        "f1": 0.8468424479166666,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.8468424479166666,
        "precision": 0.8334147135416667,
        "recall": 0.876953125
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.986328125,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.986328125,
        "precision": 0.98486328125,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333334,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.9886067708333334,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}