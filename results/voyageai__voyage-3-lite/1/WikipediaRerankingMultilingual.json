{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "map": 0.874783,
        "mrr": 0.874783,
        "nAUC_map_max": 0.591434,
        "nAUC_map_std": 0.281632,
        "nAUC_map_diff1": 0.778668,
        "nAUC_mrr_max": 0.591434,
        "nAUC_mrr_std": 0.281632,
        "nAUC_mrr_diff1": 0.778668,
        "main_score": 0.874783,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.843193,
        "mrr": 0.843193,
        "nAUC_map_max": 0.49921,
        "nAUC_map_std": 0.254965,
        "nAUC_map_diff1": 0.734291,
        "nAUC_mrr_max": 0.49921,
        "nAUC_mrr_std": 0.254965,
        "nAUC_mrr_diff1": 0.734291,
        "main_score": 0.843193,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.876586,
        "mrr": 0.876586,
        "nAUC_map_max": 0.530691,
        "nAUC_map_std": 0.318819,
        "nAUC_map_diff1": 0.806582,
        "nAUC_mrr_max": 0.530691,
        "nAUC_mrr_std": 0.318819,
        "nAUC_mrr_diff1": 0.806582,
        "main_score": 0.876586,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.89085,
        "mrr": 0.891294,
        "nAUC_map_max": 0.567109,
        "nAUC_map_std": 0.420288,
        "nAUC_map_diff1": 0.809769,
        "nAUC_mrr_max": 0.567764,
        "nAUC_mrr_std": 0.418823,
        "nAUC_mrr_diff1": 0.808618,
        "main_score": 0.89085,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.882315,
        "mrr": 0.882315,
        "nAUC_map_max": 0.598558,
        "nAUC_map_std": 0.230906,
        "nAUC_map_diff1": 0.786197,
        "nAUC_mrr_max": 0.598558,
        "nAUC_mrr_std": 0.230906,
        "nAUC_mrr_diff1": 0.786197,
        "main_score": 0.882315,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.904719,
        "mrr": 0.904719,
        "nAUC_map_max": 0.646748,
        "nAUC_map_std": 0.388387,
        "nAUC_map_diff1": 0.823967,
        "nAUC_mrr_max": 0.646748,
        "nAUC_mrr_std": 0.388387,
        "nAUC_mrr_diff1": 0.823967,
        "main_score": 0.904719,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.877876,
        "mrr": 0.877876,
        "nAUC_map_max": 0.534024,
        "nAUC_map_std": 0.313893,
        "nAUC_map_diff1": 0.769141,
        "nAUC_mrr_max": 0.534024,
        "nAUC_mrr_std": 0.313893,
        "nAUC_mrr_diff1": 0.769141,
        "main_score": 0.877876,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.901019,
        "mrr": 0.901019,
        "nAUC_map_max": 0.523774,
        "nAUC_map_std": 0.240385,
        "nAUC_map_diff1": 0.81941,
        "nAUC_mrr_max": 0.523774,
        "nAUC_mrr_std": 0.240385,
        "nAUC_mrr_diff1": 0.81941,
        "main_score": 0.901019,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.86238,
        "mrr": 0.86339,
        "nAUC_map_max": 0.435806,
        "nAUC_map_std": 0.219575,
        "nAUC_map_diff1": 0.761398,
        "nAUC_mrr_max": 0.437687,
        "nAUC_mrr_std": 0.221651,
        "nAUC_mrr_diff1": 0.757929,
        "main_score": 0.86238,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.879652,
        "mrr": 0.879652,
        "nAUC_map_max": 0.546035,
        "nAUC_map_std": 0.334444,
        "nAUC_map_diff1": 0.760698,
        "nAUC_mrr_max": 0.546035,
        "nAUC_mrr_std": 0.334444,
        "nAUC_mrr_diff1": 0.760698,
        "main_score": 0.879652,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.879285,
        "mrr": 0.879619,
        "nAUC_map_max": 0.477928,
        "nAUC_map_std": 0.260822,
        "nAUC_map_diff1": 0.776329,
        "nAUC_mrr_max": 0.476607,
        "nAUC_mrr_std": 0.264833,
        "nAUC_mrr_diff1": 0.775383,
        "main_score": 0.879285,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.873275,
        "mrr": 0.873275,
        "nAUC_map_max": 0.52596,
        "nAUC_map_std": 0.270292,
        "nAUC_map_diff1": 0.761547,
        "nAUC_mrr_max": 0.52596,
        "nAUC_mrr_std": 0.270292,
        "nAUC_mrr_diff1": 0.761547,
        "main_score": 0.873275,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.883296,
        "mrr": 0.883629,
        "nAUC_map_max": 0.555079,
        "nAUC_map_std": 0.34143,
        "nAUC_map_diff1": 0.809011,
        "nAUC_mrr_max": 0.553523,
        "nAUC_mrr_std": 0.339709,
        "nAUC_mrr_diff1": 0.808119,
        "main_score": 0.883296,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.886065,
        "mrr": 0.886398,
        "nAUC_map_max": 0.49406,
        "nAUC_map_std": 0.257757,
        "nAUC_map_diff1": 0.803762,
        "nAUC_mrr_max": 0.500722,
        "nAUC_mrr_std": 0.263788,
        "nAUC_mrr_diff1": 0.802837,
        "main_score": 0.886065,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.870886,
        "mrr": 0.870886,
        "nAUC_map_max": 0.524576,
        "nAUC_map_std": 0.188217,
        "nAUC_map_diff1": 0.737051,
        "nAUC_mrr_max": 0.524576,
        "nAUC_mrr_std": 0.188217,
        "nAUC_mrr_diff1": 0.737051,
        "main_score": 0.870886,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.899995,
        "mrr": 0.899995,
        "nAUC_map_max": 0.529609,
        "nAUC_map_std": 0.313016,
        "nAUC_map_diff1": 0.794354,
        "nAUC_mrr_max": 0.529609,
        "nAUC_mrr_std": 0.313016,
        "nAUC_mrr_diff1": 0.794354,
        "main_score": 0.899995,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 6647.447349071503,
  "kg_co2_emissions": null
}