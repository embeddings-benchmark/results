{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.922685,
        "recall": 0.946841,
        "f1": 0.930358,
        "accuracy": 0.946841,
        "main_score": 0.930358,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.946506,
        "recall": 0.963892,
        "f1": 0.95219,
        "accuracy": 0.963892,
        "main_score": 0.95219,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.88447,
        "recall": 0.91675,
        "f1": 0.894034,
        "accuracy": 0.91675,
        "main_score": 0.894034,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.932046,
        "recall": 0.952859,
        "f1": 0.938716,
        "accuracy": 0.952859,
        "main_score": 0.938716,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.950351,
        "recall": 0.965898,
        "f1": 0.955366,
        "accuracy": 0.965898,
        "main_score": 0.955366,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.972083,
        "recall": 0.980943,
        "f1": 0.974925,
        "accuracy": 0.980943,
        "main_score": 0.974925,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.885282,
        "recall": 0.915747,
        "f1": 0.894132,
        "accuracy": 0.915747,
        "main_score": 0.894132,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.895771,
        "recall": 0.927783,
        "f1": 0.905784,
        "accuracy": 0.927783,
        "main_score": 0.905784,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.853612,
        "recall": 0.894684,
        "f1": 0.86597,
        "accuracy": 0.894684,
        "main_score": 0.86597,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.915496,
        "recall": 0.941825,
        "f1": 0.924005,
        "accuracy": 0.941825,
        "main_score": 0.924005,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.910398,
        "recall": 0.937813,
        "f1": 0.919057,
        "accuracy": 0.937813,
        "main_score": 0.919057,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.950685,
        "recall": 0.966901,
        "f1": 0.956035,
        "accuracy": 0.966901,
        "main_score": 0.956035,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.866591,
        "recall": 0.903711,
        "f1": 0.877775,
        "accuracy": 0.903711,
        "main_score": 0.877775,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.92235,
        "recall": 0.945838,
        "f1": 0.929856,
        "accuracy": 0.945838,
        "main_score": 0.929856,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.876147,
        "recall": 0.909729,
        "f1": 0.886077,
        "accuracy": 0.909729,
        "main_score": 0.886077,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.871448,
        "recall": 0.911735,
        "f1": 0.88432,
        "accuracy": 0.911735,
        "main_score": 0.88432,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.970578,
        "recall": 0.97994,
        "f1": 0.973587,
        "accuracy": 0.97994,
        "main_score": 0.973587,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.957289,
        "recall": 0.96991,
        "f1": 0.961284,
        "accuracy": 0.96991,
        "main_score": 0.961284,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.775344,
        "recall": 0.829488,
        "f1": 0.790307,
        "accuracy": 0.829488,
        "main_score": 0.790307,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.847793,
        "recall": 0.894684,
        "f1": 0.862655,
        "accuracy": 0.894684,
        "main_score": 0.862655,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.789004,
        "recall": 0.837513,
        "f1": 0.802217,
        "accuracy": 0.837513,
        "main_score": 0.802217,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.866934,
        "recall": 0.90672,
        "f1": 0.879271,
        "accuracy": 0.90672,
        "main_score": 0.879271,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.948847,
        "recall": 0.964895,
        "f1": 0.954029,
        "accuracy": 0.964895,
        "main_score": 0.954029,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.965396,
        "recall": 0.975928,
        "f1": 0.968907,
        "accuracy": 0.975928,
        "main_score": 0.968907,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.784966,
        "recall": 0.83651,
        "f1": 0.79992,
        "accuracy": 0.83651,
        "main_score": 0.79992,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.85774,
        "recall": 0.900702,
        "f1": 0.871214,
        "accuracy": 0.900702,
        "main_score": 0.871214,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.895102,
        "recall": 0.925777,
        "f1": 0.904413,
        "accuracy": 0.925777,
        "main_score": 0.904413,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.902123,
        "recall": 0.932798,
        "f1": 0.911969,
        "accuracy": 0.932798,
        "main_score": 0.911969,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.873774,
        "recall": 0.90672,
        "f1": 0.883403,
        "accuracy": 0.90672,
        "main_score": 0.883403,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.855433,
        "recall": 0.897693,
        "f1": 0.868238,
        "accuracy": 0.897693,
        "main_score": 0.868238,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.662787,
        "recall": 0.729188,
        "f1": 0.680693,
        "accuracy": 0.729188,
        "main_score": 0.680693,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.759529,
        "recall": 0.826479,
        "f1": 0.779959,
        "accuracy": 0.826479,
        "main_score": 0.779959,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.865606,
        "recall": 0.902708,
        "f1": 0.876613,
        "accuracy": 0.902708,
        "main_score": 0.876613,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.936058,
        "recall": 0.954865,
        "f1": 0.94206,
        "accuracy": 0.954865,
        "main_score": 0.94206,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.801144,
        "recall": 0.845537,
        "f1": 0.813157,
        "accuracy": 0.845537,
        "main_score": 0.813157,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.866717,
        "recall": 0.907723,
        "f1": 0.879706,
        "accuracy": 0.907723,
        "main_score": 0.879706,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.03324,
        "recall": 0.052156,
        "f1": 0.036315,
        "accuracy": 0.052156,
        "main_score": 0.036315,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.083818,
        "recall": 0.15346,
        "f1": 0.097094,
        "accuracy": 0.15346,
        "main_score": 0.097094,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.092877,
        "recall": 0.115346,
        "f1": 0.096687,
        "accuracy": 0.115346,
        "main_score": 0.096687,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.156745,
        "recall": 0.245737,
        "f1": 0.176658,
        "accuracy": 0.245737,
        "main_score": 0.176658,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.77884,
        "recall": 0.826479,
        "f1": 0.791426,
        "accuracy": 0.826479,
        "main_score": 0.791426,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.86086,
        "recall": 0.901705,
        "f1": 0.873621,
        "accuracy": 0.901705,
        "main_score": 0.873621,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.583625,
        "recall": 0.642929,
        "f1": 0.597536,
        "accuracy": 0.642929,
        "main_score": 0.597536,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.694032,
        "recall": 0.777332,
        "f1": 0.718877,
        "accuracy": 0.777332,
        "main_score": 0.718877,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.780295,
        "recall": 0.826479,
        "f1": 0.792538,
        "accuracy": 0.826479,
        "main_score": 0.792538,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.842621,
        "recall": 0.888666,
        "f1": 0.856854,
        "accuracy": 0.888666,
        "main_score": 0.856854,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.763403,
        "recall": 0.806419,
        "f1": 0.77502,
        "accuracy": 0.806419,
        "main_score": 0.77502,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.836008,
        "recall": 0.88666,
        "f1": 0.85219,
        "accuracy": 0.88666,
        "main_score": 0.85219,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.857439,
        "recall": 0.894684,
        "f1": 0.868091,
        "accuracy": 0.894684,
        "main_score": 0.868091,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.912404,
        "recall": 0.938816,
        "f1": 0.920595,
        "accuracy": 0.938816,
        "main_score": 0.920595,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.06959,
        "recall": 0.087262,
        "f1": 0.073092,
        "accuracy": 0.087262,
        "main_score": 0.073092,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.144658,
        "recall": 0.23671,
        "f1": 0.163962,
        "accuracy": 0.23671,
        "main_score": 0.163962,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.829332,
        "recall": 0.871615,
        "f1": 0.841168,
        "accuracy": 0.871615,
        "main_score": 0.841168,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.879338,
        "recall": 0.913741,
        "f1": 0.889755,
        "accuracy": 0.913741,
        "main_score": 0.889755,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.839837,
        "recall": 0.880642,
        "f1": 0.851479,
        "accuracy": 0.880642,
        "main_score": 0.851479,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.889502,
        "recall": 0.924774,
        "f1": 0.900869,
        "accuracy": 0.924774,
        "main_score": 0.900869,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.005018,
        "recall": 0.007021,
        "f1": 0.005355,
        "accuracy": 0.007021,
        "main_score": 0.005355,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007229,
        "recall": 0.023069,
        "f1": 0.009493,
        "accuracy": 0.023069,
        "main_score": 0.009493,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.930698,
        "recall": 0.951581,
        "f1": 0.93722,
        "accuracy": 0.951581,
        "main_score": 0.93722,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.941782,
        "recall": 0.960474,
        "f1": 0.947859,
        "accuracy": 0.960474,
        "main_score": 0.947859,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.900939,
        "recall": 0.929842,
        "f1": 0.909783,
        "accuracy": 0.929842,
        "main_score": 0.909783,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.916255,
        "recall": 0.942688,
        "f1": 0.924802,
        "accuracy": 0.942688,
        "main_score": 0.924802,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.958086,
        "recall": 0.971344,
        "f1": 0.962352,
        "accuracy": 0.971344,
        "main_score": 0.962352,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.975791,
        "recall": 0.983202,
        "f1": 0.978096,
        "accuracy": 0.983202,
        "main_score": 0.978096,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.891469,
        "recall": 0.920949,
        "f1": 0.900433,
        "accuracy": 0.920949,
        "main_score": 0.900433,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.923172,
        "recall": 0.94664,
        "f1": 0.930567,
        "accuracy": 0.94664,
        "main_score": 0.930567,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.903848,
        "recall": 0.93083,
        "f1": 0.912154,
        "accuracy": 0.93083,
        "main_score": 0.912154,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.914361,
        "recall": 0.942688,
        "f1": 0.923748,
        "accuracy": 0.942688,
        "main_score": 0.923748,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.924654,
        "recall": 0.947628,
        "f1": 0.931884,
        "accuracy": 0.947628,
        "main_score": 0.931884,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.951416,
        "recall": 0.967391,
        "f1": 0.956686,
        "accuracy": 0.967391,
        "main_score": 0.956686,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.875198,
        "recall": 0.911067,
        "f1": 0.885968,
        "accuracy": 0.911067,
        "main_score": 0.885968,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.920619,
        "recall": 0.945652,
        "f1": 0.928656,
        "accuracy": 0.945652,
        "main_score": 0.928656,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.902586,
        "recall": 0.929842,
        "f1": 0.910935,
        "accuracy": 0.929842,
        "main_score": 0.910935,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.884634,
        "recall": 0.918972,
        "f1": 0.895243,
        "accuracy": 0.918972,
        "main_score": 0.895243,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.977767,
        "recall": 0.985178,
        "f1": 0.980237,
        "accuracy": 0.985178,
        "main_score": 0.980237,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.961792,
        "recall": 0.974308,
        "f1": 0.965909,
        "accuracy": 0.974308,
        "main_score": 0.965909,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.790006,
        "recall": 0.843874,
        "f1": 0.806028,
        "accuracy": 0.843874,
        "main_score": 0.806028,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.859025,
        "recall": 0.901186,
        "f1": 0.872134,
        "accuracy": 0.901186,
        "main_score": 0.872134,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.810527,
        "recall": 0.849802,
        "f1": 0.821544,
        "accuracy": 0.849802,
        "main_score": 0.821544,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.885293,
        "recall": 0.91996,
        "f1": 0.896311,
        "accuracy": 0.91996,
        "main_score": 0.896311,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.94277,
        "recall": 0.959486,
        "f1": 0.948024,
        "accuracy": 0.959486,
        "main_score": 0.948024,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.976779,
        "recall": 0.98419,
        "f1": 0.979249,
        "accuracy": 0.98419,
        "main_score": 0.979249,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.83,
        "recall": 0.875494,
        "f1": 0.843264,
        "accuracy": 0.875494,
        "main_score": 0.843264,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.860293,
        "recall": 0.903162,
        "f1": 0.873748,
        "accuracy": 0.903162,
        "main_score": 0.873748,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.908491,
        "recall": 0.935771,
        "f1": 0.91698,
        "accuracy": 0.935771,
        "main_score": 0.91698,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.914526,
        "recall": 0.9417,
        "f1": 0.923419,
        "accuracy": 0.9417,
        "main_score": 0.923419,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.92085,
        "recall": 0.943676,
        "f1": 0.927701,
        "accuracy": 0.943676,
        "main_score": 0.927701,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.878162,
        "recall": 0.91502,
        "f1": 0.889789,
        "accuracy": 0.91502,
        "main_score": 0.889789,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.690372,
        "recall": 0.758893,
        "f1": 0.709452,
        "accuracy": 0.758893,
        "main_score": 0.709452,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.761446,
        "recall": 0.828063,
        "f1": 0.781936,
        "accuracy": 0.828063,
        "main_score": 0.781936,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.856331,
        "recall": 0.890316,
        "f1": 0.866509,
        "accuracy": 0.890316,
        "main_score": 0.866509,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.930336,
        "recall": 0.951581,
        "f1": 0.937253,
        "accuracy": 0.951581,
        "main_score": 0.937253,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.8514,
        "recall": 0.879447,
        "f1": 0.85914,
        "accuracy": 0.879447,
        "main_score": 0.85914,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.916008,
        "recall": 0.942688,
        "f1": 0.924572,
        "accuracy": 0.942688,
        "main_score": 0.924572,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.037825,
        "recall": 0.05336,
        "f1": 0.040541,
        "accuracy": 0.05336,
        "main_score": 0.040541,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.074639,
        "recall": 0.129447,
        "f1": 0.086032,
        "accuracy": 0.129447,
        "main_score": 0.086032,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.081685,
        "recall": 0.100791,
        "f1": 0.085106,
        "accuracy": 0.100791,
        "main_score": 0.085106,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.152397,
        "recall": 0.250988,
        "f1": 0.174446,
        "accuracy": 0.250988,
        "main_score": 0.174446,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.807219,
        "recall": 0.840909,
        "f1": 0.816488,
        "accuracy": 0.840909,
        "main_score": 0.816488,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.86833,
        "recall": 0.909091,
        "f1": 0.881324,
        "accuracy": 0.909091,
        "main_score": 0.881324,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.572118,
        "recall": 0.629447,
        "f1": 0.586395,
        "accuracy": 0.629447,
        "main_score": 0.586395,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.731966,
        "recall": 0.807312,
        "f1": 0.754908,
        "accuracy": 0.807312,
        "main_score": 0.754908,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.779914,
        "recall": 0.817194,
        "f1": 0.790642,
        "accuracy": 0.817194,
        "main_score": 0.790642,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.880599,
        "recall": 0.916996,
        "f1": 0.89226,
        "accuracy": 0.916996,
        "main_score": 0.89226,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.783107,
        "recall": 0.823123,
        "f1": 0.794521,
        "accuracy": 0.823123,
        "main_score": 0.794521,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.865942,
        "recall": 0.908103,
        "f1": 0.879447,
        "accuracy": 0.908103,
        "main_score": 0.879447,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.876725,
        "recall": 0.905138,
        "f1": 0.885052,
        "accuracy": 0.905138,
        "main_score": 0.885052,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.933877,
        "recall": 0.954545,
        "f1": 0.940448,
        "accuracy": 0.954545,
        "main_score": 0.940448,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.063717,
        "recall": 0.077075,
        "f1": 0.066035,
        "accuracy": 0.077075,
        "main_score": 0.066035,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.145962,
        "recall": 0.238142,
        "f1": 0.165793,
        "accuracy": 0.238142,
        "main_score": 0.165793,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.844465,
        "recall": 0.87747,
        "f1": 0.854009,
        "accuracy": 0.87747,
        "main_score": 0.854009,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.882964,
        "recall": 0.917984,
        "f1": 0.894088,
        "accuracy": 0.917984,
        "main_score": 0.894088,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.833218,
        "recall": 0.871542,
        "f1": 0.844281,
        "accuracy": 0.871542,
        "main_score": 0.844281,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.877635,
        "recall": 0.91502,
        "f1": 0.889493,
        "accuracy": 0.91502,
        "main_score": 0.889493,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.009081,
        "recall": 0.011858,
        "f1": 0.009236,
        "accuracy": 0.011858,
        "main_score": 0.009236,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01004,
        "recall": 0.025692,
        "f1": 0.012493,
        "accuracy": 0.025692,
        "main_score": 0.012493,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 2480.6853353977203,
  "kg_co2_emissions": null
}