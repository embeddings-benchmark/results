{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "task_name": "EmotionClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.44165,
        "f1": 0.401311,
        "f1_weighted": 0.46142,
        "scores_per_experiment": [
          {
            "accuracy": 0.471,
            "f1": 0.424176,
            "f1_weighted": 0.492908
          },
          {
            "accuracy": 0.4115,
            "f1": 0.370827,
            "f1_weighted": 0.418011
          },
          {
            "accuracy": 0.444,
            "f1": 0.398006,
            "f1_weighted": 0.470179
          },
          {
            "accuracy": 0.436,
            "f1": 0.396973,
            "f1_weighted": 0.466688
          },
          {
            "accuracy": 0.426,
            "f1": 0.392535,
            "f1_weighted": 0.446132
          },
          {
            "accuracy": 0.4415,
            "f1": 0.414041,
            "f1_weighted": 0.459117
          },
          {
            "accuracy": 0.437,
            "f1": 0.384931,
            "f1_weighted": 0.457681
          },
          {
            "accuracy": 0.4345,
            "f1": 0.403747,
            "f1_weighted": 0.447188
          },
          {
            "accuracy": 0.488,
            "f1": 0.444823,
            "f1_weighted": 0.506993
          },
          {
            "accuracy": 0.427,
            "f1": 0.383054,
            "f1_weighted": 0.4493
          }
        ],
        "main_score": 0.44165,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.43815,
        "f1": 0.392159,
        "f1_weighted": 0.460537,
        "scores_per_experiment": [
          {
            "accuracy": 0.471,
            "f1": 0.413445,
            "f1_weighted": 0.494694
          },
          {
            "accuracy": 0.4,
            "f1": 0.358959,
            "f1_weighted": 0.407717
          },
          {
            "accuracy": 0.4295,
            "f1": 0.383006,
            "f1_weighted": 0.455708
          },
          {
            "accuracy": 0.427,
            "f1": 0.38473,
            "f1_weighted": 0.461586
          },
          {
            "accuracy": 0.4355,
            "f1": 0.397727,
            "f1_weighted": 0.462032
          },
          {
            "accuracy": 0.4165,
            "f1": 0.380519,
            "f1_weighted": 0.439186
          },
          {
            "accuracy": 0.428,
            "f1": 0.375223,
            "f1_weighted": 0.45266
          },
          {
            "accuracy": 0.434,
            "f1": 0.399755,
            "f1_weighted": 0.447244
          },
          {
            "accuracy": 0.498,
            "f1": 0.438921,
            "f1_weighted": 0.51846
          },
          {
            "accuracy": 0.442,
            "f1": 0.389305,
            "f1_weighted": 0.466083
          }
        ],
        "main_score": 0.43815,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 145.9655933380127,
  "kg_co2_emissions": null
}