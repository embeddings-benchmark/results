{
  "dataset_revision": "8ccc72e69e65f40c70e117d8b3c08306bb788b60",
  "task_name": "MasakhaNEWSClusteringS2S",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "v_measure": 0.506462,
        "v_measure_std": 0.411251,
        "v_measures": [
          1.0,
          0.029149,
          0.270598,
          0.232565,
          1.0
        ],
        "main_score": 0.506462,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ]
      },
      {
        "v_measure": 0.575942,
        "v_measure_std": 0.213835,
        "v_measures": [
          0.200102,
          0.625756,
          0.512107,
          0.721784,
          0.819962
        ],
        "main_score": 0.575942,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "v_measure": 0.438042,
        "v_measure_std": 0.38841,
        "v_measures": [
          1.0,
          0.060918,
          0.328417,
          0.025306,
          0.775569
        ],
        "main_score": 0.438042,
        "hf_subset": "fra",
        "languages": [
          "fra-Latn"
        ]
      },
      {
        "v_measure": 0.28586,
        "v_measure_std": 0.223783,
        "v_measures": [
          0.405093,
          0.010651,
          0.146465,
          0.21288,
          0.654209
        ],
        "main_score": 0.28586,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ]
      },
      {
        "v_measure": 0.428104,
        "v_measure_std": 0.328719,
        "v_measures": [
          0.017705,
          0.507393,
          0.376672,
          1.0,
          0.238751
        ],
        "main_score": 0.428104,
        "hf_subset": "ibo",
        "languages": [
          "ibo-Latn"
        ]
      },
      {
        "v_measure": 0.536717,
        "v_measure_std": 0.383996,
        "v_measures": [
          0.12523,
          0.334067,
          1.0,
          1.0,
          0.224288
        ],
        "main_score": 0.536717,
        "hf_subset": "lin",
        "languages": [
          "lin-Latn"
        ]
      },
      {
        "v_measure": 0.472594,
        "v_measure_std": 0.436533,
        "v_measures": [
          0.0174,
          0.103796,
          1.0,
          1.0,
          0.241775
        ],
        "main_score": 0.472594,
        "hf_subset": "lug",
        "languages": [
          "lug-Latn"
        ]
      },
      {
        "v_measure": 0.335465,
        "v_measure_std": 0.354651,
        "v_measures": [
          0.384534,
          0.034379,
          1.0,
          0.06163,
          0.196782
        ],
        "main_score": 0.335465,
        "hf_subset": "orm",
        "languages": [
          "orm-Ethi"
        ]
      },
      {
        "v_measure": 0.818303,
        "v_measure_std": 0.312208,
        "v_measures": [
          0.199517,
          1.0,
          1.0,
          0.891996,
          1.0
        ],
        "main_score": 0.818303,
        "hf_subset": "pcm",
        "languages": [
          "pcm-Latn"
        ]
      },
      {
        "v_measure": 0.489419,
        "v_measure_std": 0.427569,
        "v_measures": [
          0.112687,
          0.020374,
          1.0,
          0.314033,
          1.0
        ],
        "main_score": 0.489419,
        "hf_subset": "run",
        "languages": [
          "run-Latn"
        ]
      },
      {
        "v_measure": 0.461602,
        "v_measure_std": 0.441577,
        "v_measures": [
          1.0,
          0.177958,
          0.054774,
          0.075279,
          1.0
        ],
        "main_score": 0.461602,
        "hf_subset": "sna",
        "languages": [
          "sna-Latn"
        ]
      },
      {
        "v_measure": 0.306235,
        "v_measure_std": 0.357788,
        "v_measures": [
          0.301403,
          1.0,
          0.084294,
          0.058081,
          0.087397
        ],
        "main_score": 0.306235,
        "hf_subset": "som",
        "languages": [
          "som-Latn"
        ]
      },
      {
        "v_measure": 0.168068,
        "v_measure_std": 0.163452,
        "v_measures": [
          0.049311,
          0.040781,
          0.022303,
          0.415326,
          0.312617
        ],
        "main_score": 0.168068,
        "hf_subset": "swa",
        "languages": [
          "swa-Latn"
        ]
      },
      {
        "v_measure": 0.466002,
        "v_measure_std": 0.443864,
        "v_measures": [
          0.257623,
          1.0,
          0.005557,
          1.0,
          0.066831
        ],
        "main_score": 0.466002,
        "hf_subset": "tir",
        "languages": [
          "tir-Ethi"
        ]
      },
      {
        "v_measure": 0.299366,
        "v_measure_std": 0.358411,
        "v_measures": [
          0.17292,
          0.098551,
          1.5e-05,
          0.225346,
          1.0
        ],
        "main_score": 0.299366,
        "hf_subset": "xho",
        "languages": [
          "xho-Latn"
        ]
      },
      {
        "v_measure": 0.288305,
        "v_measure_std": 0.364075,
        "v_measures": [
          1.0,
          0.135958,
          0.071277,
          0.000225,
          0.234067
        ],
        "main_score": 0.288305,
        "hf_subset": "yor",
        "languages": [
          "yor-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 409.4353482723236,
  "kg_co2_emissions": null
}