{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.698433,
        "f1": 0.690622,
        "f1_weighted": 0.691881,
        "scores_per_experiment": [
          {
            "accuracy": 0.718016,
            "f1": 0.71194,
            "f1_weighted": 0.711819
          },
          {
            "accuracy": 0.657963,
            "f1": 0.642836,
            "f1_weighted": 0.643246
          },
          {
            "accuracy": 0.681462,
            "f1": 0.679967,
            "f1_weighted": 0.679874
          },
          {
            "accuracy": 0.710183,
            "f1": 0.700503,
            "f1_weighted": 0.699764
          },
          {
            "accuracy": 0.751958,
            "f1": 0.741131,
            "f1_weighted": 0.744084
          },
          {
            "accuracy": 0.744125,
            "f1": 0.743073,
            "f1_weighted": 0.74395
          },
          {
            "accuracy": 0.691906,
            "f1": 0.688121,
            "f1_weighted": 0.68992
          },
          {
            "accuracy": 0.663185,
            "f1": 0.644427,
            "f1_weighted": 0.646786
          },
          {
            "accuracy": 0.673629,
            "f1": 0.6666,
            "f1_weighted": 0.670262
          },
          {
            "accuracy": 0.691906,
            "f1": 0.687623,
            "f1_weighted": 0.689104
          }
        ],
        "main_score": 0.698433,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.6625,
        "f1": 0.659491,
        "f1_weighted": 0.654036,
        "scores_per_experiment": [
          {
            "accuracy": 0.614583,
            "f1": 0.612697,
            "f1_weighted": 0.609176
          },
          {
            "accuracy": 0.604167,
            "f1": 0.604167,
            "f1_weighted": 0.591797
          },
          {
            "accuracy": 0.583333,
            "f1": 0.578869,
            "f1_weighted": 0.572591
          },
          {
            "accuracy": 0.604167,
            "f1": 0.59195,
            "f1_weighted": 0.581029
          },
          {
            "accuracy": 0.729167,
            "f1": 0.725665,
            "f1_weighted": 0.723029
          },
          {
            "accuracy": 0.6875,
            "f1": 0.69596,
            "f1_weighted": 0.681534
          },
          {
            "accuracy": 0.697917,
            "f1": 0.689226,
            "f1_weighted": 0.69416
          },
          {
            "accuracy": 0.6875,
            "f1": 0.681392,
            "f1_weighted": 0.676354
          },
          {
            "accuracy": 0.770833,
            "f1": 0.774024,
            "f1_weighted": 0.772712
          },
          {
            "accuracy": 0.645833,
            "f1": 0.640957,
            "f1_weighted": 0.637975
          }
        ],
        "main_score": 0.6625,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 49.86497402191162,
  "kg_co2_emissions": null
}