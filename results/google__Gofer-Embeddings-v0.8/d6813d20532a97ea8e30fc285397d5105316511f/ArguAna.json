{
  "dataset_revision": null,
  "mteb_version": null,
  "task_name": "ArguAna",
  "evaluation_time": null,
  "scores": {
    "test": [
      {
        "map_at_1": 0.67852,
        "map_at_10": 0.79185,
        "map_at_100": 0.79336,
        "map_at_1000": 0.79336,
        "map_at_3": 0.7775,
        "map_at_5": 0.78831,
        "mrr_at_1": 0.68634,
        "mrr_at_10": 0.79461,
        "mrr_at_100": 0.79619,
        "mrr_at_1000": 0.79619,
        "mrr_at_3": 0.77975,
        "mrr_at_5": 0.79113,
        "ndcg_at_1": 0.67852,
        "ndcg_at_10": 0.83627,
        "ndcg_at_100": 0.84246,
        "ndcg_at_1000": 0.84246,
        "ndcg_at_3": 0.80861,
        "ndcg_at_5": 0.82787,
        "precision_at_1": 0.67852,
        "precision_at_10": 0.09701,
        "precision_at_100": 0.00996,
        "precision_at_1000": 0.001,
        "precision_at_3": 0.29943,
        "precision_at_5": 0.1889,
        "recall_at_1": 0.67852,
        "recall_at_10": 0.97013,
        "recall_at_100": 0.99644,
        "recall_at_1000": 0.99644,
        "recall_at_3": 0.89829,
        "recall_at_5": 0.94452,
        "main_score": 0.83627,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  }
}