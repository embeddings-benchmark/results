{"name": "laion/CLIP-ViT-B-32-laion2B-s34B-b79K", "revision": "08f73555f1b2fb7c82058aebbd492887a94968ef", "release_date": "2022-09-15", "languages": ["eng_Latn"], "n_parameters": 151000000, "memory_usage_mb": 577.0, "max_tokens": 77.0, "embed_dim": 512, "license": "mit", "open_weights": true, "public_training_code": "https://github.com/mlfoundations/open_clip", "public_training_data": "https://laion.ai/blog/laion-5b/", "framework": ["PyTorch"], "reference": "https://huggingface.co/laion/CLIP-ViT-B-32-laion2B-s34B-b79K", "similarity_fn_name": null, "use_instructions": false, "training_datasets": {}, "adapted_from": null, "superseded_by": null, "is_cross_encoder": null, "modalities": ["image", "text"], "loader": "openclip_loader"}