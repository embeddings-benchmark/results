{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 8e-06,
        "recall": 0.002006,
        "f1": 1.6e-05,
        "accuracy": 0.002006,
        "main_score": 1.6e-05,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001386,
        "recall": 0.004012,
        "f1": 0.001672,
        "accuracy": 0.004012,
        "main_score": 0.001672,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.023209,
        "recall": 0.037111,
        "f1": 0.025634,
        "accuracy": 0.037111,
        "main_score": 0.025634,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.029413,
        "recall": 0.07322,
        "f1": 0.036972,
        "accuracy": 0.07322,
        "main_score": 0.036972,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 3e-06,
        "accuracy": 0.001003,
        "main_score": 3e-06,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003295,
        "recall": 0.01003,
        "f1": 0.004076,
        "accuracy": 0.01003,
        "main_score": 0.004076,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.034822,
        "recall": 0.05015,
        "f1": 0.037425,
        "accuracy": 0.05015,
        "main_score": 0.037425,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.029831,
        "recall": 0.078235,
        "f1": 0.038108,
        "accuracy": 0.078235,
        "main_score": 0.038108,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.029535,
        "recall": 0.044132,
        "f1": 0.032089,
        "accuracy": 0.044132,
        "main_score": 0.032089,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.040491,
        "recall": 0.086259,
        "f1": 0.048889,
        "accuracy": 0.086259,
        "main_score": 0.048889,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001851,
        "recall": 0.009027,
        "f1": 0.00248,
        "accuracy": 0.009027,
        "main_score": 0.00248,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002008,
        "recall": 0.003009,
        "f1": 0.002009,
        "accuracy": 0.003009,
        "main_score": 0.002009,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001099,
        "recall": 0.009027,
        "f1": 0.001775,
        "accuracy": 0.009027,
        "main_score": 0.001775,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.079421,
        "recall": 0.097292,
        "f1": 0.083262,
        "accuracy": 0.097292,
        "main_score": 0.083262,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.054537,
        "recall": 0.12337,
        "f1": 0.068161,
        "accuracy": 0.12337,
        "main_score": 0.068161,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00174,
        "recall": 0.01003,
        "f1": 0.002773,
        "accuracy": 0.01003,
        "main_score": 0.002773,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.003015,
        "recall": 0.004012,
        "f1": 0.00302,
        "accuracy": 0.004012,
        "main_score": 0.00302,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002256,
        "recall": 0.01003,
        "f1": 0.003068,
        "accuracy": 0.01003,
        "main_score": 0.003068,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.002006,
        "f1": 1.9e-05,
        "accuracy": 0.002006,
        "main_score": 1.9e-05,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002652,
        "recall": 0.011033,
        "f1": 0.003496,
        "accuracy": 0.011033,
        "main_score": 0.003496,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005566,
        "recall": 0.013039,
        "f1": 0.006784,
        "accuracy": 0.013039,
        "main_score": 0.006784,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.040019,
        "recall": 0.057172,
        "f1": 0.04318,
        "accuracy": 0.057172,
        "main_score": 0.04318,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.03381,
        "recall": 0.094283,
        "f1": 0.043064,
        "accuracy": 0.094283,
        "main_score": 0.043064,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.03955,
        "recall": 0.054162,
        "f1": 0.041606,
        "accuracy": 0.054162,
        "main_score": 0.041606,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028543,
        "recall": 0.080241,
        "f1": 0.037305,
        "accuracy": 0.080241,
        "main_score": 0.037305,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.003013,
        "recall": 0.005015,
        "f1": 0.003017,
        "accuracy": 0.005015,
        "main_score": 0.003017,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021236,
        "recall": 0.052156,
        "f1": 0.025996,
        "accuracy": 0.052156,
        "main_score": 0.025996,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.002011,
        "recall": 0.004012,
        "f1": 0.002016,
        "accuracy": 0.004012,
        "main_score": 0.002016,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005438,
        "recall": 0.016048,
        "f1": 0.006653,
        "accuracy": 0.016048,
        "main_score": 0.006653,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003438,
        "recall": 0.01003,
        "f1": 0.004301,
        "accuracy": 0.01003,
        "main_score": 0.004301,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001006,
        "accuracy": 0.002006,
        "main_score": 0.001006,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003644,
        "recall": 0.017051,
        "f1": 0.005174,
        "accuracy": 0.017051,
        "main_score": 0.005174,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.002006,
        "f1": 1e-05,
        "accuracy": 0.002006,
        "main_score": 1e-05,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003534,
        "recall": 0.011033,
        "f1": 0.004606,
        "accuracy": 0.011033,
        "main_score": 0.004606,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003247,
        "recall": 0.008024,
        "f1": 0.003884,
        "accuracy": 0.008024,
        "main_score": 0.003884,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.001005,
        "recall": 0.002006,
        "f1": 0.001006,
        "accuracy": 0.002006,
        "main_score": 0.001006,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001171,
        "recall": 0.008024,
        "f1": 0.00183,
        "accuracy": 0.008024,
        "main_score": 0.00183,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001005,
        "accuracy": 0.002006,
        "main_score": 0.001005,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002423,
        "recall": 0.009027,
        "f1": 0.002775,
        "accuracy": 0.009027,
        "main_score": 0.002775,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 3e-06,
        "accuracy": 0.001003,
        "main_score": 3e-06,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000661,
        "recall": 0.004012,
        "f1": 0.000965,
        "accuracy": 0.004012,
        "main_score": 0.000965,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001005,
        "accuracy": 0.002006,
        "main_score": 0.001005,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004359,
        "recall": 0.017051,
        "f1": 0.005765,
        "accuracy": 0.017051,
        "main_score": 0.005765,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.002006,
        "f1": 1.9e-05,
        "accuracy": 0.002006,
        "main_score": 1.9e-05,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003279,
        "recall": 0.01003,
        "f1": 0.003957,
        "accuracy": 0.01003,
        "main_score": 0.003957,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.000335,
        "recall": 0.002006,
        "f1": 0.000504,
        "accuracy": 0.002006,
        "main_score": 0.000504,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00285,
        "recall": 0.013039,
        "f1": 0.00437,
        "accuracy": 0.013039,
        "main_score": 0.00437,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 3e-06,
        "accuracy": 0.001003,
        "main_score": 3e-06,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000725,
        "recall": 0.008024,
        "f1": 0.001265,
        "accuracy": 0.008024,
        "main_score": 0.001265,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 3e-06,
        "accuracy": 0.001003,
        "main_score": 3e-06,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0031,
        "recall": 0.01003,
        "f1": 0.003843,
        "accuracy": 0.01003,
        "main_score": 0.003843,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.01155,
        "recall": 0.014042,
        "f1": 0.012066,
        "accuracy": 0.014042,
        "main_score": 0.012066,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000899,
        "recall": 0.014042,
        "f1": 0.001675,
        "accuracy": 0.014042,
        "main_score": 0.001675,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 7.2e-05,
        "recall": 0.001976,
        "f1": 0.000134,
        "accuracy": 0.001976,
        "main_score": 0.000134,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003248,
        "recall": 0.009881,
        "f1": 0.003979,
        "accuracy": 0.009881,
        "main_score": 0.003979,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.03435,
        "recall": 0.05336,
        "f1": 0.037467,
        "accuracy": 0.05336,
        "main_score": 0.037467,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023122,
        "recall": 0.073123,
        "f1": 0.031765,
        "accuracy": 0.073123,
        "main_score": 0.031765,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 3e-06,
        "accuracy": 0.000988,
        "main_score": 3e-06,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002138,
        "recall": 0.009881,
        "f1": 0.002819,
        "accuracy": 0.009881,
        "main_score": 0.002819,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.048016,
        "recall": 0.073123,
        "f1": 0.052625,
        "accuracy": 0.073123,
        "main_score": 0.052625,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.032509,
        "recall": 0.091897,
        "f1": 0.043218,
        "accuracy": 0.091897,
        "main_score": 0.043218,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.028497,
        "recall": 0.051383,
        "f1": 0.032239,
        "accuracy": 0.051383,
        "main_score": 0.032239,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028781,
        "recall": 0.078063,
        "f1": 0.037377,
        "accuracy": 0.078063,
        "main_score": 0.037377,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0015,
        "recall": 0.007905,
        "f1": 0.002328,
        "accuracy": 0.007905,
        "main_score": 0.002328,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003955,
        "recall": 0.005929,
        "f1": 0.004288,
        "accuracy": 0.005929,
        "main_score": 0.004288,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004084,
        "recall": 0.012846,
        "f1": 0.004663,
        "accuracy": 0.012846,
        "main_score": 0.004663,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.091646,
        "recall": 0.115613,
        "f1": 0.096582,
        "accuracy": 0.115613,
        "main_score": 0.096582,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.059895,
        "recall": 0.13834,
        "f1": 0.074682,
        "accuracy": 0.13834,
        "main_score": 0.074682,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000996,
        "recall": 0.002964,
        "f1": 0.001004,
        "accuracy": 0.002964,
        "main_score": 0.001004,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002325,
        "recall": 0.009881,
        "f1": 0.003119,
        "accuracy": 0.009881,
        "main_score": 0.003119,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.002299,
        "recall": 0.003953,
        "f1": 0.002513,
        "accuracy": 0.003953,
        "main_score": 0.002513,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003016,
        "recall": 0.011858,
        "f1": 0.003918,
        "accuracy": 0.011858,
        "main_score": 0.003918,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.000128,
        "recall": 0.002964,
        "f1": 0.000228,
        "accuracy": 0.002964,
        "main_score": 0.000228,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002823,
        "recall": 0.009881,
        "f1": 0.003711,
        "accuracy": 0.009881,
        "main_score": 0.003711,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.001385,
        "recall": 0.003953,
        "f1": 0.001608,
        "accuracy": 0.003953,
        "main_score": 0.001608,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005097,
        "recall": 0.016798,
        "f1": 0.006664,
        "accuracy": 0.016798,
        "main_score": 0.006664,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.043627,
        "recall": 0.060277,
        "f1": 0.047073,
        "accuracy": 0.060277,
        "main_score": 0.047073,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031665,
        "recall": 0.093874,
        "f1": 0.04194,
        "accuracy": 0.093874,
        "main_score": 0.04194,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.043002,
        "recall": 0.061265,
        "f1": 0.046946,
        "accuracy": 0.061265,
        "main_score": 0.046946,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030183,
        "recall": 0.090909,
        "f1": 0.039316,
        "accuracy": 0.090909,
        "main_score": 0.039316,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.006463,
        "recall": 0.009881,
        "f1": 0.006784,
        "accuracy": 0.009881,
        "main_score": 0.006784,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022247,
        "recall": 0.045455,
        "f1": 0.025912,
        "accuracy": 0.045455,
        "main_score": 0.025912,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.003295,
        "recall": 0.004941,
        "f1": 0.003461,
        "accuracy": 0.004941,
        "main_score": 0.003461,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002785,
        "recall": 0.01087,
        "f1": 0.003773,
        "accuracy": 0.01087,
        "main_score": 0.003773,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001976,
        "f1": 8e-06,
        "accuracy": 0.001976,
        "main_score": 8e-06,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000758,
        "recall": 0.005929,
        "f1": 0.001281,
        "accuracy": 0.005929,
        "main_score": 0.001281,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001901,
        "recall": 0.005929,
        "f1": 0.002374,
        "accuracy": 0.005929,
        "main_score": 0.002374,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003783,
        "recall": 0.016798,
        "f1": 0.004997,
        "accuracy": 0.016798,
        "main_score": 0.004997,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001614,
        "recall": 0.005929,
        "f1": 0.002039,
        "accuracy": 0.005929,
        "main_score": 0.002039,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001196,
        "recall": 0.005929,
        "f1": 0.001787,
        "accuracy": 0.005929,
        "main_score": 0.001787,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004676,
        "recall": 0.013834,
        "f1": 0.005671,
        "accuracy": 0.013834,
        "main_score": 0.005671,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000988,
        "f1": 3e-06,
        "accuracy": 0.000988,
        "main_score": 3e-06,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000739,
        "recall": 0.004941,
        "f1": 0.001263,
        "accuracy": 0.004941,
        "main_score": 0.001263,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.001976,
        "f1": 2.1e-05,
        "accuracy": 0.001976,
        "main_score": 2.1e-05,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001877,
        "recall": 0.006917,
        "f1": 0.002356,
        "accuracy": 0.006917,
        "main_score": 0.002356,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 5.1e-05,
        "recall": 0.002964,
        "f1": 9.8e-05,
        "accuracy": 0.002964,
        "main_score": 9.8e-05,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003117,
        "recall": 0.012846,
        "f1": 0.004252,
        "accuracy": 0.012846,
        "main_score": 0.004252,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.002076,
        "recall": 0.005929,
        "f1": 0.00249,
        "accuracy": 0.005929,
        "main_score": 0.00249,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000767,
        "recall": 0.005929,
        "f1": 0.001196,
        "accuracy": 0.005929,
        "main_score": 0.001196,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000585,
        "recall": 0.004941,
        "f1": 0.000988,
        "accuracy": 0.004941,
        "main_score": 0.000988,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003365,
        "recall": 0.01087,
        "f1": 0.004193,
        "accuracy": 0.01087,
        "main_score": 0.004193,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.010353,
        "recall": 0.017787,
        "f1": 0.011778,
        "accuracy": 0.017787,
        "main_score": 0.011778,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004627,
        "recall": 0.02668,
        "f1": 0.007025,
        "accuracy": 0.02668,
        "main_score": 0.007025,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 8.400980710983276,
  "kg_co2_emissions": 0.00019139183011606035
}