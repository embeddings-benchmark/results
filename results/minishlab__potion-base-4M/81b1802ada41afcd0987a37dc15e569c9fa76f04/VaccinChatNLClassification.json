{
  "dataset_revision": "bd27d0058bea2ad52470d9072a3b5da6b97c1ac3",
  "task_name": "VaccinChatNLClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.241026,
            "f1": 0.255558,
            "f1_weighted": 0.222023,
            "precision": 0.29568,
            "precision_weighted": 0.424524,
            "recall": 0.406036,
            "recall_weighted": 0.241026,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.247009,
            "f1": 0.237481,
            "f1_weighted": 0.218573,
            "precision": 0.246756,
            "precision_weighted": 0.372634,
            "recall": 0.408854,
            "recall_weighted": 0.247009,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.264957,
            "f1": 0.269909,
            "f1_weighted": 0.240936,
            "precision": 0.307796,
            "precision_weighted": 0.428142,
            "recall": 0.420039,
            "recall_weighted": 0.264957,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.251282,
            "f1": 0.227922,
            "f1_weighted": 0.239768,
            "precision": 0.265828,
            "precision_weighted": 0.493796,
            "recall": 0.374693,
            "recall_weighted": 0.251282,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.253846,
            "f1": 0.260638,
            "f1_weighted": 0.228065,
            "precision": 0.303184,
            "precision_weighted": 0.439289,
            "recall": 0.408015,
            "recall_weighted": 0.253846,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.257265,
            "f1": 0.24905,
            "f1_weighted": 0.238206,
            "precision": 0.27575,
            "precision_weighted": 0.431342,
            "recall": 0.398813,
            "recall_weighted": 0.257265,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.244444,
            "f1": 0.234063,
            "f1_weighted": 0.222,
            "precision": 0.260547,
            "precision_weighted": 0.381294,
            "recall": 0.376499,
            "recall_weighted": 0.244444,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.246154,
            "f1": 0.225257,
            "f1_weighted": 0.218893,
            "precision": 0.240811,
            "precision_weighted": 0.35096,
            "recall": 0.374286,
            "recall_weighted": 0.246154,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.251282,
            "f1": 0.256434,
            "f1_weighted": 0.213979,
            "precision": 0.250327,
            "precision_weighted": 0.286824,
            "recall": 0.418182,
            "recall_weighted": 0.251282,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.257265,
            "f1": 0.235916,
            "f1_weighted": 0.227863,
            "precision": 0.244714,
            "precision_weighted": 0.390377,
            "recall": 0.396314,
            "recall_weighted": 0.257265,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.251453,
        "f1": 0.245223,
        "f1_weighted": 0.227031,
        "precision": 0.269139,
        "precision_weighted": 0.399918,
        "recall": 0.398173,
        "recall_weighted": 0.251453,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.245223,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 19.821748971939087,
  "kg_co2_emissions": null
}