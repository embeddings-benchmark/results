{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.686963,
        "f1": 0.68318,
        "f1_weighted": 0.68309,
        "ap": 0.639297,
        "ap_weighted": 0.639297,
        "scores_per_experiment": [
          {
            "accuracy": 0.714355,
            "f1": 0.711796,
            "f1_weighted": 0.711716,
            "ap": 0.66559,
            "ap_weighted": 0.66559
          },
          {
            "accuracy": 0.690918,
            "f1": 0.690769,
            "f1_weighted": 0.690749,
            "ap": 0.635116,
            "ap_weighted": 0.635116
          },
          {
            "accuracy": 0.695801,
            "f1": 0.694225,
            "f1_weighted": 0.694161,
            "ap": 0.644357,
            "ap_weighted": 0.644357
          },
          {
            "accuracy": 0.668945,
            "f1": 0.661979,
            "f1_weighted": 0.661837,
            "ap": 0.626437,
            "ap_weighted": 0.626437
          },
          {
            "accuracy": 0.664062,
            "f1": 0.659385,
            "f1_weighted": 0.659268,
            "ap": 0.619007,
            "ap_weighted": 0.619007
          },
          {
            "accuracy": 0.668945,
            "f1": 0.666703,
            "f1_weighted": 0.666622,
            "ap": 0.620323,
            "ap_weighted": 0.620323
          },
          {
            "accuracy": 0.6875,
            "f1": 0.687328,
            "f1_weighted": 0.687307,
            "ap": 0.632171,
            "ap_weighted": 0.632171
          },
          {
            "accuracy": 0.731445,
            "f1": 0.727831,
            "f1_weighted": 0.727739,
            "ap": 0.687236,
            "ap_weighted": 0.687236
          },
          {
            "accuracy": 0.649902,
            "f1": 0.637215,
            "f1_weighted": 0.637016,
            "ap": 0.612918,
            "ap_weighted": 0.612918
          },
          {
            "accuracy": 0.697754,
            "f1": 0.694573,
            "f1_weighted": 0.694482,
            "ap": 0.649817,
            "ap_weighted": 0.649817
          }
        ],
        "main_score": 0.686963,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.692969,
        "f1": 0.688682,
        "f1_weighted": 0.688617,
        "ap": 0.645183,
        "ap_weighted": 0.645183,
        "scores_per_experiment": [
          {
            "accuracy": 0.718262,
            "f1": 0.716421,
            "f1_weighted": 0.716376,
            "ap": 0.66708,
            "ap_weighted": 0.66708
          },
          {
            "accuracy": 0.69873,
            "f1": 0.697996,
            "f1_weighted": 0.697967,
            "ap": 0.644259,
            "ap_weighted": 0.644259
          },
          {
            "accuracy": 0.712891,
            "f1": 0.711765,
            "f1_weighted": 0.71173,
            "ap": 0.659356,
            "ap_weighted": 0.659356
          },
          {
            "accuracy": 0.670898,
            "f1": 0.662768,
            "f1_weighted": 0.662666,
            "ap": 0.629129,
            "ap_weighted": 0.629129
          },
          {
            "accuracy": 0.681152,
            "f1": 0.675298,
            "f1_weighted": 0.675213,
            "ap": 0.636713,
            "ap_weighted": 0.636713
          },
          {
            "accuracy": 0.675293,
            "f1": 0.672793,
            "f1_weighted": 0.672738,
            "ap": 0.626035,
            "ap_weighted": 0.626035
          },
          {
            "accuracy": 0.699707,
            "f1": 0.69926,
            "f1_weighted": 0.699237,
            "ap": 0.644126,
            "ap_weighted": 0.644126
          },
          {
            "accuracy": 0.73584,
            "f1": 0.732376,
            "f1_weighted": 0.732316,
            "ap": 0.691192,
            "ap_weighted": 0.691192
          },
          {
            "accuracy": 0.633789,
            "f1": 0.618808,
            "f1_weighted": 0.618661,
            "ap": 0.597936,
            "ap_weighted": 0.597936
          },
          {
            "accuracy": 0.703125,
            "f1": 0.699333,
            "f1_weighted": 0.699267,
            "ap": 0.656008,
            "ap_weighted": 0.656008
          }
        ],
        "main_score": 0.692969,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.006884098052979,
  "kg_co2_emissions": 0.0003438996189725257
}