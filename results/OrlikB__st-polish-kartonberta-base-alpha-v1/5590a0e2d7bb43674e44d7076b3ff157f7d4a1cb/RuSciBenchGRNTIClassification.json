{
  "dataset_revision": "673a610d6d3dd91a547a0d57ae1b56f37ebbf6a1",
  "task_name": "RuSciBenchGRNTIClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.075732,
        "f1": 0.050587,
        "f1_weighted": 0.05057,
        "scores_per_experiment": [
          {
            "accuracy": 0.06543,
            "f1": 0.044392,
            "f1_weighted": 0.044373
          },
          {
            "accuracy": 0.088867,
            "f1": 0.060671,
            "f1_weighted": 0.06064
          },
          {
            "accuracy": 0.085938,
            "f1": 0.054029,
            "f1_weighted": 0.054101
          },
          {
            "accuracy": 0.063965,
            "f1": 0.041429,
            "f1_weighted": 0.041456
          },
          {
            "accuracy": 0.078613,
            "f1": 0.061063,
            "f1_weighted": 0.060978
          },
          {
            "accuracy": 0.083008,
            "f1": 0.052948,
            "f1_weighted": 0.052902
          },
          {
            "accuracy": 0.074707,
            "f1": 0.050654,
            "f1_weighted": 0.050636
          },
          {
            "accuracy": 0.06543,
            "f1": 0.042419,
            "f1_weighted": 0.042407
          },
          {
            "accuracy": 0.07959,
            "f1": 0.056028,
            "f1_weighted": 0.055977
          },
          {
            "accuracy": 0.071777,
            "f1": 0.042242,
            "f1_weighted": 0.042225
          }
        ],
        "main_score": 0.075732,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ]
      }
    ]
  },
  "evaluation_time": 17.775967597961426,
  "kg_co2_emissions": 0.0008996663726680993
}