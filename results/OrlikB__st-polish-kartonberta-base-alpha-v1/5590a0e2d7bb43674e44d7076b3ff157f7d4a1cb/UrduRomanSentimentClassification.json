{
  "dataset_revision": "566be6449bb30b9b9f2b59173391647fe0ca3224",
  "task_name": "UrduRomanSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.423096,
        "f1": 0.407238,
        "f1_weighted": 0.422179,
        "scores_per_experiment": [
          {
            "accuracy": 0.479004,
            "f1": 0.428981,
            "f1_weighted": 0.458091
          },
          {
            "accuracy": 0.430664,
            "f1": 0.422272,
            "f1_weighted": 0.435841
          },
          {
            "accuracy": 0.451172,
            "f1": 0.426065,
            "f1_weighted": 0.450033
          },
          {
            "accuracy": 0.389648,
            "f1": 0.380902,
            "f1_weighted": 0.382693
          },
          {
            "accuracy": 0.38623,
            "f1": 0.361354,
            "f1_weighted": 0.381416
          },
          {
            "accuracy": 0.418457,
            "f1": 0.418196,
            "f1_weighted": 0.423768
          },
          {
            "accuracy": 0.458008,
            "f1": 0.438635,
            "f1_weighted": 0.460682
          },
          {
            "accuracy": 0.369629,
            "f1": 0.37065,
            "f1_weighted": 0.372186
          },
          {
            "accuracy": 0.422363,
            "f1": 0.411766,
            "f1_weighted": 0.42534
          },
          {
            "accuracy": 0.425781,
            "f1": 0.413557,
            "f1_weighted": 0.43174
          }
        ],
        "main_score": 0.407238,
        "hf_subset": "default",
        "languages": [
          "urd-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 8.070502996444702,
  "kg_co2_emissions": 0.0002557242800068407
}