{
  "dataset_revision": "23a20c659d868740ef9c54854de631fe19cd5c17",
  "task_name": "CSFDSKMovieReviewSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.224219,
        "f1": 0.212808,
        "f1_weighted": 0.21392,
        "scores_per_experiment": [
          {
            "accuracy": 0.222656,
            "f1": 0.215396,
            "f1_weighted": 0.216755
          },
          {
            "accuracy": 0.20752,
            "f1": 0.197181,
            "f1_weighted": 0.198519
          },
          {
            "accuracy": 0.238281,
            "f1": 0.218429,
            "f1_weighted": 0.219893
          },
          {
            "accuracy": 0.222168,
            "f1": 0.212467,
            "f1_weighted": 0.211935
          },
          {
            "accuracy": 0.222656,
            "f1": 0.205758,
            "f1_weighted": 0.207429
          },
          {
            "accuracy": 0.211426,
            "f1": 0.186638,
            "f1_weighted": 0.188241
          },
          {
            "accuracy": 0.208008,
            "f1": 0.198956,
            "f1_weighted": 0.200889
          },
          {
            "accuracy": 0.227051,
            "f1": 0.215985,
            "f1_weighted": 0.216932
          },
          {
            "accuracy": 0.23584,
            "f1": 0.233022,
            "f1_weighted": 0.233918
          },
          {
            "accuracy": 0.246582,
            "f1": 0.244251,
            "f1_weighted": 0.244688
          }
        ],
        "main_score": 0.224219,
        "hf_subset": "default",
        "languages": [
          "slk-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 13.562721014022827,
  "kg_co2_emissions": 0.0005990750837380436
}