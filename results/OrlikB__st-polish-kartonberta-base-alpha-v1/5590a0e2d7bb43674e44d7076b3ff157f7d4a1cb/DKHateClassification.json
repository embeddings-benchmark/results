{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "1.34.21",
  "scores": {
    "test": [
      {
        "accuracy": 0.571125,
        "f1": 0.466724,
        "f1_weighted": 0.637044,
        "ap": 0.888918,
        "ap_weighted": 0.888918,
        "scores_per_experiment": [
          {
            "accuracy": 0.547112,
            "f1": 0.457042,
            "f1_weighted": 0.623068,
            "ap": 0.887244,
            "ap_weighted": 0.887244
          },
          {
            "accuracy": 0.680851,
            "f1": 0.505263,
            "f1_weighted": 0.72654,
            "ap": 0.883179,
            "ap_weighted": 0.883179
          },
          {
            "accuracy": 0.443769,
            "f1": 0.408814,
            "f1_weighted": 0.516738,
            "ap": 0.898335,
            "ap_weighted": 0.898335
          },
          {
            "accuracy": 0.462006,
            "f1": 0.411936,
            "f1_weighted": 0.540762,
            "ap": 0.88818,
            "ap_weighted": 0.88818
          },
          {
            "accuracy": 0.589666,
            "f1": 0.502057,
            "f1_weighted": 0.658864,
            "ap": 0.905349,
            "ap_weighted": 0.905349
          },
          {
            "accuracy": 0.553191,
            "f1": 0.46433,
            "f1_weighted": 0.628127,
            "ap": 0.890454,
            "ap_weighted": 0.890454
          },
          {
            "accuracy": 0.486322,
            "f1": 0.418989,
            "f1_weighted": 0.567483,
            "ap": 0.881759,
            "ap_weighted": 0.881759
          },
          {
            "accuracy": 0.537994,
            "f1": 0.426619,
            "f1_weighted": 0.61634,
            "ap": 0.869908,
            "ap_weighted": 0.869908
          },
          {
            "accuracy": 0.738602,
            "f1": 0.572701,
            "f1_weighted": 0.772591,
            "ap": 0.902749,
            "ap_weighted": 0.902749
          },
          {
            "accuracy": 0.671733,
            "f1": 0.499493,
            "f1_weighted": 0.719924,
            "ap": 0.882018,
            "ap_weighted": 0.882018
          }
        ],
        "main_score": 0.571125,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 26.101219415664673,
  "kg_co2_emissions": null
}