{
    "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.7932414256893072,
                "f1": 0.787067321614858,
                "f1_weighted": 0.7917371887085407,
                "main_score": 0.7932414256893072
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.7548755884330868,
                "f1": 0.7496341150854327,
                "f1_weighted": 0.7511344709750414,
                "main_score": 0.7548755884330868
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.6920645595158035,
                "f1": 0.6957805291990489,
                "f1_weighted": 0.6841325928547694,
                "main_score": 0.6920645595158035
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.7568594485541358,
                "f1": 0.7471713629733614,
                "f1_weighted": 0.7549907502505853,
                "main_score": 0.7568594485541358
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.6879959650302623,
                "f1": 0.6673568572153533,
                "f1_weighted": 0.6869392891616662,
                "main_score": 0.6879959650302623
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.7480833893745797,
                "f1": 0.7375893026985123,
                "f1_weighted": 0.7448216382388233,
                "main_score": 0.7480833893745797
            }
        ]
    }
}