{"name": "laion/CLIP-ViT-H-14-laion2B-s32B-b79K", "revision": "de081ac0a0ca8dc9d1533eed1ae884bb8ae1404b", "release_date": "2022-09-15", "languages": ["eng_Latn"], "n_parameters": 986000000, "memory_usage_mb": 3762.0, "max_tokens": 77.0, "embed_dim": 1024, "license": "mit", "open_weights": true, "public_training_code": "https://github.com/mlfoundations/open_clip", "public_training_data": "https://laion.ai/blog/laion-5b/", "framework": ["PyTorch"], "reference": "https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K", "similarity_fn_name": null, "use_instructions": false, "training_datasets": {}, "adapted_from": null, "superseded_by": null, "is_cross_encoder": null, "modalities": ["image", "text"], "loader": "openclip_loader"}