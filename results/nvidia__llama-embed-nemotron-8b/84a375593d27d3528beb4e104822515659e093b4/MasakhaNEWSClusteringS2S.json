{
  "dataset_revision": "8ccc72e69e65f40c70e117d8b3c08306bb788b60",
  "task_name": "MasakhaNEWSClusteringS2S",
  "mteb_version": "1.39.1",
  "scores": {
    "test": [
      {
        "v_measure": 0.587542,
        "v_measure_std": 0.358356,
        "v_measures": [
          1.0,
          0.114425,
          0.321836,
          0.50145,
          1.0
        ],
        "main_score": 0.587542,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ]
      },
      {
        "v_measure": 0.732505,
        "v_measure_std": 0.258434,
        "v_measures": [
          0.242709,
          0.758743,
          0.794636,
          1.0,
          0.866439
        ],
        "main_score": 0.732505,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "v_measure": 0.759572,
        "v_measure_std": 0.297089,
        "v_measures": [
          1.0,
          0.193331,
          0.82896,
          1.0,
          0.775569
        ],
        "main_score": 0.759572,
        "hf_subset": "fra",
        "languages": [
          "fra-Latn"
        ]
      },
      {
        "v_measure": 0.650729,
        "v_measure_std": 0.308139,
        "v_measures": [
          0.127556,
          0.824803,
          0.473122,
          0.929648,
          0.898513
        ],
        "main_score": 0.650729,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ]
      },
      {
        "v_measure": 0.776215,
        "v_measure_std": 0.237612,
        "v_measures": [
          0.363356,
          0.8333,
          1.0,
          1.0,
          0.684419
        ],
        "main_score": 0.776215,
        "hf_subset": "ibo",
        "languages": [
          "ibo-Latn"
        ]
      },
      {
        "v_measure": 0.71337,
        "v_measure_std": 0.363495,
        "v_measures": [
          0.134313,
          0.432538,
          1.0,
          1.0,
          1.0
        ],
        "main_score": 0.71337,
        "hf_subset": "lin",
        "languages": [
          "lin-Latn"
        ]
      },
      {
        "v_measure": 0.497766,
        "v_measure_std": 0.418422,
        "v_measures": [
          0.011092,
          0.239465,
          1.0,
          1.0,
          0.238273
        ],
        "main_score": 0.497766,
        "hf_subset": "lug",
        "languages": [
          "lug-Latn"
        ]
      },
      {
        "v_measure": 0.500998,
        "v_measure_std": 0.317686,
        "v_measures": [
          0.384534,
          0.034379,
          1.0,
          0.441093,
          0.644985
        ],
        "main_score": 0.500998,
        "hf_subset": "orm",
        "languages": [
          "orm-Ethi"
        ]
      },
      {
        "v_measure": 1.0,
        "v_measure_std": 0.0,
        "v_measures": [
          1.0,
          1.0,
          1.0,
          1.0,
          1.0
        ],
        "main_score": 1.0,
        "hf_subset": "pcm",
        "languages": [
          "pcm-Latn"
        ]
      },
      {
        "v_measure": 0.662605,
        "v_measure_std": 0.310795,
        "v_measures": [
          0.409756,
          0.225418,
          1.0,
          0.67785,
          1.0
        ],
        "main_score": 0.662605,
        "hf_subset": "run",
        "languages": [
          "run-Latn"
        ]
      },
      {
        "v_measure": 0.59572,
        "v_measure_std": 0.368988,
        "v_measures": [
          1.0,
          0.425923,
          0.522343,
          0.030335,
          1.0
        ],
        "main_score": 0.59572,
        "hf_subset": "sna",
        "languages": [
          "sna-Latn"
        ]
      },
      {
        "v_measure": 0.488097,
        "v_measure_std": 0.267797,
        "v_measures": [
          0.350328,
          1.0,
          0.504483,
          0.27015,
          0.315524
        ],
        "main_score": 0.488097,
        "hf_subset": "som",
        "languages": [
          "som-Latn"
        ]
      },
      {
        "v_measure": 0.393936,
        "v_measure_std": 0.334226,
        "v_measures": [
          0.318608,
          0.040781,
          0.044309,
          0.822815,
          0.74317
        ],
        "main_score": 0.393936,
        "hf_subset": "swa",
        "languages": [
          "swa-Latn"
        ]
      },
      {
        "v_measure": 0.567062,
        "v_measure_std": 0.354898,
        "v_measures": [
          0.309791,
          1.0,
          0.220903,
          1.0,
          0.304614
        ],
        "main_score": 0.567062,
        "hf_subset": "tir",
        "languages": [
          "tir-Ethi"
        ]
      },
      {
        "v_measure": 0.369889,
        "v_measure_std": 0.341033,
        "v_measures": [
          0.123203,
          0.056069,
          0.228508,
          0.441664,
          1.0
        ],
        "main_score": 0.369889,
        "hf_subset": "xho",
        "languages": [
          "xho-Latn"
        ]
      },
      {
        "v_measure": 0.443615,
        "v_measure_std": 0.333957,
        "v_measures": [
          1.0,
          0.195145,
          0.656715,
          0.132147,
          0.234067
        ],
        "main_score": 0.443615,
        "hf_subset": "yor",
        "languages": [
          "yor-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 163.70454692840576,
  "kg_co2_emissions": null
}