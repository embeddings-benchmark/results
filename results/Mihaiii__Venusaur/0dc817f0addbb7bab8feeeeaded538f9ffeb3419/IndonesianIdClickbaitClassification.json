{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.547021,
        "f1": 0.541901,
        "f1_weighted": 0.547852,
        "ap": 0.446121,
        "ap_weighted": 0.446121,
        "scores_per_experiment": [
          {
            "accuracy": 0.545898,
            "f1": 0.545892,
            "f1_weighted": 0.545606,
            "ap": 0.4528,
            "ap_weighted": 0.4528
          },
          {
            "accuracy": 0.543945,
            "f1": 0.543628,
            "f1_weighted": 0.545567,
            "ap": 0.448757,
            "ap_weighted": 0.448757
          },
          {
            "accuracy": 0.515625,
            "f1": 0.51265,
            "f1_weighted": 0.518785,
            "ap": 0.427747,
            "ap_weighted": 0.427747
          },
          {
            "accuracy": 0.565918,
            "f1": 0.564135,
            "f1_weighted": 0.568627,
            "ap": 0.459159,
            "ap_weighted": 0.459159
          },
          {
            "accuracy": 0.544922,
            "f1": 0.543961,
            "f1_weighted": 0.547334,
            "ap": 0.447531,
            "ap_weighted": 0.447531
          },
          {
            "accuracy": 0.516113,
            "f1": 0.503134,
            "f1_weighted": 0.516074,
            "ap": 0.420973,
            "ap_weighted": 0.420973
          },
          {
            "accuracy": 0.526855,
            "f1": 0.526854,
            "f1_weighted": 0.526966,
            "ap": 0.440848,
            "ap_weighted": 0.440848
          },
          {
            "accuracy": 0.572754,
            "f1": 0.570999,
            "f1_weighted": 0.57542,
            "ap": 0.463713,
            "ap_weighted": 0.463713
          },
          {
            "accuracy": 0.569336,
            "f1": 0.550616,
            "f1_weighted": 0.565395,
            "ap": 0.448017,
            "ap_weighted": 0.448017
          },
          {
            "accuracy": 0.568848,
            "f1": 0.557139,
            "f1_weighted": 0.568742,
            "ap": 0.451662,
            "ap_weighted": 0.451662
          }
        ],
        "main_score": 0.541901,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.149847030639648,
  "kg_co2_emissions": 0.00020125463387319286
}