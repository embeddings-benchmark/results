{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.710449,
        "f1": 0.707047,
        "f1_weighted": 0.70697,
        "ap": 0.660825,
        "ap_weighted": 0.660825,
        "scores_per_experiment": [
          {
            "accuracy": 0.730957,
            "f1": 0.730903,
            "f1_weighted": 0.730892,
            "ap": 0.671889,
            "ap_weighted": 0.671889
          },
          {
            "accuracy": 0.688965,
            "f1": 0.681031,
            "f1_weighted": 0.680883,
            "ap": 0.64867,
            "ap_weighted": 0.64867
          },
          {
            "accuracy": 0.694336,
            "f1": 0.693022,
            "f1_weighted": 0.692963,
            "ap": 0.642291,
            "ap_weighted": 0.642291
          },
          {
            "accuracy": 0.686035,
            "f1": 0.673905,
            "f1_weighted": 0.67372,
            "ap": 0.651561,
            "ap_weighted": 0.651561
          },
          {
            "accuracy": 0.707031,
            "f1": 0.703858,
            "f1_weighted": 0.703768,
            "ap": 0.65939,
            "ap_weighted": 0.65939
          },
          {
            "accuracy": 0.689453,
            "f1": 0.685693,
            "f1_weighted": 0.685592,
            "ap": 0.642492,
            "ap_weighted": 0.642492
          },
          {
            "accuracy": 0.724121,
            "f1": 0.723907,
            "f1_weighted": 0.723885,
            "ap": 0.66681,
            "ap_weighted": 0.66681
          },
          {
            "accuracy": 0.740723,
            "f1": 0.740695,
            "f1_weighted": 0.740703,
            "ap": 0.678581,
            "ap_weighted": 0.678581
          },
          {
            "accuracy": 0.724121,
            "f1": 0.72249,
            "f1_weighted": 0.722428,
            "ap": 0.673119,
            "ap_weighted": 0.673119
          },
          {
            "accuracy": 0.71875,
            "f1": 0.714965,
            "f1_weighted": 0.714869,
            "ap": 0.673444,
            "ap_weighted": 0.673444
          }
        ],
        "main_score": 0.710449,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.714355,
        "f1": 0.711076,
        "f1_weighted": 0.711025,
        "ap": 0.664425,
        "ap_weighted": 0.664425,
        "scores_per_experiment": [
          {
            "accuracy": 0.714355,
            "f1": 0.714229,
            "f1_weighted": 0.714218,
            "ap": 0.656162,
            "ap_weighted": 0.656162
          },
          {
            "accuracy": 0.691895,
            "f1": 0.685184,
            "f1_weighted": 0.685095,
            "ap": 0.649275,
            "ap_weighted": 0.649275
          },
          {
            "accuracy": 0.691406,
            "f1": 0.68884,
            "f1_weighted": 0.688785,
            "ap": 0.641641,
            "ap_weighted": 0.641641
          },
          {
            "accuracy": 0.693848,
            "f1": 0.681259,
            "f1_weighted": 0.681136,
            "ap": 0.660792,
            "ap_weighted": 0.660792
          },
          {
            "accuracy": 0.712891,
            "f1": 0.710705,
            "f1_weighted": 0.710656,
            "ap": 0.662477,
            "ap_weighted": 0.662477
          },
          {
            "accuracy": 0.708008,
            "f1": 0.704599,
            "f1_weighted": 0.704537,
            "ap": 0.660335,
            "ap_weighted": 0.660335
          },
          {
            "accuracy": 0.725586,
            "f1": 0.725459,
            "f1_weighted": 0.725448,
            "ap": 0.666991,
            "ap_weighted": 0.666991
          },
          {
            "accuracy": 0.751465,
            "f1": 0.751455,
            "f1_weighted": 0.751458,
            "ap": 0.689139,
            "ap_weighted": 0.689139
          },
          {
            "accuracy": 0.719238,
            "f1": 0.717173,
            "f1_weighted": 0.717126,
            "ap": 0.668766,
            "ap_weighted": 0.668766
          },
          {
            "accuracy": 0.734863,
            "f1": 0.731853,
            "f1_weighted": 0.731797,
            "ap": 0.688668,
            "ap_weighted": 0.688668
          }
        ],
        "main_score": 0.714355,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.987491130828857,
  "kg_co2_emissions": 0.0004515034880206797
}