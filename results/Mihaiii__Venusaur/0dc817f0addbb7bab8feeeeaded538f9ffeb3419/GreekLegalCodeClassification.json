{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.050586,
        "f1": 0.032257,
        "f1_weighted": 0.049294,
        "scores_per_experiment": [
          {
            "accuracy": 0.041504,
            "f1": 0.027701,
            "f1_weighted": 0.042728
          },
          {
            "accuracy": 0.049805,
            "f1": 0.035186,
            "f1_weighted": 0.047106
          },
          {
            "accuracy": 0.046387,
            "f1": 0.032741,
            "f1_weighted": 0.043053
          },
          {
            "accuracy": 0.041992,
            "f1": 0.02474,
            "f1_weighted": 0.039671
          },
          {
            "accuracy": 0.054688,
            "f1": 0.035961,
            "f1_weighted": 0.054816
          },
          {
            "accuracy": 0.056641,
            "f1": 0.03499,
            "f1_weighted": 0.059171
          },
          {
            "accuracy": 0.054688,
            "f1": 0.031499,
            "f1_weighted": 0.056067
          },
          {
            "accuracy": 0.054199,
            "f1": 0.033933,
            "f1_weighted": 0.052404
          },
          {
            "accuracy": 0.052246,
            "f1": 0.034831,
            "f1_weighted": 0.04682
          },
          {
            "accuracy": 0.053711,
            "f1": 0.030989,
            "f1_weighted": 0.051102
          }
        ],
        "main_score": 0.050586,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.050586,
        "f1": 0.033104,
        "f1_weighted": 0.04459,
        "scores_per_experiment": [
          {
            "accuracy": 0.047363,
            "f1": 0.032152,
            "f1_weighted": 0.041647
          },
          {
            "accuracy": 0.050293,
            "f1": 0.033264,
            "f1_weighted": 0.045502
          },
          {
            "accuracy": 0.041504,
            "f1": 0.02651,
            "f1_weighted": 0.03421
          },
          {
            "accuracy": 0.05127,
            "f1": 0.037009,
            "f1_weighted": 0.045224
          },
          {
            "accuracy": 0.053223,
            "f1": 0.033285,
            "f1_weighted": 0.049623
          },
          {
            "accuracy": 0.053223,
            "f1": 0.03473,
            "f1_weighted": 0.046723
          },
          {
            "accuracy": 0.057129,
            "f1": 0.037211,
            "f1_weighted": 0.053404
          },
          {
            "accuracy": 0.048828,
            "f1": 0.029232,
            "f1_weighted": 0.043236
          },
          {
            "accuracy": 0.049805,
            "f1": 0.033954,
            "f1_weighted": 0.040877
          },
          {
            "accuracy": 0.053223,
            "f1": 0.033688,
            "f1_weighted": 0.045455
          }
        ],
        "main_score": 0.050586,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 470.1083254814148,
  "kg_co2_emissions": 0.013890007987427538
}