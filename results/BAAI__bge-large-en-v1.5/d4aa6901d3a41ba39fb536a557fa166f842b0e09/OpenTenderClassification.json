{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.1.8",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.313935,
            "f1": 0.297009,
            "f1_weighted": 0.297017,
            "precision": 0.311114,
            "precision_weighted": 0.311122,
            "recall": 0.313951,
            "recall_weighted": 0.313935,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.300111,
            "f1": 0.285232,
            "f1_weighted": 0.28521,
            "precision": 0.298394,
            "precision_weighted": 0.298428,
            "recall": 0.30015,
            "recall_weighted": 0.300111,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.321739,
            "f1": 0.300061,
            "f1_weighted": 0.300101,
            "precision": 0.318658,
            "precision_weighted": 0.318736,
            "recall": 0.32171,
            "recall_weighted": 0.321739,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.315719,
            "f1": 0.299771,
            "f1_weighted": 0.299821,
            "precision": 0.307517,
            "precision_weighted": 0.307529,
            "recall": 0.31564,
            "recall_weighted": 0.315719,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.286511,
            "f1": 0.260037,
            "f1_weighted": 0.260034,
            "precision": 0.288801,
            "precision_weighted": 0.288708,
            "recall": 0.286434,
            "recall_weighted": 0.286511,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.305463,
            "f1": 0.287823,
            "f1_weighted": 0.287791,
            "precision": 0.296117,
            "precision_weighted": 0.296111,
            "recall": 0.305482,
            "recall_weighted": 0.305463,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.296544,
            "f1": 0.274113,
            "f1_weighted": 0.274097,
            "precision": 0.29936,
            "precision_weighted": 0.299381,
            "recall": 0.296532,
            "recall_weighted": 0.296544,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.295652,
            "f1": 0.273772,
            "f1_weighted": 0.273709,
            "precision": 0.287876,
            "precision_weighted": 0.287747,
            "recall": 0.295707,
            "recall_weighted": 0.295652,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.290078,
            "f1": 0.276747,
            "f1_weighted": 0.276717,
            "precision": 0.284382,
            "precision_weighted": 0.284344,
            "recall": 0.290121,
            "recall_weighted": 0.290078,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.301895,
            "f1": 0.275553,
            "f1_weighted": 0.275484,
            "precision": 0.293424,
            "precision_weighted": 0.293322,
            "recall": 0.301905,
            "recall_weighted": 0.301895,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.302765,
        "f1": 0.283012,
        "f1_weighted": 0.282998,
        "precision": 0.298564,
        "precision_weighted": 0.298543,
        "recall": 0.302763,
        "recall_weighted": 0.302765,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.283012,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 99.02468466758728,
  "kg_co2_emissions": null
}