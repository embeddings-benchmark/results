{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.635509,
        "f1": 0.615467,
        "f1_weighted": 0.615665,
        "scores_per_experiment": [
          {
            "accuracy": 0.592689,
            "f1": 0.565808,
            "f1_weighted": 0.566703
          },
          {
            "accuracy": 0.652742,
            "f1": 0.622898,
            "f1_weighted": 0.62775
          },
          {
            "accuracy": 0.592689,
            "f1": 0.572651,
            "f1_weighted": 0.573659
          },
          {
            "accuracy": 0.642298,
            "f1": 0.633954,
            "f1_weighted": 0.633607
          },
          {
            "accuracy": 0.652742,
            "f1": 0.632049,
            "f1_weighted": 0.62923
          },
          {
            "accuracy": 0.689295,
            "f1": 0.674181,
            "f1_weighted": 0.677297
          },
          {
            "accuracy": 0.665796,
            "f1": 0.652192,
            "f1_weighted": 0.653728
          },
          {
            "accuracy": 0.631854,
            "f1": 0.612346,
            "f1_weighted": 0.610774
          },
          {
            "accuracy": 0.652742,
            "f1": 0.641725,
            "f1_weighted": 0.641705
          },
          {
            "accuracy": 0.582245,
            "f1": 0.546862,
            "f1_weighted": 0.542198
          }
        ],
        "main_score": 0.635509,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.586458,
        "f1": 0.575767,
        "f1_weighted": 0.568823,
        "scores_per_experiment": [
          {
            "accuracy": 0.552083,
            "f1": 0.529563,
            "f1_weighted": 0.523727
          },
          {
            "accuracy": 0.625,
            "f1": 0.599976,
            "f1_weighted": 0.603711
          },
          {
            "accuracy": 0.53125,
            "f1": 0.518435,
            "f1_weighted": 0.512522
          },
          {
            "accuracy": 0.65625,
            "f1": 0.66608,
            "f1_weighted": 0.659358
          },
          {
            "accuracy": 0.604167,
            "f1": 0.594479,
            "f1_weighted": 0.583489
          },
          {
            "accuracy": 0.635417,
            "f1": 0.631841,
            "f1_weighted": 0.625928
          },
          {
            "accuracy": 0.583333,
            "f1": 0.584177,
            "f1_weighted": 0.57799
          },
          {
            "accuracy": 0.604167,
            "f1": 0.593113,
            "f1_weighted": 0.582168
          },
          {
            "accuracy": 0.604167,
            "f1": 0.60149,
            "f1_weighted": 0.597137
          },
          {
            "accuracy": 0.46875,
            "f1": 0.438513,
            "f1_weighted": 0.422204
          }
        ],
        "main_score": 0.586458,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 15.633963823318481,
  "kg_co2_emissions": 0.0005076887640601137
}