{
  "dataset_revision": "673a610d6d3dd91a547a0d57ae1b56f37ebbf6a1",
  "evaluation_time": 111.3483555316925,
  "kg_co2_emissions": null,
  "mteb_version": "1.19.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.2205078125,
        "f1": 0.20650702008786012,
        "f1_weighted": 0.20662006217519924,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.2205078125,
        "scores_per_experiment": [
          {
            "accuracy": 0.2392578125,
            "f1": 0.22168764846207664,
            "f1_weighted": 0.22177230750829802
          },
          {
            "accuracy": 0.2080078125,
            "f1": 0.19399134251430677,
            "f1_weighted": 0.19420502031194525
          },
          {
            "accuracy": 0.205078125,
            "f1": 0.19491243876419295,
            "f1_weighted": 0.1949242740415256
          },
          {
            "accuracy": 0.22412109375,
            "f1": 0.20843960462173494,
            "f1_weighted": 0.20854068561036151
          },
          {
            "accuracy": 0.20849609375,
            "f1": 0.19541290523113822,
            "f1_weighted": 0.19547049014321707
          },
          {
            "accuracy": 0.22509765625,
            "f1": 0.20915039429901913,
            "f1_weighted": 0.20924666653914134
          },
          {
            "accuracy": 0.24365234375,
            "f1": 0.23848591838973565,
            "f1_weighted": 0.2387001185754376
          },
          {
            "accuracy": 0.208984375,
            "f1": 0.18786971557855622,
            "f1_weighted": 0.18804177399946814
          },
          {
            "accuracy": 0.2099609375,
            "f1": 0.19498052324534892,
            "f1_weighted": 0.1950464906057493
          },
          {
            "accuracy": 0.232421875,
            "f1": 0.22013970977249192,
            "f1_weighted": 0.2202527944168488
          }
        ]
      }
    ]
  },
  "task_name": "RuSciBenchGRNTIClassification"
}