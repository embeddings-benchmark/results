{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 83.2496771812439,
  "kg_co2_emissions": 0.004515639358471702,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.03515625,
        "f1": 0.02661597842261905,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.02661597842261905,
        "precision": 0.02390252976190476,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0031596472723704866,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0031596472723704866,
        "precision": 0.0027587890624999997,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004763331557765151,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.004763331557765151,
        "precision": 0.004150463043427883,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00021909168144208037,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.00021909168144208037,
        "precision": 0.0001231103151624068,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0014136904761904762,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.0014136904761904762,
        "precision": 0.0012445217225609756,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00014787946428571427,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.00014787946428571427,
        "precision": 7.685908564814814e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005503704737103174,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.005503704737103174,
        "precision": 0.004439540303798116,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0005410684121621622,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0005410684121621622,
        "precision": 0.00035264756944444444,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0034404184626436784,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.0034404184626436784,
        "precision": 0.00297359496124031,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005174699785437431,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.005174699785437431,
        "precision": 0.004419571314102564,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0010009765625,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0010009765625,
        "precision": 0.0009889240506329115,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0038410113205922863,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0038410113205922863,
        "precision": 0.003565615699404762,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.616898148148148e-05,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 3.616898148148148e-05,
        "precision": 1.842570754716981e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006789994487876889,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.006789994487876889,
        "precision": 0.006106021042277064,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000744047619047619,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.000744047619047619,
        "precision": 0.000537109375,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 9.293399419729208e-05,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 9.293399419729208e-05,
        "precision": 4.858519900497512e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002125792572463768,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.002125792572463768,
        "precision": 0.001681857638888889,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013224031120600414,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0013224031120600414,
        "precision": 0.0009867949708410335,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0032958984375,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0032958984375,
        "precision": 0.0028087797619047615,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0010579427083333333,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0010579427083333333,
        "precision": 0.0010190217391304348,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002363711222216925,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.002363711222216925,
        "precision": 0.0019212744671384706,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.02169879722104586,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.02169879722104586,
        "precision": 0.019830242999188313,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.007268067246087031,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.007268067246087031,
        "precision": 0.0064036954784025095,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008069816468253967,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.008069816468253967,
        "precision": 0.007164649714052288,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.5236046092073124e-05,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 3.5236046092073124e-05,
        "precision": 1.7904565903523647e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.006631324404761905,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.006631324404761905,
        "precision": 0.006327550551470588,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010622662609027667,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0010622662609027667,
        "precision": 0.0010203407863064475,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.017433443547873694,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.017433443547873694,
        "precision": 0.015300060453869047,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0022865993109559284,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0022865993109559284,
        "precision": 0.0021292534221065114,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005199878246753247,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.005199878246753247,
        "precision": 0.004762620192307693,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0077148437499999995,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0077148437499999995,
        "precision": 0.0065266927083333336,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.759572072072072e-05,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 1.759572072072072e-05,
        "precision": 8.877840909090909e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012677135393268943,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.012677135393268943,
        "precision": 0.011177486250728438,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009951636904761904,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0009951636904761904,
        "precision": 0.0009859525240384615,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.010757551995473458,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.010757551995473458,
        "precision": 0.01005093443627451,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011366011705685618,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0011366011705685618,
        "precision": 0.0010600142045454545,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0011067708333333333,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0011067708333333333,
        "precision": 0.0010463169642857143,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.00900006882737146,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.00900006882737146,
        "precision": 0.008003817471590909,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004910634793447293,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0004910634793447293,
        "precision": 0.0003269139324774132,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.008328733582427535,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.008328733582427535,
        "precision": 0.0076068956187490665,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002094690571253071,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.002094690571253071,
        "precision": 0.002026754712301587,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 9.217095418968692e-05,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 9.217095418968692e-05,
        "precision": 4.7884586352657005e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007740162037037037,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.007740162037037037,
        "precision": 0.007041537686713836,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0030393016581632655,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0030393016581632655,
        "precision": 0.002693232783564815,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.007242838541666667,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.007242838541666667,
        "precision": 0.006585427989130435,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.2578125,
        "f1": 0.24298354640151515,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.24298354640151515,
        "precision": 0.23691406250000002,
        "recall": 0.2578125
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.038286916778518656,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.038286916778518656,
        "precision": 0.0362902597052797,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.2333984375,
        "f1": 0.2176756966991342,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2176756966991342,
        "precision": 0.2117142288773148,
        "recall": 0.2333984375
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.019768151313689964,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.019768151313689964,
        "precision": 0.01603789500995683,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.244140625,
        "f1": 0.21884748823225386,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.21884748823225386,
        "precision": 0.21009970660849564,
        "recall": 0.244140625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009819728185595567,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0009819728185595567,
        "precision": 0.000979275173611111,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.185546875,
        "f1": 0.16966228392964977,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.16966228392964977,
        "precision": 0.1636755741003788,
        "recall": 0.185546875
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.03036671119678932,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.03036671119678932,
        "precision": 0.02723625658195971,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.11202017121403461,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11202017121403461,
        "precision": 0.10363261137728833,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.01952011376096491,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.01952011376096491,
        "precision": 0.01767423115079365,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009801136363636364,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0009801136363636364,
        "precision": 0.0009783413023679416,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018653492774586524,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.018653492774586524,
        "precision": 0.015741644965277777,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001181056356837607,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.001181056356837607,
        "precision": 0.0010858444940476189,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1767578125,
        "f1": 0.16444991437056866,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.16444991437056866,
        "precision": 0.16077705136921866,
        "recall": 0.1767578125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02103410891868709,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.02103410891868709,
        "precision": 0.01806347542431527,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.001255580357142857,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001255580357142857,
        "precision": 0.0011393229166666667,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.2490234375,
        "f1": 0.23204171316964284,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.23204171316964284,
        "precision": 0.22588630445075755,
        "recall": 0.2490234375
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.13106590846105648,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.13106590846105648,
        "precision": 0.12215944320436506,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.14815061240842492,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.14815061240842492,
        "precision": 0.13940686677631578,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.1943359375,
        "f1": 0.17747354245305844,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.17747354245305844,
        "precision": 0.1717168497921798,
        "recall": 0.1943359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005798815450193697,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.005798815450193697,
        "precision": 0.00542659922542735,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00803422071186469,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00803422071186469,
        "precision": 0.007378472222222222,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.2529296875,
        "f1": 0.23330853174603175,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.23330853174603175,
        "precision": 0.22560492621527778,
        "recall": 0.2529296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.037397633903355286,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.037397633903355286,
        "precision": 0.035241206850815616,
        "recall": 0.046875
      },
      {
        "accuracy": 0.2744140625,
        "f1": 0.2568293848079004,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2568293848079004,
        "precision": 0.25020289450698757,
        "recall": 0.2744140625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016497811547253736,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.016497811547253736,
        "precision": 0.012859133596438282,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.3369140625,
        "f1": 0.29864760890151515,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.29864760890151515,
        "precision": 0.28467843191964287,
        "recall": 0.3369140625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00107421875,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.00107421875,
        "precision": 0.0007349917763157894,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.17553663784132534,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.17553663784132534,
        "precision": 0.16796642485119045,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.08681124918917887,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.08681124918917887,
        "precision": 0.07761545898450589,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.11059470170694406,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11059470170694406,
        "precision": 0.10150463447126881,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.04765953256302521,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.04765953256302521,
        "precision": 0.043290201822916666,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011121346786437246,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0011121346786437246,
        "precision": 0.0010467810107271482,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.049796097712285665,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.049796097712285665,
        "precision": 0.04277318411839896,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0021190502025462965,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0021190502025462965,
        "precision": 0.0016749648900606564,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.16832189907212886,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.16832189907212886,
        "precision": 0.164794921875,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.03300263997644512,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.03300263997644512,
        "precision": 0.028072465999712092,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003639363354037267,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0003639363354037267,
        "precision": 0.0002071496212121212,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.2919921875,
        "f1": 0.26586301068722945,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.26586301068722945,
        "precision": 0.2558856670673077,
        "recall": 0.2919921875
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.133154296875,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.133154296875,
        "precision": 0.12354857684576023,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.18359375,
        "f1": 0.1579283840360115,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1579283840360115,
        "precision": 0.14859899215367967,
        "recall": 0.18359375
      },
      {
        "accuracy": 0.2138671875,
        "f1": 0.19698342177415837,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.19698342177415837,
        "precision": 0.19097321309446158,
        "recall": 0.2138671875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003197079613095238,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.0003197079613095238,
        "precision": 0.00018353834219858155,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0031899858761072,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.0031899858761072,
        "precision": 0.0027460515401104063,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.09539849211819665,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.09539849211819665,
        "precision": 0.08400618966030877,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.11395830648418115,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.11395830648418115,
        "precision": 0.1014297269913124,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.17578125,
        "f1": 0.12024610556972037,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.12024610556972037,
        "precision": 0.10675022087160184,
        "recall": 0.17578125
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.007123491985805376,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.007123491985805376,
        "precision": 0.004670179681648951,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.162109375,
        "f1": 0.1107021192229217,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.1107021192229217,
        "precision": 0.10001326029727908,
        "recall": 0.162109375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.000887945112159271,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.000887945112159271,
        "precision": 0.0005107527623293314,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1435546875,
        "f1": 0.09528202237332672,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.09528202237332672,
        "precision": 0.08424672470139802,
        "recall": 0.1435546875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004365355781371406,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.004365355781371406,
        "precision": 0.0039012303645367973,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.059475944277506194,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.059475944277506194,
        "precision": 0.04864069464321315,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.008166222070030664,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.008166222070030664,
        "precision": 0.007052288846486175,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005645356612391673,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0005645356612391673,
        "precision": 0.00031501538825757575,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006950224837351702,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.006950224837351702,
        "precision": 0.006332470469497607,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0019362629452187377,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0019362629452187377,
        "precision": 0.0012611516552643784,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.09768956884318732,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.09768956884318732,
        "precision": 0.08529437126352077,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0031961495535714284,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.0031961495535714284,
        "precision": 0.0024499474035579944,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00045980046948356813,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.00045980046948356813,
        "precision": 0.00027916381242994143,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.158203125,
        "f1": 0.11319498160774918,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.11319498160774918,
        "precision": 0.10311505561526738,
        "recall": 0.158203125
      },
      {
        "accuracy": 0.134765625,
        "f1": 0.08405860225928585,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.08405860225928585,
        "precision": 0.07248844586984449,
        "recall": 0.134765625
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.07664366578631468,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.07664366578631468,
        "precision": 0.06112307230994451,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.10223573265565453,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.10223573265565453,
        "precision": 0.09000939026509516,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.00187183356282344,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.00187183356282344,
        "precision": 0.001277136335387672,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005268893722987233,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.005268893722987233,
        "precision": 0.004813467471294053,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.2294921875,
        "f1": 0.195586129931908,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.195586129931908,
        "precision": 0.18525781268282143,
        "recall": 0.2294921875
      },
      {
        "accuracy": 0.259765625,
        "f1": 0.23019433366113057,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.23019433366113057,
        "precision": 0.21992868195738438,
        "recall": 0.259765625
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.030748285949208698,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.030748285949208698,
        "precision": 0.02942775084420488,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.021326085715719038,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.021326085715719038,
        "precision": 0.01726033416083621,
        "recall": 0.046875
      },
      {
        "accuracy": 0.2587890625,
        "f1": 0.22230159441348094,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.22230159441348094,
        "precision": 0.21119229051113814,
        "recall": 0.2587890625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.1962890625,
        "f1": 0.16891918344943893,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.16891918344943893,
        "precision": 0.15979956290288566,
        "recall": 0.1962890625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02428087409112077,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.02428087409112077,
        "precision": 0.02129888656299154,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.11374559504442316,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11374559504442316,
        "precision": 0.10344277209080746,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.21484375,
        "f1": 0.16713222306484024,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.16713222306484024,
        "precision": 0.15227189484258946,
        "recall": 0.21484375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006935124902233621,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0006935124902233621,
        "precision": 0.0005099336146670014,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013068637092074592,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.013068637092074592,
        "precision": 0.01041050469157083,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0036453726684968326,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0036453726684968326,
        "precision": 0.0031493270248440283,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.201171875,
        "f1": 0.18321247959189693,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.18321247959189693,
        "precision": 0.1772673694968937,
        "recall": 0.201171875
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.02275234205898268,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.02275234205898268,
        "precision": 0.018989097943334206,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011393229166666667,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0011393229166666667,
        "precision": 0.0010624445921985815,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2578125,
        "f1": 0.21848655359397548,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.21848655359397548,
        "precision": 0.20729378942398063,
        "recall": 0.2578125
      },
      {
        "accuracy": 0.173828125,
        "f1": 0.13916609612595038,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.13916609612595038,
        "precision": 0.127660517179454,
        "recall": 0.173828125
      },
      {
        "accuracy": 0.18359375,
        "f1": 0.15726143973214285,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.15726143973214285,
        "precision": 0.1476429666139781,
        "recall": 0.18359375
      },
      {
        "accuracy": 0.2197265625,
        "f1": 0.19046028926528516,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.19046028926528516,
        "precision": 0.1813713505839908,
        "recall": 0.2197265625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0002755301339285714,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.0002755301339285714,
        "precision": 0.00015540898949803147,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.03040745062229437,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.03040745062229437,
        "precision": 0.029794115538990827,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.027351065074906363,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.027351065074906363,
        "precision": 0.026859140037593984,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008725967721193415,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.008725967721193415,
        "precision": 0.008166153298074722,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.02437345568830374,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.02437345568830374,
        "precision": 0.024082299376468816,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.029470796130952378,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.029470796130952378,
        "precision": 0.02913972701149425,
        "recall": 0.03125
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.060353887648809515,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.060353887648809515,
        "precision": 0.05417596726190476,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.021815276342975205,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.021815276342975205,
        "precision": 0.021161551853130754,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00048828125,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.00048828125,
        "precision": 0.0003255208333333333,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.05345989188762627,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.05345989188762627,
        "precision": 0.051050967261904764,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011354069595052524,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.0011354069595052524,
        "precision": 0.0010622637813421827,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.006325266917164733,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.006325266917164733,
        "precision": 0.005841164044289044,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019761853799739075,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.0019761853799739075,
        "precision": 0.0019647497208348003,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004289650101107615,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.004289650101107615,
        "precision": 0.0037349241492961108,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.04448702339327339,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.04448702339327339,
        "precision": 0.043087332589285716,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.438920454545455e-05,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 4.438920454545455e-05,
        "precision": 2.2710755813953488e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006608851104122486,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.006608851104122486,
        "precision": 0.005630611920248868,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.02657295098642426,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.02657295098642426,
        "precision": 0.025933230181277054,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.02746341807995277,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.02746341807995277,
        "precision": 0.02709604179714204,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.06771453373015873,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.06771453373015873,
        "precision": 0.06348812862484737,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.020195855618871755,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.020195855618871755,
        "precision": 0.02002633940430111,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004526289682539682,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.004526289682539682,
        "precision": 0.003957434836915535,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.008502034560833902,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.008502034560833902,
        "precision": 0.007929098630790632,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.2509765625,
        "f1": 0.2307043650793651,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2307043650793651,
        "precision": 0.22191569010416665,
        "recall": 0.2509765625
      },
      {
        "accuracy": 0.34765625,
        "f1": 0.31233956473214286,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.31233956473214286,
        "precision": 0.2989216096594888,
        "recall": 0.34765625
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.03043748984952796,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.03043748984952796,
        "precision": 0.02821144527446446,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.2705078125,
        "f1": 0.25825105883699634,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.25825105883699634,
        "precision": 0.25365668402777775,
        "recall": 0.2705078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.0201453250580485,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0201453250580485,
        "precision": 0.015572288101317559,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 9.765625e-05,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 9.765625e-05,
        "precision": 5.139802631578947e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.185546875,
        "f1": 0.16851981026785712,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.16851981026785712,
        "precision": 0.16207778362662836,
        "recall": 0.185546875
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.11314442514695272,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.11314442514695272,
        "precision": 0.10100291233232228,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.10785900297619047,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.10785900297619047,
        "precision": 0.09900269001831502,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.072265625,
        "f1": 0.05858469415726816,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.05858469415726816,
        "precision": 0.05442206301581301,
        "recall": 0.072265625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006979339248343215,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0006979339248343215,
        "precision": 0.0005121863832638475,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.06112846571830947,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.06112846571830947,
        "precision": 0.053121512276785715,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0033555544613678807,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0033555544613678807,
        "precision": 0.002780877976190476,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.171875,
        "f1": 0.15715396824645017,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.15715396824645017,
        "precision": 0.1530646889032477,
        "recall": 0.171875
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.04433875215382205,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.04433875215382205,
        "precision": 0.03984407790560134,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00033743013211382113,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00033743013211382113,
        "precision": 0.0002013036809815951,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.314453125,
        "f1": 0.2903262183779762,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2903262183779762,
        "precision": 0.2814654637896825,
        "recall": 0.314453125
      },
      {
        "accuracy": 0.15625,
        "f1": 0.12889320192063294,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.12889320192063294,
        "precision": 0.11961381505580229,
        "recall": 0.15625
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.15027407488344988,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.15027407488344988,
        "precision": 0.14173322268681535,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.201171875,
        "f1": 0.18291529528650224,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.18291529528650224,
        "precision": 0.17713992956912877,
        "recall": 0.201171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.3460083981259967e-05,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 2.3460083981259967e-05,
        "precision": 1.1839609256768118e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009985077247191012,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0009985077247191012,
        "precision": 0.0009876598011363637,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002585790904679079,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.002585790904679079,
        "precision": 0.0023262470032076933,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016863683201821917,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.0016863683201821917,
        "precision": 0.001426414207175926,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003274996833839919,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0003274996833839919,
        "precision": 0.00019630292849898582,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.593039772727273e-05,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 5.593039772727273e-05,
        "precision": 2.8604160817892568e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.0538907490079365,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.0538907490079365,
        "precision": 0.04589865786283344,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006574876237623762,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0006574876237623762,
        "precision": 0.0004915149006622517,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005120643481449184,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0005120643481449184,
        "precision": 0.0003374958871019517,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 7.971938775510205e-06,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 7.971938775510205e-06,
        "precision": 4.002305327868853e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.03776429191468254,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.03776429191468254,
        "precision": 0.032126581101190474,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007258956740333209,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.0007258956740333209,
        "precision": 0.0004520255969761042,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007154035553835699,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.007154035553835699,
        "precision": 0.006074450212317934,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0025102165362112586,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.0025102165362112586,
        "precision": 0.002036361791032953,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005519008985805861,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.005519008985805861,
        "precision": 0.004976523042929293,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.009013410819012548,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.009013410819012548,
        "precision": 0.007395290020969368,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005549355158730159,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0005549355158730159,
        "precision": 0.0003594812488590726,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010110374778917977,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.010110374778917977,
        "precision": 0.008359142070654019,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00344237806559504,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.00344237806559504,
        "precision": 0.0030273802615590727,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009841622081712062,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.0009841622081712062,
        "precision": 0.000980377197265625,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.06297827606421356,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.06297827606421356,
        "precision": 0.054020929285175615,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009822901392961877,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.0009822901392961877,
        "precision": 0.0009794347426470588,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0018618389852812648,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0018618389852812648,
        "precision": 0.0011299530080494257,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00218004604468599,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.00218004604468599,
        "precision": 0.0017935862732546466,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.15533239093365322,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.15533239093365322,
        "precision": 0.14869935310429244,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.205078125,
        "f1": 0.18100811446175136,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.18100811446175136,
        "precision": 0.17433654405352117,
        "recall": 0.205078125
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.02444625753801052,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.02444625753801052,
        "precision": 0.023496318358567057,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.1943359375,
        "f1": 0.17296723874337488,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.17296723874337488,
        "precision": 0.1664174809006252,
        "recall": 0.1943359375
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.014258633470338658,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.014258633470338658,
        "precision": 0.011748294329753217,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.185546875,
        "f1": 0.15406576818427692,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.15406576818427692,
        "precision": 0.14485195736737677,
        "recall": 0.185546875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008953190651260505,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0008953190651260505,
        "precision": 0.0005779374117231637,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004944929773969085,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.004944929773969085,
        "precision": 0.0042650982833932465,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08744177949757205,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.08744177949757205,
        "precision": 0.0806356976041513,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.010654387556915551,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.010654387556915551,
        "precision": 0.009718934778919868,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 6.554110738255033e-06,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 6.554110738255033e-06,
        "precision": 3.2880892255892254e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.00680002167632376,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.00680002167632376,
        "precision": 0.00619275327224939,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.4293084239582296e-05,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 2.4293084239582296e-05,
        "precision": 1.223333950700431e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1826171875,
        "f1": 0.15763516067530653,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.15763516067530653,
        "precision": 0.15104263547867064,
        "recall": 0.1826171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004099974408166044,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.004099974408166044,
        "precision": 0.0032902066105191105,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.520823822877266e-05,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 1.520823822877266e-05,
        "precision": 7.638019395588505e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.19921875,
        "f1": 0.16824495884977755,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.16824495884977755,
        "precision": 0.1595773023092359,
        "recall": 0.19921875
      },
      {
        "accuracy": 0.140625,
        "f1": 0.11313999525262546,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.11313999525262546,
        "precision": 0.10462940890694318,
        "recall": 0.140625
      },
      {
        "accuracy": 0.154296875,
        "f1": 0.12732647260045826,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.12732647260045826,
        "precision": 0.11954497718565847,
        "recall": 0.154296875
      },
      {
        "accuracy": 0.384765625,
        "f1": 0.351365574529637,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.351365574529637,
        "precision": 0.34112025669642854,
        "recall": 0.384765625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003693843049311799,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.003693843049311799,
        "precision": 0.0026063861268939394,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.008581955766908213,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.008581955766908213,
        "precision": 0.007993952789449112,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.03309480042016807,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.03309480042016807,
        "precision": 0.029309082031249996,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.08092311143207283,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.08092311143207283,
        "precision": 0.07296256396598194,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.1318204168646708e-05,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 1.1318204168646708e-05,
        "precision": 5.679083546320576e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.029599119622762717,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.029599119622762717,
        "precision": 0.02608024366389638,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0002917778201219512,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0002917778201219512,
        "precision": 0.00016392299107142856,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.11033671731913919,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.11033671731913919,
        "precision": 0.09938538566468254,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.027061855670103e-06,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 4.027061855670103e-06,
        "precision": 2.0176911157024794e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005028161337209302,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.005028161337209302,
        "precision": 0.004589539787431604,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013221153846153847,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0013221153846153847,
        "precision": 0.0011664496527777778,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.04374523046398046,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.04374523046398046,
        "precision": 0.04147061434659091,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.09250139508928572,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.09250139508928572,
        "precision": 0.08370845734126985,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0013671875,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0013671875,
        "precision": 0.001220703125,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000982517149390244,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.000982517149390244,
        "precision": 0.0009795489296636085,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.036778428819444445,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.036778428819444445,
        "precision": 0.03282102554563492,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.001953125,
        "f1": 8.372426719756015e-05,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 8.372426719756015e-05,
        "precision": 4.338357300884956e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.040488305725250626,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.040488305725250626,
        "precision": 0.036394391741071425,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0035379584035867564,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0035379584035867564,
        "precision": 0.0030390956270149984,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.002025462962962963,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.002025462962962963,
        "precision": 0.001990685096153846,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006983938638739546,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.006983938638739546,
        "precision": 0.006607897433737646,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 9.902196348585666e-05,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 9.902196348585666e-05,
        "precision": 5.082579938246335e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.1162109375,
        "f1": 0.10076064279878619,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.10076064279878619,
        "precision": 0.09552970046191554,
        "recall": 0.1162109375
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.09896193899887853,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.09896193899887853,
        "precision": 0.09401768275669642,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.05250201899566577,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.05250201899566577,
        "precision": 0.04955875016910173,
        "recall": 0.0625
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.10409587880291005,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.10409587880291005,
        "precision": 0.10033624920562556,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.039422123015873015,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.039422123015873015,
        "precision": 0.03286623268790388,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.08895184019713559,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.08895184019713559,
        "precision": 0.08257813943551368,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.03258691178613053,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.03258691178613053,
        "precision": 0.028794642857142855,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.08503974083915242,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.08503974083915242,
        "precision": 0.07988548556390598,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001172059561776518,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.001172059561776518,
        "precision": 0.0010794058357048283,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 5.236260053619303e-06,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 5.236260053619303e-06,
        "precision": 2.6251680107526884e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005033240830588606,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.005033240830588606,
        "precision": 0.004575029032868473,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004099421077504726,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.0004099421077504726,
        "precision": 0.000253865679221652,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002615049482150815,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.002615049482150815,
        "precision": 0.0023381193230855492,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.140737640542328,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.140737640542328,
        "precision": 0.13466681159552255,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012971347548322413,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0012971347548322413,
        "precision": 0.001151095349681793,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004623616137732867,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.004623616137732867,
        "precision": 0.00411912683481977,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.10007258740421456,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.10007258740421456,
        "precision": 0.09565150019251581,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.121285979916351,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.121285979916351,
        "precision": 0.11710288635301927,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.201171875,
        "f1": 0.17779095362103176,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.17779095362103176,
        "precision": 0.16862095424107143,
        "recall": 0.201171875
      },
      {
        "accuracy": 0.099609375,
        "f1": 0.08535350913621262,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.08535350913621262,
        "precision": 0.0806046796687155,
        "recall": 0.099609375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0012407065781950893,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0012407065781950893,
        "precision": 0.0008152158079565695,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.009173179279376076,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.009173179279376076,
        "precision": 0.008046816467939175,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.011066641847914194,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.011066641847914194,
        "precision": 0.008644489326862372,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.02777086856884494,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.02777086856884494,
        "precision": 0.02477771823146621,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 9.014155081821002e-05,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 9.014155081821002e-05,
        "precision": 4.685049975856363e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2021484375,
        "f1": 0.15527498759920633,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.15527498759920633,
        "precision": 0.13887261284722222,
        "recall": 0.2021484375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002021985176282051,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.002021985176282051,
        "precision": 0.0016857328869047618,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.035576527232057654,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.035576527232057654,
        "precision": 0.030794167585640325,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0003255208333333333,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0003255208333333333,
        "precision": 0.0001953125,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0082780406337614,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0082780406337614,
        "precision": 0.007232806096311475,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03185386586293426,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.03185386586293426,
        "precision": 0.026918129090138784,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0013205104484975809,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0013205104484975809,
        "precision": 0.0008397160947712418,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009794689360119048,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0009794689360119048,
        "precision": 0.0009780178837555888,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.025942380220316533,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.025942380220316533,
        "precision": 0.02141169557912086,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0027484575415945814,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0027484575415945814,
        "precision": 0.0020850976897004484,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.5903033088235294e-06,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 3.5903033088235294e-06,
        "precision": 1.7984576427255986e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.030216517478150684,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.030216517478150684,
        "precision": 0.025221386204690915,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011421658933770014,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0011421658933770014,
        "precision": 0.0008152256438289601,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.026848760132776185,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.026848760132776185,
        "precision": 0.023399579207684675,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.008406575520833333,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.008406575520833333,
        "precision": 0.007280371215973091,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00039961754169603005,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.00039961754169603005,
        "precision": 0.00022225651716321245,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.011055025703463204,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.011055025703463204,
        "precision": 0.009463922764227643,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001501398138661202,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.001501398138661202,
        "precision": 0.001087074706251426,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010521180454940598,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0010521180454940598,
        "precision": 0.0010155602490204943,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0017903645833333333,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0017903645833333333,
        "precision": 0.0014973958333333332,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.52587890625e-05,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 1.52587890625e-05,
        "precision": 7.689468503937008e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00029538530515093014,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.00029538530515093014,
        "precision": 0.00017099160548365687,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.009751382132930019,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.009751382132930019,
        "precision": 0.008888478322072072,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00019884657931964732,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.00019884657931964732,
        "precision": 0.00010700254840879841,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012212815766550523,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.012212815766550523,
        "precision": 0.01030544704861111,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 8.346688034188035e-06,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 8.346688034188035e-06,
        "precision": 4.191255364806867e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0014105902777777778,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0014105902777777778,
        "precision": 0.0012428977272727273,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0047953287760416664,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0047953287760416664,
        "precision": 0.00448102435100349,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.000244140625,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.000244140625,
        "precision": 0.00013950892857142856,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0016490670787545788,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0016490670787545788,
        "precision": 0.0014756944444444444,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0031821287153482396,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0031821287153482396,
        "precision": 0.0030618644516175898,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009016927083333333,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.009016927083333333,
        "precision": 0.007893880208333332,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0556640625,
        "f1": 0.03409945631625319,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.03409945631625319,
        "precision": 0.02800447978670635,
        "recall": 0.0556640625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00020248219496788198,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.00020248219496788198,
        "precision": 0.00011020209655035686,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007747884741061497,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.007747884741061497,
        "precision": 0.007364386980511375,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006804230925324676,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.006804230925324676,
        "precision": 0.0055575284090909095,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.009914302917467728,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.009914302917467728,
        "precision": 0.009465044155683108,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.024269903273809523,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.024269903273809523,
        "precision": 0.02224934895833333,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.0615234375,
        "f1": 0.05075334821428571,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.05075334821428571,
        "precision": 0.047097439236111115,
        "recall": 0.0615234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00045110542952902247,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00045110542952902247,
        "precision": 0.0002562143779314657,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.019645182291666667,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.019645182291666667,
        "precision": 0.019031174516908212,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013978247549019606,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0013978247549019606,
        "precision": 0.0009605448082010581,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.054121713789682536,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.054121713789682536,
        "precision": 0.048739085477941174,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.008414371039640435,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.008414371039640435,
        "precision": 0.007903437253807773,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.0939476376488095,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.0939476376488095,
        "precision": 0.08636183965773808,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0026041666666666665,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.00244140625,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.04390021685072055,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.04390021685072055,
        "precision": 0.04197677399366278,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010101429857081452,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0010101429857081452,
        "precision": 0.000993502869897959,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0027262369791666665,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0027262369791666665,
        "precision": 0.002506510416666667,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00013584701530018942,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.00013584701530018942,
        "precision": 6.94217708096673e-05,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.039325241815476183,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.039325241815476183,
        "precision": 0.03635370163690476,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.2895172395529895e-05,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 3.2895172395529895e-05,
        "precision": 1.6623235832794655e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02150806721376211,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.02150806721376211,
        "precision": 0.018389494391755905,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0073893229166666664,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0073893229166666664,
        "precision": 0.006917317708333333,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008183396464646464,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.008183396464646464,
        "precision": 0.007411411830357142,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00034691476733980767,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.00034691476733980767,
        "precision": 0.00019716205018939395,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017686332201503991,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.0017686332201503991,
        "precision": 0.0014361594003512068,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0017903645833333333,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.0017903645833333333,
        "precision": 0.001553622159090909,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00068359375,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.00068359375,
        "precision": 0.00043402777777777775,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003298323675496689,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0003298323675496689,
        "precision": 0.0001974730365044248,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.000244140625,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.000244140625,
        "precision": 0.00013950892857142856,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.010501236862071817,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.010501236862071817,
        "precision": 0.00863268083330543,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0024088541666666668,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.0024088541666666668,
        "precision": 0.002218191964285714,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.017393052669437338,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.017393052669437338,
        "precision": 0.015674109961219335,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 6.740587151980883e-05,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 6.740587151980883e-05,
        "precision": 3.424691020025032e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00039558217005076146,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.00039558217005076146,
        "precision": 0.0002466255168575064,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004803757440476191,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.004803757440476191,
        "precision": 0.0035671805507561907,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0027180989583333332,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0027180989583333332,
        "precision": 0.0024296120169082125,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003758101790224591,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.003758101790224591,
        "precision": 0.003197662611853607,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0018736268124445836,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.0018736268124445836,
        "precision": 0.001515355603448276,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0021094798160992234,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.0021094798160992234,
        "precision": 0.001755685517282197,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002816642381633674,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.002816642381633674,
        "precision": 0.0024392141780698764,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.00394766081823222,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.00394766081823222,
        "precision": 0.0033618235095949304,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.002130681818181818,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.002130681818181818,
        "precision": 0.00205078125,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00021464450647918392,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.00021464450647918392,
        "precision": 0.00011418962038866928,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.012698743722006859,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.012698743722006859,
        "precision": 0.010404341679834901,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012121775793650794,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.0012121775793650794,
        "precision": 0.0011080228365384615,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.326999060565871e-05,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 2.326999060565871e-05,
        "precision": 1.1731333329604939e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.001953125,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.001953125,
        "precision": 0.001953125,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.17297186993442382,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.17297186993442382,
        "precision": 0.1666164822048611,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.2041015625,
        "f1": 0.18346300292760598,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.18346300292760598,
        "precision": 0.17581898844553487,
        "recall": 0.2041015625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.0777281379020523,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.0777281379020523,
        "precision": 0.07492188867734594,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.201171875,
        "f1": 0.18456678784944974,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.18456678784944974,
        "precision": 0.17850674802870015,
        "recall": 0.201171875
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.0364832983155019,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.0364832983155019,
        "precision": 0.03045452133586899,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.18359375,
        "f1": 0.16128634732622887,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.16128634732622887,
        "precision": 0.1537091515161318,
        "recall": 0.18359375
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.013878742784992786,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.013878742784992786,
        "precision": 0.011694417385581734,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.14556946417297978,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.14556946417297978,
        "precision": 0.13747929910289924,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00043790302579365076,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.00043790302579365076,
        "precision": 0.00025352274719495093,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1708984375,
        "f1": 0.14316313244047618,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.14316313244047618,
        "precision": 0.1333926246279762,
        "recall": 0.1708984375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012819320436507937,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.0012819320436507937,
        "precision": 0.0011416936566293182,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.007473451028138528,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.007473451028138528,
        "precision": 0.006616886279130352,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002226916188869009,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.002226916188869009,
        "precision": 0.00210757939375172,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006787673047438672,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.006787673047438672,
        "precision": 0.005950646743957247,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00032720162717864924,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.00032720162717864924,
        "precision": 0.0001732570659357916,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0053727386691046096,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0053727386691046096,
        "precision": 0.005144927002600893,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.1962890625,
        "f1": 0.17612761699507387,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.17612761699507387,
        "precision": 0.16828031994047618,
        "recall": 0.1962890625
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.14348863979468598,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.14348863979468598,
        "precision": 0.13608359685019839,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.2197265625,
        "f1": 0.19102260044642855,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.19102260044642855,
        "precision": 0.18004216601413292,
        "recall": 0.2197265625
      },
      {
        "accuracy": 0.1689453125,
        "f1": 0.14889001899499946,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.14889001899499946,
        "precision": 0.14219710305361982,
        "recall": 0.1689453125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005255014481846378,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.005255014481846378,
        "precision": 0.004466968578296703,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007209915290794337,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.007209915290794337,
        "precision": 0.00675547902584947,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02371884300595238,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.02371884300595238,
        "precision": 0.020915078430301316,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03528645833333333,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.03528645833333333,
        "precision": 0.031105840773809523,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.9064360119047617e-06,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 2.9064360119047617e-06,
        "precision": 1.4553837555886736e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.02672991071428571,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.02672991071428571,
        "precision": 0.023298413825757574,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 9.390024038461539e-06,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 9.390024038461539e-06,
        "precision": 4.717693236714976e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03330638896183473,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.03330638896183473,
        "precision": 0.02793724423363095,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0010134139150943396,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0010134139150943396,
        "precision": 0.000995342548076923,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0027448381696428574,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0027448381696428574,
        "precision": 0.0019368489583333334,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04510175696699134,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.04510175696699134,
        "precision": 0.040276227678571426,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0556640625,
        "f1": 0.043895816343395205,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.043895816343395205,
        "precision": 0.040524422409188035,
        "recall": 0.0556640625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009835881294964028,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0009835881294964028,
        "precision": 0.0009800879963898917,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03722563244047619,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.03722563244047619,
        "precision": 0.03162899925595238,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00026555646929824557,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.00026555646929824557,
        "precision": 0.0001430318813131313,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.1787405303030304e-05,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 5.1787405303030304e-05,
        "precision": 2.6423921213193033e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0002536855144063342,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0002536855144063342,
        "precision": 0.00014060844809322034,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.025999221303104572,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.025999221303104572,
        "precision": 0.023143949962797616,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0018212495788409704,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0018212495788409704,
        "precision": 0.0011926741750088684,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00048828125,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.00048828125,
        "precision": 0.0003255208333333333,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004024057539682539,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.004024057539682539,
        "precision": 0.0036642970150089606,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.001953125,
        "f1": 4.679361979166667e-05,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 4.679361979166667e-05,
        "precision": 2.3892971837944664e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.003435202205882353,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.003435202205882353,
        "precision": 0.00323486328125,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001210860680924287,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.001210860680924287,
        "precision": 0.0011073521205357143,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010135987418412916,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.0010135987418412916,
        "precision": 0.0009953004639355742,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012755102040816328,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0012755102040816328,
        "precision": 0.001149390571305842,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.009931495488322718,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.009931495488322718,
        "precision": 0.009116140849282296,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.012043745799731182,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.012043745799731182,
        "precision": 0.01100356825275842,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.1355377906976744e-05,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 1.1355377906976744e-05,
        "precision": 5.710891812865497e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0024577809343434343,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.0024577809343434343,
        "precision": 0.0020477664812752513,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010108821838889332,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0010108821838889332,
        "precision": 0.0009938247151797175,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.036532033504689754,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.036532033504689754,
        "precision": 0.03168364025297619,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00439453125,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.00439453125,
        "precision": 0.004231770833333333,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.004077690972222222,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.004077690972222222,
        "precision": 0.00374784923735119,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004422637391685579,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.004422637391685579,
        "precision": 0.004245926134877028,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00234375,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.00234375,
        "precision": 0.002197265625,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012441998961343931,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0012441998961343931,
        "precision": 0.001122249149526965,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0002868322567528099,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0002868322567528099,
        "precision": 0.00016102758517721604,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0047888682130370255,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0047888682130370255,
        "precision": 0.003944696614191904,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010945048309178745,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0010945048309178745,
        "precision": 0.0010387479476013707,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0031808035714285714,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0031808035714285714,
        "precision": 0.002491516914868668,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006310223950026581,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.006310223950026581,
        "precision": 0.005569442620798319,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.2509765625,
        "f1": 0.23115776909722222,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.23115776909722222,
        "precision": 0.22328330035849564,
        "recall": 0.2509765625
      },
      {
        "accuracy": 0.302734375,
        "f1": 0.27821413070436507,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.27821413070436507,
        "precision": 0.2690061538938492,
        "recall": 0.302734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03101442477247622,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.03101442477247622,
        "precision": 0.028948756435811553,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.2841796875,
        "f1": 0.2725131810349738,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2725131810349738,
        "precision": 0.2684942755255255,
        "recall": 0.2841796875
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.020115395895209772,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.020115395895209772,
        "precision": 0.016397524993070144,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.3154296875,
        "f1": 0.2837351905906593,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2837351905906593,
        "precision": 0.2729465060763889,
        "recall": 0.3154296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.18437056107954547,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.18437056107954547,
        "precision": 0.17812445926771872,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.0447230907024625,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.0447230907024625,
        "precision": 0.04051498535930981,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.11052018633540374,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11052018633540374,
        "precision": 0.1017770478219697,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.042511828628096666,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.042511828628096666,
        "precision": 0.038895663798007546,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0029334291187739464,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0029334291187739464,
        "precision": 0.0029315619001919384,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.027212071059727307,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.027212071059727307,
        "precision": 0.022547248216193527,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.181640625,
        "f1": 0.1684138371394231,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1684138371394231,
        "precision": 0.16445370802967002,
        "recall": 0.181640625
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.02639515974476912,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.02639515974476912,
        "precision": 0.02316588034361472,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0014048793859649123,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0014048793859649123,
        "precision": 0.0012261284722222222,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.15625,
        "f1": 0.1247000108555537,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.1247000108555537,
        "precision": 0.11428455171130951,
        "recall": 0.15625
      },
      {
        "accuracy": 0.171875,
        "f1": 0.1475757636703852,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1475757636703852,
        "precision": 0.13874979028069562,
        "recall": 0.171875
      },
      {
        "accuracy": 0.212890625,
        "f1": 0.1976097470238095,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.1976097470238095,
        "precision": 0.19099934895833331,
        "recall": 0.212890625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010163008042830299,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.0010163008042830299,
        "precision": 0.0009967137896825396,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002004674692622951,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.002004674692622951,
        "precision": 0.0019792653093434346,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.12193235367063492,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.12193235367063492,
        "precision": 0.1175404409386037,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.13297980502570345,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.13297980502570345,
        "precision": 0.12705721596414726,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03916659324091479,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.03916659324091479,
        "precision": 0.03754684464637878,
        "recall": 0.046875
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.1396211698457792,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.1396211698457792,
        "precision": 0.13434070452120805,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.028332243239049724,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.028332243239049724,
        "precision": 0.0234784535833279,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.11080882182463107,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.11080882182463107,
        "precision": 0.10444996516343025,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0019368489583333334,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.0019368489583333334,
        "precision": 0.0015384734623015873,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.125,
        "f1": 0.10817677331349207,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.10817677331349207,
        "precision": 0.10280524785872536,
        "recall": 0.125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002788957907030234,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.002788957907030234,
        "precision": 0.0025394354371249313,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1484375,
        "f1": 0.13123963881056808,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.13123963881056808,
        "precision": 0.12518633981036326,
        "recall": 0.1484375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003616336176078823,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.003616336176078823,
        "precision": 0.003309946865276841,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002608895782889427,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.002608895782889427,
        "precision": 0.002443776547330097,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0055078492128759395,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.0055078492128759395,
        "precision": 0.0052808357007575754,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.003009764419646301,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.003009764419646301,
        "precision": 0.0026930625075156324,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1630859375,
        "f1": 0.1490330182336489,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.1490330182336489,
        "precision": 0.14392466971544715,
        "recall": 0.1630859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0025527749160561657,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.0025527749160561657,
        "precision": 0.0017420296717171714,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002047644071546851,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.002047644071546851,
        "precision": 0.002002053290663464,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1396484375,
        "f1": 0.12561631768724696,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.12561631768724696,
        "precision": 0.12149473662571089,
        "recall": 0.1396484375
      },
      {
        "accuracy": 0.17578125,
        "f1": 0.15730794270833331,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.15730794270833331,
        "precision": 0.15084194862155387,
        "recall": 0.17578125
      },
      {
        "accuracy": 0.1220703125,
        "f1": 0.10701609714009254,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.10701609714009254,
        "precision": 0.10255878626531653,
        "recall": 0.1220703125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.628701211305518e-06,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 2.628701211305518e-06,
        "precision": 1.3161219676549866e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0010439116379310344,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.0010439116379310344,
        "precision": 0.0010114397321428572,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.12831759982638888,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.12831759982638888,
        "precision": 0.12251832640016233,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.1591796875,
        "f1": 0.14274607989804966,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.14274607989804966,
        "precision": 0.1365368923611111,
        "recall": 0.1591796875
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.06891942851583881,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.06891942851583881,
        "precision": 0.06514412329294131,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.13548306058159265,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.13548306058159265,
        "precision": 0.13060320076311288,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.099609375,
        "f1": 0.05925817155424233,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.05925817155424233,
        "precision": 0.049386460165268764,
        "recall": 0.099609375
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.11103131188045436,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.11103131188045436,
        "precision": 0.10401943824404761,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.06946575830853174,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.06946575830853174,
        "precision": 0.0636474609375,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.11645725486005572,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.11645725486005572,
        "precision": 0.10975754673179468,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002394617791307289,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.002394617791307289,
        "precision": 0.0022230360243055552,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1943359375,
        "f1": 0.17151692708333333,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.17151692708333333,
        "precision": 0.16228841145833334,
        "recall": 0.1943359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014282391786252615,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.0014282391786252615,
        "precision": 0.0012302689228874573,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005518317170869598,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.005518317170869598,
        "precision": 0.004722202552402748,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014832973119803478,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.0014832973119803478,
        "precision": 0.0013113681735112779,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004696641681247354,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.004696641681247354,
        "precision": 0.0038311270690275867,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.203125,
        "f1": 0.18648829374882364,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.18648829374882364,
        "precision": 0.18062324183934939,
        "recall": 0.203125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009117244870921341,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.0009117244870921341,
        "precision": 0.0006252712673611112,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.008462811331463675,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.008462811331463675,
        "precision": 0.007685732437115209,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.12664923428274394,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.12664923428274394,
        "precision": 0.12051499491990214,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.13828646235931086,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.13828646235931086,
        "precision": 0.13322391515032828,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.11268574822809277,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.11268574822809277,
        "precision": 0.10740741631602355,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012416294642857142,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0012416294642857142,
        "precision": 0.0007611443014705882,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.006289527529761904,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.006289527529761904,
        "precision": 0.005803245907738095,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.1884765625,
        "f1": 0.16126564758515585,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.16126564758515585,
        "precision": 0.15387759838587536,
        "recall": 0.1884765625
      },
      {
        "accuracy": 0.2177734375,
        "f1": 0.1865793760428661,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.1865793760428661,
        "precision": 0.17793235225302054,
        "recall": 0.2177734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.026282945100612423,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.026282945100612423,
        "precision": 0.024961071865096236,
        "recall": 0.03125
      },
      {
        "accuracy": 0.20703125,
        "f1": 0.18141244511828752,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.18141244511828752,
        "precision": 0.1731408077599484,
        "recall": 0.20703125
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.017051273405565365,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.017051273405565365,
        "precision": 0.014630671615715286,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.203125,
        "f1": 0.16492861935363182,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.16492861935363182,
        "precision": 0.1542113810668498,
        "recall": 0.203125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.376953125,
        "f1": 0.34421827087842716,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.34421827087842716,
        "precision": 0.33203590029761904,
        "recall": 0.376953125
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.009749730274636747,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.009749730274636747,
        "precision": 0.008619682178800287,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.09194568966776284,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.09194568966776284,
        "precision": 0.08313043904371836,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012952628968253967,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.012952628968253967,
        "precision": 0.01160232407047964,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003963192419825073,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0003963192419825073,
        "precision": 0.0002469960709064327,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004965065088420351,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.004965065088420351,
        "precision": 0.00402183512499172,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 7.584098575712144e-05,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 7.584098575712144e-05,
        "precision": 3.914169720835932e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1875,
        "f1": 0.16474035613233873,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.16474035613233873,
        "precision": 0.15881890708586913,
        "recall": 0.1875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0015028413229349383,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.0015028413229349383,
        "precision": 0.0009464348958157153,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007013868757136457,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0007013868757136457,
        "precision": 0.0005137523417262859,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.2099609375,
        "f1": 0.17926609061001295,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.17926609061001295,
        "precision": 0.17118026376316542,
        "recall": 0.2099609375
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.10166314529068707,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.10166314529068707,
        "precision": 0.09218433370745302,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.13174358216026516,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.13174358216026516,
        "precision": 0.1221344594681553,
        "recall": 0.1611328125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}