{
  "dataset_revision": "3d96e36e10a88d5b7a3f617cf8362d997504494b",
  "evaluation_time": 12.825331926345825,
  "kg_co2_emissions": 0.0005496898967816707,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.530810546875,
        "ap": 0.5165062320165343,
        "ap_weighted": 0.5165062320165343,
        "f1": 0.5265754835977123,
        "f1_weighted": 0.5265697039453661,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ],
        "main_score": 0.530810546875,
        "scores_per_experiment": [
          {
            "accuracy": 0.57763671875,
            "ap": 0.5445170040045259,
            "ap_weighted": 0.5445170040045259,
            "f1": 0.5764369122874468,
            "f1_weighted": 0.5764809418824028
          },
          {
            "accuracy": 0.52587890625,
            "ap": 0.5128076592750519,
            "ap_weighted": 0.5128076592750519,
            "f1": 0.5097921616856022,
            "f1_weighted": 0.5099656036755148
          },
          {
            "accuracy": 0.58740234375,
            "ap": 0.5495714894226288,
            "ap_weighted": 0.5495714894226288,
            "f1": 0.5856548903837198,
            "f1_weighted": 0.5856023353952603
          },
          {
            "accuracy": 0.51123046875,
            "ap": 0.5048156814290161,
            "ap_weighted": 0.5048156814290161,
            "f1": 0.5092835396249051,
            "f1_weighted": 0.5092231697295534
          },
          {
            "accuracy": 0.5009765625,
            "ap": 0.49940947590508805,
            "ap_weighted": 0.49940947590508805,
            "f1": 0.49525752511587307,
            "f1_weighted": 0.4953624615816369
          },
          {
            "accuracy": 0.53857421875,
            "ap": 0.5197464594654315,
            "ap_weighted": 0.5197464594654315,
            "f1": 0.5381089473492027,
            "f1_weighted": 0.5380803152629998
          },
          {
            "accuracy": 0.54248046875,
            "ap": 0.5219524758028595,
            "ap_weighted": 0.5219524758028595,
            "f1": 0.541083358144796,
            "f1_weighted": 0.541033902902134
          },
          {
            "accuracy": 0.5517578125,
            "ap": 0.5272420690561879,
            "ap_weighted": 0.5272420690561879,
            "f1": 0.5469026548672566,
            "f1_weighted": 0.546811048119469
          },
          {
            "accuracy": 0.4990234375,
            "ap": 0.4986624105554734,
            "ap_weighted": 0.4986624105554734,
            "f1": 0.49055813303955187,
            "f1_weighted": 0.49042987085075723
          },
          {
            "accuracy": 0.47314453125,
            "ap": 0.4863375952490798,
            "ap_weighted": 0.4863375952490798,
            "f1": 0.47267671347876894,
            "f1_weighted": 0.47270739005393164
          }
        ]
      }
    ]
  },
  "task_name": "KorSarcasmClassification"
}