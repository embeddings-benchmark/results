{
  "dataset_revision": "ffb8a34c9637fb20256e8c7be02504d16af4bd6b",
  "evaluation_time": 12.164092540740967,
  "kg_co2_emissions": 0.0003992630022090553,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.547607421875,
        "f1": 0.5503515914908438,
        "f1_weighted": 0.5416044995745215,
        "hf_subset": "default",
        "languages": [
          "ory-Orya"
        ],
        "main_score": 0.5503515914908438,
        "scores_per_experiment": [
          {
            "accuracy": 0.5791015625,
            "f1": 0.5859912626562347,
            "f1_weighted": 0.5794059708461796
          },
          {
            "accuracy": 0.54248046875,
            "f1": 0.5346156313707976,
            "f1_weighted": 0.5297051427747699
          },
          {
            "accuracy": 0.548828125,
            "f1": 0.5698743195231769,
            "f1_weighted": 0.5496315728408776
          },
          {
            "accuracy": 0.58935546875,
            "f1": 0.5653196244654426,
            "f1_weighted": 0.5741154632553243
          },
          {
            "accuracy": 0.50830078125,
            "f1": 0.5017908087335,
            "f1_weighted": 0.4947051371224166
          },
          {
            "accuracy": 0.5244140625,
            "f1": 0.5395666373626308,
            "f1_weighted": 0.5189992938271809
          },
          {
            "accuracy": 0.53955078125,
            "f1": 0.5403990046020498,
            "f1_weighted": 0.5346871982703272
          },
          {
            "accuracy": 0.546875,
            "f1": 0.5589675317944746,
            "f1_weighted": 0.5458414925248449
          },
          {
            "accuracy": 0.55908203125,
            "f1": 0.5587045843850579,
            "f1_weighted": 0.5541449765764284
          },
          {
            "accuracy": 0.5380859375,
            "f1": 0.5482865100150729,
            "f1_weighted": 0.5348087477068659
          }
        ]
      }
    ]
  },
  "task_name": "OdiaNewsClassification"
}