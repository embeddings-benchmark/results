{
  "dataset_revision": "7d8df44e588b6143d4856c781f72f919fa0599a7",
  "task_name": "WikipediaSolidStateColloidalClassification",
  "mteb_version": "1.26.4",
  "scores": {
    "test": [
      {
        "accuracy": 0.824324,
        "f1": 0.822405,
        "f1_weighted": 0.823738,
        "ap": 0.800542,
        "ap_weighted": 0.800542,
        "scores_per_experiment": [
          {
            "accuracy": 0.806306,
            "f1": 0.806165,
            "f1_weighted": 0.806707,
            "ap": 0.797191,
            "ap_weighted": 0.797191
          },
          {
            "accuracy": 0.693694,
            "f1": 0.69294,
            "f1_weighted": 0.691364,
            "ap": 0.701285,
            "ap_weighted": 0.701285
          },
          {
            "accuracy": 0.817568,
            "f1": 0.815128,
            "f1_weighted": 0.817328,
            "ap": 0.785161,
            "ap_weighted": 0.785161
          },
          {
            "accuracy": 0.842342,
            "f1": 0.836775,
            "f1_weighted": 0.839898,
            "ap": 0.793376,
            "ap_weighted": 0.793376
          },
          {
            "accuracy": 0.828829,
            "f1": 0.827696,
            "f1_weighted": 0.829143,
            "ap": 0.805557,
            "ap_weighted": 0.805557
          },
          {
            "accuracy": 0.86036,
            "f1": 0.856371,
            "f1_weighted": 0.858851,
            "ap": 0.815503,
            "ap_weighted": 0.815503
          },
          {
            "accuracy": 0.855856,
            "f1": 0.853353,
            "f1_weighted": 0.855338,
            "ap": 0.820267,
            "ap_weighted": 0.820267
          },
          {
            "accuracy": 0.831081,
            "f1": 0.830627,
            "f1_weighted": 0.831536,
            "ap": 0.816667,
            "ap_weighted": 0.816667
          },
          {
            "accuracy": 0.846847,
            "f1": 0.846735,
            "f1_weighted": 0.847164,
            "ap": 0.842904,
            "ap_weighted": 0.842904
          },
          {
            "accuracy": 0.86036,
            "f1": 0.858264,
            "f1_weighted": 0.86005,
            "ap": 0.827512,
            "ap_weighted": 0.827512
          }
        ],
        "main_score": 0.824324,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 10.711175441741943,
  "kg_co2_emissions": null
}