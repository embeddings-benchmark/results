{
  "dataset_revision": "cf24d44e517efa534f048e5fc5981f399ed25bee",
  "task_name": "CataloniaTweetClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.444913,
        "f1": 0.449377,
        "f1_weighted": 0.439689,
        "scores_per_experiment": [
          {
            "accuracy": 0.452605,
            "f1": 0.464653,
            "f1_weighted": 0.442746
          },
          {
            "accuracy": 0.495285,
            "f1": 0.503342,
            "f1_weighted": 0.495284
          },
          {
            "accuracy": 0.374194,
            "f1": 0.375537,
            "f1_weighted": 0.368987
          },
          {
            "accuracy": 0.465012,
            "f1": 0.464285,
            "f1_weighted": 0.453557
          },
          {
            "accuracy": 0.479404,
            "f1": 0.487146,
            "f1_weighted": 0.474455
          },
          {
            "accuracy": 0.452605,
            "f1": 0.461998,
            "f1_weighted": 0.448099
          },
          {
            "accuracy": 0.418362,
            "f1": 0.422013,
            "f1_weighted": 0.416387
          },
          {
            "accuracy": 0.412903,
            "f1": 0.405448,
            "f1_weighted": 0.407126
          },
          {
            "accuracy": 0.445658,
            "f1": 0.459598,
            "f1_weighted": 0.440985
          },
          {
            "accuracy": 0.453102,
            "f1": 0.449752,
            "f1_weighted": 0.449262
          }
        ],
        "main_score": 0.444913,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ]
      },
      {
        "accuracy": 0.448358,
        "f1": 0.438596,
        "f1_weighted": 0.444514,
        "scores_per_experiment": [
          {
            "accuracy": 0.444776,
            "f1": 0.434656,
            "f1_weighted": 0.435408
          },
          {
            "accuracy": 0.444279,
            "f1": 0.427925,
            "f1_weighted": 0.441598
          },
          {
            "accuracy": 0.464179,
            "f1": 0.449411,
            "f1_weighted": 0.461937
          },
          {
            "accuracy": 0.498507,
            "f1": 0.481776,
            "f1_weighted": 0.487946
          },
          {
            "accuracy": 0.39204,
            "f1": 0.390883,
            "f1_weighted": 0.394321
          },
          {
            "accuracy": 0.449254,
            "f1": 0.444657,
            "f1_weighted": 0.451288
          },
          {
            "accuracy": 0.440299,
            "f1": 0.429393,
            "f1_weighted": 0.438396
          },
          {
            "accuracy": 0.421891,
            "f1": 0.42414,
            "f1_weighted": 0.419774
          },
          {
            "accuracy": 0.457214,
            "f1": 0.438393,
            "f1_weighted": 0.450145
          },
          {
            "accuracy": 0.471144,
            "f1": 0.464729,
            "f1_weighted": 0.464333
          }
        ],
        "main_score": 0.448358,
        "hf_subset": "catalan",
        "languages": [
          "cat-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.449554,
        "f1": 0.455397,
        "f1_weighted": 0.444294,
        "scores_per_experiment": [
          {
            "accuracy": 0.440476,
            "f1": 0.451474,
            "f1_weighted": 0.43074
          },
          {
            "accuracy": 0.475198,
            "f1": 0.482159,
            "f1_weighted": 0.47431
          },
          {
            "accuracy": 0.386409,
            "f1": 0.387089,
            "f1_weighted": 0.384758
          },
          {
            "accuracy": 0.462798,
            "f1": 0.461229,
            "f1_weighted": 0.447717
          },
          {
            "accuracy": 0.485615,
            "f1": 0.494916,
            "f1_weighted": 0.480143
          },
          {
            "accuracy": 0.44494,
            "f1": 0.453043,
            "f1_weighted": 0.441311
          },
          {
            "accuracy": 0.447421,
            "f1": 0.451143,
            "f1_weighted": 0.445535
          },
          {
            "accuracy": 0.422619,
            "f1": 0.424405,
            "f1_weighted": 0.414712
          },
          {
            "accuracy": 0.454861,
            "f1": 0.472505,
            "f1_weighted": 0.451903
          },
          {
            "accuracy": 0.475198,
            "f1": 0.476007,
            "f1_weighted": 0.471809
          }
        ],
        "main_score": 0.449554,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ]
      },
      {
        "accuracy": 0.456915,
        "f1": 0.447307,
        "f1_weighted": 0.451476,
        "scores_per_experiment": [
          {
            "accuracy": 0.462189,
            "f1": 0.446311,
            "f1_weighted": 0.454794
          },
          {
            "accuracy": 0.437313,
            "f1": 0.42353,
            "f1_weighted": 0.433185
          },
          {
            "accuracy": 0.487562,
            "f1": 0.475917,
            "f1_weighted": 0.485201
          },
          {
            "accuracy": 0.493532,
            "f1": 0.473071,
            "f1_weighted": 0.481278
          },
          {
            "accuracy": 0.402488,
            "f1": 0.403316,
            "f1_weighted": 0.401963
          },
          {
            "accuracy": 0.448756,
            "f1": 0.445786,
            "f1_weighted": 0.448639
          },
          {
            "accuracy": 0.451741,
            "f1": 0.445876,
            "f1_weighted": 0.446129
          },
          {
            "accuracy": 0.426866,
            "f1": 0.430531,
            "f1_weighted": 0.421582
          },
          {
            "accuracy": 0.471642,
            "f1": 0.447233,
            "f1_weighted": 0.459572
          },
          {
            "accuracy": 0.487065,
            "f1": 0.481503,
            "f1_weighted": 0.482422
          }
        ],
        "main_score": 0.456915,
        "hf_subset": "catalan",
        "languages": [
          "cat-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 24.257839918136597,
  "kg_co2_emissions": 0.0010822801354655048
}