{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.06377,
        "f1": 0.043296,
        "f1_weighted": 0.059879,
        "scores_per_experiment": [
          {
            "accuracy": 0.055176,
            "f1": 0.038315,
            "f1_weighted": 0.055958
          },
          {
            "accuracy": 0.071777,
            "f1": 0.056054,
            "f1_weighted": 0.066505
          },
          {
            "accuracy": 0.058105,
            "f1": 0.037463,
            "f1_weighted": 0.053798
          },
          {
            "accuracy": 0.057617,
            "f1": 0.038556,
            "f1_weighted": 0.055296
          },
          {
            "accuracy": 0.066406,
            "f1": 0.042891,
            "f1_weighted": 0.062724
          },
          {
            "accuracy": 0.064941,
            "f1": 0.039816,
            "f1_weighted": 0.060037
          },
          {
            "accuracy": 0.070312,
            "f1": 0.047457,
            "f1_weighted": 0.066516
          },
          {
            "accuracy": 0.067383,
            "f1": 0.046702,
            "f1_weighted": 0.062604
          },
          {
            "accuracy": 0.058594,
            "f1": 0.038396,
            "f1_weighted": 0.054579
          },
          {
            "accuracy": 0.067383,
            "f1": 0.047309,
            "f1_weighted": 0.060774
          }
        ],
        "main_score": 0.06377,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.061475,
        "f1": 0.042753,
        "f1_weighted": 0.052746,
        "scores_per_experiment": [
          {
            "accuracy": 0.064453,
            "f1": 0.046964,
            "f1_weighted": 0.054907
          },
          {
            "accuracy": 0.066406,
            "f1": 0.045755,
            "f1_weighted": 0.055131
          },
          {
            "accuracy": 0.058594,
            "f1": 0.041787,
            "f1_weighted": 0.0457
          },
          {
            "accuracy": 0.057617,
            "f1": 0.042134,
            "f1_weighted": 0.046722
          },
          {
            "accuracy": 0.055664,
            "f1": 0.036317,
            "f1_weighted": 0.049604
          },
          {
            "accuracy": 0.0625,
            "f1": 0.04376,
            "f1_weighted": 0.055172
          },
          {
            "accuracy": 0.066895,
            "f1": 0.044617,
            "f1_weighted": 0.060465
          },
          {
            "accuracy": 0.062012,
            "f1": 0.04195,
            "f1_weighted": 0.056001
          },
          {
            "accuracy": 0.058594,
            "f1": 0.040638,
            "f1_weighted": 0.051281
          },
          {
            "accuracy": 0.062012,
            "f1": 0.043614,
            "f1_weighted": 0.052472
          }
        ],
        "main_score": 0.061475,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 1193.8574073314667,
  "kg_co2_emissions": 0.044021824446039894
}