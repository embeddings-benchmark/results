{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.56825,
        "f1": 0.564938,
        "f1_weighted": 0.564938,
        "ap": 0.539574,
        "ap_weighted": 0.539574,
        "scores_per_experiment": [
          {
            "accuracy": 0.560833,
            "f1": 0.559018,
            "f1_weighted": 0.559018,
            "ap": 0.534662,
            "ap_weighted": 0.534662
          },
          {
            "accuracy": 0.510833,
            "f1": 0.497566,
            "f1_weighted": 0.497566,
            "ap": 0.505505,
            "ap_weighted": 0.505505
          },
          {
            "accuracy": 0.6025,
            "f1": 0.597094,
            "f1_weighted": 0.597094,
            "ap": 0.55978,
            "ap_weighted": 0.55978
          },
          {
            "accuracy": 0.59,
            "f1": 0.589497,
            "f1_weighted": 0.589497,
            "ap": 0.55257,
            "ap_weighted": 0.55257
          },
          {
            "accuracy": 0.5775,
            "f1": 0.577434,
            "f1_weighted": 0.577434,
            "ap": 0.54461,
            "ap_weighted": 0.54461
          },
          {
            "accuracy": 0.521667,
            "f1": 0.520767,
            "f1_weighted": 0.520767,
            "ap": 0.511265,
            "ap_weighted": 0.511265
          },
          {
            "accuracy": 0.558333,
            "f1": 0.550135,
            "f1_weighted": 0.550135,
            "ap": 0.533828,
            "ap_weighted": 0.533828
          },
          {
            "accuracy": 0.5575,
            "f1": 0.556699,
            "f1_weighted": 0.556699,
            "ap": 0.531797,
            "ap_weighted": 0.531797
          },
          {
            "accuracy": 0.6025,
            "f1": 0.600681,
            "f1_weighted": 0.600681,
            "ap": 0.560507,
            "ap_weighted": 0.560507
          },
          {
            "accuracy": 0.600833,
            "f1": 0.600493,
            "f1_weighted": 0.600493,
            "ap": 0.561214,
            "ap_weighted": 0.561214
          }
        ],
        "main_score": 0.56825,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5655,
        "f1": 0.562563,
        "f1_weighted": 0.562563,
        "ap": 0.538726,
        "ap_weighted": 0.538726,
        "scores_per_experiment": [
          {
            "accuracy": 0.546667,
            "f1": 0.544643,
            "f1_weighted": 0.544643,
            "ap": 0.525846,
            "ap_weighted": 0.525846
          },
          {
            "accuracy": 0.493333,
            "f1": 0.481671,
            "f1_weighted": 0.481671,
            "ap": 0.496701,
            "ap_weighted": 0.496701
          },
          {
            "accuracy": 0.6175,
            "f1": 0.615288,
            "f1_weighted": 0.615288,
            "ap": 0.570738,
            "ap_weighted": 0.570738
          },
          {
            "accuracy": 0.611667,
            "f1": 0.611235,
            "f1_weighted": 0.611235,
            "ap": 0.567523,
            "ap_weighted": 0.567523
          },
          {
            "accuracy": 0.595833,
            "f1": 0.59571,
            "f1_weighted": 0.59571,
            "ap": 0.557434,
            "ap_weighted": 0.557434
          },
          {
            "accuracy": 0.493333,
            "f1": 0.491701,
            "f1_weighted": 0.491701,
            "ap": 0.496707,
            "ap_weighted": 0.496707
          },
          {
            "accuracy": 0.563333,
            "f1": 0.555827,
            "f1_weighted": 0.555827,
            "ap": 0.537087,
            "ap_weighted": 0.537087
          },
          {
            "accuracy": 0.550833,
            "f1": 0.549955,
            "f1_weighted": 0.549955,
            "ap": 0.527791,
            "ap_weighted": 0.527791
          },
          {
            "accuracy": 0.600833,
            "f1": 0.598724,
            "f1_weighted": 0.598724,
            "ap": 0.559296,
            "ap_weighted": 0.559296
          },
          {
            "accuracy": 0.581667,
            "f1": 0.58088,
            "f1_weighted": 0.58088,
            "ap": 0.548136,
            "ap_weighted": 0.548136
          }
        ],
        "main_score": 0.5655,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 170.88897228240967,
  "kg_co2_emissions": null
}