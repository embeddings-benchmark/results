{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.960547,
        "f1": 0.960505,
        "f1_weighted": 0.960508,
        "ap": 0.933171,
        "ap_weighted": 0.933171,
        "scores_per_experiment": [
          {
            "accuracy": 0.964844,
            "f1": 0.964812,
            "f1_weighted": 0.964815,
            "ap": 0.937482,
            "ap_weighted": 0.937482
          },
          {
            "accuracy": 0.969727,
            "f1": 0.969714,
            "f1_weighted": 0.969716,
            "ap": 0.948177,
            "ap_weighted": 0.948177
          },
          {
            "accuracy": 0.969238,
            "f1": 0.969226,
            "f1_weighted": 0.969228,
            "ap": 0.947694,
            "ap_weighted": 0.947694
          },
          {
            "accuracy": 0.950684,
            "f1": 0.950684,
            "f1_weighted": 0.950684,
            "ap": 0.929729,
            "ap_weighted": 0.929729
          },
          {
            "accuracy": 0.964844,
            "f1": 0.964821,
            "f1_weighted": 0.964824,
            "ap": 0.939399,
            "ap_weighted": 0.939399
          },
          {
            "accuracy": 0.967773,
            "f1": 0.967763,
            "f1_weighted": 0.967765,
            "ap": 0.946647,
            "ap_weighted": 0.946647
          },
          {
            "accuracy": 0.952148,
            "f1": 0.952072,
            "f1_weighted": 0.952077,
            "ap": 0.916629,
            "ap_weighted": 0.916629
          },
          {
            "accuracy": 0.958496,
            "f1": 0.95844,
            "f1_weighted": 0.958445,
            "ap": 0.926408,
            "ap_weighted": 0.926408
          },
          {
            "accuracy": 0.965332,
            "f1": 0.965314,
            "f1_weighted": 0.965316,
            "ap": 0.94105,
            "ap_weighted": 0.94105
          },
          {
            "accuracy": 0.942383,
            "f1": 0.942204,
            "f1_weighted": 0.942213,
            "ap": 0.898498,
            "ap_weighted": 0.898498
          }
        ],
        "main_score": 0.960547,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.962256,
        "f1": 0.962228,
        "f1_weighted": 0.96223,
        "ap": 0.937149,
        "ap_weighted": 0.937149,
        "scores_per_experiment": [
          {
            "accuracy": 0.970703,
            "f1": 0.970688,
            "f1_weighted": 0.97069,
            "ap": 0.948289,
            "ap_weighted": 0.948289
          },
          {
            "accuracy": 0.960938,
            "f1": 0.960927,
            "f1_weighted": 0.960928,
            "ap": 0.937026,
            "ap_weighted": 0.937026
          },
          {
            "accuracy": 0.970703,
            "f1": 0.970698,
            "f1_weighted": 0.970698,
            "ap": 0.951947,
            "ap_weighted": 0.951947
          },
          {
            "accuracy": 0.947266,
            "f1": 0.947265,
            "f1_weighted": 0.947265,
            "ap": 0.923095,
            "ap_weighted": 0.923095
          },
          {
            "accuracy": 0.970215,
            "f1": 0.970206,
            "f1_weighted": 0.970207,
            "ap": 0.949821,
            "ap_weighted": 0.949821
          },
          {
            "accuracy": 0.969238,
            "f1": 0.969233,
            "f1_weighted": 0.969234,
            "ap": 0.95008,
            "ap_weighted": 0.95008
          },
          {
            "accuracy": 0.954102,
            "f1": 0.954048,
            "f1_weighted": 0.954051,
            "ap": 0.92093,
            "ap_weighted": 0.92093
          },
          {
            "accuracy": 0.965332,
            "f1": 0.965307,
            "f1_weighted": 0.965309,
            "ap": 0.939049,
            "ap_weighted": 0.939049
          },
          {
            "accuracy": 0.970703,
            "f1": 0.970694,
            "f1_weighted": 0.970695,
            "ap": 0.950306,
            "ap_weighted": 0.950306
          },
          {
            "accuracy": 0.943359,
            "f1": 0.943213,
            "f1_weighted": 0.943219,
            "ap": 0.900942,
            "ap_weighted": 0.900942
          }
        ],
        "main_score": 0.962256,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 56.23110580444336,
  "kg_co2_emissions": null
}