{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.435986,
        "f1": 0.365723,
        "f1_weighted": 0.428458,
        "scores_per_experiment": [
          {
            "accuracy": 0.425781,
            "f1": 0.348608,
            "f1_weighted": 0.420628
          },
          {
            "accuracy": 0.430176,
            "f1": 0.371453,
            "f1_weighted": 0.420207
          },
          {
            "accuracy": 0.447266,
            "f1": 0.372194,
            "f1_weighted": 0.438469
          },
          {
            "accuracy": 0.426758,
            "f1": 0.35209,
            "f1_weighted": 0.419372
          },
          {
            "accuracy": 0.436035,
            "f1": 0.355364,
            "f1_weighted": 0.426025
          },
          {
            "accuracy": 0.427734,
            "f1": 0.372928,
            "f1_weighted": 0.422372
          },
          {
            "accuracy": 0.45459,
            "f1": 0.375414,
            "f1_weighted": 0.446257
          },
          {
            "accuracy": 0.44873,
            "f1": 0.382513,
            "f1_weighted": 0.441086
          },
          {
            "accuracy": 0.429199,
            "f1": 0.355147,
            "f1_weighted": 0.423405
          },
          {
            "accuracy": 0.433594,
            "f1": 0.371518,
            "f1_weighted": 0.426755
          }
        ],
        "main_score": 0.435986,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.433301,
        "f1": 0.385873,
        "f1_weighted": 0.425148,
        "scores_per_experiment": [
          {
            "accuracy": 0.438477,
            "f1": 0.390442,
            "f1_weighted": 0.435842
          },
          {
            "accuracy": 0.429688,
            "f1": 0.38463,
            "f1_weighted": 0.411103
          },
          {
            "accuracy": 0.439941,
            "f1": 0.386886,
            "f1_weighted": 0.434021
          },
          {
            "accuracy": 0.421875,
            "f1": 0.377479,
            "f1_weighted": 0.408281
          },
          {
            "accuracy": 0.417969,
            "f1": 0.372975,
            "f1_weighted": 0.406896
          },
          {
            "accuracy": 0.429199,
            "f1": 0.385345,
            "f1_weighted": 0.419319
          },
          {
            "accuracy": 0.452148,
            "f1": 0.387202,
            "f1_weighted": 0.453884
          },
          {
            "accuracy": 0.439453,
            "f1": 0.390145,
            "f1_weighted": 0.434574
          },
          {
            "accuracy": 0.435547,
            "f1": 0.394869,
            "f1_weighted": 0.431811
          },
          {
            "accuracy": 0.428711,
            "f1": 0.388752,
            "f1_weighted": 0.415752
          }
        ],
        "main_score": 0.433301,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 836.063250541687,
  "kg_co2_emissions": null
}