{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.5275,
        "f1": 0.525138,
        "f1_weighted": 0.525138,
        "ap": 0.514866,
        "ap_weighted": 0.514866,
        "scores_per_experiment": [
          {
            "accuracy": 0.548333,
            "f1": 0.54422,
            "f1_weighted": 0.54422,
            "ap": 0.527051,
            "ap_weighted": 0.527051
          },
          {
            "accuracy": 0.524167,
            "f1": 0.520635,
            "f1_weighted": 0.520635,
            "ap": 0.512788,
            "ap_weighted": 0.512788
          },
          {
            "accuracy": 0.54,
            "f1": 0.538769,
            "f1_weighted": 0.538769,
            "ap": 0.52145,
            "ap_weighted": 0.52145
          },
          {
            "accuracy": 0.538333,
            "f1": 0.538117,
            "f1_weighted": 0.538117,
            "ap": 0.520703,
            "ap_weighted": 0.520703
          },
          {
            "accuracy": 0.505833,
            "f1": 0.505833,
            "f1_weighted": 0.505833,
            "ap": 0.502951,
            "ap_weighted": 0.502951
          },
          {
            "accuracy": 0.511667,
            "f1": 0.508779,
            "f1_weighted": 0.508779,
            "ap": 0.505994,
            "ap_weighted": 0.505994
          },
          {
            "accuracy": 0.495833,
            "f1": 0.490122,
            "f1_weighted": 0.490122,
            "ap": 0.497931,
            "ap_weighted": 0.497931
          },
          {
            "accuracy": 0.5525,
            "f1": 0.548352,
            "f1_weighted": 0.548352,
            "ap": 0.528563,
            "ap_weighted": 0.528563
          },
          {
            "accuracy": 0.544167,
            "f1": 0.543999,
            "f1_weighted": 0.543999,
            "ap": 0.523962,
            "ap_weighted": 0.523962
          },
          {
            "accuracy": 0.514167,
            "f1": 0.512555,
            "f1_weighted": 0.512555,
            "ap": 0.507263,
            "ap_weighted": 0.507263
          }
        ],
        "main_score": 0.5275,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.520667,
        "f1": 0.518565,
        "f1_weighted": 0.518565,
        "ap": 0.511746,
        "ap_weighted": 0.511746,
        "scores_per_experiment": [
          {
            "accuracy": 0.5575,
            "f1": 0.553253,
            "f1_weighted": 0.553253,
            "ap": 0.532857,
            "ap_weighted": 0.532857
          },
          {
            "accuracy": 0.486667,
            "f1": 0.48322,
            "f1_weighted": 0.48322,
            "ap": 0.493546,
            "ap_weighted": 0.493546
          },
          {
            "accuracy": 0.530833,
            "f1": 0.53063,
            "f1_weighted": 0.53063,
            "ap": 0.516329,
            "ap_weighted": 0.516329
          },
          {
            "accuracy": 0.554167,
            "f1": 0.554151,
            "f1_weighted": 0.554151,
            "ap": 0.530052,
            "ap_weighted": 0.530052
          },
          {
            "accuracy": 0.508333,
            "f1": 0.50789,
            "f1_weighted": 0.50789,
            "ap": 0.504232,
            "ap_weighted": 0.504232
          },
          {
            "accuracy": 0.506667,
            "f1": 0.503876,
            "f1_weighted": 0.503876,
            "ap": 0.503386,
            "ap_weighted": 0.503386
          },
          {
            "accuracy": 0.468333,
            "f1": 0.464464,
            "f1_weighted": 0.464464,
            "ap": 0.485024,
            "ap_weighted": 0.485024
          },
          {
            "accuracy": 0.508333,
            "f1": 0.504895,
            "f1_weighted": 0.504895,
            "ap": 0.504226,
            "ap_weighted": 0.504226
          },
          {
            "accuracy": 0.568333,
            "f1": 0.568323,
            "f1_weighted": 0.568323,
            "ap": 0.53879,
            "ap_weighted": 0.53879
          },
          {
            "accuracy": 0.5175,
            "f1": 0.51495,
            "f1_weighted": 0.51495,
            "ap": 0.509017,
            "ap_weighted": 0.509017
          }
        ],
        "main_score": 0.520667,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 26.300933599472046,
  "kg_co2_emissions": 0.0012216513999168603
}