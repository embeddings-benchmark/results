{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.667041,
        "f1": 0.666083,
        "f1_weighted": 0.666061,
        "ap": 0.61486,
        "ap_weighted": 0.61486,
        "scores_per_experiment": [
          {
            "accuracy": 0.69043,
            "f1": 0.689099,
            "f1_weighted": 0.689158,
            "ap": 0.628579,
            "ap_weighted": 0.628579
          },
          {
            "accuracy": 0.678223,
            "f1": 0.677878,
            "f1_weighted": 0.677909,
            "ap": 0.620307,
            "ap_weighted": 0.620307
          },
          {
            "accuracy": 0.654297,
            "f1": 0.652279,
            "f1_weighted": 0.652202,
            "ap": 0.606911,
            "ap_weighted": 0.606911
          },
          {
            "accuracy": 0.66748,
            "f1": 0.667347,
            "f1_weighted": 0.667367,
            "ap": 0.612127,
            "ap_weighted": 0.612127
          },
          {
            "accuracy": 0.657227,
            "f1": 0.657218,
            "f1_weighted": 0.657223,
            "ap": 0.604551,
            "ap_weighted": 0.604551
          },
          {
            "accuracy": 0.630371,
            "f1": 0.630142,
            "f1_weighted": 0.630115,
            "ap": 0.584601,
            "ap_weighted": 0.584601
          },
          {
            "accuracy": 0.699219,
            "f1": 0.698826,
            "f1_weighted": 0.698794,
            "ap": 0.643966,
            "ap_weighted": 0.643966
          },
          {
            "accuracy": 0.682129,
            "f1": 0.681702,
            "f1_weighted": 0.681668,
            "ap": 0.62843,
            "ap_weighted": 0.62843
          },
          {
            "accuracy": 0.617188,
            "f1": 0.613864,
            "f1_weighted": 0.613759,
            "ap": 0.577149,
            "ap_weighted": 0.577149
          },
          {
            "accuracy": 0.693848,
            "f1": 0.692472,
            "f1_weighted": 0.692411,
            "ap": 0.641979,
            "ap_weighted": 0.641979
          }
        ],
        "main_score": 0.667041,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.671191,
        "f1": 0.670144,
        "f1_weighted": 0.670124,
        "ap": 0.618673,
        "ap_weighted": 0.618673,
        "scores_per_experiment": [
          {
            "accuracy": 0.679688,
            "f1": 0.678982,
            "f1_weighted": 0.679012,
            "ap": 0.620261,
            "ap_weighted": 0.620261
          },
          {
            "accuracy": 0.69043,
            "f1": 0.690273,
            "f1_weighted": 0.690287,
            "ap": 0.630857,
            "ap_weighted": 0.630857
          },
          {
            "accuracy": 0.645508,
            "f1": 0.642095,
            "f1_weighted": 0.642026,
            "ap": 0.600221,
            "ap_weighted": 0.600221
          },
          {
            "accuracy": 0.678223,
            "f1": 0.678094,
            "f1_weighted": 0.678106,
            "ap": 0.620595,
            "ap_weighted": 0.620595
          },
          {
            "accuracy": 0.67334,
            "f1": 0.67333,
            "f1_weighted": 0.673327,
            "ap": 0.618031,
            "ap_weighted": 0.618031
          },
          {
            "accuracy": 0.625,
            "f1": 0.624536,
            "f1_weighted": 0.62451,
            "ap": 0.58034,
            "ap_weighted": 0.58034
          },
          {
            "accuracy": 0.698242,
            "f1": 0.697369,
            "f1_weighted": 0.697337,
            "ap": 0.644239,
            "ap_weighted": 0.644239
          },
          {
            "accuracy": 0.694336,
            "f1": 0.693958,
            "f1_weighted": 0.693937,
            "ap": 0.638838,
            "ap_weighted": 0.638838
          },
          {
            "accuracy": 0.619141,
            "f1": 0.616242,
            "f1_weighted": 0.616177,
            "ap": 0.57787,
            "ap_weighted": 0.57787
          },
          {
            "accuracy": 0.708008,
            "f1": 0.706557,
            "f1_weighted": 0.706517,
            "ap": 0.655481,
            "ap_weighted": 0.655481
          }
        ],
        "main_score": 0.671191,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 19.614720821380615,
  "kg_co2_emissions": 0.0008227101701619259
}