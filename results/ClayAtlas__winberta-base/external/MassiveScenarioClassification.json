{
    "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.4353396099529253,
                "f1": 0.3933203088232628,
                "main_score": 0.4353396099529253
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.2529589778076664,
                "f1": 0.24054560287043003,
                "main_score": 0.2529589778076664
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.34912575655682576,
                "f1": 0.3388220776733138,
                "main_score": 0.34912575655682576
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.3636516476126429,
                "f1": 0.3395559644526807,
                "main_score": 0.3636516476126429
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.3919636852723605,
                "f1": 0.3777671141233066,
                "main_score": 0.3919636852723605
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.32182246133154,
                "f1": 0.286931543688699,
                "main_score": 0.32182246133154
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.49354404841963695,
                "f1": 0.45204759870360334,
                "main_score": 0.49354404841963695
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.43920645595158037,
                "f1": 0.39388774471125243,
                "main_score": 0.43920645595158037
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.3503026227303295,
                "f1": 0.3235267560184562,
                "main_score": 0.3503026227303295
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.687626092804304,
                "f1": 0.6620295429511027,
                "main_score": 0.687626092804304
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.41963685272360457,
                "f1": 0.39718885309990604,
                "main_score": 0.41963685272360457
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.5836247478143914,
                "f1": 0.549002532592521,
                "main_score": 0.5836247478143914
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.3395090786819099,
                "f1": 0.31410449154365405,
                "main_score": 0.3395090786819099
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.4531607262945528,
                "f1": 0.43329365161564104,
                "main_score": 0.4531607262945528
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.34055144586415603,
                "f1": 0.3226080493059418,
                "main_score": 0.34055144586415603
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.48769334229993283,
                "f1": 0.46200914988348574,
                "main_score": 0.48769334229993283
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.39919300605245456,
                "f1": 0.3717661362631962,
                "main_score": 0.39919300605245456
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.38093476798924014,
                "f1": 0.35716750028718,
                "main_score": 0.38093476798924014
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.4508069939475453,
                "f1": 0.4305376897299742,
                "main_score": 0.4508069939475453
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.36546738399462003,
                "f1": 0.3274492737651172,
                "main_score": 0.36546738399462003
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.44377942165433754,
                "f1": 0.40304817822880507,
                "main_score": 0.44377942165433754
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.5702084734364493,
                "f1": 0.5495498064363304,
                "main_score": 0.5702084734364493
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.3551109616677875,
                "f1": 0.3303189592048449,
                "main_score": 0.3551109616677875
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.33412911903160725,
                "f1": 0.311209080205926,
                "main_score": 0.33412911903160725
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.3090114324142569,
                "f1": 0.28036674925420313,
                "main_score": 0.3090114324142569
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.2682918628110289,
                "f1": 0.2643660747971936,
                "main_score": 0.2682918628110289
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.49522528581035646,
                "f1": 0.4803644348186012,
                "main_score": 0.49522528581035646
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.3402488231338265,
                "f1": 0.30461290829668003,
                "main_score": 0.3402488231338265
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.345527908540686,
                "f1": 0.3349186265717059,
                "main_score": 0.345527908540686
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.34142568930733025,
                "f1": 0.3264829812492043,
                "main_score": 0.34142568930733025
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.4271351714862138,
                "f1": 0.3998379391216179,
                "main_score": 0.4271351714862138
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.3099865501008742,
                "f1": 0.30019431005783714,
                "main_score": 0.3099865501008742
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.44270342972427706,
                "f1": 0.40782621083843196,
                "main_score": 0.44270342972427706
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.5143577673167451,
                "f1": 0.4646967224972376,
                "main_score": 0.5143577673167451
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.37488231338264966,
                "f1": 0.35568795691711336,
                "main_score": 0.37488231338264966
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.4590450571620713,
                "f1": 0.43540655907446507,
                "main_score": 0.4590450571620713
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.4500672494956288,
                "f1": 0.4068273214004436,
                "main_score": 0.4500672494956288
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.48655010087424344,
                "f1": 0.45986672455895206,
                "main_score": 0.48655010087424344
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.38335574983187626,
                "f1": 0.3487495617057008,
                "main_score": 0.38335574983187626
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.4478143913920645,
                "f1": 0.4095774409811561,
                "main_score": 0.4478143913920645
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.4516139878950908,
                "f1": 0.40874809080044805,
                "main_score": 0.4516139878950908
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.360221923335575,
                "f1": 0.3188059351143894,
                "main_score": 0.360221923335575
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.37807666442501675,
                "f1": 0.35809097835779563,
                "main_score": 0.37807666442501675
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.34596503026227304,
                "f1": 0.33552796756090275,
                "main_score": 0.34596503026227304
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.5738399462004035,
                "f1": 0.5392067950173084,
                "main_score": 0.5738399462004035
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.39361129791526556,
                "f1": 0.3573348460761388,
                "main_score": 0.39361129791526556
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.36163416274377946,
                "f1": 0.35369464373021253,
                "main_score": 0.36163416274377946
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.36425689307330195,
                "f1": 0.3572323238273122,
                "main_score": 0.36425689307330195
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.4704438466711499,
                "f1": 0.46775815838841667,
                "main_score": 0.4704438466711499
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.7569266980497646,
                "f1": 0.7503810873420111,
                "main_score": 0.7569266980497646
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.7196032279757902,
                "f1": 0.7105327209484684,
                "main_score": 0.7196032279757902
            }
        ]
    }
}