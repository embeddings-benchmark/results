{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.33496973772696703,
                "f1": 0.30700367642324966,
                "main_score": 0.33496973772696703
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.19559515803631475,
                "f1": 0.16655700010020094,
                "main_score": 0.19559515803631475
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.2646267652992602,
                "f1": 0.2347061896904596,
                "main_score": 0.2646267652992602
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.3157700067249495,
                "f1": 0.29663054588730453,
                "main_score": 0.3157700067249495
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.2798587760591795,
                "f1": 0.2514073861702641,
                "main_score": 0.2798587760591795
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.2826160053799597,
                "f1": 0.25406976600356346,
                "main_score": 0.2826160053799597
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.40373234700739746,
                "f1": 0.3684775969220266,
                "main_score": 0.40373234700739746
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.3420309347679893,
                "f1": 0.29937516367091355,
                "main_score": 0.3420309347679893
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.26015467383994617,
                "f1": 0.23974936009024375,
                "main_score": 0.26015467383994617
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6048419636852724,
                "f1": 0.5707615823930852,
                "main_score": 0.6048419636852724
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.36368527236045733,
                "f1": 0.3528610128351216,
                "main_score": 0.36368527236045733
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.48913920645595155,
                "f1": 0.4510811063972933,
                "main_score": 0.48913920645595155
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.30114324142568927,
                "f1": 0.27789916812631493,
                "main_score": 0.30114324142568927
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.3753194351042367,
                "f1": 0.3577870968876826,
                "main_score": 0.3753194351042367
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.24858776059179558,
                "f1": 0.24016121696621195,
                "main_score": 0.24858776059179558
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.3914256893073302,
                "f1": 0.3582510556127162,
                "main_score": 0.3914256893073302
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.3197041022192334,
                "f1": 0.29964722488737355,
                "main_score": 0.3197041022192334
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.31355077336919973,
                "f1": 0.27175518791441,
                "main_score": 0.31355077336919973
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.3703765971755212,
                "f1": 0.3594269966729341,
                "main_score": 0.3703765971755212
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.286079354404842,
                "f1": 0.25780613738124625,
                "main_score": 0.286079354404842
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.3785810356422326,
                "f1": 0.35910057289042974,
                "main_score": 0.3785810356422326
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.47901815736381986,
                "f1": 0.4449582926460981,
                "main_score": 0.47901815736381986
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.2907868190988568,
                "f1": 0.27191374864489587,
                "main_score": 0.2907868190988568
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.2577000672494956,
                "f1": 0.23628483056948565,
                "main_score": 0.2577000672494956
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.23661735036987225,
                "f1": 0.2066379761523298,
                "main_score": 0.23661735036987225
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.21267652992602554,
                "f1": 0.18697043783772252,
                "main_score": 0.21267652992602554
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.4042367182246133,
                "f1": 0.3708072704015134,
                "main_score": 0.4042367182246133
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.3012777404169469,
                "f1": 0.2812098399487521,
                "main_score": 0.3012777404169469
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.2589105581708137,
                "f1": 0.2362828321219826,
                "main_score": 0.2589105581708137
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.27713517148621386,
                "f1": 0.2639822334010705,
                "main_score": 0.27713517148621386
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.33036314727639543,
                "f1": 0.32086183132025886,
                "main_score": 0.33036314727639543
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.24193006052454602,
                "f1": 0.20242784930454744,
                "main_score": 0.24193006052454602
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.368897108271688,
                "f1": 0.3378550922159666,
                "main_score": 0.368897108271688
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.3930733019502354,
                "f1": 0.35591782756307133,
                "main_score": 0.3930733019502354
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.3177202420981843,
                "f1": 0.2941870580590916,
                "main_score": 0.3177202420981843
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.40262273032952256,
                "f1": 0.37674278643695247,
                "main_score": 0.40262273032952256
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.35416946872898447,
                "f1": 0.3401022965761375,
                "main_score": 0.35416946872898447
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.396906523201076,
                "f1": 0.3567303910099515,
                "main_score": 0.396906523201076
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.31086079354404844,
                "f1": 0.27947413132212034,
                "main_score": 0.31086079354404844
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.3514794889038332,
                "f1": 0.317603277822271,
                "main_score": 0.3514794889038332
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.3646267652992602,
                "f1": 0.33801055976714506,
                "main_score": 0.3646267652992602
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.279119031607263,
                "f1": 0.251703952528504,
                "main_score": 0.279119031607263
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.2812037659717552,
                "f1": 0.25154084848123415,
                "main_score": 0.2812037659717552
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.26338264963012775,
                "f1": 0.2294258645498349,
                "main_score": 0.26338264963012775
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.48241425689307327,
                "f1": 0.4629654473616155,
                "main_score": 0.48241425689307327
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.32733691997310016,
                "f1": 0.30034009399741,
                "main_score": 0.32733691997310016
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.3020847343644923,
                "f1": 0.293130936195692,
                "main_score": 0.3020847343644923
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.3027908540685945,
                "f1": 0.2775970336235819,
                "main_score": 0.3027908540685945
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.4045393409549429,
                "f1": 0.38469540400962854,
                "main_score": 0.4045393409549429
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.7098184263618024,
                "f1": 0.6852330903084527,
                "main_score": 0.7098184263618024
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.6403160726294551,
                "f1": 0.6285170205887711,
                "main_score": 0.6403160726294551
            }
        ]
    }
}