{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.014111,
        "f1": 0.004683,
        "f1_weighted": 0.006993,
        "scores_per_experiment": [
          {
            "accuracy": 0.015625,
            "f1": 0.003216,
            "f1_weighted": 0.005058
          },
          {
            "accuracy": 0.01416,
            "f1": 0.006125,
            "f1_weighted": 0.008565
          },
          {
            "accuracy": 0.011719,
            "f1": 0.002808,
            "f1_weighted": 0.004949
          },
          {
            "accuracy": 0.008789,
            "f1": 0.002643,
            "f1_weighted": 0.001782
          },
          {
            "accuracy": 0.007812,
            "f1": 0.003409,
            "f1_weighted": 0.003775
          },
          {
            "accuracy": 0.019043,
            "f1": 0.003823,
            "f1_weighted": 0.00877
          },
          {
            "accuracy": 0.013672,
            "f1": 0.0073,
            "f1_weighted": 0.010698
          },
          {
            "accuracy": 0.018066,
            "f1": 0.008149,
            "f1_weighted": 0.011447
          },
          {
            "accuracy": 0.013672,
            "f1": 0.004501,
            "f1_weighted": 0.007197
          },
          {
            "accuracy": 0.018555,
            "f1": 0.004856,
            "f1_weighted": 0.007689
          }
        ],
        "main_score": 0.014111,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.014697,
        "f1": 0.00389,
        "f1_weighted": 0.005505,
        "scores_per_experiment": [
          {
            "accuracy": 0.021484,
            "f1": 0.004533,
            "f1_weighted": 0.006426
          },
          {
            "accuracy": 0.012207,
            "f1": 0.003279,
            "f1_weighted": 0.004537
          },
          {
            "accuracy": 0.009277,
            "f1": 0.00349,
            "f1_weighted": 0.00271
          },
          {
            "accuracy": 0.012207,
            "f1": 0.00316,
            "f1_weighted": 0.00436
          },
          {
            "accuracy": 0.009766,
            "f1": 0.001696,
            "f1_weighted": 0.001514
          },
          {
            "accuracy": 0.018555,
            "f1": 0.002708,
            "f1_weighted": 0.00581
          },
          {
            "accuracy": 0.012207,
            "f1": 0.002745,
            "f1_weighted": 0.005442
          },
          {
            "accuracy": 0.018066,
            "f1": 0.006193,
            "f1_weighted": 0.009497
          },
          {
            "accuracy": 0.01416,
            "f1": 0.004188,
            "f1_weighted": 0.006778
          },
          {
            "accuracy": 0.019043,
            "f1": 0.006908,
            "f1_weighted": 0.00798
          }
        ],
        "main_score": 0.014697,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 2619.8325159549713,
  "kg_co2_emissions": 0.2226809447107246
}