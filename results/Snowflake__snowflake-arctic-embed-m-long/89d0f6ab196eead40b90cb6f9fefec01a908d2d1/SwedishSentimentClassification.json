{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.714551,
        "f1": 0.712252,
        "f1_weighted": 0.712285,
        "ap": 0.653094,
        "ap_weighted": 0.653094,
        "scores_per_experiment": [
          {
            "accuracy": 0.711914,
            "f1": 0.70936,
            "f1_weighted": 0.709439,
            "ap": 0.64499,
            "ap_weighted": 0.64499
          },
          {
            "accuracy": 0.709961,
            "f1": 0.707652,
            "f1_weighted": 0.707728,
            "ap": 0.643641,
            "ap_weighted": 0.643641
          },
          {
            "accuracy": 0.70752,
            "f1": 0.70401,
            "f1_weighted": 0.703916,
            "ap": 0.660657,
            "ap_weighted": 0.660657
          },
          {
            "accuracy": 0.72998,
            "f1": 0.729934,
            "f1_weighted": 0.729923,
            "ap": 0.670825,
            "ap_weighted": 0.670825
          },
          {
            "accuracy": 0.738281,
            "f1": 0.736674,
            "f1_weighted": 0.736734,
            "ap": 0.669487,
            "ap_weighted": 0.669487
          },
          {
            "accuracy": 0.666016,
            "f1": 0.655488,
            "f1_weighted": 0.655665,
            "ap": 0.6045,
            "ap_weighted": 0.6045
          },
          {
            "accuracy": 0.731934,
            "f1": 0.72968,
            "f1_weighted": 0.729752,
            "ap": 0.662663,
            "ap_weighted": 0.662663
          },
          {
            "accuracy": 0.741699,
            "f1": 0.741692,
            "f1_weighted": 0.741688,
            "ap": 0.68139,
            "ap_weighted": 0.68139
          },
          {
            "accuracy": 0.70166,
            "f1": 0.701489,
            "f1_weighted": 0.701468,
            "ap": 0.645081,
            "ap_weighted": 0.645081
          },
          {
            "accuracy": 0.706543,
            "f1": 0.70654,
            "f1_weighted": 0.706537,
            "ap": 0.647704,
            "ap_weighted": 0.647704
          }
        ],
        "main_score": 0.714551,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.715625,
        "f1": 0.713199,
        "f1_weighted": 0.713219,
        "ap": 0.653963,
        "ap_weighted": 0.653963,
        "scores_per_experiment": [
          {
            "accuracy": 0.711426,
            "f1": 0.708786,
            "f1_weighted": 0.70884,
            "ap": 0.644071,
            "ap_weighted": 0.644071
          },
          {
            "accuracy": 0.718262,
            "f1": 0.716044,
            "f1_weighted": 0.716093,
            "ap": 0.65043,
            "ap_weighted": 0.65043
          },
          {
            "accuracy": 0.710449,
            "f1": 0.706175,
            "f1_weighted": 0.706106,
            "ap": 0.664856,
            "ap_weighted": 0.664856
          },
          {
            "accuracy": 0.736328,
            "f1": 0.736247,
            "f1_weighted": 0.736238,
            "ap": 0.677067,
            "ap_weighted": 0.677067
          },
          {
            "accuracy": 0.737793,
            "f1": 0.736243,
            "f1_weighted": 0.736282,
            "ap": 0.668754,
            "ap_weighted": 0.668754
          },
          {
            "accuracy": 0.671387,
            "f1": 0.659861,
            "f1_weighted": 0.659983,
            "ap": 0.60786,
            "ap_weighted": 0.60786
          },
          {
            "accuracy": 0.73584,
            "f1": 0.734114,
            "f1_weighted": 0.734156,
            "ap": 0.666645,
            "ap_weighted": 0.666645
          },
          {
            "accuracy": 0.734375,
            "f1": 0.734332,
            "f1_weighted": 0.734326,
            "ap": 0.674556,
            "ap_weighted": 0.674556
          },
          {
            "accuracy": 0.696777,
            "f1": 0.696644,
            "f1_weighted": 0.696631,
            "ap": 0.639827,
            "ap_weighted": 0.639827
          },
          {
            "accuracy": 0.703613,
            "f1": 0.703545,
            "f1_weighted": 0.703537,
            "ap": 0.645568,
            "ap_weighted": 0.645568
          }
        ],
        "main_score": 0.715625,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 21.916242837905884,
  "kg_co2_emissions": 0.0010673292758226018
}