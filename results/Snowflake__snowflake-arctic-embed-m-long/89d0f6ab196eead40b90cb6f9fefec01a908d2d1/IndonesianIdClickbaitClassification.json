{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.545459,
        "f1": 0.537502,
        "f1_weighted": 0.53861,
        "ap": 0.452316,
        "ap_weighted": 0.452316,
        "scores_per_experiment": [
          {
            "accuracy": 0.604004,
            "f1": 0.598901,
            "f1_weighted": 0.606191,
            "ap": 0.48128,
            "ap_weighted": 0.48128
          },
          {
            "accuracy": 0.487793,
            "f1": 0.485816,
            "f1_weighted": 0.480678,
            "ap": 0.424925,
            "ap_weighted": 0.424925
          },
          {
            "accuracy": 0.541504,
            "f1": 0.511318,
            "f1_weighted": 0.530888,
            "ap": 0.427027,
            "ap_weighted": 0.427027
          },
          {
            "accuracy": 0.571777,
            "f1": 0.570815,
            "f1_weighted": 0.57409,
            "ap": 0.464647,
            "ap_weighted": 0.464647
          },
          {
            "accuracy": 0.57959,
            "f1": 0.579561,
            "f1_weighted": 0.580123,
            "ap": 0.47372,
            "ap_weighted": 0.47372
          },
          {
            "accuracy": 0.450684,
            "f1": 0.450023,
            "f1_weighted": 0.44695,
            "ap": 0.404975,
            "ap_weighted": 0.404975
          },
          {
            "accuracy": 0.515137,
            "f1": 0.500635,
            "f1_weighted": 0.486923,
            "ap": 0.449674,
            "ap_weighted": 0.449674
          },
          {
            "accuracy": 0.567383,
            "f1": 0.564793,
            "f1_weighted": 0.559382,
            "ap": 0.473635,
            "ap_weighted": 0.473635
          },
          {
            "accuracy": 0.583496,
            "f1": 0.564195,
            "f1_weighted": 0.578973,
            "ap": 0.457022,
            "ap_weighted": 0.457022
          },
          {
            "accuracy": 0.553223,
            "f1": 0.548964,
            "f1_weighted": 0.541902,
            "ap": 0.466258,
            "ap_weighted": 0.466258
          }
        ],
        "main_score": 0.537502,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.77320384979248,
  "kg_co2_emissions": 0.00035550192436126135
}