{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "task_name": "MTOPIntentClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.445289,
        "f1": 0.265724,
        "f1_weighted": 0.491048,
        "scores_per_experiment": [
          {
            "accuracy": 0.446832,
            "f1": 0.259501,
            "f1_weighted": 0.493779
          },
          {
            "accuracy": 0.4573,
            "f1": 0.290061,
            "f1_weighted": 0.505056
          },
          {
            "accuracy": 0.449587,
            "f1": 0.263775,
            "f1_weighted": 0.498666
          },
          {
            "accuracy": 0.386226,
            "f1": 0.229076,
            "f1_weighted": 0.433321
          },
          {
            "accuracy": 0.458402,
            "f1": 0.268191,
            "f1_weighted": 0.501227
          },
          {
            "accuracy": 0.429752,
            "f1": 0.257682,
            "f1_weighted": 0.476049
          },
          {
            "accuracy": 0.455096,
            "f1": 0.270925,
            "f1_weighted": 0.49909
          },
          {
            "accuracy": 0.447934,
            "f1": 0.274807,
            "f1_weighted": 0.490497
          },
          {
            "accuracy": 0.444077,
            "f1": 0.272421,
            "f1_weighted": 0.492535
          },
          {
            "accuracy": 0.477686,
            "f1": 0.270799,
            "f1_weighted": 0.520256
          }
        ],
        "main_score": 0.445289,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.447196,
        "f1": 0.26005,
        "f1_weighted": 0.494213,
        "scores_per_experiment": [
          {
            "accuracy": 0.44266,
            "f1": 0.259767,
            "f1_weighted": 0.491564
          },
          {
            "accuracy": 0.444351,
            "f1": 0.26208,
            "f1_weighted": 0.491057
          },
          {
            "accuracy": 0.448014,
            "f1": 0.257875,
            "f1_weighted": 0.503617
          },
          {
            "accuracy": 0.390814,
            "f1": 0.246712,
            "f1_weighted": 0.437488
          },
          {
            "accuracy": 0.46661,
            "f1": 0.260981,
            "f1_weighted": 0.50962
          },
          {
            "accuracy": 0.417864,
            "f1": 0.24935,
            "f1_weighted": 0.464104
          },
          {
            "accuracy": 0.477881,
            "f1": 0.268141,
            "f1_weighted": 0.52432
          },
          {
            "accuracy": 0.460693,
            "f1": 0.274992,
            "f1_weighted": 0.506379
          },
          {
            "accuracy": 0.457875,
            "f1": 0.269106,
            "f1_weighted": 0.507534
          },
          {
            "accuracy": 0.465201,
            "f1": 0.251494,
            "f1_weighted": 0.506447
          }
        ],
        "main_score": 0.447196,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 44.45949363708496,
  "kg_co2_emissions": null
}