{
  "dataset_revision": "human_evaluation",
  "task_name": "HUMESIB200ClusteringS2S",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "v_measure": 0.5399796886929997,
        "ari": 0.28570410931389206,
        "ami": 0.345946427767161,
        "main_score": 0.5399796886929997,
        "scores_per_experiment": [
          {
            "v_measure": 0.4174507096540219,
            "ari": 0.12433392539964476,
            "ami": 0.1742848072622657
          },
          {
            "v_measure": 0.6625086677319776,
            "ari": 0.4470742932281394,
            "ami": 0.5176080482720563
          }
        ],
        "agreement": {
          "metric": "mean_pairwise_ari",
          "value": 0.1508550011712345,
          "n_annotators": 2,
          "n_items": 30,
          "total_annotations": 60
        },
        "hf_subset": "eng_Latn",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "v_measure": 0.7601556159044528,
        "ari": 0.5983896940418679,
        "ami": 0.6580403082159044,
        "main_score": 0.7601556159044528,
        "hf_subset": "arb_Arab",
        "languages": [
          "ara-Arab"
        ]
      },
      {
        "v_measure": 0.6266209656940358,
        "ari": 0.36273599504797277,
        "ami": 0.44976555783829786,
        "main_score": 0.6266209656940358,
        "hf_subset": "dan_Latn",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "v_measure": 0.6805146209192693,
        "ari": 0.19278533412182142,
        "ami": 0.16888424360629792,
        "main_score": 0.6805146209192693,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ]
      }
    ]
  },
  "evaluation_time": 0,
  "kg_co2_emissions": null
}