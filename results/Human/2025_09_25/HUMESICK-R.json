{
  "dataset_revision": "human_evaluation",
  "task_name": "HUMESICK-R",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "spearman": 0.8264776647507771,
        "pearson": 0.8612778352217906,
        "mse": 0.40541124999999995,
        "main_score": 0.8264776647507771,
        "scores_per_experiment": [
          {
            "spearman": 0.8550952101996482,
            "pearson": 0.868542490226759,
            "mse": 0.40003625000000004
          },
          {
            "spearman": 0.684358803355082,
            "pearson": 0.7141779951514283,
            "mse": 1.0482862499999999
          }
        ],
        "agreement": {
          "metric": "mean_pairwise_spearman",
          "value": 0.6286212821184947,
          "n_annotators": 2,
          "n_items": 40,
          "total_annotations": 80
        },
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 0,
  "kg_co2_emissions": null
}