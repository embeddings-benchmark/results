{
  "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
  "task_name": "MassiveScenarioClassification",
  "mteb_version": "2.2.0",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.785539,
            "f1": 0.792852,
            "f1_weighted": 0.784332,
            "precision": 0.775205,
            "precision_weighted": 0.802443,
            "recall": 0.830219,
            "recall_weighted": 0.785539,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.757501,
            "f1": 0.767659,
            "f1_weighted": 0.756026,
            "precision": 0.750796,
            "precision_weighted": 0.786084,
            "recall": 0.816474,
            "recall_weighted": 0.757501,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.759469,
            "f1": 0.76515,
            "f1_weighted": 0.762436,
            "precision": 0.745904,
            "precision_weighted": 0.802113,
            "recall": 0.822251,
            "recall_weighted": 0.759469,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.730448,
            "f1": 0.737251,
            "f1_weighted": 0.734074,
            "precision": 0.724287,
            "precision_weighted": 0.771305,
            "recall": 0.786576,
            "recall_weighted": 0.730448,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.761436,
            "f1": 0.763055,
            "f1_weighted": 0.760928,
            "precision": 0.74503,
            "precision_weighted": 0.779655,
            "recall": 0.80379,
            "recall_weighted": 0.761436,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.753566,
            "f1": 0.751354,
            "f1_weighted": 0.749445,
            "precision": 0.73146,
            "precision_weighted": 0.776916,
            "recall": 0.804724,
            "recall_weighted": 0.753566,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.766355,
            "f1": 0.759554,
            "f1_weighted": 0.76481,
            "precision": 0.744553,
            "precision_weighted": 0.780895,
            "recall": 0.794911,
            "recall_weighted": 0.766355,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.757009,
            "f1": 0.760381,
            "f1_weighted": 0.75802,
            "precision": 0.742642,
            "precision_weighted": 0.789,
            "recall": 0.813865,
            "recall_weighted": 0.757009,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.790949,
            "f1": 0.784809,
            "f1_weighted": 0.789854,
            "precision": 0.772498,
            "precision_weighted": 0.79765,
            "recall": 0.808297,
            "recall_weighted": 0.790949,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.753566,
            "f1": 0.770588,
            "f1_weighted": 0.757085,
            "precision": 0.758511,
            "precision_weighted": 0.796993,
            "recall": 0.817295,
            "recall_weighted": 0.753566,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.761584,
        "f1": 0.765265,
        "f1_weighted": 0.761701,
        "precision": 0.749089,
        "precision_weighted": 0.788305,
        "recall": 0.80984,
        "recall_weighted": 0.761584,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.761584,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.778749,
            "f1": 0.785715,
            "f1_weighted": 0.778162,
            "precision": 0.767806,
            "precision_weighted": 0.79501,
            "recall": 0.822172,
            "recall_weighted": 0.778749,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.753531,
            "f1": 0.760388,
            "f1_weighted": 0.74917,
            "precision": 0.744195,
            "precision_weighted": 0.776033,
            "recall": 0.806507,
            "recall_weighted": 0.753531,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.753194,
            "f1": 0.765755,
            "f1_weighted": 0.756289,
            "precision": 0.747898,
            "precision_weighted": 0.797471,
            "recall": 0.822434,
            "recall_weighted": 0.753194,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.732011,
            "f1": 0.745682,
            "f1_weighted": 0.737756,
            "precision": 0.736006,
            "precision_weighted": 0.774502,
            "recall": 0.785179,
            "recall_weighted": 0.732011,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.761601,
            "f1": 0.761961,
            "f1_weighted": 0.759456,
            "precision": 0.748063,
            "precision_weighted": 0.777312,
            "recall": 0.799776,
            "recall_weighted": 0.761601,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.765636,
            "f1": 0.765195,
            "f1_weighted": 0.761526,
            "precision": 0.745309,
            "precision_weighted": 0.778121,
            "recall": 0.807897,
            "recall_weighted": 0.765636,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.766308,
            "f1": 0.767545,
            "f1_weighted": 0.765428,
            "precision": 0.747452,
            "precision_weighted": 0.785152,
            "recall": 0.810283,
            "recall_weighted": 0.766308,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.747814,
            "f1": 0.756487,
            "f1_weighted": 0.74928,
            "precision": 0.740492,
            "precision_weighted": 0.779097,
            "recall": 0.806315,
            "recall_weighted": 0.747814,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.782112,
            "f1": 0.780831,
            "f1_weighted": 0.781305,
            "precision": 0.765098,
            "precision_weighted": 0.788624,
            "recall": 0.805289,
            "recall_weighted": 0.782112,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.750504,
            "f1": 0.76292,
            "f1_weighted": 0.752871,
            "precision": 0.749838,
            "precision_weighted": 0.786838,
            "recall": 0.810674,
            "recall_weighted": 0.750504,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.759146,
        "f1": 0.765248,
        "f1_weighted": 0.759124,
        "precision": 0.749216,
        "precision_weighted": 0.783816,
        "recall": 0.807653,
        "recall_weighted": 0.759146,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.759146,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ]
  },
  "evaluation_time": 10.615137577056885,
  "kg_co2_emissions": null
}