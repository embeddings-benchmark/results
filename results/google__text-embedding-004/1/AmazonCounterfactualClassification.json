{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.34.7",
  "scores": {
    "test": [
      {
        "accuracy": 0.745373,
        "f1": 0.686813,
        "f1_weighted": 0.768895,
        "ap": 0.377458,
        "ap_weighted": 0.377458,
        "scores_per_experiment": [
          {
            "accuracy": 0.726866,
            "f1": 0.666526,
            "f1_weighted": 0.752907,
            "ap": 0.351352,
            "ap_weighted": 0.351352
          },
          {
            "accuracy": 0.783582,
            "f1": 0.718055,
            "f1_weighted": 0.800826,
            "ap": 0.405286,
            "ap_weighted": 0.405286
          },
          {
            "accuracy": 0.731343,
            "f1": 0.673503,
            "f1_weighted": 0.757187,
            "ap": 0.361563,
            "ap_weighted": 0.361563
          },
          {
            "accuracy": 0.747761,
            "f1": 0.685034,
            "f1_weighted": 0.770628,
            "ap": 0.369235,
            "ap_weighted": 0.369235
          },
          {
            "accuracy": 0.746269,
            "f1": 0.692578,
            "f1_weighted": 0.770813,
            "ap": 0.38797,
            "ap_weighted": 0.38797
          },
          {
            "accuracy": 0.78806,
            "f1": 0.727427,
            "f1_weighted": 0.805712,
            "ap": 0.421937,
            "ap_weighted": 0.421937
          },
          {
            "accuracy": 0.792537,
            "f1": 0.728701,
            "f1_weighted": 0.80884,
            "ap": 0.420224,
            "ap_weighted": 0.420224
          },
          {
            "accuracy": 0.773134,
            "f1": 0.711338,
            "f1_weighted": 0.79267,
            "ap": 0.400844,
            "ap_weighted": 0.400844
          },
          {
            "accuracy": 0.683582,
            "f1": 0.637005,
            "f1_weighted": 0.716186,
            "ap": 0.336162,
            "ap_weighted": 0.336162
          },
          {
            "accuracy": 0.680597,
            "f1": 0.627967,
            "f1_weighted": 0.713177,
            "ap": 0.320008,
            "ap_weighted": 0.320008
          }
        ],
        "main_score": 0.745373,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 22.72106432914734,
  "kg_co2_emissions": null
}