{
  "dataset_revision": "41a0848f718a28b9a6333b2be47b6dc93d5c1803",
  "task_name": "StyleClassification",
  "mteb_version": "1.38.38",
  "scores": {
    "test": [
      {
        "accuracy": 0.847135,
        "f1": 0.846735,
        "f1_weighted": 0.846688,
        "ap": 0.784466,
        "ap_weighted": 0.784466,
        "scores_per_experiment": [
          {
            "accuracy": 0.851562,
            "f1": 0.851441,
            "f1_weighted": 0.851396,
            "ap": 0.787961,
            "ap_weighted": 0.787961
          },
          {
            "accuracy": 0.882812,
            "f1": 0.882805,
            "f1_weighted": 0.882796,
            "ap": 0.830697,
            "ap_weighted": 0.830697
          },
          {
            "accuracy": 0.872396,
            "f1": 0.872326,
            "f1_weighted": 0.872357,
            "ap": 0.826187,
            "ap_weighted": 0.826187
          },
          {
            "accuracy": 0.820312,
            "f1": 0.819134,
            "f1_weighted": 0.818982,
            "ap": 0.744364,
            "ap_weighted": 0.744364
          },
          {
            "accuracy": 0.84375,
            "f1": 0.843733,
            "f1_weighted": 0.843716,
            "ap": 0.782647,
            "ap_weighted": 0.782647
          },
          {
            "accuracy": 0.877604,
            "f1": 0.877364,
            "f1_weighted": 0.877307,
            "ap": 0.815321,
            "ap_weighted": 0.815321
          },
          {
            "accuracy": 0.825521,
            "f1": 0.824059,
            "f1_weighted": 0.823892,
            "ap": 0.748387,
            "ap_weighted": 0.748387
          },
          {
            "accuracy": 0.8125,
            "f1": 0.812419,
            "f1_weighted": 0.812378,
            "ap": 0.745139,
            "ap_weighted": 0.745139
          },
          {
            "accuracy": 0.833333,
            "f1": 0.833043,
            "f1_weighted": 0.833116,
            "ap": 0.782104,
            "ap_weighted": 0.782104
          },
          {
            "accuracy": 0.851562,
            "f1": 0.851028,
            "f1_weighted": 0.850935,
            "ap": 0.781847,
            "ap_weighted": 0.781847
          }
        ],
        "main_score": 0.847135,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 25.885207176208496,
  "kg_co2_emissions": null
}