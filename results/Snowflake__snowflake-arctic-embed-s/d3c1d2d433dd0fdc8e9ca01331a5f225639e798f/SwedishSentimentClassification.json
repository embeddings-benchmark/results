{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.699561,
        "f1": 0.692316,
        "f1_weighted": 0.692447,
        "ap": 0.632527,
        "ap_weighted": 0.632527,
        "scores_per_experiment": [
          {
            "accuracy": 0.696289,
            "f1": 0.686716,
            "f1_weighted": 0.686877,
            "ap": 0.627735,
            "ap_weighted": 0.627735
          },
          {
            "accuracy": 0.690918,
            "f1": 0.683331,
            "f1_weighted": 0.683475,
            "ap": 0.624383,
            "ap_weighted": 0.624383
          },
          {
            "accuracy": 0.682617,
            "f1": 0.675175,
            "f1_weighted": 0.675319,
            "ap": 0.618013,
            "ap_weighted": 0.618013
          },
          {
            "accuracy": 0.674805,
            "f1": 0.659808,
            "f1_weighted": 0.660017,
            "ap": 0.609913,
            "ap_weighted": 0.609913
          },
          {
            "accuracy": 0.709473,
            "f1": 0.708872,
            "f1_weighted": 0.708911,
            "ap": 0.646303,
            "ap_weighted": 0.646303
          },
          {
            "accuracy": 0.686035,
            "f1": 0.678026,
            "f1_weighted": 0.678175,
            "ap": 0.620416,
            "ap_weighted": 0.620416
          },
          {
            "accuracy": 0.717773,
            "f1": 0.710062,
            "f1_weighted": 0.7102,
            "ap": 0.645695,
            "ap_weighted": 0.645695
          },
          {
            "accuracy": 0.704102,
            "f1": 0.698465,
            "f1_weighted": 0.698586,
            "ap": 0.635883,
            "ap_weighted": 0.635883
          },
          {
            "accuracy": 0.700195,
            "f1": 0.690416,
            "f1_weighted": 0.690577,
            "ap": 0.630697,
            "ap_weighted": 0.630697
          },
          {
            "accuracy": 0.733398,
            "f1": 0.732286,
            "f1_weighted": 0.732337,
            "ap": 0.666234,
            "ap_weighted": 0.666234
          }
        ],
        "main_score": 0.699561,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.704736,
        "f1": 0.698631,
        "f1_weighted": 0.698712,
        "ap": 0.636682,
        "ap_weighted": 0.636682,
        "scores_per_experiment": [
          {
            "accuracy": 0.703125,
            "f1": 0.695013,
            "f1_weighted": 0.69511,
            "ap": 0.633381,
            "ap_weighted": 0.633381
          },
          {
            "accuracy": 0.696777,
            "f1": 0.690263,
            "f1_weighted": 0.690351,
            "ap": 0.629141,
            "ap_weighted": 0.629141
          },
          {
            "accuracy": 0.681152,
            "f1": 0.674765,
            "f1_weighted": 0.674854,
            "ap": 0.616961,
            "ap_weighted": 0.616961
          },
          {
            "accuracy": 0.702148,
            "f1": 0.691644,
            "f1_weighted": 0.691755,
            "ap": 0.631597,
            "ap_weighted": 0.631597
          },
          {
            "accuracy": 0.70459,
            "f1": 0.703413,
            "f1_weighted": 0.70345,
            "ap": 0.640333,
            "ap_weighted": 0.640333
          },
          {
            "accuracy": 0.67627,
            "f1": 0.668728,
            "f1_weighted": 0.668826,
            "ap": 0.612743,
            "ap_weighted": 0.612743
          },
          {
            "accuracy": 0.727539,
            "f1": 0.721318,
            "f1_weighted": 0.721399,
            "ap": 0.654344,
            "ap_weighted": 0.654344
          },
          {
            "accuracy": 0.726562,
            "f1": 0.720968,
            "f1_weighted": 0.721045,
            "ap": 0.654008,
            "ap_weighted": 0.654008
          },
          {
            "accuracy": 0.689941,
            "f1": 0.682032,
            "f1_weighted": 0.68213,
            "ap": 0.62312,
            "ap_weighted": 0.62312
          },
          {
            "accuracy": 0.739258,
            "f1": 0.73817,
            "f1_weighted": 0.738203,
            "ap": 0.671188,
            "ap_weighted": 0.671188
          }
        ],
        "main_score": 0.704736,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.486779928207397,
  "kg_co2_emissions": 0.0005157912180540861
}