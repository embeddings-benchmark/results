{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "task_name": "PoemSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.449524,
        "f1": 0.326901,
        "f1_weighted": 0.506962,
        "scores_per_experiment": [
          {
            "accuracy": 0.409524,
            "f1": 0.318108,
            "f1_weighted": 0.462548
          },
          {
            "accuracy": 0.419048,
            "f1": 0.310516,
            "f1_weighted": 0.461716
          },
          {
            "accuracy": 0.457143,
            "f1": 0.32109,
            "f1_weighted": 0.510101
          },
          {
            "accuracy": 0.533333,
            "f1": 0.394363,
            "f1_weighted": 0.602803
          },
          {
            "accuracy": 0.447619,
            "f1": 0.315136,
            "f1_weighted": 0.505419
          },
          {
            "accuracy": 0.428571,
            "f1": 0.328347,
            "f1_weighted": 0.482216
          },
          {
            "accuracy": 0.466667,
            "f1": 0.355159,
            "f1_weighted": 0.541723
          },
          {
            "accuracy": 0.380952,
            "f1": 0.250497,
            "f1_weighted": 0.430982
          },
          {
            "accuracy": 0.428571,
            "f1": 0.301486,
            "f1_weighted": 0.486145
          },
          {
            "accuracy": 0.52381,
            "f1": 0.374313,
            "f1_weighted": 0.585962
          }
        ],
        "main_score": 0.449524,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.469231,
        "f1": 0.344547,
        "f1_weighted": 0.533713,
        "scores_per_experiment": [
          {
            "accuracy": 0.461538,
            "f1": 0.337985,
            "f1_weighted": 0.529173
          },
          {
            "accuracy": 0.548077,
            "f1": 0.402328,
            "f1_weighted": 0.605897
          },
          {
            "accuracy": 0.519231,
            "f1": 0.394321,
            "f1_weighted": 0.576209
          },
          {
            "accuracy": 0.471154,
            "f1": 0.350701,
            "f1_weighted": 0.544487
          },
          {
            "accuracy": 0.490385,
            "f1": 0.36087,
            "f1_weighted": 0.55989
          },
          {
            "accuracy": 0.432692,
            "f1": 0.30134,
            "f1_weighted": 0.494484
          },
          {
            "accuracy": 0.394231,
            "f1": 0.309427,
            "f1_weighted": 0.470696
          },
          {
            "accuracy": 0.471154,
            "f1": 0.32464,
            "f1_weighted": 0.553022
          },
          {
            "accuracy": 0.471154,
            "f1": 0.346678,
            "f1_weighted": 0.512782
          },
          {
            "accuracy": 0.432692,
            "f1": 0.317184,
            "f1_weighted": 0.490488
          }
        ],
        "main_score": 0.469231,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 13.215826749801636,
  "kg_co2_emissions": 0.0003716477810897398
}