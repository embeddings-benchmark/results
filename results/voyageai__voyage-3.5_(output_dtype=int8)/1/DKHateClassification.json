{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "2.1.11",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.705167,
            "f1": 0.594276,
            "f1_weighted": 0.753521,
            "precision": 0.603489,
            "precision_weighted": 0.862402,
            "recall": 0.716548,
            "recall_weighted": 0.705167,
            "ap": 0.926565,
            "ap_weighted": 0.926565
          },
          {
            "accuracy": 0.632219,
            "f1": 0.510615,
            "f1_weighted": 0.693762,
            "precision": 0.542368,
            "precision_weighted": 0.816357,
            "recall": 0.591209,
            "recall_weighted": 0.632219,
            "ap": 0.896006,
            "ap_weighted": 0.896006
          },
          {
            "accuracy": 0.702128,
            "f1": 0.559968,
            "f1_weighted": 0.74774,
            "precision": 0.567244,
            "precision_weighted": 0.829577,
            "recall": 0.63114,
            "recall_weighted": 0.702128,
            "ap": 0.905341,
            "ap_weighted": 0.905341
          },
          {
            "accuracy": 0.516717,
            "f1": 0.436698,
            "f1_weighted": 0.596091,
            "precision": 0.515576,
            "precision_weighted": 0.797361,
            "recall": 0.535696,
            "recall_weighted": 0.516717,
            "ap": 0.883306,
            "ap_weighted": 0.883306
          },
          {
            "accuracy": 0.665653,
            "f1": 0.560374,
            "f1_weighted": 0.72189,
            "precision": 0.58447,
            "precision_weighted": 0.851834,
            "recall": 0.68352,
            "recall_weighted": 0.665653,
            "ap": 0.918403,
            "ap_weighted": 0.918403
          },
          {
            "accuracy": 0.68997,
            "f1": 0.527299,
            "f1_weighted": 0.735484,
            "precision": 0.538192,
            "precision_weighted": 0.807898,
            "recall": 0.5719,
            "recall_weighted": 0.68997,
            "ap": 0.891462,
            "ap_weighted": 0.891462
          },
          {
            "accuracy": 0.553191,
            "f1": 0.461106,
            "f1_weighted": 0.628349,
            "precision": 0.52481,
            "precision_weighted": 0.805215,
            "recall": 0.556529,
            "recall_weighted": 0.553191,
            "ap": 0.888037,
            "ap_weighted": 0.888037
          },
          {
            "accuracy": 0.705167,
            "f1": 0.566664,
            "f1_weighted": 0.75059,
            "precision": 0.573098,
            "precision_weighted": 0.834067,
            "recall": 0.643335,
            "recall_weighted": 0.705167,
            "ap": 0.908272,
            "ap_weighted": 0.908272
          },
          {
            "accuracy": 0.744681,
            "f1": 0.587719,
            "f1_weighted": 0.778702,
            "precision": 0.582546,
            "precision_weighted": 0.834416,
            "recall": 0.644986,
            "recall_weighted": 0.744681,
            "ap": 0.908554,
            "ap_weighted": 0.908554
          },
          {
            "accuracy": 0.598784,
            "f1": 0.517552,
            "f1_weighted": 0.666176,
            "precision": 0.572898,
            "precision_weighted": 0.850892,
            "recall": 0.666243,
            "recall_weighted": 0.598784,
            "ap": 0.91446,
            "ap_weighted": 0.91446
          }
        ],
        "accuracy": 0.651368,
        "f1": 0.532227,
        "f1_weighted": 0.707231,
        "precision": 0.560469,
        "precision_weighted": 0.829002,
        "recall": 0.624111,
        "recall_weighted": 0.651368,
        "ap": 0.904041,
        "ap_weighted": 0.904041,
        "main_score": 0.651368,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 17.189498901367188,
  "kg_co2_emissions": null
}