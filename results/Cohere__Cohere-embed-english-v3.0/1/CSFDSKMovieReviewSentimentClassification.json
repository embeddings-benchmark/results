{
  "dataset_revision": "23a20c659d868740ef9c54854de631fe19cd5c17",
  "task_name": "CSFDSKMovieReviewSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.23999,
        "f1": 0.232425,
        "f1_weighted": 0.233533,
        "scores_per_experiment": [
          {
            "accuracy": 0.236816,
            "f1": 0.228395,
            "f1_weighted": 0.230511
          },
          {
            "accuracy": 0.231934,
            "f1": 0.225048,
            "f1_weighted": 0.226894
          },
          {
            "accuracy": 0.248047,
            "f1": 0.236228,
            "f1_weighted": 0.237687
          },
          {
            "accuracy": 0.243164,
            "f1": 0.243884,
            "f1_weighted": 0.243991
          },
          {
            "accuracy": 0.234863,
            "f1": 0.223822,
            "f1_weighted": 0.225259
          },
          {
            "accuracy": 0.245605,
            "f1": 0.231906,
            "f1_weighted": 0.232667
          },
          {
            "accuracy": 0.249023,
            "f1": 0.238456,
            "f1_weighted": 0.240263
          },
          {
            "accuracy": 0.237793,
            "f1": 0.229776,
            "f1_weighted": 0.230585
          },
          {
            "accuracy": 0.238281,
            "f1": 0.235439,
            "f1_weighted": 0.236194
          },
          {
            "accuracy": 0.234375,
            "f1": 0.231297,
            "f1_weighted": 0.231283
          }
        ],
        "main_score": 0.23999,
        "hf_subset": "default",
        "languages": [
          "slk-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 42.13929843902588,
  "kg_co2_emissions": null
}