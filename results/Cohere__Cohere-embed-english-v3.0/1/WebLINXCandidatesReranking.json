{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.123279,
        "mrr": 0.106432,
        "nAUC_map_max": -0.022272,
        "nAUC_map_std": 0.01169,
        "nAUC_map_diff1": 0.178453,
        "nAUC_mrr_max": -0.023019,
        "nAUC_mrr_std": -0.001168,
        "nAUC_mrr_diff1": 0.17897,
        "main_score": 0.106432,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.106751,
        "mrr": 0.090573,
        "nAUC_map_max": 0.060077,
        "nAUC_map_std": 0.147982,
        "nAUC_map_diff1": 0.124689,
        "nAUC_mrr_max": 0.076002,
        "nAUC_mrr_std": 0.139018,
        "nAUC_mrr_diff1": 0.120998,
        "main_score": 0.090573,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.079556,
        "mrr": 0.062754,
        "nAUC_map_max": 0.045999,
        "nAUC_map_std": 0.227987,
        "nAUC_map_diff1": 0.128019,
        "nAUC_mrr_max": 0.041086,
        "nAUC_mrr_std": 0.194616,
        "nAUC_mrr_diff1": 0.12375,
        "main_score": 0.062754,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.102854,
        "mrr": 0.083303,
        "nAUC_map_max": -0.02913,
        "nAUC_map_std": 0.079839,
        "nAUC_map_diff1": 0.074007,
        "nAUC_mrr_max": -0.022209,
        "nAUC_mrr_std": 0.077502,
        "nAUC_mrr_diff1": 0.07123,
        "main_score": 0.083303,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.110692,
        "mrr": 0.093097,
        "nAUC_map_max": 0.059351,
        "nAUC_map_std": 0.145351,
        "nAUC_map_diff1": 0.112442,
        "nAUC_mrr_max": 0.072896,
        "nAUC_mrr_std": 0.127661,
        "nAUC_mrr_diff1": 0.119121,
        "main_score": 0.093097,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.086321,
        "mrr": 0.070313,
        "nAUC_map_max": -0.010933,
        "nAUC_map_std": 0.146253,
        "nAUC_map_diff1": 0.170991,
        "nAUC_mrr_max": -0.006235,
        "nAUC_mrr_std": 0.130744,
        "nAUC_mrr_diff1": 0.179344,
        "main_score": 0.070313,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 24499.732177972794,
  "kg_co2_emissions": null
}