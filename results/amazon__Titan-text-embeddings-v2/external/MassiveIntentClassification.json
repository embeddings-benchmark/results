{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.47599193006052454,
                "f1": 0.4427505749600044,
                "main_score": 0.47599193006052454
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.3156691324815064,
                "f1": 0.3034952276390722,
                "main_score": 0.3156691324815064
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.5262945527908541,
                "f1": 0.49689536347222385,
                "main_score": 0.5262945527908541
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.500941492938803,
                "f1": 0.4847831879848094,
                "main_score": 0.500941492938803
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.46540013449899137,
                "f1": 0.44256633246301713,
                "main_score": 0.46540013449899137
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.4425689307330195,
                "f1": 0.4206066077477426,
                "main_score": 0.4425689307330195
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.5505716207128446,
                "f1": 0.5241516089202158,
                "main_score": 0.5505716207128446
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.6186953597848015,
                "f1": 0.5845989820228606,
                "main_score": 0.6186953597848015
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.47020847343644934,
                "f1": 0.4521525882986924,
                "main_score": 0.47020847343644934
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6924008069939476,
                "f1": 0.6827971089998472,
                "main_score": 0.6924008069939476
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.6253530598520511,
                "f1": 0.6183588971206536,
                "main_score": 0.6253530598520511
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.5519166106254204,
                "f1": 0.52335787325774,
                "main_score": 0.5519166106254204
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.4843308675184936,
                "f1": 0.45841102061239186,
                "main_score": 0.4843308675184936
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.6426698049764628,
                "f1": 0.622560748199624,
                "main_score": 0.6426698049764628
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.5761936785474109,
                "f1": 0.5493671211092237,
                "main_score": 0.5761936785474109
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.5753530598520511,
                "f1": 0.5536413211751344,
                "main_score": 0.5753530598520511
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.4566913248150638,
                "f1": 0.4252092657926257,
                "main_score": 0.4566913248150638
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.39199731002017485,
                "f1": 0.3719461340777357,
                "main_score": 0.39199731002017485
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.5499663752521856,
                "f1": 0.5387518115031535,
                "main_score": 0.5499663752521856
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.43143913920645593,
                "f1": 0.41756257561394455,
                "main_score": 0.43143913920645593
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.6099529253530599,
                "f1": 0.5910381212818371,
                "main_score": 0.6099529253530599
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.6429051782111634,
                "f1": 0.625268914542489,
                "main_score": 0.6429051782111634
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.4369199731002017,
                "f1": 0.4171651113018154,
                "main_score": 0.4369199731002017
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.3834566240753194,
                "f1": 0.36935911015227896,
                "main_score": 0.3834566240753194
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.34216543375924674,
                "f1": 0.32067289455027753,
                "main_score": 0.34216543375924674
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.5178547410894419,
                "f1": 0.49292856917796685,
                "main_score": 0.5178547410894419
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.5958977807666443,
                "f1": 0.5781630371862734,
                "main_score": 0.5958977807666443
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.4653665097511768,
                "f1": 0.448386852929464,
                "main_score": 0.4653665097511768
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.5446872898453262,
                "f1": 0.5213613631138984,
                "main_score": 0.5446872898453262
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.40679219905850705,
                "f1": 0.3987218130311539,
                "main_score": 0.40679219905850705
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.512441156691325,
                "f1": 0.4893351041227674,
                "main_score": 0.512441156691325
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.3176193678547411,
                "f1": 0.29917012787908787,
                "main_score": 0.3176193678547411
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.5440820443846671,
                "f1": 0.5123204915687439,
                "main_score": 0.5440820443846671
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.608170813718897,
                "f1": 0.5774887572270486,
                "main_score": 0.608170813718897
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.6006724949562878,
                "f1": 0.5760151669462318,
                "main_score": 0.6006724949562878
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.6273705447209146,
                "f1": 0.6114377989075874,
                "main_score": 0.6273705447209146
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.4968392737054472,
                "f1": 0.48070629186791286,
                "main_score": 0.4968392737054472
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.6085406859448554,
                "f1": 0.5848852652838252,
                "main_score": 0.6085406859448554
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.4858776059179556,
                "f1": 0.4692163099241966,
                "main_score": 0.4858776059179556
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.47168796234028243,
                "f1": 0.458155066134247,
                "main_score": 0.47168796234028243
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.6241425689307329,
                "f1": 0.6009795487819257,
                "main_score": 0.6241425689307329
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.45971755211835913,
                "f1": 0.44292752830003457,
                "main_score": 0.45971755211835913
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.5359784801613988,
                "f1": 0.5154318966923094,
                "main_score": 0.5359784801613988
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.5344653665097512,
                "f1": 0.5160095623356469,
                "main_score": 0.5344653665097512
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.4617350369872226,
                "f1": 0.46311285276929104,
                "main_score": 0.4617350369872226
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.4947881640887693,
                "f1": 0.46639898025891446,
                "main_score": 0.4947881640887693
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.5802958977807666,
                "f1": 0.5534728796730868,
                "main_score": 0.5802958977807666
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.3926361802286483,
                "f1": 0.3761201358829197,
                "main_score": 0.3926361802286483
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.5215534633490249,
                "f1": 0.5043895198062315,
                "main_score": 0.5215534633490249
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.6339946200403498,
                "f1": 0.6215224915017966,
                "main_score": 0.6339946200403498
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.5820780094149294,
                "f1": 0.583185844653981,
                "main_score": 0.5820780094149294
            }
        ]
    }
}