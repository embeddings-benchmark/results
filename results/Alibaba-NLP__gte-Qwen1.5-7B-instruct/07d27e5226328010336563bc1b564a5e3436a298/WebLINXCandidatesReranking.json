{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.165609,
        "mrr": 0.148282,
        "nAUC_map_max": -0.049807,
        "nAUC_map_std": -0.028355,
        "nAUC_map_diff1": 0.235929,
        "nAUC_mrr_max": -0.050928,
        "nAUC_mrr_std": -0.029611,
        "nAUC_mrr_diff1": 0.231105,
        "main_score": 0.148282,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.149633,
        "mrr": 0.134287,
        "nAUC_map_max": -0.005761,
        "nAUC_map_std": 0.098981,
        "nAUC_map_diff1": 0.120354,
        "nAUC_mrr_max": -0.015297,
        "nAUC_mrr_std": 0.08351,
        "nAUC_mrr_diff1": 0.123365,
        "main_score": 0.134287,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.110989,
        "mrr": 0.09486,
        "nAUC_map_max": 0.055742,
        "nAUC_map_std": 0.255467,
        "nAUC_map_diff1": 0.138612,
        "nAUC_mrr_max": 0.038062,
        "nAUC_mrr_std": 0.235353,
        "nAUC_mrr_diff1": 0.135004,
        "main_score": 0.09486,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.131111,
        "mrr": 0.111907,
        "nAUC_map_max": 0.007944,
        "nAUC_map_std": 0.084024,
        "nAUC_map_diff1": 0.156467,
        "nAUC_mrr_max": 0.000723,
        "nAUC_mrr_std": 0.070723,
        "nAUC_mrr_diff1": 0.16295,
        "main_score": 0.111907,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.133838,
        "mrr": 0.116405,
        "nAUC_map_max": 0.023768,
        "nAUC_map_std": 0.106427,
        "nAUC_map_diff1": 0.185931,
        "nAUC_mrr_max": 0.027458,
        "nAUC_mrr_std": 0.093326,
        "nAUC_mrr_diff1": 0.193642,
        "main_score": 0.116405,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.118441,
        "mrr": 0.100364,
        "nAUC_map_max": 0.023863,
        "nAUC_map_std": 0.209296,
        "nAUC_map_diff1": 0.232232,
        "nAUC_mrr_max": 0.029213,
        "nAUC_mrr_std": 0.205338,
        "nAUC_mrr_diff1": 0.238761,
        "main_score": 0.100364,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 16233.680040836334,
  "kg_co2_emissions": 4.646241602822736
}