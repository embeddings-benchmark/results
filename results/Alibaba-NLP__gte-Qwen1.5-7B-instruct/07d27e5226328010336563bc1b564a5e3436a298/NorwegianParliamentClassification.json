{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.59425,
        "f1": 0.583302,
        "f1_weighted": 0.583302,
        "ap": 0.560438,
        "ap_weighted": 0.560438,
        "scores_per_experiment": [
          {
            "accuracy": 0.539167,
            "f1": 0.53519,
            "f1_weighted": 0.53519,
            "ap": 0.520878,
            "ap_weighted": 0.520878
          },
          {
            "accuracy": 0.6175,
            "f1": 0.607343,
            "f1_weighted": 0.607343,
            "ap": 0.569196,
            "ap_weighted": 0.569196
          },
          {
            "accuracy": 0.62,
            "f1": 0.603046,
            "f1_weighted": 0.603046,
            "ap": 0.584545,
            "ap_weighted": 0.584545
          },
          {
            "accuracy": 0.650833,
            "f1": 0.650501,
            "f1_weighted": 0.650501,
            "ap": 0.599663,
            "ap_weighted": 0.599663
          },
          {
            "accuracy": 0.628333,
            "f1": 0.624322,
            "f1_weighted": 0.624322,
            "ap": 0.584926,
            "ap_weighted": 0.584926
          },
          {
            "accuracy": 0.604167,
            "f1": 0.568501,
            "f1_weighted": 0.568501,
            "ap": 0.558973,
            "ap_weighted": 0.558973
          },
          {
            "accuracy": 0.496667,
            "f1": 0.49464,
            "f1_weighted": 0.49464,
            "ap": 0.498346,
            "ap_weighted": 0.498346
          },
          {
            "accuracy": 0.499167,
            "f1": 0.486427,
            "f1_weighted": 0.486427,
            "ap": 0.499584,
            "ap_weighted": 0.499584
          },
          {
            "accuracy": 0.659167,
            "f1": 0.649126,
            "f1_weighted": 0.649126,
            "ap": 0.598513,
            "ap_weighted": 0.598513
          },
          {
            "accuracy": 0.6275,
            "f1": 0.613927,
            "f1_weighted": 0.613927,
            "ap": 0.58976,
            "ap_weighted": 0.58976
          }
        ],
        "main_score": 0.59425,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.587917,
        "f1": 0.576046,
        "f1_weighted": 0.576046,
        "ap": 0.556039,
        "ap_weighted": 0.556039,
        "scores_per_experiment": [
          {
            "accuracy": 0.5225,
            "f1": 0.518528,
            "f1_weighted": 0.518528,
            "ap": 0.511678,
            "ap_weighted": 0.511678
          },
          {
            "accuracy": 0.598333,
            "f1": 0.589088,
            "f1_weighted": 0.589088,
            "ap": 0.556605,
            "ap_weighted": 0.556605
          },
          {
            "accuracy": 0.61,
            "f1": 0.591404,
            "f1_weighted": 0.591404,
            "ap": 0.576105,
            "ap_weighted": 0.576105
          },
          {
            "accuracy": 0.656667,
            "f1": 0.655494,
            "f1_weighted": 0.655494,
            "ap": 0.606119,
            "ap_weighted": 0.606119
          },
          {
            "accuracy": 0.630833,
            "f1": 0.625665,
            "f1_weighted": 0.625665,
            "ap": 0.587792,
            "ap_weighted": 0.587792
          },
          {
            "accuracy": 0.573333,
            "f1": 0.530097,
            "f1_weighted": 0.530097,
            "ap": 0.540014,
            "ap_weighted": 0.540014
          },
          {
            "accuracy": 0.52,
            "f1": 0.518168,
            "f1_weighted": 0.518168,
            "ap": 0.510456,
            "ap_weighted": 0.510456
          },
          {
            "accuracy": 0.515833,
            "f1": 0.507618,
            "f1_weighted": 0.507618,
            "ap": 0.508116,
            "ap_weighted": 0.508116
          },
          {
            "accuracy": 0.623333,
            "f1": 0.609985,
            "f1_weighted": 0.609985,
            "ap": 0.57277,
            "ap_weighted": 0.57277
          },
          {
            "accuracy": 0.628333,
            "f1": 0.614414,
            "f1_weighted": 0.614414,
            "ap": 0.59073,
            "ap_weighted": 0.59073
          }
        ],
        "main_score": 0.587917,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 71.30161476135254,
  "kg_co2_emissions": 0.01794041891077801
}