{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.973253,
        "recall": 0.981946,
        "f1": 0.976095,
        "accuracy": 0.981946,
        "main_score": 0.976095,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.974423,
        "recall": 0.982949,
        "f1": 0.977265,
        "accuracy": 0.982949,
        "main_score": 0.977265,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.94985,
        "recall": 0.965898,
        "f1": 0.955032,
        "accuracy": 0.965898,
        "main_score": 0.955032,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.965731,
        "recall": 0.976931,
        "f1": 0.969408,
        "accuracy": 0.976931,
        "main_score": 0.969408,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.996991,
        "recall": 0.997994,
        "f1": 0.997325,
        "accuracy": 0.997994,
        "main_score": 0.997325,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.987964,
        "recall": 0.991976,
        "f1": 0.989301,
        "accuracy": 0.991976,
        "main_score": 0.989301,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.432564,
        "recall": 0.499498,
        "f1": 0.448357,
        "accuracy": 0.499498,
        "main_score": 0.448357,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.615723,
        "recall": 0.708124,
        "f1": 0.642645,
        "accuracy": 0.708124,
        "main_score": 0.642645,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.81989,
        "recall": 0.867603,
        "f1": 0.833801,
        "accuracy": 0.867603,
        "main_score": 0.833801,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.909813,
        "recall": 0.937813,
        "f1": 0.918823,
        "accuracy": 0.937813,
        "main_score": 0.918823,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.955199,
        "recall": 0.968907,
        "f1": 0.959545,
        "accuracy": 0.968907,
        "main_score": 0.959545,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.96874,
        "recall": 0.978937,
        "f1": 0.972083,
        "accuracy": 0.978937,
        "main_score": 0.972083,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.57977,
        "recall": 0.648947,
        "f1": 0.596034,
        "accuracy": 0.648947,
        "main_score": 0.596034,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.748362,
        "recall": 0.818455,
        "f1": 0.769795,
        "accuracy": 0.818455,
        "main_score": 0.769795,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.546248,
        "recall": 0.605817,
        "f1": 0.559755,
        "accuracy": 0.605817,
        "main_score": 0.559755,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.676826,
        "recall": 0.761284,
        "f1": 0.702176,
        "accuracy": 0.761284,
        "main_score": 0.702176,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.868923,
        "recall": 0.904714,
        "f1": 0.879391,
        "accuracy": 0.904714,
        "main_score": 0.879391,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.891792,
        "recall": 0.925777,
        "f1": 0.902775,
        "accuracy": 0.925777,
        "main_score": 0.902775,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.749275,
        "recall": 0.805416,
        "f1": 0.764517,
        "accuracy": 0.805416,
        "main_score": 0.764517,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.813892,
        "recall": 0.869609,
        "f1": 0.831227,
        "accuracy": 0.869609,
        "main_score": 0.831227,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.916959,
        "recall": 0.940822,
        "f1": 0.924228,
        "accuracy": 0.940822,
        "main_score": 0.924228,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.924273,
        "recall": 0.948847,
        "f1": 0.932297,
        "accuracy": 0.948847,
        "main_score": 0.932297,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.83714,
        "recall": 0.877633,
        "f1": 0.849024,
        "accuracy": 0.877633,
        "main_score": 0.849024,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.879388,
        "recall": 0.91675,
        "f1": 0.89124,
        "accuracy": 0.91675,
        "main_score": 0.89124,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.66691,
        "recall": 0.735206,
        "f1": 0.684726,
        "accuracy": 0.735206,
        "main_score": 0.684726,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.776396,
        "recall": 0.840522,
        "f1": 0.795955,
        "accuracy": 0.840522,
        "main_score": 0.795955,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.785004,
        "recall": 0.838516,
        "f1": 0.799874,
        "accuracy": 0.838516,
        "main_score": 0.799874,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.871281,
        "recall": 0.911735,
        "f1": 0.884487,
        "accuracy": 0.911735,
        "main_score": 0.884487,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.732067,
        "recall": 0.791374,
        "f1": 0.748507,
        "accuracy": 0.791374,
        "main_score": 0.748507,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.732146,
        "recall": 0.805416,
        "f1": 0.754315,
        "accuracy": 0.805416,
        "main_score": 0.754315,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.683166,
        "recall": 0.740221,
        "f1": 0.697688,
        "accuracy": 0.740221,
        "main_score": 0.697688,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.733099,
        "recall": 0.806419,
        "f1": 0.754998,
        "accuracy": 0.806419,
        "main_score": 0.754998,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.97994,
        "recall": 0.985958,
        "f1": 0.981946,
        "accuracy": 0.985958,
        "main_score": 0.981946,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.97342,
        "recall": 0.980943,
        "f1": 0.975928,
        "accuracy": 0.980943,
        "main_score": 0.975928,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.948178,
        "recall": 0.964895,
        "f1": 0.953694,
        "accuracy": 0.964895,
        "main_score": 0.953694,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.967235,
        "recall": 0.977934,
        "f1": 0.970746,
        "accuracy": 0.977934,
        "main_score": 0.970746,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.040003,
        "recall": 0.056169,
        "f1": 0.042827,
        "accuracy": 0.056169,
        "main_score": 0.042827,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.054106,
        "recall": 0.117352,
        "f1": 0.064809,
        "accuracy": 0.117352,
        "main_score": 0.064809,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.177114,
        "recall": 0.20662,
        "f1": 0.184669,
        "accuracy": 0.20662,
        "main_score": 0.184669,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.2185,
        "recall": 0.331996,
        "f1": 0.243938,
        "accuracy": 0.331996,
        "main_score": 0.243938,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.956369,
        "recall": 0.96991,
        "f1": 0.960715,
        "accuracy": 0.96991,
        "main_score": 0.960715,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.960883,
        "recall": 0.973922,
        "f1": 0.965229,
        "accuracy": 0.973922,
        "main_score": 0.965229,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.688815,
        "recall": 0.739218,
        "f1": 0.701651,
        "accuracy": 0.739218,
        "main_score": 0.701651,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.766232,
        "recall": 0.834504,
        "f1": 0.787462,
        "accuracy": 0.834504,
        "main_score": 0.787462,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.921598,
        "recall": 0.943831,
        "f1": 0.928251,
        "accuracy": 0.943831,
        "main_score": 0.928251,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.937479,
        "recall": 0.956871,
        "f1": 0.943831,
        "accuracy": 0.956871,
        "main_score": 0.943831,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.939769,
        "recall": 0.957874,
        "f1": 0.945403,
        "accuracy": 0.957874,
        "main_score": 0.945403,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.938649,
        "recall": 0.957874,
        "f1": 0.944835,
        "accuracy": 0.957874,
        "main_score": 0.944835,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.94888,
        "recall": 0.964895,
        "f1": 0.954029,
        "accuracy": 0.964895,
        "main_score": 0.954029,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.962387,
        "recall": 0.974925,
        "f1": 0.966566,
        "accuracy": 0.974925,
        "main_score": 0.966566,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.161522,
        "recall": 0.190572,
        "f1": 0.167908,
        "accuracy": 0.190572,
        "main_score": 0.167908,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.204277,
        "recall": 0.305918,
        "f1": 0.227397,
        "accuracy": 0.305918,
        "main_score": 0.227397,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.963725,
        "recall": 0.974925,
        "f1": 0.967235,
        "accuracy": 0.974925,
        "main_score": 0.967235,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.966065,
        "recall": 0.976931,
        "f1": 0.969575,
        "accuracy": 0.976931,
        "main_score": 0.969575,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.96456,
        "recall": 0.975928,
        "f1": 0.968238,
        "accuracy": 0.975928,
        "main_score": 0.968238,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.955868,
        "recall": 0.96991,
        "f1": 0.960381,
        "accuracy": 0.96991,
        "main_score": 0.960381,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.003678,
        "recall": 0.005015,
        "f1": 0.003964,
        "accuracy": 0.005015,
        "main_score": 0.003964,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004758,
        "recall": 0.018054,
        "f1": 0.005803,
        "accuracy": 0.018054,
        "main_score": 0.005803,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.976285,
        "recall": 0.98419,
        "f1": 0.97892,
        "accuracy": 0.98419,
        "main_score": 0.97892,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.982872,
        "recall": 0.988142,
        "f1": 0.984519,
        "accuracy": 0.988142,
        "main_score": 0.984519,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.964756,
        "recall": 0.976285,
        "f1": 0.968544,
        "accuracy": 0.976285,
        "main_score": 0.968544,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.97332,
        "recall": 0.982213,
        "f1": 0.976285,
        "accuracy": 0.982213,
        "main_score": 0.976285,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998518,
        "recall": 0.999012,
        "f1": 0.998682,
        "accuracy": 0.999012,
        "main_score": 0.998682,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.994071,
        "recall": 0.996047,
        "f1": 0.99473,
        "accuracy": 0.996047,
        "main_score": 0.99473,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.412201,
        "recall": 0.477273,
        "f1": 0.426346,
        "accuracy": 0.477273,
        "main_score": 0.426346,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.612879,
        "recall": 0.712451,
        "f1": 0.642328,
        "accuracy": 0.712451,
        "main_score": 0.642328,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.829943,
        "recall": 0.87253,
        "f1": 0.842081,
        "accuracy": 0.87253,
        "main_score": 0.842081,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.920784,
        "recall": 0.945652,
        "f1": 0.928854,
        "accuracy": 0.945652,
        "main_score": 0.928854,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.947958,
        "recall": 0.964427,
        "f1": 0.953228,
        "accuracy": 0.964427,
        "main_score": 0.953228,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.961957,
        "recall": 0.974308,
        "f1": 0.966074,
        "accuracy": 0.974308,
        "main_score": 0.966074,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.532297,
        "recall": 0.604743,
        "f1": 0.549833,
        "accuracy": 0.604743,
        "main_score": 0.549833,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.737418,
        "recall": 0.812253,
        "f1": 0.760592,
        "accuracy": 0.812253,
        "main_score": 0.760592,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.522104,
        "recall": 0.590909,
        "f1": 0.538298,
        "accuracy": 0.590909,
        "main_score": 0.538298,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.694977,
        "recall": 0.775692,
        "f1": 0.719222,
        "accuracy": 0.775692,
        "main_score": 0.719222,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.864887,
        "recall": 0.900198,
        "f1": 0.875395,
        "accuracy": 0.900198,
        "main_score": 0.875395,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.886034,
        "recall": 0.921937,
        "f1": 0.897563,
        "accuracy": 0.921937,
        "main_score": 0.897563,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.74212,
        "recall": 0.795455,
        "f1": 0.756595,
        "accuracy": 0.795455,
        "main_score": 0.756595,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.825922,
        "recall": 0.875494,
        "f1": 0.84114,
        "accuracy": 0.875494,
        "main_score": 0.84114,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.90315,
        "recall": 0.928854,
        "f1": 0.910688,
        "accuracy": 0.928854,
        "main_score": 0.910688,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.932395,
        "recall": 0.953557,
        "f1": 0.939295,
        "accuracy": 0.953557,
        "main_score": 0.939295,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.865675,
        "recall": 0.898221,
        "f1": 0.874693,
        "accuracy": 0.898221,
        "main_score": 0.874693,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.910079,
        "recall": 0.938735,
        "f1": 0.919466,
        "accuracy": 0.938735,
        "main_score": 0.919466,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.641686,
        "recall": 0.703557,
        "f1": 0.656875,
        "accuracy": 0.703557,
        "main_score": 0.656875,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.746657,
        "recall": 0.818182,
        "f1": 0.768365,
        "accuracy": 0.818182,
        "main_score": 0.768365,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.747108,
        "recall": 0.787549,
        "f1": 0.757961,
        "accuracy": 0.787549,
        "main_score": 0.757961,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.859931,
        "recall": 0.903162,
        "f1": 0.873748,
        "accuracy": 0.903162,
        "main_score": 0.873748,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.716336,
        "recall": 0.772727,
        "f1": 0.731461,
        "accuracy": 0.772727,
        "main_score": 0.731461,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.761512,
        "recall": 0.825099,
        "f1": 0.780632,
        "accuracy": 0.825099,
        "main_score": 0.780632,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.649595,
        "recall": 0.700593,
        "f1": 0.662111,
        "accuracy": 0.700593,
        "main_score": 0.662111,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.764493,
        "recall": 0.831028,
        "f1": 0.784453,
        "accuracy": 0.831028,
        "main_score": 0.784453,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.973897,
        "recall": 0.981225,
        "f1": 0.976186,
        "accuracy": 0.981225,
        "main_score": 0.976186,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.969697,
        "recall": 0.978261,
        "f1": 0.972497,
        "accuracy": 0.978261,
        "main_score": 0.972497,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.954051,
        "recall": 0.967391,
        "f1": 0.958136,
        "accuracy": 0.967391,
        "main_score": 0.958136,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.954381,
        "recall": 0.969368,
        "f1": 0.959321,
        "accuracy": 0.969368,
        "main_score": 0.959321,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.040787,
        "recall": 0.051383,
        "f1": 0.043219,
        "accuracy": 0.051383,
        "main_score": 0.043219,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.046422,
        "recall": 0.104743,
        "f1": 0.056341,
        "accuracy": 0.104743,
        "main_score": 0.056341,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.133152,
        "recall": 0.15415,
        "f1": 0.137531,
        "accuracy": 0.15415,
        "main_score": 0.137531,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.185234,
        "recall": 0.299407,
        "f1": 0.210802,
        "accuracy": 0.299407,
        "main_score": 0.210802,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.947217,
        "recall": 0.963439,
        "f1": 0.952306,
        "accuracy": 0.963439,
        "main_score": 0.952306,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.957839,
        "recall": 0.971344,
        "f1": 0.962286,
        "accuracy": 0.971344,
        "main_score": 0.962286,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.682086,
        "recall": 0.73419,
        "f1": 0.695018,
        "accuracy": 0.73419,
        "main_score": 0.695018,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.776762,
        "recall": 0.837945,
        "f1": 0.795487,
        "accuracy": 0.837945,
        "main_score": 0.795487,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.937198,
        "recall": 0.954545,
        "f1": 0.942391,
        "accuracy": 0.954545,
        "main_score": 0.942391,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.95364,
        "recall": 0.968379,
        "f1": 0.958399,
        "accuracy": 0.968379,
        "main_score": 0.958399,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.938498,
        "recall": 0.955534,
        "f1": 0.943659,
        "accuracy": 0.955534,
        "main_score": 0.943659,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.954381,
        "recall": 0.969368,
        "f1": 0.959321,
        "accuracy": 0.969368,
        "main_score": 0.959321,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.918272,
        "recall": 0.9417,
        "f1": 0.925535,
        "accuracy": 0.9417,
        "main_score": 0.925535,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.964345,
        "recall": 0.975296,
        "f1": 0.967787,
        "accuracy": 0.975296,
        "main_score": 0.967787,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.15425,
        "recall": 0.173913,
        "f1": 0.158389,
        "accuracy": 0.173913,
        "main_score": 0.158389,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.190339,
        "recall": 0.300395,
        "f1": 0.214292,
        "accuracy": 0.300395,
        "main_score": 0.214292,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.958827,
        "recall": 0.972332,
        "f1": 0.963274,
        "accuracy": 0.972332,
        "main_score": 0.963274,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.982213,
        "recall": 0.988142,
        "f1": 0.98419,
        "accuracy": 0.988142,
        "main_score": 0.98419,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.962533,
        "recall": 0.974308,
        "f1": 0.966304,
        "accuracy": 0.974308,
        "main_score": 0.966304,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.956604,
        "recall": 0.970356,
        "f1": 0.961034,
        "accuracy": 0.970356,
        "main_score": 0.961034,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.003959,
        "recall": 0.005929,
        "f1": 0.003965,
        "accuracy": 0.005929,
        "main_score": 0.003965,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004233,
        "recall": 0.025692,
        "f1": 0.005836,
        "accuracy": 0.025692,
        "main_score": 0.005836,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 1444.8619871139526,
  "kg_co2_emissions": 0.40527639320839115
}