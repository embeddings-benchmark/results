{
  "dataset_revision": "349481ec73fff722f88e0453ca05c77a447d967c",
  "task_name": "KLUE-TC",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.608057,
        "f1": 0.612069,
        "f1_weighted": 0.600601,
        "scores_per_experiment": [
          {
            "accuracy": 0.57666,
            "f1": 0.591332,
            "f1_weighted": 0.565083
          },
          {
            "accuracy": 0.602539,
            "f1": 0.627286,
            "f1_weighted": 0.598856
          },
          {
            "accuracy": 0.570801,
            "f1": 0.592393,
            "f1_weighted": 0.549574
          },
          {
            "accuracy": 0.648438,
            "f1": 0.641824,
            "f1_weighted": 0.647389
          },
          {
            "accuracy": 0.605957,
            "f1": 0.606719,
            "f1_weighted": 0.590645
          },
          {
            "accuracy": 0.566895,
            "f1": 0.581636,
            "f1_weighted": 0.550777
          },
          {
            "accuracy": 0.683594,
            "f1": 0.666466,
            "f1_weighted": 0.683013
          },
          {
            "accuracy": 0.621094,
            "f1": 0.617555,
            "f1_weighted": 0.623081
          },
          {
            "accuracy": 0.581055,
            "f1": 0.583079,
            "f1_weighted": 0.578948
          },
          {
            "accuracy": 0.623535,
            "f1": 0.612398,
            "f1_weighted": 0.618641
          }
        ],
        "main_score": 0.608057,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ]
      }
    ]
  },
  "evaluation_time": 87.86983370780945,
  "kg_co2_emissions": 0.019485471692417163
}