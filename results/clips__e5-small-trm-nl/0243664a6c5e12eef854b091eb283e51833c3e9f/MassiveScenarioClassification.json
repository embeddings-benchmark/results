{
  "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
  "task_name": "MassiveScenarioClassification",
  "mteb_version": "2.3.0",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.687654,
            "f1": 0.67527,
            "f1_weighted": 0.683124,
            "precision": 0.653234,
            "precision_weighted": 0.718686,
            "recall": 0.745418,
            "recall_weighted": 0.687654,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.666995,
            "f1": 0.653957,
            "f1_weighted": 0.665394,
            "precision": 0.639742,
            "precision_weighted": 0.715549,
            "recall": 0.730521,
            "recall_weighted": 0.666995,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.678308,
            "f1": 0.659678,
            "f1_weighted": 0.677548,
            "precision": 0.647962,
            "precision_weighted": 0.725112,
            "recall": 0.724069,
            "recall_weighted": 0.678308,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.648795,
            "f1": 0.633101,
            "f1_weighted": 0.647351,
            "precision": 0.615986,
            "precision_weighted": 0.691424,
            "recall": 0.707702,
            "recall_weighted": 0.648795,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.664535,
            "f1": 0.647184,
            "f1_weighted": 0.652937,
            "precision": 0.637471,
            "precision_weighted": 0.70633,
            "recall": 0.725742,
            "recall_weighted": 0.664535,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.632071,
            "f1": 0.616375,
            "f1_weighted": 0.618624,
            "precision": 0.607773,
            "precision_weighted": 0.685218,
            "recall": 0.6933,
            "recall_weighted": 0.632071,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.667486,
            "f1": 0.648783,
            "f1_weighted": 0.669184,
            "precision": 0.638457,
            "precision_weighted": 0.718222,
            "recall": 0.716001,
            "recall_weighted": 0.667486,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.674865,
            "f1": 0.670885,
            "f1_weighted": 0.675563,
            "precision": 0.654881,
            "precision_weighted": 0.718102,
            "recall": 0.725094,
            "recall_weighted": 0.674865,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.683719,
            "f1": 0.677788,
            "f1_weighted": 0.685848,
            "precision": 0.661175,
            "precision_weighted": 0.724499,
            "recall": 0.735391,
            "recall_weighted": 0.683719,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.655189,
            "f1": 0.643516,
            "f1_weighted": 0.653386,
            "precision": 0.631249,
            "precision_weighted": 0.703015,
            "recall": 0.714828,
            "recall_weighted": 0.655189,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.665962,
        "f1": 0.652654,
        "f1_weighted": 0.662896,
        "precision": 0.638793,
        "precision_weighted": 0.710616,
        "recall": 0.721807,
        "recall_weighted": 0.665962,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.665962,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.692334,
            "f1": 0.680889,
            "f1_weighted": 0.687566,
            "precision": 0.661441,
            "precision_weighted": 0.7179,
            "recall": 0.740585,
            "recall_weighted": 0.692334,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.694351,
            "f1": 0.680604,
            "f1_weighted": 0.689121,
            "precision": 0.662394,
            "precision_weighted": 0.728957,
            "recall": 0.750284,
            "recall_weighted": 0.694351,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.681574,
            "f1": 0.661277,
            "f1_weighted": 0.676604,
            "precision": 0.646827,
            "precision_weighted": 0.712383,
            "recall": 0.720682,
            "recall_weighted": 0.681574,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.671486,
            "f1": 0.659683,
            "f1_weighted": 0.675476,
            "precision": 0.649337,
            "precision_weighted": 0.721034,
            "recall": 0.721221,
            "recall_weighted": 0.671486,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.682246,
            "f1": 0.663871,
            "f1_weighted": 0.669679,
            "precision": 0.657242,
            "precision_weighted": 0.721221,
            "recall": 0.735543,
            "recall_weighted": 0.682246,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.648285,
            "f1": 0.627156,
            "f1_weighted": 0.638554,
            "precision": 0.624944,
            "precision_weighted": 0.702565,
            "recall": 0.692483,
            "recall_weighted": 0.648285,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.667451,
            "f1": 0.654779,
            "f1_weighted": 0.669302,
            "precision": 0.643448,
            "precision_weighted": 0.722564,
            "recall": 0.723321,
            "recall_weighted": 0.667451,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.683591,
            "f1": 0.678124,
            "f1_weighted": 0.686999,
            "precision": 0.667259,
            "precision_weighted": 0.731933,
            "recall": 0.726519,
            "recall_weighted": 0.683591,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.700403,
            "f1": 0.688357,
            "f1_weighted": 0.70168,
            "precision": 0.677901,
            "precision_weighted": 0.741107,
            "recall": 0.740116,
            "recall_weighted": 0.700403,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.656691,
            "f1": 0.646582,
            "f1_weighted": 0.655009,
            "precision": 0.637296,
            "precision_weighted": 0.710925,
            "recall": 0.718192,
            "recall_weighted": 0.656691,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.677841,
        "f1": 0.664132,
        "f1_weighted": 0.674999,
        "precision": 0.652809,
        "precision_weighted": 0.721059,
        "recall": 0.726895,
        "recall_weighted": 0.677841,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.677841,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 22.007591009140015,
  "kg_co2_emissions": null
}