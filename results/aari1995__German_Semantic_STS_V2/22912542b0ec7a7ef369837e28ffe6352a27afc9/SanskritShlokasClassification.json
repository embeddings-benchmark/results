{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.681984,
        "f1": 0.659011,
        "f1_weighted": 0.662137,
        "scores_per_experiment": [
          {
            "accuracy": 0.686684,
            "f1": 0.665846,
            "f1_weighted": 0.671469
          },
          {
            "accuracy": 0.718016,
            "f1": 0.697611,
            "f1_weighted": 0.702286
          },
          {
            "accuracy": 0.73107,
            "f1": 0.711777,
            "f1_weighted": 0.716205
          },
          {
            "accuracy": 0.710183,
            "f1": 0.656682,
            "f1_weighted": 0.666195
          },
          {
            "accuracy": 0.715405,
            "f1": 0.705921,
            "f1_weighted": 0.710271
          },
          {
            "accuracy": 0.668407,
            "f1": 0.639043,
            "f1_weighted": 0.646008
          },
          {
            "accuracy": 0.684073,
            "f1": 0.680831,
            "f1_weighted": 0.683038
          },
          {
            "accuracy": 0.613577,
            "f1": 0.616219,
            "f1_weighted": 0.614181
          },
          {
            "accuracy": 0.62141,
            "f1": 0.575801,
            "f1_weighted": 0.564277
          },
          {
            "accuracy": 0.671018,
            "f1": 0.640375,
            "f1_weighted": 0.647442
          }
        ],
        "main_score": 0.681984,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.691667,
        "f1": 0.675655,
        "f1_weighted": 0.672271,
        "scores_per_experiment": [
          {
            "accuracy": 0.739583,
            "f1": 0.72691,
            "f1_weighted": 0.72812
          },
          {
            "accuracy": 0.729167,
            "f1": 0.715756,
            "f1_weighted": 0.717409
          },
          {
            "accuracy": 0.697917,
            "f1": 0.68596,
            "f1_weighted": 0.686844
          },
          {
            "accuracy": 0.71875,
            "f1": 0.65787,
            "f1_weighted": 0.669256
          },
          {
            "accuracy": 0.739583,
            "f1": 0.731893,
            "f1_weighted": 0.731705
          },
          {
            "accuracy": 0.708333,
            "f1": 0.676329,
            "f1_weighted": 0.681914
          },
          {
            "accuracy": 0.6875,
            "f1": 0.701426,
            "f1_weighted": 0.688196
          },
          {
            "accuracy": 0.614583,
            "f1": 0.623453,
            "f1_weighted": 0.615461
          },
          {
            "accuracy": 0.583333,
            "f1": 0.571057,
            "f1_weighted": 0.532832
          },
          {
            "accuracy": 0.697917,
            "f1": 0.665901,
            "f1_weighted": 0.670971
          }
        ],
        "main_score": 0.691667,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 14.325079202651978,
  "kg_co2_emissions": 0.0004282309618817807
}