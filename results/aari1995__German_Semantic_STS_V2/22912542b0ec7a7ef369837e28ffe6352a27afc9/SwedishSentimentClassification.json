{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.707324,
        "f1": 0.705417,
        "f1_weighted": 0.705429,
        "ap": 0.64939,
        "ap_weighted": 0.64939,
        "scores_per_experiment": [
          {
            "accuracy": 0.660156,
            "f1": 0.644484,
            "f1_weighted": 0.644703,
            "ap": 0.599149,
            "ap_weighted": 0.599149
          },
          {
            "accuracy": 0.694336,
            "f1": 0.693386,
            "f1_weighted": 0.693436,
            "ap": 0.632471,
            "ap_weighted": 0.632471
          },
          {
            "accuracy": 0.70459,
            "f1": 0.70415,
            "f1_weighted": 0.704116,
            "ap": 0.649238,
            "ap_weighted": 0.649238
          },
          {
            "accuracy": 0.695312,
            "f1": 0.694613,
            "f1_weighted": 0.69457,
            "ap": 0.641453,
            "ap_weighted": 0.641453
          },
          {
            "accuracy": 0.728516,
            "f1": 0.72834,
            "f1_weighted": 0.72832,
            "ap": 0.670822,
            "ap_weighted": 0.670822
          },
          {
            "accuracy": 0.726562,
            "f1": 0.725909,
            "f1_weighted": 0.72587,
            "ap": 0.671798,
            "ap_weighted": 0.671798
          },
          {
            "accuracy": 0.742676,
            "f1": 0.742447,
            "f1_weighted": 0.742425,
            "ap": 0.68553,
            "ap_weighted": 0.68553
          },
          {
            "accuracy": 0.70752,
            "f1": 0.707519,
            "f1_weighted": 0.70752,
            "ap": 0.648163,
            "ap_weighted": 0.648163
          },
          {
            "accuracy": 0.692383,
            "f1": 0.692184,
            "f1_weighted": 0.692207,
            "ap": 0.632813,
            "ap_weighted": 0.632813
          },
          {
            "accuracy": 0.721191,
            "f1": 0.721135,
            "f1_weighted": 0.721124,
            "ap": 0.662461,
            "ap_weighted": 0.662461
          }
        ],
        "main_score": 0.707324,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.713184,
        "f1": 0.711055,
        "f1_weighted": 0.711066,
        "ap": 0.653934,
        "ap_weighted": 0.653934,
        "scores_per_experiment": [
          {
            "accuracy": 0.665527,
            "f1": 0.647512,
            "f1_weighted": 0.647667,
            "ap": 0.602277,
            "ap_weighted": 0.602277
          },
          {
            "accuracy": 0.699219,
            "f1": 0.698076,
            "f1_weighted": 0.698112,
            "ap": 0.635817,
            "ap_weighted": 0.635817
          },
          {
            "accuracy": 0.704102,
            "f1": 0.703715,
            "f1_weighted": 0.703694,
            "ap": 0.648005,
            "ap_weighted": 0.648005
          },
          {
            "accuracy": 0.706055,
            "f1": 0.705486,
            "f1_weighted": 0.705461,
            "ap": 0.650646,
            "ap_weighted": 0.650646
          },
          {
            "accuracy": 0.728516,
            "f1": 0.728312,
            "f1_weighted": 0.728298,
            "ap": 0.670536,
            "ap_weighted": 0.670536
          },
          {
            "accuracy": 0.73877,
            "f1": 0.73836,
            "f1_weighted": 0.73834,
            "ap": 0.682361,
            "ap_weighted": 0.682361
          },
          {
            "accuracy": 0.736328,
            "f1": 0.73602,
            "f1_weighted": 0.736002,
            "ap": 0.679168,
            "ap_weighted": 0.679168
          },
          {
            "accuracy": 0.728027,
            "f1": 0.727965,
            "f1_weighted": 0.727973,
            "ap": 0.66543,
            "ap_weighted": 0.66543
          },
          {
            "accuracy": 0.693359,
            "f1": 0.693191,
            "f1_weighted": 0.693205,
            "ap": 0.633329,
            "ap_weighted": 0.633329
          },
          {
            "accuracy": 0.731934,
            "f1": 0.731911,
            "f1_weighted": 0.731906,
            "ap": 0.671775,
            "ap_weighted": 0.671775
          }
        ],
        "main_score": 0.713184,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 26.51456379890442,
  "kg_co2_emissions": 0.0013938039237272255
}