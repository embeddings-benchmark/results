{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.11569,
        "recall": 0.157227,
        "f1": 0.127102,
        "accuracy": 0.157227,
        "main_score": 0.127102,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.084142,
        "recall": 0.135742,
        "f1": 0.096081,
        "accuracy": 0.135742,
        "main_score": 0.096081,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.044077,
        "recall": 0.071289,
        "f1": 0.049921,
        "accuracy": 0.071289,
        "main_score": 0.049921,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000988,
        "recall": 0.003906,
        "f1": 0.000999,
        "accuracy": 0.003906,
        "main_score": 0.000999,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.036465,
        "recall": 0.0625,
        "f1": 0.041378,
        "accuracy": 0.0625,
        "main_score": 0.041378,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.072026,
        "recall": 0.104492,
        "f1": 0.080151,
        "accuracy": 0.104492,
        "main_score": 0.080151,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.049071,
        "recall": 0.09082,
        "f1": 0.058606,
        "accuracy": 0.09082,
        "main_score": 0.058606,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.053668,
        "recall": 0.074219,
        "f1": 0.058638,
        "accuracy": 0.074219,
        "main_score": 0.058638,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.011516,
        "recall": 0.033203,
        "f1": 0.014648,
        "accuracy": 0.033203,
        "main_score": 0.014648,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.096427,
        "recall": 0.136719,
        "f1": 0.106743,
        "accuracy": 0.136719,
        "main_score": 0.106743,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.021728,
        "recall": 0.038086,
        "f1": 0.024616,
        "accuracy": 0.038086,
        "main_score": 0.024616,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.072806,
        "recall": 0.106445,
        "f1": 0.081031,
        "accuracy": 0.106445,
        "main_score": 0.081031,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.10848,
        "recall": 0.15332,
        "f1": 0.119855,
        "accuracy": 0.15332,
        "main_score": 0.119855,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.08611,
        "recall": 0.128906,
        "f1": 0.095758,
        "accuracy": 0.128906,
        "main_score": 0.095758,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.112169,
        "recall": 0.154297,
        "f1": 0.123053,
        "accuracy": 0.154297,
        "main_score": 0.123053,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.025141,
        "recall": 0.056641,
        "f1": 0.031676,
        "accuracy": 0.056641,
        "main_score": 0.031676,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.028817,
        "recall": 0.052734,
        "f1": 0.032602,
        "accuracy": 0.052734,
        "main_score": 0.032602,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.061261,
        "recall": 0.087891,
        "f1": 0.066391,
        "accuracy": 0.087891,
        "main_score": 0.066391,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.06141,
        "recall": 0.101562,
        "f1": 0.070803,
        "accuracy": 0.101562,
        "main_score": 0.070803,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.017786,
        "recall": 0.039062,
        "f1": 0.02162,
        "accuracy": 0.039062,
        "main_score": 0.02162,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.014264,
        "recall": 0.032227,
        "f1": 0.016965,
        "accuracy": 0.032227,
        "main_score": 0.016965,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007217,
        "recall": 0.021484,
        "f1": 0.009228,
        "accuracy": 0.021484,
        "main_score": 0.009228,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.107601,
        "recall": 0.147461,
        "f1": 0.117943,
        "accuracy": 0.147461,
        "main_score": 0.117943,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.051123,
        "recall": 0.088867,
        "f1": 0.059046,
        "accuracy": 0.088867,
        "main_score": 0.059046,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.035761,
        "recall": 0.061523,
        "f1": 0.041226,
        "accuracy": 0.061523,
        "main_score": 0.041226,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000987,
        "recall": 0.003906,
        "f1": 0.000998,
        "accuracy": 0.003906,
        "main_score": 0.000998,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.032529,
        "recall": 0.057617,
        "f1": 0.037485,
        "accuracy": 0.057617,
        "main_score": 0.037485,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.060583,
        "recall": 0.087891,
        "f1": 0.066545,
        "accuracy": 0.087891,
        "main_score": 0.066545,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.040454,
        "recall": 0.067383,
        "f1": 0.046539,
        "accuracy": 0.067383,
        "main_score": 0.046539,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.038278,
        "recall": 0.052734,
        "f1": 0.041288,
        "accuracy": 0.052734,
        "main_score": 0.041288,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.010042,
        "recall": 0.03418,
        "f1": 0.013298,
        "accuracy": 0.03418,
        "main_score": 0.013298,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.098771,
        "recall": 0.138672,
        "f1": 0.1088,
        "accuracy": 0.138672,
        "main_score": 0.1088,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.022109,
        "recall": 0.036133,
        "f1": 0.024473,
        "accuracy": 0.036133,
        "main_score": 0.024473,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.062089,
        "recall": 0.084961,
        "f1": 0.066686,
        "accuracy": 0.084961,
        "main_score": 0.066686,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.081955,
        "recall": 0.121094,
        "f1": 0.092179,
        "accuracy": 0.121094,
        "main_score": 0.092179,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.095627,
        "recall": 0.131836,
        "f1": 0.105214,
        "accuracy": 0.131836,
        "main_score": 0.105214,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.077769,
        "recall": 0.114258,
        "f1": 0.086807,
        "accuracy": 0.114258,
        "main_score": 0.086807,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.035779,
        "recall": 0.0625,
        "f1": 0.040923,
        "accuracy": 0.0625,
        "main_score": 0.040923,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.020696,
        "recall": 0.037109,
        "f1": 0.023906,
        "accuracy": 0.037109,
        "main_score": 0.023906,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.09615,
        "recall": 0.137695,
        "f1": 0.106036,
        "accuracy": 0.137695,
        "main_score": 0.106036,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.033025,
        "recall": 0.058594,
        "f1": 0.038017,
        "accuracy": 0.058594,
        "main_score": 0.038017,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.024536,
        "recall": 0.041992,
        "f1": 0.028397,
        "accuracy": 0.041992,
        "main_score": 0.028397,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.022288,
        "recall": 0.039062,
        "f1": 0.025318,
        "accuracy": 0.039062,
        "main_score": 0.025318,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006616,
        "recall": 0.020508,
        "f1": 0.008574,
        "accuracy": 0.020508,
        "main_score": 0.008574,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.129209,
        "recall": 0.177734,
        "f1": 0.142419,
        "accuracy": 0.177734,
        "main_score": 0.142419,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.078646,
        "recall": 0.118164,
        "f1": 0.088102,
        "accuracy": 0.118164,
        "main_score": 0.088102,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.18859,
        "recall": 0.220703,
        "f1": 0.196046,
        "accuracy": 0.220703,
        "main_score": 0.196046,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.011162,
        "recall": 0.016602,
        "f1": 0.011763,
        "accuracy": 0.016602,
        "main_score": 0.011763,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.19229,
        "recall": 0.231445,
        "f1": 0.2021,
        "accuracy": 0.231445,
        "main_score": 0.2021,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.096845,
        "recall": 0.135742,
        "f1": 0.105969,
        "accuracy": 0.135742,
        "main_score": 0.105969,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.198593,
        "recall": 0.241211,
        "f1": 0.210202,
        "accuracy": 0.241211,
        "main_score": 0.210202,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.064797,
        "recall": 0.091797,
        "f1": 0.072154,
        "accuracy": 0.091797,
        "main_score": 0.072154,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.122188,
        "recall": 0.15332,
        "f1": 0.128728,
        "accuracy": 0.15332,
        "main_score": 0.128728,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.073482,
        "recall": 0.117188,
        "f1": 0.083409,
        "accuracy": 0.117188,
        "main_score": 0.083409,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.109352,
        "recall": 0.137695,
        "f1": 0.115846,
        "accuracy": 0.137695,
        "main_score": 0.115846,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.07458,
        "recall": 0.101562,
        "f1": 0.081379,
        "accuracy": 0.101562,
        "main_score": 0.081379,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.07921,
        "recall": 0.124023,
        "f1": 0.090432,
        "accuracy": 0.124023,
        "main_score": 0.090432,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.085801,
        "recall": 0.124023,
        "f1": 0.095197,
        "accuracy": 0.124023,
        "main_score": 0.095197,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.096405,
        "recall": 0.138672,
        "f1": 0.107864,
        "accuracy": 0.138672,
        "main_score": 0.107864,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.149011,
        "recall": 0.188477,
        "f1": 0.158611,
        "accuracy": 0.188477,
        "main_score": 0.158611,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.02918,
        "recall": 0.052734,
        "f1": 0.033777,
        "accuracy": 0.052734,
        "main_score": 0.033777,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.037669,
        "recall": 0.066406,
        "f1": 0.044043,
        "accuracy": 0.066406,
        "main_score": 0.044043,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.194641,
        "recall": 0.242188,
        "f1": 0.207592,
        "accuracy": 0.242188,
        "main_score": 0.207592,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.120345,
        "recall": 0.152344,
        "f1": 0.127921,
        "accuracy": 0.152344,
        "main_score": 0.127921,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.137192,
        "recall": 0.171875,
        "f1": 0.144355,
        "accuracy": 0.171875,
        "main_score": 0.144355,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.095758,
        "recall": 0.125977,
        "f1": 0.102115,
        "accuracy": 0.125977,
        "main_score": 0.102115,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.065426,
        "recall": 0.091797,
        "f1": 0.071982,
        "accuracy": 0.091797,
        "main_score": 0.071982,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.063243,
        "recall": 0.082031,
        "f1": 0.06777,
        "accuracy": 0.082031,
        "main_score": 0.06777,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.123122,
        "recall": 0.15918,
        "f1": 0.132519,
        "accuracy": 0.15918,
        "main_score": 0.132519,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.009371,
        "recall": 0.014648,
        "f1": 0.010018,
        "accuracy": 0.014648,
        "main_score": 0.010018,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.082465,
        "recall": 0.102539,
        "f1": 0.08728,
        "accuracy": 0.102539,
        "main_score": 0.08728,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.035158,
        "recall": 0.052734,
        "f1": 0.038552,
        "accuracy": 0.052734,
        "main_score": 0.038552,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.230252,
        "recall": 0.286133,
        "f1": 0.24595,
        "accuracy": 0.286133,
        "main_score": 0.24595,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.025001,
        "recall": 0.036133,
        "f1": 0.027045,
        "accuracy": 0.036133,
        "main_score": 0.027045,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.194933,
        "recall": 0.231445,
        "f1": 0.20339,
        "accuracy": 0.231445,
        "main_score": 0.20339,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.096024,
        "recall": 0.129883,
        "f1": 0.104413,
        "accuracy": 0.129883,
        "main_score": 0.104413,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.040701,
        "recall": 0.055664,
        "f1": 0.04353,
        "accuracy": 0.055664,
        "main_score": 0.04353,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.032687,
        "recall": 0.043945,
        "f1": 0.034537,
        "accuracy": 0.043945,
        "main_score": 0.034537,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.067011,
        "recall": 0.097656,
        "f1": 0.074761,
        "accuracy": 0.097656,
        "main_score": 0.074761,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.085139,
        "recall": 0.114258,
        "f1": 0.092685,
        "accuracy": 0.114258,
        "main_score": 0.092685,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.043955,
        "recall": 0.069336,
        "f1": 0.049843,
        "accuracy": 0.069336,
        "main_score": 0.049843,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.180386,
        "recall": 0.249023,
        "f1": 0.196704,
        "accuracy": 0.249023,
        "main_score": 0.196704,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.011997,
        "recall": 0.019531,
        "f1": 0.013293,
        "accuracy": 0.019531,
        "main_score": 0.013293,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.072591,
        "recall": 0.104492,
        "f1": 0.081273,
        "accuracy": 0.104492,
        "main_score": 0.081273,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.19664,
        "recall": 0.266602,
        "f1": 0.215495,
        "accuracy": 0.266602,
        "main_score": 0.215495,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.076987,
        "recall": 0.09668,
        "f1": 0.081367,
        "accuracy": 0.09668,
        "main_score": 0.081367,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.080789,
        "recall": 0.100586,
        "f1": 0.085373,
        "accuracy": 0.100586,
        "main_score": 0.085373,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.206338,
        "recall": 0.246094,
        "f1": 0.215177,
        "accuracy": 0.246094,
        "main_score": 0.215177,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.002021,
        "recall": 0.007812,
        "f1": 0.002087,
        "accuracy": 0.007812,
        "main_score": 0.002087,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.000814,
        "recall": 0.009766,
        "f1": 0.001338,
        "accuracy": 0.009766,
        "main_score": 0.001338,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.002865,
        "recall": 0.019531,
        "f1": 0.004018,
        "accuracy": 0.019531,
        "main_score": 0.004018,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.000857,
        "recall": 0.013672,
        "f1": 0.001448,
        "accuracy": 0.013672,
        "main_score": 0.001448,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001552,
        "recall": 0.020508,
        "f1": 0.002671,
        "accuracy": 0.020508,
        "main_score": 0.002671,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.001268,
        "recall": 0.010742,
        "f1": 0.001531,
        "accuracy": 0.010742,
        "main_score": 0.001531,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.00134,
        "recall": 0.011719,
        "f1": 0.001657,
        "accuracy": 0.011719,
        "main_score": 0.001657,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003171,
        "recall": 0.014648,
        "f1": 0.004168,
        "accuracy": 0.014648,
        "main_score": 0.004168,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.00469,
        "recall": 0.016602,
        "f1": 0.005253,
        "accuracy": 0.016602,
        "main_score": 0.005253,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.002043,
        "recall": 0.010742,
        "f1": 0.002583,
        "accuracy": 0.010742,
        "main_score": 0.002583,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.001751,
        "recall": 0.014648,
        "f1": 0.002301,
        "accuracy": 0.014648,
        "main_score": 0.002301,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000581,
        "recall": 0.011719,
        "f1": 0.00103,
        "accuracy": 0.011719,
        "main_score": 0.00103,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001647,
        "recall": 0.007812,
        "f1": 0.001957,
        "accuracy": 0.007812,
        "main_score": 0.001957,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.002012,
        "recall": 0.011719,
        "f1": 0.002614,
        "accuracy": 0.011719,
        "main_score": 0.002614,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.0025,
        "recall": 0.013672,
        "f1": 0.003342,
        "accuracy": 0.013672,
        "main_score": 0.003342,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.000941,
        "recall": 0.018555,
        "f1": 0.001744,
        "accuracy": 0.018555,
        "main_score": 0.001744,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001046,
        "recall": 0.004883,
        "f1": 0.001112,
        "accuracy": 0.004883,
        "main_score": 0.001112,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000941,
        "recall": 0.008789,
        "f1": 0.001445,
        "accuracy": 0.008789,
        "main_score": 0.001445,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.002455,
        "recall": 0.015625,
        "f1": 0.003217,
        "accuracy": 0.015625,
        "main_score": 0.003217,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.002234,
        "recall": 0.019531,
        "f1": 0.00356,
        "accuracy": 0.019531,
        "main_score": 0.00356,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.003052,
        "recall": 0.018555,
        "f1": 0.004265,
        "accuracy": 0.018555,
        "main_score": 0.004265,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001699,
        "recall": 0.012695,
        "f1": 0.002597,
        "accuracy": 0.012695,
        "main_score": 0.002597,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.062378,
        "recall": 0.101562,
        "f1": 0.071647,
        "accuracy": 0.101562,
        "main_score": 0.071647,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.060038,
        "recall": 0.09082,
        "f1": 0.06713,
        "accuracy": 0.09082,
        "main_score": 0.06713,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.221142,
        "recall": 0.266602,
        "f1": 0.233629,
        "accuracy": 0.266602,
        "main_score": 0.233629,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.154188,
        "recall": 0.186523,
        "f1": 0.161382,
        "accuracy": 0.186523,
        "main_score": 0.161382,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.010323,
        "recall": 0.017578,
        "f1": 0.011399,
        "accuracy": 0.017578,
        "main_score": 0.011399,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.114775,
        "recall": 0.168945,
        "f1": 0.12799,
        "accuracy": 0.168945,
        "main_score": 0.12799,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.15213,
        "recall": 0.195312,
        "f1": 0.163079,
        "accuracy": 0.195312,
        "main_score": 0.163079,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.115082,
        "recall": 0.15625,
        "f1": 0.126271,
        "accuracy": 0.15625,
        "main_score": 0.126271,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.091648,
        "recall": 0.117188,
        "f1": 0.097662,
        "accuracy": 0.117188,
        "main_score": 0.097662,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.053469,
        "recall": 0.086914,
        "f1": 0.060202,
        "accuracy": 0.086914,
        "main_score": 0.060202,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.129199,
        "recall": 0.170898,
        "f1": 0.140686,
        "accuracy": 0.170898,
        "main_score": 0.140686,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.10822,
        "recall": 0.148438,
        "f1": 0.118697,
        "accuracy": 0.148438,
        "main_score": 0.118697,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.054289,
        "recall": 0.094727,
        "f1": 0.063967,
        "accuracy": 0.094727,
        "main_score": 0.063967,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.053582,
        "recall": 0.084961,
        "f1": 0.060674,
        "accuracy": 0.084961,
        "main_score": 0.060674,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.080863,
        "recall": 0.125977,
        "f1": 0.091084,
        "accuracy": 0.125977,
        "main_score": 0.091084,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.143136,
        "recall": 0.186523,
        "f1": 0.153555,
        "accuracy": 0.186523,
        "main_score": 0.153555,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.046139,
        "recall": 0.082031,
        "f1": 0.053586,
        "accuracy": 0.082031,
        "main_score": 0.053586,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.03089,
        "recall": 0.057617,
        "f1": 0.035958,
        "accuracy": 0.057617,
        "main_score": 0.035958,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.141598,
        "recall": 0.174805,
        "f1": 0.149599,
        "accuracy": 0.174805,
        "main_score": 0.149599,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.165282,
        "recall": 0.208984,
        "f1": 0.176113,
        "accuracy": 0.208984,
        "main_score": 0.176113,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.172129,
        "recall": 0.217773,
        "f1": 0.183438,
        "accuracy": 0.217773,
        "main_score": 0.183438,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.075832,
        "recall": 0.107422,
        "f1": 0.082676,
        "accuracy": 0.107422,
        "main_score": 0.082676,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.094805,
        "recall": 0.134766,
        "f1": 0.104313,
        "accuracy": 0.134766,
        "main_score": 0.104313,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.060089,
        "recall": 0.094727,
        "f1": 0.068201,
        "accuracy": 0.094727,
        "main_score": 0.068201,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.084831,
        "recall": 0.12793,
        "f1": 0.094617,
        "accuracy": 0.12793,
        "main_score": 0.094617,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.050136,
        "recall": 0.073242,
        "f1": 0.054433,
        "accuracy": 0.073242,
        "main_score": 0.054433,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003918,
        "recall": 0.007812,
        "f1": 0.004255,
        "accuracy": 0.007812,
        "main_score": 0.004255,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.095371,
        "recall": 0.136719,
        "f1": 0.105651,
        "accuracy": 0.136719,
        "main_score": 0.105651,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.070163,
        "recall": 0.099609,
        "f1": 0.077199,
        "accuracy": 0.099609,
        "main_score": 0.077199,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0851,
        "recall": 0.114258,
        "f1": 0.092266,
        "accuracy": 0.114258,
        "main_score": 0.092266,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.023455,
        "recall": 0.039062,
        "f1": 0.025847,
        "accuracy": 0.039062,
        "main_score": 0.025847,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.061652,
        "recall": 0.09375,
        "f1": 0.068896,
        "accuracy": 0.09375,
        "main_score": 0.068896,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.048352,
        "recall": 0.067383,
        "f1": 0.052494,
        "accuracy": 0.067383,
        "main_score": 0.052494,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.100409,
        "recall": 0.139648,
        "f1": 0.110521,
        "accuracy": 0.139648,
        "main_score": 0.110521,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.056448,
        "recall": 0.092773,
        "f1": 0.064956,
        "accuracy": 0.092773,
        "main_score": 0.064956,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.050404,
        "recall": 0.080078,
        "f1": 0.055477,
        "accuracy": 0.080078,
        "main_score": 0.055477,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.081637,
        "recall": 0.126953,
        "f1": 0.092068,
        "accuracy": 0.126953,
        "main_score": 0.092068,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.056211,
        "recall": 0.079102,
        "f1": 0.061001,
        "accuracy": 0.079102,
        "main_score": 0.061001,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.028612,
        "recall": 0.044922,
        "f1": 0.031878,
        "accuracy": 0.044922,
        "main_score": 0.031878,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.037115,
        "recall": 0.057617,
        "f1": 0.041444,
        "accuracy": 0.057617,
        "main_score": 0.041444,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.058846,
        "recall": 0.083008,
        "f1": 0.063976,
        "accuracy": 0.083008,
        "main_score": 0.063976,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.051446,
        "recall": 0.068359,
        "f1": 0.054823,
        "accuracy": 0.068359,
        "main_score": 0.054823,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.056547,
        "recall": 0.083984,
        "f1": 0.062068,
        "accuracy": 0.083984,
        "main_score": 0.062068,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.01865,
        "recall": 0.038086,
        "f1": 0.021777,
        "accuracy": 0.038086,
        "main_score": 0.021777,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.07671,
        "recall": 0.103516,
        "f1": 0.083224,
        "accuracy": 0.103516,
        "main_score": 0.083224,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.055065,
        "recall": 0.081055,
        "f1": 0.061383,
        "accuracy": 0.081055,
        "main_score": 0.061383,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.140877,
        "recall": 0.177734,
        "f1": 0.150685,
        "accuracy": 0.177734,
        "main_score": 0.150685,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.230917,
        "recall": 0.28125,
        "f1": 0.24445,
        "accuracy": 0.28125,
        "main_score": 0.24445,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.009696,
        "recall": 0.014648,
        "f1": 0.01018,
        "accuracy": 0.014648,
        "main_score": 0.01018,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.092981,
        "recall": 0.113281,
        "f1": 0.097195,
        "accuracy": 0.113281,
        "main_score": 0.097195,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.060414,
        "recall": 0.083984,
        "f1": 0.065254,
        "accuracy": 0.083984,
        "main_score": 0.065254,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.025422,
        "recall": 0.039062,
        "f1": 0.028164,
        "accuracy": 0.039062,
        "main_score": 0.028164,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.14734,
        "recall": 0.179688,
        "f1": 0.154502,
        "accuracy": 0.179688,
        "main_score": 0.154502,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.076921,
        "recall": 0.113281,
        "f1": 0.086732,
        "accuracy": 0.113281,
        "main_score": 0.086732,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.053568,
        "recall": 0.072266,
        "f1": 0.05749,
        "accuracy": 0.072266,
        "main_score": 0.05749,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.031932,
        "recall": 0.049805,
        "f1": 0.035304,
        "accuracy": 0.049805,
        "main_score": 0.035304,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.062655,
        "recall": 0.095703,
        "f1": 0.071628,
        "accuracy": 0.095703,
        "main_score": 0.071628,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.046975,
        "recall": 0.068359,
        "f1": 0.051799,
        "accuracy": 0.068359,
        "main_score": 0.051799,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.065894,
        "recall": 0.09082,
        "f1": 0.071228,
        "accuracy": 0.09082,
        "main_score": 0.071228,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.141249,
        "recall": 0.202148,
        "f1": 0.15581,
        "accuracy": 0.202148,
        "main_score": 0.15581,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.018625,
        "recall": 0.032227,
        "f1": 0.020531,
        "accuracy": 0.032227,
        "main_score": 0.020531,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.049326,
        "recall": 0.075195,
        "f1": 0.055357,
        "accuracy": 0.075195,
        "main_score": 0.055357,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.273374,
        "recall": 0.333984,
        "f1": 0.290116,
        "accuracy": 0.333984,
        "main_score": 0.290116,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.053879,
        "recall": 0.075195,
        "f1": 0.05775,
        "accuracy": 0.075195,
        "main_score": 0.05775,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.067353,
        "recall": 0.088867,
        "f1": 0.071615,
        "accuracy": 0.088867,
        "main_score": 0.071615,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.194073,
        "recall": 0.234375,
        "f1": 0.202947,
        "accuracy": 0.234375,
        "main_score": 0.202947,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.06425,
        "recall": 0.106445,
        "f1": 0.073901,
        "accuracy": 0.106445,
        "main_score": 0.073901,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.05573,
        "recall": 0.09375,
        "f1": 0.063556,
        "accuracy": 0.09375,
        "main_score": 0.063556,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.046479,
        "recall": 0.081055,
        "f1": 0.053827,
        "accuracy": 0.081055,
        "main_score": 0.053827,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.023841,
        "recall": 0.041016,
        "f1": 0.026638,
        "accuracy": 0.041016,
        "main_score": 0.026638,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.003906,
        "f1": 0.001002,
        "accuracy": 0.003906,
        "main_score": 0.001002,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.073657,
        "recall": 0.126953,
        "f1": 0.086928,
        "accuracy": 0.126953,
        "main_score": 0.086928,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.082915,
        "recall": 0.128906,
        "f1": 0.09433,
        "accuracy": 0.128906,
        "main_score": 0.09433,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.021633,
        "recall": 0.045898,
        "f1": 0.026122,
        "accuracy": 0.045898,
        "main_score": 0.026122,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.008768,
        "recall": 0.022461,
        "f1": 0.010327,
        "accuracy": 0.022461,
        "main_score": 0.010327,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.040289,
        "recall": 0.070312,
        "f1": 0.046942,
        "accuracy": 0.070312,
        "main_score": 0.046942,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.048805,
        "recall": 0.080078,
        "f1": 0.056351,
        "accuracy": 0.080078,
        "main_score": 0.056351,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.093735,
        "recall": 0.132812,
        "f1": 0.104223,
        "accuracy": 0.132812,
        "main_score": 0.104223,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.044125,
        "recall": 0.083008,
        "f1": 0.05142,
        "accuracy": 0.083008,
        "main_score": 0.05142,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.052842,
        "recall": 0.086914,
        "f1": 0.059552,
        "accuracy": 0.086914,
        "main_score": 0.059552,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.069807,
        "recall": 0.110352,
        "f1": 0.078667,
        "accuracy": 0.110352,
        "main_score": 0.078667,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.02151,
        "recall": 0.042969,
        "f1": 0.025703,
        "accuracy": 0.042969,
        "main_score": 0.025703,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.052732,
        "recall": 0.089844,
        "f1": 0.060086,
        "accuracy": 0.089844,
        "main_score": 0.060086,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.029633,
        "recall": 0.051758,
        "f1": 0.033053,
        "accuracy": 0.051758,
        "main_score": 0.033053,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.026001,
        "recall": 0.045898,
        "f1": 0.029758,
        "accuracy": 0.045898,
        "main_score": 0.029758,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.059454,
        "recall": 0.091797,
        "f1": 0.066355,
        "accuracy": 0.091797,
        "main_score": 0.066355,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.062531,
        "recall": 0.098633,
        "f1": 0.071044,
        "accuracy": 0.098633,
        "main_score": 0.071044,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004852,
        "recall": 0.015625,
        "f1": 0.005896,
        "accuracy": 0.015625,
        "main_score": 0.005896,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.019987,
        "recall": 0.035156,
        "f1": 0.021918,
        "accuracy": 0.035156,
        "main_score": 0.021918,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.017844,
        "recall": 0.035156,
        "f1": 0.020595,
        "accuracy": 0.035156,
        "main_score": 0.020595,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.061022,
        "recall": 0.085938,
        "f1": 0.065197,
        "accuracy": 0.085938,
        "main_score": 0.065197,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.130177,
        "recall": 0.160156,
        "f1": 0.136431,
        "accuracy": 0.160156,
        "main_score": 0.136431,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.009938,
        "recall": 0.015625,
        "f1": 0.010567,
        "accuracy": 0.015625,
        "main_score": 0.010567,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.039262,
        "recall": 0.049805,
        "f1": 0.041406,
        "accuracy": 0.049805,
        "main_score": 0.041406,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.013975,
        "recall": 0.027344,
        "f1": 0.015866,
        "accuracy": 0.027344,
        "main_score": 0.015866,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.102216,
        "recall": 0.139648,
        "f1": 0.110459,
        "accuracy": 0.139648,
        "main_score": 0.110459,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003415,
        "recall": 0.007812,
        "f1": 0.004087,
        "accuracy": 0.007812,
        "main_score": 0.004087,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.025078,
        "recall": 0.043945,
        "f1": 0.02831,
        "accuracy": 0.043945,
        "main_score": 0.02831,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.015175,
        "recall": 0.029297,
        "f1": 0.017846,
        "accuracy": 0.029297,
        "main_score": 0.017846,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.010777,
        "recall": 0.016602,
        "f1": 0.011282,
        "accuracy": 0.016602,
        "main_score": 0.011282,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.017059,
        "recall": 0.030273,
        "f1": 0.018821,
        "accuracy": 0.030273,
        "main_score": 0.018821,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.021621,
        "recall": 0.036133,
        "f1": 0.024258,
        "accuracy": 0.036133,
        "main_score": 0.024258,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.015536,
        "recall": 0.027344,
        "f1": 0.016812,
        "accuracy": 0.027344,
        "main_score": 0.016812,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.079439,
        "recall": 0.112305,
        "f1": 0.085868,
        "accuracy": 0.112305,
        "main_score": 0.085868,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.005173,
        "recall": 0.012695,
        "f1": 0.006146,
        "accuracy": 0.012695,
        "main_score": 0.006146,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.015696,
        "recall": 0.036133,
        "f1": 0.018683,
        "accuracy": 0.036133,
        "main_score": 0.018683,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.078856,
        "recall": 0.116211,
        "f1": 0.085493,
        "accuracy": 0.116211,
        "main_score": 0.085493,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.033554,
        "recall": 0.044922,
        "f1": 0.035771,
        "accuracy": 0.044922,
        "main_score": 0.035771,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.040286,
        "recall": 0.055664,
        "f1": 0.043568,
        "accuracy": 0.055664,
        "main_score": 0.043568,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.230146,
        "recall": 0.257812,
        "f1": 0.238011,
        "accuracy": 0.257812,
        "main_score": 0.238011,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.097361,
        "recall": 0.132812,
        "f1": 0.105656,
        "accuracy": 0.132812,
        "main_score": 0.105656,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.098408,
        "recall": 0.135742,
        "f1": 0.107608,
        "accuracy": 0.135742,
        "main_score": 0.107608,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.038707,
        "recall": 0.068359,
        "f1": 0.04458,
        "accuracy": 0.068359,
        "main_score": 0.04458,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.060407,
        "recall": 0.094727,
        "f1": 0.068131,
        "accuracy": 0.094727,
        "main_score": 0.068131,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000985,
        "recall": 0.00293,
        "f1": 0.000993,
        "accuracy": 0.00293,
        "main_score": 0.000993,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022436,
        "recall": 0.046875,
        "f1": 0.027154,
        "accuracy": 0.046875,
        "main_score": 0.027154,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.048594,
        "recall": 0.075195,
        "f1": 0.054604,
        "accuracy": 0.075195,
        "main_score": 0.054604,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.055235,
        "recall": 0.087891,
        "f1": 0.063438,
        "accuracy": 0.087891,
        "main_score": 0.063438,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.030133,
        "recall": 0.042969,
        "f1": 0.03252,
        "accuracy": 0.042969,
        "main_score": 0.03252,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.018158,
        "recall": 0.041992,
        "f1": 0.022021,
        "accuracy": 0.041992,
        "main_score": 0.022021,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.012798,
        "recall": 0.022461,
        "f1": 0.014286,
        "accuracy": 0.022461,
        "main_score": 0.014286,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.04346,
        "recall": 0.06543,
        "f1": 0.047714,
        "accuracy": 0.06543,
        "main_score": 0.047714,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.082826,
        "recall": 0.117188,
        "f1": 0.091268,
        "accuracy": 0.117188,
        "main_score": 0.091268,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.097933,
        "recall": 0.134766,
        "f1": 0.10664,
        "accuracy": 0.134766,
        "main_score": 0.10664,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.071551,
        "recall": 0.101562,
        "f1": 0.078061,
        "accuracy": 0.101562,
        "main_score": 0.078061,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.033961,
        "recall": 0.057617,
        "f1": 0.038877,
        "accuracy": 0.057617,
        "main_score": 0.038877,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.01702,
        "recall": 0.032227,
        "f1": 0.01921,
        "accuracy": 0.032227,
        "main_score": 0.01921,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.064507,
        "recall": 0.086914,
        "f1": 0.070362,
        "accuracy": 0.086914,
        "main_score": 0.070362,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.044621,
        "recall": 0.073242,
        "f1": 0.051368,
        "accuracy": 0.073242,
        "main_score": 0.051368,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.021079,
        "recall": 0.038086,
        "f1": 0.024404,
        "accuracy": 0.038086,
        "main_score": 0.024404,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.021981,
        "recall": 0.039062,
        "f1": 0.025431,
        "accuracy": 0.039062,
        "main_score": 0.025431,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.008502,
        "recall": 0.023438,
        "f1": 0.010459,
        "accuracy": 0.023438,
        "main_score": 0.010459,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.032996,
        "recall": 0.052734,
        "f1": 0.037009,
        "accuracy": 0.052734,
        "main_score": 0.037009,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.032607,
        "recall": 0.053711,
        "f1": 0.036959,
        "accuracy": 0.053711,
        "main_score": 0.036959,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.121419,
        "recall": 0.154297,
        "f1": 0.129973,
        "accuracy": 0.154297,
        "main_score": 0.129973,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.065653,
        "recall": 0.086914,
        "f1": 0.070178,
        "accuracy": 0.086914,
        "main_score": 0.070178,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00685,
        "recall": 0.012695,
        "f1": 0.007361,
        "accuracy": 0.012695,
        "main_score": 0.007361,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.134982,
        "recall": 0.168945,
        "f1": 0.143656,
        "accuracy": 0.168945,
        "main_score": 0.143656,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.049355,
        "recall": 0.077148,
        "f1": 0.055612,
        "accuracy": 0.077148,
        "main_score": 0.055612,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.084435,
        "recall": 0.112305,
        "f1": 0.090965,
        "accuracy": 0.112305,
        "main_score": 0.090965,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.074306,
        "recall": 0.098633,
        "f1": 0.080156,
        "accuracy": 0.098633,
        "main_score": 0.080156,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.055734,
        "recall": 0.077148,
        "f1": 0.059965,
        "accuracy": 0.077148,
        "main_score": 0.059965,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.023177,
        "recall": 0.042969,
        "f1": 0.026601,
        "accuracy": 0.042969,
        "main_score": 0.026601,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.050155,
        "recall": 0.072266,
        "f1": 0.055212,
        "accuracy": 0.072266,
        "main_score": 0.055212,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.0217,
        "recall": 0.044922,
        "f1": 0.02646,
        "accuracy": 0.044922,
        "main_score": 0.02646,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.02309,
        "recall": 0.041992,
        "f1": 0.026828,
        "accuracy": 0.041992,
        "main_score": 0.026828,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.027481,
        "recall": 0.046875,
        "f1": 0.031549,
        "accuracy": 0.046875,
        "main_score": 0.031549,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.066052,
        "recall": 0.09375,
        "f1": 0.072667,
        "accuracy": 0.09375,
        "main_score": 0.072667,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.025736,
        "recall": 0.050781,
        "f1": 0.03064,
        "accuracy": 0.050781,
        "main_score": 0.03064,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.014612,
        "recall": 0.030273,
        "f1": 0.016929,
        "accuracy": 0.030273,
        "main_score": 0.016929,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.074192,
        "recall": 0.097656,
        "f1": 0.078796,
        "accuracy": 0.097656,
        "main_score": 0.078796,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.137559,
        "recall": 0.169922,
        "f1": 0.145843,
        "accuracy": 0.169922,
        "main_score": 0.145843,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.127576,
        "recall": 0.15918,
        "f1": 0.135071,
        "accuracy": 0.15918,
        "main_score": 0.135071,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.036434,
        "recall": 0.05957,
        "f1": 0.040255,
        "accuracy": 0.05957,
        "main_score": 0.040255,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.07545,
        "recall": 0.117188,
        "f1": 0.085091,
        "accuracy": 0.117188,
        "main_score": 0.085091,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.061672,
        "recall": 0.098633,
        "f1": 0.06996,
        "accuracy": 0.098633,
        "main_score": 0.06996,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.048875,
        "recall": 0.086914,
        "f1": 0.057354,
        "accuracy": 0.086914,
        "main_score": 0.057354,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.034287,
        "recall": 0.056641,
        "f1": 0.038504,
        "accuracy": 0.056641,
        "main_score": 0.038504,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000991,
        "recall": 0.003906,
        "f1": 0.001004,
        "accuracy": 0.003906,
        "main_score": 0.001004,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.069806,
        "recall": 0.121094,
        "f1": 0.081643,
        "accuracy": 0.121094,
        "main_score": 0.081643,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.093425,
        "recall": 0.148438,
        "f1": 0.106886,
        "accuracy": 0.148438,
        "main_score": 0.106886,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.02677,
        "recall": 0.049805,
        "f1": 0.031796,
        "accuracy": 0.049805,
        "main_score": 0.031796,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.10478,
        "recall": 0.135742,
        "f1": 0.112986,
        "accuracy": 0.135742,
        "main_score": 0.112986,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.007619,
        "recall": 0.020508,
        "f1": 0.009157,
        "accuracy": 0.020508,
        "main_score": 0.009157,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.055722,
        "recall": 0.089844,
        "f1": 0.063296,
        "accuracy": 0.089844,
        "main_score": 0.063296,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.030604,
        "recall": 0.049805,
        "f1": 0.034766,
        "accuracy": 0.049805,
        "main_score": 0.034766,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.055115,
        "recall": 0.094727,
        "f1": 0.063496,
        "accuracy": 0.094727,
        "main_score": 0.063496,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.062275,
        "recall": 0.100586,
        "f1": 0.069891,
        "accuracy": 0.100586,
        "main_score": 0.069891,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.082312,
        "recall": 0.119141,
        "f1": 0.091574,
        "accuracy": 0.119141,
        "main_score": 0.091574,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.025721,
        "recall": 0.053711,
        "f1": 0.031045,
        "accuracy": 0.053711,
        "main_score": 0.031045,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.038216,
        "recall": 0.063477,
        "f1": 0.043461,
        "accuracy": 0.063477,
        "main_score": 0.043461,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.032661,
        "recall": 0.055664,
        "f1": 0.037338,
        "accuracy": 0.055664,
        "main_score": 0.037338,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.028163,
        "recall": 0.044922,
        "f1": 0.031262,
        "accuracy": 0.044922,
        "main_score": 0.031262,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.038249,
        "recall": 0.061523,
        "f1": 0.043665,
        "accuracy": 0.061523,
        "main_score": 0.043665,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.044688,
        "recall": 0.072266,
        "f1": 0.051035,
        "accuracy": 0.072266,
        "main_score": 0.051035,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004276,
        "recall": 0.017578,
        "f1": 0.005719,
        "accuracy": 0.017578,
        "main_score": 0.005719,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.096002,
        "recall": 0.144531,
        "f1": 0.107888,
        "accuracy": 0.144531,
        "main_score": 0.107888,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.083501,
        "recall": 0.116211,
        "f1": 0.092042,
        "accuracy": 0.116211,
        "main_score": 0.092042,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.051616,
        "recall": 0.082031,
        "f1": 0.057806,
        "accuracy": 0.082031,
        "main_score": 0.057806,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.036076,
        "recall": 0.061523,
        "f1": 0.042101,
        "accuracy": 0.061523,
        "main_score": 0.042101,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000987,
        "recall": 0.003906,
        "f1": 0.000998,
        "accuracy": 0.003906,
        "main_score": 0.000998,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.035845,
        "recall": 0.06543,
        "f1": 0.041154,
        "accuracy": 0.06543,
        "main_score": 0.041154,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.050995,
        "recall": 0.081055,
        "f1": 0.05795,
        "accuracy": 0.081055,
        "main_score": 0.05795,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.046537,
        "recall": 0.079102,
        "f1": 0.054395,
        "accuracy": 0.079102,
        "main_score": 0.054395,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.032337,
        "recall": 0.043945,
        "f1": 0.034604,
        "accuracy": 0.043945,
        "main_score": 0.034604,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.012029,
        "recall": 0.03418,
        "f1": 0.014996,
        "accuracy": 0.03418,
        "main_score": 0.014996,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.085727,
        "recall": 0.12207,
        "f1": 0.095016,
        "accuracy": 0.12207,
        "main_score": 0.095016,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.018104,
        "recall": 0.026367,
        "f1": 0.019761,
        "accuracy": 0.026367,
        "main_score": 0.019761,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.04323,
        "recall": 0.060547,
        "f1": 0.046679,
        "accuracy": 0.060547,
        "main_score": 0.046679,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.082129,
        "recall": 0.123047,
        "f1": 0.092288,
        "accuracy": 0.123047,
        "main_score": 0.092288,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.069814,
        "recall": 0.103516,
        "f1": 0.077791,
        "accuracy": 0.103516,
        "main_score": 0.077791,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.023443,
        "recall": 0.050781,
        "f1": 0.028607,
        "accuracy": 0.050781,
        "main_score": 0.028607,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.026248,
        "recall": 0.042969,
        "f1": 0.029021,
        "accuracy": 0.042969,
        "main_score": 0.029021,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.059943,
        "recall": 0.085938,
        "f1": 0.065802,
        "accuracy": 0.085938,
        "main_score": 0.065802,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.045879,
        "recall": 0.077148,
        "f1": 0.05322,
        "accuracy": 0.077148,
        "main_score": 0.05322,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.019512,
        "recall": 0.039062,
        "f1": 0.022947,
        "accuracy": 0.039062,
        "main_score": 0.022947,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.017046,
        "recall": 0.037109,
        "f1": 0.0201,
        "accuracy": 0.037109,
        "main_score": 0.0201,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007933,
        "recall": 0.020508,
        "f1": 0.009595,
        "accuracy": 0.020508,
        "main_score": 0.009595,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.093206,
        "recall": 0.132812,
        "f1": 0.102903,
        "accuracy": 0.132812,
        "main_score": 0.102903,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.098379,
        "recall": 0.134766,
        "f1": 0.108333,
        "accuracy": 0.134766,
        "main_score": 0.108333,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.045117,
        "recall": 0.083984,
        "f1": 0.05324,
        "accuracy": 0.083984,
        "main_score": 0.05324,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.053598,
        "recall": 0.082031,
        "f1": 0.060232,
        "accuracy": 0.082031,
        "main_score": 0.060232,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000987,
        "recall": 0.003906,
        "f1": 0.000998,
        "accuracy": 0.003906,
        "main_score": 0.000998,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024507,
        "recall": 0.046875,
        "f1": 0.028544,
        "accuracy": 0.046875,
        "main_score": 0.028544,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.049588,
        "recall": 0.075195,
        "f1": 0.055689,
        "accuracy": 0.075195,
        "main_score": 0.055689,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.029567,
        "recall": 0.053711,
        "f1": 0.034722,
        "accuracy": 0.053711,
        "main_score": 0.034722,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.038704,
        "recall": 0.058594,
        "f1": 0.043261,
        "accuracy": 0.058594,
        "main_score": 0.043261,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.015384,
        "recall": 0.038086,
        "f1": 0.01903,
        "accuracy": 0.038086,
        "main_score": 0.01903,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.102998,
        "recall": 0.139648,
        "f1": 0.111875,
        "accuracy": 0.139648,
        "main_score": 0.111875,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.014197,
        "recall": 0.026367,
        "f1": 0.015873,
        "accuracy": 0.026367,
        "main_score": 0.015873,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.058211,
        "recall": 0.084961,
        "f1": 0.063908,
        "accuracy": 0.084961,
        "main_score": 0.063908,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.094475,
        "recall": 0.135742,
        "f1": 0.105156,
        "accuracy": 0.135742,
        "main_score": 0.105156,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.072889,
        "recall": 0.112305,
        "f1": 0.082157,
        "accuracy": 0.112305,
        "main_score": 0.082157,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.026467,
        "recall": 0.050781,
        "f1": 0.030862,
        "accuracy": 0.050781,
        "main_score": 0.030862,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.020042,
        "recall": 0.040039,
        "f1": 0.023064,
        "accuracy": 0.040039,
        "main_score": 0.023064,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.063778,
        "recall": 0.098633,
        "f1": 0.072649,
        "accuracy": 0.098633,
        "main_score": 0.072649,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.024987,
        "recall": 0.045898,
        "f1": 0.028799,
        "accuracy": 0.045898,
        "main_score": 0.028799,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.033271,
        "recall": 0.054688,
        "f1": 0.037297,
        "accuracy": 0.054688,
        "main_score": 0.037297,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.027882,
        "recall": 0.048828,
        "f1": 0.031388,
        "accuracy": 0.048828,
        "main_score": 0.031388,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006056,
        "recall": 0.016602,
        "f1": 0.007446,
        "accuracy": 0.016602,
        "main_score": 0.007446,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.121045,
        "recall": 0.165039,
        "f1": 0.13216,
        "accuracy": 0.165039,
        "main_score": 0.13216,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.079432,
        "recall": 0.115234,
        "f1": 0.088019,
        "accuracy": 0.115234,
        "main_score": 0.088019,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.065067,
        "recall": 0.100586,
        "f1": 0.073888,
        "accuracy": 0.100586,
        "main_score": 0.073888,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.042932,
        "recall": 0.070312,
        "f1": 0.048379,
        "accuracy": 0.070312,
        "main_score": 0.048379,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000991,
        "recall": 0.003906,
        "f1": 0.001006,
        "accuracy": 0.003906,
        "main_score": 0.001006,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.045728,
        "recall": 0.083008,
        "f1": 0.053947,
        "accuracy": 0.083008,
        "main_score": 0.053947,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.071122,
        "recall": 0.105469,
        "f1": 0.079408,
        "accuracy": 0.105469,
        "main_score": 0.079408,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.055539,
        "recall": 0.09375,
        "f1": 0.064201,
        "accuracy": 0.09375,
        "main_score": 0.064201,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.062852,
        "recall": 0.09082,
        "f1": 0.069318,
        "accuracy": 0.09082,
        "main_score": 0.069318,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.013175,
        "recall": 0.030273,
        "f1": 0.015476,
        "accuracy": 0.030273,
        "main_score": 0.015476,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.08812,
        "recall": 0.134766,
        "f1": 0.098508,
        "accuracy": 0.134766,
        "main_score": 0.098508,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.018342,
        "recall": 0.033203,
        "f1": 0.021014,
        "accuracy": 0.033203,
        "main_score": 0.021014,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.073328,
        "recall": 0.098633,
        "f1": 0.079794,
        "accuracy": 0.098633,
        "main_score": 0.079794,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.084839,
        "recall": 0.126953,
        "f1": 0.095009,
        "accuracy": 0.126953,
        "main_score": 0.095009,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.084264,
        "recall": 0.123047,
        "f1": 0.092435,
        "accuracy": 0.123047,
        "main_score": 0.092435,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.038793,
        "recall": 0.071289,
        "f1": 0.045016,
        "accuracy": 0.071289,
        "main_score": 0.045016,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.037166,
        "recall": 0.063477,
        "f1": 0.041956,
        "accuracy": 0.063477,
        "main_score": 0.041956,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.046059,
        "recall": 0.072266,
        "f1": 0.051599,
        "accuracy": 0.072266,
        "main_score": 0.051599,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.050281,
        "recall": 0.094727,
        "f1": 0.05952,
        "accuracy": 0.094727,
        "main_score": 0.05952,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.024128,
        "recall": 0.045898,
        "f1": 0.028353,
        "accuracy": 0.045898,
        "main_score": 0.028353,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.024365,
        "recall": 0.045898,
        "f1": 0.027904,
        "accuracy": 0.045898,
        "main_score": 0.027904,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007897,
        "recall": 0.026367,
        "f1": 0.009967,
        "accuracy": 0.026367,
        "main_score": 0.009967,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.068477,
        "recall": 0.097656,
        "f1": 0.07629,
        "accuracy": 0.097656,
        "main_score": 0.07629,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.063607,
        "recall": 0.086914,
        "f1": 0.070117,
        "accuracy": 0.086914,
        "main_score": 0.070117,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.153298,
        "recall": 0.183594,
        "f1": 0.161049,
        "accuracy": 0.183594,
        "main_score": 0.161049,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.268304,
        "recall": 0.314453,
        "f1": 0.280636,
        "accuracy": 0.314453,
        "main_score": 0.280636,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.0067,
        "recall": 0.011719,
        "f1": 0.007376,
        "accuracy": 0.011719,
        "main_score": 0.007376,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.104442,
        "recall": 0.132812,
        "f1": 0.112012,
        "accuracy": 0.132812,
        "main_score": 0.112012,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.044226,
        "recall": 0.06543,
        "f1": 0.049107,
        "accuracy": 0.06543,
        "main_score": 0.049107,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.21984,
        "recall": 0.266602,
        "f1": 0.23279,
        "accuracy": 0.266602,
        "main_score": 0.23279,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.027417,
        "recall": 0.042969,
        "f1": 0.030796,
        "accuracy": 0.042969,
        "main_score": 0.030796,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.160979,
        "recall": 0.197266,
        "f1": 0.16979,
        "accuracy": 0.197266,
        "main_score": 0.16979,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.075835,
        "recall": 0.113281,
        "f1": 0.085211,
        "accuracy": 0.113281,
        "main_score": 0.085211,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.057747,
        "recall": 0.075195,
        "f1": 0.060905,
        "accuracy": 0.075195,
        "main_score": 0.060905,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.040838,
        "recall": 0.056641,
        "f1": 0.044417,
        "accuracy": 0.056641,
        "main_score": 0.044417,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.051072,
        "recall": 0.078125,
        "f1": 0.058016,
        "accuracy": 0.078125,
        "main_score": 0.058016,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.069153,
        "recall": 0.098633,
        "f1": 0.07631,
        "accuracy": 0.098633,
        "main_score": 0.07631,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.060569,
        "recall": 0.085938,
        "f1": 0.06628,
        "accuracy": 0.085938,
        "main_score": 0.06628,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.012272,
        "recall": 0.025391,
        "f1": 0.014311,
        "accuracy": 0.025391,
        "main_score": 0.014311,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.042675,
        "recall": 0.067383,
        "f1": 0.04898,
        "accuracy": 0.067383,
        "main_score": 0.04898,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.192591,
        "recall": 0.241211,
        "f1": 0.205995,
        "accuracy": 0.241211,
        "main_score": 0.205995,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.094202,
        "recall": 0.115234,
        "f1": 0.099133,
        "accuracy": 0.115234,
        "main_score": 0.099133,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.085874,
        "recall": 0.106445,
        "f1": 0.090266,
        "accuracy": 0.106445,
        "main_score": 0.090266,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.180353,
        "recall": 0.21875,
        "f1": 0.188854,
        "accuracy": 0.21875,
        "main_score": 0.188854,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.033994,
        "recall": 0.057617,
        "f1": 0.03927,
        "accuracy": 0.057617,
        "main_score": 0.03927,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.030259,
        "recall": 0.049805,
        "f1": 0.034181,
        "accuracy": 0.049805,
        "main_score": 0.034181,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.02509,
        "recall": 0.048828,
        "f1": 0.02947,
        "accuracy": 0.048828,
        "main_score": 0.02947,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.009271,
        "recall": 0.021484,
        "f1": 0.010987,
        "accuracy": 0.021484,
        "main_score": 0.010987,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000996,
        "recall": 0.003906,
        "f1": 0.001016,
        "accuracy": 0.003906,
        "main_score": 0.001016,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.033467,
        "recall": 0.05957,
        "f1": 0.03807,
        "accuracy": 0.05957,
        "main_score": 0.03807,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.036126,
        "recall": 0.06543,
        "f1": 0.041479,
        "accuracy": 0.06543,
        "main_score": 0.041479,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.012595,
        "recall": 0.035156,
        "f1": 0.016196,
        "accuracy": 0.035156,
        "main_score": 0.016196,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.057133,
        "recall": 0.083984,
        "f1": 0.062215,
        "accuracy": 0.083984,
        "main_score": 0.062215,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006187,
        "recall": 0.014648,
        "f1": 0.006883,
        "accuracy": 0.014648,
        "main_score": 0.006883,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.024918,
        "recall": 0.046875,
        "f1": 0.028742,
        "accuracy": 0.046875,
        "main_score": 0.028742,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.02172,
        "recall": 0.046875,
        "f1": 0.026204,
        "accuracy": 0.046875,
        "main_score": 0.026204,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.04913,
        "recall": 0.076172,
        "f1": 0.054475,
        "accuracy": 0.076172,
        "main_score": 0.054475,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.027263,
        "recall": 0.051758,
        "f1": 0.032021,
        "accuracy": 0.051758,
        "main_score": 0.032021,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.024729,
        "recall": 0.042969,
        "f1": 0.027616,
        "accuracy": 0.042969,
        "main_score": 0.027616,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.044554,
        "recall": 0.06543,
        "f1": 0.048803,
        "accuracy": 0.06543,
        "main_score": 0.048803,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.011735,
        "recall": 0.023438,
        "f1": 0.013591,
        "accuracy": 0.023438,
        "main_score": 0.013591,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.013381,
        "recall": 0.032227,
        "f1": 0.016119,
        "accuracy": 0.032227,
        "main_score": 0.016119,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.018952,
        "recall": 0.037109,
        "f1": 0.021723,
        "accuracy": 0.037109,
        "main_score": 0.021723,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.020369,
        "recall": 0.033203,
        "f1": 0.022924,
        "accuracy": 0.033203,
        "main_score": 0.022924,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.01759,
        "recall": 0.037109,
        "f1": 0.020081,
        "accuracy": 0.037109,
        "main_score": 0.020081,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002374,
        "recall": 0.006836,
        "f1": 0.002687,
        "accuracy": 0.006836,
        "main_score": 0.002687,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.046367,
        "recall": 0.070312,
        "f1": 0.051242,
        "accuracy": 0.070312,
        "main_score": 0.051242,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.073985,
        "recall": 0.103516,
        "f1": 0.081057,
        "accuracy": 0.103516,
        "main_score": 0.081057,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.021631,
        "recall": 0.039062,
        "f1": 0.024546,
        "accuracy": 0.039062,
        "main_score": 0.024546,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.047737,
        "recall": 0.076172,
        "f1": 0.054147,
        "accuracy": 0.076172,
        "main_score": 0.054147,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.003906,
        "f1": 0.001002,
        "accuracy": 0.003906,
        "main_score": 0.001002,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016668,
        "recall": 0.02832,
        "f1": 0.018269,
        "accuracy": 0.02832,
        "main_score": 0.018269,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.023696,
        "recall": 0.038086,
        "f1": 0.026395,
        "accuracy": 0.038086,
        "main_score": 0.026395,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.026981,
        "recall": 0.054688,
        "f1": 0.032641,
        "accuracy": 0.054688,
        "main_score": 0.032641,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016766,
        "recall": 0.025391,
        "f1": 0.017957,
        "accuracy": 0.025391,
        "main_score": 0.017957,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.013568,
        "recall": 0.02832,
        "f1": 0.016187,
        "accuracy": 0.02832,
        "main_score": 0.016187,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.056462,
        "recall": 0.080078,
        "f1": 0.062746,
        "accuracy": 0.080078,
        "main_score": 0.062746,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.006744,
        "recall": 0.012695,
        "f1": 0.00753,
        "accuracy": 0.012695,
        "main_score": 0.00753,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.024355,
        "recall": 0.037109,
        "f1": 0.026402,
        "accuracy": 0.037109,
        "main_score": 0.026402,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.042089,
        "recall": 0.071289,
        "f1": 0.048817,
        "accuracy": 0.071289,
        "main_score": 0.048817,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.052316,
        "recall": 0.074219,
        "f1": 0.057011,
        "accuracy": 0.074219,
        "main_score": 0.057011,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.032235,
        "recall": 0.053711,
        "f1": 0.036216,
        "accuracy": 0.053711,
        "main_score": 0.036216,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.021871,
        "recall": 0.041016,
        "f1": 0.025388,
        "accuracy": 0.041016,
        "main_score": 0.025388,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.008806,
        "recall": 0.019531,
        "f1": 0.009914,
        "accuracy": 0.019531,
        "main_score": 0.009914,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.024215,
        "recall": 0.045898,
        "f1": 0.028169,
        "accuracy": 0.045898,
        "main_score": 0.028169,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.010281,
        "recall": 0.019531,
        "f1": 0.011833,
        "accuracy": 0.019531,
        "main_score": 0.011833,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.013066,
        "recall": 0.019531,
        "f1": 0.01387,
        "accuracy": 0.019531,
        "main_score": 0.01387,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007883,
        "recall": 0.014648,
        "f1": 0.009232,
        "accuracy": 0.014648,
        "main_score": 0.009232,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.085167,
        "recall": 0.116211,
        "f1": 0.093266,
        "accuracy": 0.116211,
        "main_score": 0.093266,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.051839,
        "recall": 0.076172,
        "f1": 0.057889,
        "accuracy": 0.076172,
        "main_score": 0.057889,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.162844,
        "recall": 0.197266,
        "f1": 0.171487,
        "accuracy": 0.197266,
        "main_score": 0.171487,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.238644,
        "recall": 0.28125,
        "f1": 0.249432,
        "accuracy": 0.28125,
        "main_score": 0.249432,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.009081,
        "recall": 0.014648,
        "f1": 0.009698,
        "accuracy": 0.014648,
        "main_score": 0.009698,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.122055,
        "recall": 0.141602,
        "f1": 0.126777,
        "accuracy": 0.141602,
        "main_score": 0.126777,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.061238,
        "recall": 0.084961,
        "f1": 0.067309,
        "accuracy": 0.084961,
        "main_score": 0.067309,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.300107,
        "recall": 0.354492,
        "f1": 0.315479,
        "accuracy": 0.354492,
        "main_score": 0.315479,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.041324,
        "recall": 0.055664,
        "f1": 0.044363,
        "accuracy": 0.055664,
        "main_score": 0.044363,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.148252,
        "recall": 0.178711,
        "f1": 0.155076,
        "accuracy": 0.178711,
        "main_score": 0.155076,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.081075,
        "recall": 0.108398,
        "f1": 0.088027,
        "accuracy": 0.108398,
        "main_score": 0.088027,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.065461,
        "recall": 0.082031,
        "f1": 0.068923,
        "accuracy": 0.082031,
        "main_score": 0.068923,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.051303,
        "recall": 0.070312,
        "f1": 0.054851,
        "accuracy": 0.070312,
        "main_score": 0.054851,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.064161,
        "recall": 0.099609,
        "f1": 0.07335,
        "accuracy": 0.099609,
        "main_score": 0.07335,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.045543,
        "recall": 0.067383,
        "f1": 0.05059,
        "accuracy": 0.067383,
        "main_score": 0.05059,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.077036,
        "recall": 0.106445,
        "f1": 0.08453,
        "accuracy": 0.106445,
        "main_score": 0.08453,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.150764,
        "recall": 0.208008,
        "f1": 0.164006,
        "accuracy": 0.208008,
        "main_score": 0.164006,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.029346,
        "recall": 0.043945,
        "f1": 0.031657,
        "accuracy": 0.043945,
        "main_score": 0.031657,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.046514,
        "recall": 0.068359,
        "f1": 0.051693,
        "accuracy": 0.068359,
        "main_score": 0.051693,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.06359,
        "recall": 0.084961,
        "f1": 0.0677,
        "accuracy": 0.084961,
        "main_score": 0.0677,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.077061,
        "recall": 0.09668,
        "f1": 0.080879,
        "accuracy": 0.09668,
        "main_score": 0.080879,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.176864,
        "recall": 0.211914,
        "f1": 0.184176,
        "accuracy": 0.211914,
        "main_score": 0.184176,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.036018,
        "recall": 0.066406,
        "f1": 0.042703,
        "accuracy": 0.066406,
        "main_score": 0.042703,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.041769,
        "recall": 0.066406,
        "f1": 0.048033,
        "accuracy": 0.066406,
        "main_score": 0.048033,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.128128,
        "recall": 0.162109,
        "f1": 0.136452,
        "accuracy": 0.162109,
        "main_score": 0.136452,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.120418,
        "recall": 0.151367,
        "f1": 0.127786,
        "accuracy": 0.151367,
        "main_score": 0.127786,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.009445,
        "recall": 0.015625,
        "f1": 0.01017,
        "accuracy": 0.015625,
        "main_score": 0.01017,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.15507,
        "recall": 0.196289,
        "f1": 0.165067,
        "accuracy": 0.196289,
        "main_score": 0.165067,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.050064,
        "recall": 0.085938,
        "f1": 0.058193,
        "accuracy": 0.085938,
        "main_score": 0.058193,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.097382,
        "recall": 0.12793,
        "f1": 0.104977,
        "accuracy": 0.12793,
        "main_score": 0.104977,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.08157,
        "recall": 0.120117,
        "f1": 0.091043,
        "accuracy": 0.120117,
        "main_score": 0.091043,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.092932,
        "recall": 0.116211,
        "f1": 0.098112,
        "accuracy": 0.116211,
        "main_score": 0.098112,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.037319,
        "recall": 0.064453,
        "f1": 0.042656,
        "accuracy": 0.064453,
        "main_score": 0.042656,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.122591,
        "recall": 0.158203,
        "f1": 0.132,
        "accuracy": 0.158203,
        "main_score": 0.132,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.061184,
        "recall": 0.087891,
        "f1": 0.068067,
        "accuracy": 0.087891,
        "main_score": 0.068067,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.02937,
        "recall": 0.052734,
        "f1": 0.034425,
        "accuracy": 0.052734,
        "main_score": 0.034425,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.057787,
        "recall": 0.084961,
        "f1": 0.064079,
        "accuracy": 0.084961,
        "main_score": 0.064079,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.038708,
        "recall": 0.063477,
        "f1": 0.043255,
        "accuracy": 0.063477,
        "main_score": 0.043255,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.109127,
        "recall": 0.139648,
        "f1": 0.116271,
        "accuracy": 0.139648,
        "main_score": 0.116271,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.027906,
        "recall": 0.054688,
        "f1": 0.033495,
        "accuracy": 0.054688,
        "main_score": 0.033495,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.024551,
        "recall": 0.054688,
        "f1": 0.030136,
        "accuracy": 0.054688,
        "main_score": 0.030136,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.085137,
        "recall": 0.111328,
        "f1": 0.0905,
        "accuracy": 0.111328,
        "main_score": 0.0905,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.215154,
        "recall": 0.253906,
        "f1": 0.225223,
        "accuracy": 0.253906,
        "main_score": 0.225223,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.062038,
        "recall": 0.088867,
        "f1": 0.067045,
        "accuracy": 0.088867,
        "main_score": 0.067045,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.037852,
        "recall": 0.063477,
        "f1": 0.04364,
        "accuracy": 0.063477,
        "main_score": 0.04364,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.043035,
        "recall": 0.072266,
        "f1": 0.049778,
        "accuracy": 0.072266,
        "main_score": 0.049778,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.160588,
        "recall": 0.203125,
        "f1": 0.17109,
        "accuracy": 0.203125,
        "main_score": 0.17109,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.134925,
        "recall": 0.167969,
        "f1": 0.142332,
        "accuracy": 0.167969,
        "main_score": 0.142332,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.007509,
        "recall": 0.013672,
        "f1": 0.008244,
        "accuracy": 0.013672,
        "main_score": 0.008244,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.179697,
        "recall": 0.229492,
        "f1": 0.192899,
        "accuracy": 0.229492,
        "main_score": 0.192899,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.055187,
        "recall": 0.102539,
        "f1": 0.065732,
        "accuracy": 0.102539,
        "main_score": 0.065732,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.112081,
        "recall": 0.147461,
        "f1": 0.120947,
        "accuracy": 0.147461,
        "main_score": 0.120947,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.086795,
        "recall": 0.124023,
        "f1": 0.096684,
        "accuracy": 0.124023,
        "main_score": 0.096684,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.093404,
        "recall": 0.119141,
        "f1": 0.099032,
        "accuracy": 0.119141,
        "main_score": 0.099032,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.038359,
        "recall": 0.066406,
        "f1": 0.044709,
        "accuracy": 0.066406,
        "main_score": 0.044709,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.108944,
        "recall": 0.146484,
        "f1": 0.119188,
        "accuracy": 0.146484,
        "main_score": 0.119188,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.072616,
        "recall": 0.100586,
        "f1": 0.07997,
        "accuracy": 0.100586,
        "main_score": 0.07997,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.03182,
        "recall": 0.055664,
        "f1": 0.037305,
        "accuracy": 0.055664,
        "main_score": 0.037305,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.055665,
        "recall": 0.087891,
        "f1": 0.062477,
        "accuracy": 0.087891,
        "main_score": 0.062477,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.042954,
        "recall": 0.069336,
        "f1": 0.04903,
        "accuracy": 0.069336,
        "main_score": 0.04903,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.11209,
        "recall": 0.140625,
        "f1": 0.119259,
        "accuracy": 0.140625,
        "main_score": 0.119259,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.026885,
        "recall": 0.053711,
        "f1": 0.032856,
        "accuracy": 0.053711,
        "main_score": 0.032856,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.026848,
        "recall": 0.050781,
        "f1": 0.03205,
        "accuracy": 0.050781,
        "main_score": 0.03205,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.095994,
        "recall": 0.125,
        "f1": 0.102607,
        "accuracy": 0.125,
        "main_score": 0.102607,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.213315,
        "recall": 0.251953,
        "f1": 0.223547,
        "accuracy": 0.251953,
        "main_score": 0.223547,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.066368,
        "recall": 0.098633,
        "f1": 0.07268,
        "accuracy": 0.098633,
        "main_score": 0.07268,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.011503,
        "recall": 0.019531,
        "f1": 0.012417,
        "accuracy": 0.019531,
        "main_score": 0.012417,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.01024,
        "recall": 0.020508,
        "f1": 0.011477,
        "accuracy": 0.020508,
        "main_score": 0.011477,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.034828,
        "recall": 0.054688,
        "f1": 0.038061,
        "accuracy": 0.054688,
        "main_score": 0.038061,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.098823,
        "recall": 0.140625,
        "f1": 0.108366,
        "accuracy": 0.140625,
        "main_score": 0.108366,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00473,
        "recall": 0.008789,
        "f1": 0.005066,
        "accuracy": 0.008789,
        "main_score": 0.005066,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014888,
        "recall": 0.023438,
        "f1": 0.016223,
        "accuracy": 0.023438,
        "main_score": 0.016223,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.007323,
        "recall": 0.014648,
        "f1": 0.008198,
        "accuracy": 0.014648,
        "main_score": 0.008198,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.103348,
        "recall": 0.145508,
        "f1": 0.112929,
        "accuracy": 0.145508,
        "main_score": 0.112929,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001232,
        "recall": 0.003906,
        "f1": 0.001426,
        "accuracy": 0.003906,
        "main_score": 0.001426,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.21249,
        "recall": 0.25293,
        "f1": 0.223645,
        "accuracy": 0.25293,
        "main_score": 0.223645,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.008535,
        "recall": 0.022461,
        "f1": 0.010466,
        "accuracy": 0.022461,
        "main_score": 0.010466,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.007048,
        "recall": 0.014648,
        "f1": 0.008352,
        "accuracy": 0.014648,
        "main_score": 0.008352,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001802,
        "recall": 0.005859,
        "f1": 0.002297,
        "accuracy": 0.005859,
        "main_score": 0.002297,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.013213,
        "recall": 0.024414,
        "f1": 0.014888,
        "accuracy": 0.024414,
        "main_score": 0.014888,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.007061,
        "recall": 0.010742,
        "f1": 0.007251,
        "accuracy": 0.010742,
        "main_score": 0.007251,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.003741,
        "recall": 0.009766,
        "f1": 0.004208,
        "accuracy": 0.009766,
        "main_score": 0.004208,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.056801,
        "recall": 0.097656,
        "f1": 0.064804,
        "accuracy": 0.097656,
        "main_score": 0.064804,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.002553,
        "recall": 0.005859,
        "f1": 0.002891,
        "accuracy": 0.005859,
        "main_score": 0.002891,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.008058,
        "recall": 0.016602,
        "f1": 0.008928,
        "accuracy": 0.016602,
        "main_score": 0.008928,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.074611,
        "recall": 0.117188,
        "f1": 0.082147,
        "accuracy": 0.117188,
        "main_score": 0.082147,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.012631,
        "recall": 0.022461,
        "f1": 0.014073,
        "accuracy": 0.022461,
        "main_score": 0.014073,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.01656,
        "recall": 0.029297,
        "f1": 0.018506,
        "accuracy": 0.029297,
        "main_score": 0.018506,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 15.454734563827515,
  "kg_co2_emissions": 0.0004800595275984692
}