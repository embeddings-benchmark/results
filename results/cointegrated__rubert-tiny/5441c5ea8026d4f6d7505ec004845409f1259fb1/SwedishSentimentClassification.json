{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.695752,
        "f1": 0.693801,
        "f1_weighted": 0.693839,
        "ap": 0.636249,
        "ap_weighted": 0.636249,
        "scores_per_experiment": [
          {
            "accuracy": 0.657715,
            "f1": 0.645841,
            "f1_weighted": 0.646031,
            "ap": 0.598126,
            "ap_weighted": 0.598126
          },
          {
            "accuracy": 0.725586,
            "f1": 0.725227,
            "f1_weighted": 0.725198,
            "ap": 0.669233,
            "ap_weighted": 0.669233
          },
          {
            "accuracy": 0.683105,
            "f1": 0.682393,
            "f1_weighted": 0.682437,
            "ap": 0.623524,
            "ap_weighted": 0.623524
          },
          {
            "accuracy": 0.705078,
            "f1": 0.704873,
            "f1_weighted": 0.704896,
            "ap": 0.643884,
            "ap_weighted": 0.643884
          },
          {
            "accuracy": 0.700684,
            "f1": 0.700632,
            "f1_weighted": 0.700643,
            "ap": 0.641013,
            "ap_weighted": 0.641013
          },
          {
            "accuracy": 0.660156,
            "f1": 0.659584,
            "f1_weighted": 0.659543,
            "ap": 0.609598,
            "ap_weighted": 0.609598
          },
          {
            "accuracy": 0.723633,
            "f1": 0.722712,
            "f1_weighted": 0.722759,
            "ap": 0.657964,
            "ap_weighted": 0.657964
          },
          {
            "accuracy": 0.713379,
            "f1": 0.713072,
            "f1_weighted": 0.713099,
            "ap": 0.650799,
            "ap_weighted": 0.650799
          },
          {
            "accuracy": 0.674805,
            "f1": 0.670353,
            "f1_weighted": 0.670465,
            "ap": 0.613384,
            "ap_weighted": 0.613384
          },
          {
            "accuracy": 0.713379,
            "f1": 0.713329,
            "f1_weighted": 0.713318,
            "ap": 0.654962,
            "ap_weighted": 0.654962
          }
        ],
        "main_score": 0.695752,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.694189,
        "f1": 0.692462,
        "f1_weighted": 0.69248,
        "ap": 0.634766,
        "ap_weighted": 0.634766,
        "scores_per_experiment": [
          {
            "accuracy": 0.67334,
            "f1": 0.665217,
            "f1_weighted": 0.665319,
            "ap": 0.610315,
            "ap_weighted": 0.610315
          },
          {
            "accuracy": 0.708984,
            "f1": 0.708421,
            "f1_weighted": 0.708396,
            "ap": 0.653445,
            "ap_weighted": 0.653445
          },
          {
            "accuracy": 0.69873,
            "f1": 0.698529,
            "f1_weighted": 0.698544,
            "ap": 0.637846,
            "ap_weighted": 0.637846
          },
          {
            "accuracy": 0.703613,
            "f1": 0.70335,
            "f1_weighted": 0.703367,
            "ap": 0.641857,
            "ap_weighted": 0.641857
          },
          {
            "accuracy": 0.695801,
            "f1": 0.69564,
            "f1_weighted": 0.695627,
            "ap": 0.639106,
            "ap_weighted": 0.639106
          },
          {
            "accuracy": 0.665527,
            "f1": 0.664394,
            "f1_weighted": 0.664356,
            "ap": 0.614851,
            "ap_weighted": 0.614851
          },
          {
            "accuracy": 0.71875,
            "f1": 0.717541,
            "f1_weighted": 0.717577,
            "ap": 0.652545,
            "ap_weighted": 0.652545
          },
          {
            "accuracy": 0.707031,
            "f1": 0.706669,
            "f1_weighted": 0.706689,
            "ap": 0.644474,
            "ap_weighted": 0.644474
          },
          {
            "accuracy": 0.663086,
            "f1": 0.65799,
            "f1_weighted": 0.658071,
            "ap": 0.603709,
            "ap_weighted": 0.603709
          },
          {
            "accuracy": 0.707031,
            "f1": 0.70687,
            "f1_weighted": 0.706857,
            "ap": 0.649511,
            "ap_weighted": 0.649511
          }
        ],
        "main_score": 0.694189,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.281255722045898,
  "kg_co2_emissions": 0.000456019036956863
}