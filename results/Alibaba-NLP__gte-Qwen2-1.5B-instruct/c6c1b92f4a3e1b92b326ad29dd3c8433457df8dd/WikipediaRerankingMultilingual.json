{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "map": 0.862423,
        "mrr": 0.862423,
        "nAUC_map_max": 0.538022,
        "nAUC_map_std": 0.276461,
        "nAUC_map_diff1": 0.752192,
        "nAUC_mrr_max": 0.538022,
        "nAUC_mrr_std": 0.276461,
        "nAUC_mrr_diff1": 0.752192,
        "main_score": 0.862423,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.821522,
        "mrr": 0.821522,
        "nAUC_map_max": 0.408151,
        "nAUC_map_std": 0.319771,
        "nAUC_map_diff1": 0.683066,
        "nAUC_mrr_max": 0.408151,
        "nAUC_mrr_std": 0.319771,
        "nAUC_mrr_diff1": 0.683066,
        "main_score": 0.821522,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.881536,
        "mrr": 0.881536,
        "nAUC_map_max": 0.50332,
        "nAUC_map_std": 0.33302,
        "nAUC_map_diff1": 0.759718,
        "nAUC_mrr_max": 0.50332,
        "nAUC_mrr_std": 0.33302,
        "nAUC_mrr_diff1": 0.759718,
        "main_score": 0.881536,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.878065,
        "mrr": 0.878509,
        "nAUC_map_max": 0.513065,
        "nAUC_map_std": 0.350553,
        "nAUC_map_diff1": 0.79678,
        "nAUC_mrr_max": 0.517026,
        "nAUC_mrr_std": 0.349634,
        "nAUC_mrr_diff1": 0.795694,
        "main_score": 0.878065,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.882235,
        "mrr": 0.882235,
        "nAUC_map_max": 0.560354,
        "nAUC_map_std": 0.29023,
        "nAUC_map_diff1": 0.783333,
        "nAUC_mrr_max": 0.560354,
        "nAUC_mrr_std": 0.29023,
        "nAUC_mrr_diff1": 0.783333,
        "main_score": 0.882235,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.92325,
        "mrr": 0.92325,
        "nAUC_map_max": 0.584082,
        "nAUC_map_std": 0.481579,
        "nAUC_map_diff1": 0.851912,
        "nAUC_mrr_max": 0.584082,
        "nAUC_mrr_std": 0.481579,
        "nAUC_mrr_diff1": 0.851912,
        "main_score": 0.92325,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.873883,
        "mrr": 0.873883,
        "nAUC_map_max": 0.514015,
        "nAUC_map_std": 0.324399,
        "nAUC_map_diff1": 0.785504,
        "nAUC_mrr_max": 0.514015,
        "nAUC_mrr_std": 0.324399,
        "nAUC_mrr_diff1": 0.785504,
        "main_score": 0.873883,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.868467,
        "mrr": 0.868467,
        "nAUC_map_max": 0.403313,
        "nAUC_map_std": 0.248978,
        "nAUC_map_diff1": 0.74074,
        "nAUC_mrr_max": 0.403313,
        "nAUC_mrr_std": 0.248978,
        "nAUC_mrr_diff1": 0.74074,
        "main_score": 0.868467,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.855994,
        "mrr": 0.856781,
        "nAUC_map_max": 0.488399,
        "nAUC_map_std": 0.297685,
        "nAUC_map_diff1": 0.74534,
        "nAUC_mrr_max": 0.492482,
        "nAUC_mrr_std": 0.303895,
        "nAUC_mrr_diff1": 0.742966,
        "main_score": 0.855994,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.88565,
        "mrr": 0.88565,
        "nAUC_map_max": 0.533465,
        "nAUC_map_std": 0.286022,
        "nAUC_map_diff1": 0.759246,
        "nAUC_mrr_max": 0.533465,
        "nAUC_mrr_std": 0.286022,
        "nAUC_mrr_diff1": 0.759246,
        "main_score": 0.88565,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.891745,
        "mrr": 0.892079,
        "nAUC_map_max": 0.511784,
        "nAUC_map_std": 0.274078,
        "nAUC_map_diff1": 0.753515,
        "nAUC_mrr_max": 0.510891,
        "nAUC_mrr_std": 0.278555,
        "nAUC_mrr_diff1": 0.752404,
        "main_score": 0.891745,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.871851,
        "mrr": 0.871851,
        "nAUC_map_max": 0.555128,
        "nAUC_map_std": 0.279496,
        "nAUC_map_diff1": 0.751859,
        "nAUC_mrr_max": 0.555128,
        "nAUC_mrr_std": 0.279496,
        "nAUC_mrr_diff1": 0.751859,
        "main_score": 0.871851,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.878272,
        "mrr": 0.878605,
        "nAUC_map_max": 0.510512,
        "nAUC_map_std": 0.310042,
        "nAUC_map_diff1": 0.770601,
        "nAUC_mrr_max": 0.508906,
        "nAUC_mrr_std": 0.308735,
        "nAUC_mrr_diff1": 0.769648,
        "main_score": 0.878272,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.865771,
        "mrr": 0.866104,
        "nAUC_map_max": 0.378759,
        "nAUC_map_std": 0.215106,
        "nAUC_map_diff1": 0.757757,
        "nAUC_mrr_max": 0.38255,
        "nAUC_mrr_std": 0.220147,
        "nAUC_mrr_diff1": 0.756553,
        "main_score": 0.865771,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.844646,
        "mrr": 0.844646,
        "nAUC_map_max": 0.448286,
        "nAUC_map_std": 0.250268,
        "nAUC_map_diff1": 0.725798,
        "nAUC_mrr_max": 0.448286,
        "nAUC_mrr_std": 0.250268,
        "nAUC_mrr_diff1": 0.725798,
        "main_score": 0.844646,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.884613,
        "mrr": 0.884613,
        "nAUC_map_max": 0.449738,
        "nAUC_map_std": 0.252679,
        "nAUC_map_diff1": 0.779504,
        "nAUC_mrr_max": 0.449738,
        "nAUC_mrr_std": 0.252679,
        "nAUC_mrr_diff1": 0.779504,
        "main_score": 0.884613,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 854.5179557800293,
  "kg_co2_emissions": 0.23568347041826399
}