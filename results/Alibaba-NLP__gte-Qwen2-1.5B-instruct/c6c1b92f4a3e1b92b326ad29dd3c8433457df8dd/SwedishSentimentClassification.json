{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.926807,
        "f1": 0.926569,
        "f1_weighted": 0.926577,
        "ap": 0.888153,
        "ap_weighted": 0.888153,
        "scores_per_experiment": [
          {
            "accuracy": 0.945801,
            "f1": 0.945736,
            "f1_weighted": 0.945741,
            "ap": 0.910054,
            "ap_weighted": 0.910054
          },
          {
            "accuracy": 0.937988,
            "f1": 0.937876,
            "f1_weighted": 0.937884,
            "ap": 0.897074,
            "ap_weighted": 0.897074
          },
          {
            "accuracy": 0.938477,
            "f1": 0.938474,
            "f1_weighted": 0.938472,
            "ap": 0.915673,
            "ap_weighted": 0.915673
          },
          {
            "accuracy": 0.930176,
            "f1": 0.930171,
            "f1_weighted": 0.930173,
            "ap": 0.898548,
            "ap_weighted": 0.898548
          },
          {
            "accuracy": 0.932129,
            "f1": 0.932056,
            "f1_weighted": 0.932063,
            "ap": 0.892647,
            "ap_weighted": 0.892647
          },
          {
            "accuracy": 0.929688,
            "f1": 0.929686,
            "f1_weighted": 0.929685,
            "ap": 0.902793,
            "ap_weighted": 0.902793
          },
          {
            "accuracy": 0.920898,
            "f1": 0.920678,
            "f1_weighted": 0.92069,
            "ap": 0.871935,
            "ap_weighted": 0.871935
          },
          {
            "accuracy": 0.933594,
            "f1": 0.933471,
            "f1_weighted": 0.933479,
            "ap": 0.891191,
            "ap_weighted": 0.891191
          },
          {
            "accuracy": 0.936035,
            "f1": 0.936034,
            "f1_weighted": 0.936033,
            "ap": 0.911325,
            "ap_weighted": 0.911325
          },
          {
            "accuracy": 0.863281,
            "f1": 0.861504,
            "f1_weighted": 0.86155,
            "ap": 0.790286,
            "ap_weighted": 0.790286
          }
        ],
        "main_score": 0.926807,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.920996,
        "f1": 0.920772,
        "f1_weighted": 0.920778,
        "ap": 0.87909,
        "ap_weighted": 0.87909,
        "scores_per_experiment": [
          {
            "accuracy": 0.938965,
            "f1": 0.938914,
            "f1_weighted": 0.938918,
            "ap": 0.902561,
            "ap_weighted": 0.902561
          },
          {
            "accuracy": 0.931641,
            "f1": 0.931477,
            "f1_weighted": 0.931484,
            "ap": 0.886385,
            "ap_weighted": 0.886385
          },
          {
            "accuracy": 0.929688,
            "f1": 0.929686,
            "f1_weighted": 0.929686,
            "ap": 0.901922,
            "ap_weighted": 0.901922
          },
          {
            "accuracy": 0.916504,
            "f1": 0.91648,
            "f1_weighted": 0.916482,
            "ap": 0.876919,
            "ap_weighted": 0.876919
          },
          {
            "accuracy": 0.922363,
            "f1": 0.92229,
            "f1_weighted": 0.922294,
            "ap": 0.880116,
            "ap_weighted": 0.880116
          },
          {
            "accuracy": 0.926758,
            "f1": 0.926758,
            "f1_weighted": 0.926758,
            "ap": 0.896123,
            "ap_weighted": 0.896123
          },
          {
            "accuracy": 0.910156,
            "f1": 0.909826,
            "f1_weighted": 0.909836,
            "ap": 0.855937,
            "ap_weighted": 0.855937
          },
          {
            "accuracy": 0.931152,
            "f1": 0.931022,
            "f1_weighted": 0.931028,
            "ap": 0.887447,
            "ap_weighted": 0.887447
          },
          {
            "accuracy": 0.929199,
            "f1": 0.929198,
            "f1_weighted": 0.929198,
            "ap": 0.901071,
            "ap_weighted": 0.901071
          },
          {
            "accuracy": 0.873535,
            "f1": 0.872072,
            "f1_weighted": 0.872099,
            "ap": 0.80242,
            "ap_weighted": 0.80242
          }
        ],
        "main_score": 0.920996,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 46.12475275993347,
  "kg_co2_emissions": 0.01055991912677745
}