{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.993982,
        "recall": 0.995988,
        "f1": 0.994651,
        "accuracy": 0.995988,
        "main_score": 0.994651,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.993982,
        "recall": 0.995988,
        "f1": 0.994651,
        "accuracy": 0.995988,
        "main_score": 0.994651,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.927533,
        "recall": 0.94985,
        "f1": 0.934704,
        "accuracy": 0.94985,
        "main_score": 0.934704,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.932631,
        "recall": 0.953862,
        "f1": 0.939485,
        "accuracy": 0.953862,
        "main_score": 0.939485,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.995486,
        "recall": 0.996991,
        "f1": 0.995988,
        "accuracy": 0.996991,
        "main_score": 0.995988,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.996991,
        "recall": 0.997994,
        "f1": 0.997325,
        "accuracy": 0.997994,
        "main_score": 0.997325,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.528548,
        "recall": 0.599799,
        "f1": 0.546691,
        "accuracy": 0.599799,
        "main_score": 0.546691,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.575911,
        "recall": 0.667001,
        "f1": 0.60266,
        "accuracy": 0.667001,
        "main_score": 0.60266,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.696543,
        "recall": 0.761284,
        "f1": 0.714002,
        "accuracy": 0.761284,
        "main_score": 0.714002,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.762621,
        "recall": 0.826479,
        "f1": 0.782481,
        "accuracy": 0.826479,
        "main_score": 0.782481,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.951521,
        "recall": 0.966901,
        "f1": 0.956536,
        "accuracy": 0.966901,
        "main_score": 0.956536,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.956035,
        "recall": 0.96991,
        "f1": 0.960548,
        "accuracy": 0.96991,
        "main_score": 0.960548,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.388569,
        "recall": 0.46339,
        "f1": 0.407511,
        "accuracy": 0.46339,
        "main_score": 0.407511,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.457235,
        "recall": 0.559679,
        "f1": 0.486152,
        "accuracy": 0.559679,
        "main_score": 0.486152,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.566667,
        "recall": 0.640923,
        "f1": 0.586474,
        "accuracy": 0.640923,
        "main_score": 0.586474,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.605199,
        "recall": 0.696088,
        "f1": 0.631867,
        "accuracy": 0.696088,
        "main_score": 0.631867,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.977432,
        "recall": 0.984955,
        "f1": 0.97994,
        "accuracy": 0.984955,
        "main_score": 0.97994,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.978101,
        "recall": 0.984955,
        "f1": 0.980274,
        "accuracy": 0.984955,
        "main_score": 0.980274,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.889418,
        "recall": 0.920762,
        "f1": 0.899016,
        "accuracy": 0.920762,
        "main_score": 0.899016,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.881478,
        "recall": 0.91675,
        "f1": 0.892645,
        "accuracy": 0.91675,
        "main_score": 0.892645,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.957706,
        "recall": 0.970913,
        "f1": 0.962053,
        "accuracy": 0.970913,
        "main_score": 0.962053,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.958709,
        "recall": 0.971916,
        "f1": 0.963056,
        "accuracy": 0.971916,
        "main_score": 0.963056,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.913156,
        "recall": 0.938816,
        "f1": 0.921163,
        "accuracy": 0.938816,
        "main_score": 0.921163,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.917787,
        "recall": 0.942828,
        "f1": 0.925777,
        "accuracy": 0.942828,
        "main_score": 0.925777,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.554868,
        "recall": 0.638917,
        "f1": 0.576897,
        "accuracy": 0.638917,
        "main_score": 0.576897,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.615549,
        "recall": 0.706118,
        "f1": 0.641314,
        "accuracy": 0.706118,
        "main_score": 0.641314,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.739219,
        "recall": 0.80341,
        "f1": 0.757651,
        "accuracy": 0.80341,
        "main_score": 0.757651,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.757539,
        "recall": 0.825476,
        "f1": 0.778268,
        "accuracy": 0.825476,
        "main_score": 0.778268,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.794818,
        "recall": 0.84654,
        "f1": 0.810021,
        "accuracy": 0.84654,
        "main_score": 0.810021,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.827065,
        "recall": 0.875627,
        "f1": 0.84206,
        "accuracy": 0.875627,
        "main_score": 0.84206,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.850674,
        "recall": 0.887663,
        "f1": 0.861139,
        "accuracy": 0.887663,
        "main_score": 0.861139,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.878887,
        "recall": 0.91675,
        "f1": 0.891073,
        "accuracy": 0.91675,
        "main_score": 0.891073,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.985958,
        "recall": 0.98997,
        "f1": 0.987295,
        "accuracy": 0.98997,
        "main_score": 0.987295,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.984955,
        "recall": 0.988967,
        "f1": 0.986292,
        "accuracy": 0.988967,
        "main_score": 0.986292,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.984788,
        "recall": 0.988967,
        "f1": 0.986125,
        "accuracy": 0.988967,
        "main_score": 0.986125,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.990973,
        "recall": 0.993982,
        "f1": 0.991976,
        "accuracy": 0.993982,
        "main_score": 0.991976,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.068299,
        "recall": 0.091274,
        "f1": 0.072783,
        "accuracy": 0.091274,
        "main_score": 0.072783,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.062842,
        "recall": 0.12337,
        "f1": 0.073894,
        "accuracy": 0.12337,
        "main_score": 0.073894,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.335497,
        "recall": 0.396189,
        "f1": 0.349963,
        "accuracy": 0.396189,
        "main_score": 0.349963,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.333914,
        "recall": 0.435306,
        "f1": 0.361255,
        "accuracy": 0.435306,
        "main_score": 0.361255,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.977767,
        "recall": 0.984955,
        "f1": 0.980107,
        "accuracy": 0.984955,
        "main_score": 0.980107,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.980441,
        "recall": 0.986961,
        "f1": 0.982615,
        "accuracy": 0.986961,
        "main_score": 0.982615,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.775178,
        "recall": 0.828485,
        "f1": 0.791126,
        "accuracy": 0.828485,
        "main_score": 0.791126,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.775911,
        "recall": 0.837513,
        "f1": 0.794851,
        "accuracy": 0.837513,
        "main_score": 0.794851,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.965062,
        "recall": 0.975928,
        "f1": 0.968572,
        "accuracy": 0.975928,
        "main_score": 0.968572,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.951688,
        "recall": 0.965898,
        "f1": 0.956202,
        "accuracy": 0.965898,
        "main_score": 0.956202,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.974758,
        "recall": 0.982949,
        "f1": 0.977432,
        "accuracy": 0.982949,
        "main_score": 0.977432,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.969074,
        "recall": 0.978937,
        "f1": 0.97225,
        "accuracy": 0.978937,
        "main_score": 0.97225,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.976262,
        "recall": 0.983952,
        "f1": 0.97877,
        "accuracy": 0.983952,
        "main_score": 0.97877,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.990973,
        "recall": 0.993982,
        "f1": 0.991976,
        "accuracy": 0.993982,
        "main_score": 0.991976,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.330698,
        "recall": 0.395186,
        "f1": 0.346181,
        "accuracy": 0.395186,
        "main_score": 0.346181,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.350392,
        "recall": 0.449348,
        "f1": 0.375478,
        "accuracy": 0.449348,
        "main_score": 0.375478,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.98345,
        "recall": 0.988967,
        "f1": 0.985289,
        "accuracy": 0.988967,
        "main_score": 0.985289,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.980441,
        "recall": 0.986961,
        "f1": 0.982615,
        "accuracy": 0.986961,
        "main_score": 0.982615,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.980441,
        "recall": 0.986961,
        "f1": 0.982615,
        "accuracy": 0.986961,
        "main_score": 0.982615,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.968907,
        "recall": 0.978937,
        "f1": 0.97225,
        "accuracy": 0.978937,
        "main_score": 0.97225,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.007029,
        "recall": 0.01003,
        "f1": 0.007371,
        "accuracy": 0.01003,
        "main_score": 0.007371,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001442,
        "recall": 0.018054,
        "f1": 0.002406,
        "accuracy": 0.018054,
        "main_score": 0.002406,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.998518,
        "recall": 0.999012,
        "f1": 0.998682,
        "accuracy": 0.999012,
        "main_score": 0.998682,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.995553,
        "recall": 0.997036,
        "f1": 0.996047,
        "accuracy": 0.997036,
        "main_score": 0.996047,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.94277,
        "recall": 0.960474,
        "f1": 0.948353,
        "accuracy": 0.960474,
        "main_score": 0.948353,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.960968,
        "recall": 0.97332,
        "f1": 0.964921,
        "accuracy": 0.97332,
        "main_score": 0.964921,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998518,
        "recall": 0.999012,
        "f1": 0.998682,
        "accuracy": 0.999012,
        "main_score": 0.998682,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.995553,
        "recall": 0.997036,
        "f1": 0.996047,
        "accuracy": 0.997036,
        "main_score": 0.996047,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.535282,
        "recall": 0.619565,
        "f1": 0.557784,
        "accuracy": 0.619565,
        "main_score": 0.557784,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.572177,
        "recall": 0.666008,
        "f1": 0.599435,
        "accuracy": 0.666008,
        "main_score": 0.599435,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.704788,
        "recall": 0.774704,
        "f1": 0.724847,
        "accuracy": 0.774704,
        "main_score": 0.724847,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.784832,
        "recall": 0.847826,
        "f1": 0.804743,
        "accuracy": 0.847826,
        "main_score": 0.804743,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.946887,
        "recall": 0.963439,
        "f1": 0.952141,
        "accuracy": 0.963439,
        "main_score": 0.952141,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.94697,
        "recall": 0.964427,
        "f1": 0.952734,
        "accuracy": 0.964427,
        "main_score": 0.952734,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.365618,
        "recall": 0.450593,
        "f1": 0.386216,
        "accuracy": 0.450593,
        "main_score": 0.386216,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.424054,
        "recall": 0.52668,
        "f1": 0.452529,
        "accuracy": 0.52668,
        "main_score": 0.452529,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.578249,
        "recall": 0.657115,
        "f1": 0.599688,
        "accuracy": 0.657115,
        "main_score": 0.599688,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.593316,
        "recall": 0.681818,
        "f1": 0.619076,
        "accuracy": 0.681818,
        "main_score": 0.619076,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.985178,
        "recall": 0.990119,
        "f1": 0.986825,
        "accuracy": 0.990119,
        "main_score": 0.986825,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.986989,
        "recall": 0.991107,
        "f1": 0.988307,
        "accuracy": 0.991107,
        "main_score": 0.988307,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.891775,
        "recall": 0.922925,
        "f1": 0.9014,
        "accuracy": 0.922925,
        "main_score": 0.9014,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.871706,
        "recall": 0.908103,
        "f1": 0.883399,
        "accuracy": 0.908103,
        "main_score": 0.883399,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.94837,
        "recall": 0.964427,
        "f1": 0.953458,
        "accuracy": 0.964427,
        "main_score": 0.953458,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.946146,
        "recall": 0.963439,
        "f1": 0.95191,
        "accuracy": 0.963439,
        "main_score": 0.95191,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.938109,
        "recall": 0.956522,
        "f1": 0.944005,
        "accuracy": 0.956522,
        "main_score": 0.944005,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.934783,
        "recall": 0.955534,
        "f1": 0.941535,
        "accuracy": 0.955534,
        "main_score": 0.941535,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.533097,
        "recall": 0.616601,
        "f1": 0.554549,
        "accuracy": 0.616601,
        "main_score": 0.554549,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.573888,
        "recall": 0.66996,
        "f1": 0.60138,
        "accuracy": 0.66996,
        "main_score": 0.60138,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.733837,
        "recall": 0.800395,
        "f1": 0.75323,
        "accuracy": 0.800395,
        "main_score": 0.75323,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.757592,
        "recall": 0.821146,
        "f1": 0.776402,
        "accuracy": 0.821146,
        "main_score": 0.776402,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.799444,
        "recall": 0.853755,
        "f1": 0.816024,
        "accuracy": 0.853755,
        "main_score": 0.816024,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.813603,
        "recall": 0.865613,
        "f1": 0.829809,
        "accuracy": 0.865613,
        "main_score": 0.829809,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.853147,
        "recall": 0.893281,
        "f1": 0.865242,
        "accuracy": 0.893281,
        "main_score": 0.865242,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.881094,
        "recall": 0.916008,
        "f1": 0.892292,
        "accuracy": 0.916008,
        "main_score": 0.892292,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.980567,
        "recall": 0.986166,
        "f1": 0.982378,
        "accuracy": 0.986166,
        "main_score": 0.982378,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.978014,
        "recall": 0.98419,
        "f1": 0.979974,
        "accuracy": 0.98419,
        "main_score": 0.979974,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.980072,
        "recall": 0.986166,
        "f1": 0.982049,
        "accuracy": 0.986166,
        "main_score": 0.982049,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.979578,
        "recall": 0.986166,
        "f1": 0.981719,
        "accuracy": 0.986166,
        "main_score": 0.981719,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.058833,
        "recall": 0.082016,
        "f1": 0.063028,
        "accuracy": 0.082016,
        "main_score": 0.063028,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.059979,
        "recall": 0.114625,
        "f1": 0.070266,
        "accuracy": 0.114625,
        "main_score": 0.070266,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.315412,
        "recall": 0.387352,
        "f1": 0.332044,
        "accuracy": 0.387352,
        "main_score": 0.332044,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.336062,
        "recall": 0.440711,
        "f1": 0.364401,
        "accuracy": 0.440711,
        "main_score": 0.364401,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.990119,
        "recall": 0.993083,
        "f1": 0.991107,
        "accuracy": 0.993083,
        "main_score": 0.991107,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.978261,
        "recall": 0.985178,
        "f1": 0.980567,
        "accuracy": 0.985178,
        "main_score": 0.980567,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.791914,
        "recall": 0.843874,
        "f1": 0.807436,
        "accuracy": 0.843874,
        "main_score": 0.807436,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.813752,
        "recall": 0.866601,
        "f1": 0.830435,
        "accuracy": 0.866601,
        "main_score": 0.830435,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.976943,
        "recall": 0.98419,
        "f1": 0.979249,
        "accuracy": 0.98419,
        "main_score": 0.979249,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.964427,
        "recall": 0.976285,
        "f1": 0.968379,
        "accuracy": 0.976285,
        "main_score": 0.968379,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.976038,
        "recall": 0.983202,
        "f1": 0.978327,
        "accuracy": 0.983202,
        "main_score": 0.978327,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.972661,
        "recall": 0.981225,
        "f1": 0.975461,
        "accuracy": 0.981225,
        "main_score": 0.975461,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.979249,
        "recall": 0.986166,
        "f1": 0.981555,
        "accuracy": 0.986166,
        "main_score": 0.981555,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.988142,
        "recall": 0.992095,
        "f1": 0.98946,
        "accuracy": 0.992095,
        "main_score": 0.98946,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.323802,
        "recall": 0.375494,
        "f1": 0.336644,
        "accuracy": 0.375494,
        "main_score": 0.336644,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.348579,
        "recall": 0.449605,
        "f1": 0.375444,
        "accuracy": 0.449605,
        "main_score": 0.375444,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.975296,
        "recall": 0.983202,
        "f1": 0.977931,
        "accuracy": 0.983202,
        "main_score": 0.977931,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.972167,
        "recall": 0.981225,
        "f1": 0.975132,
        "accuracy": 0.981225,
        "main_score": 0.975132,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.974638,
        "recall": 0.982213,
        "f1": 0.977108,
        "accuracy": 0.982213,
        "main_score": 0.977108,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.973155,
        "recall": 0.981225,
        "f1": 0.975791,
        "accuracy": 0.981225,
        "main_score": 0.975791,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.008949,
        "recall": 0.011858,
        "f1": 0.009329,
        "accuracy": 0.011858,
        "main_score": 0.009329,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003566,
        "recall": 0.029644,
        "f1": 0.005785,
        "accuracy": 0.029644,
        "main_score": 0.005785,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 412.76595520973206,
  "kg_co2_emissions": 0.11493600579589895
}