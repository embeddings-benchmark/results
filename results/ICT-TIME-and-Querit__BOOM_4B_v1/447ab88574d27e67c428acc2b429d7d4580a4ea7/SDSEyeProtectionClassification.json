{
  "dataset_revision": "35cbe5ee544dd26e343238a333de4568e6f77819",
  "task_name": "SDSEyeProtectionClassification",
  "mteb_version": "2.7.22",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.821,
            "f1": 0.459012,
            "f1_weighted": 0.899328,
            "precision": 0.503569,
            "precision_weighted": 0.996305,
            "recall": 0.710777,
            "recall_weighted": 0.821,
            "ap": 0.998553,
            "ap_weighted": 0.998553
          },
          {
            "accuracy": 0.8165,
            "f1": 0.460046,
            "f1_weighted": 0.896565,
            "precision": 0.505099,
            "precision_weighted": 0.996915,
            "recall": 0.808271,
            "recall_weighted": 0.8165,
            "ap": 0.99904,
            "ap_weighted": 0.99904
          },
          {
            "accuracy": 0.6985,
            "f1": 0.412846,
            "f1_weighted": 0.820338,
            "precision": 0.499405,
            "precision_weighted": 0.994654,
            "recall": 0.449875,
            "recall_weighted": 0.6985,
            "ap": 0.99725,
            "ap_weighted": 0.99725
          },
          {
            "accuracy": 0.859,
            "f1": 0.469029,
            "f1_weighted": 0.921796,
            "precision": 0.502686,
            "precision_weighted": 0.995777,
            "recall": 0.630075,
            "recall_weighted": 0.859,
            "ap": 0.998149,
            "ap_weighted": 0.998149
          },
          {
            "accuracy": 0.8565,
            "f1": 0.471528,
            "f1_weighted": 0.920324,
            "precision": 0.504624,
            "precision_weighted": 0.996361,
            "recall": 0.728571,
            "recall_weighted": 0.8565,
            "ap": 0.998642,
            "ap_weighted": 0.998642
          },
          {
            "accuracy": 0.797,
            "f1": 0.445937,
            "f1_weighted": 0.884766,
            "precision": 0.499988,
            "precision_weighted": 0.995008,
            "recall": 0.499248,
            "recall_weighted": 0.797,
            "ap": 0.997496,
            "ap_weighted": 0.997496
          },
          {
            "accuracy": 0.8075,
            "f1": 0.45681,
            "f1_weighted": 0.891081,
            "precision": 0.504844,
            "precision_weighted": 0.996907,
            "recall": 0.803759,
            "recall_weighted": 0.8075,
            "ap": 0.999018,
            "ap_weighted": 0.999018
          },
          {
            "accuracy": 0.788,
            "f1": 0.449842,
            "f1_weighted": 0.879009,
            "precision": 0.504366,
            "precision_weighted": 0.996889,
            "recall": 0.793985,
            "recall_weighted": 0.788,
            "ap": 0.998969,
            "ap_weighted": 0.998969
          },
          {
            "accuracy": 0.621,
            "f1": 0.386807,
            "f1_weighted": 0.763865,
            "precision": 0.50117,
            "precision_weighted": 0.995902,
            "recall": 0.610526,
            "recall_weighted": 0.621,
            "ap": 0.998052,
            "ap_weighted": 0.998052
          },
          {
            "accuracy": 0.752,
            "f1": 0.438903,
            "f1_weighted": 0.855947,
            "precision": 0.50499,
            "precision_weighted": 0.997525,
            "recall": 0.875689,
            "recall_weighted": 0.752,
            "ap": 0.999378,
            "ap_weighted": 0.999378
          }
        ],
        "accuracy": 0.7817,
        "f1": 0.445076,
        "f1_weighted": 0.873302,
        "precision": 0.503074,
        "precision_weighted": 0.996224,
        "recall": 0.691078,
        "recall_weighted": 0.7817,
        "ap": 0.998455,
        "ap_weighted": 0.998455,
        "main_score": 0.7817,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 62.82807993888855,
  "kg_co2_emissions": null
}