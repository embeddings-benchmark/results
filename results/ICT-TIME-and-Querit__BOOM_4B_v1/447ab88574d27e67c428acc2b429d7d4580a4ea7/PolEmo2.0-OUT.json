{
  "dataset_revision": "6a21ab8716e255ab1867265f8b396105e8aa63d4",
  "task_name": "PolEmo2.0-OUT",
  "mteb_version": "2.7.22",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.663968,
            "f1": 0.506329,
            "f1_weighted": 0.667794,
            "precision": 0.595387,
            "precision_weighted": 0.786264,
            "recall": 0.742297,
            "recall_weighted": 0.663968,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.708502,
            "f1": 0.548282,
            "f1_weighted": 0.719381,
            "precision": 0.608228,
            "precision_weighted": 0.802642,
            "recall": 0.779319,
            "recall_weighted": 0.708502,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.67004,
            "f1": 0.497118,
            "f1_weighted": 0.652939,
            "precision": 0.566353,
            "precision_weighted": 0.749761,
            "recall": 0.749963,
            "recall_weighted": 0.67004,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.688259,
            "f1": 0.541291,
            "f1_weighted": 0.722706,
            "precision": 0.617044,
            "precision_weighted": 0.818753,
            "recall": 0.512329,
            "recall_weighted": 0.688259,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.694332,
            "f1": 0.543287,
            "f1_weighted": 0.714118,
            "precision": 0.597208,
            "precision_weighted": 0.786122,
            "recall": 0.765515,
            "recall_weighted": 0.694332,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.6417,
            "f1": 0.497088,
            "f1_weighted": 0.658284,
            "precision": 0.60122,
            "precision_weighted": 0.797711,
            "recall": 0.727117,
            "recall_weighted": 0.6417,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.753036,
            "f1": 0.586398,
            "f1_weighted": 0.763839,
            "precision": 0.614479,
            "precision_weighted": 0.808159,
            "recall": 0.812796,
            "recall_weighted": 0.753036,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.710526,
            "f1": 0.554368,
            "f1_weighted": 0.728511,
            "precision": 0.624692,
            "precision_weighted": 0.824928,
            "recall": 0.781167,
            "recall_weighted": 0.710526,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.639676,
            "f1": 0.502137,
            "f1_weighted": 0.66468,
            "precision": 0.62297,
            "precision_weighted": 0.822772,
            "recall": 0.723649,
            "recall_weighted": 0.639676,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.696356,
            "f1": 0.527914,
            "f1_weighted": 0.691828,
            "precision": 0.608731,
            "precision_weighted": 0.800904,
            "recall": 0.7683,
            "recall_weighted": 0.696356,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.68664,
        "f1": 0.530421,
        "f1_weighted": 0.698408,
        "precision": 0.605631,
        "precision_weighted": 0.799802,
        "recall": 0.736245,
        "recall_weighted": 0.68664,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.68664,
        "hf_subset": "default",
        "languages": [
          "pol-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.061748504638672,
  "kg_co2_emissions": null
}