{
  "dataset_revision": "84af4753ebb04ca836fb54ce89a339839b03b748",
  "task_name": "PoemSentimentClassification",
  "mteb_version": "2.7.22",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.647619,
            "f1": 0.496593,
            "f1_weighted": 0.686049,
            "precision": 0.500514,
            "precision_weighted": 0.753995,
            "recall": 0.509759,
            "recall_weighted": 0.647619,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.704762,
            "f1": 0.534838,
            "f1_weighted": 0.740999,
            "precision": 0.538685,
            "precision_weighted": 0.826482,
            "recall": 0.567842,
            "recall_weighted": 0.704762,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.6,
            "f1": 0.481449,
            "f1_weighted": 0.658165,
            "precision": 0.503738,
            "precision_weighted": 0.765841,
            "recall": 0.482108,
            "recall_weighted": 0.6,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.666667,
            "f1": 0.524846,
            "f1_weighted": 0.71662,
            "precision": 0.54466,
            "precision_weighted": 0.809828,
            "recall": 0.53428,
            "recall_weighted": 0.666667,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.704762,
            "f1": 0.511842,
            "f1_weighted": 0.728288,
            "precision": 0.503318,
            "precision_weighted": 0.784833,
            "recall": 0.547225,
            "recall_weighted": 0.704762,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.771429,
            "f1": 0.577432,
            "f1_weighted": 0.796367,
            "precision": 0.573417,
            "precision_weighted": 0.845614,
            "recall": 0.602739,
            "recall_weighted": 0.771429,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.561905,
            "f1": 0.457835,
            "f1_weighted": 0.615549,
            "precision": 0.502358,
            "precision_weighted": 0.803083,
            "recall": 0.495973,
            "recall_weighted": 0.561905,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.72381,
            "f1": 0.511517,
            "f1_weighted": 0.736856,
            "precision": 0.521643,
            "precision_weighted": 0.763769,
            "recall": 0.518127,
            "recall_weighted": 0.72381,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.619048,
            "f1": 0.46377,
            "f1_weighted": 0.639609,
            "precision": 0.46982,
            "precision_weighted": 0.782257,
            "recall": 0.541672,
            "recall_weighted": 0.619048,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.580952,
            "f1": 0.464795,
            "f1_weighted": 0.634157,
            "precision": 0.499042,
            "precision_weighted": 0.828936,
            "recall": 0.506562,
            "recall_weighted": 0.580952,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.658095,
        "f1": 0.502492,
        "f1_weighted": 0.695266,
        "precision": 0.51572,
        "precision_weighted": 0.796464,
        "recall": 0.530629,
        "recall_weighted": 0.658095,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.658095,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.721154,
            "f1": 0.552539,
            "f1_weighted": 0.766181,
            "precision": 0.556878,
            "precision_weighted": 0.872609,
            "recall": 0.584918,
            "recall_weighted": 0.721154,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.701923,
            "f1": 0.543812,
            "f1_weighted": 0.745078,
            "precision": 0.547348,
            "precision_weighted": 0.854094,
            "recall": 0.580139,
            "recall_weighted": 0.701923,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.634615,
            "f1": 0.521234,
            "f1_weighted": 0.681583,
            "precision": 0.546584,
            "precision_weighted": 0.823382,
            "recall": 0.55231,
            "recall_weighted": 0.634615,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.682692,
            "f1": 0.554551,
            "f1_weighted": 0.749716,
            "precision": 0.578414,
            "precision_weighted": 0.872793,
            "recall": 0.556291,
            "recall_weighted": 0.682692,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.721154,
            "f1": 0.530044,
            "f1_weighted": 0.756392,
            "precision": 0.532224,
            "precision_weighted": 0.808368,
            "recall": 0.537245,
            "recall_weighted": 0.721154,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.740385,
            "f1": 0.549355,
            "f1_weighted": 0.771992,
            "precision": 0.542083,
            "precision_weighted": 0.843253,
            "recall": 0.585097,
            "recall_weighted": 0.740385,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.644231,
            "f1": 0.532115,
            "f1_weighted": 0.691924,
            "precision": 0.546792,
            "precision_weighted": 0.829477,
            "recall": 0.570402,
            "recall_weighted": 0.644231,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.730769,
            "f1": 0.553897,
            "f1_weighted": 0.770992,
            "precision": 0.601293,
            "precision_weighted": 0.85793,
            "recall": 0.555003,
            "recall_weighted": 0.730769,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.596154,
            "f1": 0.461011,
            "f1_weighted": 0.610826,
            "precision": 0.486224,
            "precision_weighted": 0.822198,
            "recall": 0.561821,
            "recall_weighted": 0.596154,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.586538,
            "f1": 0.4925,
            "f1_weighted": 0.629615,
            "precision": 0.522513,
            "precision_weighted": 0.831472,
            "recall": 0.548663,
            "recall_weighted": 0.586538,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.675962,
        "f1": 0.529106,
        "f1_weighted": 0.71743,
        "precision": 0.546036,
        "precision_weighted": 0.841558,
        "recall": 0.563189,
        "recall_weighted": 0.675962,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.675962,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 46.92606043815613,
  "kg_co2_emissions": null
}