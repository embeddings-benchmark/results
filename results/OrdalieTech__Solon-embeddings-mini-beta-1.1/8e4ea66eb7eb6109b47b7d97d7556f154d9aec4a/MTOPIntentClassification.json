{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "task_name": "MTOPIntentClassification",
  "mteb_version": "1.38.46",
  "scores": {
    "test": [
      {
        "accuracy": 0.503414,
        "f1": 0.33708,
        "f1_weighted": 0.523064,
        "scores_per_experiment": [
          {
            "accuracy": 0.505794,
            "f1": 0.357305,
            "f1_weighted": 0.517542
          },
          {
            "accuracy": 0.524585,
            "f1": 0.338077,
            "f1_weighted": 0.542998
          },
          {
            "accuracy": 0.537112,
            "f1": 0.329854,
            "f1_weighted": 0.563059
          },
          {
            "accuracy": 0.50047,
            "f1": 0.33194,
            "f1_weighted": 0.51535
          },
          {
            "accuracy": 0.512371,
            "f1": 0.342887,
            "f1_weighted": 0.547781
          },
          {
            "accuracy": 0.531475,
            "f1": 0.348883,
            "f1_weighted": 0.544395
          },
          {
            "accuracy": 0.49264,
            "f1": 0.33163,
            "f1_weighted": 0.510775
          },
          {
            "accuracy": 0.475102,
            "f1": 0.326633,
            "f1_weighted": 0.490012
          },
          {
            "accuracy": 0.470091,
            "f1": 0.32532,
            "f1_weighted": 0.487771
          },
          {
            "accuracy": 0.484497,
            "f1": 0.338269,
            "f1_weighted": 0.510962
          }
        ],
        "main_score": 0.503414,
        "hf_subset": "fr",
        "languages": [
          "fra-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 5.197575569152832,
  "kg_co2_emissions": null
}