{
  "dataset_revision": "3047317d2586abb183293f92b1b7d66d1c9ec81a",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "2.1.5",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.5075,
            "f1": 0.505569,
            "f1_weighted": 0.505569,
            "precision": 0.507619,
            "precision_weighted": 0.507619,
            "recall": 0.5075,
            "recall_weighted": 0.5075,
            "ap": 0.5038,
            "ap_weighted": 0.5038
          },
          {
            "accuracy": 0.488333,
            "f1": 0.462722,
            "f1_weighted": 0.462722,
            "precision": 0.485585,
            "precision_weighted": 0.485585,
            "recall": 0.488333,
            "recall_weighted": 0.488333,
            "ap": 0.494408,
            "ap_weighted": 0.494408
          },
          {
            "accuracy": 0.530833,
            "f1": 0.523686,
            "f1_weighted": 0.523686,
            "precision": 0.532802,
            "precision_weighted": 0.532802,
            "recall": 0.530833,
            "recall_weighted": 0.530833,
            "ap": 0.51618,
            "ap_weighted": 0.51618
          },
          {
            "accuracy": 0.5,
            "f1": 0.486864,
            "f1_weighted": 0.486864,
            "precision": 0.5,
            "precision_weighted": 0.5,
            "recall": 0.5,
            "recall_weighted": 0.5,
            "ap": 0.5,
            "ap_weighted": 0.5
          },
          {
            "accuracy": 0.550833,
            "f1": 0.548119,
            "f1_weighted": 0.548119,
            "precision": 0.552085,
            "precision_weighted": 0.552085,
            "recall": 0.550833,
            "recall_weighted": 0.550833,
            "ap": 0.528475,
            "ap_weighted": 0.528475
          },
          {
            "accuracy": 0.496667,
            "f1": 0.496352,
            "f1_weighted": 0.496352,
            "precision": 0.496658,
            "precision_weighted": 0.496658,
            "recall": 0.496667,
            "recall_weighted": 0.496667,
            "ap": 0.498344,
            "ap_weighted": 0.498344
          },
          {
            "accuracy": 0.4775,
            "f1": 0.46954,
            "f1_weighted": 0.46954,
            "precision": 0.476063,
            "precision_weighted": 0.476063,
            "recall": 0.4775,
            "recall_weighted": 0.4775,
            "ap": 0.489157,
            "ap_weighted": 0.489157
          },
          {
            "accuracy": 0.513333,
            "f1": 0.50965,
            "f1_weighted": 0.50965,
            "precision": 0.513746,
            "precision_weighted": 0.513746,
            "recall": 0.513333,
            "recall_weighted": 0.513333,
            "ap": 0.506818,
            "ap_weighted": 0.506818
          },
          {
            "accuracy": 0.501667,
            "f1": 0.491944,
            "f1_weighted": 0.491944,
            "precision": 0.501805,
            "precision_weighted": 0.501805,
            "recall": 0.501667,
            "recall_weighted": 0.501667,
            "ap": 0.500836,
            "ap_weighted": 0.500836
          },
          {
            "accuracy": 0.524167,
            "f1": 0.518777,
            "f1_weighted": 0.518777,
            "precision": 0.5253,
            "precision_weighted": 0.5253,
            "recall": 0.524167,
            "recall_weighted": 0.524167,
            "ap": 0.512824,
            "ap_weighted": 0.512824
          }
        ],
        "accuracy": 0.509083,
        "f1": 0.501322,
        "f1_weighted": 0.501322,
        "precision": 0.509166,
        "precision_weighted": 0.509166,
        "recall": 0.509083,
        "recall_weighted": 0.509083,
        "ap": 0.505084,
        "ap_weighted": 0.505084,
        "main_score": 0.509083,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.505,
            "f1": 0.503405,
            "f1_weighted": 0.503405,
            "precision": 0.505065,
            "precision_weighted": 0.505065,
            "recall": 0.505,
            "recall_weighted": 0.505,
            "ap": 0.502522,
            "ap_weighted": 0.502522
          },
          {
            "accuracy": 0.4475,
            "f1": 0.420505,
            "f1_weighted": 0.420505,
            "precision": 0.435477,
            "precision_weighted": 0.435477,
            "recall": 0.4475,
            "recall_weighted": 0.4475,
            "ap": 0.4786,
            "ap_weighted": 0.4786
          },
          {
            "accuracy": 0.516667,
            "f1": 0.510378,
            "f1_weighted": 0.510378,
            "precision": 0.517569,
            "precision_weighted": 0.517569,
            "recall": 0.516667,
            "recall_weighted": 0.516667,
            "ap": 0.50856,
            "ap_weighted": 0.50856
          },
          {
            "accuracy": 0.520833,
            "f1": 0.508379,
            "f1_weighted": 0.508379,
            "precision": 0.523183,
            "precision_weighted": 0.523183,
            "recall": 0.520833,
            "recall_weighted": 0.520833,
            "ap": 0.510746,
            "ap_weighted": 0.510746
          },
          {
            "accuracy": 0.529167,
            "f1": 0.524954,
            "f1_weighted": 0.524954,
            "precision": 0.530239,
            "precision_weighted": 0.530239,
            "recall": 0.529167,
            "recall_weighted": 0.529167,
            "ap": 0.515631,
            "ap_weighted": 0.515631
          },
          {
            "accuracy": 0.489167,
            "f1": 0.48878,
            "f1_weighted": 0.48878,
            "precision": 0.489134,
            "precision_weighted": 0.489134,
            "recall": 0.489167,
            "recall_weighted": 0.489167,
            "ap": 0.494695,
            "ap_weighted": 0.494695
          },
          {
            "accuracy": 0.486667,
            "f1": 0.480185,
            "f1_weighted": 0.480185,
            "precision": 0.485967,
            "precision_weighted": 0.485967,
            "recall": 0.486667,
            "recall_weighted": 0.486667,
            "ap": 0.493479,
            "ap_weighted": 0.493479
          },
          {
            "accuracy": 0.518333,
            "f1": 0.514545,
            "f1_weighted": 0.514545,
            "precision": 0.518924,
            "precision_weighted": 0.518924,
            "recall": 0.518333,
            "recall_weighted": 0.518333,
            "ap": 0.509452,
            "ap_weighted": 0.509452
          },
          {
            "accuracy": 0.485833,
            "f1": 0.469429,
            "f1_weighted": 0.469429,
            "precision": 0.483834,
            "precision_weighted": 0.483834,
            "recall": 0.485833,
            "recall_weighted": 0.485833,
            "ap": 0.493065,
            "ap_weighted": 0.493065
          },
          {
            "accuracy": 0.526667,
            "f1": 0.5181,
            "f1_weighted": 0.5181,
            "precision": 0.528708,
            "precision_weighted": 0.528708,
            "recall": 0.526667,
            "recall_weighted": 0.526667,
            "ap": 0.514303,
            "ap_weighted": 0.514303
          }
        ],
        "accuracy": 0.502583,
        "f1": 0.493866,
        "f1_weighted": 0.493866,
        "precision": 0.50181,
        "precision_weighted": 0.50181,
        "recall": 0.502583,
        "recall_weighted": 0.502583,
        "ap": 0.502105,
        "ap_weighted": 0.502105,
        "main_score": 0.502583,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.326910018920898,
  "kg_co2_emissions": null
}