{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.34.26",
  "scores": {
    "validation": [
      {
        "precision": 0.54517,
        "recall": 0.622869,
        "f1": 0.564644,
        "accuracy": 0.622869,
        "main_score": 0.564644,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.650351,
        "recall": 0.730191,
        "f1": 0.674046,
        "accuracy": 0.730191,
        "main_score": 0.674046,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.690549,
        "recall": 0.771314,
        "f1": 0.71398,
        "accuracy": 0.771314,
        "main_score": 0.71398,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.793581,
        "recall": 0.853561,
        "f1": 0.812604,
        "accuracy": 0.853561,
        "main_score": 0.812604,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.969241,
        "recall": 0.978937,
        "f1": 0.972417,
        "accuracy": 0.978937,
        "main_score": 0.972417,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.962387,
        "recall": 0.974925,
        "f1": 0.966566,
        "accuracy": 0.974925,
        "main_score": 0.966566,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.163702,
        "recall": 0.19659,
        "f1": 0.16967,
        "accuracy": 0.19659,
        "main_score": 0.16967,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.310159,
        "recall": 0.409228,
        "f1": 0.337048,
        "accuracy": 0.409228,
        "main_score": 0.337048,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.189015,
        "recall": 0.234704,
        "f1": 0.197398,
        "accuracy": 0.234704,
        "main_score": 0.197398,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.28099,
        "recall": 0.381143,
        "f1": 0.308056,
        "accuracy": 0.381143,
        "main_score": 0.308056,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.899866,
        "recall": 0.928786,
        "f1": 0.908659,
        "accuracy": 0.928786,
        "main_score": 0.908659,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.924774,
        "recall": 0.948847,
        "f1": 0.932798,
        "accuracy": 0.948847,
        "main_score": 0.932798,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.411335,
        "recall": 0.468405,
        "f1": 0.423546,
        "accuracy": 0.468405,
        "main_score": 0.423546,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.532949,
        "recall": 0.628887,
        "f1": 0.560454,
        "accuracy": 0.628887,
        "main_score": 0.560454,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.239661,
        "recall": 0.291876,
        "f1": 0.248857,
        "accuracy": 0.291876,
        "main_score": 0.248857,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.360576,
        "recall": 0.462387,
        "f1": 0.388249,
        "accuracy": 0.462387,
        "main_score": 0.388249,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.849274,
        "recall": 0.889669,
        "f1": 0.861367,
        "accuracy": 0.889669,
        "main_score": 0.861367,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.864928,
        "recall": 0.904714,
        "f1": 0.877633,
        "accuracy": 0.904714,
        "main_score": 0.877633,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.172785,
        "recall": 0.214644,
        "f1": 0.180161,
        "accuracy": 0.214644,
        "main_score": 0.180161,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.359723,
        "recall": 0.456369,
        "f1": 0.385213,
        "accuracy": 0.456369,
        "main_score": 0.385213,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.717887,
        "recall": 0.78335,
        "f1": 0.735776,
        "accuracy": 0.78335,
        "main_score": 0.735776,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.750763,
        "recall": 0.819458,
        "f1": 0.771782,
        "accuracy": 0.819458,
        "main_score": 0.771782,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.715233,
        "recall": 0.778335,
        "f1": 0.73308,
        "accuracy": 0.778335,
        "main_score": 0.73308,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.737138,
        "recall": 0.807422,
        "f1": 0.758726,
        "accuracy": 0.807422,
        "main_score": 0.758726,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.08668,
        "recall": 0.095286,
        "f1": 0.08847,
        "accuracy": 0.095286,
        "main_score": 0.08847,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.088745,
        "recall": 0.167503,
        "f1": 0.102704,
        "accuracy": 0.167503,
        "main_score": 0.102704,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.217858,
        "recall": 0.267803,
        "f1": 0.22776,
        "accuracy": 0.267803,
        "main_score": 0.22776,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.381011,
        "recall": 0.481444,
        "f1": 0.409942,
        "accuracy": 0.481444,
        "main_score": 0.409942,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.423237,
        "recall": 0.494483,
        "f1": 0.440351,
        "accuracy": 0.494483,
        "main_score": 0.440351,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.419153,
        "recall": 0.529589,
        "f1": 0.449831,
        "accuracy": 0.529589,
        "main_score": 0.449831,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.428063,
        "recall": 0.488465,
        "f1": 0.442375,
        "accuracy": 0.488465,
        "main_score": 0.442375,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.558175,
        "recall": 0.656971,
        "f1": 0.585953,
        "accuracy": 0.656971,
        "main_score": 0.585953,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.898863,
        "recall": 0.927783,
        "f1": 0.907857,
        "accuracy": 0.927783,
        "main_score": 0.907857,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.907389,
        "recall": 0.935807,
        "f1": 0.916583,
        "accuracy": 0.935807,
        "main_score": 0.916583,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.899281,
        "recall": 0.927783,
        "f1": 0.908077,
        "accuracy": 0.927783,
        "main_score": 0.908077,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.876212,
        "recall": 0.913741,
        "f1": 0.888064,
        "accuracy": 0.913741,
        "main_score": 0.888064,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.001056,
        "recall": 0.004012,
        "f1": 0.001106,
        "accuracy": 0.004012,
        "main_score": 0.001106,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028521,
        "recall": 0.055165,
        "f1": 0.034,
        "accuracy": 0.055165,
        "main_score": 0.034,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.101542,
        "recall": 0.1334,
        "f1": 0.106348,
        "accuracy": 0.1334,
        "main_score": 0.106348,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.145432,
        "recall": 0.221665,
        "f1": 0.163889,
        "accuracy": 0.221665,
        "main_score": 0.163889,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.850561,
        "recall": 0.890672,
        "f1": 0.862471,
        "accuracy": 0.890672,
        "main_score": 0.862471,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.883484,
        "recall": 0.91675,
        "f1": 0.894183,
        "accuracy": 0.91675,
        "main_score": 0.894183,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.571282,
        "recall": 0.644935,
        "f1": 0.591169,
        "accuracy": 0.644935,
        "main_score": 0.591169,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.62169,
        "recall": 0.709127,
        "f1": 0.647867,
        "accuracy": 0.709127,
        "main_score": 0.647867,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.872284,
        "recall": 0.910732,
        "f1": 0.884621,
        "accuracy": 0.910732,
        "main_score": 0.884621,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.859244,
        "recall": 0.899699,
        "f1": 0.871749,
        "accuracy": 0.899699,
        "main_score": 0.871749,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.815538,
        "recall": 0.862588,
        "f1": 0.829445,
        "accuracy": 0.862588,
        "main_score": 0.829445,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.824891,
        "recall": 0.875627,
        "f1": 0.840923,
        "accuracy": 0.875627,
        "main_score": 0.840923,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.865716,
        "recall": 0.898696,
        "f1": 0.875111,
        "accuracy": 0.898696,
        "main_score": 0.875111,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.883651,
        "recall": 0.917753,
        "f1": 0.89445,
        "accuracy": 0.917753,
        "main_score": 0.89445,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.084531,
        "recall": 0.105316,
        "f1": 0.087603,
        "accuracy": 0.105316,
        "main_score": 0.087603,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.14326,
        "recall": 0.227683,
        "f1": 0.161772,
        "accuracy": 0.227683,
        "main_score": 0.161772,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.885133,
        "recall": 0.91675,
        "f1": 0.894851,
        "accuracy": 0.91675,
        "main_score": 0.894851,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.880174,
        "recall": 0.915747,
        "f1": 0.891508,
        "accuracy": 0.915747,
        "main_score": 0.891508,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.894357,
        "recall": 0.922768,
        "f1": 0.903276,
        "accuracy": 0.922768,
        "main_score": 0.903276,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.872818,
        "recall": 0.909729,
        "f1": 0.884621,
        "accuracy": 0.909729,
        "main_score": 0.884621,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.003025,
        "recall": 0.005015,
        "f1": 0.00304,
        "accuracy": 0.005015,
        "main_score": 0.00304,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002599,
        "recall": 0.02006,
        "f1": 0.003671,
        "accuracy": 0.02006,
        "main_score": 0.003671,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.485715,
        "recall": 0.546443,
        "f1": 0.501075,
        "accuracy": 0.546443,
        "main_score": 0.501075,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.645844,
        "recall": 0.730237,
        "f1": 0.671311,
        "accuracy": 0.730237,
        "main_score": 0.671311,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.681383,
        "recall": 0.75,
        "f1": 0.700391,
        "accuracy": 0.75,
        "main_score": 0.700391,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.770043,
        "recall": 0.832016,
        "f1": 0.789163,
        "accuracy": 0.832016,
        "main_score": 0.789163,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.964427,
        "recall": 0.976285,
        "f1": 0.968379,
        "accuracy": 0.976285,
        "main_score": 0.968379,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.973979,
        "recall": 0.982213,
        "f1": 0.976614,
        "accuracy": 0.982213,
        "main_score": 0.976614,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.098178,
        "recall": 0.117589,
        "f1": 0.101102,
        "accuracy": 0.117589,
        "main_score": 0.101102,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.300884,
        "recall": 0.402174,
        "f1": 0.32988,
        "accuracy": 0.402174,
        "main_score": 0.32988,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.154589,
        "recall": 0.190711,
        "f1": 0.161523,
        "accuracy": 0.190711,
        "main_score": 0.161523,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.278477,
        "recall": 0.378458,
        "f1": 0.305276,
        "accuracy": 0.378458,
        "main_score": 0.305276,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.899237,
        "recall": 0.927866,
        "f1": 0.908202,
        "accuracy": 0.927866,
        "main_score": 0.908202,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.919796,
        "recall": 0.945652,
        "f1": 0.92836,
        "accuracy": 0.945652,
        "main_score": 0.92836,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.368657,
        "recall": 0.421937,
        "f1": 0.379691,
        "accuracy": 0.421937,
        "main_score": 0.379691,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.595833,
        "recall": 0.687747,
        "f1": 0.622925,
        "accuracy": 0.687747,
        "main_score": 0.622925,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.172337,
        "recall": 0.19664,
        "f1": 0.17723,
        "accuracy": 0.19664,
        "main_score": 0.17723,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.340553,
        "recall": 0.437747,
        "f1": 0.366852,
        "accuracy": 0.437747,
        "main_score": 0.366852,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.855814,
        "recall": 0.897233,
        "f1": 0.868939,
        "accuracy": 0.897233,
        "main_score": 0.868939,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.852026,
        "recall": 0.893281,
        "f1": 0.864657,
        "accuracy": 0.893281,
        "main_score": 0.864657,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.129315,
        "recall": 0.152174,
        "f1": 0.133083,
        "accuracy": 0.152174,
        "main_score": 0.133083,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.320517,
        "recall": 0.424901,
        "f1": 0.348827,
        "accuracy": 0.424901,
        "main_score": 0.348827,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.722773,
        "recall": 0.771739,
        "f1": 0.737164,
        "accuracy": 0.771739,
        "main_score": 0.737164,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.753854,
        "recall": 0.820158,
        "f1": 0.774097,
        "accuracy": 0.820158,
        "main_score": 0.774097,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.691132,
        "recall": 0.729249,
        "f1": 0.701929,
        "accuracy": 0.729249,
        "main_score": 0.701929,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.768923,
        "recall": 0.831028,
        "f1": 0.788406,
        "accuracy": 0.831028,
        "main_score": 0.788406,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.077916,
        "recall": 0.082016,
        "f1": 0.07864,
        "accuracy": 0.082016,
        "main_score": 0.07864,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.085662,
        "recall": 0.162055,
        "f1": 0.098926,
        "accuracy": 0.162055,
        "main_score": 0.098926,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.183111,
        "recall": 0.219368,
        "f1": 0.190111,
        "accuracy": 0.219368,
        "main_score": 0.190111,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.372863,
        "recall": 0.477273,
        "f1": 0.401692,
        "accuracy": 0.477273,
        "main_score": 0.401692,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.385503,
        "recall": 0.454545,
        "f1": 0.402723,
        "accuracy": 0.454545,
        "main_score": 0.402723,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.427779,
        "recall": 0.537549,
        "f1": 0.458439,
        "accuracy": 0.537549,
        "main_score": 0.458439,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.392344,
        "recall": 0.433794,
        "f1": 0.402429,
        "accuracy": 0.433794,
        "main_score": 0.402429,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.555498,
        "recall": 0.653162,
        "f1": 0.582375,
        "accuracy": 0.653162,
        "main_score": 0.582375,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.872157,
        "recall": 0.903162,
        "f1": 0.88173,
        "accuracy": 0.903162,
        "main_score": 0.88173,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.891551,
        "recall": 0.923913,
        "f1": 0.90191,
        "accuracy": 0.923913,
        "main_score": 0.90191,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.88772,
        "recall": 0.909091,
        "f1": 0.894065,
        "accuracy": 0.909091,
        "main_score": 0.894065,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.901021,
        "recall": 0.931818,
        "f1": 0.911067,
        "accuracy": 0.931818,
        "main_score": 0.911067,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.000988,
        "f1": 5e-06,
        "accuracy": 0.000988,
        "main_score": 5e-06,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023172,
        "recall": 0.046443,
        "f1": 0.027299,
        "accuracy": 0.046443,
        "main_score": 0.027299,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.074986,
        "recall": 0.08498,
        "f1": 0.076327,
        "accuracy": 0.08498,
        "main_score": 0.076327,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.13702,
        "recall": 0.203557,
        "f1": 0.152323,
        "accuracy": 0.203557,
        "main_score": 0.152323,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.828931,
        "recall": 0.858696,
        "f1": 0.837434,
        "accuracy": 0.858696,
        "main_score": 0.837434,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.87887,
        "recall": 0.916008,
        "f1": 0.890876,
        "accuracy": 0.916008,
        "main_score": 0.890876,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.559703,
        "recall": 0.613636,
        "f1": 0.574202,
        "accuracy": 0.613636,
        "main_score": 0.574202,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.64986,
        "recall": 0.733202,
        "f1": 0.67481,
        "accuracy": 0.733202,
        "main_score": 0.67481,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.882927,
        "recall": 0.912055,
        "f1": 0.891917,
        "accuracy": 0.912055,
        "main_score": 0.891917,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.893445,
        "recall": 0.924901,
        "f1": 0.903458,
        "accuracy": 0.924901,
        "main_score": 0.903458,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.782213,
        "recall": 0.817194,
        "f1": 0.79192,
        "accuracy": 0.817194,
        "main_score": 0.79192,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.832543,
        "recall": 0.878458,
        "f1": 0.846429,
        "accuracy": 0.878458,
        "main_score": 0.846429,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.81717,
        "recall": 0.842885,
        "f1": 0.824322,
        "accuracy": 0.842885,
        "main_score": 0.824322,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.884717,
        "recall": 0.918972,
        "f1": 0.895553,
        "accuracy": 0.918972,
        "main_score": 0.895553,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.050928,
        "recall": 0.062253,
        "f1": 0.052481,
        "accuracy": 0.062253,
        "main_score": 0.052481,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.128189,
        "recall": 0.211462,
        "f1": 0.145986,
        "accuracy": 0.211462,
        "main_score": 0.145986,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.867844,
        "recall": 0.896245,
        "f1": 0.876198,
        "accuracy": 0.896245,
        "main_score": 0.876198,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.899045,
        "recall": 0.93083,
        "f1": 0.909256,
        "accuracy": 0.93083,
        "main_score": 0.909256,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.877909,
        "recall": 0.906126,
        "f1": 0.886248,
        "accuracy": 0.906126,
        "main_score": 0.886248,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.882082,
        "recall": 0.916008,
        "f1": 0.893083,
        "accuracy": 0.916008,
        "main_score": 0.893083,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.004942,
        "recall": 0.005929,
        "f1": 0.004943,
        "accuracy": 0.005929,
        "main_score": 0.004943,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003176,
        "recall": 0.02668,
        "f1": 0.004734,
        "accuracy": 0.02668,
        "main_score": 0.004734,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 21.69639492034912,
  "kg_co2_emissions": null
}