{
  "dataset_revision": "78cfd586d70d2753fe7080a29dfbc5c278b1d54d",
  "task_name": "WRIMEClassification",
  "mteb_version": "2.2.0",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.257812,
            "f1": 0.232549,
            "f1_weighted": 0.267004,
            "precision": 0.238093,
            "precision_weighted": 0.290556,
            "recall": 0.256358,
            "recall_weighted": 0.257812,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.250488,
            "f1": 0.23595,
            "f1_weighted": 0.263928,
            "precision": 0.25848,
            "precision_weighted": 0.322735,
            "recall": 0.273033,
            "recall_weighted": 0.250488,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.204102,
            "f1": 0.203933,
            "f1_weighted": 0.211021,
            "precision": 0.253744,
            "precision_weighted": 0.312368,
            "recall": 0.284976,
            "recall_weighted": 0.204102,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.244141,
            "f1": 0.200426,
            "f1_weighted": 0.230232,
            "precision": 0.218537,
            "precision_weighted": 0.259884,
            "recall": 0.221625,
            "recall_weighted": 0.244141,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.250977,
            "f1": 0.204225,
            "f1_weighted": 0.250539,
            "precision": 0.248115,
            "precision_weighted": 0.307752,
            "recall": 0.235408,
            "recall_weighted": 0.250977,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.262207,
            "f1": 0.231531,
            "f1_weighted": 0.277807,
            "precision": 0.244114,
            "precision_weighted": 0.309525,
            "recall": 0.254297,
            "recall_weighted": 0.262207,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.227539,
            "f1": 0.222792,
            "f1_weighted": 0.239097,
            "precision": 0.249539,
            "precision_weighted": 0.304432,
            "recall": 0.275681,
            "recall_weighted": 0.227539,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.20166,
            "f1": 0.192663,
            "f1_weighted": 0.19745,
            "precision": 0.246236,
            "precision_weighted": 0.305881,
            "recall": 0.272263,
            "recall_weighted": 0.20166,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.208984,
            "f1": 0.198188,
            "f1_weighted": 0.218806,
            "precision": 0.243885,
            "precision_weighted": 0.303083,
            "recall": 0.249454,
            "recall_weighted": 0.208984,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.201172,
            "f1": 0.195071,
            "f1_weighted": 0.206462,
            "precision": 0.235089,
            "precision_weighted": 0.289141,
            "recall": 0.25523,
            "recall_weighted": 0.201172,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.230908,
        "f1": 0.211733,
        "f1_weighted": 0.236235,
        "precision": 0.243583,
        "precision_weighted": 0.300536,
        "recall": 0.257832,
        "recall_weighted": 0.230908,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.230908,
        "hf_subset": "default",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ]
  },
  "evaluation_time": 6.930802345275879,
  "kg_co2_emissions": null
}