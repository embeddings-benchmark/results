{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "task_name": "ToxicConversationsClassification",
  "mteb_version": "1.34.26",
  "scores": {
    "test": [
      {
        "accuracy": 0.60083,
        "f1": 0.456917,
        "f1_weighted": 0.689016,
        "ap": 0.095257,
        "ap_weighted": 0.095257,
        "scores_per_experiment": [
          {
            "accuracy": 0.492676,
            "f1": 0.40478,
            "f1_weighted": 0.597324,
            "ap": 0.094107,
            "ap_weighted": 0.094107
          },
          {
            "accuracy": 0.570312,
            "f1": 0.44736,
            "f1_weighted": 0.666791,
            "ap": 0.09823,
            "ap_weighted": 0.09823
          },
          {
            "accuracy": 0.623535,
            "f1": 0.464939,
            "f1_weighted": 0.710159,
            "ap": 0.09208,
            "ap_weighted": 0.09208
          },
          {
            "accuracy": 0.643555,
            "f1": 0.48271,
            "f1_weighted": 0.725526,
            "ap": 0.100383,
            "ap_weighted": 0.100383
          },
          {
            "accuracy": 0.561523,
            "f1": 0.43936,
            "f1_weighted": 0.659663,
            "ap": 0.09419,
            "ap_weighted": 0.09419
          },
          {
            "accuracy": 0.492676,
            "f1": 0.403198,
            "f1_weighted": 0.597725,
            "ap": 0.092241,
            "ap_weighted": 0.092241
          },
          {
            "accuracy": 0.696777,
            "f1": 0.506834,
            "f1_weighted": 0.764476,
            "ap": 0.102082,
            "ap_weighted": 0.102082
          },
          {
            "accuracy": 0.566406,
            "f1": 0.436269,
            "f1_weighted": 0.664274,
            "ap": 0.089129,
            "ap_weighted": 0.089129
          },
          {
            "accuracy": 0.706543,
            "f1": 0.503855,
            "f1_weighted": 0.770802,
            "ap": 0.096344,
            "ap_weighted": 0.096344
          },
          {
            "accuracy": 0.654297,
            "f1": 0.479865,
            "f1_weighted": 0.733424,
            "ap": 0.093788,
            "ap_weighted": 0.093788
          }
        ],
        "main_score": 0.60083,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 1.1552681922912598,
  "kg_co2_emissions": null
}