{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.544073,
            "f1": 0.458169,
            "f1_weighted": 0.620141,
            "precision": 0.527015,
            "precision_weighted": 0.80791,
            "recall": 0.56178,
            "recall_weighted": 0.544073,
            "ap": 0.889256,
            "ap_weighted": 0.889256
          },
          {
            "accuracy": 0.474164,
            "f1": 0.402415,
            "f1_weighted": 0.557872,
            "precision": 0.495829,
            "precision_weighted": 0.777468,
            "recall": 0.490473,
            "recall_weighted": 0.474164,
            "ap": 0.873312,
            "ap_weighted": 0.873312
          },
          {
            "accuracy": 0.531915,
            "f1": 0.433722,
            "f1_weighted": 0.610756,
            "precision": 0.501116,
            "precision_weighted": 0.782868,
            "recall": 0.502541,
            "recall_weighted": 0.531915,
            "ap": 0.875935,
            "ap_weighted": 0.875935
          },
          {
            "accuracy": 0.367781,
            "f1": 0.340427,
            "f1_weighted": 0.441269,
            "precision": 0.496271,
            "precision_weighted": 0.77713,
            "recall": 0.492463,
            "recall_weighted": 0.367781,
            "ap": 0.873745,
            "ap_weighted": 0.873745
          },
          {
            "accuracy": 0.340426,
            "f1": 0.327274,
            "f1_weighted": 0.39789,
            "precision": 0.522205,
            "precision_weighted": 0.811879,
            "recall": 0.539592,
            "recall_weighted": 0.340426,
            "ap": 0.88434,
            "ap_weighted": 0.88434
          },
          {
            "accuracy": 0.398176,
            "f1": 0.3633,
            "f1_weighted": 0.475175,
            "precision": 0.504659,
            "precision_weighted": 0.787468,
            "recall": 0.509824,
            "recall_weighted": 0.398176,
            "ap": 0.877538,
            "ap_weighted": 0.877538
          },
          {
            "accuracy": 0.677812,
            "f1": 0.503333,
            "f1_weighted": 0.724339,
            "precision": 0.518065,
            "precision_weighted": 0.793991,
            "recall": 0.533579,
            "recall_weighted": 0.677812,
            "ap": 0.882792,
            "ap_weighted": 0.882792
          },
          {
            "accuracy": 0.571429,
            "f1": 0.458964,
            "f1_weighted": 0.644156,
            "precision": 0.511249,
            "precision_weighted": 0.791709,
            "recall": 0.52511,
            "recall_weighted": 0.571429,
            "ap": 0.880918,
            "ap_weighted": 0.880918
          },
          {
            "accuracy": 0.361702,
            "f1": 0.338978,
            "f1_weighted": 0.430992,
            "precision": 0.505053,
            "precision_weighted": 0.788315,
            "recall": 0.509909,
            "recall_weighted": 0.361702,
            "ap": 0.877559,
            "ap_weighted": 0.877559
          },
          {
            "accuracy": 0.656535,
            "f1": 0.509803,
            "f1_weighted": 0.711152,
            "precision": 0.531297,
            "precision_weighted": 0.805047,
            "recall": 0.563262,
            "recall_weighted": 0.656535,
            "ap": 0.889506,
            "ap_weighted": 0.889506
          }
        ],
        "accuracy": 0.492401,
        "f1": 0.413639,
        "f1_weighted": 0.561374,
        "precision": 0.511276,
        "precision_weighted": 0.792378,
        "recall": 0.522853,
        "recall_weighted": 0.492401,
        "ap": 0.88049,
        "ap_weighted": 0.88049,
        "main_score": 0.492401,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 6.3144073486328125,
  "kg_co2_emissions": null
}