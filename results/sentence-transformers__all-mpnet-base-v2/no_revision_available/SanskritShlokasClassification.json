{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "evaluation_time": 18.790501356124878,
  "kg_co2_emissions": 0.0005049086129727159,
  "mteb_version": "1.12.41",
  "scores": {
    "train": [
      {
        "accuracy": 0.6783289817232376,
        "f1": 0.6690202303372802,
        "f1_weighted": 0.669289214164592,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ],
        "main_score": 0.6783289817232376,
        "scores_per_experiment": [
          {
            "accuracy": 0.660574412532637,
            "f1": 0.6543304739637366,
            "f1_weighted": 0.6562355002199488
          },
          {
            "accuracy": 0.7232375979112271,
            "f1": 0.7043054063730755,
            "f1_weighted": 0.7089579132463759
          },
          {
            "accuracy": 0.6945169712793734,
            "f1": 0.6877515300671485,
            "f1_weighted": 0.688873973626783
          },
          {
            "accuracy": 0.660574412532637,
            "f1": 0.6386096421831979,
            "f1_weighted": 0.6331666201794355
          },
          {
            "accuracy": 0.7232375979112271,
            "f1": 0.7191392084125647,
            "f1_weighted": 0.7211276469310386
          },
          {
            "accuracy": 0.6579634464751958,
            "f1": 0.6553979156275852,
            "f1_weighted": 0.6548709705362162
          },
          {
            "accuracy": 0.6919060052219321,
            "f1": 0.6870276188458005,
            "f1_weighted": 0.6873863338971338
          },
          {
            "accuracy": 0.6318537859007833,
            "f1": 0.6163686716778843,
            "f1_weighted": 0.6106088899169808
          },
          {
            "accuracy": 0.6788511749347258,
            "f1": 0.6720076915262245,
            "f1_weighted": 0.6748659356144079
          },
          {
            "accuracy": 0.660574412532637,
            "f1": 0.6552641446955839,
            "f1_weighted": 0.6567983574775987
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.6541666666666667,
        "f1": 0.6564219948573211,
        "f1_weighted": 0.6468484586808269,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ],
        "main_score": 0.6541666666666667,
        "scores_per_experiment": [
          {
            "accuracy": 0.6875,
            "f1": 0.6852801519468187,
            "f1_weighted": 0.6827932098765431
          },
          {
            "accuracy": 0.7083333333333334,
            "f1": 0.7088446526151445,
            "f1_weighted": 0.7034767759562842
          },
          {
            "accuracy": 0.625,
            "f1": 0.6241125918545274,
            "f1_weighted": 0.6174440569601859
          },
          {
            "accuracy": 0.5729166666666666,
            "f1": 0.57119021134594,
            "f1_weighted": 0.5447603819058213
          },
          {
            "accuracy": 0.7604166666666666,
            "f1": 0.760303893637227,
            "f1_weighted": 0.7572530864197531
          },
          {
            "accuracy": 0.5520833333333334,
            "f1": 0.5675132863675688,
            "f1_weighted": 0.5540154569892474
          },
          {
            "accuracy": 0.6979166666666666,
            "f1": 0.703494512559122,
            "f1_weighted": 0.6928640308582449
          },
          {
            "accuracy": 0.6458333333333334,
            "f1": 0.6518518518518518,
            "f1_weighted": 0.6335648148148149
          },
          {
            "accuracy": 0.71875,
            "f1": 0.7120867208672088,
            "f1_weighted": 0.7110501355013551
          },
          {
            "accuracy": 0.5729166666666666,
            "f1": 0.5795420755278026,
            "f1_weighted": 0.5712626375260185
          }
        ]
      }
    ]
  },
  "task_name": "SanskritShlokasClassification"
}