{
  "dataset_revision": "f8f98e5c4d3059cf1a00c8eb3d70aa271423f636",
  "evaluation_time": 6.483675479888916,
  "kg_co2_emissions": 0.00017280421019455272,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.5462564102564104,
        "ap": 0.8412472735799472,
        "ap_weighted": 0.8412472735799472,
        "f1": 0.4526084467039671,
        "f1_weighted": 0.6066366167149383,
        "hf_subset": "default",
        "languages": [
          "ita-Latn"
        ],
        "main_score": 0.5462564102564104,
        "scores_per_experiment": [
          {
            "accuracy": 0.5764102564102564,
            "ap": 0.8493116587026452,
            "ap_weighted": 0.8493116587026452,
            "f1": 0.47876552830205776,
            "f1_weighted": 0.6330997312598031
          },
          {
            "accuracy": 0.56,
            "ap": 0.840308037258587,
            "ap_weighted": 0.840308037258587,
            "f1": 0.4573840012765146,
            "f1_weighted": 0.6188105841740731
          },
          {
            "accuracy": 0.56,
            "ap": 0.8410057569984488,
            "ap_weighted": 0.8410057569984488,
            "f1": 0.45857242528228276,
            "f1_weighted": 0.6188856772650254
          },
          {
            "accuracy": 0.5620512820512821,
            "ap": 0.8378545965373876,
            "ap_weighted": 0.8378545965373876,
            "f1": 0.4538345387258304,
            "f1_weighted": 0.6201492110716282
          },
          {
            "accuracy": 0.558974358974359,
            "ap": 0.8443605967363957,
            "ap_weighted": 0.8443605967363957,
            "f1": 0.4636716711184796,
            "f1_weighted": 0.6183356438675587
          },
          {
            "accuracy": 0.5323076923076923,
            "ap": 0.8429461179740914,
            "ap_weighted": 0.8429461179740914,
            "f1": 0.45009004373552874,
            "f1_weighted": 0.5955520373632027
          },
          {
            "accuracy": 0.5035897435897436,
            "ap": 0.8433237320555644,
            "ap_weighted": 0.8433237320555644,
            "f1": 0.4371421755725191,
            "f1_weighted": 0.5694422587590526
          },
          {
            "accuracy": 0.5866666666666667,
            "ap": 0.8354739968381869,
            "ap_weighted": 0.8354739968381869,
            "f1": 0.45732263976609316,
            "f1_weighted": 0.6385673161162666
          },
          {
            "accuracy": 0.49641025641025643,
            "ap": 0.8393962258378476,
            "ap_weighted": 0.8393962258378476,
            "f1": 0.4285443144501384,
            "f1_weighted": 0.5632662885197774
          },
          {
            "accuracy": 0.5261538461538462,
            "ap": 0.8384920168603163,
            "ap_weighted": 0.8384920168603163,
            "f1": 0.44075712881022616,
            "f1_weighted": 0.590257418752994
          }
        ]
      }
    ]
  },
  "task_name": "Itacola"
}