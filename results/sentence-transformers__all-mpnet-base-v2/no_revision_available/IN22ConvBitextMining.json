{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "evaluation_time": 17.525331020355225,
  "kg_co2_emissions": 0.0007713896469112491,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007637002193948236,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0007637002193948236,
        "precision": 0.0007158014564254716,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007163080163301712,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0007163080163301712,
        "precision": 0.000691302396037525,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009007314651345738,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.0009007314651345738,
        "precision": 0.0007996401520261513,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.00242939193751634,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.00242939193751634,
        "precision": 0.0016836871037643805,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.020360703095234033,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.020360703095234033,
        "precision": 0.017135176214077234,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.057218895542248835,
        "f1": 0.03735769845943864,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.03735769845943864,
        "precision": 0.03210911406148163,
        "recall": 0.057218895542248835
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.014397172008714317,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.014397172008714317,
        "precision": 0.012130999569794318,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008708058908410085,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0008708058908410085,
        "precision": 0.0007760096272726185,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013318290954323238,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0013318290954323238,
        "precision": 0.001331251045920923,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.018629407850964737,
        "f1": 0.008740316347857437,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.008740316347857437,
        "precision": 0.006991536376094739,
        "recall": 0.018629407850964737
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.000700647397409738,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.000700647397409738,
        "precision": 0.0006832622671533086,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00010817446801094476,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.00010817446801094476,
        "precision": 5.5947790939683165e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013735968922370314,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.0013735968922370314,
        "precision": 0.0013528498558438677,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006995353316414498,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.0006995353316414498,
        "precision": 0.0006828080533610649,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.039254823685961414,
        "f1": 0.023686591001960258,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.023686591001960258,
        "precision": 0.019693177377808117,
        "recall": 0.039254823685961414
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006765880647304716,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.0006765880647304716,
        "precision": 0.0006709878801760611,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.013145402317059001,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.013145402317059001,
        "precision": 0.011203227553286057,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.577096803360626e-05,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 3.577096803360626e-05,
        "precision": 1.8258813609289126e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.000724107739326314,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.000724107739326314,
        "precision": 0.0006960370760681923,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0007838763960223107,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0007838763960223107,
        "precision": 0.0007262049562688346,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 0.0006653359946773121,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.0006653359946773121,
        "precision": 0.0006653359946773121,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.03260146373918829,
        "f1": 0.022474211817443163,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.022474211817443163,
        "precision": 0.019722459842220322,
        "recall": 0.03260146373918829
      },
      {
        "accuracy": 0.07784431137724551,
        "f1": 0.06221237274629682,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.06221237274629682,
        "precision": 0.05825830629644055,
        "recall": 0.07784431137724551
      },
      {
        "accuracy": 0.036593479707252165,
        "f1": 0.029527530684041188,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.029527530684041188,
        "precision": 0.028072147563202993,
        "recall": 0.036593479707252165
      },
      {
        "accuracy": 0.027944111776447105,
        "f1": 0.01990739674083143,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.01990739674083143,
        "precision": 0.018307644304566866,
        "recall": 0.027944111776447105
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.004227233010183239,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004227233010183239,
        "precision": 0.0035123107557628198,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.026409242650444455,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.026409242650444455,
        "precision": 0.02438715560666647,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0012657526562977243,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0012657526562977243,
        "precision": 0.0010435396670698662,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0028057991441085774,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0028057991441085774,
        "precision": 0.0025673732755912477,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.023804227463484224,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.023804227463484224,
        "precision": 0.021591124944362477,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.02752845395020627,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.02752845395020627,
        "precision": 0.026330088340783504,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.07052561543579508,
        "f1": 0.057406399322566984,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.057406399322566984,
        "precision": 0.05363741750967299,
        "recall": 0.07052561543579508
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0017357085524959067,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0017357085524959067,
        "precision": 0.001589674839666085,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.06387225548902195,
        "f1": 0.049810964869083915,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.049810964869083915,
        "precision": 0.046332025420906475,
        "recall": 0.06387225548902195
      },
      {
        "accuracy": 0.027278775781769793,
        "f1": 0.019922852707283844,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.019922852707283844,
        "precision": 0.01805957463064302,
        "recall": 0.027278775781769793
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.021847370621142056,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.021847370621142056,
        "precision": 0.019847715034716943,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.07850964737192283,
        "f1": 0.06395098211465476,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.06395098211465476,
        "precision": 0.059162489236551645,
        "recall": 0.07850964737192283
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0024152225645660617,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0024152225645660617,
        "precision": 0.0018183107404285861,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.02594810379241517,
        "f1": 0.01928792727195921,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.01928792727195921,
        "precision": 0.017585199970429514,
        "recall": 0.02594810379241517
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0027549776783194002,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0027549776783194002,
        "precision": 0.0024965908831821866,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.01849969675299053,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.01849969675299053,
        "precision": 0.016280167136577883,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.020048937778994903,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.020048937778994903,
        "precision": 0.017336560790510165,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.021956087824351298,
        "f1": 0.011805983991612735,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.011805983991612735,
        "precision": 0.00954681364688688,
        "recall": 0.021956087824351298
      },
      {
        "accuracy": 0.06121091151031271,
        "f1": 0.04400196577149113,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.04400196577149113,
        "precision": 0.03977792326011853,
        "recall": 0.06121091151031271
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.01928057928513158,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.01928057928513158,
        "precision": 0.017362575461869832,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.002002713868484291,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002002713868484291,
        "precision": 0.0015080569615521452,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.03792415169660679,
        "f1": 0.02776046837852305,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.02776046837852305,
        "precision": 0.02573701080264071,
        "recall": 0.03792415169660679
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0011968656963698729,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0011968656963698729,
        "precision": 0.0009985979004161693,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00179087291347255,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00179087291347255,
        "precision": 0.0016717036520036855,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0332667997338656,
        "f1": 0.02436374141879704,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.02436374141879704,
        "precision": 0.022510743626892194,
        "recall": 0.0332667997338656
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.02484120927202891,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.02484120927202891,
        "precision": 0.02354201147450922,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.20159680638722555,
        "f1": 0.1579761955195299,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.1579761955195299,
        "precision": 0.1445170505549747,
        "recall": 0.20159680638722555
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0010270541019287897,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0010270541019287897,
        "precision": 0.0008541544322748125,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.11377245508982035,
        "f1": 0.08996170933406859,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.08996170933406859,
        "precision": 0.08357079943612761,
        "recall": 0.11377245508982035
      },
      {
        "accuracy": 0.1317365269461078,
        "f1": 0.09358542775361312,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.09358542775361312,
        "precision": 0.08244683896507185,
        "recall": 0.1317365269461078
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.022675942590951282,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.022675942590951282,
        "precision": 0.020591383621406403,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.25482368596141053,
        "f1": 0.21020213061131224,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.21020213061131224,
        "precision": 0.19488492951566802,
        "recall": 0.25482368596141053
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0030278548242620093,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0030278548242620093,
        "precision": 0.002268478915185502,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.17365269461077845,
        "f1": 0.13003135697746476,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.13003135697746476,
        "precision": 0.11670811815522394,
        "recall": 0.17365269461077845
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0026833046707589073,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0026833046707589073,
        "precision": 0.0024669116785279717,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.05056553559547571,
        "f1": 0.02917443246720238,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.02917443246720238,
        "precision": 0.02489646878556094,
        "recall": 0.05056553559547571
      },
      {
        "accuracy": 0.09514304723885562,
        "f1": 0.06409017021540124,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06409017021540124,
        "precision": 0.05682294372120602,
        "recall": 0.09514304723885562
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.011975836370176872,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.011975836370176872,
        "precision": 0.009547643529679458,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.014590734029315882,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.014590734029315882,
        "precision": 0.013573133910111163,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0014280747276503337,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0014280747276503337,
        "precision": 0.0011183032589978368,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.023884516274735836,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.023884516274735836,
        "precision": 0.022665557759679437,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.000393526864531005,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.000393526864531005,
        "precision": 0.00025288224719862903,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00233656833789901,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.00233656833789901,
        "precision": 0.002221744780970802,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.09447771124417831,
        "f1": 0.06875124647379495,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.06875124647379495,
        "precision": 0.06227710424317211,
        "recall": 0.09447771124417831
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.025934011042637414,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.025934011042637414,
        "precision": 0.02460295333758933,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.028488999013467315,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.028488999013467315,
        "precision": 0.026685781875402634,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0002141017111076991,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0002141017111076991,
        "precision": 0.00011937068432253534,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.033932135728542916,
        "f1": 0.027816362946934313,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.027816362946934313,
        "precision": 0.026262936433758884,
        "recall": 0.033932135728542916
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0015246050452809405,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0015246050452809405,
        "precision": 0.0014331747336326413,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.018797325982954725,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.018797325982954725,
        "precision": 0.01732091372809936,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.028691836677709356,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.028691836677709356,
        "precision": 0.026308418459477765,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.00042916553033573894,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00042916553033573894,
        "precision": 0.00027128631970473933,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.0026049533505210385,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0026049533505210385,
        "precision": 0.00213530582498529,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0012189977466432991,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0012189977466432991,
        "precision": 0.000998940466078652,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.002442190424332267,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.002442190424332267,
        "precision": 0.0022618667784977163,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0026112012609605657,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0026112012609605657,
        "precision": 0.002181394786185205,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.008343883681815413,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.008343883681815413,
        "precision": 0.006742167838236571,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0020502996148298687,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0020502996148298687,
        "precision": 0.0013065421659507722,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.04058549567531603,
        "f1": 0.031851540478015125,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.031851540478015125,
        "precision": 0.029584881517794266,
        "recall": 0.04058549567531603
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.003235651416900858,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.003235651416900858,
        "precision": 0.0026397421607002444,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.003947269774828007,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.003947269774828007,
        "precision": 0.003708063558121507,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.00998003992015968,
        "f1": 0.008471944998891106,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.008471944998891106,
        "precision": 0.007950765136393879,
        "recall": 0.00998003992015968
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.022720252418133653,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.022720252418133653,
        "precision": 0.02189577120093446,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.01996007984031936,
        "f1": 0.014560734809367974,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.014560734809367974,
        "precision": 0.013552869840294992,
        "recall": 0.01996007984031936
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.020625415834996674,
        "f1": 0.01611282125905054,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.01611282125905054,
        "precision": 0.015404878747824284,
        "recall": 0.020625415834996674
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0009874431032115664,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.0009874431032115664,
        "precision": 0.0008475350411239112,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.025201380737676568,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.025201380737676568,
        "precision": 0.023661558846081468,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.010524208563292326,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.010524208563292326,
        "precision": 0.009494241220321983,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.00665335994677312,
        "f1": 0.003843899502582137,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.003843899502582137,
        "precision": 0.003378428328528129,
        "recall": 0.00665335994677312
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0014718500281854462,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.0014718500281854462,
        "precision": 0.0012142931118894287,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0011189741728663885,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0011189741728663885,
        "precision": 0.000925421883505716,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0027617604297577687,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.0027617604297577687,
        "precision": 0.0024617903739501657,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0010733644743322393,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.0010733644743322393,
        "precision": 0.0008957382428236591,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.015056467152275535,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.015056467152275535,
        "precision": 0.013285708443461072,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.028609447771124417,
        "f1": 0.017863299742944833,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.017863299742944833,
        "precision": 0.015522650275902388,
        "recall": 0.028609447771124417
      },
      {
        "accuracy": 0.04324683965402528,
        "f1": 0.0248778690187207,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0248778690187207,
        "precision": 0.02129978058593071,
        "recall": 0.04324683965402528
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008079232764912272,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0008079232764912272,
        "precision": 0.0007413170853616695,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006672842699179484,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0006672842699179484,
        "precision": 0.0006663115606519122,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.03526280771789754,
        "f1": 0.021394104587395425,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.021394104587395425,
        "precision": 0.01885308199741818,
        "recall": 0.03526280771789754
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0006717009582941679,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0006717009582941679,
        "precision": 0.0006685280123048804,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00030480954751630824,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.00030480954751630824,
        "precision": 0.00017703398781981195,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.000740230682093681,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.000740230682093681,
        "precision": 0.000704957991704066,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007362130426346821,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0007362130426346821,
        "precision": 0.0007025295475633303,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.01293768776384191,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.01293768776384191,
        "precision": 0.011290920825660461,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006760252714143795,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0006760252714143795,
        "precision": 0.0006706975001117645,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.047238855622089154,
        "f1": 0.034820854830834864,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.034820854830834864,
        "precision": 0.03181876800836066,
        "recall": 0.047238855622089154
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 4.608011231580015e-06,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 4.608011231580015e-06,
        "precision": 2.3084570207621488e-06,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0007043416080050002,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0007043416080050002,
        "precision": 0.0006853982730994634,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008367377991268518,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0008367377991268518,
        "precision": 0.0007629237168186853,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0008182011414982093,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0008182011414982093,
        "precision": 0.0007492954800880649,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.04524284763805722,
        "f1": 0.028671029315735327,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.028671029315735327,
        "precision": 0.02438151072824173,
        "recall": 0.04524284763805722
      },
      {
        "accuracy": 0.029940119760479042,
        "f1": 0.01591958999219398,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.01591958999219398,
        "precision": 0.013639655751610634,
        "recall": 0.029940119760479042
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.004740697195873812,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.004740697195873812,
        "precision": 0.004510899264256449,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.01128960889923617,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.01128960889923617,
        "precision": 0.010335423646554013,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.05322687957418496,
        "f1": 0.04115372360070063,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.04115372360070063,
        "precision": 0.038973872231608565,
        "recall": 0.05322687957418496
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.012058530871363922,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.012058530871363922,
        "precision": 0.01168622232418148,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0001043293479266091,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.0001043293479266091,
        "precision": 5.411795740330642e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.011119175789834472,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.011119175789834472,
        "precision": 0.010993516842284425,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.2642851198480865e-05,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 3.2642851198480865e-05,
        "precision": 1.6633235389429172e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.06919494344644045,
        "f1": 0.05078477330743981,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.05078477330743981,
        "precision": 0.04629097302746289,
        "recall": 0.06919494344644045
      },
      {
        "accuracy": 0.010645375914836993,
        "f1": 0.008659834926073917,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.008659834926073917,
        "precision": 0.008321955489678175,
        "recall": 0.010645375914836993
      },
      {
        "accuracy": 0.02262142381902861,
        "f1": 0.012739034376758844,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.012739034376758844,
        "precision": 0.010989421539859772,
        "recall": 0.02262142381902861
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.2842310968334106e-05,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 3.2842310968334106e-05,
        "precision": 1.6733218131861726e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0006653359946773121,
        "f1": 8.948702013144749e-07,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 8.948702013144749e-07,
        "precision": 4.4773620099415346e-07,
        "recall": 0.0006653359946773121
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 3.582675569826216e-05,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 3.582675569826216e-05,
        "precision": 1.8066052936333827e-05,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.05189620758483034,
        "f1": 0.036806358481429394,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.036806358481429394,
        "precision": 0.0327690211150876,
        "recall": 0.05189620758483034
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007966720878793243,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0007966720878793243,
        "precision": 0.0007349666433816016,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006671688762053486,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.0006671688762053486,
        "precision": 0.0006662536994975567,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.04058549567531603,
        "f1": 0.02420495327488485,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.02420495327488485,
        "precision": 0.021098756856662227,
        "recall": 0.04058549567531603
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0008085006636893265,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.0008085006636893265,
        "precision": 0.0007396499978297116,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0003329581994626018,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.0003329581994626018,
        "precision": 0.0002010717829714382,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.001504897600178659,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.001504897600178659,
        "precision": 0.0014246681240693217,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007429278425329801,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.0007429278425329801,
        "precision": 0.0007063087882897703,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.015884466850954928,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.015884466850954928,
        "precision": 0.013997149163861598,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0006750296794074938,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.0006750296794074938,
        "precision": 0.0006701961461818442,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.030605455755156354,
        "f1": 0.018845695592202578,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.018845695592202578,
        "precision": 0.01603264493530473,
        "recall": 0.030605455755156354
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 7.810960953535739e-05,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 7.810960953535739e-05,
        "precision": 4.123240283760976e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.000856344037014909,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.000856344037014909,
        "precision": 0.0007681517131752464,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0008510504793547548,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0008510504793547548,
        "precision": 0.0007648372804835259,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008332318986364539,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0008332318986364539,
        "precision": 0.0007586219286712106,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.05189620758483034,
        "f1": 0.03316818426765015,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.03316818426765015,
        "precision": 0.02825828343170851,
        "recall": 0.05189620758483034
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.005194594204482339,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.005194594204482339,
        "precision": 0.0038198406780919356,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.007214699280466852,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.007214699280466852,
        "precision": 0.005886292330252784,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.0037146819102848194,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.0037146819102848194,
        "precision": 0.002471051890580508,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.285224881911237e-05,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 3.285224881911237e-05,
        "precision": 1.657182158910343e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.01929474384564205,
        "f1": 0.007804464205829736,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.007804464205829736,
        "precision": 0.006548492191181263,
        "recall": 0.01929474384564205
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0021353658532352786,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.0021353658532352786,
        "precision": 0.0016896572755480536,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.013972055888223553,
        "f1": 0.004740928100306662,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.004740928100306662,
        "precision": 0.003907419494922222,
        "recall": 0.013972055888223553
      },
      {
        "accuracy": 0.015302727877578177,
        "f1": 0.005646223168195674,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.005646223168195674,
        "precision": 0.004775173642513317,
        "recall": 0.015302727877578177
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0003424502030975719,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0003424502030975719,
        "precision": 0.00018204200961874023,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.002459778367298366,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.002459778367298366,
        "precision": 0.0019883200738595214,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0009973745006143263,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.0009973745006143263,
        "precision": 0.0008560221604720841,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0013367224314457366,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.0013367224314457366,
        "precision": 0.0011186286635388432,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.0011755195171283615,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.0011755195171283615,
        "precision": 0.0009495641208327625,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.011310711909514305,
        "f1": 0.0050154486304333935,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.0050154486304333935,
        "precision": 0.0038891692986950744,
        "recall": 0.011310711909514305
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.02052614143751019,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.02052614143751019,
        "precision": 0.019740310166980763,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.02661343978709248,
        "f1": 0.02152684308372931,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.02152684308372931,
        "precision": 0.02066934281932366,
        "recall": 0.02661343978709248
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0013735968922370314,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0013735968922370314,
        "precision": 0.0013528498558438677,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.019325402409487245,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.019325402409487245,
        "precision": 0.018618671747414262,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0016473571646365185,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0016473571646365185,
        "precision": 0.0012591606879446295,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.017298735861610112,
        "f1": 0.01497005988023952,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.01497005988023952,
        "precision": 0.014105123087159017,
        "recall": 0.017298735861610112
      },
      {
        "accuracy": 0.031936127744510975,
        "f1": 0.02660304272748056,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.02660304272748056,
        "precision": 0.02539309060855333,
        "recall": 0.031936127744510975
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0022062303059036978,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0022062303059036978,
        "precision": 0.0018845912883173757,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.00083613065252466,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.00083613065252466,
        "precision": 0.0005079182554020113,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007128153708232987,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0007128153708232987,
        "precision": 0.0006894708036961347,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0027612715788994813,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.0027612715788994813,
        "precision": 0.002714139984678806,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.004657351962741184,
        "f1": 0.0032084249255003284,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0032084249255003284,
        "precision": 0.003049456642271013,
        "recall": 0.004657351962741184
      },
      {
        "accuracy": 0.01330671989354624,
        "f1": 0.007907641507109238,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.007907641507109238,
        "precision": 0.006337998976087286,
        "recall": 0.01330671989354624
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.013539060556849631,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.013539060556849631,
        "precision": 0.013090238026370896,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.00028327046134568346,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.00028327046134568346,
        "precision": 0.00016064919006606243,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.024617431803060547,
        "f1": 0.0208417703876698,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.0208417703876698,
        "precision": 0.020047292702719353,
        "recall": 0.024617431803060547
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007476720826865317,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.0007476720826865317,
        "precision": 0.0007089535623089055,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.041916167664670656,
        "f1": 0.03296141697599651,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.03296141697599651,
        "precision": 0.031086460984605793,
        "recall": 0.041916167664670656
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.011143676503880309,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.011143676503880309,
        "precision": 0.010595140462778424,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.054557551563539586,
        "f1": 0.03291200438521459,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.03291200438521459,
        "precision": 0.02794249251085321,
        "recall": 0.054557551563539586
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.277634202255548e-05,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 8.277634202255548e-05,
        "precision": 4.3838296876508e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 0.0008326300741470402,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.0008326300741470402,
        "precision": 0.000760864380916695,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0007891363115859757,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0007891363115859757,
        "precision": 0.000732305151518237,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007351315767848147,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.0007351315767848147,
        "precision": 0.0007013745660681596,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.05588822355289421,
        "f1": 0.037220850004533734,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.037220850004533734,
        "precision": 0.03264137758438243,
        "recall": 0.05588822355289421
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.00145508101461491,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.00145508101461491,
        "precision": 0.0011134822201808417,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.11976047904191617,
        "f1": 0.09503740511724543,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.09503740511724543,
        "precision": 0.08707021304652128,
        "recall": 0.11976047904191617
      },
      {
        "accuracy": 0.06254158349966733,
        "f1": 0.04729540438123272,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.04729540438123272,
        "precision": 0.04267364741416638,
        "recall": 0.06254158349966733
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.02391364734179105,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.02391364734179105,
        "precision": 0.021922105609569396,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.17764471057884232,
        "f1": 0.1394856271103776,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.1394856271103776,
        "precision": 0.1266221525203561,
        "recall": 0.17764471057884232
      },
      {
        "accuracy": 0.0053226879574184965,
        "f1": 0.001101248582284102,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001101248582284102,
        "precision": 0.0007090699118897122,
        "recall": 0.0053226879574184965
      },
      {
        "accuracy": 0.07385229540918163,
        "f1": 0.05190576038879432,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.05190576038879432,
        "precision": 0.04569062932336385,
        "recall": 0.07385229540918163
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0011088933244621866,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0011088933244621866,
        "precision": 0.000998003992015968,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.04590818363273453,
        "f1": 0.027535941884696345,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.027535941884696345,
        "precision": 0.0238432013634805,
        "recall": 0.04590818363273453
      },
      {
        "accuracy": 0.0825016633399867,
        "f1": 0.0566683789921525,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.0566683789921525,
        "precision": 0.04979039035925264,
        "recall": 0.0825016633399867
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.013985714824993714,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.013985714824993714,
        "precision": 0.011945440582136336,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.005947610264075435,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.005947610264075435,
        "precision": 0.004620159808107904,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.0076180818028233985,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0076180818028233985,
        "precision": 0.006220898453147439,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0010590381644641842,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0010590381644641842,
        "precision": 0.00091816494783508,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.006166884478681936,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.006166884478681936,
        "precision": 0.005353009893928057,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0026279907717033464,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0026279907717033464,
        "precision": 0.002352927005597235,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.004941569851749492,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.004941569851749492,
        "precision": 0.004016155142473933,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.13639387890884896,
        "f1": 0.09666866363473149,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.09666866363473149,
        "precision": 0.0848144407525645,
        "recall": 0.13639387890884896
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0039148119053525636,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.0039148119053525636,
        "precision": 0.003423067056145726,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.0061494994197747385,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0061494994197747385,
        "precision": 0.005281851200627459,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0031687337575561133,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0031687337575561133,
        "precision": 0.0024946971261239274,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.07518296739853626,
        "f1": 0.053385100890090915,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.053385100890090915,
        "precision": 0.047122685845240736,
        "recall": 0.07518296739853626
      },
      {
        "accuracy": 0.03127079174983367,
        "f1": 0.023427914251203292,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.023427914251203292,
        "precision": 0.02153599205529827,
        "recall": 0.03127079174983367
      },
      {
        "accuracy": 0.12109115103127079,
        "f1": 0.09660838533094022,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.09660838533094022,
        "precision": 0.08943728704207746,
        "recall": 0.12109115103127079
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0031136924654701936,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0031136924654701936,
        "precision": 0.0022402004178078585,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.07651363938789088,
        "f1": 0.05426882873831081,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.05426882873831081,
        "precision": 0.048086894993082614,
        "recall": 0.07651363938789088
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0035141034211820634,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0035141034211820634,
        "precision": 0.0032242717025325724,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.05389221556886228,
        "f1": 0.035263878577251835,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.035263878577251835,
        "precision": 0.030210340623724383,
        "recall": 0.05389221556886228
      },
      {
        "accuracy": 0.24085163007318697,
        "f1": 0.18899819408801444,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.18899819408801444,
        "precision": 0.17043003939211523,
        "recall": 0.24085163007318697
      },
      {
        "accuracy": 0.025282767797737856,
        "f1": 0.01554091029441404,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.01554091029441404,
        "precision": 0.013400758997549528,
        "recall": 0.025282767797737856
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0038424000660447306,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0038424000660447306,
        "precision": 0.003485324415503895,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.1370592149035263,
        "f1": 0.10139931776658323,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.10139931776658323,
        "precision": 0.08993153663812346,
        "recall": 0.1370592149035263
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.004082640433791431,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004082640433791431,
        "precision": 0.0034418459426149056,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.17564870259481039,
        "f1": 0.13375410351458256,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.13375410351458256,
        "precision": 0.1198840008221246,
        "recall": 0.17564870259481039
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.004484509377911363,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.004484509377911363,
        "precision": 0.004090671001109847,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.07252162341982701,
        "f1": 0.053783658668007606,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.053783658668007606,
        "precision": 0.04841998302577144,
        "recall": 0.07252162341982701
      },
      {
        "accuracy": 0.1111111111111111,
        "f1": 0.08172420034348352,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.08172420034348352,
        "precision": 0.07302818605213814,
        "recall": 0.1111111111111111
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.0028917726619098064,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0028917726619098064,
        "precision": 0.0025856412354733544,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.011976047904191617,
        "f1": 0.00921351386456981,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.00921351386456981,
        "precision": 0.008787303170149334,
        "recall": 0.011976047904191617
      },
      {
        "accuracy": 0.012641383898868928,
        "f1": 0.0063557875860100685,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0063557875860100685,
        "precision": 0.005148488355603537,
        "recall": 0.012641383898868928
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 3.221445428773891e-05,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 3.221445428773891e-05,
        "precision": 1.640643375783658e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0006662284641537404,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.0006662284641537404,
        "precision": 0.0006657825289019278,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 0.0007176088512628649,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0007176088512628649,
        "precision": 0.0006922065691483378,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 0.0007185628742514971,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.0007185628742514971,
        "precision": 0.0006930583277888668,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.037258815701929474,
        "f1": 0.02506700864407283,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.02506700864407283,
        "precision": 0.022038978911423278,
        "recall": 0.037258815701929474
      },
      {
        "accuracy": 0.009314703925482368,
        "f1": 0.0035785693666576953,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0035785693666576953,
        "precision": 0.0028168544973312614,
        "recall": 0.009314703925482368
      },
      {
        "accuracy": 0.14437791084497673,
        "f1": 0.10536667319767784,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.10536667319767784,
        "precision": 0.09374716545375228,
        "recall": 0.14437791084497673
      },
      {
        "accuracy": 0.007318695941450432,
        "f1": 0.0026211790429221346,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0026211790429221346,
        "precision": 0.002340790843873323,
        "recall": 0.007318695941450432
      },
      {
        "accuracy": 0.05322687957418496,
        "f1": 0.032789631470597706,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.032789631470597706,
        "precision": 0.028352759452920432,
        "recall": 0.05322687957418496
      },
      {
        "accuracy": 0.09780439121756487,
        "f1": 0.07315475608888783,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.07315475608888783,
        "precision": 0.0660604022280669,
        "recall": 0.09780439121756487
      },
      {
        "accuracy": 0.023286759813705923,
        "f1": 0.013942312769658079,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.013942312769658079,
        "precision": 0.011829899449498959,
        "recall": 0.023286759813705923
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.760939999801822e-05,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 8.760939999801822e-05,
        "precision": 4.6580896339020474e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0013306719893546241,
        "f1": 2.0039531728228636e-05,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 2.0039531728228636e-05,
        "precision": 1.015791547683679e-05,
        "recall": 0.0013306719893546241
      },
      {
        "accuracy": 0.0026613439787092482,
        "f1": 8.784841712601834e-05,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 8.784841712601834e-05,
        "precision": 4.577780606080519e-05,
        "recall": 0.0026613439787092482
      },
      {
        "accuracy": 0.001996007984031936,
        "f1": 8.7455715388985e-05,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 8.7455715388985e-05,
        "precision": 4.5776330147885535e-05,
        "recall": 0.001996007984031936
      },
      {
        "accuracy": 0.0385894876912841,
        "f1": 0.02344591109202658,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.02344591109202658,
        "precision": 0.019946774046983765,
        "recall": 0.0385894876912841
      },
      {
        "accuracy": 0.003992015968063872,
        "f1": 0.0025432141084557186,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0025432141084557186,
        "precision": 0.0023847659783353867,
        "recall": 0.003992015968063872
      },
      {
        "accuracy": 0.07917498336660013,
        "f1": 0.055857272627527176,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.055857272627527176,
        "precision": 0.04993907234914296,
        "recall": 0.07917498336660013
      },
      {
        "accuracy": 0.09314703925482369,
        "f1": 0.06886073679329273,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.06886073679329273,
        "precision": 0.06135051325919588,
        "recall": 0.09314703925482369
      },
      {
        "accuracy": 0.005988023952095809,
        "f1": 0.003498558438678199,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.003498558438678199,
        "precision": 0.0030474058248297,
        "recall": 0.005988023952095809
      },
      {
        "accuracy": 0.014637391882900865,
        "f1": 0.008044458307717018,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.008044458307717018,
        "precision": 0.007155394040002719,
        "recall": 0.014637391882900865
      },
      {
        "accuracy": 0.0166333998669328,
        "f1": 0.008227358397096702,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.008227358397096702,
        "precision": 0.007370279861141681,
        "recall": 0.0166333998669328
      },
      {
        "accuracy": 0.00332667997338656,
        "f1": 0.0008734540535036905,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0008734540535036905,
        "precision": 0.0007815214628243296,
        "recall": 0.00332667997338656
      },
      {
        "accuracy": 0.057218895542248835,
        "f1": 0.04198587691601663,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.04198587691601663,
        "precision": 0.037903593166400885,
        "recall": 0.057218895542248835
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.004110801775032138,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.004110801775032138,
        "precision": 0.0035475819329165268,
        "recall": 0.008649367930805056
      },
      {
        "accuracy": 0.008649367930805056,
        "f1": 0.0044668194842422656,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0044668194842422656,
        "precision": 0.0040681198205252365,
        "recall": 0.008649367930805056
      }
    ]
  },
  "task_name": "IN22ConvBitextMining"
}