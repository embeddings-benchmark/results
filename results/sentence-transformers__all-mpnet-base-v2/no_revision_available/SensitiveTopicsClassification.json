{
  "dataset_revision": "416b34a802308eac30e4192afc0ff99bb8dcc7f2",
  "evaluation_time": 5.999760150909424,
  "kg_co2_emissions": 0.0002375809007317553,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.178271484375,
        "f1": 0.023994927796670774,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "lrap": 0.2602199978298548,
        "main_score": 0.178271484375,
        "scores_per_experiment": [
          {
            "accuracy": 0.177734375,
            "f1": 0.011100274264231814,
            "lrap": 0.25929090711804914
          },
          {
            "accuracy": 0.17626953125,
            "f1": 0.04401523750893917,
            "lrap": 0.2650146484374936
          },
          {
            "accuracy": 0.1796875,
            "f1": 0.036719201180483024,
            "lrap": 0.26542154947916036
          },
          {
            "accuracy": 0.1796875,
            "f1": 0.013967018489347486,
            "lrap": 0.25717502170138257
          },
          {
            "accuracy": 0.17626953125,
            "f1": 0.008626676440540049,
            "lrap": 0.25588650173610483
          },
          {
            "accuracy": 0.1787109375,
            "f1": 0.02603077178883574,
            "lrap": 0.26227484809027146
          },
          {
            "accuracy": 0.17822265625,
            "f1": 0.01197197779336779,
            "lrap": 0.25657823350693815
          },
          {
            "accuracy": 0.17626953125,
            "f1": 0.026235766134475806,
            "lrap": 0.26159667968749367
          },
          {
            "accuracy": 0.17822265625,
            "f1": 0.036293119436998394,
            "lrap": 0.26085069444443804
          },
          {
            "accuracy": 0.181640625,
            "f1": 0.0249892349294885,
            "lrap": 0.2581108940972158
          }
        ]
      }
    ]
  },
  "task_name": "SensitiveTopicsClassification"
}