{
  "dataset_revision": "46958b007a63fdbf239b7672c25d0bea67b5ea1a",
  "evaluation_time": 28.911446809768677,
  "kg_co2_emissions": 0.0009102836074269275,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.41563333333333335,
        "f1": 0.4135522392887542,
        "f1_weighted": 0.4135522392887542,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.41563333333333335,
        "scores_per_experiment": [
          {
            "accuracy": 0.4176666666666667,
            "f1": 0.41695002211057347,
            "f1_weighted": 0.41695002211057347
          },
          {
            "accuracy": 0.403,
            "f1": 0.40330863079995244,
            "f1_weighted": 0.40330863079995244
          },
          {
            "accuracy": 0.41733333333333333,
            "f1": 0.4178406462922027,
            "f1_weighted": 0.4178406462922027
          },
          {
            "accuracy": 0.403,
            "f1": 0.40213668687594145,
            "f1_weighted": 0.40213668687594145
          },
          {
            "accuracy": 0.41,
            "f1": 0.40311739451186446,
            "f1_weighted": 0.4031173945118644
          },
          {
            "accuracy": 0.41233333333333333,
            "f1": 0.40764890471951637,
            "f1_weighted": 0.40764890471951637
          },
          {
            "accuracy": 0.4066666666666667,
            "f1": 0.4027003884662734,
            "f1_weighted": 0.40270038846627343
          },
          {
            "accuracy": 0.42833333333333334,
            "f1": 0.4283537212356463,
            "f1_weighted": 0.4283537212356463
          },
          {
            "accuracy": 0.41733333333333333,
            "f1": 0.4137204316325005,
            "f1_weighted": 0.4137204316325005
          },
          {
            "accuracy": 0.44066666666666665,
            "f1": 0.439745566243071,
            "f1_weighted": 0.439745566243071
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.41200000000000003,
        "f1": 0.4096591284991685,
        "f1_weighted": 0.40965912849916863,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ],
        "main_score": 0.41200000000000003,
        "scores_per_experiment": [
          {
            "accuracy": 0.413,
            "f1": 0.4120703780616238,
            "f1_weighted": 0.4120703780616238
          },
          {
            "accuracy": 0.4103333333333333,
            "f1": 0.4103868664983083,
            "f1_weighted": 0.41038686649830836
          },
          {
            "accuracy": 0.4033333333333333,
            "f1": 0.40379683831346663,
            "f1_weighted": 0.4037968383134666
          },
          {
            "accuracy": 0.406,
            "f1": 0.4045015727068884,
            "f1_weighted": 0.40450157270688836
          },
          {
            "accuracy": 0.4126666666666667,
            "f1": 0.40330087618356547,
            "f1_weighted": 0.40330087618356547
          },
          {
            "accuracy": 0.39666666666666667,
            "f1": 0.39139132597560905,
            "f1_weighted": 0.39139132597560905
          },
          {
            "accuracy": 0.4036666666666667,
            "f1": 0.3998701615427585,
            "f1_weighted": 0.3998701615427586
          },
          {
            "accuracy": 0.42133333333333334,
            "f1": 0.42149300670934525,
            "f1_weighted": 0.4214930067093453
          },
          {
            "accuracy": 0.42,
            "f1": 0.41834936249492544,
            "f1_weighted": 0.4183493624949255
          },
          {
            "accuracy": 0.433,
            "f1": 0.4314308965051948,
            "f1_weighted": 0.43143089650519484
          }
        ]
      }
    ]
  },
  "task_name": "MultilingualSentiment"
}