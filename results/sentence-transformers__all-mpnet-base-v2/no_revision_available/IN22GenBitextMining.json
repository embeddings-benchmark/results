{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 36.96668791770935,
  "kg_co2_emissions": 0.001503842711727758,
  "mteb_version": "1.12.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006051886469980554,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0006051886469980554,
        "precision": 0.00038756587841477075,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009856308941424072,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.0009856308941424072,
        "precision": 0.0009811073148800749,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001956924854085603,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.001956924854085603,
        "precision": 0.0019550286306042886,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009842218137254902,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.0009842218137254902,
        "precision": 0.0009804072342519685,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.0684298322006484,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0684298322006484,
        "precision": 0.06021048256633345,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.1259765625,
        "f1": 0.09264108638246964,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.09264108638246964,
        "precision": 0.081213801660579,
        "recall": 0.1259765625
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.09877679557855337,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.09877679557855337,
        "precision": 0.0883735161323052,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0001540700414781297,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0001540700414781297,
        "precision": 8.329879870661428e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009822401889534884,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.0009822401889534884,
        "precision": 0.0009794096209912537,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.032114278809999425,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.032114278809999425,
        "precision": 0.026638446731220167,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0017555015462381533,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.0017555015462381533,
        "precision": 0.0014550367852715286,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009925932708723202,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.0009925932708723202,
        "precision": 0.0009846279880127773,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002923112376161068,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.002923112376161068,
        "precision": 0.0026154555308061014,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001466804718875502,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.001466804718875502,
        "precision": 0.0013030648031825795,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0947265625,
        "f1": 0.06597527364128926,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.06597527364128926,
        "precision": 0.057254709038220546,
        "recall": 0.0947265625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0011669780242829077,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.0011669780242829077,
        "precision": 0.001079238307958399,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.04928257097331389,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.04928257097331389,
        "precision": 0.04311039024366532,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0013492068230912268,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.0013492068230912268,
        "precision": 0.0008933904460005688,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0002895357299987726,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0002895357299987726,
        "precision": 0.00015515218377794093,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0025323762758693324,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0025323762758693324,
        "precision": 0.0020152613303350527,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0024643849031754862,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.0024643849031754862,
        "precision": 0.001977946581462177,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.12513447110615078,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.12513447110615078,
        "precision": 0.11124117667214913,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.287109375,
        "f1": 0.2560532902695913,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2560532902695913,
        "precision": 0.246450871609563,
        "recall": 0.287109375
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.12808009378449076,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.12808009378449076,
        "precision": 0.12095744931511132,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.07112339413978787,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.07112339413978787,
        "precision": 0.06628267505819371,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004082940435419017,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004082940435419017,
        "precision": 0.003588336489425997,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.134765625,
        "f1": 0.1091252739972929,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1091252739972929,
        "precision": 0.10149189450644922,
        "recall": 0.134765625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002650383949390279,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.002650383949390279,
        "precision": 0.0023336909773327263,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0056988777640981075,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0056988777640981075,
        "precision": 0.00469120280444804,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.12128331942606428,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.12128331942606428,
        "precision": 0.11172858407093897,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.11690873838667025,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.11690873838667025,
        "precision": 0.11096360114000403,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.2861328125,
        "f1": 0.25497440193844145,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.25497440193844145,
        "precision": 0.2439652104080815,
        "recall": 0.2861328125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016778555508060577,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0016778555508060577,
        "precision": 0.0014163202567959,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.259765625,
        "f1": 0.23242070646367521,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.23242070646367521,
        "precision": 0.22272463672969187,
        "recall": 0.259765625
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.03995756305326617,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.03995756305326617,
        "precision": 0.03563139063627345,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.107421875,
        "f1": 0.07820855074366703,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.07820855074366703,
        "precision": 0.07002512411017121,
        "recall": 0.107421875
      },
      {
        "accuracy": 0.2880859375,
        "f1": 0.2642371389843816,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2642371389843816,
        "precision": 0.25591459728422616,
        "recall": 0.2880859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008830442266949153,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0008830442266949153,
        "precision": 0.0005717348394373672,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04802788494232536,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.04802788494232536,
        "precision": 0.04259410573533391,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0023731376148368333,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0023731376148368333,
        "precision": 0.0021763341043097716,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.02934121302902142,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.02934121302902142,
        "precision": 0.026505458772554145,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.04636932971032236,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.04636932971032236,
        "precision": 0.040761337713170205,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.012491945729947962,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.012491945729947962,
        "precision": 0.010263499879776884,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.14428677229827536,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.14428677229827536,
        "precision": 0.13537294742477232,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.07004982836529172,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.07004982836529172,
        "precision": 0.06497198310710055,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003434952445652174,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003434952445652174,
        "precision": 0.0026452850877192982,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.09810411327986333,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.09810411327986333,
        "precision": 0.09189116451869209,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0007894731669690318,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0007894731669690318,
        "precision": 0.00044318067999708625,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004757256039990117,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.004757256039990117,
        "precision": 0.0038261122375954195,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.12609263751137584,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.12609263751137584,
        "precision": 0.11636111429788666,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.10697936945243885,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.10697936945243885,
        "precision": 0.1007801956919478,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.39453125,
        "f1": 0.35073442995806275,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.35073442995806275,
        "precision": 0.337813250814306,
        "recall": 0.39453125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012095668859649124,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0012095668859649124,
        "precision": 0.0011005704365079365,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.3212890625,
        "f1": 0.286795784429109,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.286795784429109,
        "precision": 0.2759435863510649,
        "recall": 0.3212890625
      },
      {
        "accuracy": 0.244140625,
        "f1": 0.19125054632867133,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.19125054632867133,
        "precision": 0.1752124504907708,
        "recall": 0.244140625
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.07310050136861398,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.07310050136861398,
        "precision": 0.06495865110367063,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.443359375,
        "f1": 0.392294795590694,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.392294795590694,
        "precision": 0.3746186755952381,
        "recall": 0.443359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001956102324695122,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001956102324695122,
        "precision": 0.001954615935114504,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.34375,
        "f1": 0.2869800121753247,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2869800121753247,
        "precision": 0.2692059662694016,
        "recall": 0.34375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009720570264824509,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.009720570264824509,
        "precision": 0.00934752255145613,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.03145777565074501,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.03145777565074501,
        "precision": 0.027505444777973065,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.158203125,
        "f1": 0.11647193331626013,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.11647193331626013,
        "precision": 0.10635040992963998,
        "recall": 0.158203125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015100170773048632,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.015100170773048632,
        "precision": 0.012262954786892478,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04050545802674695,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.04050545802674695,
        "precision": 0.03624380489043377,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.000581281025787983,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.000581281025787983,
        "precision": 0.00033450209770851617,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08732577105762448,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.08732577105762448,
        "precision": 0.08040831781066156,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00022197105893965029,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.00022197105893965029,
        "precision": 0.00012455520435750636,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.010990469323241412,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.010990469323241412,
        "precision": 0.009047334315610226,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.3427734375,
        "f1": 0.29012212639280655,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.29012212639280655,
        "precision": 0.2728103263381584,
        "recall": 0.3427734375
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.10835897309645012,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.10835897309645012,
        "precision": 0.10029653099721458,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.13375139854234347,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.13375139854234347,
        "precision": 0.12573212553250468,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005254710932892408,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0005254710932892408,
        "precision": 0.0003443073328180465,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1328125,
        "f1": 0.107093130664908,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.107093130664908,
        "precision": 0.09840587070299772,
        "recall": 0.1328125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0016520182291666664,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0016520182291666664,
        "precision": 0.0014772053006329115,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.07144879317730879,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.07144879317730879,
        "precision": 0.06473999315053153,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.1806640625,
        "f1": 0.1457215049641965,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.1457215049641965,
        "precision": 0.135600227309791,
        "recall": 0.1806640625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.563311129756616e-05,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 1.563311129756616e-05,
        "precision": 7.85576016185956e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004219747256630962,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.004219747256630962,
        "precision": 0.0037754232620492534,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013427881217671117,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0013427881217671117,
        "precision": 0.0011924787232817395,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019615075107296135,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.0019615075107296135,
        "precision": 0.0019573343211206897,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00101046792072092,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.00101046792072092,
        "precision": 0.0009937038502109705,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.013746171845897092,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.013746171845897092,
        "precision": 0.011571789925796216,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0025791028530662862,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0025791028530662862,
        "precision": 0.001683474936370023,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.1194213197826479,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.1194213197826479,
        "precision": 0.11225294123867058,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.008274728748011384,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.008274728748011384,
        "precision": 0.007065922634632085,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006675482855902777,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.006675482855902777,
        "precision": 0.006022395816618363,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.038220806624854164,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.038220806624854164,
        "precision": 0.03490837850827696,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.1220703125,
        "f1": 0.09876774780088772,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.09876774780088772,
        "precision": 0.09254319477841613,
        "recall": 0.1220703125
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.07178520153480161,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.07178520153480161,
        "precision": 0.06702502691406612,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006330409116972927,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.0006330409116972927,
        "precision": 0.00034399434547129055,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.07306560413691177,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.07306560413691177,
        "precision": 0.06923090217200141,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00050220040892563,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.00050220040892563,
        "precision": 0.0002891859178146769,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.09738521583965443,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.09738521583965443,
        "precision": 0.09051347907677575,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07900345124788008,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.07900345124788008,
        "precision": 0.07418459858563434,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0049517511225981616,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.0049517511225981616,
        "precision": 0.004263583096590909,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0021977390715901745,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.0021977390715901745,
        "precision": 0.00141990089052508,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0025113227521650536,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0025113227521650536,
        "precision": 0.0022726683490044246,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00035916317783094096,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.00035916317783094096,
        "precision": 0.00019380429536679537,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006917317708333333,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.0006917317708333333,
        "precision": 0.0003999255952380952,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.021541539566901493,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.021541539566901493,
        "precision": 0.018109985383201622,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.03521051607098605,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.03521051607098605,
        "precision": 0.029692733014389405,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.06425257292213502,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.06425257292213502,
        "precision": 0.05834189410849566,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.3042510636330003e-05,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 1.3042510636330003e-05,
        "precision": 6.546848667119806e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003659893670204584,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0003659893670204584,
        "precision": 0.00020253755030011044,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04101975307168322,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.04101975307168322,
        "precision": 0.03516840544126093,
        "recall": 0.0625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0005513600077701353,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0005513600077701353,
        "precision": 0.00030295597563520353,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009875214073999349,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0009875214073999349,
        "precision": 0.0009820602560097393,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00010995682386546138,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.00010995682386546138,
        "precision": 5.6318614592441465e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0017365929216456323,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0017365929216456323,
        "precision": 0.001521533632112972,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.026574631487769527,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.026574631487769527,
        "precision": 0.02303526907256155,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0009126674448898677,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0009126674448898677,
        "precision": 0.000628578704591132,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.0747119140625,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.0747119140625,
        "precision": 0.06666050149936868,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0010261421882515633,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0010261421882515633,
        "precision": 0.0005817540965092028,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008611691449571039,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0008611691449571039,
        "precision": 0.0006042350765550157,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00043084912180026505,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.00043084912180026505,
        "precision": 0.00022960900119617226,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0020782609476647598,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0020782609476647598,
        "precision": 0.0020171336756061,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1064453125,
        "f1": 0.07858730081510348,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.07858730081510348,
        "precision": 0.07005456009423228,
        "recall": 0.1064453125
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.051009114583333334,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.051009114583333334,
        "precision": 0.04501550758823032,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.021828615273406522,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.021828615273406522,
        "precision": 0.01954143766146587,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.06306076251280042,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.06306076251280042,
        "precision": 0.058622704883448076,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.2294921875,
        "f1": 0.20265098977204107,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.20265098977204107,
        "precision": 0.19379707404020183,
        "recall": 0.2294921875
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.07021157675038811,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.07021157675038811,
        "precision": 0.06492540306209646,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004030404421029421,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.0004030404421029421,
        "precision": 0.00023557618388683887,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.07832506915090937,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.07832506915090937,
        "precision": 0.07232305249493441,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019550938760080645,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.0019550938760080645,
        "precision": 0.001954110431382442,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2138671875,
        "f1": 0.18170657467532464,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.18170657467532464,
        "precision": 0.16971261160714285,
        "recall": 0.2138671875
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.07840572433070483,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.07840572433070483,
        "precision": 0.07210836878295139,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.03488891694817132,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.03488891694817132,
        "precision": 0.030371585152907273,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0015242638860593035,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.0015242638860593035,
        "precision": 0.0012825031455070228,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016018791454587848,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.0016018791454587848,
        "precision": 0.0013731054298984084,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006814264167205343,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.0006814264167205343,
        "precision": 0.00041281513206078914,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 7.820593758093758e-05,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 7.820593758093758e-05,
        "precision": 4.008704605985842e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.08893101607083684,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.08893101607083684,
        "precision": 0.07803845866590008,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003292840799614643,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0003292840799614643,
        "precision": 0.0001971977557915058,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00028845324361628707,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.00028845324361628707,
        "precision": 0.00016750101132686083,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.028147509106788763,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.028147509106788763,
        "precision": 0.023218601213569792,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012335158111376734,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.0012335158111376734,
        "precision": 0.0011142329180071197,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.1965797326512592e-05,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 1.1965797326512592e-05,
        "precision": 6.007774203431373e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0007316091854280588,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.0007316091854280588,
        "precision": 0.00045650773282883937,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002783698333180133,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.002783698333180133,
        "precision": 0.002051769673582996,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.024177617981585908,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.024177617981585908,
        "precision": 0.020914573288265063,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0002981569242398713,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.0002981569242398713,
        "precision": 0.00015961952302679858,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.047221271024981956,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.047221271024981956,
        "precision": 0.0421118146857382,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0019634866931991864,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.0019634866931991864,
        "precision": 0.0013161264623714837,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.000873674197892948,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.000873674197892948,
        "precision": 0.0005381053150288216,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0015684682248752369,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0015684682248752369,
        "precision": 0.001299013970498536,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0040794906113787366,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.0040794906113787366,
        "precision": 0.0036974765041847026,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.08748185679338022,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.08748185679338022,
        "precision": 0.07766184824290293,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.020895935151991254,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.020895935151991254,
        "precision": 0.015841470297739135,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.0320146612931306,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.0320146612931306,
        "precision": 0.026961608599284995,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.03574016991656124,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.03574016991656124,
        "precision": 0.03066428552792893,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004650297619047619,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.0004650297619047619,
        "precision": 0.0002616992065353346,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.034485860445657754,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.034485860445657754,
        "precision": 0.030472665525794453,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003255208333333333,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.003255208333333333,
        "precision": 0.0022135416666666666,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.02259399590210137,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.02259399590210137,
        "precision": 0.018377316654083573,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.03026628226881707,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.03026628226881707,
        "precision": 0.025440696200600982,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0014288933722527474,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0014288933722527474,
        "precision": 0.0008647433474467942,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004395207798315814,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.004395207798315814,
        "precision": 0.003052781118338184,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001542202594408665,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.001542202594408665,
        "precision": 0.001294223135228871,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007246508629493464,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.007246508629493464,
        "precision": 0.006335152876254668,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030924479166666665,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.0030924479166666665,
        "precision": 0.0020899564844877347,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004322535065872959,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.004322535065872959,
        "precision": 0.0028295425338961126,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.11269737335947592,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.11269737335947592,
        "precision": 0.10667947237413145,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.1370845329753278,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.1370845329753278,
        "precision": 0.1300368369979262,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.11395447655044907,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.11395447655044907,
        "precision": 0.1072698846254079,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0030654579540149393,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0030654579540149393,
        "precision": 0.0026531327242231635,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.07083624828389853,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.07083624828389853,
        "precision": 0.06495817861353821,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.141552734375,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.141552734375,
        "precision": 0.1334619915674603,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.505373023715415e-05,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 1.505373023715415e-05,
        "precision": 7.560923049155433e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0032086182925962488,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0032086182925962488,
        "precision": 0.002719831579458638,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004731528779380342,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.0004731528779380342,
        "precision": 0.0002860960218562735,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004382406661383027,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.0004382406661383027,
        "precision": 0.0002527462008743058,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0030290570175438595,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0030290570175438595,
        "precision": 0.0027029854910714285,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.014022033341297323,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.014022033341297323,
        "precision": 0.011350802138677028,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.11110879736184906,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.11110879736184906,
        "precision": 0.10144170960507311,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009803403046421664,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.0009803403046421664,
        "precision": 0.0009784550629844961,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.138671875,
        "f1": 0.1110826384352013,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.1110826384352013,
        "precision": 0.10352075924007462,
        "recall": 0.138671875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00288819530796354,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.00288819530796354,
        "precision": 0.0026012288119305,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.177734375,
        "f1": 0.14852609949059212,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.14852609949059212,
        "precision": 0.1382760712594697,
        "recall": 0.177734375
      },
      {
        "accuracy": 0.1455078125,
        "f1": 0.11232408509267941,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.11232408509267941,
        "precision": 0.10178616698841503,
        "recall": 0.1455078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.032896526844409246,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.032896526844409246,
        "precision": 0.028026748192244367,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0017427367898539337,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.0017427367898539337,
        "precision": 0.001420488416651859,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002034505208333333,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.002034505208333333,
        "precision": 0.0016369047619047617,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004964263907115777,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0004964263907115777,
        "precision": 0.00027114154137033596,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012530760882856443,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.0012530760882856443,
        "precision": 0.0011269221230158731,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.0715437114530354,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.0715437114530354,
        "precision": 0.06401098297504912,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0032076370455276703,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0032076370455276703,
        "precision": 0.002451982728823588,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.33203125,
        "f1": 0.2983699514461233,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2983699514461233,
        "precision": 0.28642694382440476,
        "recall": 0.33203125
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.08785339049800792,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.08785339049800792,
        "precision": 0.08141281145048124,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.08431956669518346,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.08431956669518346,
        "precision": 0.07569352662254594,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.3720703125,
        "f1": 0.3410594658492926,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3410594658492926,
        "precision": 0.33017311146450923,
        "recall": 0.3720703125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002154198930678466,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002154198930678466,
        "precision": 0.002064521182610125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.146484375,
        "f1": 0.11285530987511051,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.11285530987511051,
        "precision": 0.10311152295500553,
        "recall": 0.146484375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005771347130097513,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.005771347130097513,
        "precision": 0.004908416069488683,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.033556893632886754,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.033556893632886754,
        "precision": 0.02935379024130566,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.09128117341395511,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09128117341395511,
        "precision": 0.08420584542410714,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.016962668244874825,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.016962668244874825,
        "precision": 0.014308833179000838,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.007974960274908575,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.007974960274908575,
        "precision": 0.007198715957633597,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.004090547133824272,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.004090547133824272,
        "precision": 0.0032103181027713277,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0029516989087301584,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0029516989087301584,
        "precision": 0.0022928749894354293,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003350770248668956,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.003350770248668956,
        "precision": 0.002775016387314933,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9073486328125e-06,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 1.9073486328125e-06,
        "precision": 9.546065493646139e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.0045386036622673135,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0045386036622673135,
        "precision": 0.003296607943361715,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.0752542867288961,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.0752542867288961,
        "precision": 0.06601462316922843,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.00796622810782967,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.00796622810782967,
        "precision": 0.006458760657979408,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005535587576956176,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.005535587576956176,
        "precision": 0.004982679269803397,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.004453538555474264,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.004453538555474264,
        "precision": 0.004262017577431665,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.11127208295177043,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.11127208295177043,
        "precision": 0.09962387505901982,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.07635385968623559,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.07635385968623559,
        "precision": 0.06880383613782051,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.337890625,
        "f1": 0.2999867049183455,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2999867049183455,
        "precision": 0.2869990216138539,
        "recall": 0.337890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011727595644120147,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0011727595644120147,
        "precision": 0.0010836050417795844,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.12496160523504274,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.12496160523504274,
        "precision": 0.11121060344118708,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.008176977638058129,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.008176977638058129,
        "precision": 0.0070769542639778915,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.05533519366179486,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.05533519366179486,
        "precision": 0.049169372150903626,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.333984375,
        "f1": 0.2661745101686508,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.2661745101686508,
        "precision": 0.24074009486607145,
        "recall": 0.333984375
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.018499544642362403,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.018499544642362403,
        "precision": 0.015656768212695467,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0006510416666666666,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.00048828125,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.11222780959338863,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.11222780959338863,
        "precision": 0.10223033440806878,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0018582509793447293,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0018582509793447293,
        "precision": 0.001547617057477413,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.3408203125,
        "f1": 0.2728424028228716,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2728424028228716,
        "precision": 0.24998178633432538,
        "recall": 0.3408203125
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.016410771219599125,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.016410771219599125,
        "precision": 0.014787937160736907,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.05284301315242861,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.05284301315242861,
        "precision": 0.04815616741943718,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.14994564163624363,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.14994564163624363,
        "precision": 0.137650881291018,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003689194119259546,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.003689194119259546,
        "precision": 0.0031058175223214286,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.05053251957227179,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.05053251957227179,
        "precision": 0.047639965043835025,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.01917025469486941,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.01917025469486941,
        "precision": 0.01647914804234038,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0011945202924537584,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.0011945202924537584,
        "precision": 0.0008111785680661083,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010528382149790922,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.0010528382149790922,
        "precision": 0.0010160954496891998,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00029694509144237403,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.00029694509144237403,
        "precision": 0.00017178754664179104,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 8.160545653848565e-05,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 8.160545653848565e-05,
        "precision": 4.1825041453128114e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.07312749099858473,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.07312749099858473,
        "precision": 0.06451818689123376,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016465037719633308,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0016465037719633308,
        "precision": 0.001401795504385965,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.2490234375,
        "f1": 0.1961210176542208,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.1961210176542208,
        "precision": 0.17874379485276773,
        "recall": 0.2490234375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0058858996272152415,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0058858996272152415,
        "precision": 0.005245916499525534,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.02206326524046475,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.02206326524046475,
        "precision": 0.019513098812320245,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.07340544465300325,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.07340544465300325,
        "precision": 0.06557552017245188,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.016131085233937532,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.016131085233937532,
        "precision": 0.013575590718669032,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001648488127235479,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.001648488127235479,
        "precision": 0.0014753269912297974,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014686339065619887,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0014686339065619887,
        "precision": 0.0012614586371640308,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0017393486567936454,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0017393486567936454,
        "precision": 0.0014396490533911926,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0020667448718798657,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0020667448718798657,
        "precision": 0.0020117799488852824,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.06055462549603174,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.06055462549603174,
        "precision": 0.05322354622075123,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01389649179104686,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.01389649179104686,
        "precision": 0.012463257841569661,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.054578923717864984,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.054578923717864984,
        "precision": 0.05050945390534385,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.216796875,
        "f1": 0.17652452256944443,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.17652452256944443,
        "precision": 0.1640493349966006,
        "recall": 0.216796875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00316890746124031,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.00316890746124031,
        "precision": 0.0027482451141264998,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008451491425486566,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.008451491425486566,
        "precision": 0.007992739853934724,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.0075016279324705065,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0075016279324705065,
        "precision": 0.00660073532462796,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.358846618357488e-06,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 2.358846618357488e-06,
        "precision": 1.1808494558645707e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.125,
        "f1": 0.09442281351461039,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09442281351461039,
        "precision": 0.08576615441849816,
        "recall": 0.125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0033341067922869395,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0033341067922869395,
        "precision": 0.0031498846283304987,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0045830722639933165,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0045830722639933165,
        "precision": 0.003909441380718954,
        "recall": 0.009765625
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}