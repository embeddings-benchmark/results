{
  "dataset_revision": "f5502326c4e48adc99b18b1582f68b8fb5e7ec30",
  "evaluation_time": 13.052369832992554,
  "kg_co2_emissions": 0.00037674254995575087,
  "mteb_version": "1.12.41",
  "scores": {
    "train": [
      {
        "accuracy": 0.55,
        "f1": 0.27494801226488325,
        "f1_weighted": 0.5039219872297563,
        "hf_subset": "default",
        "languages": [
          "ssw-Latn"
        ],
        "main_score": 0.55,
        "scores_per_experiment": [
          {
            "accuracy": 0.55,
            "f1": 0.27687100481218124,
            "f1_weighted": 0.49531485671191555
          },
          {
            "accuracy": 0.525,
            "f1": 0.25762527233115473,
            "f1_weighted": 0.47101307189542485
          },
          {
            "accuracy": 0.575,
            "f1": 0.2901315697242433,
            "f1_weighted": 0.5349495661073025
          },
          {
            "accuracy": 0.55,
            "f1": 0.301480463980464,
            "f1_weighted": 0.5032188644688645
          },
          {
            "accuracy": 0.5875,
            "f1": 0.2871693121693122,
            "f1_weighted": 0.5486616161616162
          },
          {
            "accuracy": 0.5375,
            "f1": 0.2621536796536797,
            "f1_weighted": 0.4803262987012987
          },
          {
            "accuracy": 0.5625,
            "f1": 0.26406689273396516,
            "f1_weighted": 0.5261846795930788
          },
          {
            "accuracy": 0.55,
            "f1": 0.2762498304164971,
            "f1_weighted": 0.5079634717134718
          },
          {
            "accuracy": 0.5375,
            "f1": 0.26982431149097813,
            "f1_weighted": 0.4997507122507122
          },
          {
            "accuracy": 0.525,
            "f1": 0.2639077853363568,
            "f1_weighted": 0.47183673469387755
          }
        ]
      }
    ]
  },
  "task_name": "SiswatiNewsClassification"
}