{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 11.1291823387146,
  "kg_co2_emissions": 0.001703361703304456,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.610546875,
        "ap": 0.1035309305335275,
        "ap_weighted": 0.1035309305335275,
        "f1": 0.4688053661436461,
        "f1_weighted": 0.6953450317935015,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.610546875,
        "scores_per_experiment": [
          {
            "accuracy": 0.62939453125,
            "ap": 0.10107714406881807,
            "ap_weighted": 0.10107714406881807,
            "f1": 0.4771994151911072,
            "f1_weighted": 0.7146513428703208
          },
          {
            "accuracy": 0.68212890625,
            "ap": 0.10709201716209987,
            "ap_weighted": 0.10709201716209987,
            "f1": 0.5059436925043773,
            "f1_weighted": 0.7543028981441594
          },
          {
            "accuracy": 0.7041015625,
            "ap": 0.10638246441831684,
            "ap_weighted": 0.10638246441831684,
            "f1": 0.5144230769230769,
            "f1_weighted": 0.7698962871844952
          },
          {
            "accuracy": 0.7109375,
            "ap": 0.12146074615945504,
            "ap_weighted": 0.12146074615945504,
            "f1": 0.5312486468095635,
            "f1_weighted": 0.7755574661315765
          },
          {
            "accuracy": 0.466796875,
            "ap": 0.08645617677903843,
            "ap_weighted": 0.08645617677903843,
            "f1": 0.3842134652640946,
            "f1_weighted": 0.5740451964436958
          },
          {
            "accuracy": 0.4462890625,
            "ap": 0.09829843134792964,
            "ap_weighted": 0.09829843134792964,
            "f1": 0.38211894312507716,
            "f1_weighted": 0.5497390731286634
          },
          {
            "accuracy": 0.6533203125,
            "ap": 0.09813261000773767,
            "ap_weighted": 0.09813261000773767,
            "f1": 0.48450041124251964,
            "f1_weighted": 0.7328327574608611
          },
          {
            "accuracy": 0.568359375,
            "ap": 0.10160287707854178,
            "ap_weighted": 0.10160287707854178,
            "f1": 0.44938199513382,
            "f1_weighted": 0.6648410317822385
          },
          {
            "accuracy": 0.63330078125,
            "ap": 0.11300794558736614,
            "ap_weighted": 0.11300794558736614,
            "f1": 0.48948447175075144,
            "f1_weighted": 0.717579520119385
          },
          {
            "accuracy": 0.61083984375,
            "ap": 0.10179889272597134,
            "ap_weighted": 0.10179889272597134,
            "f1": 0.4695395434920727,
            "f1_weighted": 0.7000047446696191
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}