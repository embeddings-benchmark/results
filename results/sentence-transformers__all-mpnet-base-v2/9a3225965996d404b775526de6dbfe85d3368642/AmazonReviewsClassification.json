{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "task_name": "AmazonReviewsClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.26212,
        "f1": 0.257053,
        "f1_weighted": 0.257053,
        "scores_per_experiment": [
          {
            "accuracy": 0.2988,
            "f1": 0.30026,
            "f1_weighted": 0.30026
          },
          {
            "accuracy": 0.2592,
            "f1": 0.244713,
            "f1_weighted": 0.244713
          },
          {
            "accuracy": 0.269,
            "f1": 0.26941,
            "f1_weighted": 0.26941
          },
          {
            "accuracy": 0.2528,
            "f1": 0.244681,
            "f1_weighted": 0.244681
          },
          {
            "accuracy": 0.2492,
            "f1": 0.246886,
            "f1_weighted": 0.246886
          },
          {
            "accuracy": 0.257,
            "f1": 0.248815,
            "f1_weighted": 0.248815
          },
          {
            "accuracy": 0.2404,
            "f1": 0.241935,
            "f1_weighted": 0.241935
          },
          {
            "accuracy": 0.28,
            "f1": 0.266058,
            "f1_weighted": 0.266058
          },
          {
            "accuracy": 0.2766,
            "f1": 0.270265,
            "f1_weighted": 0.270265
          },
          {
            "accuracy": 0.2382,
            "f1": 0.237512,
            "f1_weighted": 0.237512
          }
        ],
        "main_score": 0.26212,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.2604,
        "f1": 0.255542,
        "f1_weighted": 0.255542,
        "scores_per_experiment": [
          {
            "accuracy": 0.2924,
            "f1": 0.292772,
            "f1_weighted": 0.292772
          },
          {
            "accuracy": 0.2574,
            "f1": 0.243816,
            "f1_weighted": 0.243816
          },
          {
            "accuracy": 0.265,
            "f1": 0.265523,
            "f1_weighted": 0.265523
          },
          {
            "accuracy": 0.2534,
            "f1": 0.245443,
            "f1_weighted": 0.245443
          },
          {
            "accuracy": 0.2552,
            "f1": 0.25206,
            "f1_weighted": 0.25206
          },
          {
            "accuracy": 0.2598,
            "f1": 0.252026,
            "f1_weighted": 0.252026
          },
          {
            "accuracy": 0.2528,
            "f1": 0.253876,
            "f1_weighted": 0.253876
          },
          {
            "accuracy": 0.2716,
            "f1": 0.260601,
            "f1_weighted": 0.260601
          },
          {
            "accuracy": 0.2494,
            "f1": 0.244139,
            "f1_weighted": 0.244139
          },
          {
            "accuracy": 0.247,
            "f1": 0.24517,
            "f1_weighted": 0.24517
          }
        ],
        "main_score": 0.2604,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 60.19761657714844,
  "kg_co2_emissions": null
}