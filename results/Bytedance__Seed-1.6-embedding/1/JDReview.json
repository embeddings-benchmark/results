{
  "dataset_revision": "b7c64bd89eb87f8ded463478346f76731f07bf8b",
  "task_name": "JDReview",
  "mteb_version": "1.38.29",
  "scores": {
    "test": [
      {
        "accuracy": 0.914259,
        "f1": 0.869994,
        "f1_weighted": 0.917671,
        "ap": 0.658591,
        "ap_weighted": 0.658591,
        "scores_per_experiment": [
          {
            "accuracy": 0.915572,
            "f1": 0.871563,
            "f1_weighted": 0.918817,
            "ap": 0.661804,
            "ap_weighted": 0.661804
          },
          {
            "accuracy": 0.913696,
            "f1": 0.869145,
            "f1_weighted": 0.917134,
            "ap": 0.656591,
            "ap_weighted": 0.656591
          },
          {
            "accuracy": 0.913696,
            "f1": 0.869145,
            "f1_weighted": 0.917134,
            "ap": 0.656591,
            "ap_weighted": 0.656591
          },
          {
            "accuracy": 0.917448,
            "f1": 0.873995,
            "f1_weighted": 0.920503,
            "ap": 0.667103,
            "ap_weighted": 0.667103
          },
          {
            "accuracy": 0.915572,
            "f1": 0.871563,
            "f1_weighted": 0.918817,
            "ap": 0.661804,
            "ap_weighted": 0.661804
          },
          {
            "accuracy": 0.906191,
            "f1": 0.860518,
            "f1_weighted": 0.910684,
            "ap": 0.638995,
            "ap_weighted": 0.638995
          },
          {
            "accuracy": 0.915572,
            "f1": 0.871563,
            "f1_weighted": 0.918817,
            "ap": 0.661804,
            "ap_weighted": 0.661804
          },
          {
            "accuracy": 0.921201,
            "f1": 0.878906,
            "f1_weighted": 0.923886,
            "ap": 0.677967,
            "ap_weighted": 0.677967
          },
          {
            "accuracy": 0.915572,
            "f1": 0.871563,
            "f1_weighted": 0.918817,
            "ap": 0.661804,
            "ap_weighted": 0.661804
          },
          {
            "accuracy": 0.908068,
            "f1": 0.861979,
            "f1_weighted": 0.912108,
            "ap": 0.641449,
            "ap_weighted": 0.641449
          }
        ],
        "main_score": 0.914259,
        "hf_subset": "default",
        "languages": [
          "cmn-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 19.05058979988098,
  "kg_co2_emissions": null
}