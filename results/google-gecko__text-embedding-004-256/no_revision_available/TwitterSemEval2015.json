{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.0.3.dev0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8744113965548072,
      "accuracy_threshold": 0.81749027967453,
      "ap": 0.7823227169439763,
      "f1": 0.7078881018129428,
      "f1_threshold": 0.7770020961761475,
      "precision": 0.6494822648160388,
      "recall": 0.7778364116094987
    },
    "dot": {
      "accuracy": 0.8540859510043511,
      "accuracy_threshold": 0.2934325337409973,
      "ap": 0.7243362281752107,
      "f1": 0.6724369133243935,
      "f1_threshold": 0.28300565481185913,
      "precision": 0.6249716745977792,
      "recall": 0.7277044854881266
    },
    "euclidean": {
      "accuracy": 0.8744113965548072,
      "accuracy_threshold": 0.3685424327850342,
      "ap": 0.7825131382455399,
      "f1": 0.7066734331387973,
      "f1_threshold": 0.3929133415222168,
      "precision": 0.6805962854349951,
      "recall": 0.7348284960422163
    },
    "evaluation_time": 544.23,
    "manhattan": {
      "accuracy": 0.8739941586696072,
      "accuracy_threshold": 4.759272575378418,
      "ap": 0.7812531368757971,
      "f1": 0.7083969465648854,
      "f1_threshold": 5.010133743286133,
      "precision": 0.684029484029484,
      "recall": 0.7345646437994723
    },
    "max": {
      "accuracy": 0.8744113965548072,
      "ap": 0.7825131382455399,
      "f1": 0.7083969465648854
    }
  }
}