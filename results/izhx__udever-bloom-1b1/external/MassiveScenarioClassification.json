{
    "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.5046738399462004,
                "f1": 0.48277337351043065,
                "main_score": 0.5046738399462004
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.2722259583053127,
                "f1": 0.2615959037949326,
                "main_score": 0.2722259583053127
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.6543039677202419,
                "f1": 0.6558227814316873,
                "main_score": 0.6543039677202419
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.4073638197713517,
                "f1": 0.3985702036251076,
                "main_score": 0.4073638197713517
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.6764626765299259,
                "f1": 0.6712298813657769,
                "main_score": 0.6764626765299259
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.43940820443846673,
                "f1": 0.41634124995878385,
                "main_score": 0.43940820443846673
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.525252185608608,
                "f1": 0.5025821961669483,
                "main_score": 0.525252185608608
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.5667114996637526,
                "f1": 0.5420411783181425,
                "main_score": 0.5667114996637526
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.418123739071957,
                "f1": 0.4025676895490678,
                "main_score": 0.418123739071957
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.7571956960322798,
                "f1": 0.7595126212201125,
                "main_score": 0.7571956960322798
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.717787491593813,
                "f1": 0.7190678548502462,
                "main_score": 0.717787491593813
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.49959650302622743,
                "f1": 0.48625859921623515,
                "main_score": 0.49959650302622743
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.41005379959650307,
                "f1": 0.3825957953711836,
                "main_score": 0.41005379959650307
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.7199058507061199,
                "f1": 0.7230034867942927,
                "main_score": 0.7199058507061199
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.36691324815063886,
                "f1": 0.3509762112518494,
                "main_score": 0.36691324815063886
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.6927706792199058,
                "f1": 0.6896935505580095,
                "main_score": 0.6927706792199058
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.4431405514458642,
                "f1": 0.4175837557089336,
                "main_score": 0.4431405514458642
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.3363819771351715,
                "f1": 0.32009991996454656,
                "main_score": 0.3363819771351715
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.6898117014122395,
                "f1": 0.6848993356947226,
                "main_score": 0.6898117014122395
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.42101546738399465,
                "f1": 0.3953758020143903,
                "main_score": 0.42101546738399465
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.6027236045729657,
                "f1": 0.588041857941664,
                "main_score": 0.6027236045729657
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.6247814391392064,
                "f1": 0.614800551358116,
                "main_score": 0.6247814391392064
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.5468392737054473,
                "f1": 0.5328619831432411,
                "main_score": 0.5468392737054473
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.27215870880968396,
                "f1": 0.26137784395348485,
                "main_score": 0.27215870880968396
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.32138533960995297,
                "f1": 0.29886918185071976,
                "main_score": 0.32138533960995297
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.5794889038332213,
                "f1": 0.5719252000109654,
                "main_score": 0.5794889038332213
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.4794552790854068,
                "f1": 0.4621337507975437,
                "main_score": 0.4794552790854068
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.42757229320780094,
                "f1": 0.4062195245815035,
                "main_score": 0.42757229320780094
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.6284129119031607,
                "f1": 0.6256205475932971,
                "main_score": 0.6284129119031607
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.3321116341627438,
                "f1": 0.32231827617771047,
                "main_score": 0.3321116341627438
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.6256893073301949,
                "f1": 0.6094616552257348,
                "main_score": 0.6256893073301949
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.288399462004035,
                "f1": 0.278503615081592,
                "main_score": 0.288399462004035
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.5031607262945528,
                "f1": 0.479933680054182,
                "main_score": 0.5031607262945528
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.528513786146604,
                "f1": 0.5044433263951382,
                "main_score": 0.528513786146604
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.45595158036314737,
                "f1": 0.44241686886064757,
                "main_score": 0.45595158036314737
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.7024209818426362,
                "f1": 0.7048109122752664,
                "main_score": 0.7024209818426362
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.5273369199731002,
                "f1": 0.5114034087602817,
                "main_score": 0.5273369199731002
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.5426361802286482,
                "f1": 0.533188846615122,
                "main_score": 0.5426361802286482
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.4688634835238735,
                "f1": 0.452572616869608,
                "main_score": 0.4688634835238735
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.47155346334902487,
                "f1": 0.4521880761840922,
                "main_score": 0.47155346334902487
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.479119031607263,
                "f1": 0.4596730030717468,
                "main_score": 0.479119031607263
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.5120040349697377,
                "f1": 0.49113423730259215,
                "main_score": 0.5120040349697377
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.618392737054472,
                "f1": 0.6165834459536363,
                "main_score": 0.618392737054472
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.5979152656355078,
                "f1": 0.582891677685128,
                "main_score": 0.5979152656355078
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.4162071284465366,
                "f1": 0.39591525429243574,
                "main_score": 0.4162071284465366
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.5046738399462004,
                "f1": 0.4950612154409957,
                "main_score": 0.5046738399462004
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.43412911903160717,
                "f1": 0.43850703021748155,
                "main_score": 0.43412911903160717
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.6015131136516476,
                "f1": 0.5926001273867632,
                "main_score": 0.6015131136516476
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.6898789509078682,
                "f1": 0.6986968024553558,
                "main_score": 0.6898789509078682
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.7472091459314055,
                "f1": 0.7469866015852225,
                "main_score": 0.7472091459314055
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.717014122394082,
                "f1": 0.7266856729607628,
                "main_score": 0.717014122394082
            }
        ]
    }
}