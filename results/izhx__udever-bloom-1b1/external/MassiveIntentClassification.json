{
    "dataset_revision": "31efe3c427b0bae9c22cbb560b8f15491cc6bed7",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.44979825151311364,
                "f1": 0.4308686679862984,
                "main_score": 0.44979825151311364
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.2535305985205111,
                "f1": 0.2456465252790922,
                "main_score": 0.2535305985205111
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.5707800941492938,
                "f1": 0.549335411254588,
                "main_score": 0.5707800941492938
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.3910558170813719,
                "f1": 0.3915270496151374,
                "main_score": 0.3910558170813719
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.6136852723604573,
                "f1": 0.5865381984021665,
                "main_score": 0.6136852723604573
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.4296906523201076,
                "f1": 0.4188085083446726,
                "main_score": 0.4296906523201076
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.4954270342972428,
                "f1": 0.48442067471729133,
                "main_score": 0.4954270342972428
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.5093140551445864,
                "f1": 0.4740396853548677,
                "main_score": 0.5093140551445864
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.40094149293880293,
                "f1": 0.3827158057191927,
                "main_score": 0.40094149293880293
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6793207800941494,
                "f1": 0.6650282035579518,
                "main_score": 0.6793207800941494
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.6381304640215198,
                "f1": 0.6251979490279083,
                "main_score": 0.6381304640215198
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.49058507061197043,
                "f1": 0.4749872899848797,
                "main_score": 0.49058507061197043
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.4257901815736382,
                "f1": 0.40386069905109956,
                "main_score": 0.4257901815736382
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.6533960995292535,
                "f1": 0.6396475759829612,
                "main_score": 0.6533960995292535
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.37148621385339614,
                "f1": 0.35954583318470384,
                "main_score": 0.37148621385339614
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.6288836583725621,
                "f1": 0.6113909233127686,
                "main_score": 0.6288836583725621
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.4162071284465366,
                "f1": 0.40237798909807876,
                "main_score": 0.4162071284465366
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.32982515131136514,
                "f1": 0.3182828709111086,
                "main_score": 0.32982515131136514
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.6211499663752521,
                "f1": 0.6030765133068972,
                "main_score": 0.6211499663752521
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.4103900470746468,
                "f1": 0.39531615524370683,
                "main_score": 0.4103900470746468
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.558338937457969,
                "f1": 0.5486425916837068,
                "main_score": 0.558338937457969
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.5883322125084061,
                "f1": 0.5652595986400214,
                "main_score": 0.5883322125084061
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.49310692669804973,
                "f1": 0.47241381065322263,
                "main_score": 0.49310692669804973
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.2643241425689307,
                "f1": 0.2578783343772585,
                "main_score": 0.2643241425689307
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.2876933422999327,
                "f1": 0.2734778980866226,
                "main_score": 0.2876933422999327
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.5233019502353733,
                "f1": 0.4949897965390079,
                "main_score": 0.5233019502353733
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.46930060524546063,
                "f1": 0.4471215467580226,
                "main_score": 0.46930060524546063
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.4425689307330195,
                "f1": 0.4361087006714549,
                "main_score": 0.4425689307330195
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.5774714189643577,
                "f1": 0.5457143159052273,
                "main_score": 0.5774714189643577
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.33305312710154683,
                "f1": 0.334982889160085,
                "main_score": 0.33305312710154683
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.5569939475453933,
                "f1": 0.5400478534026828,
                "main_score": 0.5569939475453933
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.2738735709482179,
                "f1": 0.2613911221269247,
                "main_score": 0.2738735709482179
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.46183591123066575,
                "f1": 0.4529847979854711,
                "main_score": 0.46183591123066575
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.4833557498318763,
                "f1": 0.46102865846786295,
                "main_score": 0.4833557498318763
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.44468728984532613,
                "f1": 0.4243443803309795,
                "main_score": 0.44468728984532613
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.6474445191661062,
                "f1": 0.6345367959032218,
                "main_score": 0.6474445191661062
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.4841291190316072,
                "f1": 0.4714401920664497,
                "main_score": 0.4841291190316072
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.529892400806994,
                "f1": 0.5091931775407477,
                "main_score": 0.529892400806994
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.44771351714862134,
                "f1": 0.4290054169209577,
                "main_score": 0.44771351714862134
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.4545393409549428,
                "f1": 0.4502776171558315,
                "main_score": 0.4545393409549428
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.45675857431069267,
                "f1": 0.4445608727957947,
                "main_score": 0.45675857431069267
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.4645595158036314,
                "f1": 0.4470548836690419,
                "main_score": 0.4645595158036314
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.554640215198386,
                "f1": 0.5228532276735651,
                "main_score": 0.554640215198386
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.51408876933423,
                "f1": 0.48864542361562036,
                "main_score": 0.51408876933423
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.3919636852723604,
                "f1": 0.38882470376017536,
                "main_score": 0.3919636852723604
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.4853396099529254,
                "f1": 0.46961492802320653,
                "main_score": 0.4853396099529254
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.3950907868190988,
                "f1": 0.39309733555833565,
                "main_score": 0.3950907868190988
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.5471755211835911,
                "f1": 0.5208348704897728,
                "main_score": 0.5471755211835911
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.6200739744451916,
                "f1": 0.6057772322803523,
                "main_score": 0.6200739744451916
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.66906523201076,
                "f1": 0.652730417732602,
                "main_score": 0.66906523201076
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.6256220578345663,
                "f1": 0.623944953225828,
                "main_score": 0.6256220578345663
            }
        ]
    }
}