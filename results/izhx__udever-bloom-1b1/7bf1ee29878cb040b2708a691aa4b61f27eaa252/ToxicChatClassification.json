{
  "dataset_revision": "3e0319203c7162b9c9f8015b594441f979c199bc",
  "task_name": "ToxicChatClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.687715,
        "f1": 0.581958,
        "f1_weighted": 0.736459,
        "ap": 0.220659,
        "ap_weighted": 0.220659,
        "scores_per_experiment": [
          {
            "accuracy": 0.61512,
            "f1": 0.530569,
            "f1_weighted": 0.679817,
            "ap": 0.191119,
            "ap_weighted": 0.191119
          },
          {
            "accuracy": 0.835911,
            "f1": 0.696434,
            "f1_weighted": 0.850583,
            "ap": 0.299547,
            "ap_weighted": 0.299547
          },
          {
            "accuracy": 0.774914,
            "f1": 0.652971,
            "f1_weighted": 0.807079,
            "ap": 0.268995,
            "ap_weighted": 0.268995
          },
          {
            "accuracy": 0.622852,
            "f1": 0.53959,
            "f1_weighted": 0.686266,
            "ap": 0.19983,
            "ap_weighted": 0.19983
          },
          {
            "accuracy": 0.537801,
            "f1": 0.467857,
            "f1_weighted": 0.612385,
            "ap": 0.157365,
            "ap_weighted": 0.157365
          },
          {
            "accuracy": 0.770619,
            "f1": 0.640081,
            "f1_weighted": 0.802461,
            "ap": 0.248748,
            "ap_weighted": 0.248748
          },
          {
            "accuracy": 0.732818,
            "f1": 0.617564,
            "f1_weighted": 0.774843,
            "ap": 0.240412,
            "ap_weighted": 0.240412
          },
          {
            "accuracy": 0.560997,
            "f1": 0.482638,
            "f1_weighted": 0.633474,
            "ap": 0.160746,
            "ap_weighted": 0.160746
          },
          {
            "accuracy": 0.713058,
            "f1": 0.586479,
            "f1_weighted": 0.757872,
            "ap": 0.203928,
            "ap_weighted": 0.203928
          },
          {
            "accuracy": 0.713058,
            "f1": 0.605396,
            "f1_weighted": 0.759806,
            "ap": 0.235899,
            "ap_weighted": 0.235899
          }
        ],
        "main_score": 0.687715,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.722227334976196,
  "kg_co2_emissions": 0.0006162482042861464
}