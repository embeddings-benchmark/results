{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.700342,
        "f1": 0.698184,
        "f1_weighted": 0.698229,
        "ap": 0.638356,
        "ap_weighted": 0.638356,
        "scores_per_experiment": [
          {
            "accuracy": 0.697266,
            "f1": 0.687942,
            "f1_weighted": 0.6881,
            "ap": 0.628595,
            "ap_weighted": 0.628595
          },
          {
            "accuracy": 0.699219,
            "f1": 0.695101,
            "f1_weighted": 0.695205,
            "ap": 0.632983,
            "ap_weighted": 0.632983
          },
          {
            "accuracy": 0.709961,
            "f1": 0.707901,
            "f1_weighted": 0.707973,
            "ap": 0.643966,
            "ap_weighted": 0.643966
          },
          {
            "accuracy": 0.702148,
            "f1": 0.702046,
            "f1_weighted": 0.702062,
            "ap": 0.641893,
            "ap_weighted": 0.641893
          },
          {
            "accuracy": 0.70459,
            "f1": 0.704104,
            "f1_weighted": 0.704139,
            "ap": 0.64237,
            "ap_weighted": 0.64237
          },
          {
            "accuracy": 0.686035,
            "f1": 0.684083,
            "f1_weighted": 0.68401,
            "ap": 0.635792,
            "ap_weighted": 0.635792
          },
          {
            "accuracy": 0.6875,
            "f1": 0.686723,
            "f1_weighted": 0.686769,
            "ap": 0.627059,
            "ap_weighted": 0.627059
          },
          {
            "accuracy": 0.711914,
            "f1": 0.711901,
            "f1_weighted": 0.711906,
            "ap": 0.651708,
            "ap_weighted": 0.651708
          },
          {
            "accuracy": 0.692871,
            "f1": 0.692845,
            "f1_weighted": 0.692853,
            "ap": 0.6344,
            "ap_weighted": 0.6344
          },
          {
            "accuracy": 0.711914,
            "f1": 0.709196,
            "f1_weighted": 0.709278,
            "ap": 0.644797,
            "ap_weighted": 0.644797
          }
        ],
        "main_score": 0.700342,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.697168,
        "f1": 0.694947,
        "f1_weighted": 0.694978,
        "ap": 0.63525,
        "ap_weighted": 0.63525,
        "scores_per_experiment": [
          {
            "accuracy": 0.692383,
            "f1": 0.683128,
            "f1_weighted": 0.683234,
            "ap": 0.624477,
            "ap_weighted": 0.624477
          },
          {
            "accuracy": 0.693848,
            "f1": 0.689103,
            "f1_weighted": 0.689178,
            "ap": 0.627827,
            "ap_weighted": 0.627827
          },
          {
            "accuracy": 0.711426,
            "f1": 0.709848,
            "f1_weighted": 0.70989,
            "ap": 0.645513,
            "ap_weighted": 0.645513
          },
          {
            "accuracy": 0.708984,
            "f1": 0.708904,
            "f1_weighted": 0.708914,
            "ap": 0.64771,
            "ap_weighted": 0.64771
          },
          {
            "accuracy": 0.688965,
            "f1": 0.688689,
            "f1_weighted": 0.688707,
            "ap": 0.629107,
            "ap_weighted": 0.629107
          },
          {
            "accuracy": 0.665527,
            "f1": 0.663395,
            "f1_weighted": 0.663343,
            "ap": 0.61648,
            "ap_weighted": 0.61648
          },
          {
            "accuracy": 0.682129,
            "f1": 0.681527,
            "f1_weighted": 0.681554,
            "ap": 0.622486,
            "ap_weighted": 0.622486
          },
          {
            "accuracy": 0.726562,
            "f1": 0.726458,
            "f1_weighted": 0.726469,
            "ap": 0.663621,
            "ap_weighted": 0.663621
          },
          {
            "accuracy": 0.696289,
            "f1": 0.69626,
            "f1_weighted": 0.696266,
            "ap": 0.636896,
            "ap_weighted": 0.636896
          },
          {
            "accuracy": 0.705566,
            "f1": 0.702161,
            "f1_weighted": 0.702223,
            "ap": 0.638387,
            "ap_weighted": 0.638387
          }
        ],
        "main_score": 0.697168,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 41.87981867790222,
  "kg_co2_emissions": 0.002491411992395867
}