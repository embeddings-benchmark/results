{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.291779,
        "recall": 0.323972,
        "f1": 0.297985,
        "accuracy": 0.323972,
        "main_score": 0.297985,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.500912,
        "recall": 0.580742,
        "f1": 0.521554,
        "accuracy": 0.580742,
        "main_score": 0.521554,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.259828,
        "recall": 0.32999,
        "f1": 0.273665,
        "accuracy": 0.32999,
        "main_score": 0.273665,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.238879,
        "recall": 0.320963,
        "f1": 0.25684,
        "accuracy": 0.320963,
        "main_score": 0.25684,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.631395,
        "recall": 0.695085,
        "f1": 0.648464,
        "accuracy": 0.695085,
        "main_score": 0.648464,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.571647,
        "recall": 0.657974,
        "f1": 0.593432,
        "accuracy": 0.657974,
        "main_score": 0.593432,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.284089,
        "recall": 0.363089,
        "f1": 0.301159,
        "accuracy": 0.363089,
        "main_score": 0.301159,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.310652,
        "recall": 0.40321,
        "f1": 0.331502,
        "accuracy": 0.40321,
        "main_score": 0.331502,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.212281,
        "recall": 0.263791,
        "f1": 0.222968,
        "accuracy": 0.263791,
        "main_score": 0.222968,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.245732,
        "recall": 0.326981,
        "f1": 0.262655,
        "accuracy": 0.326981,
        "main_score": 0.262655,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.399674,
        "recall": 0.476429,
        "f1": 0.417749,
        "accuracy": 0.476429,
        "main_score": 0.417749,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.401614,
        "recall": 0.496489,
        "f1": 0.424054,
        "accuracy": 0.496489,
        "main_score": 0.424054,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.479031,
        "recall": 0.570712,
        "f1": 0.501797,
        "accuracy": 0.570712,
        "main_score": 0.501797,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.418499,
        "recall": 0.510532,
        "f1": 0.440505,
        "accuracy": 0.510532,
        "main_score": 0.440505,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.450085,
        "recall": 0.530592,
        "f1": 0.469673,
        "accuracy": 0.530592,
        "main_score": 0.469673,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.316365,
        "recall": 0.392177,
        "f1": 0.333082,
        "accuracy": 0.392177,
        "main_score": 0.333082,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.205291,
        "recall": 0.250752,
        "f1": 0.214407,
        "accuracy": 0.250752,
        "main_score": 0.214407,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.190266,
        "recall": 0.260782,
        "f1": 0.20439,
        "accuracy": 0.260782,
        "main_score": 0.20439,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.093802,
        "recall": 0.120361,
        "f1": 0.0979,
        "accuracy": 0.120361,
        "main_score": 0.0979,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.159028,
        "recall": 0.229689,
        "f1": 0.174269,
        "accuracy": 0.229689,
        "main_score": 0.174269,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.421245,
        "recall": 0.496489,
        "f1": 0.438962,
        "accuracy": 0.496489,
        "main_score": 0.438962,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.348614,
        "recall": 0.437312,
        "f1": 0.369268,
        "accuracy": 0.437312,
        "main_score": 0.369268,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.505486,
        "recall": 0.580742,
        "f1": 0.524051,
        "accuracy": 0.580742,
        "main_score": 0.524051,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.441469,
        "recall": 0.514544,
        "f1": 0.458453,
        "accuracy": 0.514544,
        "main_score": 0.458453,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.206299,
        "recall": 0.264794,
        "f1": 0.217985,
        "accuracy": 0.264794,
        "main_score": 0.217985,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.253574,
        "recall": 0.338014,
        "f1": 0.272257,
        "accuracy": 0.338014,
        "main_score": 0.272257,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.280834,
        "recall": 0.354062,
        "f1": 0.296456,
        "accuracy": 0.354062,
        "main_score": 0.296456,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.241336,
        "recall": 0.306921,
        "f1": 0.255789,
        "accuracy": 0.306921,
        "main_score": 0.255789,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.017206,
        "recall": 0.024072,
        "f1": 0.018132,
        "accuracy": 0.024072,
        "main_score": 0.018132,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.041312,
        "recall": 0.07322,
        "f1": 0.046113,
        "accuracy": 0.07322,
        "main_score": 0.046113,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.209729,
        "recall": 0.272818,
        "f1": 0.222664,
        "accuracy": 0.272818,
        "main_score": 0.222664,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.181548,
        "recall": 0.261785,
        "f1": 0.197904,
        "accuracy": 0.261785,
        "main_score": 0.197904,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.535275,
        "recall": 0.603811,
        "f1": 0.552576,
        "accuracy": 0.603811,
        "main_score": 0.552576,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.456785,
        "recall": 0.547643,
        "f1": 0.479819,
        "accuracy": 0.547643,
        "main_score": 0.479819,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.500591,
        "recall": 0.570712,
        "f1": 0.518373,
        "accuracy": 0.570712,
        "main_score": 0.518373,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.42846,
        "recall": 0.517553,
        "f1": 0.449079,
        "accuracy": 0.517553,
        "main_score": 0.449079,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.001016,
        "recall": 0.003009,
        "f1": 0.001029,
        "accuracy": 0.003009,
        "main_score": 0.001029,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003158,
        "recall": 0.009027,
        "f1": 0.003628,
        "accuracy": 0.009027,
        "main_score": 0.003628,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.019387,
        "recall": 0.036108,
        "f1": 0.021453,
        "accuracy": 0.036108,
        "main_score": 0.021453,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031819,
        "recall": 0.061184,
        "f1": 0.036982,
        "accuracy": 0.061184,
        "main_score": 0.036982,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.49136,
        "recall": 0.564694,
        "f1": 0.509823,
        "accuracy": 0.564694,
        "main_score": 0.509823,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.438571,
        "recall": 0.520562,
        "f1": 0.457716,
        "accuracy": 0.520562,
        "main_score": 0.457716,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.172596,
        "recall": 0.221665,
        "f1": 0.18136,
        "accuracy": 0.221665,
        "main_score": 0.18136,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.16005,
        "recall": 0.231695,
        "f1": 0.174385,
        "accuracy": 0.231695,
        "main_score": 0.174385,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.45514,
        "recall": 0.528586,
        "f1": 0.473141,
        "accuracy": 0.528586,
        "main_score": 0.473141,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.381501,
        "recall": 0.478435,
        "f1": 0.404286,
        "accuracy": 0.478435,
        "main_score": 0.404286,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.405017,
        "recall": 0.486459,
        "f1": 0.424217,
        "accuracy": 0.486459,
        "main_score": 0.424217,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.362151,
        "recall": 0.448345,
        "f1": 0.38082,
        "accuracy": 0.448345,
        "main_score": 0.38082,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.459741,
        "recall": 0.535607,
        "f1": 0.477103,
        "accuracy": 0.535607,
        "main_score": 0.477103,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.40186,
        "recall": 0.494483,
        "f1": 0.423357,
        "accuracy": 0.494483,
        "main_score": 0.423357,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.008342,
        "recall": 0.017051,
        "f1": 0.009312,
        "accuracy": 0.017051,
        "main_score": 0.009312,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022715,
        "recall": 0.052156,
        "f1": 0.026886,
        "accuracy": 0.052156,
        "main_score": 0.026886,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.44645,
        "recall": 0.523571,
        "f1": 0.466056,
        "accuracy": 0.523571,
        "main_score": 0.466056,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.421314,
        "recall": 0.517553,
        "f1": 0.444646,
        "accuracy": 0.517553,
        "main_score": 0.444646,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.463764,
        "recall": 0.53661,
        "f1": 0.481096,
        "accuracy": 0.53661,
        "main_score": 0.481096,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.428731,
        "recall": 0.523571,
        "f1": 0.452517,
        "accuracy": 0.523571,
        "main_score": 0.452517,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000722,
        "recall": 0.006018,
        "f1": 0.001071,
        "accuracy": 0.006018,
        "main_score": 0.001071,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.352373,
        "recall": 0.401186,
        "f1": 0.362401,
        "accuracy": 0.401186,
        "main_score": 0.362401,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.521363,
        "recall": 0.600791,
        "f1": 0.542011,
        "accuracy": 0.600791,
        "main_score": 0.542011,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.211651,
        "recall": 0.274704,
        "f1": 0.224282,
        "accuracy": 0.274704,
        "main_score": 0.224282,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.238103,
        "recall": 0.31917,
        "f1": 0.255271,
        "accuracy": 0.31917,
        "main_score": 0.255271,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.623926,
        "recall": 0.689723,
        "f1": 0.64089,
        "accuracy": 0.689723,
        "main_score": 0.64089,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.572913,
        "recall": 0.658103,
        "f1": 0.595135,
        "accuracy": 0.658103,
        "main_score": 0.595135,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.265417,
        "recall": 0.333992,
        "f1": 0.279571,
        "accuracy": 0.333992,
        "main_score": 0.279571,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.277408,
        "recall": 0.36166,
        "f1": 0.296909,
        "accuracy": 0.36166,
        "main_score": 0.296909,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.213037,
        "recall": 0.256917,
        "f1": 0.221294,
        "accuracy": 0.256917,
        "main_score": 0.221294,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.275588,
        "recall": 0.360672,
        "f1": 0.293668,
        "accuracy": 0.360672,
        "main_score": 0.293668,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.408913,
        "recall": 0.482213,
        "f1": 0.426128,
        "accuracy": 0.482213,
        "main_score": 0.426128,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.40617,
        "recall": 0.500988,
        "f1": 0.428612,
        "accuracy": 0.500988,
        "main_score": 0.428612,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.472353,
        "recall": 0.555336,
        "f1": 0.492047,
        "accuracy": 0.555336,
        "main_score": 0.492047,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.41362,
        "recall": 0.501976,
        "f1": 0.435557,
        "accuracy": 0.501976,
        "main_score": 0.435557,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.407609,
        "recall": 0.498024,
        "f1": 0.430191,
        "accuracy": 0.498024,
        "main_score": 0.430191,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.252606,
        "recall": 0.302372,
        "f1": 0.263664,
        "accuracy": 0.302372,
        "main_score": 0.263664,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.168489,
        "recall": 0.198617,
        "f1": 0.173944,
        "accuracy": 0.198617,
        "main_score": 0.173944,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.164433,
        "recall": 0.219368,
        "f1": 0.174918,
        "accuracy": 0.219368,
        "main_score": 0.174918,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.099698,
        "recall": 0.139328,
        "f1": 0.106695,
        "accuracy": 0.139328,
        "main_score": 0.106695,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.164047,
        "recall": 0.231225,
        "f1": 0.178071,
        "accuracy": 0.231225,
        "main_score": 0.178071,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.409527,
        "recall": 0.478261,
        "f1": 0.425728,
        "accuracy": 0.478261,
        "main_score": 0.425728,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.376274,
        "recall": 0.475296,
        "f1": 0.399115,
        "accuracy": 0.475296,
        "main_score": 0.399115,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.450512,
        "recall": 0.518775,
        "f1": 0.466352,
        "accuracy": 0.518775,
        "main_score": 0.466352,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.399377,
        "recall": 0.468379,
        "f1": 0.416253,
        "accuracy": 0.468379,
        "main_score": 0.416253,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.223044,
        "recall": 0.283597,
        "f1": 0.234533,
        "accuracy": 0.283597,
        "main_score": 0.234533,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.243736,
        "recall": 0.331028,
        "f1": 0.262231,
        "accuracy": 0.331028,
        "main_score": 0.262231,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.246279,
        "recall": 0.3083,
        "f1": 0.258373,
        "accuracy": 0.3083,
        "main_score": 0.258373,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.245821,
        "recall": 0.336957,
        "f1": 0.265844,
        "accuracy": 0.336957,
        "main_score": 0.265844,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.021219,
        "recall": 0.029644,
        "f1": 0.02257,
        "accuracy": 0.029644,
        "main_score": 0.02257,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019983,
        "recall": 0.035573,
        "f1": 0.022671,
        "accuracy": 0.035573,
        "main_score": 0.022671,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.175273,
        "recall": 0.221344,
        "f1": 0.184253,
        "accuracy": 0.221344,
        "main_score": 0.184253,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.160568,
        "recall": 0.244071,
        "f1": 0.178299,
        "accuracy": 0.244071,
        "main_score": 0.178299,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.52385,
        "recall": 0.590909,
        "f1": 0.540013,
        "accuracy": 0.590909,
        "main_score": 0.540013,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.488771,
        "recall": 0.577075,
        "f1": 0.509549,
        "accuracy": 0.577075,
        "main_score": 0.509549,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.480927,
        "recall": 0.550395,
        "f1": 0.498026,
        "accuracy": 0.550395,
        "main_score": 0.498026,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.476119,
        "recall": 0.572134,
        "f1": 0.499703,
        "accuracy": 0.572134,
        "main_score": 0.499703,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.003953,
        "f1": 0.001349,
        "accuracy": 0.003953,
        "main_score": 0.001349,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004346,
        "recall": 0.014822,
        "f1": 0.005551,
        "accuracy": 0.014822,
        "main_score": 0.005551,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.022332,
        "recall": 0.037549,
        "f1": 0.024419,
        "accuracy": 0.037549,
        "main_score": 0.024419,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018718,
        "recall": 0.04249,
        "f1": 0.022674,
        "accuracy": 0.04249,
        "main_score": 0.022674,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.462116,
        "recall": 0.530632,
        "f1": 0.47876,
        "accuracy": 0.530632,
        "main_score": 0.47876,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.446563,
        "recall": 0.54249,
        "f1": 0.470918,
        "accuracy": 0.54249,
        "main_score": 0.470918,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.159137,
        "recall": 0.212451,
        "f1": 0.169555,
        "accuracy": 0.212451,
        "main_score": 0.169555,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.148815,
        "recall": 0.213439,
        "f1": 0.162779,
        "accuracy": 0.213439,
        "main_score": 0.162779,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.423576,
        "recall": 0.48913,
        "f1": 0.439536,
        "accuracy": 0.48913,
        "main_score": 0.439536,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.394557,
        "recall": 0.502964,
        "f1": 0.420132,
        "accuracy": 0.502964,
        "main_score": 0.420132,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.410521,
        "recall": 0.481225,
        "f1": 0.42714,
        "accuracy": 0.481225,
        "main_score": 0.42714,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.347179,
        "recall": 0.445652,
        "f1": 0.370989,
        "accuracy": 0.445652,
        "main_score": 0.370989,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.435152,
        "recall": 0.504941,
        "f1": 0.451883,
        "accuracy": 0.504941,
        "main_score": 0.451883,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.415027,
        "recall": 0.518775,
        "f1": 0.439453,
        "accuracy": 0.518775,
        "main_score": 0.439453,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.015482,
        "recall": 0.022727,
        "f1": 0.0166,
        "accuracy": 0.022727,
        "main_score": 0.0166,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022533,
        "recall": 0.046443,
        "f1": 0.02633,
        "accuracy": 0.046443,
        "main_score": 0.02633,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.442496,
        "recall": 0.514822,
        "f1": 0.460256,
        "accuracy": 0.514822,
        "main_score": 0.460256,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.430226,
        "recall": 0.537549,
        "f1": 0.457485,
        "accuracy": 0.537549,
        "main_score": 0.457485,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.455879,
        "recall": 0.52668,
        "f1": 0.472668,
        "accuracy": 0.52668,
        "main_score": 0.472668,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.422574,
        "recall": 0.514822,
        "f1": 0.445028,
        "accuracy": 0.514822,
        "main_score": 0.445028,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.000988,
        "recall": 0.000988,
        "f1": 0.000988,
        "accuracy": 0.000988,
        "main_score": 0.000988,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001457,
        "recall": 0.007905,
        "f1": 0.001819,
        "accuracy": 0.007905,
        "main_score": 0.001819,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 498.507511138916,
  "kg_co2_emissions": 0.041985109624671085
}