{
  "dataset_revision": "0c47583c9d339b3b6f89e4db76088af5f1ec8d39",
  "task_name": "SlovakMovieReviewSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.557666,
        "f1": 0.548601,
        "f1_weighted": 0.557132,
        "ap": 0.438617,
        "ap_weighted": 0.438617,
        "scores_per_experiment": [
          {
            "accuracy": 0.559082,
            "f1": 0.548398,
            "f1_weighted": 0.561626,
            "ap": 0.431961,
            "ap_weighted": 0.431961
          },
          {
            "accuracy": 0.496582,
            "f1": 0.473479,
            "f1_weighted": 0.494482,
            "ap": 0.393212,
            "ap_weighted": 0.393212
          },
          {
            "accuracy": 0.560547,
            "f1": 0.544011,
            "f1_weighted": 0.560547,
            "ap": 0.428738,
            "ap_weighted": 0.428738
          },
          {
            "accuracy": 0.600586,
            "f1": 0.586032,
            "f1_weighted": 0.600813,
            "ap": 0.45673,
            "ap_weighted": 0.45673
          },
          {
            "accuracy": 0.521484,
            "f1": 0.521017,
            "f1_weighted": 0.523867,
            "ap": 0.422859,
            "ap_weighted": 0.422859
          },
          {
            "accuracy": 0.580078,
            "f1": 0.566535,
            "f1_weighted": 0.581126,
            "ap": 0.44321,
            "ap_weighted": 0.44321
          },
          {
            "accuracy": 0.568848,
            "f1": 0.567957,
            "f1_weighted": 0.564221,
            "ap": 0.461415,
            "ap_weighted": 0.461415
          },
          {
            "accuracy": 0.570801,
            "f1": 0.564361,
            "f1_weighted": 0.574447,
            "ap": 0.443317,
            "ap_weighted": 0.443317
          },
          {
            "accuracy": 0.56543,
            "f1": 0.564589,
            "f1_weighted": 0.568233,
            "ap": 0.448716,
            "ap_weighted": 0.448716
          },
          {
            "accuracy": 0.553223,
            "f1": 0.549627,
            "f1_weighted": 0.541963,
            "ap": 0.456016,
            "ap_weighted": 0.456016
          }
        ],
        "main_score": 0.557666,
        "hf_subset": "default",
        "languages": [
          "svk-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 9.21439814567566,
  "kg_co2_emissions": 0.0003677611706022794
}