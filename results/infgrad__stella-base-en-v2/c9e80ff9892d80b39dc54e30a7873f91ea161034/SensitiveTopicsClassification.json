{
  "dataset_revision": "416b34a802308eac30e4192afc0ff99bb8dcc7f2",
  "task_name": "SensitiveTopicsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.17998,
        "f1": 0.02582,
        "lrap": 0.261202,
        "scores_per_experiment": [
          {
            "accuracy": 0.176758,
            "f1": 0.010103,
            "lrap": 0.257121
          },
          {
            "accuracy": 0.188965,
            "f1": 0.05024,
            "lrap": 0.271308
          },
          {
            "accuracy": 0.184082,
            "f1": 0.037017,
            "lrap": 0.264201
          },
          {
            "accuracy": 0.17334,
            "f1": 0.003989,
            "lrap": 0.254069
          },
          {
            "accuracy": 0.175781,
            "f1": 0.022133,
            "lrap": 0.256009
          },
          {
            "accuracy": 0.178223,
            "f1": 0.02419,
            "lrap": 0.26039
          },
          {
            "accuracy": 0.177246,
            "f1": 0.016574,
            "lrap": 0.261597
          },
          {
            "accuracy": 0.179688,
            "f1": 0.024782,
            "lrap": 0.259467
          },
          {
            "accuracy": 0.177734,
            "f1": 0.015205,
            "lrap": 0.256741
          },
          {
            "accuracy": 0.187988,
            "f1": 0.05397,
            "lrap": 0.271118
          }
        ],
        "main_score": 0.17998,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ]
      }
    ]
  },
  "evaluation_time": 5.5971519947052,
  "kg_co2_emissions": 0.0002415295080342498
}