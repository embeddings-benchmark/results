{
  "dataset_revision": "566be6449bb30b9b9f2b59173391647fe0ca3224",
  "task_name": "UrduRomanSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.422754,
        "f1": 0.405665,
        "f1_weighted": 0.422704,
        "scores_per_experiment": [
          {
            "accuracy": 0.481934,
            "f1": 0.449152,
            "f1_weighted": 0.473946
          },
          {
            "accuracy": 0.432617,
            "f1": 0.421603,
            "f1_weighted": 0.431242
          },
          {
            "accuracy": 0.422363,
            "f1": 0.41339,
            "f1_weighted": 0.428641
          },
          {
            "accuracy": 0.422852,
            "f1": 0.408937,
            "f1_weighted": 0.421579
          },
          {
            "accuracy": 0.362793,
            "f1": 0.333372,
            "f1_weighted": 0.355199
          },
          {
            "accuracy": 0.455078,
            "f1": 0.437043,
            "f1_weighted": 0.457922
          },
          {
            "accuracy": 0.454102,
            "f1": 0.438786,
            "f1_weighted": 0.462566
          },
          {
            "accuracy": 0.34375,
            "f1": 0.313551,
            "f1_weighted": 0.33458
          },
          {
            "accuracy": 0.420898,
            "f1": 0.41533,
            "f1_weighted": 0.42922
          },
          {
            "accuracy": 0.431152,
            "f1": 0.425488,
            "f1_weighted": 0.432141
          }
        ],
        "main_score": 0.405665,
        "hf_subset": "default",
        "languages": [
          "urd-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.7012128829956055,
  "kg_co2_emissions": 0.00024256225159526154
}