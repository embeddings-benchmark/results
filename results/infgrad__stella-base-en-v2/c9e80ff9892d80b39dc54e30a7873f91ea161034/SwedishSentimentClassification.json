{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.703027,
        "f1": 0.701064,
        "f1_weighted": 0.701048,
        "ap": 0.646031,
        "ap_weighted": 0.646031,
        "scores_per_experiment": [
          {
            "accuracy": 0.728516,
            "f1": 0.727051,
            "f1_weighted": 0.72711,
            "ap": 0.661064,
            "ap_weighted": 0.661064
          },
          {
            "accuracy": 0.682129,
            "f1": 0.680298,
            "f1_weighted": 0.680369,
            "ap": 0.621151,
            "ap_weighted": 0.621151
          },
          {
            "accuracy": 0.638672,
            "f1": 0.627019,
            "f1_weighted": 0.626826,
            "ap": 0.60108,
            "ap_weighted": 0.60108
          },
          {
            "accuracy": 0.706543,
            "f1": 0.706401,
            "f1_weighted": 0.706382,
            "ap": 0.649428,
            "ap_weighted": 0.649428
          },
          {
            "accuracy": 0.713379,
            "f1": 0.710125,
            "f1_weighted": 0.710035,
            "ap": 0.666302,
            "ap_weighted": 0.666302
          },
          {
            "accuracy": 0.676758,
            "f1": 0.676634,
            "f1_weighted": 0.676616,
            "ap": 0.622415,
            "ap_weighted": 0.622415
          },
          {
            "accuracy": 0.737305,
            "f1": 0.736841,
            "f1_weighted": 0.736873,
            "ap": 0.671945,
            "ap_weighted": 0.671945
          },
          {
            "accuracy": 0.730957,
            "f1": 0.730596,
            "f1_weighted": 0.730625,
            "ap": 0.666539,
            "ap_weighted": 0.666539
          },
          {
            "accuracy": 0.686035,
            "f1": 0.685699,
            "f1_weighted": 0.685669,
            "ap": 0.631612,
            "ap_weighted": 0.631612
          },
          {
            "accuracy": 0.72998,
            "f1": 0.729973,
            "f1_weighted": 0.729977,
            "ap": 0.668772,
            "ap_weighted": 0.668772
          }
        ],
        "main_score": 0.703027,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.697314,
        "f1": 0.695475,
        "f1_weighted": 0.695465,
        "ap": 0.640038,
        "ap_weighted": 0.640038,
        "scores_per_experiment": [
          {
            "accuracy": 0.720703,
            "f1": 0.719315,
            "f1_weighted": 0.719354,
            "ap": 0.653902,
            "ap_weighted": 0.653902
          },
          {
            "accuracy": 0.686523,
            "f1": 0.684694,
            "f1_weighted": 0.684741,
            "ap": 0.624301,
            "ap_weighted": 0.624301
          },
          {
            "accuracy": 0.631348,
            "f1": 0.620709,
            "f1_weighted": 0.620585,
            "ap": 0.592912,
            "ap_weighted": 0.592912
          },
          {
            "accuracy": 0.71582,
            "f1": 0.715712,
            "f1_weighted": 0.715701,
            "ap": 0.657401,
            "ap_weighted": 0.657401
          },
          {
            "accuracy": 0.69873,
            "f1": 0.69556,
            "f1_weighted": 0.695499,
            "ap": 0.65019,
            "ap_weighted": 0.65019
          },
          {
            "accuracy": 0.685547,
            "f1": 0.685542,
            "f1_weighted": 0.68554,
            "ap": 0.628458,
            "ap_weighted": 0.628458
          },
          {
            "accuracy": 0.740234,
            "f1": 0.739895,
            "f1_weighted": 0.739913,
            "ap": 0.674845,
            "ap_weighted": 0.674845
          },
          {
            "accuracy": 0.712891,
            "f1": 0.712574,
            "f1_weighted": 0.712592,
            "ap": 0.64986,
            "ap_weighted": 0.64986
          },
          {
            "accuracy": 0.666992,
            "f1": 0.666404,
            "f1_weighted": 0.666377,
            "ap": 0.614994,
            "ap_weighted": 0.614994
          },
          {
            "accuracy": 0.714355,
            "f1": 0.714344,
            "f1_weighted": 0.714348,
            "ap": 0.653516,
            "ap_weighted": 0.653516
          }
        ],
        "main_score": 0.697314,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 16.939812898635864,
  "kg_co2_emissions": 0.0006472486873024691
}