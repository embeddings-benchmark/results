{
  "dataset_revision": "2cc697991407cbbe34e7ef7bc9564449a4a99132",
  "task_name": "ToxicConversationsVNClassification",
  "mteb_version": "1.38.41",
  "scores": {
    "test": [
      {
        "accuracy": 0.666699,
        "f1": 0.496656,
        "f1_weighted": 0.743656,
        "ap": 0.104839,
        "ap_weighted": 0.104839,
        "scores_per_experiment": [
          {
            "accuracy": 0.795898,
            "f1": 0.542634,
            "f1_weighted": 0.83545,
            "ap": 0.095503,
            "ap_weighted": 0.095503
          },
          {
            "accuracy": 0.651367,
            "f1": 0.49,
            "f1_weighted": 0.736813,
            "ap": 0.102295,
            "ap_weighted": 0.102295
          },
          {
            "accuracy": 0.743164,
            "f1": 0.549898,
            "f1_weighted": 0.80365,
            "ap": 0.126489,
            "ap_weighted": 0.126489
          },
          {
            "accuracy": 0.729492,
            "f1": 0.522719,
            "f1_weighted": 0.792997,
            "ap": 0.101084,
            "ap_weighted": 0.101084
          },
          {
            "accuracy": 0.534668,
            "f1": 0.427822,
            "f1_weighted": 0.640548,
            "ap": 0.094141,
            "ap_weighted": 0.094141
          },
          {
            "accuracy": 0.52002,
            "f1": 0.410421,
            "f1_weighted": 0.629121,
            "ap": 0.082053,
            "ap_weighted": 0.082053
          },
          {
            "accuracy": 0.766113,
            "f1": 0.570045,
            "f1_weighted": 0.819844,
            "ap": 0.140281,
            "ap_weighted": 0.140281
          },
          {
            "accuracy": 0.632324,
            "f1": 0.472623,
            "f1_weighted": 0.722307,
            "ap": 0.092231,
            "ap_weighted": 0.092231
          },
          {
            "accuracy": 0.540039,
            "f1": 0.431159,
            "f1_weighted": 0.645273,
            "ap": 0.094965,
            "ap_weighted": 0.094965
          },
          {
            "accuracy": 0.753906,
            "f1": 0.549242,
            "f1_weighted": 0.81056,
            "ap": 0.119349,
            "ap_weighted": 0.119349
          }
        ],
        "main_score": 0.666699,
        "hf_subset": "default",
        "languages": [
          "vie-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.5060648918151855,
  "kg_co2_emissions": null
}