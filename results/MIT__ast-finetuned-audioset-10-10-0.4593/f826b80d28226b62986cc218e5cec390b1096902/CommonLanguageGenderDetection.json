{
  "dataset_revision": "65cdf4a4565f09b1747cd8fb37d18cd9aa1f6dd9",
  "task_name": "CommonLanguageGenderDetection",
  "mteb_version": "1.38.33",
  "scores": {
    "test": [
      {
        "accuracy": 0.5233,
        "f1": 0.350169,
        "f1_weighted": 0.640486,
        "scores_per_experiment": [
          {
            "accuracy": 0.4915,
            "f1": 0.329163,
            "f1_weighted": 0.621714
          },
          {
            "accuracy": 0.52,
            "f1": 0.346078,
            "f1_weighted": 0.639292
          },
          {
            "accuracy": 0.562,
            "f1": 0.356869,
            "f1_weighted": 0.662363
          },
          {
            "accuracy": 0.5335,
            "f1": 0.359689,
            "f1_weighted": 0.656625
          },
          {
            "accuracy": 0.5095,
            "f1": 0.359046,
            "f1_weighted": 0.622438
          }
        ],
        "main_score": 0.5233,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 3247.853232383728,
  "kg_co2_emissions": null
}