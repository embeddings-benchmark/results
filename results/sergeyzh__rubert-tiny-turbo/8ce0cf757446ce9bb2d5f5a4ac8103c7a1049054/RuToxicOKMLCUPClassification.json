{
  "dataset_revision": "13722b7320ef4b6a471f9e8b379f3f49167d0517",
  "task_name": "RuToxicOKMLCUPClassification",
  "mteb_version": "1.38.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.7484,
        "f1": 0.746853,
        "f1_weighted": 0.746853,
        "ap": 0.682316,
        "ap_weighted": 0.682316,
        "scores_per_experiment": [
          {
            "accuracy": 0.7665,
            "f1": 0.763972,
            "f1_weighted": 0.763972,
            "ap": 0.692092,
            "ap_weighted": 0.692092
          },
          {
            "accuracy": 0.796,
            "f1": 0.795604,
            "f1_weighted": 0.795604,
            "ap": 0.74407,
            "ap_weighted": 0.74407
          },
          {
            "accuracy": 0.7545,
            "f1": 0.754425,
            "f1_weighted": 0.754425,
            "ap": 0.694369,
            "ap_weighted": 0.694369
          },
          {
            "accuracy": 0.759,
            "f1": 0.756156,
            "f1_weighted": 0.756156,
            "ap": 0.684665,
            "ap_weighted": 0.684665
          },
          {
            "accuracy": 0.7415,
            "f1": 0.739978,
            "f1_weighted": 0.739978,
            "ap": 0.671333,
            "ap_weighted": 0.671333
          },
          {
            "accuracy": 0.7195,
            "f1": 0.716282,
            "f1_weighted": 0.716282,
            "ap": 0.64947,
            "ap_weighted": 0.64947
          },
          {
            "accuracy": 0.704,
            "f1": 0.70101,
            "f1_weighted": 0.70101,
            "ap": 0.63668,
            "ap_weighted": 0.63668
          },
          {
            "accuracy": 0.709,
            "f1": 0.708951,
            "f1_weighted": 0.708951,
            "ap": 0.649347,
            "ap_weighted": 0.649347
          },
          {
            "accuracy": 0.7675,
            "f1": 0.767451,
            "f1_weighted": 0.767451,
            "ap": 0.707443,
            "ap_weighted": 0.707443
          },
          {
            "accuracy": 0.7665,
            "f1": 0.764698,
            "f1_weighted": 0.764698,
            "ap": 0.693694,
            "ap_weighted": 0.693694
          }
        ],
        "main_score": 0.7484,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ]
      }
    ]
  },
  "evaluation_time": 5.789905786514282,
  "kg_co2_emissions": null
}