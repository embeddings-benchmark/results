{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.137066,
        "mrr": 0.119763,
        "nAUC_map_max": -0.146908,
        "nAUC_map_std": -0.126001,
        "nAUC_map_diff1": 0.125112,
        "nAUC_mrr_max": -0.148725,
        "nAUC_mrr_std": -0.125767,
        "nAUC_mrr_diff1": 0.12477,
        "main_score": 0.119763,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.113618,
        "mrr": 0.095919,
        "nAUC_map_max": -0.075051,
        "nAUC_map_std": -0.15672,
        "nAUC_map_diff1": 0.163291,
        "nAUC_mrr_max": -0.082153,
        "nAUC_mrr_std": -0.161558,
        "nAUC_mrr_diff1": 0.147775,
        "main_score": 0.095919,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.108068,
        "mrr": 0.094187,
        "nAUC_map_max": 0.012642,
        "nAUC_map_std": -0.209905,
        "nAUC_map_diff1": 0.26861,
        "nAUC_mrr_max": 0.00367,
        "nAUC_mrr_std": -0.209163,
        "nAUC_mrr_diff1": 0.268757,
        "main_score": 0.094187,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.116176,
        "mrr": 0.098535,
        "nAUC_map_max": -0.029869,
        "nAUC_map_std": -0.031974,
        "nAUC_map_diff1": 0.111513,
        "nAUC_mrr_max": -0.028402,
        "nAUC_mrr_std": -0.042007,
        "nAUC_mrr_diff1": 0.108725,
        "main_score": 0.098535,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.121769,
        "mrr": 0.105113,
        "nAUC_map_max": -0.054175,
        "nAUC_map_std": -0.08455,
        "nAUC_map_diff1": 0.188295,
        "nAUC_mrr_max": -0.053527,
        "nAUC_mrr_std": -0.088413,
        "nAUC_mrr_diff1": 0.192454,
        "main_score": 0.105113,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.106654,
        "mrr": 0.09149,
        "nAUC_map_max": 0.055081,
        "nAUC_map_std": -0.111621,
        "nAUC_map_diff1": 0.14715,
        "nAUC_mrr_max": 0.056019,
        "nAUC_mrr_std": -0.117745,
        "nAUC_mrr_diff1": 0.147073,
        "main_score": 0.09149,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 773.8798537254333,
  "kg_co2_emissions": 0.02903424186723693
}