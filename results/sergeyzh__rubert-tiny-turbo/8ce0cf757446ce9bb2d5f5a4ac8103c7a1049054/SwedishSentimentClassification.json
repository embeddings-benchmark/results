{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.722998,
        "f1": 0.721671,
        "f1_weighted": 0.721678,
        "ap": 0.663054,
        "ap_weighted": 0.663054,
        "scores_per_experiment": [
          {
            "accuracy": 0.698242,
            "f1": 0.687128,
            "f1_weighted": 0.687301,
            "ap": 0.628673,
            "ap_weighted": 0.628673
          },
          {
            "accuracy": 0.717285,
            "f1": 0.716295,
            "f1_weighted": 0.716246,
            "ap": 0.663844,
            "ap_weighted": 0.663844
          },
          {
            "accuracy": 0.744629,
            "f1": 0.744607,
            "f1_weighted": 0.7446,
            "ap": 0.684789,
            "ap_weighted": 0.684789
          },
          {
            "accuracy": 0.71875,
            "f1": 0.71844,
            "f1_weighted": 0.718467,
            "ap": 0.655619,
            "ap_weighted": 0.655619
          },
          {
            "accuracy": 0.73584,
            "f1": 0.735829,
            "f1_weighted": 0.735824,
            "ap": 0.675745,
            "ap_weighted": 0.675745
          },
          {
            "accuracy": 0.727051,
            "f1": 0.727043,
            "f1_weighted": 0.727039,
            "ap": 0.667123,
            "ap_weighted": 0.667123
          },
          {
            "accuracy": 0.719727,
            "f1": 0.719532,
            "f1_weighted": 0.71951,
            "ap": 0.662383,
            "ap_weighted": 0.662383
          },
          {
            "accuracy": 0.745605,
            "f1": 0.745601,
            "f1_weighted": 0.745604,
            "ap": 0.684055,
            "ap_weighted": 0.684055
          },
          {
            "accuracy": 0.700684,
            "f1": 0.700065,
            "f1_weighted": 0.700025,
            "ap": 0.646246,
            "ap_weighted": 0.646246
          },
          {
            "accuracy": 0.722168,
            "f1": 0.722167,
            "f1_weighted": 0.722166,
            "ap": 0.662061,
            "ap_weighted": 0.662061
          }
        ],
        "main_score": 0.722998,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.725488,
        "f1": 0.724139,
        "f1_weighted": 0.72414,
        "ap": 0.665456,
        "ap_weighted": 0.665456,
        "scores_per_experiment": [
          {
            "accuracy": 0.707031,
            "f1": 0.696471,
            "f1_weighted": 0.696582,
            "ap": 0.635402,
            "ap_weighted": 0.635402
          },
          {
            "accuracy": 0.719238,
            "f1": 0.718255,
            "f1_weighted": 0.718222,
            "ap": 0.665233,
            "ap_weighted": 0.665233
          },
          {
            "accuracy": 0.746094,
            "f1": 0.746059,
            "f1_weighted": 0.746053,
            "ap": 0.686067,
            "ap_weighted": 0.686067
          },
          {
            "accuracy": 0.716797,
            "f1": 0.716342,
            "f1_weighted": 0.716364,
            "ap": 0.652816,
            "ap_weighted": 0.652816
          },
          {
            "accuracy": 0.734863,
            "f1": 0.734724,
            "f1_weighted": 0.734712,
            "ap": 0.676275,
            "ap_weighted": 0.676275
          },
          {
            "accuracy": 0.727051,
            "f1": 0.72693,
            "f1_weighted": 0.726919,
            "ap": 0.66836,
            "ap_weighted": 0.66836
          },
          {
            "accuracy": 0.726562,
            "f1": 0.726261,
            "f1_weighted": 0.726243,
            "ap": 0.669313,
            "ap_weighted": 0.669313
          },
          {
            "accuracy": 0.744141,
            "f1": 0.744137,
            "f1_weighted": 0.744139,
            "ap": 0.682183,
            "ap_weighted": 0.682183
          },
          {
            "accuracy": 0.697266,
            "f1": 0.69639,
            "f1_weighted": 0.696358,
            "ap": 0.643317,
            "ap_weighted": 0.643317
          },
          {
            "accuracy": 0.73584,
            "f1": 0.735817,
            "f1_weighted": 0.735812,
            "ap": 0.67559,
            "ap_weighted": 0.67559
          }
        ],
        "main_score": 0.725488,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 16.995654821395874,
  "kg_co2_emissions": 0.0005026618160870946
}