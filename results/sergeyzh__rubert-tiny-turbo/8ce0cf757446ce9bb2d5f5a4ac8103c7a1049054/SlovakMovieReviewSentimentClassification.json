{
  "dataset_revision": "0c47583c9d339b3b6f89e4db76088af5f1ec8d39",
  "task_name": "SlovakMovieReviewSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.539307,
        "f1": 0.533492,
        "f1_weighted": 0.540825,
        "ap": 0.429629,
        "ap_weighted": 0.429629,
        "scores_per_experiment": [
          {
            "accuracy": 0.534668,
            "f1": 0.534609,
            "f1_weighted": 0.533614,
            "ap": 0.435328,
            "ap_weighted": 0.435328
          },
          {
            "accuracy": 0.469727,
            "f1": 0.466388,
            "f1_weighted": 0.474426,
            "ap": 0.392068,
            "ap_weighted": 0.392068
          },
          {
            "accuracy": 0.504395,
            "f1": 0.47094,
            "f1_weighted": 0.496274,
            "ap": 0.393261,
            "ap_weighted": 0.393261
          },
          {
            "accuracy": 0.554688,
            "f1": 0.549584,
            "f1_weighted": 0.558714,
            "ap": 0.434549,
            "ap_weighted": 0.434549
          },
          {
            "accuracy": 0.524414,
            "f1": 0.524377,
            "f1_weighted": 0.525173,
            "ap": 0.426981,
            "ap_weighted": 0.426981
          },
          {
            "accuracy": 0.536133,
            "f1": 0.532275,
            "f1_weighted": 0.540364,
            "ap": 0.424944,
            "ap_weighted": 0.424944
          },
          {
            "accuracy": 0.53125,
            "f1": 0.531239,
            "f1_weighted": 0.531675,
            "ap": 0.431467,
            "ap_weighted": 0.431467
          },
          {
            "accuracy": 0.586914,
            "f1": 0.578815,
            "f1_weighted": 0.589937,
            "ap": 0.45247,
            "ap_weighted": 0.45247
          },
          {
            "accuracy": 0.564453,
            "f1": 0.562289,
            "f1_weighted": 0.56815,
            "ap": 0.445016,
            "ap_weighted": 0.445016
          },
          {
            "accuracy": 0.586426,
            "f1": 0.5844,
            "f1_weighted": 0.589926,
            "ap": 0.460206,
            "ap_weighted": 0.460206
          }
        ],
        "main_score": 0.539307,
        "hf_subset": "default",
        "languages": [
          "svk-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.119289875030518,
  "kg_co2_emissions": 0.00021220981112463928
}