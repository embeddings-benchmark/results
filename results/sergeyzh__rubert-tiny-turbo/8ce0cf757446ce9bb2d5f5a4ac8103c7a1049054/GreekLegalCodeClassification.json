{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.019531,
        "f1": 0.008226,
        "f1_weighted": 0.009272,
        "scores_per_experiment": [
          {
            "accuracy": 0.018066,
            "f1": 0.010623,
            "f1_weighted": 0.008009
          },
          {
            "accuracy": 0.019531,
            "f1": 0.008646,
            "f1_weighted": 0.009163
          },
          {
            "accuracy": 0.019043,
            "f1": 0.006634,
            "f1_weighted": 0.00889
          },
          {
            "accuracy": 0.01416,
            "f1": 0.007032,
            "f1_weighted": 0.005169
          },
          {
            "accuracy": 0.018066,
            "f1": 0.008308,
            "f1_weighted": 0.01019
          },
          {
            "accuracy": 0.023926,
            "f1": 0.01092,
            "f1_weighted": 0.014648
          },
          {
            "accuracy": 0.018066,
            "f1": 0.006702,
            "f1_weighted": 0.009494
          },
          {
            "accuracy": 0.023926,
            "f1": 0.008068,
            "f1_weighted": 0.011146
          },
          {
            "accuracy": 0.021484,
            "f1": 0.007838,
            "f1_weighted": 0.008574
          },
          {
            "accuracy": 0.019043,
            "f1": 0.007491,
            "f1_weighted": 0.007434
          }
        ],
        "main_score": 0.019531,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.018115,
        "f1": 0.006573,
        "f1_weighted": 0.008154,
        "scores_per_experiment": [
          {
            "accuracy": 0.021484,
            "f1": 0.009513,
            "f1_weighted": 0.008978
          },
          {
            "accuracy": 0.019531,
            "f1": 0.007699,
            "f1_weighted": 0.008503
          },
          {
            "accuracy": 0.014648,
            "f1": 0.00928,
            "f1_weighted": 0.008424
          },
          {
            "accuracy": 0.013184,
            "f1": 0.005392,
            "f1_weighted": 0.005585
          },
          {
            "accuracy": 0.014648,
            "f1": 0.004651,
            "f1_weighted": 0.008293
          },
          {
            "accuracy": 0.018555,
            "f1": 0.004197,
            "f1_weighted": 0.007755
          },
          {
            "accuracy": 0.018555,
            "f1": 0.006562,
            "f1_weighted": 0.01091
          },
          {
            "accuracy": 0.018066,
            "f1": 0.004817,
            "f1_weighted": 0.006773
          },
          {
            "accuracy": 0.018066,
            "f1": 0.006009,
            "f1_weighted": 0.008018
          },
          {
            "accuracy": 0.024414,
            "f1": 0.007609,
            "f1_weighted": 0.008305
          }
        ],
        "main_score": 0.018115,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 169.50828909873962,
  "kg_co2_emissions": 0.006767052222730535
}