{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.1.14",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.318172,
            "f1": 0.296186,
            "f1_weighted": 0.296155,
            "precision": 0.312204,
            "precision_weighted": 0.312178,
            "recall": 0.318218,
            "recall_weighted": 0.318172,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.301895,
            "f1": 0.287286,
            "f1_weighted": 0.287264,
            "precision": 0.30265,
            "precision_weighted": 0.302681,
            "recall": 0.301932,
            "recall_weighted": 0.301895,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.325307,
            "f1": 0.30962,
            "f1_weighted": 0.309646,
            "precision": 0.32752,
            "precision_weighted": 0.327586,
            "recall": 0.325287,
            "recall_weighted": 0.325307,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.323746,
            "f1": 0.302137,
            "f1_weighted": 0.302191,
            "precision": 0.314509,
            "precision_weighted": 0.314501,
            "recall": 0.323673,
            "recall_weighted": 0.323746,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.299443,
            "f1": 0.273696,
            "f1_weighted": 0.27375,
            "precision": 0.30088,
            "precision_weighted": 0.300827,
            "recall": 0.299318,
            "recall_weighted": 0.299443,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.322631,
            "f1": 0.303191,
            "f1_weighted": 0.303127,
            "precision": 0.316178,
            "precision_weighted": 0.316132,
            "recall": 0.322652,
            "recall_weighted": 0.322631,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.313043,
            "f1": 0.291531,
            "f1_weighted": 0.291537,
            "precision": 0.317688,
            "precision_weighted": 0.317709,
            "recall": 0.312996,
            "recall_weighted": 0.313043,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.292754,
            "f1": 0.269374,
            "f1_weighted": 0.269331,
            "precision": 0.286524,
            "precision_weighted": 0.286441,
            "recall": 0.292809,
            "recall_weighted": 0.292754,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.306355,
            "f1": 0.293062,
            "f1_weighted": 0.293001,
            "precision": 0.299573,
            "precision_weighted": 0.299536,
            "recall": 0.306444,
            "recall_weighted": 0.306355,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.316165,
            "f1": 0.295141,
            "f1_weighted": 0.295115,
            "precision": 0.308119,
            "precision_weighted": 0.308065,
            "recall": 0.316143,
            "recall_weighted": 0.316165,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.311951,
        "f1": 0.292122,
        "f1_weighted": 0.292112,
        "precision": 0.308584,
        "precision_weighted": 0.308566,
        "recall": 0.311947,
        "recall_weighted": 0.311951,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.292122,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 80.29181218147278,
  "kg_co2_emissions": null
}