{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.13335,
        "mrr": 0.11554,
        "nAUC_map_max": 0.00788,
        "nAUC_map_std": 0.01211,
        "nAUC_map_diff1": 0.179053,
        "nAUC_mrr_max": 0.011645,
        "nAUC_mrr_std": 0.010009,
        "nAUC_mrr_diff1": 0.173886,
        "main_score": 0.11554,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.111342,
        "mrr": 0.093577,
        "nAUC_map_max": 0.138505,
        "nAUC_map_std": 0.179912,
        "nAUC_map_diff1": 0.080262,
        "nAUC_mrr_max": 0.143288,
        "nAUC_mrr_std": 0.168985,
        "nAUC_mrr_diff1": 0.075134,
        "main_score": 0.093577,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.080787,
        "mrr": 0.062231,
        "nAUC_map_max": -0.054124,
        "nAUC_map_std": 0.215784,
        "nAUC_map_diff1": -0.094412,
        "nAUC_mrr_max": -0.065745,
        "nAUC_mrr_std": 0.156284,
        "nAUC_mrr_diff1": -0.085275,
        "main_score": 0.062231,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.112046,
        "mrr": 0.091643,
        "nAUC_map_max": 0.024009,
        "nAUC_map_std": -0.022021,
        "nAUC_map_diff1": 0.005903,
        "nAUC_mrr_max": 0.024191,
        "nAUC_mrr_std": -0.021753,
        "nAUC_mrr_diff1": -0.002343,
        "main_score": 0.091643,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.106396,
        "mrr": 0.087813,
        "nAUC_map_max": 0.025987,
        "nAUC_map_std": 0.12279,
        "nAUC_map_diff1": 0.008658,
        "nAUC_mrr_max": 0.025606,
        "nAUC_mrr_std": 0.100501,
        "nAUC_mrr_diff1": 0.014655,
        "main_score": 0.087813,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.089272,
        "mrr": 0.071883,
        "nAUC_map_max": 0.157878,
        "nAUC_map_std": 0.19634,
        "nAUC_map_diff1": 0.060458,
        "nAUC_mrr_max": 0.165423,
        "nAUC_mrr_std": 0.183867,
        "nAUC_mrr_diff1": 0.063698,
        "main_score": 0.071883,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 6885.274266242981,
  "kg_co2_emissions": 0.6521997475347465
}