{
  "dataset_revision": "f333c1fcfa3ab43f008a327c8bd0140441354d34",
  "task_name": "BrazilianToxicTweetsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.213135,
        "f1": 0.154663,
        "lrap": 0.783717,
        "scores_per_experiment": [
          {
            "accuracy": 0.195801,
            "f1": 0.153336,
            "lrap": 0.799845
          },
          {
            "accuracy": 0.178711,
            "f1": 0.146329,
            "lrap": 0.775865
          },
          {
            "accuracy": 0.19043,
            "f1": 0.154158,
            "lrap": 0.801364
          },
          {
            "accuracy": 0.197754,
            "f1": 0.156565,
            "lrap": 0.790283
          },
          {
            "accuracy": 0.297363,
            "f1": 0.142221,
            "lrap": 0.765584
          },
          {
            "accuracy": 0.196289,
            "f1": 0.195798,
            "lrap": 0.813761
          },
          {
            "accuracy": 0.259766,
            "f1": 0.142496,
            "lrap": 0.750366
          },
          {
            "accuracy": 0.138184,
            "f1": 0.178668,
            "lrap": 0.792169
          },
          {
            "accuracy": 0.228027,
            "f1": 0.137813,
            "lrap": 0.762126
          },
          {
            "accuracy": 0.249023,
            "f1": 0.13925,
            "lrap": 0.785807
          }
        ],
        "main_score": 0.213135,
        "hf_subset": "default",
        "languages": [
          "por-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 5.3065526485443115,
  "kg_co2_emissions": 0.0002557714489372515
}