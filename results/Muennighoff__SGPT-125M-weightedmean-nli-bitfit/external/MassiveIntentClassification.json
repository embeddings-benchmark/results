{
    "dataset_revision": "072a486a144adf7f4479a4a0dddb2152e161e1ea",
    "task_name": "MassiveIntentClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.3779421654337593,
                "f1": 0.3681580701507746,
                "main_score": 0.3779421654337593
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.23722259583053126,
                "f1": 0.23235269695764274,
                "main_score": 0.23722259583053126
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.2964021519838601,
                "f1": 0.28273175327650135,
                "main_score": 0.2964021519838601
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.394754539340955,
                "f1": 0.39259973614151206,
                "main_score": 0.394754539340955
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.26550100874243443,
                "f1": 0.25607924873522975,
                "main_score": 0.26550100874243443
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.38782784129119036,
                "f1": 0.3764180582626517,
                "main_score": 0.38782784129119036
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.43557498318762605,
                "f1": 0.4135305173800667,
                "main_score": 0.43557498318762605
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.4039340954942838,
                "f1": 0.38333932195289344,
                "main_score": 0.4039340954942838
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.3728648285137861,
                "f1": 0.36640059066802844,
                "main_score": 0.3728648285137861
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.5808002689979825,
                "f1": 0.5649243881660991,
                "main_score": 0.5808002689979825
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.41176866173503707,
                "f1": 0.4066779962225799,
                "main_score": 0.41176866173503707
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.36422326832548757,
                "f1": 0.346441738042885,
                "main_score": 0.36422326832548757
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.3875588433086752,
                "f1": 0.3726725894668694,
                "main_score": 0.3875588433086752
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.4367182246133153,
                "f1": 0.423518466245666,
                "main_score": 0.4367182246133153
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.3198049764626766,
                "f1": 0.3055792887280901,
                "main_score": 0.3198049764626766
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.2803967720242098,
                "f1": 0.28428418145508305,
                "main_score": 0.2803967720242098
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.3813718897108272,
                "f1": 0.3705740698819687,
                "main_score": 0.3813718897108272
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.2605245460659045,
                "f1": 0.2525483953344816,
                "main_score": 0.2605245460659045
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.41156691324815065,
                "f1": 0.4083715033247605,
                "main_score": 0.41156691324815065
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.3862811028917284,
                "f1": 0.3767691901246032,
                "main_score": 0.3862811028917284
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.440383322125084,
                "f1": 0.43772590108774556,
                "main_score": 0.440383322125084
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.46207128446536655,
                "f1": 0.44666328759408236,
                "main_score": 0.46207128446536655
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.3760591795561533,
                "f1": 0.36581071742378013,
                "main_score": 0.3760591795561533
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.2447209145931405,
                "f1": 0.24238209697895605,
                "main_score": 0.2447209145931405
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.2623739071956961,
                "f1": 0.2537878315084505,
                "main_score": 0.2623739071956961
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.17831203765971754,
                "f1": 0.17275078420466344,
                "main_score": 0.17831203765971754
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.37266308002689974,
                "f1": 0.3692473791708214,
                "main_score": 0.37266308002689974
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.4093140551445864,
                "f1": 0.40825227889641963,
                "main_score": 0.4093140551445864
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.1788500336247478,
                "f1": 0.17621569082971816,
                "main_score": 0.1788500336247478
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.3297579018157364,
                "f1": 0.33402014633349664,
                "main_score": 0.3297579018157364
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.40911230665770015,
                "f1": 0.4009538559124075,
                "main_score": 0.40911230665770015
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.17834566240753194,
                "f1": 0.17006381849454313,
                "main_score": 0.17834566240753194
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.3947881640887693,
                "f1": 0.37819934317839304,
                "main_score": 0.3947881640887693
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.4176193678547412,
                "f1": 0.40281991759509694,
                "main_score": 0.4176193678547412
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.4261936785474109,
                "f1": 0.4083673914649905,
                "main_score": 0.4261936785474109
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.4454270342972427,
                "f1": 0.43452431642784484,
                "main_score": 0.4454270342972427
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.3996973772696705,
                "f1": 0.3874209466530094,
                "main_score": 0.3996973772696705
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.37461331540013454,
                "f1": 0.3691132021821187,
                "main_score": 0.37461331540013454
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.38288500336247483,
                "f1": 0.3737259394049676,
                "main_score": 0.38288500336247483
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.4095494283792872,
                "f1": 0.3976770790286908,
                "main_score": 0.4095494283792872
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.41852723604572956,
                "f1": 0.4042848260365438,
                "main_score": 0.41852723604572956
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.38328850033624756,
                "f1": 0.3690334596675622,
                "main_score": 0.38328850033624756
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.19031607262945527,
                "f1": 0.1866510306325761,
                "main_score": 0.19031607262945527
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.19384667114996637,
                "f1": 0.19186399376652535,
                "main_score": 0.19384667114996637
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.34088769334229996,
                "f1": 0.3420383086009429,
                "main_score": 0.34088769334229996
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.40285810356422325,
                "f1": 0.39361500249640413,
                "main_score": 0.40285810356422325
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.38860121049092133,
                "f1": 0.37819168596272346,
                "main_score": 0.38860121049092133
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.27834566240753195,
                "f1": 0.26898389386106486,
                "main_score": 0.27834566240753195
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.3870544720914593,
                "f1": 0.3828002644202442,
                "main_score": 0.3870544720914593
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.4578009414929387,
                "f1": 0.4421526778674136,
                "main_score": 0.4578009414929387
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.4232010759919301,
                "f1": 0.4225772977490916,
                "main_score": 0.4232010759919301
            }
        ]
    }
}