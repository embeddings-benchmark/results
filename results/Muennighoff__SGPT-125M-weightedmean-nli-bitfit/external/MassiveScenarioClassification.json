{
    "dataset_revision": "7d571f92784cd94a019292a1f45445077d0ef634",
    "task_name": "MassiveScenarioClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "af",
                "languages": [
                    "afr-Latn"
                ],
                "accuracy": 0.40245460659045057,
                "f1": 0.3879924050989544,
                "main_score": 0.40245460659045057
            },
            {
                "hf_subset": "am",
                "languages": [
                    "amh-Ethi"
                ],
                "accuracy": 0.2568930733019502,
                "f1": 0.2548816627916271,
                "main_score": 0.2568930733019502
            },
            {
                "hf_subset": "ar",
                "languages": [
                    "ara-Arab"
                ],
                "accuracy": 0.3239744451916611,
                "f1": 0.31863029579075774,
                "main_score": 0.3239744451916611
            },
            {
                "hf_subset": "az",
                "languages": [
                    "aze-Latn"
                ],
                "accuracy": 0.40531271015467385,
                "f1": 0.3970707903394894,
                "main_score": 0.40531271015467385
            },
            {
                "hf_subset": "bn",
                "languages": [
                    "ben-Beng"
                ],
                "accuracy": 0.2723268325487559,
                "f1": 0.2644365328185879,
                "main_score": 0.2723268325487559
            },
            {
                "hf_subset": "cy",
                "languages": [
                    "cym-Latn"
                ],
                "accuracy": 0.3869872225958305,
                "f1": 0.3655930387892567,
                "main_score": 0.3869872225958305
            },
            {
                "hf_subset": "da",
                "languages": [
                    "dan-Latn"
                ],
                "accuracy": 0.4475453934095494,
                "f1": 0.4287356484024154,
                "main_score": 0.4475453934095494
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.41355077336919976,
                "f1": 0.3982365179458047,
                "main_score": 0.41355077336919976
            },
            {
                "hf_subset": "el",
                "languages": [
                    "ell-Grek"
                ],
                "accuracy": 0.3843981170141224,
                "f1": 0.3702538368296387,
                "main_score": 0.3843981170141224
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6633826496301277,
                "f1": 0.6589634765029931,
                "main_score": 0.6633826496301277
            },
            {
                "hf_subset": "es",
                "languages": [
                    "spa-Latn"
                ],
                "accuracy": 0.4417955615332885,
                "f1": 0.4310228811620319,
                "main_score": 0.4417955615332885
            },
            {
                "hf_subset": "fa",
                "languages": [
                    "fas-Arab"
                ],
                "accuracy": 0.3482851378614661,
                "f1": 0.3395952441502803,
                "main_score": 0.3482851378614661
            },
            {
                "hf_subset": "fi",
                "languages": [
                    "fin-Latn"
                ],
                "accuracy": 0.40561533288500334,
                "f1": 0.38049390117336274,
                "main_score": 0.40561533288500334
            },
            {
                "hf_subset": "fr",
                "languages": [
                    "fra-Latn"
                ],
                "accuracy": 0.45917955615332884,
                "f1": 0.4465741971572902,
                "main_score": 0.45917955615332884
            },
            {
                "hf_subset": "he",
                "languages": [
                    "heb-Hebr"
                ],
                "accuracy": 0.3208473436449227,
                "f1": 0.2953932929808133,
                "main_score": 0.3208473436449227
            },
            {
                "hf_subset": "hi",
                "languages": [
                    "hin-Deva"
                ],
                "accuracy": 0.28369199731002015,
                "f1": 0.2752902837981212,
                "main_score": 0.28369199731002015
            },
            {
                "hf_subset": "hu",
                "languages": [
                    "hun-Latn"
                ],
                "accuracy": 0.3949226630800269,
                "f1": 0.37327234047050406,
                "main_score": 0.3949226630800269
            },
            {
                "hf_subset": "hy",
                "languages": [
                    "hye-Armn"
                ],
                "accuracy": 0.2590450571620713,
                "f1": 0.24547396574853445,
                "main_score": 0.2590450571620713
            },
            {
                "hf_subset": "id",
                "languages": [
                    "ind-Latn"
                ],
                "accuracy": 0.4095830531271016,
                "f1": 0.40177843177422223,
                "main_score": 0.4095830531271016
            },
            {
                "hf_subset": "is",
                "languages": [
                    "isl-Latn"
                ],
                "accuracy": 0.38564223268325487,
                "f1": 0.3735307758495248,
                "main_score": 0.38564223268325487
            },
            {
                "hf_subset": "it",
                "languages": [
                    "ita-Latn"
                ],
                "accuracy": 0.4658708809683928,
                "f1": 0.44103900526804984,
                "main_score": 0.4658708809683928
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.4624747814391393,
                "f1": 0.454107101796664,
                "main_score": 0.4624747814391393
            },
            {
                "hf_subset": "jv",
                "languages": [
                    "jav-Latn"
                ],
                "accuracy": 0.396570275722932,
                "f1": 0.3882737576832412,
                "main_score": 0.396570275722932
            },
            {
                "hf_subset": "ka",
                "languages": [
                    "kat-Geor"
                ],
                "accuracy": 0.2527908540685945,
                "f1": 0.23662661686788491,
                "main_score": 0.2527908540685945
            },
            {
                "hf_subset": "km",
                "languages": [
                    "khm-Khmr"
                ],
                "accuracy": 0.2897108271687962,
                "f1": 0.27195758324189245,
                "main_score": 0.2897108271687962
            },
            {
                "hf_subset": "kn",
                "languages": [
                    "kan-Knda"
                ],
                "accuracy": 0.1927370544720915,
                "f1": 0.18694271924323635,
                "main_score": 0.1927370544720915
            },
            {
                "hf_subset": "ko",
                "languages": [
                    "kor-Kore"
                ],
                "accuracy": 0.3572965702757229,
                "f1": 0.34382870061773085,
                "main_score": 0.3572965702757229
            },
            {
                "hf_subset": "lv",
                "languages": [
                    "lav-Latn"
                ],
                "accuracy": 0.3957296570275723,
                "f1": 0.38074945140886923,
                "main_score": 0.3957296570275723
            },
            {
                "hf_subset": "ml",
                "languages": [
                    "mal-Mlym"
                ],
                "accuracy": 0.1989576328177539,
                "f1": 0.20009313648468288,
                "main_score": 0.1989576328177539
            },
            {
                "hf_subset": "mn",
                "languages": [
                    "mon-Cyrl"
                ],
                "accuracy": 0.32431069266980495,
                "f1": 0.31395958664782575,
                "main_score": 0.32431069266980495
            },
            {
                "hf_subset": "ms",
                "languages": [
                    "msa-Latn"
                ],
                "accuracy": 0.4232347007397445,
                "f1": 0.40813740263147014,
                "main_score": 0.4232347007397445
            },
            {
                "hf_subset": "my",
                "languages": [
                    "mya-Mymr"
                ],
                "accuracy": 0.20864156018829857,
                "f1": 0.20409870408935438,
                "main_score": 0.20864156018829857
            },
            {
                "hf_subset": "nb",
                "languages": [
                    "nob-Latn"
                ],
                "accuracy": 0.4047074646940148,
                "f1": 0.3919044149415904,
                "main_score": 0.4047074646940148
            },
            {
                "hf_subset": "nl",
                "languages": [
                    "nld-Latn"
                ],
                "accuracy": 0.43591123066577,
                "f1": 0.4143420363064241,
                "main_score": 0.43591123066577
            },
            {
                "hf_subset": "pl",
                "languages": [
                    "pol-Latn"
                ],
                "accuracy": 0.41876260928043046,
                "f1": 0.41192117676667617,
                "main_score": 0.41876260928043046
            },
            {
                "hf_subset": "pt",
                "languages": [
                    "por-Latn"
                ],
                "accuracy": 0.4630800268997983,
                "f1": 0.4525536730126799,
                "main_score": 0.4630800268997983
            },
            {
                "hf_subset": "ro",
                "languages": [
                    "ron-Latn"
                ],
                "accuracy": 0.42525218560860784,
                "f1": 0.4102418109296485,
                "main_score": 0.42525218560860784
            },
            {
                "hf_subset": "ru",
                "languages": [
                    "rus-Cyrl"
                ],
                "accuracy": 0.3594821788836584,
                "f1": 0.3508598314806566,
                "main_score": 0.3594821788836584
            },
            {
                "hf_subset": "sl",
                "languages": [
                    "slv-Latn"
                ],
                "accuracy": 0.3869199731002017,
                "f1": 0.3768119408674127,
                "main_score": 0.3869199731002017
            },
            {
                "hf_subset": "sq",
                "languages": [
                    "sqi-Latn"
                ],
                "accuracy": 0.4047410894418292,
                "f1": 0.39480530387013596,
                "main_score": 0.4047410894418292
            },
            {
                "hf_subset": "sv",
                "languages": [
                    "swe-Latn"
                ],
                "accuracy": 0.41523201075991933,
                "f1": 0.40200979960243827,
                "main_score": 0.41523201075991933
            },
            {
                "hf_subset": "sw",
                "languages": [
                    "swa-Latn"
                ],
                "accuracy": 0.39549428379287155,
                "f1": 0.3818556124333806,
                "main_score": 0.39549428379287155
            },
            {
                "hf_subset": "ta",
                "languages": [
                    "tam-Taml"
                ],
                "accuracy": 0.228782784129119,
                "f1": 0.22239467186721457,
                "main_score": 0.228782784129119
            },
            {
                "hf_subset": "te",
                "languages": [
                    "tel-Telu"
                ],
                "accuracy": 0.2051445864156019,
                "f1": 0.19999047885530216,
                "main_score": 0.2051445864156019
            },
            {
                "hf_subset": "th",
                "languages": [
                    "tha-Thai"
                ],
                "accuracy": 0.34926025554808343,
                "f1": 0.3324016717215723,
                "main_score": 0.34926025554808343
            },
            {
                "hf_subset": "tl",
                "languages": [
                    "tgl-Latn"
                ],
                "accuracy": 0.4074983187626093,
                "f1": 0.3930274328728882,
                "main_score": 0.4074983187626093
            },
            {
                "hf_subset": "tr",
                "languages": [
                    "tur-Latn"
                ],
                "accuracy": 0.39068594485541364,
                "f1": 0.3921542039662971,
                "main_score": 0.39068594485541364
            },
            {
                "hf_subset": "ur",
                "languages": [
                    "urd-Arab"
                ],
                "accuracy": 0.29747814391392063,
                "f1": 0.2826183689222045,
                "main_score": 0.29747814391392063
            },
            {
                "hf_subset": "vi",
                "languages": [
                    "vie-Latn"
                ],
                "accuracy": 0.3802286482851379,
                "f1": 0.378742438608697,
                "main_score": 0.3802286482851379
            },
            {
                "hf_subset": "zh-CN",
                "languages": [
                    "cmo-Hans"
                ],
                "accuracy": 0.48550773369199723,
                "f1": 0.467399625882649,
                "main_score": 0.48550773369199723
            },
            {
                "hf_subset": "zh-TW",
                "languages": [
                    "cmo-Hant"
                ],
                "accuracy": 0.45178211163416276,
                "f1": 0.4484809741811729,
                "main_score": 0.45178211163416276
            }
        ]
    }
}