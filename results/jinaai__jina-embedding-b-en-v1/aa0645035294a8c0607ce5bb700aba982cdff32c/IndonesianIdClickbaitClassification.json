{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.560645,
        "f1": 0.549371,
        "f1_weighted": 0.553293,
        "ap": 0.459212,
        "ap_weighted": 0.459212,
        "scores_per_experiment": [
          {
            "accuracy": 0.604492,
            "f1": 0.597912,
            "f1_weighted": 0.6062,
            "ap": 0.480218,
            "ap_weighted": 0.480218
          },
          {
            "accuracy": 0.508789,
            "f1": 0.491465,
            "f1_weighted": 0.476341,
            "ap": 0.447256,
            "ap_weighted": 0.447256
          },
          {
            "accuracy": 0.553223,
            "f1": 0.504028,
            "f1_weighted": 0.529197,
            "ap": 0.427698,
            "ap_weighted": 0.427698
          },
          {
            "accuracy": 0.59082,
            "f1": 0.590664,
            "f1_weighted": 0.589376,
            "ap": 0.484269,
            "ap_weighted": 0.484269
          },
          {
            "accuracy": 0.614746,
            "f1": 0.593038,
            "f1_weighted": 0.608183,
            "ap": 0.478658,
            "ap_weighted": 0.478658
          },
          {
            "accuracy": 0.445801,
            "f1": 0.443524,
            "f1_weighted": 0.449259,
            "ap": 0.396734,
            "ap_weighted": 0.396734
          },
          {
            "accuracy": 0.553223,
            "f1": 0.544273,
            "f1_weighted": 0.533982,
            "ap": 0.470345,
            "ap_weighted": 0.470345
          },
          {
            "accuracy": 0.604492,
            "f1": 0.604468,
            "f1_weighted": 0.604966,
            "ap": 0.491596,
            "ap_weighted": 0.491596
          },
          {
            "accuracy": 0.555664,
            "f1": 0.549888,
            "f1_weighted": 0.558104,
            "ap": 0.447869,
            "ap_weighted": 0.447869
          },
          {
            "accuracy": 0.575195,
            "f1": 0.574445,
            "f1_weighted": 0.577324,
            "ap": 0.467474,
            "ap_weighted": 0.467474
          }
        ],
        "main_score": 0.549371,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 9.501707315444946,
  "kg_co2_emissions": 0.00028571196104461814
}