{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.122579,
        "recall": 0.164062,
        "f1": 0.134001,
        "accuracy": 0.164062,
        "main_score": 0.134001,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.080507,
        "recall": 0.128906,
        "f1": 0.092215,
        "accuracy": 0.128906,
        "main_score": 0.092215,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.043217,
        "recall": 0.076172,
        "f1": 0.050898,
        "accuracy": 0.076172,
        "main_score": 0.050898,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 6.2e-05,
        "recall": 0.001953,
        "f1": 0.000117,
        "accuracy": 0.001953,
        "main_score": 0.000117,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.050311,
        "recall": 0.094727,
        "f1": 0.058735,
        "accuracy": 0.094727,
        "main_score": 0.058735,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.093353,
        "recall": 0.140625,
        "f1": 0.104106,
        "accuracy": 0.140625,
        "main_score": 0.104106,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.065889,
        "recall": 0.111328,
        "f1": 0.076083,
        "accuracy": 0.111328,
        "main_score": 0.076083,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.081277,
        "recall": 0.112305,
        "f1": 0.087616,
        "accuracy": 0.112305,
        "main_score": 0.087616,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.009189,
        "recall": 0.030273,
        "f1": 0.011898,
        "accuracy": 0.030273,
        "main_score": 0.011898,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.117636,
        "recall": 0.166016,
        "f1": 0.13058,
        "accuracy": 0.166016,
        "main_score": 0.13058,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.018068,
        "recall": 0.039062,
        "f1": 0.021368,
        "accuracy": 0.039062,
        "main_score": 0.021368,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.088452,
        "recall": 0.125977,
        "f1": 0.097208,
        "accuracy": 0.125977,
        "main_score": 0.097208,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.105378,
        "recall": 0.151367,
        "f1": 0.117535,
        "accuracy": 0.151367,
        "main_score": 0.117535,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.113479,
        "recall": 0.164062,
        "f1": 0.126446,
        "accuracy": 0.164062,
        "main_score": 0.126446,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.117441,
        "recall": 0.157227,
        "f1": 0.126997,
        "accuracy": 0.157227,
        "main_score": 0.126997,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.015455,
        "recall": 0.041016,
        "f1": 0.019163,
        "accuracy": 0.041016,
        "main_score": 0.019163,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.050796,
        "recall": 0.076172,
        "f1": 0.056525,
        "accuracy": 0.076172,
        "main_score": 0.056525,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.076939,
        "recall": 0.114258,
        "f1": 0.085109,
        "accuracy": 0.114258,
        "main_score": 0.085109,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.051233,
        "recall": 0.089844,
        "f1": 0.060052,
        "accuracy": 0.089844,
        "main_score": 0.060052,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.027986,
        "recall": 0.053711,
        "f1": 0.032383,
        "accuracy": 0.053711,
        "main_score": 0.032383,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.032508,
        "recall": 0.060547,
        "f1": 0.038146,
        "accuracy": 0.060547,
        "main_score": 0.038146,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.008961,
        "recall": 0.021484,
        "f1": 0.010946,
        "accuracy": 0.021484,
        "main_score": 0.010946,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.10768,
        "recall": 0.150391,
        "f1": 0.118095,
        "accuracy": 0.150391,
        "main_score": 0.118095,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.053192,
        "recall": 0.098633,
        "f1": 0.063668,
        "accuracy": 0.098633,
        "main_score": 0.063668,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.026501,
        "recall": 0.053711,
        "f1": 0.032416,
        "accuracy": 0.053711,
        "main_score": 0.032416,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 8.3e-05,
        "recall": 0.001953,
        "f1": 0.000153,
        "accuracy": 0.001953,
        "main_score": 0.000153,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0441,
        "recall": 0.085938,
        "f1": 0.053611,
        "accuracy": 0.085938,
        "main_score": 0.053611,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.083919,
        "recall": 0.121094,
        "f1": 0.092795,
        "accuracy": 0.121094,
        "main_score": 0.092795,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.044841,
        "recall": 0.079102,
        "f1": 0.052676,
        "accuracy": 0.079102,
        "main_score": 0.052676,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.076096,
        "recall": 0.104492,
        "f1": 0.082814,
        "accuracy": 0.104492,
        "main_score": 0.082814,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004878,
        "recall": 0.021484,
        "f1": 0.0073,
        "accuracy": 0.021484,
        "main_score": 0.0073,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.105278,
        "recall": 0.146484,
        "f1": 0.116033,
        "accuracy": 0.146484,
        "main_score": 0.116033,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.022295,
        "recall": 0.042969,
        "f1": 0.026173,
        "accuracy": 0.042969,
        "main_score": 0.026173,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.087828,
        "recall": 0.119141,
        "f1": 0.095359,
        "accuracy": 0.119141,
        "main_score": 0.095359,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.093034,
        "recall": 0.123047,
        "f1": 0.100629,
        "accuracy": 0.123047,
        "main_score": 0.100629,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.109978,
        "recall": 0.148438,
        "f1": 0.120532,
        "accuracy": 0.148438,
        "main_score": 0.120532,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.088218,
        "recall": 0.123047,
        "f1": 0.09716,
        "accuracy": 0.123047,
        "main_score": 0.09716,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.019224,
        "recall": 0.039062,
        "f1": 0.022041,
        "accuracy": 0.039062,
        "main_score": 0.022041,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.042566,
        "recall": 0.06543,
        "f1": 0.047638,
        "accuracy": 0.06543,
        "main_score": 0.047638,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.122179,
        "recall": 0.168945,
        "f1": 0.13334,
        "accuracy": 0.168945,
        "main_score": 0.13334,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.040256,
        "recall": 0.073242,
        "f1": 0.047768,
        "accuracy": 0.073242,
        "main_score": 0.047768,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.03453,
        "recall": 0.0625,
        "f1": 0.040253,
        "accuracy": 0.0625,
        "main_score": 0.040253,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.033994,
        "recall": 0.055664,
        "f1": 0.038872,
        "accuracy": 0.055664,
        "main_score": 0.038872,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.009531,
        "recall": 0.021484,
        "f1": 0.011873,
        "accuracy": 0.021484,
        "main_score": 0.011873,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.096769,
        "recall": 0.134766,
        "f1": 0.106125,
        "accuracy": 0.134766,
        "main_score": 0.106125,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.061422,
        "recall": 0.099609,
        "f1": 0.069973,
        "accuracy": 0.099609,
        "main_score": 0.069973,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.263769,
        "recall": 0.299805,
        "f1": 0.273887,
        "accuracy": 0.299805,
        "main_score": 0.273887,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.012053,
        "recall": 0.02832,
        "f1": 0.014758,
        "accuracy": 0.02832,
        "main_score": 0.014758,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.323751,
        "recall": 0.367188,
        "f1": 0.336532,
        "accuracy": 0.367188,
        "main_score": 0.336532,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.117904,
        "recall": 0.185547,
        "f1": 0.133479,
        "accuracy": 0.185547,
        "main_score": 0.133479,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.294836,
        "recall": 0.332031,
        "f1": 0.304922,
        "accuracy": 0.332031,
        "main_score": 0.304922,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.065101,
        "recall": 0.09668,
        "f1": 0.072706,
        "accuracy": 0.09668,
        "main_score": 0.072706,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.237421,
        "recall": 0.264648,
        "f1": 0.244501,
        "accuracy": 0.264648,
        "main_score": 0.244501,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.05158,
        "recall": 0.083984,
        "f1": 0.058339,
        "accuracy": 0.083984,
        "main_score": 0.058339,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.263003,
        "recall": 0.291016,
        "f1": 0.271233,
        "accuracy": 0.291016,
        "main_score": 0.271233,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.060819,
        "recall": 0.086914,
        "f1": 0.067259,
        "accuracy": 0.086914,
        "main_score": 0.067259,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.063016,
        "recall": 0.099609,
        "f1": 0.070703,
        "accuracy": 0.099609,
        "main_score": 0.070703,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.065941,
        "recall": 0.099609,
        "f1": 0.073512,
        "accuracy": 0.099609,
        "main_score": 0.073512,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.075566,
        "recall": 0.109375,
        "f1": 0.083748,
        "accuracy": 0.109375,
        "main_score": 0.083748,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.25541,
        "recall": 0.289062,
        "f1": 0.263655,
        "accuracy": 0.289062,
        "main_score": 0.263655,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.029423,
        "recall": 0.050781,
        "f1": 0.034357,
        "accuracy": 0.050781,
        "main_score": 0.034357,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.032719,
        "recall": 0.058594,
        "f1": 0.037325,
        "accuracy": 0.058594,
        "main_score": 0.037325,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.285354,
        "recall": 0.319336,
        "f1": 0.295092,
        "accuracy": 0.319336,
        "main_score": 0.295092,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.279757,
        "recall": 0.313477,
        "f1": 0.288742,
        "accuracy": 0.313477,
        "main_score": 0.288742,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.290752,
        "recall": 0.331055,
        "f1": 0.301575,
        "accuracy": 0.331055,
        "main_score": 0.301575,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.241888,
        "recall": 0.263672,
        "f1": 0.247509,
        "accuracy": 0.263672,
        "main_score": 0.247509,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.041636,
        "recall": 0.068359,
        "f1": 0.047805,
        "accuracy": 0.068359,
        "main_score": 0.047805,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.029945,
        "recall": 0.049805,
        "f1": 0.034474,
        "accuracy": 0.049805,
        "main_score": 0.034474,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.2627,
        "recall": 0.291016,
        "f1": 0.270255,
        "accuracy": 0.291016,
        "main_score": 0.270255,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.027091,
        "recall": 0.040039,
        "f1": 0.029205,
        "accuracy": 0.040039,
        "main_score": 0.029205,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.255002,
        "recall": 0.286133,
        "f1": 0.263294,
        "accuracy": 0.286133,
        "main_score": 0.263294,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.074381,
        "recall": 0.131836,
        "f1": 0.086603,
        "accuracy": 0.131836,
        "main_score": 0.086603,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.321436,
        "recall": 0.375,
        "f1": 0.336347,
        "accuracy": 0.375,
        "main_score": 0.336347,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.012953,
        "recall": 0.023438,
        "f1": 0.01448,
        "accuracy": 0.023438,
        "main_score": 0.01448,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.243817,
        "recall": 0.276367,
        "f1": 0.251576,
        "accuracy": 0.276367,
        "main_score": 0.251576,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.061786,
        "recall": 0.09375,
        "f1": 0.069669,
        "accuracy": 0.09375,
        "main_score": 0.069669,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.216305,
        "recall": 0.243164,
        "f1": 0.22417,
        "accuracy": 0.243164,
        "main_score": 0.22417,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.024957,
        "recall": 0.041016,
        "f1": 0.027567,
        "accuracy": 0.041016,
        "main_score": 0.027567,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.044446,
        "recall": 0.067383,
        "f1": 0.049371,
        "accuracy": 0.067383,
        "main_score": 0.049371,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.032039,
        "recall": 0.055664,
        "f1": 0.036609,
        "accuracy": 0.055664,
        "main_score": 0.036609,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.040778,
        "recall": 0.063477,
        "f1": 0.045561,
        "accuracy": 0.063477,
        "main_score": 0.045561,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.259465,
        "recall": 0.293945,
        "f1": 0.267306,
        "accuracy": 0.293945,
        "main_score": 0.267306,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.010402,
        "recall": 0.019531,
        "f1": 0.011733,
        "accuracy": 0.019531,
        "main_score": 0.011733,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.069204,
        "recall": 0.106445,
        "f1": 0.078107,
        "accuracy": 0.106445,
        "main_score": 0.078107,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.33608,
        "recall": 0.387695,
        "f1": 0.350713,
        "accuracy": 0.387695,
        "main_score": 0.350713,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.250399,
        "recall": 0.274414,
        "f1": 0.257021,
        "accuracy": 0.274414,
        "main_score": 0.257021,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.246232,
        "recall": 0.272461,
        "f1": 0.253967,
        "accuracy": 0.272461,
        "main_score": 0.253967,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.248187,
        "recall": 0.277344,
        "f1": 0.255439,
        "accuracy": 0.277344,
        "main_score": 0.255439,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001171,
        "recall": 0.005859,
        "f1": 0.001339,
        "accuracy": 0.005859,
        "main_score": 0.001339,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.000243,
        "recall": 0.006836,
        "f1": 0.000457,
        "accuracy": 0.006836,
        "main_score": 0.000457,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.021293,
        "recall": 0.056641,
        "f1": 0.025921,
        "accuracy": 0.056641,
        "main_score": 0.025921,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.0153,
        "recall": 0.051758,
        "f1": 0.019586,
        "accuracy": 0.051758,
        "main_score": 0.019586,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.020703,
        "recall": 0.050781,
        "f1": 0.025295,
        "accuracy": 0.050781,
        "main_score": 0.025295,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.00451,
        "recall": 0.029297,
        "f1": 0.00681,
        "accuracy": 0.029297,
        "main_score": 0.00681,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.021594,
        "recall": 0.049805,
        "f1": 0.02511,
        "accuracy": 0.049805,
        "main_score": 0.02511,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001783,
        "recall": 0.009766,
        "f1": 0.002224,
        "accuracy": 0.009766,
        "main_score": 0.002224,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.017314,
        "recall": 0.053711,
        "f1": 0.021362,
        "accuracy": 0.053711,
        "main_score": 0.021362,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.000872,
        "recall": 0.007812,
        "f1": 0.001412,
        "accuracy": 0.007812,
        "main_score": 0.001412,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.011291,
        "recall": 0.036133,
        "f1": 0.015037,
        "accuracy": 0.036133,
        "main_score": 0.015037,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000336,
        "recall": 0.004883,
        "f1": 0.000594,
        "accuracy": 0.004883,
        "main_score": 0.000594,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000648,
        "recall": 0.007812,
        "f1": 0.000961,
        "accuracy": 0.007812,
        "main_score": 0.000961,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.000763,
        "recall": 0.007812,
        "f1": 0.001169,
        "accuracy": 0.007812,
        "main_score": 0.001169,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.00226,
        "recall": 0.007812,
        "f1": 0.002524,
        "accuracy": 0.007812,
        "main_score": 0.002524,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.02381,
        "recall": 0.058594,
        "f1": 0.028157,
        "accuracy": 0.058594,
        "main_score": 0.028157,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000482,
        "recall": 0.006836,
        "f1": 0.000792,
        "accuracy": 0.006836,
        "main_score": 0.000792,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000724,
        "recall": 0.009766,
        "f1": 0.001275,
        "accuracy": 0.009766,
        "main_score": 0.001275,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.019828,
        "recall": 0.048828,
        "f1": 0.023329,
        "accuracy": 0.048828,
        "main_score": 0.023329,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.020915,
        "recall": 0.050781,
        "f1": 0.025131,
        "accuracy": 0.050781,
        "main_score": 0.025131,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.02493,
        "recall": 0.058594,
        "f1": 0.030216,
        "accuracy": 0.058594,
        "main_score": 0.030216,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.014124,
        "recall": 0.041992,
        "f1": 0.018124,
        "accuracy": 0.041992,
        "main_score": 0.018124,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.045694,
        "recall": 0.075195,
        "f1": 0.052304,
        "accuracy": 0.075195,
        "main_score": 0.052304,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.052287,
        "recall": 0.083984,
        "f1": 0.05866,
        "accuracy": 0.083984,
        "main_score": 0.05866,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.313327,
        "recall": 0.356445,
        "f1": 0.324244,
        "accuracy": 0.356445,
        "main_score": 0.324244,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.255173,
        "recall": 0.292969,
        "f1": 0.265101,
        "accuracy": 0.292969,
        "main_score": 0.265101,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.015909,
        "recall": 0.02832,
        "f1": 0.017866,
        "accuracy": 0.02832,
        "main_score": 0.017866,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.121405,
        "recall": 0.191406,
        "f1": 0.137424,
        "accuracy": 0.191406,
        "main_score": 0.137424,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.264466,
        "recall": 0.304688,
        "f1": 0.274685,
        "accuracy": 0.304688,
        "main_score": 0.274685,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.091237,
        "recall": 0.128906,
        "f1": 0.100099,
        "accuracy": 0.128906,
        "main_score": 0.100099,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.210413,
        "recall": 0.242188,
        "f1": 0.218764,
        "accuracy": 0.242188,
        "main_score": 0.218764,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.052081,
        "recall": 0.081055,
        "f1": 0.058521,
        "accuracy": 0.081055,
        "main_score": 0.058521,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.254794,
        "recall": 0.289062,
        "f1": 0.264409,
        "accuracy": 0.289062,
        "main_score": 0.264409,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.068578,
        "recall": 0.108398,
        "f1": 0.078547,
        "accuracy": 0.108398,
        "main_score": 0.078547,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.049433,
        "recall": 0.082031,
        "f1": 0.056477,
        "accuracy": 0.082031,
        "main_score": 0.056477,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.045331,
        "recall": 0.082031,
        "f1": 0.052916,
        "accuracy": 0.082031,
        "main_score": 0.052916,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.054171,
        "recall": 0.092773,
        "f1": 0.062987,
        "accuracy": 0.092773,
        "main_score": 0.062987,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.244007,
        "recall": 0.271484,
        "f1": 0.251059,
        "accuracy": 0.271484,
        "main_score": 0.251059,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.041669,
        "recall": 0.067383,
        "f1": 0.046825,
        "accuracy": 0.067383,
        "main_score": 0.046825,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.027537,
        "recall": 0.055664,
        "f1": 0.032486,
        "accuracy": 0.055664,
        "main_score": 0.032486,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.259428,
        "recall": 0.293945,
        "f1": 0.26914,
        "accuracy": 0.293945,
        "main_score": 0.26914,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.300357,
        "recall": 0.342773,
        "f1": 0.31175,
        "accuracy": 0.342773,
        "main_score": 0.31175,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.318652,
        "recall": 0.360352,
        "f1": 0.330167,
        "accuracy": 0.360352,
        "main_score": 0.330167,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.212744,
        "recall": 0.241211,
        "f1": 0.220365,
        "accuracy": 0.241211,
        "main_score": 0.220365,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.088089,
        "recall": 0.133789,
        "f1": 0.098683,
        "accuracy": 0.133789,
        "main_score": 0.098683,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.072634,
        "recall": 0.117188,
        "f1": 0.08381,
        "accuracy": 0.117188,
        "main_score": 0.08381,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.140835,
        "recall": 0.177734,
        "f1": 0.148605,
        "accuracy": 0.177734,
        "main_score": 0.148605,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.104379,
        "recall": 0.129883,
        "f1": 0.109927,
        "accuracy": 0.129883,
        "main_score": 0.109927,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003053,
        "recall": 0.006836,
        "f1": 0.003605,
        "accuracy": 0.006836,
        "main_score": 0.003605,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.140617,
        "recall": 0.180664,
        "f1": 0.150529,
        "accuracy": 0.180664,
        "main_score": 0.150529,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.122279,
        "recall": 0.160156,
        "f1": 0.131073,
        "accuracy": 0.160156,
        "main_score": 0.131073,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.098876,
        "recall": 0.135742,
        "f1": 0.108157,
        "accuracy": 0.135742,
        "main_score": 0.108157,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.077274,
        "recall": 0.092773,
        "f1": 0.079621,
        "accuracy": 0.092773,
        "main_score": 0.079621,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.085675,
        "recall": 0.129883,
        "f1": 0.097224,
        "accuracy": 0.129883,
        "main_score": 0.097224,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.099389,
        "recall": 0.125,
        "f1": 0.104707,
        "accuracy": 0.125,
        "main_score": 0.104707,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.107517,
        "recall": 0.150391,
        "f1": 0.118688,
        "accuracy": 0.150391,
        "main_score": 0.118688,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.073161,
        "recall": 0.114258,
        "f1": 0.082475,
        "accuracy": 0.114258,
        "main_score": 0.082475,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.065528,
        "recall": 0.102539,
        "f1": 0.074755,
        "accuracy": 0.102539,
        "main_score": 0.074755,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.079252,
        "recall": 0.121094,
        "f1": 0.088237,
        "accuracy": 0.121094,
        "main_score": 0.088237,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.093293,
        "recall": 0.114258,
        "f1": 0.096884,
        "accuracy": 0.114258,
        "main_score": 0.096884,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.049318,
        "recall": 0.079102,
        "f1": 0.055371,
        "accuracy": 0.079102,
        "main_score": 0.055371,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.040221,
        "recall": 0.069336,
        "f1": 0.046846,
        "accuracy": 0.069336,
        "main_score": 0.046846,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.130191,
        "recall": 0.158203,
        "f1": 0.136605,
        "accuracy": 0.158203,
        "main_score": 0.136605,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.111913,
        "recall": 0.137695,
        "f1": 0.117843,
        "accuracy": 0.137695,
        "main_score": 0.117843,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.119881,
        "recall": 0.148438,
        "f1": 0.126867,
        "accuracy": 0.148438,
        "main_score": 0.126867,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.078139,
        "recall": 0.088867,
        "f1": 0.079739,
        "accuracy": 0.088867,
        "main_score": 0.079739,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.060731,
        "recall": 0.09375,
        "f1": 0.068405,
        "accuracy": 0.09375,
        "main_score": 0.068405,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.042684,
        "recall": 0.071289,
        "f1": 0.048893,
        "accuracy": 0.071289,
        "main_score": 0.048893,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.283504,
        "recall": 0.31543,
        "f1": 0.291876,
        "accuracy": 0.31543,
        "main_score": 0.291876,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.324195,
        "recall": 0.379883,
        "f1": 0.340421,
        "accuracy": 0.379883,
        "main_score": 0.340421,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.013973,
        "recall": 0.027344,
        "f1": 0.015903,
        "accuracy": 0.027344,
        "main_score": 0.015903,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.254662,
        "recall": 0.286133,
        "f1": 0.263418,
        "accuracy": 0.286133,
        "main_score": 0.263418,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.083213,
        "recall": 0.138672,
        "f1": 0.095154,
        "accuracy": 0.138672,
        "main_score": 0.095154,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.025424,
        "recall": 0.041992,
        "f1": 0.028305,
        "accuracy": 0.041992,
        "main_score": 0.028305,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.242057,
        "recall": 0.274414,
        "f1": 0.249896,
        "accuracy": 0.274414,
        "main_score": 0.249896,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.078752,
        "recall": 0.113281,
        "f1": 0.087533,
        "accuracy": 0.113281,
        "main_score": 0.087533,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.22524,
        "recall": 0.251953,
        "f1": 0.232403,
        "accuracy": 0.251953,
        "main_score": 0.232403,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.029274,
        "recall": 0.048828,
        "f1": 0.03289,
        "accuracy": 0.048828,
        "main_score": 0.03289,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.061738,
        "recall": 0.087891,
        "f1": 0.068157,
        "accuracy": 0.087891,
        "main_score": 0.068157,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.037462,
        "recall": 0.060547,
        "f1": 0.042717,
        "accuracy": 0.060547,
        "main_score": 0.042717,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.06073,
        "recall": 0.089844,
        "f1": 0.067923,
        "accuracy": 0.089844,
        "main_score": 0.067923,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.249954,
        "recall": 0.28418,
        "f1": 0.258223,
        "accuracy": 0.28418,
        "main_score": 0.258223,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.015763,
        "recall": 0.03125,
        "f1": 0.018474,
        "accuracy": 0.03125,
        "main_score": 0.018474,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.059037,
        "recall": 0.09082,
        "f1": 0.066439,
        "accuracy": 0.09082,
        "main_score": 0.066439,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.376392,
        "recall": 0.423828,
        "f1": 0.389933,
        "accuracy": 0.423828,
        "main_score": 0.389933,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.245689,
        "recall": 0.275391,
        "f1": 0.253529,
        "accuracy": 0.275391,
        "main_score": 0.253529,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.245109,
        "recall": 0.276367,
        "f1": 0.253672,
        "accuracy": 0.276367,
        "main_score": 0.253672,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.267014,
        "recall": 0.292969,
        "f1": 0.273314,
        "accuracy": 0.292969,
        "main_score": 0.273314,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.074361,
        "recall": 0.117188,
        "f1": 0.084352,
        "accuracy": 0.117188,
        "main_score": 0.084352,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.08322,
        "recall": 0.129883,
        "f1": 0.094546,
        "accuracy": 0.129883,
        "main_score": 0.094546,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.052074,
        "recall": 0.099609,
        "f1": 0.061876,
        "accuracy": 0.099609,
        "main_score": 0.061876,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.020491,
        "recall": 0.045898,
        "f1": 0.02498,
        "accuracy": 0.045898,
        "main_score": 0.02498,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001361,
        "recall": 0.003906,
        "f1": 0.001576,
        "accuracy": 0.003906,
        "main_score": 0.001576,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.063473,
        "recall": 0.118164,
        "f1": 0.076616,
        "accuracy": 0.118164,
        "main_score": 0.076616,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.090957,
        "recall": 0.133789,
        "f1": 0.101749,
        "accuracy": 0.133789,
        "main_score": 0.101749,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.02101,
        "recall": 0.055664,
        "f1": 0.027475,
        "accuracy": 0.055664,
        "main_score": 0.027475,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003727,
        "recall": 0.018555,
        "f1": 0.005681,
        "accuracy": 0.018555,
        "main_score": 0.005681,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.065605,
        "recall": 0.103516,
        "f1": 0.07452,
        "accuracy": 0.103516,
        "main_score": 0.07452,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.047125,
        "recall": 0.084961,
        "f1": 0.054757,
        "accuracy": 0.084961,
        "main_score": 0.054757,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.108595,
        "recall": 0.145508,
        "f1": 0.118514,
        "accuracy": 0.145508,
        "main_score": 0.118514,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.050358,
        "recall": 0.086914,
        "f1": 0.058346,
        "accuracy": 0.086914,
        "main_score": 0.058346,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.083987,
        "recall": 0.12207,
        "f1": 0.093093,
        "accuracy": 0.12207,
        "main_score": 0.093093,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.094067,
        "recall": 0.132812,
        "f1": 0.103322,
        "accuracy": 0.132812,
        "main_score": 0.103322,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.012682,
        "recall": 0.029297,
        "f1": 0.015552,
        "accuracy": 0.029297,
        "main_score": 0.015552,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.081345,
        "recall": 0.116211,
        "f1": 0.089888,
        "accuracy": 0.116211,
        "main_score": 0.089888,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.039929,
        "recall": 0.074219,
        "f1": 0.046399,
        "accuracy": 0.074219,
        "main_score": 0.046399,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.023382,
        "recall": 0.048828,
        "f1": 0.02812,
        "accuracy": 0.048828,
        "main_score": 0.02812,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.058379,
        "recall": 0.103516,
        "f1": 0.06912,
        "accuracy": 0.103516,
        "main_score": 0.06912,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.070565,
        "recall": 0.112305,
        "f1": 0.080328,
        "accuracy": 0.112305,
        "main_score": 0.080328,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003101,
        "recall": 0.013672,
        "f1": 0.004322,
        "accuracy": 0.013672,
        "main_score": 0.004322,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.00931,
        "recall": 0.023438,
        "f1": 0.01142,
        "accuracy": 0.023438,
        "main_score": 0.01142,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.011043,
        "recall": 0.023438,
        "f1": 0.01298,
        "accuracy": 0.023438,
        "main_score": 0.01298,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.236473,
        "recall": 0.262695,
        "f1": 0.242164,
        "accuracy": 0.262695,
        "main_score": 0.242164,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.235186,
        "recall": 0.258789,
        "f1": 0.24208,
        "accuracy": 0.258789,
        "main_score": 0.24208,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.024926,
        "recall": 0.037109,
        "f1": 0.027078,
        "accuracy": 0.037109,
        "main_score": 0.027078,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.21403,
        "recall": 0.239258,
        "f1": 0.219993,
        "accuracy": 0.239258,
        "main_score": 0.219993,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.046076,
        "recall": 0.09082,
        "f1": 0.055033,
        "accuracy": 0.09082,
        "main_score": 0.055033,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.241785,
        "recall": 0.273438,
        "f1": 0.249717,
        "accuracy": 0.273438,
        "main_score": 0.249717,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.006124,
        "recall": 0.015625,
        "f1": 0.007582,
        "accuracy": 0.015625,
        "main_score": 0.007582,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.011709,
        "recall": 0.027344,
        "f1": 0.014406,
        "accuracy": 0.027344,
        "main_score": 0.014406,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.215956,
        "recall": 0.235352,
        "f1": 0.221071,
        "accuracy": 0.235352,
        "main_score": 0.221071,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.006394,
        "recall": 0.017578,
        "f1": 0.008096,
        "accuracy": 0.017578,
        "main_score": 0.008096,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.010904,
        "recall": 0.027344,
        "f1": 0.013319,
        "accuracy": 0.027344,
        "main_score": 0.013319,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.010904,
        "recall": 0.024414,
        "f1": 0.013262,
        "accuracy": 0.024414,
        "main_score": 0.013262,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.011058,
        "recall": 0.025391,
        "f1": 0.012763,
        "accuracy": 0.025391,
        "main_score": 0.012763,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.22916,
        "recall": 0.25,
        "f1": 0.234734,
        "accuracy": 0.25,
        "main_score": 0.234734,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.004167,
        "recall": 0.015625,
        "f1": 0.005803,
        "accuracy": 0.015625,
        "main_score": 0.005803,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.01356,
        "recall": 0.030273,
        "f1": 0.016543,
        "accuracy": 0.030273,
        "main_score": 0.016543,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.240381,
        "recall": 0.269531,
        "f1": 0.247945,
        "accuracy": 0.269531,
        "main_score": 0.247945,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.220325,
        "recall": 0.241211,
        "f1": 0.22613,
        "accuracy": 0.241211,
        "main_score": 0.22613,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.216353,
        "recall": 0.244141,
        "f1": 0.223567,
        "accuracy": 0.244141,
        "main_score": 0.223567,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.275561,
        "recall": 0.307617,
        "f1": 0.28387,
        "accuracy": 0.307617,
        "main_score": 0.28387,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.099238,
        "recall": 0.140625,
        "f1": 0.109149,
        "accuracy": 0.140625,
        "main_score": 0.109149,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.093949,
        "recall": 0.137695,
        "f1": 0.104777,
        "accuracy": 0.137695,
        "main_score": 0.104777,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.04718,
        "recall": 0.083008,
        "f1": 0.054504,
        "accuracy": 0.083008,
        "main_score": 0.054504,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.055228,
        "recall": 0.088867,
        "f1": 0.063131,
        "accuracy": 0.088867,
        "main_score": 0.063131,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001029,
        "recall": 0.00293,
        "f1": 0.001077,
        "accuracy": 0.00293,
        "main_score": 0.001077,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.038736,
        "recall": 0.066406,
        "f1": 0.043729,
        "accuracy": 0.066406,
        "main_score": 0.043729,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.083022,
        "recall": 0.120117,
        "f1": 0.091891,
        "accuracy": 0.120117,
        "main_score": 0.091891,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.069315,
        "recall": 0.109375,
        "f1": 0.079528,
        "accuracy": 0.109375,
        "main_score": 0.079528,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.05705,
        "recall": 0.079102,
        "f1": 0.062203,
        "accuracy": 0.079102,
        "main_score": 0.062203,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.016428,
        "recall": 0.03418,
        "f1": 0.019037,
        "accuracy": 0.03418,
        "main_score": 0.019037,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.019704,
        "recall": 0.035156,
        "f1": 0.021941,
        "accuracy": 0.035156,
        "main_score": 0.021941,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.072071,
        "recall": 0.099609,
        "f1": 0.078416,
        "accuracy": 0.099609,
        "main_score": 0.078416,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.093122,
        "recall": 0.129883,
        "f1": 0.102402,
        "accuracy": 0.129883,
        "main_score": 0.102402,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.096822,
        "recall": 0.131836,
        "f1": 0.106145,
        "accuracy": 0.131836,
        "main_score": 0.106145,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.087771,
        "recall": 0.131836,
        "f1": 0.098063,
        "accuracy": 0.131836,
        "main_score": 0.098063,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.015405,
        "recall": 0.038086,
        "f1": 0.01896,
        "accuracy": 0.038086,
        "main_score": 0.01896,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.037166,
        "recall": 0.053711,
        "f1": 0.040486,
        "accuracy": 0.053711,
        "main_score": 0.040486,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.072372,
        "recall": 0.105469,
        "f1": 0.080777,
        "accuracy": 0.105469,
        "main_score": 0.080777,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.05932,
        "recall": 0.09668,
        "f1": 0.068524,
        "accuracy": 0.09668,
        "main_score": 0.068524,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.025813,
        "recall": 0.047852,
        "f1": 0.029595,
        "accuracy": 0.047852,
        "main_score": 0.029595,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.031624,
        "recall": 0.057617,
        "f1": 0.03673,
        "accuracy": 0.057617,
        "main_score": 0.03673,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.01583,
        "recall": 0.026367,
        "f1": 0.017462,
        "accuracy": 0.026367,
        "main_score": 0.017462,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.021841,
        "recall": 0.042969,
        "f1": 0.026151,
        "accuracy": 0.042969,
        "main_score": 0.026151,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.037386,
        "recall": 0.0625,
        "f1": 0.042159,
        "accuracy": 0.0625,
        "main_score": 0.042159,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.255649,
        "recall": 0.285156,
        "f1": 0.263559,
        "accuracy": 0.285156,
        "main_score": 0.263559,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.212485,
        "recall": 0.24707,
        "f1": 0.221491,
        "accuracy": 0.24707,
        "main_score": 0.221491,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.013204,
        "recall": 0.025391,
        "f1": 0.014814,
        "accuracy": 0.025391,
        "main_score": 0.014814,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.255093,
        "recall": 0.291992,
        "f1": 0.265468,
        "accuracy": 0.291992,
        "main_score": 0.265468,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.07326,
        "recall": 0.12793,
        "f1": 0.084715,
        "accuracy": 0.12793,
        "main_score": 0.084715,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.226455,
        "recall": 0.264648,
        "f1": 0.236114,
        "accuracy": 0.264648,
        "main_score": 0.236114,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.053347,
        "recall": 0.076172,
        "f1": 0.05845,
        "accuracy": 0.076172,
        "main_score": 0.05845,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.203149,
        "recall": 0.233398,
        "f1": 0.210789,
        "accuracy": 0.233398,
        "main_score": 0.210789,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.019546,
        "recall": 0.041992,
        "f1": 0.023349,
        "accuracy": 0.041992,
        "main_score": 0.023349,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.043035,
        "recall": 0.064453,
        "f1": 0.047427,
        "accuracy": 0.064453,
        "main_score": 0.047427,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.018555,
        "recall": 0.039062,
        "f1": 0.022333,
        "accuracy": 0.039062,
        "main_score": 0.022333,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.027917,
        "recall": 0.054688,
        "f1": 0.033759,
        "accuracy": 0.054688,
        "main_score": 0.033759,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.021874,
        "recall": 0.041016,
        "f1": 0.02571,
        "accuracy": 0.041016,
        "main_score": 0.02571,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.207746,
        "recall": 0.236328,
        "f1": 0.215541,
        "accuracy": 0.236328,
        "main_score": 0.215541,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.031212,
        "recall": 0.054688,
        "f1": 0.035412,
        "accuracy": 0.054688,
        "main_score": 0.035412,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.010764,
        "recall": 0.024414,
        "f1": 0.012688,
        "accuracy": 0.024414,
        "main_score": 0.012688,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.21247,
        "recall": 0.246094,
        "f1": 0.22121,
        "accuracy": 0.246094,
        "main_score": 0.22121,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.256991,
        "recall": 0.291992,
        "f1": 0.266415,
        "accuracy": 0.291992,
        "main_score": 0.266415,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.260361,
        "recall": 0.296875,
        "f1": 0.270236,
        "accuracy": 0.296875,
        "main_score": 0.270236,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.213525,
        "recall": 0.240234,
        "f1": 0.22071,
        "accuracy": 0.240234,
        "main_score": 0.22071,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.084434,
        "recall": 0.124023,
        "f1": 0.092893,
        "accuracy": 0.124023,
        "main_score": 0.092893,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.088686,
        "recall": 0.130859,
        "f1": 0.098032,
        "accuracy": 0.130859,
        "main_score": 0.098032,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.043551,
        "recall": 0.083008,
        "f1": 0.052796,
        "accuracy": 0.083008,
        "main_score": 0.052796,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.021949,
        "recall": 0.049805,
        "f1": 0.027038,
        "accuracy": 0.049805,
        "main_score": 0.027038,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 5.6e-05,
        "recall": 0.001953,
        "f1": 0.000106,
        "accuracy": 0.001953,
        "main_score": 0.000106,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.065957,
        "recall": 0.116211,
        "f1": 0.077291,
        "accuracy": 0.116211,
        "main_score": 0.077291,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.100713,
        "recall": 0.152344,
        "f1": 0.113072,
        "accuracy": 0.152344,
        "main_score": 0.113072,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.026661,
        "recall": 0.054688,
        "f1": 0.032017,
        "accuracy": 0.054688,
        "main_score": 0.032017,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.116512,
        "recall": 0.149414,
        "f1": 0.125787,
        "accuracy": 0.149414,
        "main_score": 0.125787,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004022,
        "recall": 0.016602,
        "f1": 0.00526,
        "accuracy": 0.016602,
        "main_score": 0.00526,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.084108,
        "recall": 0.124023,
        "f1": 0.09332,
        "accuracy": 0.124023,
        "main_score": 0.09332,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.029357,
        "recall": 0.064453,
        "f1": 0.036358,
        "accuracy": 0.064453,
        "main_score": 0.036358,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.07237,
        "recall": 0.108398,
        "f1": 0.080955,
        "accuracy": 0.108398,
        "main_score": 0.080955,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.080598,
        "recall": 0.128906,
        "f1": 0.0915,
        "accuracy": 0.128906,
        "main_score": 0.0915,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.096615,
        "recall": 0.12793,
        "f1": 0.103757,
        "accuracy": 0.12793,
        "main_score": 0.103757,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.013791,
        "recall": 0.033203,
        "f1": 0.017016,
        "accuracy": 0.033203,
        "main_score": 0.017016,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.063008,
        "recall": 0.091797,
        "f1": 0.069456,
        "accuracy": 0.091797,
        "main_score": 0.069456,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.039185,
        "recall": 0.070312,
        "f1": 0.045796,
        "accuracy": 0.070312,
        "main_score": 0.045796,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.027305,
        "recall": 0.058594,
        "f1": 0.033496,
        "accuracy": 0.058594,
        "main_score": 0.033496,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.035419,
        "recall": 0.066406,
        "f1": 0.042139,
        "accuracy": 0.066406,
        "main_score": 0.042139,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.053842,
        "recall": 0.089844,
        "f1": 0.062354,
        "accuracy": 0.089844,
        "main_score": 0.062354,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003796,
        "recall": 0.011719,
        "f1": 0.00488,
        "accuracy": 0.011719,
        "main_score": 0.00488,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.101855,
        "recall": 0.144531,
        "f1": 0.112551,
        "accuracy": 0.144531,
        "main_score": 0.112551,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.093408,
        "recall": 0.128906,
        "f1": 0.103058,
        "accuracy": 0.128906,
        "main_score": 0.103058,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.05216,
        "recall": 0.087891,
        "f1": 0.059753,
        "accuracy": 0.087891,
        "main_score": 0.059753,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.045275,
        "recall": 0.073242,
        "f1": 0.051691,
        "accuracy": 0.073242,
        "main_score": 0.051691,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000977,
        "f1": 2e-06,
        "accuracy": 0.000977,
        "main_score": 2e-06,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.041243,
        "recall": 0.068359,
        "f1": 0.046887,
        "accuracy": 0.068359,
        "main_score": 0.046887,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.07797,
        "recall": 0.118164,
        "f1": 0.087307,
        "accuracy": 0.118164,
        "main_score": 0.087307,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.050807,
        "recall": 0.089844,
        "f1": 0.060538,
        "accuracy": 0.089844,
        "main_score": 0.060538,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.058877,
        "recall": 0.084961,
        "f1": 0.064508,
        "accuracy": 0.084961,
        "main_score": 0.064508,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.012446,
        "recall": 0.03125,
        "f1": 0.014961,
        "accuracy": 0.03125,
        "main_score": 0.014961,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.097488,
        "recall": 0.139648,
        "f1": 0.108161,
        "accuracy": 0.139648,
        "main_score": 0.108161,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.024968,
        "recall": 0.040039,
        "f1": 0.02746,
        "accuracy": 0.040039,
        "main_score": 0.02746,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.070537,
        "recall": 0.104492,
        "f1": 0.078406,
        "accuracy": 0.104492,
        "main_score": 0.078406,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.095209,
        "recall": 0.134766,
        "f1": 0.105427,
        "accuracy": 0.134766,
        "main_score": 0.105427,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.085795,
        "recall": 0.126953,
        "f1": 0.095293,
        "accuracy": 0.126953,
        "main_score": 0.095293,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.013532,
        "recall": 0.036133,
        "f1": 0.016728,
        "accuracy": 0.036133,
        "main_score": 0.016728,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.038258,
        "recall": 0.05957,
        "f1": 0.042381,
        "accuracy": 0.05957,
        "main_score": 0.042381,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.069099,
        "recall": 0.101562,
        "f1": 0.077253,
        "accuracy": 0.101562,
        "main_score": 0.077253,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.050717,
        "recall": 0.079102,
        "f1": 0.057576,
        "accuracy": 0.079102,
        "main_score": 0.057576,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.024771,
        "recall": 0.048828,
        "f1": 0.029328,
        "accuracy": 0.048828,
        "main_score": 0.029328,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.032495,
        "recall": 0.05957,
        "f1": 0.038028,
        "accuracy": 0.05957,
        "main_score": 0.038028,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.010856,
        "recall": 0.024414,
        "f1": 0.013285,
        "accuracy": 0.024414,
        "main_score": 0.013285,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.098226,
        "recall": 0.144531,
        "f1": 0.108971,
        "accuracy": 0.144531,
        "main_score": 0.108971,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.11069,
        "recall": 0.142578,
        "f1": 0.119196,
        "accuracy": 0.142578,
        "main_score": 0.119196,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.05485,
        "recall": 0.09375,
        "f1": 0.064078,
        "accuracy": 0.09375,
        "main_score": 0.064078,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.039194,
        "recall": 0.066406,
        "f1": 0.045094,
        "accuracy": 0.066406,
        "main_score": 0.045094,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001358,
        "recall": 0.003906,
        "f1": 0.00157,
        "accuracy": 0.003906,
        "main_score": 0.00157,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.047131,
        "recall": 0.082031,
        "f1": 0.054366,
        "accuracy": 0.082031,
        "main_score": 0.054366,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.074626,
        "recall": 0.109375,
        "f1": 0.082984,
        "accuracy": 0.109375,
        "main_score": 0.082984,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.031071,
        "recall": 0.058594,
        "f1": 0.036889,
        "accuracy": 0.058594,
        "main_score": 0.036889,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.08206,
        "recall": 0.115234,
        "f1": 0.089386,
        "accuracy": 0.115234,
        "main_score": 0.089386,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.010602,
        "recall": 0.026367,
        "f1": 0.012976,
        "accuracy": 0.026367,
        "main_score": 0.012976,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.112972,
        "recall": 0.161133,
        "f1": 0.124881,
        "accuracy": 0.161133,
        "main_score": 0.124881,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.021004,
        "recall": 0.035156,
        "f1": 0.023576,
        "accuracy": 0.035156,
        "main_score": 0.023576,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.09738,
        "recall": 0.135742,
        "f1": 0.106126,
        "accuracy": 0.135742,
        "main_score": 0.106126,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.104314,
        "recall": 0.143555,
        "f1": 0.114435,
        "accuracy": 0.143555,
        "main_score": 0.114435,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.09772,
        "recall": 0.131836,
        "f1": 0.10699,
        "accuracy": 0.131836,
        "main_score": 0.10699,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.01467,
        "recall": 0.038086,
        "f1": 0.018147,
        "accuracy": 0.038086,
        "main_score": 0.018147,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.049887,
        "recall": 0.076172,
        "f1": 0.055529,
        "accuracy": 0.076172,
        "main_score": 0.055529,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.070782,
        "recall": 0.105469,
        "f1": 0.079523,
        "accuracy": 0.105469,
        "main_score": 0.079523,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.029694,
        "recall": 0.052734,
        "f1": 0.034532,
        "accuracy": 0.052734,
        "main_score": 0.034532,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.033955,
        "recall": 0.05957,
        "f1": 0.039299,
        "accuracy": 0.05957,
        "main_score": 0.039299,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.043704,
        "recall": 0.077148,
        "f1": 0.05027,
        "accuracy": 0.077148,
        "main_score": 0.05027,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.00702,
        "recall": 0.016602,
        "f1": 0.008853,
        "accuracy": 0.016602,
        "main_score": 0.008853,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.117844,
        "recall": 0.161133,
        "f1": 0.128566,
        "accuracy": 0.161133,
        "main_score": 0.128566,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.099846,
        "recall": 0.144531,
        "f1": 0.111613,
        "accuracy": 0.144531,
        "main_score": 0.111613,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.056136,
        "recall": 0.094727,
        "f1": 0.064905,
        "accuracy": 0.094727,
        "main_score": 0.064905,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.040986,
        "recall": 0.072266,
        "f1": 0.048012,
        "accuracy": 0.072266,
        "main_score": 0.048012,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 5.1e-05,
        "recall": 0.000977,
        "f1": 9.8e-05,
        "accuracy": 0.000977,
        "main_score": 9.8e-05,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.048893,
        "recall": 0.09082,
        "f1": 0.057773,
        "accuracy": 0.09082,
        "main_score": 0.057773,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.082676,
        "recall": 0.125,
        "f1": 0.092452,
        "accuracy": 0.125,
        "main_score": 0.092452,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.054708,
        "recall": 0.099609,
        "f1": 0.065195,
        "accuracy": 0.099609,
        "main_score": 0.065195,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.080341,
        "recall": 0.118164,
        "f1": 0.089681,
        "accuracy": 0.118164,
        "main_score": 0.089681,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.008604,
        "recall": 0.025391,
        "f1": 0.010819,
        "accuracy": 0.025391,
        "main_score": 0.010819,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.099875,
        "recall": 0.149414,
        "f1": 0.111797,
        "accuracy": 0.149414,
        "main_score": 0.111797,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.018823,
        "recall": 0.035156,
        "f1": 0.021958,
        "accuracy": 0.035156,
        "main_score": 0.021958,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.088572,
        "recall": 0.115234,
        "f1": 0.095092,
        "accuracy": 0.115234,
        "main_score": 0.095092,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.087062,
        "recall": 0.125,
        "f1": 0.096939,
        "accuracy": 0.125,
        "main_score": 0.096939,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.104649,
        "recall": 0.147461,
        "f1": 0.115516,
        "accuracy": 0.147461,
        "main_score": 0.115516,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.01664,
        "recall": 0.041992,
        "f1": 0.019852,
        "accuracy": 0.041992,
        "main_score": 0.019852,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.04996,
        "recall": 0.073242,
        "f1": 0.054972,
        "accuracy": 0.073242,
        "main_score": 0.054972,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.063457,
        "recall": 0.099609,
        "f1": 0.072628,
        "accuracy": 0.099609,
        "main_score": 0.072628,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.050234,
        "recall": 0.094727,
        "f1": 0.060163,
        "accuracy": 0.094727,
        "main_score": 0.060163,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.021361,
        "recall": 0.045898,
        "f1": 0.025956,
        "accuracy": 0.045898,
        "main_score": 0.025956,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.032059,
        "recall": 0.06543,
        "f1": 0.038837,
        "accuracy": 0.06543,
        "main_score": 0.038837,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003317,
        "recall": 0.017578,
        "f1": 0.005157,
        "accuracy": 0.017578,
        "main_score": 0.005157,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.042676,
        "recall": 0.063477,
        "f1": 0.047611,
        "accuracy": 0.063477,
        "main_score": 0.047611,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.036156,
        "recall": 0.055664,
        "f1": 0.040696,
        "accuracy": 0.055664,
        "main_score": 0.040696,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.283103,
        "recall": 0.314453,
        "f1": 0.291688,
        "accuracy": 0.314453,
        "main_score": 0.291688,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.306971,
        "recall": 0.344727,
        "f1": 0.317136,
        "accuracy": 0.344727,
        "main_score": 0.317136,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.025258,
        "recall": 0.037109,
        "f1": 0.026949,
        "accuracy": 0.037109,
        "main_score": 0.026949,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.265919,
        "recall": 0.292969,
        "f1": 0.27285,
        "accuracy": 0.292969,
        "main_score": 0.27285,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.082406,
        "recall": 0.136719,
        "f1": 0.093864,
        "accuracy": 0.136719,
        "main_score": 0.093864,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.295357,
        "recall": 0.331055,
        "f1": 0.304301,
        "accuracy": 0.331055,
        "main_score": 0.304301,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.025234,
        "recall": 0.043945,
        "f1": 0.028425,
        "accuracy": 0.043945,
        "main_score": 0.028425,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.239528,
        "recall": 0.269531,
        "f1": 0.246696,
        "accuracy": 0.269531,
        "main_score": 0.246696,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.05804,
        "recall": 0.083008,
        "f1": 0.063518,
        "accuracy": 0.083008,
        "main_score": 0.063518,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.218192,
        "recall": 0.248047,
        "f1": 0.226036,
        "accuracy": 0.248047,
        "main_score": 0.226036,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.030274,
        "recall": 0.050781,
        "f1": 0.033916,
        "accuracy": 0.050781,
        "main_score": 0.033916,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.043913,
        "recall": 0.066406,
        "f1": 0.048465,
        "accuracy": 0.066406,
        "main_score": 0.048465,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.037547,
        "recall": 0.061523,
        "f1": 0.042231,
        "accuracy": 0.061523,
        "main_score": 0.042231,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.04177,
        "recall": 0.060547,
        "f1": 0.046179,
        "accuracy": 0.060547,
        "main_score": 0.046179,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.014249,
        "recall": 0.032227,
        "f1": 0.017437,
        "accuracy": 0.032227,
        "main_score": 0.017437,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.037756,
        "recall": 0.0625,
        "f1": 0.042682,
        "accuracy": 0.0625,
        "main_score": 0.042682,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.308371,
        "recall": 0.348633,
        "f1": 0.319232,
        "accuracy": 0.348633,
        "main_score": 0.319232,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.268016,
        "recall": 0.290039,
        "f1": 0.273718,
        "accuracy": 0.290039,
        "main_score": 0.273718,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.252822,
        "recall": 0.280273,
        "f1": 0.260204,
        "accuracy": 0.280273,
        "main_score": 0.260204,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.253891,
        "recall": 0.275391,
        "f1": 0.259443,
        "accuracy": 0.275391,
        "main_score": 0.259443,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.049089,
        "recall": 0.071289,
        "f1": 0.053823,
        "accuracy": 0.071289,
        "main_score": 0.053823,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.047846,
        "recall": 0.073242,
        "f1": 0.053161,
        "accuracy": 0.073242,
        "main_score": 0.053161,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.019012,
        "recall": 0.038086,
        "f1": 0.02289,
        "accuracy": 0.038086,
        "main_score": 0.02289,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.006444,
        "recall": 0.018555,
        "f1": 0.007984,
        "accuracy": 0.018555,
        "main_score": 0.007984,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 5.6e-05,
        "recall": 0.001953,
        "f1": 0.000107,
        "accuracy": 0.001953,
        "main_score": 0.000107,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.040065,
        "recall": 0.071289,
        "f1": 0.046534,
        "accuracy": 0.071289,
        "main_score": 0.046534,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.038751,
        "recall": 0.066406,
        "f1": 0.044917,
        "accuracy": 0.066406,
        "main_score": 0.044917,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.011719,
        "recall": 0.032227,
        "f1": 0.014983,
        "accuracy": 0.032227,
        "main_score": 0.014983,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.090524,
        "recall": 0.117188,
        "f1": 0.096572,
        "accuracy": 0.117188,
        "main_score": 0.096572,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.002118,
        "recall": 0.007812,
        "f1": 0.002667,
        "accuracy": 0.007812,
        "main_score": 0.002667,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.039121,
        "recall": 0.069336,
        "f1": 0.045096,
        "accuracy": 0.069336,
        "main_score": 0.045096,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.028984,
        "recall": 0.051758,
        "f1": 0.03346,
        "accuracy": 0.051758,
        "main_score": 0.03346,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.066028,
        "recall": 0.094727,
        "f1": 0.072965,
        "accuracy": 0.094727,
        "main_score": 0.072965,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.032525,
        "recall": 0.056641,
        "f1": 0.037092,
        "accuracy": 0.056641,
        "main_score": 0.037092,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.046403,
        "recall": 0.073242,
        "f1": 0.051866,
        "accuracy": 0.073242,
        "main_score": 0.051866,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.045875,
        "recall": 0.069336,
        "f1": 0.050634,
        "accuracy": 0.069336,
        "main_score": 0.050634,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.004546,
        "recall": 0.015625,
        "f1": 0.005871,
        "accuracy": 0.015625,
        "main_score": 0.005871,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.025085,
        "recall": 0.042969,
        "f1": 0.028483,
        "accuracy": 0.042969,
        "main_score": 0.028483,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.011117,
        "recall": 0.03125,
        "f1": 0.014707,
        "accuracy": 0.03125,
        "main_score": 0.014707,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.024773,
        "recall": 0.051758,
        "f1": 0.030021,
        "accuracy": 0.051758,
        "main_score": 0.030021,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.024352,
        "recall": 0.054688,
        "f1": 0.029596,
        "accuracy": 0.054688,
        "main_score": 0.029596,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003496,
        "recall": 0.006836,
        "f1": 0.003846,
        "accuracy": 0.006836,
        "main_score": 0.003846,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.057126,
        "recall": 0.091797,
        "f1": 0.064648,
        "accuracy": 0.091797,
        "main_score": 0.064648,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.100277,
        "recall": 0.141602,
        "f1": 0.110338,
        "accuracy": 0.141602,
        "main_score": 0.110338,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.020564,
        "recall": 0.045898,
        "f1": 0.025223,
        "accuracy": 0.045898,
        "main_score": 0.025223,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.04599,
        "recall": 0.083984,
        "f1": 0.054433,
        "accuracy": 0.083984,
        "main_score": 0.054433,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002012,
        "recall": 0.003906,
        "f1": 0.002064,
        "accuracy": 0.003906,
        "main_score": 0.002064,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020788,
        "recall": 0.041016,
        "f1": 0.024435,
        "accuracy": 0.041016,
        "main_score": 0.024435,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.040339,
        "recall": 0.067383,
        "f1": 0.046307,
        "accuracy": 0.067383,
        "main_score": 0.046307,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.039749,
        "recall": 0.077148,
        "f1": 0.048448,
        "accuracy": 0.077148,
        "main_score": 0.048448,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.031972,
        "recall": 0.054688,
        "f1": 0.036303,
        "accuracy": 0.054688,
        "main_score": 0.036303,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006797,
        "recall": 0.022461,
        "f1": 0.009166,
        "accuracy": 0.022461,
        "main_score": 0.009166,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.06054,
        "recall": 0.091797,
        "f1": 0.068687,
        "accuracy": 0.091797,
        "main_score": 0.068687,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.006066,
        "recall": 0.015625,
        "f1": 0.00721,
        "accuracy": 0.015625,
        "main_score": 0.00721,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.038392,
        "recall": 0.057617,
        "f1": 0.04222,
        "accuracy": 0.057617,
        "main_score": 0.04222,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.047548,
        "recall": 0.081055,
        "f1": 0.0555,
        "accuracy": 0.081055,
        "main_score": 0.0555,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.05986,
        "recall": 0.086914,
        "f1": 0.066225,
        "accuracy": 0.086914,
        "main_score": 0.066225,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.051355,
        "recall": 0.077148,
        "f1": 0.057163,
        "accuracy": 0.077148,
        "main_score": 0.057163,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.009996,
        "recall": 0.025391,
        "f1": 0.012403,
        "accuracy": 0.025391,
        "main_score": 0.012403,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.022141,
        "recall": 0.033203,
        "f1": 0.023872,
        "accuracy": 0.033203,
        "main_score": 0.023872,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.038853,
        "recall": 0.070312,
        "f1": 0.045862,
        "accuracy": 0.070312,
        "main_score": 0.045862,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.015578,
        "recall": 0.033203,
        "f1": 0.018318,
        "accuracy": 0.033203,
        "main_score": 0.018318,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.019479,
        "recall": 0.036133,
        "f1": 0.022267,
        "accuracy": 0.036133,
        "main_score": 0.022267,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.008416,
        "recall": 0.024414,
        "f1": 0.011028,
        "accuracy": 0.024414,
        "main_score": 0.011028,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.055895,
        "recall": 0.087891,
        "f1": 0.063223,
        "accuracy": 0.087891,
        "main_score": 0.063223,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.040023,
        "recall": 0.063477,
        "f1": 0.044826,
        "accuracy": 0.063477,
        "main_score": 0.044826,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.288463,
        "recall": 0.31543,
        "f1": 0.296206,
        "accuracy": 0.31543,
        "main_score": 0.296206,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.335326,
        "recall": 0.387695,
        "f1": 0.350313,
        "accuracy": 0.387695,
        "main_score": 0.350313,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.016365,
        "recall": 0.02832,
        "f1": 0.018415,
        "accuracy": 0.02832,
        "main_score": 0.018415,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.276274,
        "recall": 0.300781,
        "f1": 0.283371,
        "accuracy": 0.300781,
        "main_score": 0.283371,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.101433,
        "recall": 0.15918,
        "f1": 0.114816,
        "accuracy": 0.15918,
        "main_score": 0.114816,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.389251,
        "recall": 0.439453,
        "f1": 0.403329,
        "accuracy": 0.439453,
        "main_score": 0.403329,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.027732,
        "recall": 0.047852,
        "f1": 0.031834,
        "accuracy": 0.047852,
        "main_score": 0.031834,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.243557,
        "recall": 0.277344,
        "f1": 0.251573,
        "accuracy": 0.277344,
        "main_score": 0.251573,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.072764,
        "recall": 0.100586,
        "f1": 0.079941,
        "accuracy": 0.100586,
        "main_score": 0.079941,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.214616,
        "recall": 0.243164,
        "f1": 0.223017,
        "accuracy": 0.243164,
        "main_score": 0.223017,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.034297,
        "recall": 0.053711,
        "f1": 0.037948,
        "accuracy": 0.053711,
        "main_score": 0.037948,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.063368,
        "recall": 0.091797,
        "f1": 0.070073,
        "accuracy": 0.091797,
        "main_score": 0.070073,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.038883,
        "recall": 0.0625,
        "f1": 0.043735,
        "accuracy": 0.0625,
        "main_score": 0.043735,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.059712,
        "recall": 0.094727,
        "f1": 0.067932,
        "accuracy": 0.094727,
        "main_score": 0.067932,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.250838,
        "recall": 0.291016,
        "f1": 0.260042,
        "accuracy": 0.291016,
        "main_score": 0.260042,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.022773,
        "recall": 0.039062,
        "f1": 0.025873,
        "accuracy": 0.039062,
        "main_score": 0.025873,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.05054,
        "recall": 0.083008,
        "f1": 0.057178,
        "accuracy": 0.083008,
        "main_score": 0.057178,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.251805,
        "recall": 0.28125,
        "f1": 0.259959,
        "accuracy": 0.28125,
        "main_score": 0.259959,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.251768,
        "recall": 0.280273,
        "f1": 0.260117,
        "accuracy": 0.280273,
        "main_score": 0.260117,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.2719,
        "recall": 0.296875,
        "f1": 0.277701,
        "accuracy": 0.296875,
        "main_score": 0.277701,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.030286,
        "recall": 0.053711,
        "f1": 0.035212,
        "accuracy": 0.053711,
        "main_score": 0.035212,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.039407,
        "recall": 0.05957,
        "f1": 0.043758,
        "accuracy": 0.05957,
        "main_score": 0.043758,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.283034,
        "recall": 0.31543,
        "f1": 0.291668,
        "accuracy": 0.31543,
        "main_score": 0.291668,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.252417,
        "recall": 0.27832,
        "f1": 0.258995,
        "accuracy": 0.27832,
        "main_score": 0.258995,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.016985,
        "recall": 0.03125,
        "f1": 0.019549,
        "accuracy": 0.03125,
        "main_score": 0.019549,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.303534,
        "recall": 0.342773,
        "f1": 0.314314,
        "accuracy": 0.342773,
        "main_score": 0.314314,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.073761,
        "recall": 0.135742,
        "f1": 0.087361,
        "accuracy": 0.135742,
        "main_score": 0.087361,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.242207,
        "recall": 0.273438,
        "f1": 0.250331,
        "accuracy": 0.273438,
        "main_score": 0.250331,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.05827,
        "recall": 0.09082,
        "f1": 0.065699,
        "accuracy": 0.09082,
        "main_score": 0.065699,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.224643,
        "recall": 0.251953,
        "f1": 0.23102,
        "accuracy": 0.251953,
        "main_score": 0.23102,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.026106,
        "recall": 0.043945,
        "f1": 0.029953,
        "accuracy": 0.043945,
        "main_score": 0.029953,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.271559,
        "recall": 0.305664,
        "f1": 0.280649,
        "accuracy": 0.305664,
        "main_score": 0.280649,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.042846,
        "recall": 0.068359,
        "f1": 0.048363,
        "accuracy": 0.068359,
        "main_score": 0.048363,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.023059,
        "recall": 0.042969,
        "f1": 0.026432,
        "accuracy": 0.042969,
        "main_score": 0.026432,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.036943,
        "recall": 0.066406,
        "f1": 0.042883,
        "accuracy": 0.066406,
        "main_score": 0.042883,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.029977,
        "recall": 0.050781,
        "f1": 0.034438,
        "accuracy": 0.050781,
        "main_score": 0.034438,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.253188,
        "recall": 0.275391,
        "f1": 0.259427,
        "accuracy": 0.275391,
        "main_score": 0.259427,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.027144,
        "recall": 0.050781,
        "f1": 0.031199,
        "accuracy": 0.050781,
        "main_score": 0.031199,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.019471,
        "recall": 0.038086,
        "f1": 0.022849,
        "accuracy": 0.038086,
        "main_score": 0.022849,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.254785,
        "recall": 0.279297,
        "f1": 0.261509,
        "accuracy": 0.279297,
        "main_score": 0.261509,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.333329,
        "recall": 0.375977,
        "f1": 0.345117,
        "accuracy": 0.375977,
        "main_score": 0.345117,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.221192,
        "recall": 0.245117,
        "f1": 0.227444,
        "accuracy": 0.245117,
        "main_score": 0.227444,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.036149,
        "recall": 0.060547,
        "f1": 0.041062,
        "accuracy": 0.060547,
        "main_score": 0.041062,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.041202,
        "recall": 0.067383,
        "f1": 0.046307,
        "accuracy": 0.067383,
        "main_score": 0.046307,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.300485,
        "recall": 0.339844,
        "f1": 0.310488,
        "accuracy": 0.339844,
        "main_score": 0.310488,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.252777,
        "recall": 0.288086,
        "f1": 0.262306,
        "accuracy": 0.288086,
        "main_score": 0.262306,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.014417,
        "recall": 0.027344,
        "f1": 0.016279,
        "accuracy": 0.027344,
        "main_score": 0.016279,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.312747,
        "recall": 0.352539,
        "f1": 0.323771,
        "accuracy": 0.352539,
        "main_score": 0.323771,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.090492,
        "recall": 0.155273,
        "f1": 0.10416,
        "accuracy": 0.155273,
        "main_score": 0.10416,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.245286,
        "recall": 0.28418,
        "f1": 0.255327,
        "accuracy": 0.28418,
        "main_score": 0.255327,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.071913,
        "recall": 0.106445,
        "f1": 0.079614,
        "accuracy": 0.106445,
        "main_score": 0.079614,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.210914,
        "recall": 0.244141,
        "f1": 0.219347,
        "accuracy": 0.244141,
        "main_score": 0.219347,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.035632,
        "recall": 0.058594,
        "f1": 0.039998,
        "accuracy": 0.058594,
        "main_score": 0.039998,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.264918,
        "recall": 0.292969,
        "f1": 0.272789,
        "accuracy": 0.292969,
        "main_score": 0.272789,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.061534,
        "recall": 0.09082,
        "f1": 0.06821,
        "accuracy": 0.09082,
        "main_score": 0.06821,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.036393,
        "recall": 0.061523,
        "f1": 0.041721,
        "accuracy": 0.061523,
        "main_score": 0.041721,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.052261,
        "recall": 0.083984,
        "f1": 0.059139,
        "accuracy": 0.083984,
        "main_score": 0.059139,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.035227,
        "recall": 0.05957,
        "f1": 0.040541,
        "accuracy": 0.05957,
        "main_score": 0.040541,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.239612,
        "recall": 0.269531,
        "f1": 0.247466,
        "accuracy": 0.269531,
        "main_score": 0.247466,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.023825,
        "recall": 0.049805,
        "f1": 0.028972,
        "accuracy": 0.049805,
        "main_score": 0.028972,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.017582,
        "recall": 0.038086,
        "f1": 0.021174,
        "accuracy": 0.038086,
        "main_score": 0.021174,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.244911,
        "recall": 0.277344,
        "f1": 0.253277,
        "accuracy": 0.277344,
        "main_score": 0.253277,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.330835,
        "recall": 0.371094,
        "f1": 0.342393,
        "accuracy": 0.371094,
        "main_score": 0.342393,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.217141,
        "recall": 0.244141,
        "f1": 0.223651,
        "accuracy": 0.244141,
        "main_score": 0.223651,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.008843,
        "recall": 0.016602,
        "f1": 0.009805,
        "accuracy": 0.016602,
        "main_score": 0.009805,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.012792,
        "recall": 0.018555,
        "f1": 0.013655,
        "accuracy": 0.018555,
        "main_score": 0.013655,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.224697,
        "recall": 0.249023,
        "f1": 0.231285,
        "accuracy": 0.249023,
        "main_score": 0.231285,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.224981,
        "recall": 0.263672,
        "f1": 0.234911,
        "accuracy": 0.263672,
        "main_score": 0.234911,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.013112,
        "recall": 0.023438,
        "f1": 0.014369,
        "accuracy": 0.023438,
        "main_score": 0.014369,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.208293,
        "recall": 0.236328,
        "f1": 0.215387,
        "accuracy": 0.236328,
        "main_score": 0.215387,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.041534,
        "recall": 0.085938,
        "f1": 0.050703,
        "accuracy": 0.085938,
        "main_score": 0.050703,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.253668,
        "recall": 0.283203,
        "f1": 0.261719,
        "accuracy": 0.283203,
        "main_score": 0.261719,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.005095,
        "recall": 0.010742,
        "f1": 0.005815,
        "accuracy": 0.010742,
        "main_score": 0.005815,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.261252,
        "recall": 0.298828,
        "f1": 0.271399,
        "accuracy": 0.298828,
        "main_score": 0.271399,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.011603,
        "recall": 0.025391,
        "f1": 0.013877,
        "accuracy": 0.025391,
        "main_score": 0.013877,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.193671,
        "recall": 0.220703,
        "f1": 0.201455,
        "accuracy": 0.220703,
        "main_score": 0.201455,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.0036,
        "recall": 0.011719,
        "f1": 0.004646,
        "accuracy": 0.011719,
        "main_score": 0.004646,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.013818,
        "recall": 0.021484,
        "f1": 0.014938,
        "accuracy": 0.021484,
        "main_score": 0.014938,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.013099,
        "recall": 0.018555,
        "f1": 0.013859,
        "accuracy": 0.018555,
        "main_score": 0.013859,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.014142,
        "recall": 0.026367,
        "f1": 0.016116,
        "accuracy": 0.026367,
        "main_score": 0.016116,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.20851,
        "recall": 0.239258,
        "f1": 0.216387,
        "accuracy": 0.239258,
        "main_score": 0.216387,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.00417,
        "recall": 0.009766,
        "f1": 0.004955,
        "accuracy": 0.009766,
        "main_score": 0.004955,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.012952,
        "recall": 0.023438,
        "f1": 0.014933,
        "accuracy": 0.023438,
        "main_score": 0.014933,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.242875,
        "recall": 0.282227,
        "f1": 0.251525,
        "accuracy": 0.282227,
        "main_score": 0.251525,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.198352,
        "recall": 0.226562,
        "f1": 0.20603,
        "accuracy": 0.226562,
        "main_score": 0.20603,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.195355,
        "recall": 0.232422,
        "f1": 0.205078,
        "accuracy": 0.232422,
        "main_score": 0.205078,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 55.820974826812744,
  "kg_co2_emissions": 0.0020194301723651283
}