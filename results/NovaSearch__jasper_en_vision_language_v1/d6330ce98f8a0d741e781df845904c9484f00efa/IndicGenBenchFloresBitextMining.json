{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.690545,
        "recall": 0.75326,
        "f1": 0.707643,
        "accuracy": 0.75326,
        "main_score": 0.707643,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.70886,
        "recall": 0.777332,
        "f1": 0.728472,
        "accuracy": 0.777332,
        "main_score": 0.728472,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.474927,
        "recall": 0.545637,
        "f1": 0.491554,
        "accuracy": 0.545637,
        "main_score": 0.491554,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.468185,
        "recall": 0.560682,
        "f1": 0.491346,
        "accuracy": 0.560682,
        "main_score": 0.491346,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.969074,
        "recall": 0.978937,
        "f1": 0.97225,
        "accuracy": 0.978937,
        "main_score": 0.97225,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.95102,
        "recall": 0.966901,
        "f1": 0.956202,
        "accuracy": 0.966901,
        "main_score": 0.956202,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.31741,
        "recall": 0.385155,
        "f1": 0.332294,
        "accuracy": 0.385155,
        "main_score": 0.332294,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.310957,
        "recall": 0.405216,
        "f1": 0.33304,
        "accuracy": 0.405216,
        "main_score": 0.33304,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.400917,
        "recall": 0.476429,
        "f1": 0.417352,
        "accuracy": 0.476429,
        "main_score": 0.417352,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.393528,
        "recall": 0.489468,
        "f1": 0.417305,
        "accuracy": 0.489468,
        "main_score": 0.417305,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.696407,
        "recall": 0.758275,
        "f1": 0.713373,
        "accuracy": 0.758275,
        "main_score": 0.713373,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.671501,
        "recall": 0.747242,
        "f1": 0.693154,
        "accuracy": 0.747242,
        "main_score": 0.693154,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.221261,
        "recall": 0.27683,
        "f1": 0.233114,
        "accuracy": 0.27683,
        "main_score": 0.233114,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.242604,
        "recall": 0.321966,
        "f1": 0.260872,
        "accuracy": 0.321966,
        "main_score": 0.260872,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.431585,
        "recall": 0.495486,
        "f1": 0.4465,
        "accuracy": 0.495486,
        "main_score": 0.4465,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.369939,
        "recall": 0.471414,
        "f1": 0.394293,
        "accuracy": 0.471414,
        "main_score": 0.394293,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.896783,
        "recall": 0.925777,
        "f1": 0.9055,
        "accuracy": 0.925777,
        "main_score": 0.9055,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.879639,
        "recall": 0.91675,
        "f1": 0.891474,
        "accuracy": 0.91675,
        "main_score": 0.891474,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.503552,
        "recall": 0.57673,
        "f1": 0.521108,
        "accuracy": 0.57673,
        "main_score": 0.521108,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.486301,
        "recall": 0.590772,
        "f1": 0.515399,
        "accuracy": 0.590772,
        "main_score": 0.515399,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.874323,
        "recall": 0.909729,
        "f1": 0.885089,
        "accuracy": 0.909729,
        "main_score": 0.885089,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.85234,
        "recall": 0.895687,
        "f1": 0.865831,
        "accuracy": 0.895687,
        "main_score": 0.865831,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.786399,
        "recall": 0.835507,
        "f1": 0.800084,
        "accuracy": 0.835507,
        "main_score": 0.800084,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.738692,
        "recall": 0.804413,
        "f1": 0.75779,
        "accuracy": 0.804413,
        "main_score": 0.75779,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.18468,
        "recall": 0.228686,
        "f1": 0.193139,
        "accuracy": 0.228686,
        "main_score": 0.193139,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.197363,
        "recall": 0.283852,
        "f1": 0.216036,
        "accuracy": 0.283852,
        "main_score": 0.216036,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.376673,
        "recall": 0.437312,
        "f1": 0.389802,
        "accuracy": 0.437312,
        "main_score": 0.389802,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.405566,
        "recall": 0.50652,
        "f1": 0.430915,
        "accuracy": 0.50652,
        "main_score": 0.430915,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.613082,
        "recall": 0.687061,
        "f1": 0.632712,
        "accuracy": 0.687061,
        "main_score": 0.632712,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.556749,
        "recall": 0.651956,
        "f1": 0.583332,
        "accuracy": 0.651956,
        "main_score": 0.583332,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.67446,
        "recall": 0.738215,
        "f1": 0.690781,
        "accuracy": 0.738215,
        "main_score": 0.690781,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.667286,
        "recall": 0.744233,
        "f1": 0.688996,
        "accuracy": 0.744233,
        "main_score": 0.688996,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.930792,
        "recall": 0.952859,
        "f1": 0.937981,
        "accuracy": 0.952859,
        "main_score": 0.937981,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.916583,
        "recall": 0.941825,
        "f1": 0.924774,
        "accuracy": 0.941825,
        "main_score": 0.924774,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.925109,
        "recall": 0.944835,
        "f1": 0.930878,
        "accuracy": 0.944835,
        "main_score": 0.930878,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.899816,
        "recall": 0.930792,
        "f1": 0.909796,
        "accuracy": 0.930792,
        "main_score": 0.909796,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.083012,
        "recall": 0.105316,
        "f1": 0.087701,
        "accuracy": 0.105316,
        "main_score": 0.087701,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.10056,
        "recall": 0.164493,
        "f1": 0.112751,
        "accuracy": 0.164493,
        "main_score": 0.112751,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.364724,
        "recall": 0.426279,
        "f1": 0.379157,
        "accuracy": 0.426279,
        "main_score": 0.379157,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.349149,
        "recall": 0.44333,
        "f1": 0.372959,
        "accuracy": 0.44333,
        "main_score": 0.372959,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.917954,
        "recall": 0.940822,
        "f1": 0.924908,
        "accuracy": 0.940822,
        "main_score": 0.924908,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.897275,
        "recall": 0.928786,
        "f1": 0.907121,
        "accuracy": 0.928786,
        "main_score": 0.907121,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.61015,
        "recall": 0.667001,
        "f1": 0.625045,
        "accuracy": 0.667001,
        "main_score": 0.625045,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.587508,
        "recall": 0.676028,
        "f1": 0.612464,
        "accuracy": 0.676028,
        "main_score": 0.612464,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.886192,
        "recall": 0.918756,
        "f1": 0.896122,
        "accuracy": 0.918756,
        "main_score": 0.896122,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.86777,
        "recall": 0.90672,
        "f1": 0.87994,
        "accuracy": 0.90672,
        "main_score": 0.87994,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.90128,
        "recall": 0.927783,
        "f1": 0.909326,
        "accuracy": 0.927783,
        "main_score": 0.909326,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.856152,
        "recall": 0.898696,
        "f1": 0.869294,
        "accuracy": 0.898696,
        "main_score": 0.869294,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.867362,
        "recall": 0.902708,
        "f1": 0.877702,
        "accuracy": 0.902708,
        "main_score": 0.877702,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.834621,
        "recall": 0.883651,
        "f1": 0.849716,
        "accuracy": 0.883651,
        "main_score": 0.849716,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.393388,
        "recall": 0.462387,
        "f1": 0.409855,
        "accuracy": 0.462387,
        "main_score": 0.409855,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.370957,
        "recall": 0.474423,
        "f1": 0.398133,
        "accuracy": 0.474423,
        "main_score": 0.398133,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.895135,
        "recall": 0.923771,
        "f1": 0.903544,
        "accuracy": 0.923771,
        "main_score": 0.903544,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.881812,
        "recall": 0.917753,
        "f1": 0.893146,
        "accuracy": 0.917753,
        "main_score": 0.893146,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.911092,
        "recall": 0.934804,
        "f1": 0.918143,
        "accuracy": 0.934804,
        "main_score": 0.918143,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.879923,
        "recall": 0.915747,
        "f1": 0.891207,
        "accuracy": 0.915747,
        "main_score": 0.891207,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.012631,
        "recall": 0.017051,
        "f1": 0.013293,
        "accuracy": 0.017051,
        "main_score": 0.013293,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003634,
        "recall": 0.021063,
        "f1": 0.005289,
        "accuracy": 0.021063,
        "main_score": 0.005289,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.66269,
        "recall": 0.722332,
        "f1": 0.678445,
        "accuracy": 0.722332,
        "main_score": 0.678445,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.656152,
        "recall": 0.744071,
        "f1": 0.681722,
        "accuracy": 0.744071,
        "main_score": 0.681722,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.451977,
        "recall": 0.513834,
        "f1": 0.466336,
        "accuracy": 0.513834,
        "main_score": 0.466336,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.44783,
        "recall": 0.551383,
        "f1": 0.474498,
        "accuracy": 0.551383,
        "main_score": 0.474498,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.968379,
        "recall": 0.978261,
        "f1": 0.971509,
        "accuracy": 0.978261,
        "main_score": 0.971509,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.956192,
        "recall": 0.970356,
        "f1": 0.960804,
        "accuracy": 0.970356,
        "main_score": 0.960804,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.303934,
        "recall": 0.365613,
        "f1": 0.317611,
        "accuracy": 0.365613,
        "main_score": 0.317611,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.307836,
        "recall": 0.400198,
        "f1": 0.329651,
        "accuracy": 0.400198,
        "main_score": 0.329651,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.401408,
        "recall": 0.474308,
        "f1": 0.41898,
        "accuracy": 0.474308,
        "main_score": 0.41898,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.415452,
        "recall": 0.502964,
        "f1": 0.437135,
        "accuracy": 0.502964,
        "main_score": 0.437135,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.66163,
        "recall": 0.722332,
        "f1": 0.677246,
        "accuracy": 0.722332,
        "main_score": 0.677246,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.660454,
        "recall": 0.740119,
        "f1": 0.683045,
        "accuracy": 0.740119,
        "main_score": 0.683045,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.213259,
        "recall": 0.258893,
        "f1": 0.223119,
        "accuracy": 0.258893,
        "main_score": 0.223119,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.218634,
        "recall": 0.301383,
        "f1": 0.237225,
        "accuracy": 0.301383,
        "main_score": 0.237225,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.389819,
        "recall": 0.451581,
        "f1": 0.40466,
        "accuracy": 0.451581,
        "main_score": 0.40466,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.354043,
        "recall": 0.463439,
        "f1": 0.3806,
        "accuracy": 0.463439,
        "main_score": 0.3806,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.885326,
        "recall": 0.91996,
        "f1": 0.896146,
        "accuracy": 0.91996,
        "main_score": 0.896146,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.863813,
        "recall": 0.901186,
        "f1": 0.875347,
        "accuracy": 0.901186,
        "main_score": 0.875347,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.459704,
        "recall": 0.533597,
        "f1": 0.477928,
        "accuracy": 0.533597,
        "main_score": 0.477928,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.477257,
        "recall": 0.578063,
        "f1": 0.504388,
        "accuracy": 0.578063,
        "main_score": 0.504388,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.869409,
        "recall": 0.902174,
        "f1": 0.879048,
        "accuracy": 0.902174,
        "main_score": 0.879048,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.857625,
        "recall": 0.899209,
        "f1": 0.870455,
        "accuracy": 0.899209,
        "main_score": 0.870455,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.755564,
        "recall": 0.806324,
        "f1": 0.769362,
        "accuracy": 0.806324,
        "main_score": 0.769362,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.758283,
        "recall": 0.820158,
        "f1": 0.776424,
        "accuracy": 0.820158,
        "main_score": 0.776424,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.163504,
        "recall": 0.206522,
        "f1": 0.173351,
        "accuracy": 0.206522,
        "main_score": 0.173351,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.186835,
        "recall": 0.271739,
        "f1": 0.205429,
        "accuracy": 0.271739,
        "main_score": 0.205429,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.378679,
        "recall": 0.431818,
        "f1": 0.39101,
        "accuracy": 0.431818,
        "main_score": 0.39101,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.377607,
        "recall": 0.481225,
        "f1": 0.40391,
        "accuracy": 0.481225,
        "main_score": 0.40391,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.604535,
        "recall": 0.679842,
        "f1": 0.624589,
        "accuracy": 0.679842,
        "main_score": 0.624589,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.567251,
        "recall": 0.662055,
        "f1": 0.594248,
        "accuracy": 0.662055,
        "main_score": 0.594248,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.630284,
        "recall": 0.692688,
        "f1": 0.645642,
        "accuracy": 0.692688,
        "main_score": 0.645642,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.626976,
        "recall": 0.715415,
        "f1": 0.651968,
        "accuracy": 0.715415,
        "main_score": 0.651968,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.922925,
        "recall": 0.943676,
        "f1": 0.929103,
        "accuracy": 0.943676,
        "main_score": 0.929103,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.909667,
        "recall": 0.935771,
        "f1": 0.917885,
        "accuracy": 0.935771,
        "main_score": 0.917885,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.919911,
        "recall": 0.943676,
        "f1": 0.927273,
        "accuracy": 0.943676,
        "main_score": 0.927273,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.902668,
        "recall": 0.931818,
        "f1": 0.911858,
        "accuracy": 0.931818,
        "main_score": 0.911858,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.093319,
        "recall": 0.118577,
        "f1": 0.099762,
        "accuracy": 0.118577,
        "main_score": 0.099762,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.092935,
        "recall": 0.152174,
        "f1": 0.104466,
        "accuracy": 0.152174,
        "main_score": 0.104466,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.359997,
        "recall": 0.407115,
        "f1": 0.37192,
        "accuracy": 0.407115,
        "main_score": 0.37192,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.339469,
        "recall": 0.438735,
        "f1": 0.364577,
        "accuracy": 0.438735,
        "main_score": 0.364577,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.885042,
        "recall": 0.913043,
        "f1": 0.893168,
        "accuracy": 0.913043,
        "main_score": 0.893168,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.875856,
        "recall": 0.913043,
        "f1": 0.887648,
        "accuracy": 0.913043,
        "main_score": 0.887648,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.595144,
        "recall": 0.649209,
        "f1": 0.609133,
        "accuracy": 0.649209,
        "main_score": 0.609133,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.605601,
        "recall": 0.695652,
        "f1": 0.631292,
        "accuracy": 0.695652,
        "main_score": 0.631292,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.87337,
        "recall": 0.905138,
        "f1": 0.882423,
        "accuracy": 0.905138,
        "main_score": 0.882423,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.867836,
        "recall": 0.906126,
        "f1": 0.879974,
        "accuracy": 0.906126,
        "main_score": 0.879974,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.871249,
        "recall": 0.90415,
        "f1": 0.880536,
        "accuracy": 0.90415,
        "main_score": 0.880536,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.872727,
        "recall": 0.912055,
        "f1": 0.885211,
        "accuracy": 0.912055,
        "main_score": 0.885211,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.836107,
        "recall": 0.873518,
        "f1": 0.846312,
        "accuracy": 0.873518,
        "main_score": 0.846312,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.81693,
        "recall": 0.869565,
        "f1": 0.832971,
        "accuracy": 0.869565,
        "main_score": 0.832971,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.394264,
        "recall": 0.459486,
        "f1": 0.409384,
        "accuracy": 0.459486,
        "main_score": 0.409384,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.38413,
        "recall": 0.48913,
        "f1": 0.410136,
        "accuracy": 0.48913,
        "main_score": 0.410136,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.873205,
        "recall": 0.90415,
        "f1": 0.88197,
        "accuracy": 0.90415,
        "main_score": 0.88197,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.88475,
        "recall": 0.91996,
        "f1": 0.89608,
        "accuracy": 0.91996,
        "main_score": 0.89608,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.893786,
        "recall": 0.922925,
        "f1": 0.902503,
        "accuracy": 0.922925,
        "main_score": 0.902503,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.878706,
        "recall": 0.91502,
        "f1": 0.890184,
        "accuracy": 0.91502,
        "main_score": 0.890184,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.016141,
        "recall": 0.019763,
        "f1": 0.016965,
        "accuracy": 0.019763,
        "main_score": 0.016965,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006437,
        "recall": 0.031621,
        "f1": 0.009505,
        "accuracy": 0.031621,
        "main_score": 0.009505,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 254.67870092391968,
  "kg_co2_emissions": 0.022155178188284927
}