{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "map": 0.890813,
        "mrr": 0.891924,
        "nAUC_map_max": 0.510328,
        "nAUC_map_std": 0.418337,
        "nAUC_map_diff1": 0.801525,
        "nAUC_mrr_max": 0.505331,
        "nAUC_mrr_std": 0.414828,
        "nAUC_mrr_diff1": 0.798385,
        "main_score": 0.890813,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.716494,
        "mrr": 0.718839,
        "nAUC_map_max": 0.42369,
        "nAUC_map_std": 0.269442,
        "nAUC_map_diff1": 0.606392,
        "nAUC_mrr_max": 0.423487,
        "nAUC_mrr_std": 0.269613,
        "nAUC_mrr_diff1": 0.599069,
        "main_score": 0.716494,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.892945,
        "mrr": 0.893945,
        "nAUC_map_max": 0.524099,
        "nAUC_map_std": 0.451442,
        "nAUC_map_diff1": 0.82795,
        "nAUC_mrr_max": 0.523217,
        "nAUC_mrr_std": 0.453655,
        "nAUC_mrr_diff1": 0.82518,
        "main_score": 0.892945,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.887609,
        "mrr": 0.888876,
        "nAUC_map_max": 0.477108,
        "nAUC_map_std": 0.461139,
        "nAUC_map_diff1": 0.814964,
        "nAUC_mrr_max": 0.474681,
        "nAUC_mrr_std": 0.456973,
        "nAUC_mrr_diff1": 0.812348,
        "main_score": 0.887609,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.901622,
        "mrr": 0.901789,
        "nAUC_map_max": 0.530372,
        "nAUC_map_std": 0.341221,
        "nAUC_map_diff1": 0.818972,
        "nAUC_mrr_max": 0.52987,
        "nAUC_mrr_std": 0.340058,
        "nAUC_mrr_diff1": 0.818729,
        "main_score": 0.901622,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.936476,
        "mrr": 0.93742,
        "nAUC_map_max": 0.569785,
        "nAUC_map_std": 0.50203,
        "nAUC_map_diff1": 0.871266,
        "nAUC_mrr_max": 0.562468,
        "nAUC_mrr_std": 0.510207,
        "nAUC_mrr_diff1": 0.868447,
        "main_score": 0.936476,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.815776,
        "mrr": 0.81722,
        "nAUC_map_max": 0.500788,
        "nAUC_map_std": 0.407269,
        "nAUC_map_diff1": 0.729414,
        "nAUC_mrr_max": 0.498603,
        "nAUC_mrr_std": 0.404652,
        "nAUC_mrr_diff1": 0.726869,
        "main_score": 0.815776,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.82571,
        "mrr": 0.826377,
        "nAUC_map_max": 0.303048,
        "nAUC_map_std": 0.275858,
        "nAUC_map_diff1": 0.689134,
        "nAUC_mrr_max": 0.302515,
        "nAUC_mrr_std": 0.275344,
        "nAUC_mrr_diff1": 0.687603,
        "main_score": 0.82571,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.801996,
        "mrr": 0.80391,
        "nAUC_map_max": 0.419179,
        "nAUC_map_std": 0.345932,
        "nAUC_map_diff1": 0.679127,
        "nAUC_mrr_max": 0.424504,
        "nAUC_mrr_std": 0.351492,
        "nAUC_mrr_diff1": 0.674703,
        "main_score": 0.801996,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.918818,
        "mrr": 0.919263,
        "nAUC_map_max": 0.565269,
        "nAUC_map_std": 0.427802,
        "nAUC_map_diff1": 0.84591,
        "nAUC_mrr_max": 0.563044,
        "nAUC_mrr_std": 0.429934,
        "nAUC_mrr_diff1": 0.84475,
        "main_score": 0.918818,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.899685,
        "mrr": 0.900897,
        "nAUC_map_max": 0.402521,
        "nAUC_map_std": 0.359667,
        "nAUC_map_diff1": 0.785077,
        "nAUC_mrr_max": 0.398499,
        "nAUC_mrr_std": 0.363267,
        "nAUC_mrr_diff1": 0.781387,
        "main_score": 0.899685,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.906754,
        "mrr": 0.906776,
        "nAUC_map_max": 0.505687,
        "nAUC_map_std": 0.362637,
        "nAUC_map_diff1": 0.804692,
        "nAUC_mrr_max": 0.505597,
        "nAUC_mrr_std": 0.362479,
        "nAUC_mrr_diff1": 0.804644,
        "main_score": 0.906754,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.896731,
        "mrr": 0.897842,
        "nAUC_map_max": 0.546856,
        "nAUC_map_std": 0.476824,
        "nAUC_map_diff1": 0.815057,
        "nAUC_mrr_max": 0.548107,
        "nAUC_mrr_std": 0.482332,
        "nAUC_mrr_diff1": 0.812187,
        "main_score": 0.896731,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.883993,
        "mrr": 0.884848,
        "nAUC_map_max": 0.411838,
        "nAUC_map_std": 0.350903,
        "nAUC_map_diff1": 0.76703,
        "nAUC_mrr_max": 0.416517,
        "nAUC_mrr_std": 0.355683,
        "nAUC_mrr_diff1": 0.765182,
        "main_score": 0.883993,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.857536,
        "mrr": 0.858314,
        "nAUC_map_max": 0.450795,
        "nAUC_map_std": 0.330687,
        "nAUC_map_diff1": 0.77862,
        "nAUC_mrr_max": 0.450397,
        "nAUC_mrr_std": 0.330009,
        "nAUC_mrr_diff1": 0.776361,
        "main_score": 0.857536,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.904614,
        "mrr": 0.905803,
        "nAUC_map_max": 0.447045,
        "nAUC_map_std": 0.415093,
        "nAUC_map_diff1": 0.781914,
        "nAUC_mrr_max": 0.444386,
        "nAUC_mrr_std": 0.414846,
        "nAUC_mrr_diff1": 0.778209,
        "main_score": 0.904614,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 470.63251209259033,
  "kg_co2_emissions": 0.04110611000757119
}