{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.599356,
        "f1": 0.578899,
        "f1_weighted": 0.614707,
        "ap": 0.750163,
        "ap_weighted": 0.750163,
        "scores_per_experiment": [
          {
            "accuracy": 0.560086,
            "f1": 0.547069,
            "f1_weighted": 0.577387,
            "ap": 0.736814,
            "ap_weighted": 0.736814
          },
          {
            "accuracy": 0.630901,
            "f1": 0.600781,
            "f1_weighted": 0.644079,
            "ap": 0.753883,
            "ap_weighted": 0.753883
          },
          {
            "accuracy": 0.648069,
            "f1": 0.628866,
            "f1_weighted": 0.662199,
            "ap": 0.778075,
            "ap_weighted": 0.778075
          },
          {
            "accuracy": 0.611588,
            "f1": 0.596189,
            "f1_weighted": 0.627325,
            "ap": 0.762745,
            "ap_weighted": 0.762745
          },
          {
            "accuracy": 0.581545,
            "f1": 0.567835,
            "f1_weighted": 0.598228,
            "ap": 0.74794,
            "ap_weighted": 0.74794
          },
          {
            "accuracy": 0.600858,
            "f1": 0.591097,
            "f1_weighted": 0.616043,
            "ap": 0.767211,
            "ap_weighted": 0.767211
          },
          {
            "accuracy": 0.60515,
            "f1": 0.586879,
            "f1_weighted": 0.621184,
            "ap": 0.754457,
            "ap_weighted": 0.754457
          },
          {
            "accuracy": 0.553648,
            "f1": 0.532994,
            "f1_weighted": 0.571773,
            "ap": 0.723355,
            "ap_weighted": 0.723355
          },
          {
            "accuracy": 0.590129,
            "f1": 0.544836,
            "f1_weighted": 0.601529,
            "ap": 0.720287,
            "ap_weighted": 0.720287
          },
          {
            "accuracy": 0.611588,
            "f1": 0.592443,
            "f1_weighted": 0.627321,
            "ap": 0.756866,
            "ap_weighted": 0.756866
          }
        ],
        "main_score": 0.599356,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.582548,
        "f1": 0.56483,
        "f1_weighted": 0.598897,
        "ap": 0.741524,
        "ap_weighted": 0.741524,
        "scores_per_experiment": [
          {
            "accuracy": 0.585653,
            "f1": 0.573605,
            "f1_weighted": 0.601692,
            "ap": 0.751306,
            "ap_weighted": 0.751306
          },
          {
            "accuracy": 0.56424,
            "f1": 0.54438,
            "f1_weighted": 0.581655,
            "ap": 0.727989,
            "ap_weighted": 0.727989
          },
          {
            "accuracy": 0.630621,
            "f1": 0.613055,
            "f1_weighted": 0.645362,
            "ap": 0.768551,
            "ap_weighted": 0.768551
          },
          {
            "accuracy": 0.602784,
            "f1": 0.585448,
            "f1_weighted": 0.618668,
            "ap": 0.752628,
            "ap_weighted": 0.752628
          },
          {
            "accuracy": 0.568522,
            "f1": 0.551686,
            "f1_weighted": 0.585731,
            "ap": 0.734084,
            "ap_weighted": 0.734084
          },
          {
            "accuracy": 0.571734,
            "f1": 0.561008,
            "f1_weighted": 0.587898,
            "ap": 0.745501,
            "ap_weighted": 0.745501
          },
          {
            "accuracy": 0.592077,
            "f1": 0.572268,
            "f1_weighted": 0.608339,
            "ap": 0.743137,
            "ap_weighted": 0.743137
          },
          {
            "accuracy": 0.533191,
            "f1": 0.520145,
            "f1_weighted": 0.551149,
            "ap": 0.720186,
            "ap_weighted": 0.720186
          },
          {
            "accuracy": 0.561028,
            "f1": 0.532162,
            "f1_weighted": 0.5777,
            "ap": 0.717231,
            "ap_weighted": 0.717231
          },
          {
            "accuracy": 0.615632,
            "f1": 0.594545,
            "f1_weighted": 0.630778,
            "ap": 0.754622,
            "ap_weighted": 0.754622
          }
        ],
        "main_score": 0.582548,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 42.42458939552307,
  "kg_co2_emissions": null
}