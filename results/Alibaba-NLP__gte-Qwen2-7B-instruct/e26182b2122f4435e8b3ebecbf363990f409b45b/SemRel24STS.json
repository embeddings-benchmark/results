{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 356.0233654975891,
  "kg_co2_emissions": 0.03349565770724446,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.833569437542509,
        "cosine_spearman": 0.8140081386981985,
        "euclidean_pearson": 0.8108919080251267,
        "euclidean_spearman": 0.8140081386981985,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.8140081386981985,
        "manhattan_pearson": 0.8061851211882383,
        "manhattan_spearman": 0.8120006759815195,
        "pearson": 0.833569437542509,
        "spearman": 0.8140081386981985
      },
      {
        "cosine_pearson": 0.6675608516152908,
        "cosine_spearman": 0.6454074352831501,
        "euclidean_pearson": 0.6628121891739125,
        "euclidean_spearman": 0.6454074352831501,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.6454074352831501,
        "manhattan_pearson": 0.6576121831175439,
        "manhattan_spearman": 0.6421100327122286,
        "pearson": 0.6675608516152908,
        "spearman": 0.6454074352831501
      },
      {
        "cosine_pearson": 0.6580419123335969,
        "cosine_spearman": 0.6604921026216631,
        "euclidean_pearson": 0.6518374721521558,
        "euclidean_spearman": 0.6604921026216631,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.6604921026216631,
        "manhattan_pearson": 0.6415076830930855,
        "manhattan_spearman": 0.6494072905010329,
        "pearson": 0.6580419123335969,
        "spearman": 0.6604921026216631
      },
      {
        "cosine_pearson": 0.5189516061387438,
        "cosine_spearman": 0.44880142001827317,
        "euclidean_pearson": 0.5246652967225749,
        "euclidean_spearman": 0.44880142001827317,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.44880142001827317,
        "manhattan_pearson": 0.5301304090612995,
        "manhattan_spearman": 0.4547593663102621,
        "pearson": 0.5189516061387438,
        "spearman": 0.44880142001827317
      },
      {
        "cosine_pearson": 0.4228636803287107,
        "cosine_spearman": 0.36708733156162177,
        "euclidean_pearson": 0.4085127718402518,
        "euclidean_spearman": 0.36708733156162177,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.36708733156162177,
        "manhattan_pearson": 0.40343853274128916,
        "manhattan_spearman": 0.36305469498861165,
        "pearson": 0.4228636803287107,
        "spearman": 0.36708733156162177
      },
      {
        "cosine_pearson": 0.8433021630712616,
        "cosine_spearman": 0.8330613181302486,
        "euclidean_pearson": 0.832210737678025,
        "euclidean_spearman": 0.8330609410872267,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8330613181302486,
        "manhattan_pearson": 0.8290906304076437,
        "manhattan_spearman": 0.829439592327664,
        "pearson": 0.8433021630712616,
        "spearman": 0.8330613181302486
      },
      {
        "cosine_pearson": 0.4931587333041344,
        "cosine_spearman": 0.46498545371013983,
        "euclidean_pearson": 0.49760432272427935,
        "euclidean_spearman": 0.46498545371013983,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.46498545371013983,
        "manhattan_pearson": 0.49903736069229054,
        "manhattan_spearman": 0.4675484920133114,
        "pearson": 0.4931587333041344,
        "spearman": 0.46498545371013983
      },
      {
        "cosine_pearson": 0.7887362151267527,
        "cosine_spearman": 0.7978275670850565,
        "euclidean_pearson": 0.7617214204088322,
        "euclidean_spearman": 0.7978275670850565,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.7978275670850565,
        "manhattan_pearson": 0.755675497703123,
        "manhattan_spearman": 0.7913558305820494,
        "pearson": 0.7887362151267527,
        "spearman": 0.7978275670850565
      },
      {
        "cosine_pearson": 0.4809750182641661,
        "cosine_spearman": 0.47718155308321314,
        "euclidean_pearson": 0.49283239979765886,
        "euclidean_spearman": 0.47718155308321314,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.47718155308321314,
        "manhattan_pearson": 0.4873621649895905,
        "manhattan_spearman": 0.469944447229986,
        "pearson": 0.4809750182641661,
        "spearman": 0.47718155308321314
      },
      {
        "cosine_pearson": 0.4505578452343442,
        "cosine_spearman": 0.4496583379380963,
        "euclidean_pearson": 0.46519154592070955,
        "euclidean_spearman": 0.4496583379380963,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.4496583379380963,
        "manhattan_pearson": 0.4820624595986101,
        "manhattan_spearman": 0.46724791135461835,
        "pearson": 0.4505578452343442,
        "spearman": 0.4496583379380963
      },
      {
        "cosine_pearson": 0.8285035097858051,
        "cosine_spearman": 0.806525985831385,
        "euclidean_pearson": 0.8149168764183242,
        "euclidean_spearman": 0.806525985831385,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.806525985831385,
        "manhattan_pearson": 0.8131623694759061,
        "manhattan_spearman": 0.8003463010023645,
        "pearson": 0.8285035097858051,
        "spearman": 0.806525985831385
      },
      {
        "cosine_pearson": 0.822703311867833,
        "cosine_spearman": 0.7885363261355761,
        "euclidean_pearson": 0.8075221871533662,
        "euclidean_spearman": 0.7885363261355761,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.7885363261355761,
        "manhattan_pearson": 0.8047881725517677,
        "manhattan_spearman": 0.7835206070632272,
        "pearson": 0.822703311867833,
        "spearman": 0.7885363261355761
      }
    ]
  },
  "task_name": "SemRel24STS"
}