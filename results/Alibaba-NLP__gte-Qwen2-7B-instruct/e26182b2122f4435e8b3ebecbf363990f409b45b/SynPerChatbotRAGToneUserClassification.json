{
  "dataset_revision": "f1f6ad83bb135dc94fbf1ca05c3ba164f5619369",
  "task_name": "SynPerChatbotRAGToneUserClassification",
  "mteb_version": "1.25.8",
  "scores": {
    "test": [
      {
        "accuracy": 0.421711,
        "f1": 0.412049,
        "f1_weighted": 0.422519,
        "scores_per_experiment": [
          {
            "accuracy": 0.401104,
            "f1": 0.409604,
            "f1_weighted": 0.413902
          },
          {
            "accuracy": 0.463661,
            "f1": 0.458522,
            "f1_weighted": 0.467319
          },
          {
            "accuracy": 0.435143,
            "f1": 0.411159,
            "f1_weighted": 0.430078
          },
          {
            "accuracy": 0.401104,
            "f1": 0.38713,
            "f1_weighted": 0.410742
          },
          {
            "accuracy": 0.434223,
            "f1": 0.412671,
            "f1_weighted": 0.426251
          },
          {
            "accuracy": 0.419503,
            "f1": 0.402901,
            "f1_weighted": 0.413522
          },
          {
            "accuracy": 0.391904,
            "f1": 0.387338,
            "f1_weighted": 0.390689
          },
          {
            "accuracy": 0.424103,
            "f1": 0.404197,
            "f1_weighted": 0.431808
          },
          {
            "accuracy": 0.427783,
            "f1": 0.430343,
            "f1_weighted": 0.435045
          },
          {
            "accuracy": 0.418583,
            "f1": 0.416628,
            "f1_weighted": 0.405836
          }
        ],
        "main_score": 0.421711,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 104.08423113822937,
  "kg_co2_emissions": null
}