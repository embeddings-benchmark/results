{
  "dataset_revision": "9dae119101e9b4e9bb40d5b9d29ffd7a621f9942",
  "task_name": "SynPerChatbotConvSAFriendship",
  "mteb_version": "1.25.8",
  "scores": {
    "test": [
      {
        "accuracy": 0.487681,
        "f1": 0.470091,
        "f1_weighted": 0.501431,
        "ap": 0.659384,
        "ap_weighted": 0.659384,
        "scores_per_experiment": [
          {
            "accuracy": 0.478261,
            "f1": 0.464655,
            "f1_weighted": 0.493103,
            "ap": 0.657289,
            "ap_weighted": 0.657289
          },
          {
            "accuracy": 0.449275,
            "f1": 0.41798,
            "f1_weighted": 0.462967,
            "ap": 0.633919,
            "ap_weighted": 0.633919
          },
          {
            "accuracy": 0.514493,
            "f1": 0.488691,
            "f1_weighted": 0.526977,
            "ap": 0.664267,
            "ap_weighted": 0.664267
          },
          {
            "accuracy": 0.485507,
            "f1": 0.461737,
            "f1_weighted": 0.499441,
            "ap": 0.652754,
            "ap_weighted": 0.652754
          },
          {
            "accuracy": 0.543478,
            "f1": 0.515789,
            "f1_weighted": 0.554386,
            "ap": 0.676573,
            "ap_weighted": 0.676573
          },
          {
            "accuracy": 0.507246,
            "f1": 0.498718,
            "f1_weighted": 0.520513,
            "ap": 0.67663,
            "ap_weighted": 0.67663
          },
          {
            "accuracy": 0.463768,
            "f1": 0.454487,
            "f1_weighted": 0.478205,
            "ap": 0.655061,
            "ap_weighted": 0.655061
          },
          {
            "accuracy": 0.449275,
            "f1": 0.43746,
            "f1_weighted": 0.464636,
            "ap": 0.64641,
            "ap_weighted": 0.64641
          },
          {
            "accuracy": 0.492754,
            "f1": 0.481871,
            "f1_weighted": 0.506901,
            "ap": 0.666667,
            "ap_weighted": 0.666667
          },
          {
            "accuracy": 0.492754,
            "f1": 0.479526,
            "f1_weighted": 0.507184,
            "ap": 0.664269,
            "ap_weighted": 0.664269
          }
        ],
        "main_score": 0.487681,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 35.41565990447998,
  "kg_co2_emissions": null
}