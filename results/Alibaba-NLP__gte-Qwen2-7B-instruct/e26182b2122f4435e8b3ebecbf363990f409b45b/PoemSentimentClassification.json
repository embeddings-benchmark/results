{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 24.81924271583557,
  "kg_co2_emissions": 0.0013705899168940305,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.5499999999999999,
        "f1": 0.43099361910896217,
        "f1_weighted": 0.6092954720003506,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5499999999999999,
        "scores_per_experiment": [
          {
            "accuracy": 0.6346153846153846,
            "f1": 0.5015108011004044,
            "f1_weighted": 0.7042640091677239
          },
          {
            "accuracy": 0.5384615384615384,
            "f1": 0.44115130919088585,
            "f1_weighted": 0.6098923628791943
          },
          {
            "accuracy": 0.49038461538461536,
            "f1": 0.40938971742543173,
            "f1_weighted": 0.5507694571911604
          },
          {
            "accuracy": 0.6634615384615384,
            "f1": 0.521680297104026,
            "f1_weighted": 0.7304337882890686
          },
          {
            "accuracy": 0.5961538461538461,
            "f1": 0.3954846794405368,
            "f1_weighted": 0.6446808709117706
          },
          {
            "accuracy": 0.5769230769230769,
            "f1": 0.46519246519246515,
            "f1_weighted": 0.6447268947268946
          },
          {
            "accuracy": 0.47115384615384615,
            "f1": 0.3842425643396517,
            "f1_weighted": 0.5177365245326411
          },
          {
            "accuracy": 0.5384615384615384,
            "f1": 0.39650081376424084,
            "f1_weighted": 0.5939016865487453
          },
          {
            "accuracy": 0.5096153846153846,
            "f1": 0.4005527743012099,
            "f1_weighted": 0.5407059304900357
          },
          {
            "accuracy": 0.4807692307692308,
            "f1": 0.3942307692307692,
            "f1_weighted": 0.5558431952662721
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5609523809523809,
        "f1": 0.4306544973799896,
        "f1_weighted": 0.6235133874944778,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5609523809523809,
        "scores_per_experiment": [
          {
            "accuracy": 0.5904761904761905,
            "f1": 0.4559646311291048,
            "f1_weighted": 0.6693376068376069
          },
          {
            "accuracy": 0.5238095238095238,
            "f1": 0.4087757054041129,
            "f1_weighted": 0.6049736967957915
          },
          {
            "accuracy": 0.47619047619047616,
            "f1": 0.41299874205722026,
            "f1_weighted": 0.5491246162045762
          },
          {
            "accuracy": 0.7142857142857143,
            "f1": 0.5509920634920635,
            "f1_weighted": 0.7798866213151927
          },
          {
            "accuracy": 0.6,
            "f1": 0.42876069346657586,
            "f1_weighted": 0.6552256938811561
          },
          {
            "accuracy": 0.6095238095238096,
            "f1": 0.45706115779645196,
            "f1_weighted": 0.6644866835623139
          },
          {
            "accuracy": 0.5142857142857142,
            "f1": 0.42250951281891336,
            "f1_weighted": 0.5757077804610709
          },
          {
            "accuracy": 0.6666666666666666,
            "f1": 0.4644155433629118,
            "f1_weighted": 0.705840534411963
          },
          {
            "accuracy": 0.4857142857142857,
            "f1": 0.3660537663778048,
            "f1_weighted": 0.525645879570345
          },
          {
            "accuracy": 0.42857142857142855,
            "f1": 0.33901315789473685,
            "f1_weighted": 0.5049047619047619
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}