{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.590083,
        "f1": 0.576169,
        "f1_weighted": 0.576169,
        "ap": 0.556415,
        "ap_weighted": 0.556415,
        "scores_per_experiment": [
          {
            "accuracy": 0.594167,
            "f1": 0.594133,
            "f1_weighted": 0.594133,
            "ap": 0.555791,
            "ap_weighted": 0.555791
          },
          {
            "accuracy": 0.605833,
            "f1": 0.575454,
            "f1_weighted": 0.575454,
            "ap": 0.560214,
            "ap_weighted": 0.560214
          },
          {
            "accuracy": 0.614167,
            "f1": 0.587892,
            "f1_weighted": 0.587892,
            "ap": 0.583415,
            "ap_weighted": 0.583415
          },
          {
            "accuracy": 0.624167,
            "f1": 0.61779,
            "f1_weighted": 0.61779,
            "ap": 0.574336,
            "ap_weighted": 0.574336
          },
          {
            "accuracy": 0.526667,
            "f1": 0.513693,
            "f1_weighted": 0.513693,
            "ap": 0.514389,
            "ap_weighted": 0.514389
          },
          {
            "accuracy": 0.6,
            "f1": 0.549435,
            "f1_weighted": 0.549435,
            "ap": 0.555988,
            "ap_weighted": 0.555988
          },
          {
            "accuracy": 0.488333,
            "f1": 0.486049,
            "f1_weighted": 0.486049,
            "ap": 0.494287,
            "ap_weighted": 0.494287
          },
          {
            "accuracy": 0.545,
            "f1": 0.544715,
            "f1_weighted": 0.544715,
            "ap": 0.524429,
            "ap_weighted": 0.524429
          },
          {
            "accuracy": 0.685,
            "f1": 0.683731,
            "f1_weighted": 0.683731,
            "ap": 0.622877,
            "ap_weighted": 0.622877
          },
          {
            "accuracy": 0.6175,
            "f1": 0.608795,
            "f1_weighted": 0.608795,
            "ap": 0.578426,
            "ap_weighted": 0.578426
          }
        ],
        "main_score": 0.590083,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.579,
        "f1": 0.562954,
        "f1_weighted": 0.562954,
        "ap": 0.549633,
        "ap_weighted": 0.549633,
        "scores_per_experiment": [
          {
            "accuracy": 0.545833,
            "f1": 0.545694,
            "f1_weighted": 0.545694,
            "ap": 0.524946,
            "ap_weighted": 0.524946
          },
          {
            "accuracy": 0.598333,
            "f1": 0.566327,
            "f1_weighted": 0.566327,
            "ap": 0.555432,
            "ap_weighted": 0.555432
          },
          {
            "accuracy": 0.620833,
            "f1": 0.589609,
            "f1_weighted": 0.589609,
            "ap": 0.592983,
            "ap_weighted": 0.592983
          },
          {
            "accuracy": 0.623333,
            "f1": 0.616516,
            "f1_weighted": 0.616516,
            "ap": 0.573675,
            "ap_weighted": 0.573675
          },
          {
            "accuracy": 0.5325,
            "f1": 0.517875,
            "f1_weighted": 0.517875,
            "ap": 0.517871,
            "ap_weighted": 0.517871
          },
          {
            "accuracy": 0.573333,
            "f1": 0.511809,
            "f1_weighted": 0.511809,
            "ap": 0.539812,
            "ap_weighted": 0.539812
          },
          {
            "accuracy": 0.48,
            "f1": 0.478225,
            "f1_weighted": 0.478225,
            "ap": 0.490358,
            "ap_weighted": 0.490358
          },
          {
            "accuracy": 0.545833,
            "f1": 0.545808,
            "f1_weighted": 0.545808,
            "ap": 0.525049,
            "ap_weighted": 0.525049
          },
          {
            "accuracy": 0.6625,
            "f1": 0.661507,
            "f1_weighted": 0.661507,
            "ap": 0.605075,
            "ap_weighted": 0.605075
          },
          {
            "accuracy": 0.6075,
            "f1": 0.59617,
            "f1_weighted": 0.59617,
            "ap": 0.571128,
            "ap_weighted": 0.571128
          }
        ],
        "main_score": 0.579,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 54.951600074768066,
  "kg_co2_emissions": 0.0044528875322392535
}