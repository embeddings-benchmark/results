{
  "dataset_revision": "e9c678325565a5e4dadc43fd6693a8ccff1dd6b2",
  "task_name": "SynPerChatbotConvSASadness",
  "mteb_version": "1.25.8",
  "scores": {
    "test": [
      {
        "accuracy": 0.646078,
        "f1": 0.633545,
        "f1_weighted": 0.655051,
        "ap": 0.75288,
        "ap_weighted": 0.75288,
        "scores_per_experiment": [
          {
            "accuracy": 0.72549,
            "f1": 0.699495,
            "f1_weighted": 0.728956,
            "ap": 0.778186,
            "ap_weighted": 0.778186
          },
          {
            "accuracy": 0.656863,
            "f1": 0.647059,
            "f1_weighted": 0.666667,
            "ap": 0.763552,
            "ap_weighted": 0.763552
          },
          {
            "accuracy": 0.676471,
            "f1": 0.66215,
            "f1_weighted": 0.685336,
            "ap": 0.766934,
            "ap_weighted": 0.766934
          },
          {
            "accuracy": 0.617647,
            "f1": 0.611334,
            "f1_weighted": 0.627846,
            "ap": 0.745932,
            "ap_weighted": 0.745932
          },
          {
            "accuracy": 0.617647,
            "f1": 0.613148,
            "f1_weighted": 0.627054,
            "ap": 0.751307,
            "ap_weighted": 0.751307
          },
          {
            "accuracy": 0.607843,
            "f1": 0.58871,
            "f1_weighted": 0.61828,
            "ap": 0.718137,
            "ap_weighted": 0.718137
          },
          {
            "accuracy": 0.598039,
            "f1": 0.586555,
            "f1_weighted": 0.609524,
            "ap": 0.722895,
            "ap_weighted": 0.722895
          },
          {
            "accuracy": 0.686275,
            "f1": 0.664474,
            "f1_weighted": 0.692982,
            "ap": 0.760784,
            "ap_weighted": 0.760784
          },
          {
            "accuracy": 0.617647,
            "f1": 0.611334,
            "f1_weighted": 0.627846,
            "ap": 0.745932,
            "ap_weighted": 0.745932
          },
          {
            "accuracy": 0.656863,
            "f1": 0.651197,
            "f1_weighted": 0.666015,
            "ap": 0.775136,
            "ap_weighted": 0.775136
          }
        ],
        "main_score": 0.646078,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 28.68846368789673,
  "kg_co2_emissions": null
}