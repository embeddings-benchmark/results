{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 2061.4366958141327,
  "kg_co2_emissions": 0.19797415552407108,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.689453125,
        "f1": 0.6581814236111112,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.6581814236111112,
        "precision": 0.646435546875,
        "recall": 0.689453125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9892578125,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9892578125,
        "precision": 0.98828125,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.9474934895833333,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.9474934895833333,
        "precision": 0.9424641927083334,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9762369791666666,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.9762369791666666,
        "precision": 0.9737955729166667,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.9365234375,
        "f1": 0.9195963541666667,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.9195963541666667,
        "precision": 0.9114583333333334,
        "recall": 0.9365234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333333,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.9886067708333333,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0070445820785494705,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0070445820785494705,
        "precision": 0.005613060984154735,
        "recall": 0.015625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9807942708333334,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.9807942708333334,
        "precision": 0.978515625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00908644996528441,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.00908644996528441,
        "precision": 0.006643132072948069,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.9638671875,
        "f1": 0.9527994791666666,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.9527994791666666,
        "precision": 0.9474283854166667,
        "recall": 0.9638671875
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9490559895833333,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.9490559895833333,
        "precision": 0.9438802083333333,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9703776041666667,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.9703776041666667,
        "precision": 0.9669596354166667,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.697265625,
        "f1": 0.6642136346726191,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.6642136346726191,
        "precision": 0.6516206287202381,
        "recall": 0.697265625
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9912109375,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9912109375,
        "precision": 0.990234375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9747721354166666,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.9747721354166666,
        "precision": 0.97216796875,
        "recall": 0.98046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.947265625,
        "f1": 0.9358723958333333,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.9358723958333333,
        "precision": 0.9305013020833333,
        "recall": 0.947265625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.004224374304083021,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.004224374304083021,
        "precision": 0.00299463313379329,
        "recall": 0.013671875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.012337661752451441,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.012337661752451441,
        "precision": 0.009809584796232482,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9718424479166667,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.9718424479166667,
        "precision": 0.9685872395833334,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9835611979166667,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.9835611979166667,
        "precision": 0.9817708333333334,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666667,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.9869791666666667,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.6318359375,
        "f1": 0.5934545677607359,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5934545677607359,
        "precision": 0.5813614220951289,
        "recall": 0.6318359375
      },
      {
        "accuracy": 0.6259765625,
        "f1": 0.586580699388445,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.586580699388445,
        "precision": 0.5729550928101503,
        "recall": 0.6259765625
      },
      {
        "accuracy": 0.6474609375,
        "f1": 0.6176719703886444,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6176719703886444,
        "precision": 0.6085028938555597,
        "recall": 0.6474609375
      },
      {
        "accuracy": 0.6259765625,
        "f1": 0.5922136202375923,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5922136202375923,
        "precision": 0.5817772979516144,
        "recall": 0.6259765625
      },
      {
        "accuracy": 0.6435546875,
        "f1": 0.6147241857612014,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6147241857612014,
        "precision": 0.604885446873326,
        "recall": 0.6435546875
      },
      {
        "accuracy": 0.638671875,
        "f1": 0.602691042681277,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.602691042681277,
        "precision": 0.5899690627867527,
        "recall": 0.638671875
      },
      {
        "accuracy": 0.6455078125,
        "f1": 0.6133522374977453,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.6133522374977453,
        "precision": 0.6017074342757937,
        "recall": 0.6455078125
      },
      {
        "accuracy": 0.609375,
        "f1": 0.5715755785971076,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5715755785971076,
        "precision": 0.5589451636326637,
        "recall": 0.609375
      },
      {
        "accuracy": 0.619140625,
        "f1": 0.5873488653273808,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5873488653273808,
        "precision": 0.5766433635085979,
        "recall": 0.619140625
      },
      {
        "accuracy": 0.6357421875,
        "f1": 0.6022692113498198,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6022692113498198,
        "precision": 0.5924582233359089,
        "recall": 0.6357421875
      },
      {
        "accuracy": 0.6337890625,
        "f1": 0.593179676768544,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.593179676768544,
        "precision": 0.5791759672619047,
        "recall": 0.6337890625
      },
      {
        "accuracy": 0.626953125,
        "f1": 0.5931782413486227,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5931782413486227,
        "precision": 0.581406543780283,
        "recall": 0.626953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00857312903142858,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00857312903142858,
        "precision": 0.007160929890422078,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.64453125,
        "f1": 0.6127994759219507,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6127994759219507,
        "precision": 0.6036525359236182,
        "recall": 0.64453125
      },
      {
        "accuracy": 0.6298828125,
        "f1": 0.5841002511326501,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.5841002511326501,
        "precision": 0.5682525522979625,
        "recall": 0.6298828125
      },
      {
        "accuracy": 0.642578125,
        "f1": 0.604028552827381,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.604028552827381,
        "precision": 0.5918042135815573,
        "recall": 0.642578125
      },
      {
        "accuracy": 0.6337890625,
        "f1": 0.5980806317613196,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.5980806317613196,
        "precision": 0.5856272777672347,
        "recall": 0.6337890625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013872202054112074,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.013872202054112074,
        "precision": 0.011430880260547203,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.6708984375,
        "f1": 0.6415056074695321,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6415056074695321,
        "precision": 0.6319468649839743,
        "recall": 0.6708984375
      },
      {
        "accuracy": 0.55078125,
        "f1": 0.5114231682912119,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.5114231682912119,
        "precision": 0.4972516741071429,
        "recall": 0.55078125
      },
      {
        "accuracy": 0.6259765625,
        "f1": 0.5904149827659508,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5904149827659508,
        "precision": 0.5781151751065009,
        "recall": 0.6259765625
      },
      {
        "accuracy": 0.638671875,
        "f1": 0.6002541765237077,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6002541765237077,
        "precision": 0.5871060694570376,
        "recall": 0.638671875
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98095703125,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.98095703125,
        "precision": 0.9788411458333334,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.986328125,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.986328125,
        "precision": 0.98486328125,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.69921875,
        "f1": 0.6695188492063493,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.6695188492063493,
        "precision": 0.6584321277680653,
        "recall": 0.69921875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.9333333333333333,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9333333333333333,
        "precision": 0.926513671875,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.986328125,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.986328125,
        "precision": 0.98486328125,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9899088541666666,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9899088541666666,
        "precision": 0.98876953125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.9677734375,
        "f1": 0.9583333333333333,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9583333333333333,
        "precision": 0.9541015625,
        "recall": 0.9677734375
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9113606770833333,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.9113606770833333,
        "precision": 0.9038899739583333,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9632161458333333,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9632161458333333,
        "precision": 0.9591471354166667,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9873046875,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9873046875,
        "precision": 0.98583984375,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.008277529761904762,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.008277529761904762,
        "precision": 0.006530879501488901,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666666,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9938151041666666,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.97451171875,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.97451171875,
        "precision": 0.9717610677083334,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.97314453125,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.97314453125,
        "precision": 0.9700520833333334,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9757486979166666,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9757486979166666,
        "precision": 0.9729817708333334,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018907613273524013,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.018907613273524013,
        "precision": 0.015195011423038765,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9508463541666666,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.9508463541666666,
        "precision": 0.9463216145833333,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.9306640625,
        "f1": 0.9129231770833334,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9129231770833334,
        "precision": 0.9044921875,
        "recall": 0.9306640625
      },
      {
        "accuracy": 0.955078125,
        "f1": 0.9437500000000001,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9437500000000001,
        "precision": 0.9383951822916666,
        "recall": 0.955078125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9876953125,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9876953125,
        "precision": 0.986572265625,
        "recall": 0.990234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.6875,
        "f1": 0.651709829883658,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.651709829883658,
        "precision": 0.6374279203869047,
        "recall": 0.6875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9718424479166667,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.9718424479166667,
        "precision": 0.9685872395833334,
        "recall": 0.978515625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.94912109375,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.94912109375,
        "precision": 0.944091796875,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.006509641617063492,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.006509641617063492,
        "precision": 0.0048195595697923446,
        "recall": 0.0185546875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.014687817424161302,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.014687817424161302,
        "precision": 0.012204598331135297,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9734700520833333,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.9734700520833333,
        "precision": 0.9705403645833333,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.98486328125,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.98486328125,
        "precision": 0.9832356770833333,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9912109375,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9912109375,
        "precision": 0.990234375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.951171875,
        "f1": 0.93837890625,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.93837890625,
        "precision": 0.9329264322916667,
        "recall": 0.951171875
      },
      {
        "accuracy": 0.9638671875,
        "f1": 0.95302734375,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.95302734375,
        "precision": 0.9481608072916666,
        "recall": 0.9638671875
      },
      {
        "accuracy": 0.701171875,
        "f1": 0.6743038862179487,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.6743038862179487,
        "precision": 0.6634765625,
        "recall": 0.701171875
      },
      {
        "accuracy": 0.9462890625,
        "f1": 0.9342013888888889,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9342013888888889,
        "precision": 0.9287516276041666,
        "recall": 0.9462890625
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9554036458333333,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9554036458333333,
        "precision": 0.9512369791666667,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.9677734375,
        "f1": 0.9580729166666666,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9580729166666666,
        "precision": 0.9536946614583333,
        "recall": 0.9677734375
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9596354166666666,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9596354166666666,
        "precision": 0.9554036458333333,
        "recall": 0.96875
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.9307291666666666,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9307291666666666,
        "precision": 0.9254394531250001,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.888671875,
        "f1": 0.8677269345238096,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.8677269345238096,
        "precision": 0.8590115017361111,
        "recall": 0.888671875
      },
      {
        "accuracy": 0.9677734375,
        "f1": 0.9596354166666666,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9596354166666666,
        "precision": 0.9558919270833333,
        "recall": 0.9677734375
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.9296875,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9296875,
        "precision": 0.9222005208333334,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9660993303571428,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9660993303571428,
        "precision": 0.9627278645833334,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0037872626277231534,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0037872626277231534,
        "precision": 0.00271387141504329,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.9619140625,
        "f1": 0.9508138020833333,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9508138020833333,
        "precision": 0.9459635416666667,
        "recall": 0.9619140625
      },
      {
        "accuracy": 0.9560546875,
        "f1": 0.9433268229166667,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9433268229166667,
        "precision": 0.9375,
        "recall": 0.9560546875
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.9164713541666666,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9164713541666666,
        "precision": 0.9085611979166667,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.93544921875,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.93544921875,
        "precision": 0.9294759114583333,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.012800901610644257,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.012800901610644257,
        "precision": 0.010218042662516517,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9082356770833333,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.9082356770833333,
        "precision": 0.900830078125,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.888671875,
        "f1": 0.8658115014097744,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8658115014097744,
        "precision": 0.8564181857638888,
        "recall": 0.888671875
      },
      {
        "accuracy": 0.9267578125,
        "f1": 0.9112165178571427,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9112165178571427,
        "precision": 0.9047247023809524,
        "recall": 0.9267578125
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9557942708333333,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9557942708333333,
        "precision": 0.9512532552083334,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.697265625,
        "f1": 0.6643415178571428,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.6643415178571428,
        "precision": 0.6509602864583334,
        "recall": 0.697265625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.9674479166666666,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.9674479166666666,
        "precision": 0.9640299479166667,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9860026041666666,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.9860026041666666,
        "precision": 0.984375,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9501953125,
        "f1": 0.9365234375,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.9365234375,
        "precision": 0.9300130208333333,
        "recall": 0.9501953125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666667,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.9938151041666667,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003324833622685185,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.003324833622685185,
        "precision": 0.002206006113541064,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9899088541666666,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.9899088541666666,
        "precision": 0.98876953125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.01329451245547671,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.01329451245547671,
        "precision": 0.010571709768922462,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9702799479166666,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.9702799479166666,
        "precision": 0.9673665364583334,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.970703125,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.970703125,
        "precision": 0.96728515625,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.98583984375,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.98583984375,
        "precision": 0.9842122395833334,
        "recall": 0.9892578125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.7001953125,
        "f1": 0.6704613095238094,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.6704613095238094,
        "precision": 0.6584170386904762,
        "recall": 0.7001953125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9722330729166666,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9722330729166666,
        "precision": 0.9693196614583333,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666666,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9938151041666666,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.94140625,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.94140625,
        "precision": 0.9352213541666666,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.005966574950415119,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005966574950415119,
        "precision": 0.004816149605032212,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.016915351444747193,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.016915351444747193,
        "precision": 0.014096899203900146,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9762369791666667,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.9762369791666667,
        "precision": 0.9737955729166667,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9733072916666667,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9733072916666667,
        "precision": 0.9703776041666667,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9747721354166666,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.9747721354166666,
        "precision": 0.9720052083333333,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9873697916666666,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.9873697916666666,
        "precision": 0.986083984375,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.67578125,
        "f1": 0.6450567336309524,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.6450567336309524,
        "precision": 0.6326009114583333,
        "recall": 0.67578125
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9571614583333334,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.9571614583333334,
        "precision": 0.95263671875,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9501953125,
        "f1": 0.9372395833333333,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.9372395833333333,
        "precision": 0.9310709635416666,
        "recall": 0.9501953125
      },
      {
        "accuracy": 0.984375,
        "f1": 0.97998046875,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.97998046875,
        "precision": 0.9778645833333334,
        "recall": 0.984375
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9860026041666666,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.9860026041666666,
        "precision": 0.9845377604166666,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.896484375,
        "f1": 0.8746279761904762,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.8746279761904762,
        "precision": 0.8644205729166666,
        "recall": 0.896484375
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9650065104166667,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.9650065104166667,
        "precision": 0.9607747395833334,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9733723958333333,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.9733723958333333,
        "precision": 0.9706217447916667,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9796549479166666,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.9796549479166666,
        "precision": 0.9775390625,
        "recall": 0.984375
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.007168172181781723,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.007168172181781723,
        "precision": 0.005703658854941801,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9811197916666667,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.9811197916666667,
        "precision": 0.9791666666666667,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.97705078125,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.97705078125,
        "precision": 0.9744466145833333,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9641927083333333,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.9641927083333333,
        "precision": 0.96015625,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9694010416666666,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.9694010416666666,
        "precision": 0.9659830729166667,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014643177792848844,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.014643177792848844,
        "precision": 0.011918805938214577,
        "recall": 0.03125
      },
      {
        "accuracy": 0.9443359375,
        "f1": 0.9294270833333333,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.9294270833333333,
        "precision": 0.922607421875,
        "recall": 0.9443359375
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.9347981770833333,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.9347981770833333,
        "precision": 0.927978515625,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9806315104166667,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.9806315104166667,
        "precision": 0.9783528645833333,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.98583984375,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.98583984375,
        "precision": 0.9842122395833334,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9306640625,
        "f1": 0.9148297991071428,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.9148297991071428,
        "precision": 0.9075846354166667,
        "recall": 0.9306640625
      },
      {
        "accuracy": 0.9267578125,
        "f1": 0.9082179214015151,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9082179214015151,
        "precision": 0.9001953125000001,
        "recall": 0.9267578125
      },
      {
        "accuracy": 0.658203125,
        "f1": 0.621824029090803,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.621824029090803,
        "precision": 0.6084269205729167,
        "recall": 0.658203125
      },
      {
        "accuracy": 0.9375,
        "f1": 0.92021484375,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.92021484375,
        "precision": 0.9122721354166666,
        "recall": 0.9375
      },
      {
        "accuracy": 0.9375,
        "f1": 0.9215317234848484,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9215317234848484,
        "precision": 0.9143229166666667,
        "recall": 0.9375
      },
      {
        "accuracy": 0.892578125,
        "f1": 0.8676432291666667,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.8676432291666667,
        "precision": 0.8568359375000001,
        "recall": 0.892578125
      },
      {
        "accuracy": 0.9365234375,
        "f1": 0.9197265625,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.9197265625,
        "precision": 0.9121419270833333,
        "recall": 0.9365234375
      },
      {
        "accuracy": 0.9365234375,
        "f1": 0.9221571180555557,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9221571180555557,
        "precision": 0.9155680338541667,
        "recall": 0.9365234375
      },
      {
        "accuracy": 0.8857421875,
        "f1": 0.8608258928571428,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.8608258928571428,
        "precision": 0.8498860677083334,
        "recall": 0.8857421875
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.9249348958333333,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9249348958333333,
        "precision": 0.91748046875,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.9150390625,
        "f1": 0.8912760416666666,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.8912760416666666,
        "precision": 0.8800455729166666,
        "recall": 0.9150390625
      },
      {
        "accuracy": 0.92578125,
        "f1": 0.9083224826388888,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9083224826388888,
        "precision": 0.9007893880208333,
        "recall": 0.92578125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006763583638583639,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.006763583638583639,
        "precision": 0.00527246005890126,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.9271158854166667,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.9271158854166667,
        "precision": 0.9200032552083334,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.9267578125,
        "f1": 0.90703125,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.90703125,
        "precision": 0.89794921875,
        "recall": 0.9267578125
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.8832573784722222,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.8832573784722222,
        "precision": 0.8723063151041666,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.898388671875,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.898388671875,
        "precision": 0.8899018787202381,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.014959194215732939,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.014959194215732939,
        "precision": 0.012516298334063279,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8952985491071428,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.8952985491071428,
        "precision": 0.8860677083333333,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.830078125,
        "f1": 0.7980329241071429,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.7980329241071429,
        "precision": 0.7843044704861112,
        "recall": 0.830078125
      },
      {
        "accuracy": 0.896484375,
        "f1": 0.8719726562500001,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.8719726562500001,
        "precision": 0.8604329427083333,
        "recall": 0.896484375
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9497721354166666,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.9497721354166666,
        "precision": 0.9444173177083334,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.697265625,
        "f1": 0.6631045386904761,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.6631045386904761,
        "precision": 0.6495198567708333,
        "recall": 0.697265625
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9899088541666666,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9899088541666666,
        "precision": 0.98876953125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9558919270833333,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9558919270833333,
        "precision": 0.9510091145833334,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.9670247395833333,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9670247395833333,
        "precision": 0.9634602864583333,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.9423828125,
        "f1": 0.9264973958333333,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.9264973958333333,
        "precision": 0.919189453125,
        "recall": 0.9423828125
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333334,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9856770833333334,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008443145537659805,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.008443145537659805,
        "precision": 0.006794838280706675,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9820963541666666,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9820963541666666,
        "precision": 0.97998046875,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9910481770833333,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.9910481770833333,
        "precision": 0.9900716145833333,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.015565722379713423,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.015565722379713423,
        "precision": 0.013281493390082895,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9611002604166667,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.9611002604166667,
        "precision": 0.9568684895833334,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9388020833333333,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9388020833333333,
        "precision": 0.9319661458333333,
        "recall": 0.953125
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.96533203125,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.96533203125,
        "precision": 0.9619140625,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.6669921875,
        "f1": 0.639942251758658,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.639942251758658,
        "precision": 0.630078125,
        "recall": 0.6669921875
      },
      {
        "accuracy": 0.9677734375,
        "f1": 0.95888671875,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.95888671875,
        "precision": 0.9546712239583333,
        "recall": 0.9677734375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9396809895833333,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.9396809895833333,
        "precision": 0.933349609375,
        "recall": 0.953125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9782552083333333,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.9782552083333333,
        "precision": 0.975830078125,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.921875,
        "f1": 0.9048828124999999,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.9048828124999999,
        "precision": 0.8974609375,
        "recall": 0.921875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9871419270833333,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.9871419270833333,
        "precision": 0.9856770833333333,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.0063955056193345855,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.0063955056193345855,
        "precision": 0.004902820400955112,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666667,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.9869791666666667,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.98583984375,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.98583984375,
        "precision": 0.9842122395833334,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9781901041666666,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.9781901041666666,
        "precision": 0.9757486979166667,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9884440104166667,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.9884440104166667,
        "precision": 0.9871419270833334,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.010710914451521827,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.010710914451521827,
        "precision": 0.008669731589426452,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.9443359375,
        "f1": 0.93017578125,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.93017578125,
        "precision": 0.9235026041666667,
        "recall": 0.9443359375
      },
      {
        "accuracy": 0.9677734375,
        "f1": 0.9581705729166666,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.9581705729166666,
        "precision": 0.9534505208333334,
        "recall": 0.9677734375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.6845703125,
        "f1": 0.6534954737103175,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.6534954737103175,
        "precision": 0.6419297960069443,
        "recall": 0.6845703125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9889322916666667,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9889322916666667,
        "precision": 0.98779296875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9736979166666666,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9736979166666666,
        "precision": 0.9711100260416667,
        "recall": 0.9794921875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333333,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9886067708333333,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.9258463541666667,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.9258463541666667,
        "precision": 0.918701171875,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666667,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9938151041666667,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006009777887347788,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.006009777887347788,
        "precision": 0.0043355513440643005,
        "recall": 0.015625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.98974609375,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.98974609375,
        "precision": 0.9886067708333334,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.01434895467941779,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.01434895467941779,
        "precision": 0.011422304883727311,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9568684895833333,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.9568684895833333,
        "precision": 0.9521484375,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9651692708333333,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9651692708333333,
        "precision": 0.96142578125,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.98193359375,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.98193359375,
        "precision": 0.9798177083333333,
        "recall": 0.986328125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0017461555741814666,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0017461555741814666,
        "precision": 0.001424268668097888,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00045978129322268326,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.00045978129322268326,
        "precision": 0.0002798454694332927,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0020296588958810067,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0020296588958810067,
        "precision": 0.0019922070762031932,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0028538339503404713,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0028538339503404713,
        "precision": 0.0025764109047906603,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011073191397015366,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0011073191397015366,
        "precision": 0.0010440532142414688,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006556589834515366,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0006556589834515366,
        "precision": 0.0004905953791469194,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0018619791666666667,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.0018619791666666667,
        "precision": 0.001549490053651059,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0016881542487684727,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0016881542487684727,
        "precision": 0.0014180720358954665,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.002012310606060606,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.002012310606060606,
        "precision": 0.001983642578125,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002244365676440329,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.002244365676440329,
        "precision": 0.0018567890516339486,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002635986573351629,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.002635986573351629,
        "precision": 0.002101609962418639,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007215561518928901,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0007215561518928901,
        "precision": 0.0005246684925766283,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0024587616237974593,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0024587616237974593,
        "precision": 0.0022873649798555154,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00296875,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.00296875,
        "precision": 0.0029496173469387753,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0025044517868906455,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0025044517868906455,
        "precision": 0.002311097198587046,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012375165831367925,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0012375165831367925,
        "precision": 0.0011188801189659116,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001553243379207475,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.001553243379207475,
        "precision": 0.0013031266693376068,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.03211948444517893,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.03211948444517893,
        "precision": 0.029642483980862885,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0032191246560534592,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.0032191246560534592,
        "precision": 0.002834339908392435,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0020549635305139187,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0020549635305139187,
        "precision": 0.002006618653998193,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00046913296568627447,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.00046913296568627447,
        "precision": 0.0002724886133603239,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001577167241655969,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.001577167241655969,
        "precision": 0.0013611238766339869,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.6904296875,
        "f1": 0.6597539992559524,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.6597539992559524,
        "precision": 0.648593284970238,
        "recall": 0.6904296875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9705403645833333,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9705403645833333,
        "precision": 0.96728515625,
        "recall": 0.9775390625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9482421875,
        "f1": 0.9358723958333333,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.9358723958333333,
        "precision": 0.9298502604166667,
        "recall": 0.9482421875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333333,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9886067708333333,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005603528453407225,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005603528453407225,
        "precision": 0.004322224855736368,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9845377604166666,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9845377604166666,
        "precision": 0.9827473958333333,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9873046875,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9873046875,
        "precision": 0.98583984375,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.015791147615125286,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.015791147615125286,
        "precision": 0.012654751995108189,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.95654296875,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.95654296875,
        "precision": 0.95234375,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.9676106770833333,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9676106770833333,
        "precision": 0.9641927083333334,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.66796875,
        "f1": 0.6321754796852452,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.6321754796852452,
        "precision": 0.6186128162202381,
        "recall": 0.66796875
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.982421875,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.982421875,
        "precision": 0.98046875,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9560546875,
        "f1": 0.9441266741071428,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.9441266741071428,
        "precision": 0.9388020833333334,
        "recall": 0.9560546875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.98486328125,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.98486328125,
        "precision": 0.9832356770833333,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.9287109375,
        "f1": 0.910546875,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.910546875,
        "precision": 0.9022623697916666,
        "recall": 0.9287109375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9860026041666667,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.9860026041666667,
        "precision": 0.984375,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.00737537825344176,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.00737537825344176,
        "precision": 0.005773733993960011,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.97705078125,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.97705078125,
        "precision": 0.9744466145833334,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9807942708333334,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.9807942708333334,
        "precision": 0.978515625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.0341796875,
        "f1": 0.014824954536319126,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.014824954536319126,
        "precision": 0.01177524883651377,
        "recall": 0.0341796875
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9494466145833333,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.9494466145833333,
        "precision": 0.944775390625,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9571940104166667,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.9571940104166667,
        "precision": 0.9524739583333334,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9814453125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.988671875,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.988671875,
        "precision": 0.987548828125,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.6953125,
        "f1": 0.6675478980654762,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.6675478980654762,
        "precision": 0.6569374689980159,
        "recall": 0.6953125
      },
      {
        "accuracy": 0.982421875,
        "f1": 0.9776041666666666,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.9776041666666666,
        "precision": 0.975341796875,
        "recall": 0.982421875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9421875,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.9421875,
        "precision": 0.9368489583333334,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9781901041666666,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.9781901041666666,
        "precision": 0.9755859375,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.9166341145833333,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.9166341145833333,
        "precision": 0.9088541666666667,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9910481770833333,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.9910481770833333,
        "precision": 0.9900716145833334,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9807942708333333,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.9807942708333333,
        "precision": 0.978515625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.00519743589336517,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.00519743589336517,
        "precision": 0.004107094310079801,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9830729166666666,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.9830729166666666,
        "precision": 0.98095703125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015172142856650837,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.015172142856650837,
        "precision": 0.012639341962977458,
        "recall": 0.03125
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9473958333333332,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.9473958333333332,
        "precision": 0.9430338541666667,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.95556640625,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.95556640625,
        "precision": 0.9508463541666667,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.97119140625,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.97119140625,
        "precision": 0.9680989583333333,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.98583984375,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.98583984375,
        "precision": 0.9842122395833334,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.689453125,
        "f1": 0.6538829985119048,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.6538829985119048,
        "precision": 0.6399739583333333,
        "recall": 0.689453125
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.974609375,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.974609375,
        "precision": 0.9716796875,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9519856770833333,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9519856770833333,
        "precision": 0.9479817708333333,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9949544270833334,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9949544270833334,
        "precision": 0.9944661458333334,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.974609375,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.974609375,
        "precision": 0.9716796875,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.9248046875,
        "f1": 0.9065941220238094,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.9065941220238094,
        "precision": 0.8985514322916667,
        "recall": 0.9248046875
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9803059895833333,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9803059895833333,
        "precision": 0.9783528645833334,
        "recall": 0.984375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9949544270833333,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9949544270833333,
        "precision": 0.9944661458333334,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0037935168416816413,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0037935168416816413,
        "precision": 0.002460531745668015,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9793294270833333,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9793294270833333,
        "precision": 0.9768880208333334,
        "recall": 0.984375
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9807942708333334,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9807942708333334,
        "precision": 0.978515625,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.010838777439103619,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.010838777439103619,
        "precision": 0.008036705772041752,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9475911458333333,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.9475911458333333,
        "precision": 0.9417317708333334,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.9521484375,
        "f1": 0.93798828125,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.93798828125,
        "precision": 0.93115234375,
        "recall": 0.9521484375
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9781901041666666,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9781901041666666,
        "precision": 0.9755859375,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0047773001854363485,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0047773001854363485,
        "precision": 0.0041231607120138965,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0040576703900575065,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0040576703900575065,
        "precision": 0.003680318338759484,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006593147067120541,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.006593147067120541,
        "precision": 0.005991470435990597,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007125799366008469,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.007125799366008469,
        "precision": 0.006414151531339032,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.009459995799528442,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.009459995799528442,
        "precision": 0.00898574368961961,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0043754868711050315,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0043754868711050315,
        "precision": 0.003911141767039593,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0033033486607645926,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.0033033486607645926,
        "precision": 0.002832914538255899,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.00575497150119995,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.00575497150119995,
        "precision": 0.0050267707912684525,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007879752938173737,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.007879752938173737,
        "precision": 0.0075538855100560605,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003302880893588624,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.003302880893588624,
        "precision": 0.002792904910819155,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004937534637800343,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.004937534637800343,
        "precision": 0.004527898921444564,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.005285575776849719,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.005285575776849719,
        "precision": 0.005102663099969238,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0065240986714150545,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0065240986714150545,
        "precision": 0.0059843589627403895,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.03507091973858614,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.03507091973858614,
        "precision": 0.030985500045687134,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005894132933425212,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.005894132933425212,
        "precision": 0.005501382838481842,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.007783915259471485,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.007783915259471485,
        "precision": 0.007479894605327172,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0036180703049454345,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.0036180703049454345,
        "precision": 0.0034369476854720594,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0037538451051703334,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0037538451051703334,
        "precision": 0.0031398062708812317,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004906253146395489,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.004906253146395489,
        "precision": 0.004229250567141192,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002617641081652032,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.002617641081652032,
        "precision": 0.0023344050476273304,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004925075619667549,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.004925075619667549,
        "precision": 0.004611263858898451,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.00440034060188933,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.00440034060188933,
        "precision": 0.0038980676318797853,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.953125,
        "f1": 0.93994140625,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.93994140625,
        "precision": 0.9339192708333333,
        "recall": 0.953125
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9557291666666666,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9557291666666666,
        "precision": 0.9510091145833334,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.7138671875,
        "f1": 0.6866667728972417,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.6866667728972417,
        "precision": 0.6758626302083333,
        "recall": 0.7138671875
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9513997395833333,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9513997395833333,
        "precision": 0.9477376302083333,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9560081845238095,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9560081845238095,
        "precision": 0.9514973958333334,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.921875,
        "f1": 0.9032877604166667,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.9032877604166667,
        "precision": 0.8952473958333333,
        "recall": 0.921875
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.955078125,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.955078125,
        "precision": 0.9503580729166667,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.9697265625,
        "f1": 0.9621419270833333,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9621419270833333,
        "precision": 0.958740234375,
        "recall": 0.9697265625
      },
      {
        "accuracy": 0.9267578125,
        "f1": 0.9096354166666667,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9096354166666667,
        "precision": 0.9024522569444444,
        "recall": 0.9267578125
      },
      {
        "accuracy": 0.9013671875,
        "f1": 0.8791015624999999,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.8791015624999999,
        "precision": 0.8690592447916666,
        "recall": 0.9013671875
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9542643229166666,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9542643229166666,
        "precision": 0.9490559895833334,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.931640625,
        "f1": 0.9155459449404761,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9155459449404761,
        "precision": 0.9083170572916667,
        "recall": 0.931640625
      },
      {
        "accuracy": 0.955078125,
        "f1": 0.9427734375,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9427734375,
        "precision": 0.9370930989583334,
        "recall": 0.955078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005789995840113764,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005789995840113764,
        "precision": 0.00436935250645339,
        "recall": 0.015625
      },
      {
        "accuracy": 0.9619140625,
        "f1": 0.9498697916666666,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9498697916666666,
        "precision": 0.9440104166666666,
        "recall": 0.9619140625
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.9347330729166666,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9347330729166666,
        "precision": 0.9279296875,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.9306175595238095,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9306175595238095,
        "precision": 0.9239908854166667,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.9462890625,
        "f1": 0.9315615699404762,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.9315615699404762,
        "precision": 0.9251302083333333,
        "recall": 0.9462890625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01891246846765616,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.01891246846765616,
        "precision": 0.015977393948214638,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.86328125,
        "f1": 0.8361002604166666,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8361002604166666,
        "precision": 0.8247667100694445,
        "recall": 0.86328125
      },
      {
        "accuracy": 0.921875,
        "f1": 0.9035559275793651,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9035559275793651,
        "precision": 0.8955485026041666,
        "recall": 0.921875
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.9671875,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9671875,
        "precision": 0.9637858072916667,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9405924479166666,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.9405924479166666,
        "precision": 0.9342447916666666,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.96875,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.96875,
        "precision": 0.96484375,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.58984375,
        "f1": 0.559619986133658,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.559619986133658,
        "precision": 0.5489536830357142,
        "recall": 0.58984375
      },
      {
        "accuracy": 0.9130859375,
        "f1": 0.8910342261904762,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.8910342261904762,
        "precision": 0.88134765625,
        "recall": 0.9130859375
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9651692708333333,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9651692708333333,
        "precision": 0.9611002604166667,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.871044921875,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.871044921875,
        "precision": 0.8609630766369047,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.9677734375,
        "f1": 0.9576822916666666,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.9576822916666666,
        "precision": 0.9527994791666666,
        "recall": 0.9677734375
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9640299479166666,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.9640299479166666,
        "precision": 0.9599609375,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.9521484375,
        "f1": 0.93837890625,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.93837890625,
        "precision": 0.9320475260416667,
        "recall": 0.9521484375
      },
      {
        "accuracy": 0.8349609375,
        "f1": 0.8042178199404761,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.8042178199404761,
        "precision": 0.7908854166666666,
        "recall": 0.8349609375
      },
      {
        "accuracy": 0.955078125,
        "f1": 0.94091796875,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.94091796875,
        "precision": 0.93408203125,
        "recall": 0.955078125
      },
      {
        "accuracy": 0.9638671875,
        "f1": 0.9523111979166666,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.9523111979166666,
        "precision": 0.9466145833333334,
        "recall": 0.9638671875
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9498697916666667,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.9498697916666667,
        "precision": 0.9446614583333334,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007475705498166436,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.007475705498166436,
        "precision": 0.006519604077678379,
        "recall": 0.015625
      },
      {
        "accuracy": 0.9560546875,
        "f1": 0.943359375,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.943359375,
        "precision": 0.9373372395833334,
        "recall": 0.9560546875
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9474934895833333,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.9474934895833333,
        "precision": 0.9414876302083333,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9398437500000001,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.9398437500000001,
        "precision": 0.9337076822916667,
        "recall": 0.953125
      },
      {
        "accuracy": 0.9443359375,
        "f1": 0.9277994791666666,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.9277994791666666,
        "precision": 0.920166015625,
        "recall": 0.9443359375
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.011304194946998086,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.011304194946998086,
        "precision": 0.009102271535203835,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.875,
        "f1": 0.8489490327380953,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.8489490327380953,
        "precision": 0.8382975260416667,
        "recall": 0.875
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9216145833333333,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.9216145833333333,
        "precision": 0.9136555989583333,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9625651041666667,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.9625651041666667,
        "precision": 0.9581705729166666,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9754231770833333,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.9754231770833333,
        "precision": 0.9724934895833333,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9884440104166666,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.9884440104166666,
        "precision": 0.9871419270833334,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.6748046875,
        "f1": 0.6391501510642135,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.6391501510642135,
        "precision": 0.6256700303819445,
        "recall": 0.6748046875
      },
      {
        "accuracy": 0.9619140625,
        "f1": 0.9512369791666666,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.9512369791666666,
        "precision": 0.9463704427083334,
        "recall": 0.9619140625
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9759114583333334,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9759114583333334,
        "precision": 0.97333984375,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.93359375,
        "f1": 0.9172743055555554,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.9172743055555554,
        "precision": 0.9100341796875,
        "recall": 0.93359375
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9763997395833333,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.9763997395833333,
        "precision": 0.97412109375,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9814453125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9845377604166666,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.9845377604166666,
        "precision": 0.9827473958333333,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.9130859375,
        "f1": 0.89326171875,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.89326171875,
        "precision": 0.8843858506944444,
        "recall": 0.9130859375
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.9664713541666667,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.9664713541666667,
        "precision": 0.96240234375,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9739583333333333,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.9739583333333333,
        "precision": 0.970703125,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9733072916666667,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.9733072916666667,
        "precision": 0.9703776041666667,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.005317370078419299,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.005317370078419299,
        "precision": 0.004126152201096727,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9850260416666666,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.9850260416666666,
        "precision": 0.9833984375,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9757486979166666,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.9757486979166666,
        "precision": 0.9729817708333334,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9564615885416667,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.9564615885416667,
        "precision": 0.9521251860119048,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9680013020833333,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.9680013020833333,
        "precision": 0.9644368489583334,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.0156349127747698,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0156349127747698,
        "precision": 0.012660994919059435,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9210611979166666,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.9210611979166666,
        "precision": 0.9129557291666667,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.9170107886904761,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.9170107886904761,
        "precision": 0.908935546875,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9860026041666667,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.9860026041666667,
        "precision": 0.984375,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.6904296875,
        "f1": 0.6594269987824675,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.6594269987824675,
        "precision": 0.6474609375,
        "recall": 0.6904296875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9746744791666666,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.9746744791666666,
        "precision": 0.9720865885416667,
        "recall": 0.98046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.96533203125,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.96533203125,
        "precision": 0.9612630208333333,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9962565104166666,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9962565104166666,
        "precision": 0.9959309895833334,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.002998720322404241,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.002998720322404241,
        "precision": 0.0018439771491529306,
        "recall": 0.0126953125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.012834367264192757,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.012834367264192757,
        "precision": 0.010675425919566545,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9763997395833333,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.9763997395833333,
        "precision": 0.9739583333333334,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.9833984375,
        "f1": 0.9781901041666666,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.9781901041666666,
        "precision": 0.9755859375,
        "recall": 0.9833984375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}