{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "task_name": "AmazonReviewsClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.25094,
        "f1": 0.23994,
        "f1_weighted": 0.23994,
        "scores_per_experiment": [
          {
            "accuracy": 0.2894,
            "f1": 0.287905,
            "f1_weighted": 0.287905
          },
          {
            "accuracy": 0.2476,
            "f1": 0.235483,
            "f1_weighted": 0.235483
          },
          {
            "accuracy": 0.2408,
            "f1": 0.236405,
            "f1_weighted": 0.236405
          },
          {
            "accuracy": 0.2446,
            "f1": 0.241255,
            "f1_weighted": 0.241255
          },
          {
            "accuracy": 0.2344,
            "f1": 0.226665,
            "f1_weighted": 0.226665
          },
          {
            "accuracy": 0.2454,
            "f1": 0.224912,
            "f1_weighted": 0.224912
          },
          {
            "accuracy": 0.2268,
            "f1": 0.214822,
            "f1_weighted": 0.214822
          },
          {
            "accuracy": 0.2762,
            "f1": 0.262938,
            "f1_weighted": 0.262938
          },
          {
            "accuracy": 0.2476,
            "f1": 0.228157,
            "f1_weighted": 0.228157
          },
          {
            "accuracy": 0.2566,
            "f1": 0.240856,
            "f1_weighted": 0.240856
          }
        ],
        "main_score": 0.25094,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.25174,
        "f1": 0.240524,
        "f1_weighted": 0.240524,
        "scores_per_experiment": [
          {
            "accuracy": 0.2726,
            "f1": 0.270244,
            "f1_weighted": 0.270244
          },
          {
            "accuracy": 0.2486,
            "f1": 0.233403,
            "f1_weighted": 0.233403
          },
          {
            "accuracy": 0.2566,
            "f1": 0.253063,
            "f1_weighted": 0.253063
          },
          {
            "accuracy": 0.2446,
            "f1": 0.241626,
            "f1_weighted": 0.241626
          },
          {
            "accuracy": 0.246,
            "f1": 0.23826,
            "f1_weighted": 0.23826
          },
          {
            "accuracy": 0.237,
            "f1": 0.217866,
            "f1_weighted": 0.217866
          },
          {
            "accuracy": 0.2358,
            "f1": 0.221848,
            "f1_weighted": 0.221848
          },
          {
            "accuracy": 0.2792,
            "f1": 0.266983,
            "f1_weighted": 0.266983
          },
          {
            "accuracy": 0.2386,
            "f1": 0.21887,
            "f1_weighted": 0.21887
          },
          {
            "accuracy": 0.2584,
            "f1": 0.24308,
            "f1_weighted": 0.24308
          }
        ],
        "main_score": 0.25174,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 76.49205708503723,
  "kg_co2_emissions": null
}