{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.5897,
        "f1": 0.566492,
        "f1_weighted": 0.60508,
        "ap": 0.740859,
        "ap_weighted": 0.740859,
        "scores_per_experiment": [
          {
            "accuracy": 0.648069,
            "f1": 0.59969,
            "f1_weighted": 0.654639,
            "ap": 0.746146,
            "ap_weighted": 0.746146
          },
          {
            "accuracy": 0.570815,
            "f1": 0.551794,
            "f1_weighted": 0.588252,
            "ap": 0.734342,
            "ap_weighted": 0.734342
          },
          {
            "accuracy": 0.553648,
            "f1": 0.541451,
            "f1_weighted": 0.57098,
            "ap": 0.734504,
            "ap_weighted": 0.734504
          },
          {
            "accuracy": 0.575107,
            "f1": 0.554597,
            "f1_weighted": 0.592336,
            "ap": 0.734825,
            "ap_weighted": 0.734825
          },
          {
            "accuracy": 0.648069,
            "f1": 0.622172,
            "f1_weighted": 0.661229,
            "ap": 0.768304,
            "ap_weighted": 0.768304
          },
          {
            "accuracy": 0.555794,
            "f1": 0.546418,
            "f1_weighted": 0.572168,
            "ap": 0.740672,
            "ap_weighted": 0.740672
          },
          {
            "accuracy": 0.598712,
            "f1": 0.573642,
            "f1_weighted": 0.614465,
            "ap": 0.74219,
            "ap_weighted": 0.74219
          },
          {
            "accuracy": 0.562232,
            "f1": 0.5364,
            "f1_weighted": 0.57961,
            "ap": 0.722384,
            "ap_weighted": 0.722384
          },
          {
            "accuracy": 0.555794,
            "f1": 0.529075,
            "f1_weighted": 0.573366,
            "ap": 0.718317,
            "ap_weighted": 0.718317
          },
          {
            "accuracy": 0.628755,
            "f1": 0.609687,
            "f1_weighted": 0.643751,
            "ap": 0.766908,
            "ap_weighted": 0.766908
          }
        ],
        "main_score": 0.5897,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.576017,
        "f1": 0.555251,
        "f1_weighted": 0.59199,
        "ap": 0.734793,
        "ap_weighted": 0.734793,
        "scores_per_experiment": [
          {
            "accuracy": 0.59743,
            "f1": 0.551805,
            "f1_weighted": 0.607842,
            "ap": 0.721917,
            "ap_weighted": 0.721917
          },
          {
            "accuracy": 0.544968,
            "f1": 0.522871,
            "f1_weighted": 0.563107,
            "ap": 0.715608,
            "ap_weighted": 0.715608
          },
          {
            "accuracy": 0.566381,
            "f1": 0.554101,
            "f1_weighted": 0.583098,
            "ap": 0.739661,
            "ap_weighted": 0.739661
          },
          {
            "accuracy": 0.59636,
            "f1": 0.584623,
            "f1_weighted": 0.611984,
            "ap": 0.75832,
            "ap_weighted": 0.75832
          },
          {
            "accuracy": 0.624197,
            "f1": 0.598799,
            "f1_weighted": 0.638355,
            "ap": 0.753898,
            "ap_weighted": 0.753898
          },
          {
            "accuracy": 0.536403,
            "f1": 0.5271,
            "f1_weighted": 0.553091,
            "ap": 0.727782,
            "ap_weighted": 0.727782
          },
          {
            "accuracy": 0.578158,
            "f1": 0.558309,
            "f1_weighted": 0.595001,
            "ap": 0.735459,
            "ap_weighted": 0.735459
          },
          {
            "accuracy": 0.571734,
            "f1": 0.549836,
            "f1_weighted": 0.588743,
            "ap": 0.729613,
            "ap_weighted": 0.729613
          },
          {
            "accuracy": 0.541756,
            "f1": 0.521974,
            "f1_weighted": 0.56008,
            "ap": 0.716408,
            "ap_weighted": 0.716408
          },
          {
            "accuracy": 0.602784,
            "f1": 0.583089,
            "f1_weighted": 0.618597,
            "ap": 0.749266,
            "ap_weighted": 0.749266
          }
        ],
        "main_score": 0.576017,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 47.57921242713928,
  "kg_co2_emissions": null
}