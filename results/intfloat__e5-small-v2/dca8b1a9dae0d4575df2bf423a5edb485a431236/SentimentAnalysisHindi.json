{
  "dataset_revision": "1beac1b941da76a9c51e3e5b39d230fde9a80983",
  "evaluation_time": 10.503339529037476,
  "kg_co2_emissions": 0.00031696707842554175,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.4150390625,
        "f1": 0.3988635263308418,
        "f1_weighted": 0.42155447005872115,
        "hf_subset": "default",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.3988635263308418,
        "scores_per_experiment": [
          {
            "accuracy": 0.50146484375,
            "f1": 0.4672712755149089,
            "f1_weighted": 0.5154523468039396
          },
          {
            "accuracy": 0.39990234375,
            "f1": 0.39573226053279226,
            "f1_weighted": 0.4108972496573354
          },
          {
            "accuracy": 0.42041015625,
            "f1": 0.40843533658654757,
            "f1_weighted": 0.4302276297229005
          },
          {
            "accuracy": 0.439453125,
            "f1": 0.42578643521890475,
            "f1_weighted": 0.43660925713828136
          },
          {
            "accuracy": 0.38525390625,
            "f1": 0.37311692921207773,
            "f1_weighted": 0.38877421652236965
          },
          {
            "accuracy": 0.39599609375,
            "f1": 0.3722340766264711,
            "f1_weighted": 0.37497500063314204
          },
          {
            "accuracy": 0.390625,
            "f1": 0.3798653986607589,
            "f1_weighted": 0.40909549764651393
          },
          {
            "accuracy": 0.4345703125,
            "f1": 0.41331543876516347,
            "f1_weighted": 0.4500962575772407
          },
          {
            "accuracy": 0.36279296875,
            "f1": 0.3582386911448281,
            "f1_weighted": 0.3694097726662787
          },
          {
            "accuracy": 0.419921875,
            "f1": 0.39463942104596544,
            "f1_weighted": 0.43000747221921015
          }
        ]
      }
    ]
  },
  "task_name": "SentimentAnalysisHindi"
}