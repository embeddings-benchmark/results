{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 19.147691249847412,
  "kg_co2_emissions": 0.0006240369226807592,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.7619901986722687,
        "cosine_spearman": 0.756407237045411,
        "euclidean_pearson": 0.7498340509614008,
        "euclidean_spearman": 0.756407237045411,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.756407237045411,
        "manhattan_pearson": 0.7471119793887544,
        "manhattan_spearman": 0.7529620493004768,
        "pearson": 0.7619901986722687,
        "spearman": 0.756407237045411
      },
      {
        "cosine_pearson": 0.16587625835705533,
        "cosine_spearman": 0.14929237877888143,
        "euclidean_pearson": 0.13787860547427694,
        "euclidean_spearman": 0.14841073855583684,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.14929237877888143,
        "manhattan_pearson": 0.13605820865120477,
        "manhattan_spearman": 0.14791966610792256,
        "pearson": 0.16587625835705533,
        "spearman": 0.14929237877888143
      },
      {
        "cosine_pearson": 0.2632096884491574,
        "cosine_spearman": 0.230375491449959,
        "euclidean_pearson": 0.27302852049037973,
        "euclidean_spearman": 0.230375491449959,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.230375491449959,
        "manhattan_pearson": 0.28152917777189773,
        "manhattan_spearman": 0.23735479860409903,
        "pearson": 0.2632096884491574,
        "spearman": 0.230375491449959
      },
      {
        "cosine_pearson": 0.39534302883744044,
        "cosine_spearman": 0.3850988997423429,
        "euclidean_pearson": 0.3965721563043083,
        "euclidean_spearman": 0.3850988997423429,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.3850988997423429,
        "manhattan_pearson": 0.3953881573918097,
        "manhattan_spearman": 0.3843539252526824,
        "pearson": 0.39534302883744044,
        "spearman": 0.3850988997423429
      },
      {
        "cosine_pearson": 0.14199207132365407,
        "cosine_spearman": 0.07559091554545265,
        "euclidean_pearson": 0.1819833639221309,
        "euclidean_spearman": 0.07560166682727852,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.07559091554545265,
        "manhattan_pearson": 0.18798859745450855,
        "manhattan_spearman": 0.08136305319640873,
        "pearson": 0.14199207132365407,
        "spearman": 0.07559091554545265
      },
      {
        "cosine_pearson": 0.8161281881687639,
        "cosine_spearman": 0.8040365194072209,
        "euclidean_pearson": 0.8148976814635933,
        "euclidean_spearman": 0.8040361399320471,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8040365194072209,
        "manhattan_pearson": 0.8133543767847129,
        "manhattan_spearman": 0.8014100569755169,
        "pearson": 0.8161281881687639,
        "spearman": 0.8040365194072209
      },
      {
        "cosine_pearson": 0.4282227085771356,
        "cosine_spearman": 0.39657891418351554,
        "euclidean_pearson": 0.43023905215737146,
        "euclidean_spearman": 0.39657891418351554,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.39657891418351554,
        "manhattan_pearson": 0.4313788907549611,
        "manhattan_spearman": 0.39825386477040003,
        "pearson": 0.4282227085771356,
        "spearman": 0.39657891418351554
      },
      {
        "cosine_pearson": 0.4680732667084972,
        "cosine_spearman": 0.44225174878881174,
        "euclidean_pearson": 0.48368342149066257,
        "euclidean_spearman": 0.4422503083626192,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.44225174878881174,
        "manhattan_pearson": 0.48192046457797677,
        "manhattan_spearman": 0.44086597258764065,
        "pearson": 0.4680732667084972,
        "spearman": 0.44225174878881174
      },
      {
        "cosine_pearson": 0.4374032506613744,
        "cosine_spearman": 0.44606447682681016,
        "euclidean_pearson": 0.4664648663302587,
        "euclidean_spearman": 0.44606447682681016,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.44606447682681016,
        "manhattan_pearson": 0.46024280096260994,
        "manhattan_spearman": 0.440611001241349,
        "pearson": 0.4374032506613744,
        "spearman": 0.44606447682681016
      },
      {
        "cosine_pearson": 0.509502096498891,
        "cosine_spearman": 0.5114388951060959,
        "euclidean_pearson": 0.5250496595955145,
        "euclidean_spearman": 0.5114388951060959,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.5114388951060959,
        "manhattan_pearson": 0.5246533699508309,
        "manhattan_spearman": 0.5119350098722041,
        "pearson": 0.509502096498891,
        "spearman": 0.5114388951060959
      },
      {
        "cosine_pearson": 0.5117767613539582,
        "cosine_spearman": 0.5005329241324344,
        "euclidean_pearson": 0.538580240607487,
        "euclidean_spearman": 0.5005329241324344,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.5005329241324344,
        "manhattan_pearson": 0.541097444705042,
        "manhattan_spearman": 0.5006794438564139,
        "pearson": 0.5117767613539582,
        "spearman": 0.5005329241324344
      },
      {
        "cosine_pearson": 0.3113848975803624,
        "cosine_spearman": 0.31599430725172545,
        "euclidean_pearson": 0.3589601671607145,
        "euclidean_spearman": 0.3165072328673749,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.31599430725172545,
        "manhattan_pearson": 0.357419701662812,
        "manhattan_spearman": 0.3146103784127206,
        "pearson": 0.3113848975803624,
        "spearman": 0.31599430725172545
      }
    ]
  },
  "task_name": "SemRel24STS"
}