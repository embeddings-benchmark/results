{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 12.977452754974365,
  "kg_co2_emissions": 0.0003685658631478959,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.48942307692307685,
        "f1": 0.3936448674218557,
        "f1_weighted": 0.5312115757925483,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.48942307692307685,
        "scores_per_experiment": [
          {
            "accuracy": 0.4519230769230769,
            "f1": 0.3566729323308271,
            "f1_weighted": 0.4934644303065356
          },
          {
            "accuracy": 0.49038461538461536,
            "f1": 0.3999869178440607,
            "f1_weighted": 0.5253844141206779
          },
          {
            "accuracy": 0.6153846153846154,
            "f1": 0.5023545606027675,
            "f1_weighted": 0.6808163219812862
          },
          {
            "accuracy": 0.5192307692307693,
            "f1": 0.4228946157386102,
            "f1_weighted": 0.5852428404545293
          },
          {
            "accuracy": 0.4230769230769231,
            "f1": 0.3357711991252364,
            "f1_weighted": 0.45872553947088107
          },
          {
            "accuracy": 0.4519230769230769,
            "f1": 0.37116739941062593,
            "f1_weighted": 0.495641683435536
          },
          {
            "accuracy": 0.5,
            "f1": 0.4143395390070922,
            "f1_weighted": 0.5372297804146208
          },
          {
            "accuracy": 0.5769230769230769,
            "f1": 0.4208685751463891,
            "f1_weighted": 0.6169079375406636
          },
          {
            "accuracy": 0.3942307692307692,
            "f1": 0.3270663103951258,
            "f1_weighted": 0.4109854860058167
          },
          {
            "accuracy": 0.47115384615384615,
            "f1": 0.3853266246178226,
            "f1_weighted": 0.5077173241949352
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5,
        "f1": 0.3783356762547543,
        "f1_weighted": 0.5479058508905172,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5,
        "scores_per_experiment": [
          {
            "accuracy": 0.580952380952381,
            "f1": 0.44521019053086514,
            "f1_weighted": 0.6411999333588138
          },
          {
            "accuracy": 0.4857142857142857,
            "f1": 0.3895717157922689,
            "f1_weighted": 0.5374635328885927
          },
          {
            "accuracy": 0.49523809523809526,
            "f1": 0.36865188110273306,
            "f1_weighted": 0.5648696016791879
          },
          {
            "accuracy": 0.580952380952381,
            "f1": 0.4098044532827142,
            "f1_weighted": 0.6302191345669607
          },
          {
            "accuracy": 0.4666666666666667,
            "f1": 0.3611999702425234,
            "f1_weighted": 0.5145868316081081
          },
          {
            "accuracy": 0.41904761904761906,
            "f1": 0.3457415734655444,
            "f1_weighted": 0.4211056755228322
          },
          {
            "accuracy": 0.49523809523809526,
            "f1": 0.3815425899357033,
            "f1_weighted": 0.5370625937818668
          },
          {
            "accuracy": 0.5428571428571428,
            "f1": 0.36160127845757606,
            "f1_weighted": 0.5844658243110855
          },
          {
            "accuracy": 0.3904761904761905,
            "f1": 0.3045537104307213,
            "f1_weighted": 0.45042874440902464
          },
          {
            "accuracy": 0.5428571428571428,
            "f1": 0.4154793993068926,
            "f1_weighted": 0.5976566367787006
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}