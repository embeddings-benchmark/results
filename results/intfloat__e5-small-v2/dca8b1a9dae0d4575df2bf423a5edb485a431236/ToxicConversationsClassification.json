{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 10.301158666610718,
  "kg_co2_emissions": 0.0003159586185442801,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.6373046875,
        "ap": 0.11485635917540979,
        "ap_weighted": 0.11485635917540979,
        "f1": 0.49088917525135367,
        "f1_weighted": 0.7163767988495129,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6373046875,
        "scores_per_experiment": [
          {
            "accuracy": 0.60546875,
            "ap": 0.12083387219400551,
            "ap_weighted": 0.12083387219400551,
            "f1": 0.48195788503536297,
            "f1_weighted": 0.6948906162343972
          },
          {
            "accuracy": 0.7109375,
            "ap": 0.11927238062743797,
            "ap_weighted": 0.11927238062743797,
            "f1": 0.5294000745249038,
            "f1_weighted": 0.7754460820084461
          },
          {
            "accuracy": 0.7216796875,
            "ap": 0.13423514660493827,
            "ap_weighted": 0.13423514660493827,
            "f1": 0.5459912539844775,
            "f1_weighted": 0.7837360415674923
          },
          {
            "accuracy": 0.75048828125,
            "ap": 0.12114643497917416,
            "ap_weighted": 0.12114643497917416,
            "f1": 0.5478702515225758,
            "f1_weighted": 0.8026576207786512
          },
          {
            "accuracy": 0.54345703125,
            "ap": 0.09845915619293095,
            "ap_weighted": 0.09845915619293095,
            "f1": 0.4344885551325521,
            "f1_weighted": 0.6434559108905946
          },
          {
            "accuracy": 0.48095703125,
            "ap": 0.10046309855722658,
            "ap_weighted": 0.10046309855722658,
            "f1": 0.40325800542352175,
            "f1_weighted": 0.5845206854300826
          },
          {
            "accuracy": 0.70654296875,
            "ap": 0.1078952907786172,
            "ap_weighted": 0.1078952907786172,
            "f1": 0.516976393279217,
            "f1_weighted": 0.7717018617995832
          },
          {
            "accuracy": 0.52001953125,
            "ap": 0.10734194685164974,
            "ap_weighted": 0.10734194685164974,
            "f1": 0.4291778842950367,
            "f1_weighted": 0.6208682139772358
          },
          {
            "accuracy": 0.65869140625,
            "ap": 0.1209604481190717,
            "ap_weighted": 0.1209604481190717,
            "f1": 0.5073939834395417,
            "f1_weighted": 0.737206104078511
          },
          {
            "accuracy": 0.6748046875,
            "ap": 0.11795581684904602,
            "ap_weighted": 0.11795581684904602,
            "f1": 0.5123774658763469,
            "f1_weighted": 0.7492848517301354
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}