{
  "dataset_revision": "69e8f12da6e31d59addadda9a9c8a2e601a0e282",
  "evaluation_time": 231.42529010772705,
  "kg_co2_emissions": 0.006919096474237824,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.11299435028248588,
        "f1": 0.08922518159806295,
        "hf_subset": "bos-eng",
        "languages": [
          "bos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08922518159806295,
        "precision": 0.08382173382173382,
        "recall": 0.11299435028248588
      },
      {
        "accuracy": 0.2658959537572254,
        "f1": 0.211166162033214,
        "hf_subset": "fry-eng",
        "languages": [
          "fry-Latn",
          "eng-Latn"
        ],
        "main_score": 0.211166162033214,
        "precision": 0.1937928641685867,
        "recall": 0.2658959537572254
      },
      {
        "accuracy": 0.02,
        "f1": 0.013987155837944933,
        "hf_subset": "ukr-eng",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.013987155837944933,
        "precision": 0.012882557687321754,
        "recall": 0.02
      },
      {
        "accuracy": 0.022,
        "f1": 0.013733261984038899,
        "hf_subset": "wuu-eng",
        "languages": [
          "wuu-Hans",
          "eng-Latn"
        ],
        "main_score": 0.013733261984038899,
        "precision": 0.011875862875862874,
        "recall": 0.022
      },
      {
        "accuracy": 0.145,
        "f1": 0.11875186741543352,
        "hf_subset": "ron-eng",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11875186741543352,
        "precision": 0.11195608614766195,
        "recall": 0.145
      },
      {
        "accuracy": 0.07660455486542443,
        "f1": 0.05973815813181844,
        "hf_subset": "hsb-eng",
        "languages": [
          "hsb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05973815813181844,
        "precision": 0.05550325349396847,
        "recall": 0.07660455486542443
      },
      {
        "accuracy": 0.3657587548638132,
        "f1": 0.31657007747525867,
        "hf_subset": "nov-eng",
        "languages": [
          "nov-Latn",
          "eng-Latn"
        ],
        "main_score": 0.31657007747525867,
        "precision": 0.30236551170403303,
        "recall": 0.3657587548638132
      },
      {
        "accuracy": 0.06338028169014084,
        "f1": 0.043613111550145515,
        "hf_subset": "xho-eng",
        "languages": [
          "xho-Latn",
          "eng-Latn"
        ],
        "main_score": 0.043613111550145515,
        "precision": 0.039460093896713615,
        "recall": 0.06338028169014084
      },
      {
        "accuracy": 0.0072992700729927005,
        "f1": 0.006386861313868613,
        "hf_subset": "tha-eng",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ],
        "main_score": 0.006386861313868613,
        "precision": 0.006082725060827251,
        "recall": 0.0072992700729927005
      },
      {
        "accuracy": 0.069,
        "f1": 0.0555104542109578,
        "hf_subset": "kzj-eng",
        "languages": [
          "kzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0555104542109578,
        "precision": 0.052909583767672005,
        "recall": 0.069
      },
      {
        "accuracy": 0.008,
        "f1": 0.0029176913481243874,
        "hf_subset": "rus-eng",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0029176913481243874,
        "precision": 0.0025618479618992824,
        "recall": 0.008
      },
      {
        "accuracy": 0.006702412868632708,
        "f1": 0.005072806602533775,
        "hf_subset": "kat-eng",
        "languages": [
          "kat-Geor",
          "eng-Latn"
        ],
        "main_score": 0.005072806602533775,
        "precision": 0.004775469168900804,
        "recall": 0.006702412868632708
      },
      {
        "accuracy": 0.09486166007905138,
        "f1": 0.068900467121811,
        "hf_subset": "csb-eng",
        "languages": [
          "csb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.068900467121811,
        "precision": 0.06302564712175697,
        "recall": 0.09486166007905138
      },
      {
        "accuracy": 0.115,
        "f1": 0.09144540555871933,
        "hf_subset": "nno-eng",
        "languages": [
          "nno-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09144540555871933,
        "precision": 0.08588125970886662,
        "recall": 0.115
      },
      {
        "accuracy": 0.006,
        "f1": 0.0052,
        "hf_subset": "uig-eng",
        "languages": [
          "uig-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0052,
        "precision": 0.0051111111111111105,
        "recall": 0.006
      },
      {
        "accuracy": 0.079,
        "f1": 0.06522650682650682,
        "hf_subset": "vie-eng",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06522650682650682,
        "precision": 0.06118186837953572,
        "recall": 0.079
      },
      {
        "accuracy": 0.07881773399014778,
        "f1": 0.05644339240398354,
        "hf_subset": "tuk-eng",
        "languages": [
          "tuk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05644339240398354,
        "precision": 0.053758856156478164,
        "recall": 0.07881773399014778
      },
      {
        "accuracy": 0.07833333333333334,
        "f1": 0.05977757427757427,
        "hf_subset": "ceb-eng",
        "languages": [
          "ceb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05977757427757427,
        "precision": 0.055532925407925406,
        "recall": 0.07833333333333334
      },
      {
        "accuracy": 0.091,
        "f1": 0.07384034848192743,
        "hf_subset": "war-eng",
        "languages": [
          "war-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07384034848192743,
        "precision": 0.07016640344426059,
        "recall": 0.091
      },
      {
        "accuracy": 0.011904761904761904,
        "f1": 0.001433349259436216,
        "hf_subset": "amh-eng",
        "languages": [
          "amh-Ethi",
          "eng-Latn"
        ],
        "main_score": 0.001433349259436216,
        "precision": 0.0007665945165945166,
        "recall": 0.011904761904761904
      },
      {
        "accuracy": 0.309,
        "f1": 0.2621919550063513,
        "hf_subset": "spa-eng",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2621919550063513,
        "precision": 0.24851491484306884,
        "recall": 0.309
      },
      {
        "accuracy": 0.10256410256410256,
        "f1": 0.07187212708489303,
        "hf_subset": "swh-eng",
        "languages": [
          "swh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07187212708489303,
        "precision": 0.06532988253576488,
        "recall": 0.10256410256410256
      },
      {
        "accuracy": 0.09217391304347826,
        "f1": 0.07189438628633557,
        "hf_subset": "cym-eng",
        "languages": [
          "cym-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07189438628633557,
        "precision": 0.067220340046427,
        "recall": 0.09217391304347826
      },
      {
        "accuracy": 0.196,
        "f1": 0.16473806678454564,
        "hf_subset": "nld-eng",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.16473806678454564,
        "precision": 0.15633165534393037,
        "recall": 0.196
      },
      {
        "accuracy": 0.045,
        "f1": 0.034277846790890264,
        "hf_subset": "bre-eng",
        "languages": [
          "bre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.034277846790890264,
        "precision": 0.03177388219955518,
        "recall": 0.045
      },
      {
        "accuracy": 0.16071428571428573,
        "f1": 0.11190476190476191,
        "hf_subset": "swg-eng",
        "languages": [
          "swg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11190476190476191,
        "precision": 0.1034966572836031,
        "recall": 0.16071428571428573
      },
      {
        "accuracy": 0.05,
        "f1": 0.04028657913069678,
        "hf_subset": "lvs-eng",
        "languages": [
          "lvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04028657913069678,
        "precision": 0.03894885968661948,
        "recall": 0.05
      },
      {
        "accuracy": 0.222,
        "f1": 0.191929499542591,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.191929499542591,
        "precision": 0.18380929836019702,
        "recall": 0.222
      },
      {
        "accuracy": 0.02,
        "f1": 0.013737817049016403,
        "hf_subset": "bel-eng",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.013737817049016403,
        "precision": 0.012850534188034187,
        "recall": 0.02
      },
      {
        "accuracy": 0.065,
        "f1": 0.04946242930887363,
        "hf_subset": "hun-eng",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04946242930887363,
        "precision": 0.04643386752136752,
        "recall": 0.065
      },
      {
        "accuracy": 0.03636363636363636,
        "f1": 0.026069173881673877,
        "hf_subset": "mon-eng",
        "languages": [
          "mon-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.026069173881673877,
        "precision": 0.023832368473320795,
        "recall": 0.03636363636363636
      },
      {
        "accuracy": 0.223,
        "f1": 0.18769236142793752,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.18769236142793752,
        "precision": 0.17778333333333332,
        "recall": 0.223
      },
      {
        "accuracy": 0.102,
        "f1": 0.0797035076035076,
        "hf_subset": "hrv-eng",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0797035076035076,
        "precision": 0.07444245534159327,
        "recall": 0.102
      },
      {
        "accuracy": 0.004,
        "f1": 0.0016758503811475957,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0016758503811475957,
        "precision": 0.001504602922249981,
        "recall": 0.004
      },
      {
        "accuracy": 0.167,
        "f1": 0.13674042910494524,
        "hf_subset": "lfn-eng",
        "languages": [
          "lfn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.13674042910494524,
        "precision": 0.12805552336552337,
        "recall": 0.167
      },
      {
        "accuracy": 0.017316017316017316,
        "f1": 0.004598405621859779,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.004598405621859779,
        "precision": 0.00313196904105995,
        "recall": 0.017316017316017316
      },
      {
        "accuracy": 0.106,
        "f1": 0.09105546780445811,
        "hf_subset": "zsm-eng",
        "languages": [
          "zsm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09105546780445811,
        "precision": 0.08837725865310288,
        "recall": 0.106
      },
      {
        "accuracy": 0.003,
        "f1": 0.0011455061494796595,
        "hf_subset": "pes-eng",
        "languages": [
          "pes-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0011455061494796595,
        "precision": 0.0010782493368700265,
        "recall": 0.003
      },
      {
        "accuracy": 0.208955223880597,
        "f1": 0.16464915681333592,
        "hf_subset": "ang-eng",
        "languages": [
          "ang-Latn",
          "eng-Latn"
        ],
        "main_score": 0.16464915681333592,
        "precision": 0.15304060056858562,
        "recall": 0.208955223880597
      },
      {
        "accuracy": 0.068,
        "f1": 0.05060835944857723,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05060835944857723,
        "precision": 0.04745635114748415,
        "recall": 0.068
      },
      {
        "accuracy": 0.048,
        "f1": 0.03174369044421421,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03174369044421421,
        "precision": 0.027766263921263922,
        "recall": 0.048
      },
      {
        "accuracy": 0.026,
        "f1": 0.01685880889069089,
        "hf_subset": "yue-eng",
        "languages": [
          "yue-Hant",
          "eng-Latn"
        ],
        "main_score": 0.01685880889069089,
        "precision": 0.015822200659700657,
        "recall": 0.026
      },
      {
        "accuracy": 0.286,
        "f1": 0.24526999021309517,
        "hf_subset": "ile-eng",
        "languages": [
          "ile-Latn",
          "eng-Latn"
        ],
        "main_score": 0.24526999021309517,
        "precision": 0.23275048150773955,
        "recall": 0.286
      },
      {
        "accuracy": 0.17307692307692307,
        "f1": 0.1343031968031968,
        "hf_subset": "tzl-eng",
        "languages": [
          "tzl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1343031968031968,
        "precision": 0.12115384615384615,
        "recall": 0.17307692307692307
      },
      {
        "accuracy": 0.25984251968503935,
        "f1": 0.21195679417078211,
        "hf_subset": "ast-eng",
        "languages": [
          "ast-Latn",
          "eng-Latn"
        ],
        "main_score": 0.21195679417078211,
        "precision": 0.1997047244094488,
        "recall": 0.25984251968503935
      },
      {
        "accuracy": 0.033,
        "f1": 0.025377947656208526,
        "hf_subset": "cmn-eng",
        "languages": [
          "cmn-Hans",
          "eng-Latn"
        ],
        "main_score": 0.025377947656208526,
        "precision": 0.023462910996932228,
        "recall": 0.033
      },
      {
        "accuracy": 0.15140845070422534,
        "f1": 0.11748322426139328,
        "hf_subset": "max-eng",
        "languages": [
          "max-Deva",
          "eng-Latn"
        ],
        "main_score": 0.11748322426139328,
        "precision": 0.10964151337792642,
        "recall": 0.15140845070422534
      },
      {
        "accuracy": 0.04342581423401689,
        "f1": 0.031858792012460654,
        "hf_subset": "gla-eng",
        "languages": [
          "gla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.031858792012460654,
        "precision": 0.029412395003468584,
        "recall": 0.04342581423401689
      },
      {
        "accuracy": 0.08292682926829269,
        "f1": 0.058290327558620236,
        "hf_subset": "jav-eng",
        "languages": [
          "jav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.058290327558620236,
        "precision": 0.05492145614096833,
        "recall": 0.08292682926829269
      },
      {
        "accuracy": 0.009,
        "f1": 0.0024543479938792,
        "hf_subset": "mhr-eng",
        "languages": [
          "mhr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0024543479938792,
        "precision": 0.0019370519968141995,
        "recall": 0.009
      },
      {
        "accuracy": 0.163,
        "f1": 0.13768233028341564,
        "hf_subset": "nob-eng",
        "languages": [
          "nob-Latn",
          "eng-Latn"
        ],
        "main_score": 0.13768233028341564,
        "precision": 0.13016413681674877,
        "recall": 0.163
      },
      {
        "accuracy": 0.19708029197080293,
        "f1": 0.14751843111428206,
        "hf_subset": "cha-eng",
        "languages": [
          "cha-Latn",
          "eng-Latn"
        ],
        "main_score": 0.14751843111428206,
        "precision": 0.13695716286957163,
        "recall": 0.19708029197080293
      },
      {
        "accuracy": 0.007,
        "f1": 0.0024349572649572646,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0024349572649572646,
        "precision": 0.002235785710855936,
        "recall": 0.007
      },
      {
        "accuracy": 0.001,
        "f1": 3.838771593090211e-06,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 3.838771593090211e-06,
        "precision": 1.923076923076923e-06,
        "recall": 0.001
      },
      {
        "accuracy": 0.075,
        "f1": 0.05991541964352625,
        "hf_subset": "slk-eng",
        "languages": [
          "slk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05991541964352625,
        "precision": 0.05646616724254339,
        "recall": 0.075
      },
      {
        "accuracy": 0.004,
        "f1": 0.0012616246498599439,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0012616246498599439,
        "precision": 0.0011388278388278388,
        "recall": 0.004
      },
      {
        "accuracy": 0.077,
        "f1": 0.06192275853637457,
        "hf_subset": "pol-eng",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06192275853637457,
        "precision": 0.05831205208968367,
        "recall": 0.077
      },
      {
        "accuracy": 0.007,
        "f1": 0.006003322259136213,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ],
        "main_score": 0.006003322259136213,
        "precision": 0.006001663893510816,
        "recall": 0.007
      },
      {
        "accuracy": 0.064,
        "f1": 0.04483328696898954,
        "hf_subset": "tur-eng",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04483328696898954,
        "precision": 0.03976388708161643,
        "recall": 0.064
      },
      {
        "accuracy": 0.009879253567508232,
        "f1": 0.005291849325390232,
        "hf_subset": "arq-eng",
        "languages": [
          "arq-Arab",
          "eng-Latn"
        ],
        "main_score": 0.005291849325390232,
        "precision": 0.0049206771144581045,
        "recall": 0.009879253567508232
      },
      {
        "accuracy": 0.0047169811320754715,
        "f1": 0.0016724969408497114,
        "hf_subset": "yid-eng",
        "languages": [
          "yid-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.0016724969408497114,
        "precision": 0.0014848836640922866,
        "recall": 0.0047169811320754715
      },
      {
        "accuracy": 0.069,
        "f1": 0.05300514877842464,
        "hf_subset": "isl-eng",
        "languages": [
          "isl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05300514877842464,
        "precision": 0.05057078391995458,
        "recall": 0.069
      },
      {
        "accuracy": 0.041,
        "f1": 0.03172449629236437,
        "hf_subset": "cor-eng",
        "languages": [
          "cor-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03172449629236437,
        "precision": 0.03045470810245655,
        "recall": 0.041
      },
      {
        "accuracy": 0.015,
        "f1": 0.011171717171717171,
        "hf_subset": "tat-eng",
        "languages": [
          "tat-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.011171717171717171,
        "precision": 0.010515412676698586,
        "recall": 0.015
      },
      {
        "accuracy": 0.096,
        "f1": 0.06850712540314308,
        "hf_subset": "sqi-eng",
        "languages": [
          "sqi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06850712540314308,
        "precision": 0.06315859554769157,
        "recall": 0.096
      },
      {
        "accuracy": 0.0709812108559499,
        "f1": 0.0536041179598181,
        "hf_subset": "dsb-eng",
        "languages": [
          "dsb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0536041179598181,
        "precision": 0.049956558086044774,
        "recall": 0.0709812108559499
      },
      {
        "accuracy": 0.017,
        "f1": 0.011685415608599967,
        "hf_subset": "jpn-eng",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ],
        "main_score": 0.011685415608599967,
        "precision": 0.010633662683139337,
        "recall": 0.017
      },
      {
        "accuracy": 0.1183206106870229,
        "f1": 0.09124026200811113,
        "hf_subset": "fao-eng",
        "languages": [
          "fao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09124026200811113,
        "precision": 0.08450161479741632,
        "recall": 0.1183206106870229
      },
      {
        "accuracy": 0.194,
        "f1": 0.16545757575757575,
        "hf_subset": "nds-eng",
        "languages": [
          "nds-Latn",
          "eng-Latn"
        ],
        "main_score": 0.16545757575757575,
        "precision": 0.1569511655011655,
        "recall": 0.194
      },
      {
        "accuracy": 0.052,
        "f1": 0.04071123052574665,
        "hf_subset": "gle-eng",
        "languages": [
          "gle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04071123052574665,
        "precision": 0.03853209956709956,
        "recall": 0.052
      },
      {
        "accuracy": 0.009,
        "f1": 0.005327513227513228,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ],
        "main_score": 0.005327513227513228,
        "precision": 0.004892027228410497,
        "recall": 0.009
      },
      {
        "accuracy": 0.076,
        "f1": 0.06133300865800865,
        "hf_subset": "pam-eng",
        "languages": [
          "pam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06133300865800865,
        "precision": 0.05786909386909387,
        "recall": 0.076
      },
      {
        "accuracy": 0.062,
        "f1": 0.049653815465580176,
        "hf_subset": "fin-eng",
        "languages": [
          "fin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.049653815465580176,
        "precision": 0.04720584574738987,
        "recall": 0.062
      },
      {
        "accuracy": 0.004790419161676647,
        "f1": 0.000841893642809116,
        "hf_subset": "orv-eng",
        "languages": [
          "orv-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.000841893642809116,
        "precision": 0.0006207135296485539,
        "recall": 0.004790419161676647
      },
      {
        "accuracy": 0.19658119658119658,
        "f1": 0.14567562067562068,
        "hf_subset": "gsw-eng",
        "languages": [
          "gsw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.14567562067562068,
        "precision": 0.1319088319088319,
        "recall": 0.19658119658119658
      },
      {
        "accuracy": 0.006956521739130435,
        "f1": 0.0035651461738418263,
        "hf_subset": "kaz-eng",
        "languages": [
          "kaz-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.0035651461738418263,
        "precision": 0.0035226315657332233,
        "recall": 0.006956521739130435
      },
      {
        "accuracy": 0.048,
        "f1": 0.035855923344947735,
        "hf_subset": "est-eng",
        "languages": [
          "est-Latn",
          "eng-Latn"
        ],
        "main_score": 0.035855923344947735,
        "precision": 0.03293072390572391,
        "recall": 0.048
      },
      {
        "accuracy": 0.17,
        "f1": 0.14363238428122135,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ],
        "main_score": 0.14363238428122135,
        "precision": 0.1360568596009907,
        "recall": 0.17
      },
      {
        "accuracy": 0.14476190476190476,
        "f1": 0.12117224045795474,
        "hf_subset": "pms-eng",
        "languages": [
          "pms-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12117224045795474,
        "precision": 0.11597195657651144,
        "recall": 0.14476190476190476
      },
      {
        "accuracy": 0.001,
        "f1": 2.4937655860349126e-06,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 2.4937655860349126e-06,
        "precision": 1.2484394506866417e-06,
        "recall": 0.001
      },
      {
        "accuracy": 0.11219512195121951,
        "f1": 0.09024350968147361,
        "hf_subset": "kur-eng",
        "languages": [
          "kur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09024350968147361,
        "precision": 0.08539209123803476,
        "recall": 0.11219512195121951
      },
      {
        "accuracy": 0.006,
        "f1": 0.004402985074626865,
        "hf_subset": "heb-eng",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.004402985074626865,
        "precision": 0.004251494768310912,
        "recall": 0.006
      },
      {
        "accuracy": 0.008086253369272238,
        "f1": 0.006745055145383283,
        "hf_subset": "hye-eng",
        "languages": [
          "hye-Armn",
          "eng-Latn"
        ],
        "main_score": 0.006745055145383283,
        "precision": 0.006741807692056676,
        "recall": 0.008086253369272238
      },
      {
        "accuracy": 0.046,
        "f1": 0.03451553066816224,
        "hf_subset": "dtp-eng",
        "languages": [
          "dtp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03451553066816224,
        "precision": 0.031669841269841265,
        "recall": 0.046
      },
      {
        "accuracy": 0.07,
        "f1": 0.055176605149236724,
        "hf_subset": "tgl-eng",
        "languages": [
          "tgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.055176605149236724,
        "precision": 0.05186071428571429,
        "recall": 0.07
      },
      {
        "accuracy": 0.003257328990228013,
        "f1": 0.00021715526601520088,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.00021715526601520088,
        "precision": 0.00011232168931820734,
        "recall": 0.003257328990228013
      },
      {
        "accuracy": 0.018,
        "f1": 0.011973784526934133,
        "hf_subset": "kab-eng",
        "languages": [
          "kab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011973784526934133,
        "precision": 0.010971357506846465,
        "recall": 0.018
      },
      {
        "accuracy": 0.075,
        "f1": 0.06301345188018347,
        "hf_subset": "ind-eng",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06301345188018347,
        "precision": 0.060589864593456666,
        "recall": 0.075
      },
      {
        "accuracy": 0.011,
        "f1": 0.003583436394276928,
        "hf_subset": "mkd-eng",
        "languages": [
          "mkd-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.003583436394276928,
        "precision": 0.002695793166301333,
        "recall": 0.011
      },
      {
        "accuracy": 0.038,
        "f1": 0.02900353238492773,
        "hf_subset": "lit-eng",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02900353238492773,
        "precision": 0.027015672259492484,
        "recall": 0.038
      },
      {
        "accuracy": 0.24,
        "f1": 0.20911019762244182,
        "hf_subset": "glg-eng",
        "languages": [
          "glg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.20911019762244182,
        "precision": 0.19973260667903525,
        "recall": 0.24
      },
      {
        "accuracy": 0.09234507897934387,
        "f1": 0.0716924161171446,
        "hf_subset": "slv-eng",
        "languages": [
          "slv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0716924161171446,
        "precision": 0.06753250105226376,
        "recall": 0.09234507897934387
      },
      {
        "accuracy": 0.006925207756232687,
        "f1": 0.0031927033349606134,
        "hf_subset": "khm-eng",
        "languages": [
          "khm-Khmr",
          "eng-Latn"
        ],
        "main_score": 0.0031927033349606134,
        "precision": 0.0030068218659501057,
        "recall": 0.006925207756232687
      },
      {
        "accuracy": 0.127,
        "f1": 0.09173156392457812,
        "hf_subset": "lat-eng",
        "languages": [
          "lat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09173156392457812,
        "precision": 0.08430812741872062,
        "recall": 0.127
      },
      {
        "accuracy": 0.201,
        "f1": 0.1660518590126349,
        "hf_subset": "ido-eng",
        "languages": [
          "ido-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1660518590126349,
        "precision": 0.1565715577844041,
        "recall": 0.201
      },
      {
        "accuracy": 0.058,
        "f1": 0.05040204424580883,
        "hf_subset": "ber-eng",
        "languages": [
          "ber-Tfng",
          "eng-Latn"
        ],
        "main_score": 0.05040204424580883,
        "precision": 0.0492760055703626,
        "recall": 0.058
      },
      {
        "accuracy": 0.158,
        "f1": 0.12395453942193072,
        "hf_subset": "epo-eng",
        "languages": [
          "epo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12395453942193072,
        "precision": 0.11499790741300785,
        "recall": 0.158
      },
      {
        "accuracy": 0.04,
        "f1": 0.03159744463529774,
        "hf_subset": "srp-eng",
        "languages": [
          "srp-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.03159744463529774,
        "precision": 0.030187548794667264,
        "recall": 0.04
      },
      {
        "accuracy": 0.092,
        "f1": 0.07386403309401553,
        "hf_subset": "eus-eng",
        "languages": [
          "eus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07386403309401553,
        "precision": 0.06998096637517412,
        "recall": 0.092
      },
      {
        "accuracy": 0.277,
        "f1": 0.22722032038010298,
        "hf_subset": "por-eng",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ],
        "main_score": 0.22722032038010298,
        "precision": 0.21306217289956422,
        "recall": 0.277
      },
      {
        "accuracy": 0.053738317757009345,
        "f1": 0.03416304585451167,
        "hf_subset": "uzb-eng",
        "languages": [
          "uzb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03416304585451167,
        "precision": 0.030699365921328537,
        "recall": 0.053738317757009345
      },
      {
        "accuracy": 0.004366812227074236,
        "f1": 0.001513822221339673,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.001513822221339673,
        "precision": 0.0014851520862967683,
        "recall": 0.004366812227074236
      },
      {
        "accuracy": 0.293,
        "f1": 0.25134635368520775,
        "hf_subset": "fra-eng",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.25134635368520775,
        "precision": 0.23830726397437912,
        "recall": 0.293
      },
      {
        "accuracy": 0.006289308176100629,
        "f1": 0.0028504174482327413,
        "hf_subset": "arz-eng",
        "languages": [
          "arz-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0028504174482327413,
        "precision": 0.002543675751222921,
        "recall": 0.006289308176100629
      },
      {
        "accuracy": 0.221,
        "f1": 0.18237911522029168,
        "hf_subset": "ita-eng",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.18237911522029168,
        "precision": 0.1719418869806356,
        "recall": 0.221
      },
      {
        "accuracy": 0.104,
        "f1": 0.07670833848993866,
        "hf_subset": "afr-eng",
        "languages": [
          "afr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07670833848993866,
        "precision": 0.07037614267094604,
        "recall": 0.104
      },
      {
        "accuracy": 0.192,
        "f1": 0.1575538179212092,
        "hf_subset": "cbk-eng",
        "languages": [
          "cbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1575538179212092,
        "precision": 0.14776300220098174,
        "recall": 0.192
      },
      {
        "accuracy": 0.129,
        "f1": 0.10243534595867564,
        "hf_subset": "swe-eng",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.10243534595867564,
        "precision": 0.09582772967772968,
        "recall": 0.129
      },
      {
        "accuracy": 0.017,
        "f1": 0.011583333333333334,
        "hf_subset": "kor-eng",
        "languages": [
          "kor-Hang",
          "eng-Latn"
        ],
        "main_score": 0.011583333333333334,
        "precision": 0.010500791191659357,
        "recall": 0.017
      },
      {
        "accuracy": 0.385,
        "f1": 0.3382973656530885,
        "hf_subset": "ina-eng",
        "languages": [
          "ina-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3382973656530885,
        "precision": 0.3225824143248056,
        "recall": 0.385
      },
      {
        "accuracy": 0.148,
        "f1": 0.12232149036600257,
        "hf_subset": "oci-eng",
        "languages": [
          "oci-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12232149036600257,
        "precision": 0.11617123908029704,
        "recall": 0.148
      },
      {
        "accuracy": 0.008547008547008548,
        "f1": 0.004347826086956521,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.004347826086956521,
        "precision": 0.004310991153096417,
        "recall": 0.008547008547008548
      }
    ]
  },
  "task_name": "Tatoeba"
}