{
  "dataset_revision": "264a18480c529d9e922483839b4b9758e690b762",
  "evaluation_time": 1107.3931732177734,
  "kg_co2_emissions": 0.037843097287052666,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.08203125,
        "f1": 0.05615770673690933,
        "hf_subset": "eng_Latn-aai_Latn",
        "languages": [
          "eng-Latn",
          "aai-Latn"
        ],
        "main_score": 0.05615770673690933,
        "precision": 0.05057975878288379,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.0498043618977661,
        "hf_subset": "aai_Latn-eng_Latn",
        "languages": [
          "aai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0498043618977661,
        "precision": 0.04580078125,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007291666666666667,
        "hf_subset": "eng_Latn-aak_Arab",
        "languages": [
          "eng-Latn",
          "aak-Arab"
        ],
        "main_score": 0.007291666666666667,
        "precision": 0.004991319444444444,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0004502624045801527,
        "hf_subset": "aak_Arab-eng_Latn",
        "languages": [
          "aak-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0004502624045801527,
        "precision": 0.0002356401821862348,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.016498778998778996,
        "hf_subset": "eng_Latn-aau_Latn",
        "languages": [
          "eng-Latn",
          "aau-Latn"
        ],
        "main_score": 0.016498778998778996,
        "precision": 0.012386010997386758,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005916400547445255,
        "hf_subset": "aau_Latn-eng_Latn",
        "languages": [
          "aau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005916400547445255,
        "precision": 0.005237055759803921,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011610243055555556,
        "hf_subset": "eng_Latn-aaz_Latn",
        "languages": [
          "eng-Latn",
          "aaz-Latn"
        ],
        "main_score": 0.011610243055555556,
        "precision": 0.008989025297619047,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009068080357142856,
        "hf_subset": "aaz_Latn-eng_Latn",
        "languages": [
          "aaz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009068080357142856,
        "precision": 0.008534564393939393,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018836805555555555,
        "hf_subset": "eng_Latn-abt_Latn",
        "languages": [
          "eng-Latn",
          "abt-Latn"
        ],
        "main_score": 0.018836805555555555,
        "precision": 0.01635199652777778,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0065748619196895055,
        "hf_subset": "abt_Latn-eng_Latn",
        "languages": [
          "abt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0065748619196895055,
        "precision": 0.0042736235119047615,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03183340097402597,
        "hf_subset": "eng_Latn-abx_Latn",
        "languages": [
          "eng-Latn",
          "abx-Latn"
        ],
        "main_score": 0.03183340097402597,
        "precision": 0.02861912393162393,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011966765873015872,
        "hf_subset": "abx_Latn-eng_Latn",
        "languages": [
          "abx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011966765873015872,
        "precision": 0.010646446078431371,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011160714285714285,
        "hf_subset": "eng_Latn-aby_Latn",
        "languages": [
          "eng-Latn",
          "aby-Latn"
        ],
        "main_score": 0.0011160714285714285,
        "precision": 0.0006510416666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "aby_Latn-eng_Latn",
        "languages": [
          "aby-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005594477479757085,
        "hf_subset": "eng_Latn-acf_Latn",
        "languages": [
          "eng-Latn",
          "acf-Latn"
        ],
        "main_score": 0.005594477479757085,
        "precision": 0.004837549603174603,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004096798780487805,
        "hf_subset": "acf_Latn-eng_Latn",
        "languages": [
          "acf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004096798780487805,
        "precision": 0.00400390625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.012463064621781726,
        "hf_subset": "eng_Latn-acr_Latn",
        "languages": [
          "eng-Latn",
          "acr-Latn"
        ],
        "main_score": 0.012463064621781726,
        "precision": 0.00928579303851833,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022529636732431624,
        "hf_subset": "acr_Latn-eng_Latn",
        "languages": [
          "acr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022529636732431624,
        "precision": 0.01891670878256963,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019791666666666666,
        "hf_subset": "eng_Latn-acu_Latn",
        "languages": [
          "eng-Latn",
          "acu-Latn"
        ],
        "main_score": 0.019791666666666666,
        "precision": 0.018363864942528736,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012094422846889951,
        "hf_subset": "acu_Latn-eng_Latn",
        "languages": [
          "acu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012094422846889951,
        "precision": 0.009192088293650792,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.0686169733044733,
        "hf_subset": "eng_Latn-adz_Latn",
        "languages": [
          "eng-Latn",
          "adz-Latn"
        ],
        "main_score": 0.0686169733044733,
        "precision": 0.058821614583333334,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04070004836194595,
        "hf_subset": "adz_Latn-eng_Latn",
        "languages": [
          "adz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04070004836194595,
        "precision": 0.0363328470890046,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03610491071428572,
        "hf_subset": "eng_Latn-aer_Latn",
        "languages": [
          "eng-Latn",
          "aer-Latn"
        ],
        "main_score": 0.03610491071428572,
        "precision": 0.03195970695970696,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016567460317460314,
        "hf_subset": "aer_Latn-eng_Latn",
        "languages": [
          "aer-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016567460317460314,
        "precision": 0.014615885416666667,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008159722222222221,
        "hf_subset": "eng_Latn-aey_Latn",
        "languages": [
          "eng-Latn",
          "aey-Latn"
        ],
        "main_score": 0.008159722222222221,
        "precision": 0.006781684027777778,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008471331908831908,
        "hf_subset": "aey_Latn-eng_Latn",
        "languages": [
          "aey-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008471331908831908,
        "precision": 0.00816717195273632,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005754697712418301,
        "hf_subset": "eng_Latn-agd_Latn",
        "languages": [
          "eng-Latn",
          "agd-Latn"
        ],
        "main_score": 0.005754697712418301,
        "precision": 0.004917689732142857,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005859375,
        "hf_subset": "agd_Latn-eng_Latn",
        "languages": [
          "agd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005208333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012398856026785714,
        "hf_subset": "eng_Latn-agg_Latn",
        "languages": [
          "eng-Latn",
          "agg-Latn"
        ],
        "main_score": 0.012398856026785714,
        "precision": 0.010659222676081229,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003569135273972603,
        "hf_subset": "agg_Latn-eng_Latn",
        "languages": [
          "agg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003569135273972603,
        "precision": 0.002305585488505747,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0042906746031746035,
        "hf_subset": "eng_Latn-agm_Latn",
        "languages": [
          "eng-Latn",
          "agm-Latn"
        ],
        "main_score": 0.0042906746031746035,
        "precision": 0.0029926915322580645,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004557291666666666,
        "hf_subset": "agm_Latn-eng_Latn",
        "languages": [
          "agm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004557291666666666,
        "precision": 0.003255208333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.028580729166666666,
        "hf_subset": "eng_Latn-agn_Latn",
        "languages": [
          "eng-Latn",
          "agn-Latn"
        ],
        "main_score": 0.028580729166666666,
        "precision": 0.023149181547619045,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013281249999999998,
        "hf_subset": "agn_Latn-eng_Latn",
        "languages": [
          "agn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013281249999999998,
        "precision": 0.0107421875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015294908285895003,
        "hf_subset": "eng_Latn-agr_Latn",
        "languages": [
          "eng-Latn",
          "agr-Latn"
        ],
        "main_score": 0.015294908285895003,
        "precision": 0.013850911458333334,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005729166666666667,
        "hf_subset": "agr_Latn-eng_Latn",
        "languages": [
          "agr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005729166666666667,
        "precision": 0.004966517857142857,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01115451388888889,
        "hf_subset": "eng_Latn-agt_Latn",
        "languages": [
          "eng-Latn",
          "agt-Latn"
        ],
        "main_score": 0.01115451388888889,
        "precision": 0.007533482142857143,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "agt_Latn-eng_Latn",
        "languages": [
          "agt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013561712609801201,
        "hf_subset": "eng_Latn-agu_Latn",
        "languages": [
          "eng-Latn",
          "agu-Latn"
        ],
        "main_score": 0.013561712609801201,
        "precision": 0.01175704656862745,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006510416666666666,
        "hf_subset": "agu_Latn-eng_Latn",
        "languages": [
          "agu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006510416666666666,
        "precision": 0.005859375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006975446428571428,
        "hf_subset": "eng_Latn-aia_Latn",
        "languages": [
          "eng-Latn",
          "aia-Latn"
        ],
        "main_score": 0.006975446428571428,
        "precision": 0.005859375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01112689393939394,
        "hf_subset": "aia_Latn-eng_Latn",
        "languages": [
          "aia-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01112689393939394,
        "precision": 0.01015625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-aii_Syrc",
        "languages": [
          "eng-Latn",
          "aii-Syrc"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "aii_Syrc-eng_Latn",
        "languages": [
          "aii-Syrc",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.046875,
        "f1": 0.018217495331465917,
        "hf_subset": "eng_Latn-aka_Latn",
        "languages": [
          "eng-Latn",
          "aka-Latn"
        ],
        "main_score": 0.018217495331465917,
        "precision": 0.013481880958872781,
        "recall": 0.046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007084396258503402,
        "hf_subset": "aka_Latn-eng_Latn",
        "languages": [
          "aka-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007084396258503402,
        "precision": 0.0058861301369863015,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005533854166666666,
        "hf_subset": "eng_Latn-ake_Latn",
        "languages": [
          "eng-Latn",
          "ake-Latn"
        ],
        "main_score": 0.005533854166666666,
        "precision": 0.0038132440476190475,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "ake_Latn-eng_Latn",
        "languages": [
          "ake-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019299768518518518,
        "hf_subset": "eng_Latn-alp_Latn",
        "languages": [
          "eng-Latn",
          "alp-Latn"
        ],
        "main_score": 0.019299768518518518,
        "precision": 0.016919495435120436,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004314024390243903,
        "hf_subset": "alp_Latn-eng_Latn",
        "languages": [
          "alp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004314024390243903,
        "precision": 0.004117235725308642,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02997891865079365,
        "hf_subset": "eng_Latn-alq_Latn",
        "languages": [
          "eng-Latn",
          "alq-Latn"
        ],
        "main_score": 0.02997891865079365,
        "precision": 0.02587890625,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02011774777682157,
        "hf_subset": "alq_Latn-eng_Latn",
        "languages": [
          "alq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02011774777682157,
        "precision": 0.016329308712121213,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009955018939393937,
        "hf_subset": "eng_Latn-als_Latn",
        "languages": [
          "eng-Latn",
          "als-Latn"
        ],
        "main_score": 0.009955018939393937,
        "precision": 0.00646391369047619,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011641245039682538,
        "hf_subset": "als_Latn-eng_Latn",
        "languages": [
          "als-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011641245039682538,
        "precision": 0.010471684272300469,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.0209130145113601,
        "hf_subset": "eng_Latn-aly_Latn",
        "languages": [
          "eng-Latn",
          "aly-Latn"
        ],
        "main_score": 0.0209130145113601,
        "precision": 0.018058728871855344,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02392181657318376,
        "hf_subset": "aly_Latn-eng_Latn",
        "languages": [
          "aly-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02392181657318376,
        "precision": 0.01998638297466422,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009220271915584416,
        "hf_subset": "eng_Latn-ame_Latn",
        "languages": [
          "eng-Latn",
          "ame-Latn"
        ],
        "main_score": 0.009220271915584416,
        "precision": 0.007133556547619047,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0004365079365079365,
        "hf_subset": "ame_Latn-eng_Latn",
        "languages": [
          "ame-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0004365079365079365,
        "precision": 0.00022576444892473117,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-amf_Latn",
        "languages": [
          "eng-Latn",
          "amf-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0002232142857142857,
        "hf_subset": "amf_Latn-eng_Latn",
        "languages": [
          "amf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0002232142857142857,
        "precision": 0.00011488970588235294,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005784970238095238,
        "hf_subset": "eng_Latn-amk_Latn",
        "languages": [
          "eng-Latn",
          "amk-Latn"
        ],
        "main_score": 0.005784970238095238,
        "precision": 0.004969017621870882,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011569940476190477,
        "hf_subset": "amk_Latn-eng_Latn",
        "languages": [
          "amk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011569940476190477,
        "precision": 0.00890687003968254,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011160714285714285,
        "hf_subset": "eng_Latn-amm_Latn",
        "languages": [
          "eng-Latn",
          "amm-Latn"
        ],
        "main_score": 0.0011160714285714285,
        "precision": 0.0006510416666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "amm_Latn-eng_Latn",
        "languages": [
          "amm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006592480742296919,
        "hf_subset": "eng_Latn-amn_Latn",
        "languages": [
          "eng-Latn",
          "amn-Latn"
        ],
        "main_score": 0.006592480742296919,
        "precision": 0.005400686553030302,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004056490384615385,
        "hf_subset": "amn_Latn-eng_Latn",
        "languages": [
          "amn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004056490384615385,
        "precision": 0.003982843137254902,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014227092352092352,
        "hf_subset": "eng_Latn-amo_Latn",
        "languages": [
          "eng-Latn",
          "amo-Latn"
        ],
        "main_score": 0.014227092352092352,
        "precision": 0.011946614583333334,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012772942468317972,
        "hf_subset": "amo_Latn-eng_Latn",
        "languages": [
          "amo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012772942468317972,
        "precision": 0.01227544716708023,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005989583333333333,
        "hf_subset": "eng_Latn-amp_Latn",
        "languages": [
          "eng-Latn",
          "amp-Latn"
        ],
        "main_score": 0.005989583333333333,
        "precision": 0.005161830357142857,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012738715277777778,
        "hf_subset": "amp_Latn-eng_Latn",
        "languages": [
          "amp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012738715277777778,
        "precision": 0.010927413438967136,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01772553066037736,
        "hf_subset": "eng_Latn-amr_Latn",
        "languages": [
          "eng-Latn",
          "amr-Latn"
        ],
        "main_score": 0.01772553066037736,
        "precision": 0.017002203525641024,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011300223214285714,
        "hf_subset": "amr_Latn-eng_Latn",
        "languages": [
          "amr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011300223214285714,
        "precision": 0.009973099816849818,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02156667649371069,
        "hf_subset": "eng_Latn-amu_Latn",
        "languages": [
          "eng-Latn",
          "amu-Latn"
        ],
        "main_score": 0.02156667649371069,
        "precision": 0.01853680173992674,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.019639068613677986,
        "hf_subset": "amu_Latn-eng_Latn",
        "languages": [
          "amu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019639068613677986,
        "precision": 0.016757740788093365,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.12468902625152625,
        "hf_subset": "eng_Latn-amx_Latn",
        "languages": [
          "eng-Latn",
          "amx-Latn"
        ],
        "main_score": 0.12468902625152625,
        "precision": 0.11608124586640212,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.15625,
        "f1": 0.1183960373419176,
        "hf_subset": "amx_Latn-eng_Latn",
        "languages": [
          "amx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1183960373419176,
        "precision": 0.10979042658730159,
        "recall": 0.15625
      },
      {
        "accuracy": 0.05405405405405406,
        "f1": 0.035866511672963286,
        "hf_subset": "eng_Latn-anh_Latn",
        "languages": [
          "eng-Latn",
          "anh-Latn"
        ],
        "main_score": 0.035866511672963286,
        "precision": 0.03311883311883312,
        "recall": 0.05405405405405406
      },
      {
        "accuracy": 0.02702702702702703,
        "f1": 0.012216762216762217,
        "hf_subset": "anh_Latn-eng_Latn",
        "languages": [
          "anh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012216762216762217,
        "precision": 0.01091436263850057,
        "recall": 0.02702702702702703
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012113864942528736,
        "hf_subset": "eng_Latn-anv_Latn",
        "languages": [
          "eng-Latn",
          "anv-Latn"
        ],
        "main_score": 0.012113864942528736,
        "precision": 0.010810718201754386,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007256054131054131,
        "hf_subset": "anv_Latn-eng_Latn",
        "languages": [
          "anv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007256054131054131,
        "precision": 0.006258598663522012,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006387061403508773,
        "hf_subset": "eng_Latn-aoi_Latn",
        "languages": [
          "eng-Latn",
          "aoi-Latn"
        ],
        "main_score": 0.006387061403508773,
        "precision": 0.005386594742063492,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.00839721184016242,
        "hf_subset": "aoi_Latn-eng_Latn",
        "languages": [
          "aoi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00839721184016242,
        "precision": 0.005738467261904762,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015420386904761904,
        "hf_subset": "eng_Latn-aoj_Latn",
        "languages": [
          "eng-Latn",
          "aoj-Latn"
        ],
        "main_score": 0.015420386904761904,
        "precision": 0.011682581018518517,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008676861702127659,
        "hf_subset": "aoj_Latn-eng_Latn",
        "languages": [
          "aoj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008676861702127659,
        "precision": 0.006866518404546312,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.05925894474637681,
        "hf_subset": "eng_Latn-aom_Latn",
        "languages": [
          "eng-Latn",
          "aom-Latn"
        ],
        "main_score": 0.05925894474637681,
        "precision": 0.054772050865800864,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04680245535714286,
        "hf_subset": "aom_Latn-eng_Latn",
        "languages": [
          "aom-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04680245535714286,
        "precision": 0.043201264880952384,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007870628720238094,
        "hf_subset": "eng_Latn-aon_Latn",
        "languages": [
          "eng-Latn",
          "aon-Latn"
        ],
        "main_score": 0.007870628720238094,
        "precision": 0.006636424731182796,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0008032332251082251,
        "hf_subset": "aon_Latn-eng_Latn",
        "languages": [
          "aon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0008032332251082251,
        "precision": 0.0004376882530120482,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012872587481962482,
        "hf_subset": "eng_Latn-apb_Latn",
        "languages": [
          "eng-Latn",
          "apb-Latn"
        ],
        "main_score": 0.012872587481962482,
        "precision": 0.010940004006410254,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "apb_Latn-eng_Latn",
        "languages": [
          "apb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01307040276219338,
        "hf_subset": "eng_Latn-ape_Latn",
        "languages": [
          "eng-Latn",
          "ape-Latn"
        ],
        "main_score": 0.01307040276219338,
        "precision": 0.010020377403189902,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005727242405582923,
        "hf_subset": "ape_Latn-eng_Latn",
        "languages": [
          "ape-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005727242405582923,
        "precision": 0.004939532039141414,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001488095238095238,
        "hf_subset": "eng_Latn-apn_Latn",
        "languages": [
          "eng-Latn",
          "apn-Latn"
        ],
        "main_score": 0.001488095238095238,
        "precision": 0.0008463541666666667,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00043267986542443063,
        "hf_subset": "apn_Latn-eng_Latn",
        "languages": [
          "apn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00043267986542443063,
        "precision": 0.00022462007119386637,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020062362938596492,
        "hf_subset": "eng_Latn-apr_Latn",
        "languages": [
          "eng-Latn",
          "apr-Latn"
        ],
        "main_score": 0.020062362938596492,
        "precision": 0.016288610038610037,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00546875,
        "hf_subset": "apr_Latn-eng_Latn",
        "languages": [
          "apr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00546875,
        "precision": 0.0048828125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0060546875,
        "hf_subset": "eng_Latn-apu_Latn",
        "languages": [
          "eng-Latn",
          "apu-Latn"
        ],
        "main_score": 0.0060546875,
        "precision": 0.005308493589743589,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "apu_Latn-eng_Latn",
        "languages": [
          "apu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.08502385425876804,
        "hf_subset": "eng_Latn-apw_Latn",
        "languages": [
          "eng-Latn",
          "apw-Latn"
        ],
        "main_score": 0.08502385425876804,
        "precision": 0.07887903928018576,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.06933069969186773,
        "hf_subset": "apw_Latn-eng_Latn",
        "languages": [
          "apw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06933069969186773,
        "precision": 0.06420355902777777,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-apz_Latn",
        "languages": [
          "eng-Latn",
          "apz-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005208333333333333,
        "hf_subset": "apz_Latn-eng_Latn",
        "languages": [
          "apz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005208333333333333,
        "precision": 0.00027901785714285713,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001471185064935065,
        "hf_subset": "eng_Latn-arb_Arab",
        "languages": [
          "eng-Latn",
          "arb-Arab"
        ],
        "main_score": 0.001471185064935065,
        "precision": 0.0008370535714285714,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00234375,
        "hf_subset": "arb_Arab-eng_Latn",
        "languages": [
          "arb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.00234375,
        "precision": 0.0015076754385964911,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.0840072710156223,
        "hf_subset": "eng_Latn-are_Latn",
        "languages": [
          "eng-Latn",
          "are-Latn"
        ],
        "main_score": 0.0840072710156223,
        "precision": 0.07827413586048454,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.09375,
        "f1": 0.05335506507381507,
        "hf_subset": "are_Latn-eng_Latn",
        "languages": [
          "are-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05335506507381507,
        "precision": 0.04707569370695035,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023050704656862743,
        "hf_subset": "eng_Latn-arl_Latn",
        "languages": [
          "eng-Latn",
          "arl-Latn"
        ],
        "main_score": 0.023050704656862743,
        "precision": 0.019680238381410257,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007898163377192981,
        "hf_subset": "arl_Latn-eng_Latn",
        "languages": [
          "arl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007898163377192981,
        "precision": 0.006634424603174603,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "eng_Latn-arn_Latn",
        "languages": [
          "eng-Latn",
          "arn-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0043306564723590586,
        "hf_subset": "arn_Latn-eng_Latn",
        "languages": [
          "arn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0043306564723590586,
        "precision": 0.0024421703834115807,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.16129032258064516,
        "f1": 0.1043713542764776,
        "hf_subset": "eng_Latn-arp_Latn",
        "languages": [
          "eng-Latn",
          "arp-Latn"
        ],
        "main_score": 0.1043713542764776,
        "precision": 0.09185227854582695,
        "recall": 0.16129032258064516
      },
      {
        "accuracy": 0.13978494623655913,
        "f1": 0.10314551040357492,
        "hf_subset": "arp_Latn-eng_Latn",
        "languages": [
          "arp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.10314551040357492,
        "precision": 0.09713261648745519,
        "recall": 0.13978494623655913
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0047543134884078,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0047543134884078,
        "precision": 0.003355333097094259,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005532296650717704,
        "hf_subset": "eng_Latn-aso_Latn",
        "languages": [
          "eng-Latn",
          "aso-Latn"
        ],
        "main_score": 0.0005532296650717704,
        "precision": 0.00028935185185185184,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006765727124183006,
        "hf_subset": "aso_Latn-eng_Latn",
        "languages": [
          "aso-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006765727124183006,
        "precision": 0.00035574776785714284,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013383891704204204,
        "hf_subset": "eng_Latn-ata_Latn",
        "languages": [
          "eng-Latn",
          "ata-Latn"
        ],
        "main_score": 0.013383891704204204,
        "precision": 0.011245969742063492,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0026400211352657008,
        "hf_subset": "ata_Latn-eng_Latn",
        "languages": [
          "ata-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026400211352657008,
        "precision": 0.001504441738816739,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019567265070921984,
        "hf_subset": "eng_Latn-atb_Latn",
        "languages": [
          "eng-Latn",
          "atb-Latn"
        ],
        "main_score": 0.019567265070921984,
        "precision": 0.01690349486714976,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012987012987012986,
        "hf_subset": "atb_Latn-eng_Latn",
        "languages": [
          "atb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012987012987012986,
        "precision": 0.011237980769230771,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017476851851851855,
        "hf_subset": "eng_Latn-atd_Latn",
        "languages": [
          "eng-Latn",
          "atd-Latn"
        ],
        "main_score": 0.017476851851851855,
        "precision": 0.016751802884615384,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004014756944444444,
        "hf_subset": "atd_Latn-eng_Latn",
        "languages": [
          "atd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004014756944444444,
        "precision": 0.00274094012605042,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015625,
        "hf_subset": "eng_Latn-atg_Latn",
        "languages": [
          "eng-Latn",
          "atg-Latn"
        ],
        "main_score": 0.0015625,
        "precision": 0.0009765625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008072916666666666,
        "hf_subset": "atg_Latn-eng_Latn",
        "languages": [
          "atg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008072916666666666,
        "precision": 0.0068359375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01914368632445141,
        "hf_subset": "eng_Latn-att_Latn",
        "languages": [
          "eng-Latn",
          "att-Latn"
        ],
        "main_score": 0.01914368632445141,
        "precision": 0.01521577380952381,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007868638728013728,
        "hf_subset": "att_Latn-eng_Latn",
        "languages": [
          "att-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007868638728013728,
        "precision": 0.006600839120370371,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005890376984126984,
        "hf_subset": "eng_Latn-auc_Latn",
        "languages": [
          "eng-Latn",
          "auc-Latn"
        ],
        "main_score": 0.005890376984126984,
        "precision": 0.005045572916666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004045758928571429,
        "hf_subset": "auc_Latn-eng_Latn",
        "languages": [
          "auc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004045758928571429,
        "precision": 0.003977272727272727,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.04608707264957265,
        "hf_subset": "eng_Latn-aui_Latn",
        "languages": [
          "eng-Latn",
          "aui-Latn"
        ],
        "main_score": 0.04608707264957265,
        "precision": 0.038771446078431374,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.03551333648989899,
        "hf_subset": "aui_Latn-eng_Latn",
        "languages": [
          "aui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03551333648989899,
        "precision": 0.030930193095186697,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "eng_Latn-auy_Latn",
        "languages": [
          "eng-Latn",
          "auy-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 7.584951456310679e-05,
        "hf_subset": "auy_Latn-eng_Latn",
        "languages": [
          "auy-Latn",
          "eng-Latn"
        ],
        "main_score": 7.584951456310679e-05,
        "precision": 3.829656862745098e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013237847222222222,
        "hf_subset": "eng_Latn-avt_Latn",
        "languages": [
          "eng-Latn",
          "avt-Latn"
        ],
        "main_score": 0.013237847222222222,
        "precision": 0.010384114583333333,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012100387168141593,
        "hf_subset": "avt_Latn-eng_Latn",
        "languages": [
          "avt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012100387168141593,
        "precision": 0.011916387648809524,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015625,
        "hf_subset": "eng_Latn-awb_Latn",
        "languages": [
          "eng-Latn",
          "awb-Latn"
        ],
        "main_score": 0.0015625,
        "precision": 0.0009765625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013020833333333333,
        "hf_subset": "awb_Latn-eng_Latn",
        "languages": [
          "awb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.00078125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0707070707070707,
        "f1": 0.043771043771043766,
        "hf_subset": "eng_Latn-awk_Latn",
        "languages": [
          "eng-Latn",
          "awk-Latn"
        ],
        "main_score": 0.043771043771043766,
        "precision": 0.034006734006734006,
        "recall": 0.0707070707070707
      },
      {
        "accuracy": 0.0707070707070707,
        "f1": 0.04463684463684463,
        "hf_subset": "awk_Latn-eng_Latn",
        "languages": [
          "awk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04463684463684463,
        "precision": 0.03775853775853776,
        "recall": 0.0707070707070707
      },
      {
        "accuracy": 0.19921875,
        "f1": 0.15382263136169386,
        "hf_subset": "eng_Latn-awx_Latn",
        "languages": [
          "eng-Latn",
          "awx-Latn"
        ],
        "main_score": 0.15382263136169386,
        "precision": 0.14252852182539683,
        "recall": 0.19921875
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.10069704961117511,
        "hf_subset": "awx_Latn-eng_Latn",
        "languages": [
          "awx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.10069704961117511,
        "precision": 0.09197779415458347,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01617476851851852,
        "hf_subset": "eng_Latn-azb_Arab",
        "languages": [
          "eng-Latn",
          "azb-Arab"
        ],
        "main_score": 0.01617476851851852,
        "precision": 0.014798677884615384,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007337276365348399,
        "hf_subset": "azb_Arab-eng_Latn",
        "languages": [
          "azb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.007337276365348399,
        "precision": 0.00478931604969574,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.027883184523809522,
        "hf_subset": "eng_Latn-azg_Latn",
        "languages": [
          "eng-Latn",
          "azg-Latn"
        ],
        "main_score": 0.027883184523809522,
        "precision": 0.023893229166666665,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013583519345238094,
        "hf_subset": "azg_Latn-eng_Latn",
        "languages": [
          "azg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013583519345238094,
        "precision": 0.012016726762820513,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010243055555555556,
        "hf_subset": "eng_Latn-azz_Latn",
        "languages": [
          "eng-Latn",
          "azz-Latn"
        ],
        "main_score": 0.010243055555555556,
        "precision": 0.00927734375,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01472694657316368,
        "hf_subset": "azz_Latn-eng_Latn",
        "languages": [
          "azz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01472694657316368,
        "precision": 0.012210648148148148,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020316329656862746,
        "hf_subset": "eng_Latn-bao_Latn",
        "languages": [
          "eng-Latn",
          "bao-Latn"
        ],
        "main_score": 0.020316329656862746,
        "precision": 0.016261456642316017,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011067708333333332,
        "hf_subset": "bao_Latn-eng_Latn",
        "languages": [
          "bao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011067708333333332,
        "precision": 0.009114583333333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002803308823529412,
        "hf_subset": "eng_Latn-bba_Latn",
        "languages": [
          "eng-Latn",
          "bba-Latn"
        ],
        "main_score": 0.002803308823529412,
        "precision": 0.0016547309027777778,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "bba_Latn-eng_Latn",
        "languages": [
          "bba-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007378472222222222,
        "hf_subset": "eng_Latn-bbb_Latn",
        "languages": [
          "eng-Latn",
          "bbb-Latn"
        ],
        "main_score": 0.007378472222222222,
        "precision": 0.00634765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004065688775510204,
        "hf_subset": "bbb_Latn-eng_Latn",
        "languages": [
          "bbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004065688775510204,
        "precision": 0.003987630208333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016681690705128205,
        "hf_subset": "eng_Latn-bbr_Latn",
        "languages": [
          "eng-Latn",
          "bbr-Latn"
        ],
        "main_score": 0.016681690705128205,
        "precision": 0.013429385567632849,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011229872557997558,
        "hf_subset": "bbr_Latn-eng_Latn",
        "languages": [
          "bbr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011229872557997558,
        "precision": 0.010190810857171152,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.019541529605263157,
        "hf_subset": "eng_Latn-bch_Latn",
        "languages": [
          "eng-Latn",
          "bch-Latn"
        ],
        "main_score": 0.019541529605263157,
        "precision": 0.014734001452751451,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008298088972431079,
        "hf_subset": "bch_Latn-eng_Latn",
        "languages": [
          "bch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008298088972431079,
        "precision": 0.005750868055555556,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016276041666666664,
        "hf_subset": "eng_Latn-bco_Latn",
        "languages": [
          "eng-Latn",
          "bco-Latn"
        ],
        "main_score": 0.016276041666666664,
        "precision": 0.013733878968253968,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007915296052631578,
        "hf_subset": "bco_Latn-eng_Latn",
        "languages": [
          "bco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007915296052631578,
        "precision": 0.007864583333333335,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "eng_Latn-bdd_Latn",
        "languages": [
          "eng-Latn",
          "bdd-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005659298780487805,
        "hf_subset": "bdd_Latn-eng_Latn",
        "languages": [
          "bdd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005659298780487805,
        "precision": 0.0038085937500000003,
        "recall": 0.015625
      },
      {
        "accuracy": 0.14666666666666667,
        "f1": 0.09584126984126984,
        "hf_subset": "eng_Latn-bea_Latn",
        "languages": [
          "eng-Latn",
          "bea-Latn"
        ],
        "main_score": 0.09584126984126984,
        "precision": 0.08225356125356126,
        "recall": 0.14666666666666667
      },
      {
        "accuracy": 0.13333333333333333,
        "f1": 0.08881481481481482,
        "hf_subset": "bea_Latn-eng_Latn",
        "languages": [
          "bea-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08881481481481482,
        "precision": 0.07918112014453477,
        "recall": 0.13333333333333333
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005022321428571428,
        "hf_subset": "eng_Latn-bef_Latn",
        "languages": [
          "eng-Latn",
          "bef-Latn"
        ],
        "main_score": 0.005022321428571428,
        "precision": 0.004557291666666667,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00010702054794520547,
        "hf_subset": "bef_Latn-eng_Latn",
        "languages": [
          "bef-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00010702054794520547,
        "precision": 5.425347222222222e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0060546875,
        "hf_subset": "eng_Latn-bel_Cyrl",
        "languages": [
          "eng-Latn",
          "bel-Cyrl"
        ],
        "main_score": 0.0060546875,
        "precision": 0.005098417207792208,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00044627790758047765,
        "hf_subset": "bel_Cyrl-eng_Latn",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.00044627790758047765,
        "precision": 0.00022817794570658453,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002022058823529412,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.002022058823529412,
        "precision": 0.001220703125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0009410695742471443,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0009410695742471443,
        "precision": 0.0005251326650943396,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-beo_Latn",
        "languages": [
          "eng-Latn",
          "beo-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0035097823183760685,
        "hf_subset": "beo_Latn-eng_Latn",
        "languages": [
          "beo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0035097823183760685,
        "precision": 0.002153577302631579,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.020241477272727272,
        "hf_subset": "eng_Latn-beu_Latn",
        "languages": [
          "eng-Latn",
          "beu-Latn"
        ],
        "main_score": 0.020241477272727272,
        "precision": 0.01574280753968254,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01903350779967159,
        "hf_subset": "beu_Latn-eng_Latn",
        "languages": [
          "beu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01903350779967159,
        "precision": 0.016597755238791423,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014127604166666665,
        "hf_subset": "eng_Latn-bgs_Latn",
        "languages": [
          "eng-Latn",
          "bgs-Latn"
        ],
        "main_score": 0.014127604166666665,
        "precision": 0.012023285232383808,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00706845238095238,
        "hf_subset": "bgs_Latn-eng_Latn",
        "languages": [
          "bgs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00706845238095238,
        "precision": 0.004919776404151404,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007034632034632034,
        "hf_subset": "eng_Latn-bgt_Latn",
        "languages": [
          "eng-Latn",
          "bgt-Latn"
        ],
        "main_score": 0.007034632034632034,
        "precision": 0.004557291666666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026041666666666665,
        "hf_subset": "bgt_Latn-eng_Latn",
        "languages": [
          "bgt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.0015625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.0778250102124183,
        "hf_subset": "eng_Latn-bhg_Latn",
        "languages": [
          "eng-Latn",
          "bhg-Latn"
        ],
        "main_score": 0.0778250102124183,
        "precision": 0.07108212425595238,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03811631944444444,
        "hf_subset": "bhg_Latn-eng_Latn",
        "languages": [
          "bhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03811631944444444,
        "precision": 0.035389529014363964,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0028521825396825395,
        "hf_subset": "eng_Latn-bhl_Latn",
        "languages": [
          "eng-Latn",
          "bhl-Latn"
        ],
        "main_score": 0.0028521825396825395,
        "precision": 0.0016620710784313727,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "bhl_Latn-eng_Latn",
        "languages": [
          "bhl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008537946428571428,
        "hf_subset": "eng_Latn-big_Latn",
        "languages": [
          "eng-Latn",
          "big-Latn"
        ],
        "main_score": 0.008537946428571428,
        "precision": 0.0068359375,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00412185953559193,
        "hf_subset": "big_Latn-eng_Latn",
        "languages": [
          "big-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00412185953559193,
        "precision": 0.004015563845401174,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.020392330109126985,
        "hf_subset": "eng_Latn-bjk_Latn",
        "languages": [
          "eng-Latn",
          "bjk-Latn"
        ],
        "main_score": 0.020392330109126985,
        "precision": 0.015169720862135177,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011594742063492062,
        "hf_subset": "bjk_Latn-eng_Latn",
        "languages": [
          "bjk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011594742063492062,
        "precision": 0.009145833333333332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0101010101010101,
        "hf_subset": "eng_Latn-bjp_Latn",
        "languages": [
          "eng-Latn",
          "bjp-Latn"
        ],
        "main_score": 0.0101010101010101,
        "precision": 0.00705879407051282,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004734848484848484,
        "hf_subset": "bjp_Latn-eng_Latn",
        "languages": [
          "bjp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004734848484848484,
        "precision": 0.003346051356589147,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005360243055555556,
        "hf_subset": "eng_Latn-bjr_Latn",
        "languages": [
          "eng-Latn",
          "bjr-Latn"
        ],
        "main_score": 0.005360243055555556,
        "precision": 0.0035993303571428574,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00021701388888888888,
        "hf_subset": "bjr_Latn-eng_Latn",
        "languages": [
          "bjr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00021701388888888888,
        "precision": 0.00011160714285714285,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008463541666666666,
        "hf_subset": "eng_Latn-bjv_Latn",
        "languages": [
          "eng-Latn",
          "bjv-Latn"
        ],
        "main_score": 0.008463541666666666,
        "precision": 0.007041529605263158,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00657719017094017,
        "hf_subset": "bjv_Latn-eng_Latn",
        "languages": [
          "bjv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00657719017094017,
        "precision": 0.005893049568965517,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018754650297619045,
        "hf_subset": "eng_Latn-bjz_Latn",
        "languages": [
          "eng-Latn",
          "bjz-Latn"
        ],
        "main_score": 0.018754650297619045,
        "precision": 0.015448050213675214,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0016553925304878048,
        "hf_subset": "bjz_Latn-eng_Latn",
        "languages": [
          "bjz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0016553925304878048,
        "precision": 0.0009161086309523808,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01847163481620718,
        "hf_subset": "eng_Latn-bkd_Latn",
        "languages": [
          "eng-Latn",
          "bkd-Latn"
        ],
        "main_score": 0.01847163481620718,
        "precision": 0.016132399140211643,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019806690705128204,
        "hf_subset": "bkd_Latn-eng_Latn",
        "languages": [
          "bkd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019806690705128204,
        "precision": 0.017159598214285712,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002659970238095238,
        "hf_subset": "eng_Latn-bki_Latn",
        "languages": [
          "eng-Latn",
          "bki-Latn"
        ],
        "main_score": 0.002659970238095238,
        "precision": 0.0016763755807200928,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003735632183908046,
        "hf_subset": "bki_Latn-eng_Latn",
        "languages": [
          "bki-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003735632183908046,
        "precision": 0.00019229609073359073,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004679608585858586,
        "hf_subset": "eng_Latn-bkq_Latn",
        "languages": [
          "eng-Latn",
          "bkq-Latn"
        ],
        "main_score": 0.004679608585858586,
        "precision": 0.004310587381504326,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00455417663476874,
        "hf_subset": "bkq_Latn-eng_Latn",
        "languages": [
          "bkq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00455417663476874,
        "precision": 0.004245334201388889,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.020113133394383392,
        "hf_subset": "eng_Latn-bkx_Latn",
        "languages": [
          "eng-Latn",
          "bkx-Latn"
        ],
        "main_score": 0.020113133394383392,
        "precision": 0.016034478695324282,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.00900297619047619,
        "hf_subset": "bkx_Latn-eng_Latn",
        "languages": [
          "bkx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00900297619047619,
        "precision": 0.006039074283559578,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014793669871794871,
        "hf_subset": "eng_Latn-blw_Latn",
        "languages": [
          "eng-Latn",
          "blw-Latn"
        ],
        "main_score": 0.014793669871794871,
        "precision": 0.012399384469696968,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014427083333333333,
        "hf_subset": "blw_Latn-eng_Latn",
        "languages": [
          "blw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014427083333333333,
        "precision": 0.013724662162162162,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011571898496240601,
        "hf_subset": "eng_Latn-blz_Latn",
        "languages": [
          "eng-Latn",
          "blz-Latn"
        ],
        "main_score": 0.011571898496240601,
        "precision": 0.00856062682748538,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009375,
        "hf_subset": "blz_Latn-eng_Latn",
        "languages": [
          "blz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009375,
        "precision": 0.0087890625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016422032828282827,
        "hf_subset": "eng_Latn-bmh_Latn",
        "languages": [
          "eng-Latn",
          "bmh-Latn"
        ],
        "main_score": 0.016422032828282827,
        "precision": 0.014801076680672268,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014157854587542087,
        "hf_subset": "bmh_Latn-eng_Latn",
        "languages": [
          "bmh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014157854587542087,
        "precision": 0.011659144298442647,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.14960629921259844,
        "f1": 0.110498687664042,
        "hf_subset": "eng_Latn-bmk_Latn",
        "languages": [
          "eng-Latn",
          "bmk-Latn"
        ],
        "main_score": 0.110498687664042,
        "precision": 0.09904727818113643,
        "recall": 0.14960629921259844
      },
      {
        "accuracy": 0.09448818897637795,
        "f1": 0.05530558680164979,
        "hf_subset": "bmk_Latn-eng_Latn",
        "languages": [
          "bmk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05530558680164979,
        "precision": 0.0471936200282657,
        "recall": 0.09448818897637795
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013671875,
        "hf_subset": "eng_Latn-bmr_Latn",
        "languages": [
          "eng-Latn",
          "bmr-Latn"
        ],
        "main_score": 0.013671875,
        "precision": 0.012073863636363636,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008101851851851851,
        "hf_subset": "bmr_Latn-eng_Latn",
        "languages": [
          "bmr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008101851851851851,
        "precision": 0.006790865384615385,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012864419549266246,
        "hf_subset": "eng_Latn-bmu_Latn",
        "languages": [
          "eng-Latn",
          "bmu-Latn"
        ],
        "main_score": 0.012864419549266246,
        "precision": 0.008980440132783882,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0035745504495504495,
        "hf_subset": "bmu_Latn-eng_Latn",
        "languages": [
          "bmu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0035745504495504495,
        "precision": 0.002046620457393484,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.029947916666666664,
        "hf_subset": "eng_Latn-bnp_Latn",
        "languages": [
          "eng-Latn",
          "bnp-Latn"
        ],
        "main_score": 0.029947916666666664,
        "precision": 0.02734375,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020043402777777778,
        "hf_subset": "bnp_Latn-eng_Latn",
        "languages": [
          "bnp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020043402777777778,
        "precision": 0.01837590504951981,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007059151785714286,
        "hf_subset": "eng_Latn-boa_Latn",
        "languages": [
          "eng-Latn",
          "boa-Latn"
        ],
        "main_score": 0.007059151785714286,
        "precision": 0.0058812587535014,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002943840579710145,
        "hf_subset": "boa_Latn-eng_Latn",
        "languages": [
          "boa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002943840579710145,
        "precision": 0.002130681818181818,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02048611111111111,
        "hf_subset": "eng_Latn-boj_Latn",
        "languages": [
          "eng-Latn",
          "boj-Latn"
        ],
        "main_score": 0.02048611111111111,
        "precision": 0.01758946336610487,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009264292914746543,
        "hf_subset": "boj_Latn-eng_Latn",
        "languages": [
          "boj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009264292914746543,
        "precision": 0.0086156337535014,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.025204613095238096,
        "hf_subset": "eng_Latn-bon_Latn",
        "languages": [
          "eng-Latn",
          "bon-Latn"
        ],
        "main_score": 0.025204613095238096,
        "precision": 0.0234375,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.010416666666666666,
        "hf_subset": "bon_Latn-eng_Latn",
        "languages": [
          "bon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.009765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005299176356589147,
        "hf_subset": "eng_Latn-box_Latn",
        "languages": [
          "eng-Latn",
          "box-Latn"
        ],
        "main_score": 0.005299176356589147,
        "precision": 0.003952205882352941,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.975446428571428e-05,
        "hf_subset": "box_Latn-eng_Latn",
        "languages": [
          "box-Latn",
          "eng-Latn"
        ],
        "main_score": 6.975446428571428e-05,
        "precision": 3.519144144144144e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011132812499999999,
        "hf_subset": "eng_Latn-bpr_Latn",
        "languages": [
          "eng-Latn",
          "bpr-Latn"
        ],
        "main_score": 0.011132812499999999,
        "precision": 0.008609250992063493,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 4.9135220125786166e-05,
        "hf_subset": "bpr_Latn-eng_Latn",
        "languages": [
          "bpr-Latn",
          "eng-Latn"
        ],
        "main_score": 4.9135220125786166e-05,
        "precision": 2.4723101265822784e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006975446428571428,
        "hf_subset": "eng_Latn-bps_Latn",
        "languages": [
          "eng-Latn",
          "bps-Latn"
        ],
        "main_score": 0.006975446428571428,
        "precision": 0.004557291666666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0047720181891377535,
        "hf_subset": "bps_Latn-eng_Latn",
        "languages": [
          "bps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0047720181891377535,
        "precision": 0.0031842425152972024,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009700520833333334,
        "hf_subset": "eng_Latn-bqc_Latn",
        "languages": [
          "eng-Latn",
          "bqc-Latn"
        ],
        "main_score": 0.009700520833333334,
        "precision": 0.006742931547619047,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006119791666666667,
        "hf_subset": "bqc_Latn-eng_Latn",
        "languages": [
          "bqc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006119791666666667,
        "precision": 0.005237926136363636,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008277529761904762,
        "hf_subset": "eng_Latn-bqp_Latn",
        "languages": [
          "eng-Latn",
          "bqp-Latn"
        ],
        "main_score": 0.008277529761904762,
        "precision": 0.006865530303030303,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00078125,
        "hf_subset": "bqp_Latn-eng_Latn",
        "languages": [
          "bqp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00078125,
        "precision": 0.00043402777777777775,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.078125,
        "f1": 0.043739144506486805,
        "hf_subset": "eng_Latn-bre_Latn",
        "languages": [
          "eng-Latn",
          "bre-Latn"
        ],
        "main_score": 0.043739144506486805,
        "precision": 0.03692356705565998,
        "recall": 0.078125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04973958333333333,
        "hf_subset": "bre_Latn-eng_Latn",
        "languages": [
          "bre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04973958333333333,
        "precision": 0.043294270833333336,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015665584415584417,
        "hf_subset": "eng_Latn-bsj_Latn",
        "languages": [
          "eng-Latn",
          "bsj-Latn"
        ],
        "main_score": 0.015665584415584417,
        "precision": 0.012760416666666666,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020145089285714284,
        "hf_subset": "bsj_Latn-eng_Latn",
        "languages": [
          "bsj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020145089285714284,
        "precision": 0.017317708333333334,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005527935606060606,
        "hf_subset": "eng_Latn-bsn_Latn",
        "languages": [
          "eng-Latn",
          "bsn-Latn"
        ],
        "main_score": 0.005527935606060606,
        "precision": 0.0034505208333333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0030033390167661265,
        "hf_subset": "bsn_Latn-eng_Latn",
        "languages": [
          "bsn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0030033390167661265,
        "precision": 0.0017664292279411765,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04011401435574229,
        "hf_subset": "eng_Latn-bsp_Latn",
        "languages": [
          "eng-Latn",
          "bsp-Latn"
        ],
        "main_score": 0.04011401435574229,
        "precision": 0.03546837167070218,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013940366602067183,
        "hf_subset": "bsp_Latn-eng_Latn",
        "languages": [
          "bsp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013940366602067183,
        "precision": 0.011928013392857142,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011067708333333334,
        "hf_subset": "eng_Latn-bss_Latn",
        "languages": [
          "eng-Latn",
          "bss-Latn"
        ],
        "main_score": 0.011067708333333334,
        "precision": 0.009832643995098039,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004861111111111111,
        "hf_subset": "bss_Latn-eng_Latn",
        "languages": [
          "bss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004861111111111111,
        "precision": 0.004438421699438202,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006584821428571428,
        "hf_subset": "eng_Latn-buk_Latn",
        "languages": [
          "eng-Latn",
          "buk-Latn"
        ],
        "main_score": 0.006584821428571428,
        "precision": 0.005896935096153846,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004169734904270987,
        "hf_subset": "buk_Latn-eng_Latn",
        "languages": [
          "buk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004169734904270987,
        "precision": 0.004041379343188052,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006975446428571428,
        "hf_subset": "eng_Latn-bus_Latn",
        "languages": [
          "eng-Latn",
          "bus-Latn"
        ],
        "main_score": 0.006975446428571428,
        "precision": 0.005859375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "bus_Latn-eng_Latn",
        "languages": [
          "bus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01270127442002442,
        "hf_subset": "eng_Latn-bvd_Latn",
        "languages": [
          "eng-Latn",
          "bvd-Latn"
        ],
        "main_score": 0.01270127442002442,
        "precision": 0.011061197916666666,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006076388888888888,
        "hf_subset": "bvd_Latn-eng_Latn",
        "languages": [
          "bvd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006076388888888888,
        "precision": 0.00439453125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02391378837719298,
        "hf_subset": "eng_Latn-bvr_Latn",
        "languages": [
          "eng-Latn",
          "bvr-Latn"
        ],
        "main_score": 0.02391378837719298,
        "precision": 0.019676285369220153,
        "recall": 0.046875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.020577457889602378,
        "hf_subset": "bvr_Latn-eng_Latn",
        "languages": [
          "bvr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020577457889602378,
        "precision": 0.01738268242174492,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03548177083333333,
        "hf_subset": "eng_Latn-bxh_Latn",
        "languages": [
          "eng-Latn",
          "bxh-Latn"
        ],
        "main_score": 0.03548177083333333,
        "precision": 0.03311011904761904,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020838897792022793,
        "hf_subset": "bxh_Latn-eng_Latn",
        "languages": [
          "bxh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020838897792022793,
        "precision": 0.017997311741567254,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002529761904761905,
        "hf_subset": "eng_Latn-byr_Latn",
        "languages": [
          "eng-Latn",
          "byr-Latn"
        ],
        "main_score": 0.002529761904761905,
        "precision": 0.0014450571895424837,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003607253086419753,
        "hf_subset": "byr_Latn-eng_Latn",
        "languages": [
          "byr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003607253086419753,
        "precision": 0.0001870228390269151,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006184895833333333,
        "hf_subset": "eng_Latn-byx_Latn",
        "languages": [
          "eng-Latn",
          "byx-Latn"
        ],
        "main_score": 0.006184895833333333,
        "precision": 0.004168357683982684,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011864267065030146,
        "hf_subset": "byx_Latn-eng_Latn",
        "languages": [
          "byx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011864267065030146,
        "precision": 0.010566907051282052,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.023976934523809525,
        "hf_subset": "eng_Latn-bzd_Latn",
        "languages": [
          "eng-Latn",
          "bzd-Latn"
        ],
        "main_score": 0.023976934523809525,
        "precision": 0.022214988425925928,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011253720238095238,
        "hf_subset": "bzd_Latn-eng_Latn",
        "languages": [
          "bzd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011253720238095238,
        "precision": 0.009209857723577235,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018943339646464646,
        "hf_subset": "eng_Latn-bzh_Latn",
        "languages": [
          "eng-Latn",
          "bzh-Latn"
        ],
        "main_score": 0.018943339646464646,
        "precision": 0.016560872395833332,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.014322916666666666,
        "hf_subset": "bzh_Latn-eng_Latn",
        "languages": [
          "bzh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014322916666666666,
        "precision": 0.013671875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.0535073975503663,
        "hf_subset": "eng_Latn-bzj_Latn",
        "languages": [
          "eng-Latn",
          "bzj-Latn"
        ],
        "main_score": 0.0535073975503663,
        "precision": 0.0451973157051282,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.02530313972179781,
        "hf_subset": "bzj_Latn-eng_Latn",
        "languages": [
          "bzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02530313972179781,
        "precision": 0.018142565071532998,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02585107185990338,
        "hf_subset": "eng_Latn-caa_Latn",
        "languages": [
          "eng-Latn",
          "caa-Latn"
        ],
        "main_score": 0.02585107185990338,
        "precision": 0.02477236751708259,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015586612249066292,
        "hf_subset": "caa_Latn-eng_Latn",
        "languages": [
          "caa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015586612249066292,
        "precision": 0.013162878787878788,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.025868055555555554,
        "hf_subset": "eng_Latn-cab_Latn",
        "languages": [
          "eng-Latn",
          "cab-Latn"
        ],
        "main_score": 0.025868055555555554,
        "precision": 0.021730680418719214,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01210269764957265,
        "hf_subset": "cab_Latn-eng_Latn",
        "languages": [
          "cab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01210269764957265,
        "precision": 0.010416666666666666,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009254181026864615,
        "hf_subset": "eng_Latn-cac_Latn",
        "languages": [
          "eng-Latn",
          "cac-Latn"
        ],
        "main_score": 0.009254181026864615,
        "precision": 0.0063516019570707075,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006111391129032258,
        "hf_subset": "cac_Latn-eng_Latn",
        "languages": [
          "cac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006111391129032258,
        "precision": 0.005338541666666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06276041666666667,
        "hf_subset": "eng_Latn-caf_Latn",
        "languages": [
          "eng-Latn",
          "caf-Latn"
        ],
        "main_score": 0.06276041666666667,
        "precision": 0.05572606646825397,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.052421743642286675,
        "hf_subset": "caf_Latn-eng_Latn",
        "languages": [
          "caf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.052421743642286675,
        "precision": 0.04824218749999999,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.01872177750410509,
        "hf_subset": "eng_Latn-cak_Latn",
        "languages": [
          "eng-Latn",
          "cak-Latn"
        ],
        "main_score": 0.01872177750410509,
        "precision": 0.01376798115079365,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007864372041920217,
        "hf_subset": "cak_Latn-eng_Latn",
        "languages": [
          "cak-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007864372041920217,
        "precision": 0.006568545386904762,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01397845643939394,
        "hf_subset": "eng_Latn-cao_Latn",
        "languages": [
          "eng-Latn",
          "cao-Latn"
        ],
        "main_score": 0.01397845643939394,
        "precision": 0.01185360863095238,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003998161764705882,
        "hf_subset": "cao_Latn-eng_Latn",
        "languages": [
          "cao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003998161764705882,
        "precision": 0.003952752976190476,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02667983058608058,
        "hf_subset": "eng_Latn-cap_Latn",
        "languages": [
          "eng-Latn",
          "cap-Latn"
        ],
        "main_score": 0.02667983058608058,
        "precision": 0.023357077205882353,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013287450396825396,
        "hf_subset": "cap_Latn-eng_Latn",
        "languages": [
          "cap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013287450396825396,
        "precision": 0.011552241901898913,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.029549064217032968,
        "hf_subset": "eng_Latn-car_Latn",
        "languages": [
          "eng-Latn",
          "car-Latn"
        ],
        "main_score": 0.029549064217032968,
        "precision": 0.02493489583333333,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025687398538961036,
        "hf_subset": "car_Latn-eng_Latn",
        "languages": [
          "car-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025687398538961036,
        "precision": 0.02293801661605938,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008764022435897436,
        "hf_subset": "eng_Latn-cav_Latn",
        "languages": [
          "eng-Latn",
          "cav-Latn"
        ],
        "main_score": 0.008764022435897436,
        "precision": 0.005829613095238094,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00010016025641025641,
        "hf_subset": "cav_Latn-eng_Latn",
        "languages": [
          "cav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00010016025641025641,
        "precision": 5.0730519480519484e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019339767156862746,
        "hf_subset": "eng_Latn-cax_Latn",
        "languages": [
          "eng-Latn",
          "cax-Latn"
        ],
        "main_score": 0.019339767156862746,
        "precision": 0.0168752959280303,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010546875,
        "hf_subset": "cax_Latn-eng_Latn",
        "languages": [
          "cax-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010546875,
        "precision": 0.00841703869047619,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01535097947761194,
        "hf_subset": "eng_Latn-cbc_Latn",
        "languages": [
          "eng-Latn",
          "cbc-Latn"
        ],
        "main_score": 0.01535097947761194,
        "precision": 0.012754498106060604,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004030257936507936,
        "hf_subset": "cbc_Latn-eng_Latn",
        "languages": [
          "cbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004030257936507936,
        "precision": 0.0039692540322580645,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005245535714285715,
        "hf_subset": "eng_Latn-cbi_Latn",
        "languages": [
          "eng-Latn",
          "cbi-Latn"
        ],
        "main_score": 0.005245535714285715,
        "precision": 0.003230168269230769,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007403633252818035,
        "hf_subset": "cbi_Latn-eng_Latn",
        "languages": [
          "cbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007403633252818035,
        "precision": 0.005024117018602312,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.11547750209859584,
        "hf_subset": "eng_Latn-cbk_Latn",
        "languages": [
          "eng-Latn",
          "cbk-Latn"
        ],
        "main_score": 0.11547750209859584,
        "precision": 0.10539713541666666,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.15625,
        "f1": 0.11114676339285715,
        "hf_subset": "cbk_Latn-eng_Latn",
        "languages": [
          "cbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11114676339285715,
        "precision": 0.09902939942002442,
        "recall": 0.15625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012639046003016591,
        "hf_subset": "eng_Latn-cbr_Latn",
        "languages": [
          "eng-Latn",
          "cbr-Latn"
        ],
        "main_score": 0.012639046003016591,
        "precision": 0.011089124177631578,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "cbr_Latn-eng_Latn",
        "languages": [
          "cbr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01635044642857143,
        "hf_subset": "eng_Latn-cbs_Latn",
        "languages": [
          "eng-Latn",
          "cbs-Latn"
        ],
        "main_score": 0.01635044642857143,
        "precision": 0.0146484375,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.013437661875161875,
        "hf_subset": "cbs_Latn-eng_Latn",
        "languages": [
          "cbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013437661875161875,
        "precision": 0.011153107864392938,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004048295454545455,
        "hf_subset": "eng_Latn-cbt_Latn",
        "languages": [
          "eng-Latn",
          "cbt-Latn"
        ],
        "main_score": 0.004048295454545455,
        "precision": 0.003978587962962963,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "cbt_Latn-eng_Latn",
        "languages": [
          "cbt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005158253205128205,
        "hf_subset": "eng_Latn-cbu_Latn",
        "languages": [
          "eng-Latn",
          "cbu-Latn"
        ],
        "main_score": 0.005158253205128205,
        "precision": 0.004586884469696969,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0044773391812865495,
        "hf_subset": "cbu_Latn-eng_Latn",
        "languages": [
          "cbu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0044773391812865495,
        "precision": 0.00420578387605042,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01640625,
        "hf_subset": "eng_Latn-cbv_Latn",
        "languages": [
          "eng-Latn",
          "cbv-Latn"
        ],
        "main_score": 0.01640625,
        "precision": 0.014927455357142856,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00287889701536643,
        "hf_subset": "cbv_Latn-eng_Latn",
        "languages": [
          "cbv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00287889701536643,
        "precision": 0.0020930610838946723,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01077724358974359,
        "hf_subset": "eng_Latn-cco_Latn",
        "languages": [
          "eng-Latn",
          "cco-Latn"
        ],
        "main_score": 0.01077724358974359,
        "precision": 0.009621043019480519,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012218844506048387,
        "hf_subset": "cco_Latn-eng_Latn",
        "languages": [
          "cco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012218844506048387,
        "precision": 0.011974999186833203,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03653273809523809,
        "hf_subset": "eng_Latn-ceb_Latn",
        "languages": [
          "eng-Latn",
          "ceb-Latn"
        ],
        "main_score": 0.03653273809523809,
        "precision": 0.030628551136363636,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021504040805511396,
        "hf_subset": "ceb_Latn-eng_Latn",
        "languages": [
          "ceb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021504040805511396,
        "precision": 0.01936306423611111,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03410487001818271,
        "hf_subset": "eng_Latn-cek_Latn",
        "languages": [
          "eng-Latn",
          "cek-Latn"
        ],
        "main_score": 0.03410487001818271,
        "precision": 0.030897352430555552,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.044919786096256686,
        "hf_subset": "cek_Latn-eng_Latn",
        "languages": [
          "cek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.044919786096256686,
        "precision": 0.042905970982142855,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.030884792291042292,
        "hf_subset": "eng_Latn-ces_Latn",
        "languages": [
          "eng-Latn",
          "ces-Latn"
        ],
        "main_score": 0.030884792291042292,
        "precision": 0.024927842511107315,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021086774553571427,
        "hf_subset": "ces_Latn-eng_Latn",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021086774553571427,
        "precision": 0.01788171046720575,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02918864989177489,
        "hf_subset": "eng_Latn-cgc_Latn",
        "languages": [
          "eng-Latn",
          "cgc-Latn"
        ],
        "main_score": 0.02918864989177489,
        "precision": 0.02458767361111111,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02558001893939394,
        "hf_subset": "cgc_Latn-eng_Latn",
        "languages": [
          "cgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02558001893939394,
        "precision": 0.02185440207156309,
        "recall": 0.046875
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.0755797371031746,
        "hf_subset": "eng_Latn-cha_Latn",
        "languages": [
          "eng-Latn",
          "cha-Latn"
        ],
        "main_score": 0.0755797371031746,
        "precision": 0.06737274038989392,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07763981894841271,
        "hf_subset": "cha_Latn-eng_Latn",
        "languages": [
          "cha-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07763981894841271,
        "precision": 0.07029022752192982,
        "recall": 0.109375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003515625,
        "hf_subset": "eng_Latn-chd_Latn",
        "languages": [
          "eng-Latn",
          "chd-Latn"
        ],
        "main_score": 0.003515625,
        "precision": 0.002278645833333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01306547619047619,
        "hf_subset": "chd_Latn-eng_Latn",
        "languages": [
          "chd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01306547619047619,
        "precision": 0.009308147687053937,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01741267230576441,
        "hf_subset": "eng_Latn-chf_Latn",
        "languages": [
          "eng-Latn",
          "chf-Latn"
        ],
        "main_score": 0.01741267230576441,
        "precision": 0.014674628831417624,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012937127976190475,
        "hf_subset": "chf_Latn-eng_Latn",
        "languages": [
          "chf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012937127976190475,
        "precision": 0.0099772472394755,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014304315476190476,
        "hf_subset": "eng_Latn-chk_Latn",
        "languages": [
          "eng-Latn",
          "chk-Latn"
        ],
        "main_score": 0.014304315476190476,
        "precision": 0.010221354166666667,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.015625,
        "hf_subset": "chk_Latn-eng_Latn",
        "languages": [
          "chk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015625,
        "precision": 0.015625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019162219183721477,
        "hf_subset": "eng_Latn-chq_Latn",
        "languages": [
          "eng-Latn",
          "chq-Latn"
        ],
        "main_score": 0.019162219183721477,
        "precision": 0.016963252314814815,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007462183395872419,
        "hf_subset": "chq_Latn-eng_Latn",
        "languages": [
          "chq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007462183395872419,
        "precision": 0.006000434027777777,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.0365478515625,
        "hf_subset": "eng_Latn-chz_Latn",
        "languages": [
          "eng-Latn",
          "chz-Latn"
        ],
        "main_score": 0.0365478515625,
        "precision": 0.03333023313492064,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019032118055555554,
        "hf_subset": "chz_Latn-eng_Latn",
        "languages": [
          "chz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019032118055555554,
        "precision": 0.017647879464285712,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020833333333333333,
        "hf_subset": "eng_Latn-cjo_Latn",
        "languages": [
          "eng-Latn",
          "cjo-Latn"
        ],
        "main_score": 0.0020833333333333333,
        "precision": 0.001255580357142857,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003504942719881744,
        "hf_subset": "cjo_Latn-eng_Latn",
        "languages": [
          "cjo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003504942719881744,
        "precision": 0.00244140625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007676373106060606,
        "hf_subset": "eng_Latn-cjv_Latn",
        "languages": [
          "eng-Latn",
          "cjv-Latn"
        ],
        "main_score": 0.007676373106060606,
        "precision": 0.006070188492063491,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 9.765625e-05,
        "hf_subset": "cjv_Latn-eng_Latn",
        "languages": [
          "cjv-Latn",
          "eng-Latn"
        ],
        "main_score": 9.765625e-05,
        "precision": 4.944620253164557e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013888888888888887,
        "hf_subset": "eng_Latn-ckb_Arab",
        "languages": [
          "eng-Latn",
          "ckb-Arab"
        ],
        "main_score": 0.0013888888888888887,
        "precision": 0.0007672991071428571,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00533234126984127,
        "hf_subset": "ckb_Arab-eng_Latn",
        "languages": [
          "ckb-Arab",
          "eng-Latn"
        ],
        "main_score": 0.00533234126984127,
        "precision": 0.004750504032258064,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010604563827220076,
        "hf_subset": "eng_Latn-cle_Latn",
        "languages": [
          "eng-Latn",
          "cle-Latn"
        ],
        "main_score": 0.010604563827220076,
        "precision": 0.009390500992063492,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003442861519607843,
        "hf_subset": "cle_Latn-eng_Latn",
        "languages": [
          "cle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003442861519607843,
        "precision": 0.0024160879629629628,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02981770833333333,
        "hf_subset": "eng_Latn-clu_Latn",
        "languages": [
          "eng-Latn",
          "clu-Latn"
        ],
        "main_score": 0.02981770833333333,
        "precision": 0.027473958333333333,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022101314484126985,
        "hf_subset": "clu_Latn-eng_Latn",
        "languages": [
          "clu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022101314484126985,
        "precision": 0.019601004464285712,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022473620129870128,
        "hf_subset": "eng_Latn-cme_Latn",
        "languages": [
          "eng-Latn",
          "cme-Latn"
        ],
        "main_score": 0.022473620129870128,
        "precision": 0.021223958333333334,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004142992424242424,
        "hf_subset": "cme_Latn-eng_Latn",
        "languages": [
          "cme-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004142992424242424,
        "precision": 0.0040283203125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.06720439533967495,
        "hf_subset": "eng_Latn-cmn_Hans",
        "languages": [
          "eng-Latn",
          "cmn-Hans"
        ],
        "main_score": 0.06720439533967495,
        "precision": 0.05678271742724868,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.036884856713303875,
        "hf_subset": "cmn_Hans-eng_Latn",
        "languages": [
          "cmn-Hans",
          "eng-Latn"
        ],
        "main_score": 0.036884856713303875,
        "precision": 0.033119890956805016,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-cni_Latn",
        "languages": [
          "eng-Latn",
          "cni-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.0026041666666666665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003670775838744589,
        "hf_subset": "cni_Latn-eng_Latn",
        "languages": [
          "cni-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003670775838744589,
        "precision": 0.002514443277310924,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0075440179522840815,
        "hf_subset": "eng_Latn-cnl_Latn",
        "languages": [
          "eng-Latn",
          "cnl-Latn"
        ],
        "main_score": 0.0075440179522840815,
        "precision": 0.006028852513227513,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011067708333333332,
        "hf_subset": "cnl_Latn-eng_Latn",
        "languages": [
          "cnl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011067708333333332,
        "precision": 0.009114583333333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006293402777777778,
        "hf_subset": "eng_Latn-cnt_Latn",
        "languages": [
          "eng-Latn",
          "cnt-Latn"
        ],
        "main_score": 0.006293402777777778,
        "precision": 0.005438112745098039,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00571606394129979,
        "hf_subset": "cnt_Latn-eng_Latn",
        "languages": [
          "cnt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00571606394129979,
        "precision": 0.0038773037624140563,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01134815705128205,
        "hf_subset": "eng_Latn-cof_Latn",
        "languages": [
          "eng-Latn",
          "cof-Latn"
        ],
        "main_score": 0.01134815705128205,
        "precision": 0.01027624591503268,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0063623366013071895,
        "hf_subset": "cof_Latn-eng_Latn",
        "languages": [
          "cof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0063623366013071895,
        "precision": 0.005356732536764706,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015811011904761904,
        "hf_subset": "eng_Latn-con_Latn",
        "languages": [
          "eng-Latn",
          "con-Latn"
        ],
        "main_score": 0.015811011904761904,
        "precision": 0.014418191056910569,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009276772660818713,
        "hf_subset": "con_Latn-eng_Latn",
        "languages": [
          "con-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009276772660818713,
        "precision": 0.007212779185435435,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003255208333333333,
        "hf_subset": "eng_Latn-cop_Copt",
        "languages": [
          "eng-Latn",
          "cop-Copt"
        ],
        "main_score": 0.003255208333333333,
        "precision": 0.0020833333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.0398832684824903e-05,
        "hf_subset": "cop_Copt-eng_Latn",
        "languages": [
          "cop-Copt",
          "eng-Latn"
        ],
        "main_score": 3.0398832684824903e-05,
        "precision": 1.52587890625e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012428977272727272,
        "hf_subset": "eng_Latn-cot_Latn",
        "languages": [
          "eng-Latn",
          "cot-Latn"
        ],
        "main_score": 0.012428977272727272,
        "precision": 0.01015625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00013241525423728814,
        "hf_subset": "cot_Latn-eng_Latn",
        "languages": [
          "cot-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00013241525423728814,
        "precision": 6.734913793103448e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012182017543859648,
        "hf_subset": "eng_Latn-cpa_Latn",
        "languages": [
          "eng-Latn",
          "cpa-Latn"
        ],
        "main_score": 0.012182017543859648,
        "precision": 0.01079010533184191,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.019791666666666666,
        "hf_subset": "cpa_Latn-eng_Latn",
        "languages": [
          "cpa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019791666666666666,
        "precision": 0.0185546875,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.0201171875,
        "hf_subset": "eng_Latn-cpb_Latn",
        "languages": [
          "eng-Latn",
          "cpb-Latn"
        ],
        "main_score": 0.0201171875,
        "precision": 0.016508556547619048,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01643335412193171,
        "hf_subset": "cpb_Latn-eng_Latn",
        "languages": [
          "cpb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01643335412193171,
        "precision": 0.014820498511904763,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.025065104166666664,
        "hf_subset": "eng_Latn-cpc_Latn",
        "languages": [
          "eng-Latn",
          "cpc-Latn"
        ],
        "main_score": 0.025065104166666664,
        "precision": 0.02331140892621871,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01732954785034132,
        "hf_subset": "cpc_Latn-eng_Latn",
        "languages": [
          "cpc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01732954785034132,
        "precision": 0.016520617479946525,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.027018229166666664,
        "hf_subset": "eng_Latn-cpu_Latn",
        "languages": [
          "eng-Latn",
          "cpu-Latn"
        ],
        "main_score": 0.027018229166666664,
        "precision": 0.025948660714285712,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010231218434343436,
        "hf_subset": "cpu_Latn-eng_Latn",
        "languages": [
          "cpu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010231218434343436,
        "precision": 0.009119516450648056,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0070474366128663,
        "hf_subset": "eng_Latn-cpy_Latn",
        "languages": [
          "eng-Latn",
          "cpy-Latn"
        ],
        "main_score": 0.0070474366128663,
        "precision": 0.004944816468253968,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008369140624999999,
        "hf_subset": "cpy_Latn-eng_Latn",
        "languages": [
          "cpy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008369140624999999,
        "precision": 0.006929393481182796,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021354166666666667,
        "hf_subset": "eng_Latn-crn_Latn",
        "languages": [
          "eng-Latn",
          "crn-Latn"
        ],
        "main_score": 0.021354166666666667,
        "precision": 0.018229166666666664,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006696830035971223,
        "hf_subset": "crn_Latn-eng_Latn",
        "languages": [
          "crn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006696830035971223,
        "precision": 0.005484655365769496,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06785714285714285,
        "hf_subset": "eng_Latn-crx_Latn",
        "languages": [
          "eng-Latn",
          "crx-Latn"
        ],
        "main_score": 0.06785714285714285,
        "precision": 0.06260916456228957,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04378889339826839,
        "hf_subset": "crx_Latn-eng_Latn",
        "languages": [
          "crx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04378889339826839,
        "precision": 0.03872767857142857,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.031380208333333326,
        "hf_subset": "eng_Latn-cso_Latn",
        "languages": [
          "eng-Latn",
          "cso-Latn"
        ],
        "main_score": 0.031380208333333326,
        "precision": 0.029079861111111112,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007274154213366543,
        "hf_subset": "cso_Latn-eng_Latn",
        "languages": [
          "cso-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007274154213366543,
        "precision": 0.006276939655172414,
        "recall": 0.015625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06416170634920634,
        "hf_subset": "eng_Latn-csy_Latn",
        "languages": [
          "eng-Latn",
          "csy-Latn"
        ],
        "main_score": 0.06416170634920634,
        "precision": 0.058774302041160596,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07485795454545455,
        "hf_subset": "csy_Latn-eng_Latn",
        "languages": [
          "csy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07485795454545455,
        "precision": 0.06978355845543345,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.037760416666666664,
        "hf_subset": "eng_Latn-cta_Latn",
        "languages": [
          "eng-Latn",
          "cta-Latn"
        ],
        "main_score": 0.037760416666666664,
        "precision": 0.033410164337474124,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016543311403508773,
        "hf_subset": "cta_Latn-eng_Latn",
        "languages": [
          "cta-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016543311403508773,
        "precision": 0.016128782242063492,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011700148809523808,
        "hf_subset": "eng_Latn-cth_Latn",
        "languages": [
          "eng-Latn",
          "cth-Latn"
        ],
        "main_score": 0.011700148809523808,
        "precision": 0.009339488636363637,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018880208333333332,
        "hf_subset": "cth_Latn-eng_Latn",
        "languages": [
          "cth-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018880208333333332,
        "precision": 0.017933238636363636,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019165761743886744,
        "hf_subset": "eng_Latn-ctp_Latn",
        "languages": [
          "eng-Latn",
          "ctp-Latn"
        ],
        "main_score": 0.019165761743886744,
        "precision": 0.016710069444444444,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01228073408018868,
        "hf_subset": "ctp_Latn-eng_Latn",
        "languages": [
          "ctp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01228073408018868,
        "precision": 0.012016369047619047,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006128472222222221,
        "hf_subset": "eng_Latn-ctu_Latn",
        "languages": [
          "eng-Latn",
          "ctu-Latn"
        ],
        "main_score": 0.006128472222222221,
        "precision": 0.003946122408293461,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013608812179086195,
        "hf_subset": "ctu_Latn-eng_Latn",
        "languages": [
          "ctu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013608812179086195,
        "precision": 0.010491868157883782,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017838541666666666,
        "hf_subset": "eng_Latn-cub_Latn",
        "languages": [
          "eng-Latn",
          "cub-Latn"
        ],
        "main_score": 0.017838541666666666,
        "precision": 0.015950520833333332,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00030517578125,
        "hf_subset": "cub_Latn-eng_Latn",
        "languages": [
          "cub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00030517578125,
        "precision": 0.00015676593853187706,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009817363410596027,
        "hf_subset": "eng_Latn-cuc_Latn",
        "languages": [
          "eng-Latn",
          "cuc-Latn"
        ],
        "main_score": 0.009817363410596027,
        "precision": 0.009140625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00400390625,
        "hf_subset": "cuc_Latn-eng_Latn",
        "languages": [
          "cuc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00400390625,
        "precision": 0.003955696202531646,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004185267857142857,
        "hf_subset": "eng_Latn-cui_Latn",
        "languages": [
          "eng-Latn",
          "cui-Latn"
        ],
        "main_score": 0.004185267857142857,
        "precision": 0.004050925925925926,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003364591985703139,
        "hf_subset": "cui_Latn-eng_Latn",
        "languages": [
          "cui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003364591985703139,
        "precision": 0.0023510652579662996,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01284016148325359,
        "hf_subset": "eng_Latn-cuk_Latn",
        "languages": [
          "eng-Latn",
          "cuk-Latn"
        ],
        "main_score": 0.01284016148325359,
        "precision": 0.01232638888888889,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008311612688553682,
        "hf_subset": "cuk_Latn-eng_Latn",
        "languages": [
          "cuk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008311612688553682,
        "precision": 0.006769353693181818,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017730034722222225,
        "hf_subset": "eng_Latn-cut_Latn",
        "languages": [
          "eng-Latn",
          "cut-Latn"
        ],
        "main_score": 0.017730034722222225,
        "precision": 0.015235925099206349,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01358309659090909,
        "hf_subset": "cut_Latn-eng_Latn",
        "languages": [
          "cut-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01358309659090909,
        "precision": 0.011747814360119048,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03274502509337068,
        "hf_subset": "eng_Latn-cux_Latn",
        "languages": [
          "eng-Latn",
          "cux-Latn"
        ],
        "main_score": 0.03274502509337068,
        "precision": 0.0306552984775641,
        "recall": 0.046875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02269376570515435,
        "hf_subset": "cux_Latn-eng_Latn",
        "languages": [
          "cux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02269376570515435,
        "precision": 0.01914925163906142,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007421875,
        "hf_subset": "eng_Latn-cwe_Latn",
        "languages": [
          "eng-Latn",
          "cwe-Latn"
        ],
        "main_score": 0.007421875,
        "precision": 0.006184895833333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0024228050595238096,
        "hf_subset": "cwe_Latn-eng_Latn",
        "languages": [
          "cwe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0024228050595238096,
        "precision": 0.0014322916666666668,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021827903368794328,
        "hf_subset": "eng_Latn-cya_Latn",
        "languages": [
          "eng-Latn",
          "cya-Latn"
        ],
        "main_score": 0.021827903368794328,
        "precision": 0.019898773521505375,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007421875,
        "hf_subset": "cya_Latn-eng_Latn",
        "languages": [
          "cya-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007421875,
        "precision": 0.006184895833333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0022786458333333335,
        "hf_subset": "eng_Latn-daa_Latn",
        "languages": [
          "eng-Latn",
          "daa-Latn"
        ],
        "main_score": 0.0022786458333333335,
        "precision": 0.0014719202898550725,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004149496336996337,
        "hf_subset": "daa_Latn-eng_Latn",
        "languages": [
          "daa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004149496336996337,
        "precision": 0.0040299063902669505,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02209463713369963,
        "hf_subset": "eng_Latn-dad_Latn",
        "languages": [
          "eng-Latn",
          "dad-Latn"
        ],
        "main_score": 0.02209463713369963,
        "precision": 0.01872452445652174,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01933896866565452,
        "hf_subset": "dad_Latn-eng_Latn",
        "languages": [
          "dad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01933896866565452,
        "precision": 0.016567460317460318,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009422232434640524,
        "hf_subset": "eng_Latn-dah_Latn",
        "languages": [
          "eng-Latn",
          "dah-Latn"
        ],
        "main_score": 0.009422232434640524,
        "precision": 0.008703454748376624,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0001905764483810077,
        "hf_subset": "dah_Latn-eng_Latn",
        "languages": [
          "dah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001905764483810077,
        "precision": 9.649367559523809e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.125,
        "f1": 0.087355189503627,
        "hf_subset": "eng_Latn-dan_Latn",
        "languages": [
          "eng-Latn",
          "dan-Latn"
        ],
        "main_score": 0.087355189503627,
        "precision": 0.0794859871031746,
        "recall": 0.125
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.10627696249114968,
        "hf_subset": "dan_Latn-eng_Latn",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ],
        "main_score": 0.10627696249114968,
        "precision": 0.10065895974099098,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006510416666666666,
        "hf_subset": "eng_Latn-ded_Latn",
        "languages": [
          "eng-Latn",
          "ded-Latn"
        ],
        "main_score": 0.006510416666666666,
        "precision": 0.005859375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0065926535087719295,
        "hf_subset": "ded_Latn-eng_Latn",
        "languages": [
          "ded-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0065926535087719295,
        "precision": 0.00590093085106383,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.11876925158175157,
        "hf_subset": "eng_Latn-deu_Latn",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.11876925158175157,
        "precision": 0.10222498384633459,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.171875,
        "f1": 0.1327681433150183,
        "hf_subset": "deu_Latn-eng_Latn",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1327681433150183,
        "precision": 0.12175651850414078,
        "recall": 0.171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016409632034632034,
        "hf_subset": "eng_Latn-dgc_Latn",
        "languages": [
          "eng-Latn",
          "dgc-Latn"
        ],
        "main_score": 0.016409632034632034,
        "precision": 0.013736979166666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0025548986486486486,
        "hf_subset": "dgc_Latn-eng_Latn",
        "languages": [
          "dgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0025548986486486486,
        "precision": 0.0015190972222222222,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.04929470486111111,
        "hf_subset": "eng_Latn-dgr_Latn",
        "languages": [
          "eng-Latn",
          "dgr-Latn"
        ],
        "main_score": 0.04929470486111111,
        "precision": 0.04427739845938375,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02411954365079365,
        "hf_subset": "dgr_Latn-eng_Latn",
        "languages": [
          "dgr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02411954365079365,
        "precision": 0.020149739583333333,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010196834415584416,
        "hf_subset": "eng_Latn-dgz_Latn",
        "languages": [
          "eng-Latn",
          "dgz-Latn"
        ],
        "main_score": 0.010196834415584416,
        "precision": 0.008398437500000001,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "dgz_Latn-eng_Latn",
        "languages": [
          "dgz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0024537852112676054,
        "hf_subset": "eng_Latn-dhg_Latn",
        "languages": [
          "eng-Latn",
          "dhg-Latn"
        ],
        "main_score": 0.0024537852112676054,
        "precision": 0.0015634790100250626,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0009324853172401036,
        "hf_subset": "dhg_Latn-eng_Latn",
        "languages": [
          "dhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0009324853172401036,
        "precision": 0.0004890977738294315,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.030241549744897955,
        "hf_subset": "eng_Latn-dif_Latn",
        "languages": [
          "eng-Latn",
          "dif-Latn"
        ],
        "main_score": 0.030241549744897955,
        "precision": 0.023970702166175747,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.027235243055555552,
        "hf_subset": "dif_Latn-eng_Latn",
        "languages": [
          "dif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.027235243055555552,
        "precision": 0.023832775297619048,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012471621260683761,
        "hf_subset": "eng_Latn-dik_Latn",
        "languages": [
          "eng-Latn",
          "dik-Latn"
        ],
        "main_score": 0.012471621260683761,
        "precision": 0.00950985863095238,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005859375,
        "hf_subset": "dik_Latn-eng_Latn",
        "languages": [
          "dik-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005208333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.09473684210526316,
        "f1": 0.05526543631806789,
        "hf_subset": "eng_Latn-dji_Latn",
        "languages": [
          "eng-Latn",
          "dji-Latn"
        ],
        "main_score": 0.05526543631806789,
        "precision": 0.04717177559282822,
        "recall": 0.09473684210526316
      },
      {
        "accuracy": 0.031578947368421054,
        "f1": 0.010267190965920549,
        "hf_subset": "dji_Latn-eng_Latn",
        "languages": [
          "dji-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010267190965920549,
        "precision": 0.008326180143805604,
        "recall": 0.031578947368421054
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.017457477418414916,
        "hf_subset": "eng_Latn-djk_Latn",
        "languages": [
          "eng-Latn",
          "djk-Latn"
        ],
        "main_score": 0.017457477418414916,
        "precision": 0.01535939999764728,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006778273809523809,
        "hf_subset": "djk_Latn-eng_Latn",
        "languages": [
          "djk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006778273809523809,
        "precision": 0.005699778676292651,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01069931906328965,
        "hf_subset": "eng_Latn-djr_Latn",
        "languages": [
          "eng-Latn",
          "djr-Latn"
        ],
        "main_score": 0.01069931906328965,
        "precision": 0.008121744791666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013538217439293598,
        "hf_subset": "djr_Latn-eng_Latn",
        "languages": [
          "djr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013538217439293598,
        "precision": 0.0008072916666666667,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011610243055555558,
        "hf_subset": "eng_Latn-dob_Latn",
        "languages": [
          "eng-Latn",
          "dob-Latn"
        ],
        "main_score": 0.011610243055555558,
        "precision": 0.00999518060064935,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0024317849445812806,
        "hf_subset": "dob_Latn-eng_Latn",
        "languages": [
          "dob-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0024317849445812806,
        "precision": 0.0013764880952380951,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004241071428571429,
        "hf_subset": "eng_Latn-dop_Latn",
        "languages": [
          "eng-Latn",
          "dop-Latn"
        ],
        "main_score": 0.004241071428571429,
        "precision": 0.0026041666666666665,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00016736216833405828,
        "hf_subset": "dop_Latn-eng_Latn",
        "languages": [
          "dop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00016736216833405828,
        "precision": 8.463541666666667e-05,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01831225356990622,
        "hf_subset": "eng_Latn-dov_Latn",
        "languages": [
          "eng-Latn",
          "dov-Latn"
        ],
        "main_score": 0.01831225356990622,
        "precision": 0.014977128990800864,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006119791666666666,
        "hf_subset": "dov_Latn-eng_Latn",
        "languages": [
          "dov-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006119791666666666,
        "precision": 0.004231770833333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.004791764567669173,
        "hf_subset": "eng_Latn-dwr_Latn",
        "languages": [
          "eng-Latn",
          "dwr-Latn"
        ],
        "main_score": 0.004791764567669173,
        "precision": 0.002812236304962598,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002526661706349206,
        "hf_subset": "dwr_Latn-eng_Latn",
        "languages": [
          "dwr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002526661706349206,
        "precision": 0.001438856792717087,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004631696428571429,
        "hf_subset": "eng_Latn-dww_Latn",
        "languages": [
          "eng-Latn",
          "dww-Latn"
        ],
        "main_score": 0.004631696428571429,
        "precision": 0.002743675595238095,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009715544871794872,
        "hf_subset": "dww_Latn-eng_Latn",
        "languages": [
          "dww-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009715544871794872,
        "precision": 0.007842092803030304,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.06766917293233082,
        "f1": 0.04274078052273541,
        "hf_subset": "eng_Latn-dwy_Latn",
        "languages": [
          "eng-Latn",
          "dwy-Latn"
        ],
        "main_score": 0.04274078052273541,
        "precision": 0.03707919553384279,
        "recall": 0.06766917293233082
      },
      {
        "accuracy": 0.08270676691729323,
        "f1": 0.049317738791422996,
        "hf_subset": "dwy_Latn-eng_Latn",
        "languages": [
          "dwy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.049317738791422996,
        "precision": 0.042972154104938896,
        "recall": 0.08270676691729323
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014792798913043479,
        "hf_subset": "eng_Latn-ebk_Latn",
        "languages": [
          "eng-Latn",
          "ebk-Latn"
        ],
        "main_score": 0.014792798913043479,
        "precision": 0.011679292929292928,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012783554732868758,
        "hf_subset": "ebk_Latn-eng_Latn",
        "languages": [
          "ebk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012783554732868758,
        "precision": 0.011280254289215686,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015569196428571429,
        "hf_subset": "eng_Latn-eko_Latn",
        "languages": [
          "eng-Latn",
          "eko-Latn"
        ],
        "main_score": 0.015569196428571429,
        "precision": 0.01410590277777778,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004801432291666666,
        "hf_subset": "eko_Latn-eng_Latn",
        "languages": [
          "eko-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004801432291666666,
        "precision": 0.0032154967008797657,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024058493589743588,
        "hf_subset": "eng_Latn-emi_Latn",
        "languages": [
          "eng-Latn",
          "emi-Latn"
        ],
        "main_score": 0.024058493589743588,
        "precision": 0.01906114718614719,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014249490914786967,
        "hf_subset": "emi_Latn-eng_Latn",
        "languages": [
          "emi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014249490914786967,
        "precision": 0.013321720157657656,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016381615990990993,
        "hf_subset": "eng_Latn-emp_Latn",
        "languages": [
          "eng-Latn",
          "emp-Latn"
        ],
        "main_score": 0.016381615990990993,
        "precision": 0.015027468607305935,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "emp_Latn-eng_Latn",
        "languages": [
          "emp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0009682158119658119,
        "hf_subset": "eng_Latn-enq_Latn",
        "languages": [
          "eng-Latn",
          "enq-Latn"
        ],
        "main_score": 0.0009682158119658119,
        "precision": 0.0005390117694805195,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006831173780487805,
        "hf_subset": "enq_Latn-eng_Latn",
        "languages": [
          "enq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006831173780487805,
        "precision": 0.0057400173611111115,
        "recall": 0.015625
      },
      {
        "accuracy": 0.140625,
        "f1": 0.09027191253753754,
        "hf_subset": "eng_Latn-epo_Latn",
        "languages": [
          "eng-Latn",
          "epo-Latn"
        ],
        "main_score": 0.09027191253753754,
        "precision": 0.07854366770382396,
        "recall": 0.140625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.07093874007936507,
        "hf_subset": "epo_Latn-eng_Latn",
        "languages": [
          "epo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07093874007936507,
        "precision": 0.0625857611036839,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.015953515709039877,
        "hf_subset": "eng_Latn-eri_Latn",
        "languages": [
          "eng-Latn",
          "eri-Latn"
        ],
        "main_score": 0.015953515709039877,
        "precision": 0.012311129322704461,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011518673780487805,
        "hf_subset": "eri_Latn-eng_Latn",
        "languages": [
          "eri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011518673780487805,
        "precision": 0.010188802083333334,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01720063025210084,
        "hf_subset": "eng_Latn-ese_Latn",
        "languages": [
          "eng-Latn",
          "ese-Latn"
        ],
        "main_score": 0.01720063025210084,
        "precision": 0.016520182291666668,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00010702054794520547,
        "hf_subset": "ese_Latn-eng_Latn",
        "languages": [
          "ese-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00010702054794520547,
        "precision": 5.425347222222222e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.09375,
        "f1": 0.07832031249999999,
        "hf_subset": "eng_Latn-esk_Latn",
        "languages": [
          "eng-Latn",
          "esk-Latn"
        ],
        "main_score": 0.07832031249999999,
        "precision": 0.07360491071428571,
        "recall": 0.09375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.04726098914878549,
        "hf_subset": "esk_Latn-eng_Latn",
        "languages": [
          "esk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04726098914878549,
        "precision": 0.04262136742268746,
        "recall": 0.078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013832764607279693,
        "hf_subset": "eng_Latn-etr_Latn",
        "languages": [
          "eng-Latn",
          "etr-Latn"
        ],
        "main_score": 0.013832764607279693,
        "precision": 0.012904575892857144,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002381577322134387,
        "hf_subset": "etr_Latn-eng_Latn",
        "languages": [
          "etr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002381577322134387,
        "precision": 0.001338527672040603,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.010958887444745831,
        "hf_subset": "eng_Latn-ewe_Latn",
        "languages": [
          "eng-Latn",
          "ewe-Latn"
        ],
        "main_score": 0.010958887444745831,
        "precision": 0.008092359539969833,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01165679196584606,
        "hf_subset": "ewe_Latn-eng_Latn",
        "languages": [
          "ewe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01165679196584606,
        "precision": 0.009156085046046722,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0043877180232558145,
        "hf_subset": "eng_Latn-faa_Latn",
        "languages": [
          "eng-Latn",
          "faa-Latn"
        ],
        "main_score": 0.0043877180232558145,
        "precision": 0.002758629493464052,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0007332785087719298,
        "hf_subset": "faa_Latn-eng_Latn",
        "languages": [
          "faa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007332785087719298,
        "precision": 0.00039666948742746617,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006178977272727273,
        "hf_subset": "eng_Latn-fai_Latn",
        "languages": [
          "eng-Latn",
          "fai-Latn"
        ],
        "main_score": 0.006178977272727273,
        "precision": 0.0052734375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004009046052631579,
        "hf_subset": "fai_Latn-eng_Latn",
        "languages": [
          "fai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004009046052631579,
        "precision": 0.003958333333333334,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.025755306234335838,
        "hf_subset": "eng_Latn-far_Latn",
        "languages": [
          "eng-Latn",
          "far-Latn"
        ],
        "main_score": 0.025755306234335838,
        "precision": 0.021963496572871576,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0162109375,
        "hf_subset": "far_Latn-eng_Latn",
        "languages": [
          "far-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0162109375,
        "precision": 0.014555431547619048,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025294411945812806,
        "hf_subset": "eng_Latn-ffm_Latn",
        "languages": [
          "eng-Latn",
          "ffm-Latn"
        ],
        "main_score": 0.025294411945812806,
        "precision": 0.021529796511627907,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010022321428571429,
        "hf_subset": "ffm_Latn-eng_Latn",
        "languages": [
          "ffm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010022321428571429,
        "precision": 0.00788845486111111,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "eng_Latn-for_Latn",
        "languages": [
          "eng-Latn",
          "for-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003379544408651634,
        "hf_subset": "for_Latn-eng_Latn",
        "languages": [
          "for-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003379544408651634,
        "precision": 0.00017277644230769232,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.41015625,
        "f1": 0.3284582713293651,
        "hf_subset": "eng_Latn-fra_Latn",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ],
        "main_score": 0.3284582713293651,
        "precision": 0.30355606849747474,
        "recall": 0.41015625
      },
      {
        "accuracy": 0.453125,
        "f1": 0.38241133100967656,
        "hf_subset": "fra_Latn-eng_Latn",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.38241133100967656,
        "precision": 0.3573974609375,
        "recall": 0.453125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015506628787878786,
        "hf_subset": "eng_Latn-fue_Latn",
        "languages": [
          "eng-Latn",
          "fue-Latn"
        ],
        "main_score": 0.015506628787878786,
        "precision": 0.01173387521043771,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01125670701461479,
        "hf_subset": "fue_Latn-eng_Latn",
        "languages": [
          "fue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01125670701461479,
        "precision": 0.009743923611111111,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-fuf_Latn",
        "languages": [
          "eng-Latn",
          "fuf-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0035556068691844555,
        "hf_subset": "fuf_Latn-eng_Latn",
        "languages": [
          "fuf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0035556068691844555,
        "precision": 0.0022042410714285714,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011330128205128204,
        "hf_subset": "eng_Latn-fuh_Latn",
        "languages": [
          "eng-Latn",
          "fuh-Latn"
        ],
        "main_score": 0.011330128205128204,
        "precision": 0.010253906249999998,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0054121394067940115,
        "hf_subset": "fuh_Latn-eng_Latn",
        "languages": [
          "fuh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0054121394067940115,
        "precision": 0.004702088559085841,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014083059210526315,
        "hf_subset": "eng_Latn-gah_Latn",
        "languages": [
          "eng-Latn",
          "gah-Latn"
        ],
        "main_score": 0.014083059210526315,
        "precision": 0.013237847222222222,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001223169191919192,
        "hf_subset": "gah_Latn-eng_Latn",
        "languages": [
          "gah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001223169191919192,
        "precision": 0.0006742931547619048,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013439360119047618,
        "hf_subset": "eng_Latn-gai_Latn",
        "languages": [
          "eng-Latn",
          "gai-Latn"
        ],
        "main_score": 0.013439360119047618,
        "precision": 0.010323660714285716,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.000813298181114551,
        "hf_subset": "gai_Latn-eng_Latn",
        "languages": [
          "gai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000813298181114551,
        "precision": 0.0004255265879848854,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019068224676724137,
        "hf_subset": "eng_Latn-gam_Latn",
        "languages": [
          "eng-Latn",
          "gam-Latn"
        ],
        "main_score": 0.019068224676724137,
        "precision": 0.015773663360608925,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008370535714285714,
        "hf_subset": "gam_Latn-eng_Latn",
        "languages": [
          "gam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008370535714285714,
        "precision": 0.008112980769230768,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010691981778996865,
        "hf_subset": "eng_Latn-gaw_Latn",
        "languages": [
          "eng-Latn",
          "gaw-Latn"
        ],
        "main_score": 0.010691981778996865,
        "precision": 0.009522444298820446,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008463541666666668,
        "hf_subset": "gaw_Latn-eng_Latn",
        "languages": [
          "gaw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008463541666666668,
        "precision": 0.008167613636363636,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00859375,
        "hf_subset": "eng_Latn-gdn_Latn",
        "languages": [
          "eng-Latn",
          "gdn-Latn"
        ],
        "main_score": 0.00859375,
        "precision": 0.00693687882262997,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0005378006140201263,
        "hf_subset": "gdn_Latn-eng_Latn",
        "languages": [
          "gdn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005378006140201263,
        "precision": 0.0002768132716049383,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010872395833333333,
        "hf_subset": "eng_Latn-gdr_Latn",
        "languages": [
          "eng-Latn",
          "gdr-Latn"
        ],
        "main_score": 0.010872395833333333,
        "precision": 0.009585813492063493,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006274324633699634,
        "hf_subset": "gdr_Latn-eng_Latn",
        "languages": [
          "gdr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006274324633699634,
        "precision": 0.004231770833333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012306378517316016,
        "hf_subset": "eng_Latn-geb_Latn",
        "languages": [
          "eng-Latn",
          "geb-Latn"
        ],
        "main_score": 0.012306378517316016,
        "precision": 0.010810153388278388,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005484532828282828,
        "hf_subset": "geb_Latn-eng_Latn",
        "languages": [
          "geb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005484532828282828,
        "precision": 0.00478515625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011610243055555556,
        "hf_subset": "eng_Latn-gfk_Latn",
        "languages": [
          "eng-Latn",
          "gfk-Latn"
        ],
        "main_score": 0.011610243055555556,
        "precision": 0.009955015326109075,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "gfk_Latn-eng_Latn",
        "languages": [
          "gfk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015625,
        "hf_subset": "eng_Latn-ghs_Latn",
        "languages": [
          "eng-Latn",
          "ghs-Latn"
        ],
        "main_score": 0.0015625,
        "precision": 0.0009765625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "ghs_Latn-eng_Latn",
        "languages": [
          "ghs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.010752688172043012,
        "f1": 0.0015360983102918587,
        "hf_subset": "eng_Latn-glk_Arab",
        "languages": [
          "eng-Latn",
          "glk-Arab"
        ],
        "main_score": 0.0015360983102918587,
        "precision": 0.0008271298593879239,
        "recall": 0.010752688172043012
      },
      {
        "accuracy": 0.021505376344086023,
        "f1": 0.0033344573077067176,
        "hf_subset": "glk_Arab-eng_Latn",
        "languages": [
          "glk-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0033344573077067176,
        "precision": 0.0019248639320323907,
        "recall": 0.021505376344086023
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.010416666666666666,
        "hf_subset": "eng_Latn-gmv_Latn",
        "languages": [
          "eng-Latn",
          "gmv-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.009765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003339336841385241,
        "hf_subset": "gmv_Latn-eng_Latn",
        "languages": [
          "gmv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003339336841385241,
        "precision": 0.002333039314516129,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012370923913043477,
        "hf_subset": "eng_Latn-gng_Latn",
        "languages": [
          "eng-Latn",
          "gng-Latn"
        ],
        "main_score": 0.012370923913043477,
        "precision": 0.010105942234848484,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005946180555555555,
        "hf_subset": "gng_Latn-eng_Latn",
        "languages": [
          "gng-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005946180555555555,
        "precision": 0.005252223782771535,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0021785641339869283,
        "hf_subset": "eng_Latn-gnn_Latn",
        "languages": [
          "eng-Latn",
          "gnn-Latn"
        ],
        "main_score": 0.0021785641339869283,
        "precision": 0.0012174753385690885,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00010146103896103897,
        "hf_subset": "gnn_Latn-eng_Latn",
        "languages": [
          "gnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00010146103896103897,
        "precision": 5.139802631578947e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004541015625,
        "hf_subset": "eng_Latn-gnw_Latn",
        "languages": [
          "eng-Latn",
          "gnw-Latn"
        ],
        "main_score": 0.004541015625,
        "precision": 0.0027187529475570646,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004557291666666666,
        "hf_subset": "gnw_Latn-eng_Latn",
        "languages": [
          "gnw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004557291666666666,
        "precision": 0.0028645833333333336,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01013764880952381,
        "hf_subset": "eng_Latn-gof_Latn",
        "languages": [
          "eng-Latn",
          "gof-Latn"
        ],
        "main_score": 0.01013764880952381,
        "precision": 0.009309895833333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004427469421793922,
        "hf_subset": "gof_Latn-eng_Latn",
        "languages": [
          "gof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004427469421793922,
        "precision": 0.00417906746031746,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005739446271929824,
        "hf_subset": "eng_Latn-grc_Grek",
        "languages": [
          "eng-Latn",
          "grc-Grek"
        ],
        "main_score": 0.0005739446271929824,
        "precision": 0.00030012559101654846,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0008524562485318299,
        "hf_subset": "grc_Grek-eng_Latn",
        "languages": [
          "grc-Grek",
          "eng-Latn"
        ],
        "main_score": 0.0008524562485318299,
        "precision": 0.00044485567664565825,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-gub_Latn",
        "languages": [
          "eng-Latn",
          "gub-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00043402777777777775,
        "hf_subset": "gub_Latn-eng_Latn",
        "languages": [
          "gub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00043402777777777775,
        "precision": 0.00022977941176470588,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007918074324324325,
        "hf_subset": "eng_Latn-guh_Latn",
        "languages": [
          "eng-Latn",
          "guh-Latn"
        ],
        "main_score": 0.007918074324324325,
        "precision": 0.007866010273972603,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003472222222222222,
        "hf_subset": "guh_Latn-eng_Latn",
        "languages": [
          "guh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003472222222222222,
        "precision": 0.00244140625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005966395547945206,
        "hf_subset": "eng_Latn-gui_Latn",
        "languages": [
          "eng-Latn",
          "gui-Latn"
        ],
        "main_score": 0.005966395547945206,
        "precision": 0.005262586805555556,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "gui_Latn-eng_Latn",
        "languages": [
          "gui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002409788676236045,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.002409788676236045,
        "precision": 0.0014369419642857144,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0025540865384615385,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.0025540865384615385,
        "precision": 0.0016276041666666665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.51171875,
        "f1": 0.43263888888888885,
        "hf_subset": "eng_Latn-gul_Latn",
        "languages": [
          "eng-Latn",
          "gul-Latn"
        ],
        "main_score": 0.43263888888888885,
        "precision": 0.40176866319444443,
        "recall": 0.51171875
      },
      {
        "accuracy": 0.50390625,
        "f1": 0.4252730992965368,
        "hf_subset": "gul_Latn-eng_Latn",
        "languages": [
          "gul-Latn",
          "eng-Latn"
        ],
        "main_score": 0.4252730992965368,
        "precision": 0.39977678571428565,
        "recall": 0.50390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.027862696256038644,
        "hf_subset": "eng_Latn-gum_Latn",
        "languages": [
          "eng-Latn",
          "gum-Latn"
        ],
        "main_score": 0.027862696256038644,
        "precision": 0.02566333023594053,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011203148251488094,
        "hf_subset": "gum_Latn-eng_Latn",
        "languages": [
          "gum-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011203148251488094,
        "precision": 0.008819820374015748,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015950520833333332,
        "hf_subset": "eng_Latn-gun_Latn",
        "languages": [
          "eng-Latn",
          "gun-Latn"
        ],
        "main_score": 0.015950520833333332,
        "precision": 0.013578869047619048,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011774918300653595,
        "hf_subset": "gun_Latn-eng_Latn",
        "languages": [
          "gun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011774918300653595,
        "precision": 0.010176964962121213,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01764464934940681,
        "hf_subset": "eng_Latn-guo_Latn",
        "languages": [
          "eng-Latn",
          "guo-Latn"
        ],
        "main_score": 0.01764464934940681,
        "precision": 0.01600970643939394,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014533420138888888,
        "hf_subset": "guo_Latn-eng_Latn",
        "languages": [
          "guo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014533420138888888,
        "precision": 0.012547167304421767,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.06197916666666667,
        "hf_subset": "eng_Latn-gup_Latn",
        "languages": [
          "eng-Latn",
          "gup-Latn"
        ],
        "main_score": 0.06197916666666667,
        "precision": 0.0595703125,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.042956912878787876,
        "hf_subset": "gup_Latn-eng_Latn",
        "languages": [
          "gup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.042956912878787876,
        "precision": 0.03767649451243201,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0180203111946533,
        "hf_subset": "eng_Latn-gux_Latn",
        "languages": [
          "eng-Latn",
          "gux-Latn"
        ],
        "main_score": 0.0180203111946533,
        "precision": 0.014507378472222221,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009068080357142856,
        "hf_subset": "gux_Latn-eng_Latn",
        "languages": [
          "gux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009068080357142856,
        "precision": 0.008515211640211639,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004756433823529411,
        "hf_subset": "eng_Latn-gvc_Latn",
        "languages": [
          "eng-Latn",
          "gvc-Latn"
        ],
        "main_score": 0.004756433823529411,
        "precision": 0.0031841077302631575,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.005700298285623746,
        "hf_subset": "gvc_Latn-eng_Latn",
        "languages": [
          "gvc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005700298285623746,
        "precision": 0.003758971671747967,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00746432387057387,
        "hf_subset": "eng_Latn-gvf_Latn",
        "languages": [
          "eng-Latn",
          "gvf-Latn"
        ],
        "main_score": 0.00746432387057387,
        "precision": 0.006391059027777778,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027030590717299578,
        "hf_subset": "gvf_Latn-eng_Latn",
        "languages": [
          "gvf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027030590717299578,
        "precision": 0.002003205128205128,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05102241543458781,
        "hf_subset": "eng_Latn-gvn_Latn",
        "languages": [
          "eng-Latn",
          "gvn-Latn"
        ],
        "main_score": 0.05102241543458781,
        "precision": 0.044777122118794324,
        "recall": 0.078125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.04854054365773116,
        "hf_subset": "gvn_Latn-eng_Latn",
        "languages": [
          "gvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04854054365773116,
        "precision": 0.04248976934523809,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.015438988095238094,
        "hf_subset": "eng_Latn-gvs_Latn",
        "languages": [
          "eng-Latn",
          "gvs-Latn"
        ],
        "main_score": 0.015438988095238094,
        "precision": 0.014322916666666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0028735632183908046,
        "hf_subset": "gvs_Latn-eng_Latn",
        "languages": [
          "gvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0028735632183908046,
        "precision": 0.0020926339285714285,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07196528050322692,
        "hf_subset": "eng_Latn-gwi_Latn",
        "languages": [
          "eng-Latn",
          "gwi-Latn"
        ],
        "main_score": 0.07196528050322692,
        "precision": 0.06635446259469696,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.06231129227053141,
        "hf_subset": "gwi_Latn-eng_Latn",
        "languages": [
          "gwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06231129227053141,
        "precision": 0.056704684714795006,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012841356981981982,
        "hf_subset": "eng_Latn-gym_Latn",
        "languages": [
          "eng-Latn",
          "gym-Latn"
        ],
        "main_score": 0.012841356981981982,
        "precision": 0.010013640873015872,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00022977941176470588,
        "hf_subset": "gym_Latn-eng_Latn",
        "languages": [
          "gym-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00022977941176470588,
        "precision": 0.00011837121212121212,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008891858552631578,
        "hf_subset": "eng_Latn-gyr_Latn",
        "languages": [
          "eng-Latn",
          "gyr-Latn"
        ],
        "main_score": 0.008891858552631578,
        "precision": 0.008422619047619049,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0109375,
        "hf_subset": "gyr_Latn-eng_Latn",
        "languages": [
          "gyr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0109375,
        "precision": 0.009765625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.034367210630006965,
        "hf_subset": "eng_Latn-hat_Latn",
        "languages": [
          "eng-Latn",
          "hat-Latn"
        ],
        "main_score": 0.034367210630006965,
        "precision": 0.029208519345238094,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03219590755300876,
        "hf_subset": "hat_Latn-eng_Latn",
        "languages": [
          "hat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03219590755300876,
        "precision": 0.02949569578705608,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019220753205128206,
        "hf_subset": "eng_Latn-hau_Latn",
        "languages": [
          "eng-Latn",
          "hau-Latn"
        ],
        "main_score": 0.019220753205128206,
        "precision": 0.016133432539682538,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021098400297619047,
        "hf_subset": "hau_Latn-eng_Latn",
        "languages": [
          "hau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021098400297619047,
        "precision": 0.019034822805095747,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017113095238095236,
        "hf_subset": "eng_Latn-haw_Latn",
        "languages": [
          "eng-Latn",
          "haw-Latn"
        ],
        "main_score": 0.017113095238095236,
        "precision": 0.014548399390243903,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0087890625,
        "hf_subset": "haw_Latn-eng_Latn",
        "languages": [
          "haw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0087890625,
        "precision": 0.007198660714285715,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006009615384615385,
        "hf_subset": "eng_Latn-hbo_Hebr",
        "languages": [
          "eng-Latn",
          "hbo-Hebr"
        ],
        "main_score": 0.0006009615384615385,
        "precision": 0.0003255208333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "hbo_Hebr-eng_Latn",
        "languages": [
          "hbo-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005433505639097744,
        "hf_subset": "eng_Latn-hch_Latn",
        "languages": [
          "eng-Latn",
          "hch-Latn"
        ],
        "main_score": 0.005433505639097744,
        "precision": 0.004774305555555556,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009004934210526316,
        "hf_subset": "hch_Latn-eng_Latn",
        "languages": [
          "hch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009004934210526316,
        "precision": 0.008463541666666668,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005969038734896944,
        "hf_subset": "eng_Latn-heb_Hebr",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ],
        "main_score": 0.0005969038734896944,
        "precision": 0.00032001201923076926,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0004059126180836707,
        "hf_subset": "heb_Hebr-eng_Latn",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ],
        "main_score": 0.0004059126180836707,
        "precision": 0.00020837037695590327,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.029968067956349202,
        "hf_subset": "eng_Latn-heg_Latn",
        "languages": [
          "eng-Latn",
          "heg-Latn"
        ],
        "main_score": 0.029968067956349202,
        "precision": 0.024336328613892365,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0134765625,
        "hf_subset": "heg_Latn-eng_Latn",
        "languages": [
          "heg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0134765625,
        "precision": 0.011691951674737692,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011414930555555555,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.011414930555555555,
        "precision": 0.008900669642857142,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009114583333333332,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.009114583333333332,
        "precision": 0.0078125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003551136363636364,
        "hf_subset": "eng_Latn-hix_Latn",
        "languages": [
          "eng-Latn",
          "hix-Latn"
        ],
        "main_score": 0.0003551136363636364,
        "precision": 0.00018601190476190475,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003999255952380952,
        "hf_subset": "hix_Latn-eng_Latn",
        "languages": [
          "hix-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003999255952380952,
        "precision": 0.003953313253012048,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01330128205128205,
        "hf_subset": "eng_Latn-hla_Latn",
        "languages": [
          "eng-Latn",
          "hla-Latn"
        ],
        "main_score": 0.01330128205128205,
        "precision": 0.010276245915032678,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007128365145783178,
        "hf_subset": "hla_Latn-eng_Latn",
        "languages": [
          "hla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007128365145783178,
        "precision": 0.005773809523809524,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.02851281930053793,
        "hf_subset": "eng_Latn-hlt_Latn",
        "languages": [
          "eng-Latn",
          "hlt-Latn"
        ],
        "main_score": 0.02851281930053793,
        "precision": 0.024956723474646267,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023853339947089946,
        "hf_subset": "hlt_Latn-eng_Latn",
        "languages": [
          "hlt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023853339947089946,
        "precision": 0.02213704971432553,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024029017857142856,
        "hf_subset": "eng_Latn-hmo_Latn",
        "languages": [
          "eng-Latn",
          "hmo-Latn"
        ],
        "main_score": 0.024029017857142856,
        "precision": 0.021270978009259256,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01222939158794422,
        "hf_subset": "hmo_Latn-eng_Latn",
        "languages": [
          "hmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01222939158794422,
        "precision": 0.010462239583333335,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011393229166666666,
        "hf_subset": "eng_Latn-hns_Latn",
        "languages": [
          "eng-Latn",
          "hns-Latn"
        ],
        "main_score": 0.011393229166666666,
        "precision": 0.009933035714285714,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003395774147727273,
        "hf_subset": "hns_Latn-eng_Latn",
        "languages": [
          "hns-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003395774147727273,
        "precision": 0.0023848684210526316,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.05167875744047619,
        "hf_subset": "eng_Latn-hop_Latn",
        "languages": [
          "eng-Latn",
          "hop-Latn"
        ],
        "main_score": 0.05167875744047619,
        "precision": 0.0474609375,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03531374007936508,
        "hf_subset": "hop_Latn-eng_Latn",
        "languages": [
          "hop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03531374007936508,
        "precision": 0.03160511363636363,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011446661998132587,
        "hf_subset": "eng_Latn-hot_Latn",
        "languages": [
          "eng-Latn",
          "hot-Latn"
        ],
        "main_score": 0.011446661998132587,
        "precision": 0.008715194310897435,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003960129310344828,
        "hf_subset": "hot_Latn-eng_Latn",
        "languages": [
          "hot-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003960129310344828,
        "precision": 0.003933376736111111,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.029696800595238094,
        "hf_subset": "eng_Latn-hrv_Latn",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ],
        "main_score": 0.029696800595238094,
        "precision": 0.02562313988095238,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.014710693973102061,
        "hf_subset": "hrv_Latn-eng_Latn",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014710693973102061,
        "precision": 0.011848324201839826,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017892628205128207,
        "hf_subset": "eng_Latn-hto_Latn",
        "languages": [
          "eng-Latn",
          "hto-Latn"
        ],
        "main_score": 0.017892628205128207,
        "precision": 0.015807995495495497,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012824927178318136,
        "hf_subset": "hto_Latn-eng_Latn",
        "languages": [
          "hto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012824927178318136,
        "precision": 0.011305023521505376,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012955729166666666,
        "hf_subset": "eng_Latn-hub_Latn",
        "languages": [
          "eng-Latn",
          "hub-Latn"
        ],
        "main_score": 0.012955729166666666,
        "precision": 0.011300223214285714,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.023908769904863653,
        "hf_subset": "hub_Latn-eng_Latn",
        "languages": [
          "hub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023908769904863653,
        "precision": 0.019865369496855342,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.010416666666666666,
        "hf_subset": "eng_Latn-hui_Latn",
        "languages": [
          "eng-Latn",
          "hui-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.009765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004616477272727273,
        "hf_subset": "hui_Latn-eng_Latn",
        "languages": [
          "hui-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004616477272727273,
        "precision": 0.004296875,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020455109126984127,
        "hf_subset": "eng_Latn-hun_Latn",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ],
        "main_score": 0.020455109126984127,
        "precision": 0.016482923199767713,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.029947916666666664,
        "hf_subset": "hun_Latn-eng_Latn",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029947916666666664,
        "precision": 0.027994791666666664,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010054976851851851,
        "hf_subset": "eng_Latn-hus_Latn",
        "languages": [
          "eng-Latn",
          "hus-Latn"
        ],
        "main_score": 0.010054976851851851,
        "precision": 0.009264823717948718,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0012175324675324675,
        "hf_subset": "hus_Latn-eng_Latn",
        "languages": [
          "hus-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0012175324675324675,
        "precision": 0.0007024396929824562,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016053636128364388,
        "hf_subset": "eng_Latn-huu_Latn",
        "languages": [
          "eng-Latn",
          "huu-Latn"
        ],
        "main_score": 0.016053636128364388,
        "precision": 0.014546741940389293,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010803486877705626,
        "hf_subset": "huu_Latn-eng_Latn",
        "languages": [
          "huu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010803486877705626,
        "precision": 0.008739802939669188,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006427476945569051,
        "hf_subset": "eng_Latn-huv_Latn",
        "languages": [
          "eng-Latn",
          "huv-Latn"
        ],
        "main_score": 0.006427476945569051,
        "precision": 0.005275046933147262,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0052948835784313725,
        "hf_subset": "huv_Latn-eng_Latn",
        "languages": [
          "huv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0052948835784313725,
        "precision": 0.003636500218531468,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.05555555555555555,
        "f1": 0.03467498110355253,
        "hf_subset": "eng_Latn-hvn_Latn",
        "languages": [
          "eng-Latn",
          "hvn-Latn"
        ],
        "main_score": 0.03467498110355253,
        "precision": 0.028911564625850344,
        "recall": 0.05555555555555555
      },
      {
        "accuracy": 0.05555555555555555,
        "f1": 0.028716271197474205,
        "hf_subset": "hvn_Latn-eng_Latn",
        "languages": [
          "hvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.028716271197474205,
        "precision": 0.024498456790123455,
        "recall": 0.05555555555555555
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020833333333333333,
        "hf_subset": "eng_Latn-ian_Latn",
        "languages": [
          "eng-Latn",
          "ian-Latn"
        ],
        "main_score": 0.0020833333333333333,
        "precision": 0.001255580357142857,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006306069460988684,
        "hf_subset": "ian_Latn-eng_Latn",
        "languages": [
          "ian-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006306069460988684,
        "precision": 0.005440143623737374,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015553456959706958,
        "hf_subset": "eng_Latn-ign_Latn",
        "languages": [
          "eng-Latn",
          "ign-Latn"
        ],
        "main_score": 0.015553456959706958,
        "precision": 0.013177083333333334,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007909335609243697,
        "hf_subset": "ign_Latn-eng_Latn",
        "languages": [
          "ign-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007909335609243697,
        "precision": 0.0063185655872926095,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010738721000253549,
        "hf_subset": "eng_Latn-ikk_Latn",
        "languages": [
          "eng-Latn",
          "ikk-Latn"
        ],
        "main_score": 0.010738721000253549,
        "precision": 0.009624240951420891,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0018927315244279528,
        "hf_subset": "ikk_Latn-eng_Latn",
        "languages": [
          "ikk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0018927315244279528,
        "precision": 0.0010224313446969698,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007338371829710144,
        "hf_subset": "eng_Latn-ikw_Latn",
        "languages": [
          "eng-Latn",
          "ikw-Latn"
        ],
        "main_score": 0.007338371829710144,
        "precision": 0.005906723484848485,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.004347718253968254,
        "hf_subset": "ikw_Latn-eng_Latn",
        "languages": [
          "ikw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004347718253968254,
        "precision": 0.002629312195869221,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024254765070921985,
        "hf_subset": "eng_Latn-ilo_Latn",
        "languages": [
          "eng-Latn",
          "ilo-Latn"
        ],
        "main_score": 0.024254765070921985,
        "precision": 0.020622323781291176,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024705730518076455,
        "hf_subset": "ilo_Latn-eng_Latn",
        "languages": [
          "ilo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024705730518076455,
        "precision": 0.021992470561594202,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006510416666666666,
        "hf_subset": "eng_Latn-imo_Latn",
        "languages": [
          "eng-Latn",
          "imo-Latn"
        ],
        "main_score": 0.006510416666666666,
        "precision": 0.005859375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "imo_Latn-eng_Latn",
        "languages": [
          "imo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008279204173486087,
        "hf_subset": "eng_Latn-inb_Latn",
        "languages": [
          "eng-Latn",
          "inb-Latn"
        ],
        "main_score": 0.008279204173486087,
        "precision": 0.00805366847826087,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005511010599415204,
        "hf_subset": "inb_Latn-eng_Latn",
        "languages": [
          "inb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005511010599415204,
        "precision": 0.0047929067460317455,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03641741071428571,
        "hf_subset": "eng_Latn-ind_Latn",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ],
        "main_score": 0.03641741071428571,
        "precision": 0.031202129289215685,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.0364501953125,
        "hf_subset": "ind_Latn-eng_Latn",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0364501953125,
        "precision": 0.034506598077449366,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002959280303030303,
        "hf_subset": "eng_Latn-ino_Latn",
        "languages": [
          "eng-Latn",
          "ino-Latn"
        ],
        "main_score": 0.002959280303030303,
        "precision": 0.002139136904761905,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "ino_Latn-eng_Latn",
        "languages": [
          "ino-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0018730835137085137,
        "hf_subset": "eng_Latn-iou_Latn",
        "languages": [
          "eng-Latn",
          "iou-Latn"
        ],
        "main_score": 0.0018730835137085137,
        "precision": 0.001014704335016835,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002025462962962963,
        "hf_subset": "iou_Latn-eng_Latn",
        "languages": [
          "iou-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002025462962962963,
        "precision": 0.0013385903426791277,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0021205357142857146,
        "hf_subset": "eng_Latn-ipi_Latn",
        "languages": [
          "eng-Latn",
          "ipi-Latn"
        ],
        "main_score": 0.0021205357142857146,
        "precision": 0.0012770432692307692,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 8.223684210526316e-05,
        "hf_subset": "ipi_Latn-eng_Latn",
        "languages": [
          "ipi-Latn",
          "eng-Latn"
        ],
        "main_score": 8.223684210526316e-05,
        "precision": 4.1555851063829786e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009114583333333334,
        "hf_subset": "eng_Latn-isn_Latn",
        "languages": [
          "eng-Latn",
          "isn-Latn"
        ],
        "main_score": 0.009114583333333334,
        "precision": 0.007516571969696969,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030691964285714285,
        "hf_subset": "isn_Latn-eng_Latn",
        "languages": [
          "isn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0030691964285714285,
        "precision": 0.001953125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.19921875,
        "f1": 0.12966979075343993,
        "hf_subset": "eng_Latn-ita_Latn",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ],
        "main_score": 0.12966979075343993,
        "precision": 0.10996953350468974,
        "recall": 0.19921875
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.12249074835526316,
        "hf_subset": "ita_Latn-eng_Latn",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12249074835526316,
        "precision": 0.11196109778370808,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006397267713903743,
        "hf_subset": "eng_Latn-iws_Latn",
        "languages": [
          "eng-Latn",
          "iws-Latn"
        ],
        "main_score": 0.006397267713903743,
        "precision": 0.004544836956521739,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003966812015503876,
        "hf_subset": "iws_Latn-eng_Latn",
        "languages": [
          "iws-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003966812015503876,
        "precision": 0.003936767578125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006449142156862745,
        "hf_subset": "eng_Latn-ixl_Latn",
        "languages": [
          "eng-Latn",
          "ixl-Latn"
        ],
        "main_score": 0.006449142156862745,
        "precision": 0.003962232429029304,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005434099965349964,
        "hf_subset": "ixl_Latn-eng_Latn",
        "languages": [
          "ixl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005434099965349964,
        "precision": 0.004802045430222603,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010416666666666666,
        "hf_subset": "eng_Latn-jac_Latn",
        "languages": [
          "eng-Latn",
          "jac-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.00859375,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004243631916329285,
        "hf_subset": "jac_Latn-eng_Latn",
        "languages": [
          "jac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004243631916329285,
        "precision": 0.004078800516917293,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.030059523809523807,
        "hf_subset": "eng_Latn-jae_Latn",
        "languages": [
          "eng-Latn",
          "jae-Latn"
        ],
        "main_score": 0.030059523809523807,
        "precision": 0.027104434288537548,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008331159630997993,
        "hf_subset": "jae_Latn-eng_Latn",
        "languages": [
          "jae-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008331159630997993,
        "precision": 0.00807918462351602,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03937007874015748,
        "f1": 0.015328083989501312,
        "hf_subset": "eng_Latn-jao_Latn",
        "languages": [
          "eng-Latn",
          "jao-Latn"
        ],
        "main_score": 0.015328083989501312,
        "precision": 0.012417481905670881,
        "recall": 0.03937007874015748
      },
      {
        "accuracy": 0.015748031496062992,
        "f1": 0.0032981726340811173,
        "hf_subset": "jao_Latn-eng_Latn",
        "languages": [
          "jao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0032981726340811173,
        "precision": 0.0020434945631796026,
        "recall": 0.015748031496062992
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018229166666666664,
        "hf_subset": "eng_Latn-jic_Latn",
        "languages": [
          "eng-Latn",
          "jic-Latn"
        ],
        "main_score": 0.018229166666666664,
        "precision": 0.016276041666666664,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012682291666666666,
        "hf_subset": "jic_Latn-eng_Latn",
        "languages": [
          "jic-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012682291666666666,
        "precision": 0.01123046875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.027734375,
        "hf_subset": "eng_Latn-jid_Latn",
        "languages": [
          "eng-Latn",
          "jid-Latn"
        ],
        "main_score": 0.027734375,
        "precision": 0.02300486196633826,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022847493489583332,
        "hf_subset": "jid_Latn-eng_Latn",
        "languages": [
          "jid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022847493489583332,
        "precision": 0.02086409120734908,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00022977941176470588,
        "hf_subset": "eng_Latn-jiv_Latn",
        "languages": [
          "eng-Latn",
          "jiv-Latn"
        ],
        "main_score": 0.00022977941176470588,
        "precision": 0.00011837121212121212,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.000731981981981982,
        "hf_subset": "jiv_Latn-eng_Latn",
        "languages": [
          "jiv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000731981981981982,
        "precision": 0.00038752480158730157,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013541666666666667,
        "hf_subset": "eng_Latn-jni_Latn",
        "languages": [
          "eng-Latn",
          "jni-Latn"
        ],
        "main_score": 0.013541666666666667,
        "precision": 0.01171875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006001420454545455,
        "hf_subset": "jni_Latn-eng_Latn",
        "languages": [
          "jni-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006001420454545455,
        "precision": 0.005280671296296296,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.031149651472431074,
        "hf_subset": "eng_Latn-jpn_Jpan",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ],
        "main_score": 0.031149651472431074,
        "precision": 0.02955109126984127,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.0205054012345679,
        "hf_subset": "jpn_Jpan-eng_Latn",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ],
        "main_score": 0.0205054012345679,
        "precision": 0.016807725694444442,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018779177118171682,
        "hf_subset": "eng_Latn-jvn_Latn",
        "languages": [
          "eng-Latn",
          "jvn-Latn"
        ],
        "main_score": 0.018779177118171682,
        "precision": 0.016453598484848484,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011538163442460317,
        "hf_subset": "jvn_Latn-eng_Latn",
        "languages": [
          "jvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011538163442460317,
        "precision": 0.008125788232265046,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012473958333333333,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.012473958333333333,
        "precision": 0.011120495495495495,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0031257294584500464,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0031257294584500464,
        "precision": 0.0019325875946969696,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0106689453125,
        "hf_subset": "eng_Latn-kaq_Latn",
        "languages": [
          "eng-Latn",
          "kaq-Latn"
        ],
        "main_score": 0.0106689453125,
        "precision": 0.007657490079365079,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027947154471544716,
        "hf_subset": "kaq_Latn-eng_Latn",
        "languages": [
          "kaq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027947154471544716,
        "precision": 0.00205078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010859949448529412,
        "hf_subset": "eng_Latn-kbc_Latn",
        "languages": [
          "eng-Latn",
          "kbc-Latn"
        ],
        "main_score": 0.010859949448529412,
        "precision": 0.009593238967293907,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011299377705627705,
        "hf_subset": "kbc_Latn-eng_Latn",
        "languages": [
          "kbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011299377705627705,
        "precision": 0.010251050804093567,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014694940476190476,
        "hf_subset": "eng_Latn-kbh_Latn",
        "languages": [
          "eng-Latn",
          "kbh-Latn"
        ],
        "main_score": 0.014694940476190476,
        "precision": 0.0138671875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0075488718066843066,
        "hf_subset": "kbh_Latn-eng_Latn",
        "languages": [
          "kbh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0075488718066843066,
        "precision": 0.005207004676870748,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01450441919191919,
        "hf_subset": "eng_Latn-kbm_Latn",
        "languages": [
          "eng-Latn",
          "kbm-Latn"
        ],
        "main_score": 0.01450441919191919,
        "precision": 0.012197730654761905,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.565126050420168e-05,
        "hf_subset": "kbm_Latn-eng_Latn",
        "languages": [
          "kbm-Latn",
          "eng-Latn"
        ],
        "main_score": 6.565126050420168e-05,
        "precision": 3.3103813559322034e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.02309656489343989,
        "hf_subset": "eng_Latn-kbq_Latn",
        "languages": [
          "eng-Latn",
          "kbq-Latn"
        ],
        "main_score": 0.02309656489343989,
        "precision": 0.016866469109195405,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006879340277777778,
        "hf_subset": "kbq_Latn-eng_Latn",
        "languages": [
          "kbq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006879340277777778,
        "precision": 0.00567062762605042,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012586805555555556,
        "hf_subset": "eng_Latn-kdc_Latn",
        "languages": [
          "eng-Latn",
          "kdc-Latn"
        ],
        "main_score": 0.012586805555555556,
        "precision": 0.01103515625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.001002209595959596,
        "hf_subset": "kdc_Latn-eng_Latn",
        "languages": [
          "kdc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001002209595959596,
        "precision": 0.0005262145402836777,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014322916666666666,
        "hf_subset": "eng_Latn-kde_Latn",
        "languages": [
          "eng-Latn",
          "kde-Latn"
        ],
        "main_score": 0.014322916666666666,
        "precision": 0.012204071969696969,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009114583333333332,
        "hf_subset": "kde_Latn-eng_Latn",
        "languages": [
          "kde-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009114583333333332,
        "precision": 0.0078125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003751240079365079,
        "hf_subset": "eng_Latn-kdl_Latn",
        "languages": [
          "eng-Latn",
          "kdl-Latn"
        ],
        "main_score": 0.003751240079365079,
        "precision": 0.0025860821759259257,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0037697847624965477,
        "hf_subset": "kdl_Latn-eng_Latn",
        "languages": [
          "kdl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0037697847624965477,
        "precision": 0.0025800831620728564,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012155257936507936,
        "hf_subset": "eng_Latn-kek_Latn",
        "languages": [
          "eng-Latn",
          "kek-Latn"
        ],
        "main_score": 0.012155257936507936,
        "precision": 0.009119136072261072,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0029166666666666664,
        "hf_subset": "kek_Latn-eng_Latn",
        "languages": [
          "kek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0029166666666666664,
        "precision": 0.0021158854166666665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0026364356655071523,
        "hf_subset": "eng_Latn-ken_Latn",
        "languages": [
          "eng-Latn",
          "ken-Latn"
        ],
        "main_score": 0.0026364356655071523,
        "precision": 0.0014294949841824841,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004072473404255319,
        "hf_subset": "ken_Latn-eng_Latn",
        "languages": [
          "ken-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004072473404255319,
        "precision": 0.00399116847826087,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008760340073529412,
        "hf_subset": "eng_Latn-kew_Latn",
        "languages": [
          "eng-Latn",
          "kew-Latn"
        ],
        "main_score": 0.008760340073529412,
        "precision": 0.007076977926587302,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007491012168141593,
        "hf_subset": "kew_Latn-eng_Latn",
        "languages": [
          "kew-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007491012168141593,
        "precision": 0.00621977306547619,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012710336538461538,
        "hf_subset": "eng_Latn-kgf_Latn",
        "languages": [
          "eng-Latn",
          "kgf-Latn"
        ],
        "main_score": 0.012710336538461538,
        "precision": 0.010850694444444444,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011979166666666666,
        "hf_subset": "kgf_Latn-eng_Latn",
        "languages": [
          "kgf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011979166666666666,
        "precision": 0.0107421875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008880208333333334,
        "hf_subset": "eng_Latn-kgk_Latn",
        "languages": [
          "eng-Latn",
          "kgk-Latn"
        ],
        "main_score": 0.008880208333333334,
        "precision": 0.007045865221088436,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008072916666666666,
        "hf_subset": "kgk_Latn-eng_Latn",
        "languages": [
          "kgk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008072916666666666,
        "precision": 0.0068359375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014847132034632036,
        "hf_subset": "eng_Latn-kgp_Latn",
        "languages": [
          "eng-Latn",
          "kgp-Latn"
        ],
        "main_score": 0.014847132034632036,
        "precision": 0.011458333333333334,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00787353515625,
        "hf_subset": "kgp_Latn-eng_Latn",
        "languages": [
          "kgp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00787353515625,
        "precision": 0.007843257874015748,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0048828125,
        "hf_subset": "eng_Latn-khs_Latn",
        "languages": [
          "eng-Latn",
          "khs-Latn"
        ],
        "main_score": 0.0048828125,
        "precision": 0.004464285714285714,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0028038775613714747,
        "hf_subset": "khs_Latn-eng_Latn",
        "languages": [
          "khs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0028038775613714747,
        "precision": 0.0020543642661982825,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02864583333333333,
        "hf_subset": "eng_Latn-khz_Latn",
        "languages": [
          "eng-Latn",
          "khz-Latn"
        ],
        "main_score": 0.02864583333333333,
        "precision": 0.024869791666666665,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012302714646464647,
        "hf_subset": "khz_Latn-eng_Latn",
        "languages": [
          "khz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012302714646464647,
        "precision": 0.009507921006944444,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02229662698412698,
        "hf_subset": "eng_Latn-kik_Latn",
        "languages": [
          "eng-Latn",
          "kik-Latn"
        ],
        "main_score": 0.02229662698412698,
        "precision": 0.019973028273809524,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018880208333333332,
        "hf_subset": "kik_Latn-eng_Latn",
        "languages": [
          "kik-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018880208333333332,
        "precision": 0.017933238636363636,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.10843373493975904,
        "f1": 0.0597298284045272,
        "hf_subset": "eng_Latn-kiw_Latn",
        "languages": [
          "eng-Latn",
          "kiw-Latn"
        ],
        "main_score": 0.0597298284045272,
        "precision": 0.04849875693249187,
        "recall": 0.10843373493975904
      },
      {
        "accuracy": 0.024096385542168676,
        "f1": 0.0034599938214396045,
        "hf_subset": "kiw_Latn-eng_Latn",
        "languages": [
          "kiw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0034599938214396045,
        "precision": 0.0018646012621916237,
        "recall": 0.024096385542168676
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.023072406045751635,
        "hf_subset": "eng_Latn-kiz_Latn",
        "languages": [
          "eng-Latn",
          "kiz-Latn"
        ],
        "main_score": 0.023072406045751635,
        "precision": 0.017333984375,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01066468253968254,
        "hf_subset": "kiz_Latn-eng_Latn",
        "languages": [
          "kiz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01066468253968254,
        "precision": 0.007391237745098039,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.012487553615196077,
        "hf_subset": "eng_Latn-kje_Latn",
        "languages": [
          "eng-Latn",
          "kje-Latn"
        ],
        "main_score": 0.012487553615196077,
        "precision": 0.008257335287640227,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01804315476190476,
        "hf_subset": "kje_Latn-eng_Latn",
        "languages": [
          "kje-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01804315476190476,
        "precision": 0.015035962301587304,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010107860889110889,
        "hf_subset": "eng_Latn-kjs_Latn",
        "languages": [
          "eng-Latn",
          "kjs-Latn"
        ],
        "main_score": 0.010107860889110889,
        "precision": 0.009058541285103784,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012448705808080808,
        "hf_subset": "kjs_Latn-eng_Latn",
        "languages": [
          "kjs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012448705808080808,
        "precision": 0.011107568027210885,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02011126893939394,
        "hf_subset": "eng_Latn-kkc_Latn",
        "languages": [
          "eng-Latn",
          "kkc-Latn"
        ],
        "main_score": 0.02011126893939394,
        "precision": 0.01759672619047619,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007856267507002801,
        "hf_subset": "kkc_Latn-eng_Latn",
        "languages": [
          "kkc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007856267507002801,
        "precision": 0.006628787878787878,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.032232142857142855,
        "hf_subset": "eng_Latn-kkl_Latn",
        "languages": [
          "eng-Latn",
          "kkl-Latn"
        ],
        "main_score": 0.032232142857142855,
        "precision": 0.028194754464285713,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02621392986542443,
        "hf_subset": "kkl_Latn-eng_Latn",
        "languages": [
          "kkl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02621392986542443,
        "precision": 0.022102342357397504,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03302951388888888,
        "hf_subset": "eng_Latn-klt_Latn",
        "languages": [
          "eng-Latn",
          "klt-Latn"
        ],
        "main_score": 0.03302951388888888,
        "precision": 0.026567150297619045,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022138278388278386,
        "hf_subset": "klt_Latn-eng_Latn",
        "languages": [
          "klt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022138278388278386,
        "precision": 0.0189343341503268,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005805262445887446,
        "hf_subset": "eng_Latn-klv_Latn",
        "languages": [
          "eng-Latn",
          "klv-Latn"
        ],
        "main_score": 0.005805262445887446,
        "precision": 0.003636532738095238,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00759548611111111,
        "hf_subset": "klv_Latn-eng_Latn",
        "languages": [
          "klv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00759548611111111,
        "precision": 0.006444268048128343,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007570684523809523,
        "hf_subset": "eng_Latn-kmg_Latn",
        "languages": [
          "eng-Latn",
          "kmg-Latn"
        ],
        "main_score": 0.007570684523809523,
        "precision": 0.006438078703703704,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "kmg_Latn-eng_Latn",
        "languages": [
          "kmg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008854166666666666,
        "hf_subset": "eng_Latn-kmh_Latn",
        "languages": [
          "eng-Latn",
          "kmh-Latn"
        ],
        "main_score": 0.008854166666666666,
        "precision": 0.007269965277777778,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0015168898336511971,
        "hf_subset": "kmh_Latn-eng_Latn",
        "languages": [
          "kmh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0015168898336511971,
        "precision": 0.0008903952205882354,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.029048295454545455,
        "hf_subset": "eng_Latn-kmk_Latn",
        "languages": [
          "eng-Latn",
          "kmk-Latn"
        ],
        "main_score": 0.029048295454545455,
        "precision": 0.02513744212962963,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.023177083333333334,
        "hf_subset": "kmk_Latn-eng_Latn",
        "languages": [
          "kmk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023177083333333334,
        "precision": 0.022053101053639848,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010180574633699634,
        "hf_subset": "eng_Latn-kmo_Latn",
        "languages": [
          "eng-Latn",
          "kmo-Latn"
        ],
        "main_score": 0.010180574633699634,
        "precision": 0.008138020833333334,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004030257936507936,
        "hf_subset": "kmo_Latn-eng_Latn",
        "languages": [
          "kmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004030257936507936,
        "precision": 0.0027973790322580643,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02427421536796537,
        "hf_subset": "eng_Latn-kms_Latn",
        "languages": [
          "eng-Latn",
          "kms-Latn"
        ],
        "main_score": 0.02427421536796537,
        "precision": 0.020819382440476188,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010053021771771772,
        "hf_subset": "kms_Latn-eng_Latn",
        "languages": [
          "kms-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010053021771771772,
        "precision": 0.009117542613636363,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001113623903508772,
        "hf_subset": "eng_Latn-kmu_Latn",
        "languages": [
          "eng-Latn",
          "kmu-Latn"
        ],
        "main_score": 0.001113623903508772,
        "precision": 0.0006277901785714285,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0022278169988925803,
        "hf_subset": "kmu_Latn-eng_Latn",
        "languages": [
          "kmu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0022278169988925803,
        "precision": 0.0012290139260987716,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03238071207849168,
        "hf_subset": "eng_Latn-kne_Latn",
        "languages": [
          "eng-Latn",
          "kne-Latn"
        ],
        "main_score": 0.03238071207849168,
        "precision": 0.027858382936507935,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01658911611519608,
        "hf_subset": "kne_Latn-eng_Latn",
        "languages": [
          "kne-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01658911611519608,
        "precision": 0.015018586189516129,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013349541083916084,
        "hf_subset": "eng_Latn-knf_Latn",
        "languages": [
          "eng-Latn",
          "knf-Latn"
        ],
        "main_score": 0.013349541083916084,
        "precision": 0.011197916666666667,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009713918893606392,
        "hf_subset": "knf_Latn-eng_Latn",
        "languages": [
          "knf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009713918893606392,
        "precision": 0.00889209142394822,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0008010702959830866,
        "hf_subset": "eng_Latn-knj_Latn",
        "languages": [
          "eng-Latn",
          "knj-Latn"
        ],
        "main_score": 0.0008010702959830866,
        "precision": 0.0004365808823529412,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0005283216140267056,
        "hf_subset": "knj_Latn-eng_Latn",
        "languages": [
          "knj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005283216140267056,
        "precision": 0.0002730429292929293,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006076388888888888,
        "hf_subset": "eng_Latn-knv_Latn",
        "languages": [
          "eng-Latn",
          "knv-Latn"
        ],
        "main_score": 0.006076388888888888,
        "precision": 0.00439453125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015625,
        "hf_subset": "knv_Latn-eng_Latn",
        "languages": [
          "knv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0015625,
        "precision": 0.0009765625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.08421354756178079,
        "hf_subset": "eng_Latn-kos_Latn",
        "languages": [
          "eng-Latn",
          "kos-Latn"
        ],
        "main_score": 0.08421354756178079,
        "precision": 0.07524181547619048,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.06520023652751233,
        "hf_subset": "kos_Latn-eng_Latn",
        "languages": [
          "kos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06520023652751233,
        "precision": 0.05814010642135642,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009579613095238096,
        "hf_subset": "eng_Latn-kpf_Latn",
        "languages": [
          "eng-Latn",
          "kpf-Latn"
        ],
        "main_score": 0.009579613095238096,
        "precision": 0.0078125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004557291666666666,
        "hf_subset": "kpf_Latn-eng_Latn",
        "languages": [
          "kpf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004557291666666666,
        "precision": 0.003255208333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07516121031746031,
        "hf_subset": "eng_Latn-kpg_Latn",
        "languages": [
          "eng-Latn",
          "kpg-Latn"
        ],
        "main_score": 0.07516121031746031,
        "precision": 0.06800130208333333,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05607475242051855,
        "hf_subset": "kpg_Latn-eng_Latn",
        "languages": [
          "kpg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05607475242051855,
        "precision": 0.051529947916666666,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006673177083333333,
        "hf_subset": "eng_Latn-kpj_Latn",
        "languages": [
          "eng-Latn",
          "kpj-Latn"
        ],
        "main_score": 0.006673177083333333,
        "precision": 0.005942486702127659,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00706845238095238,
        "hf_subset": "kpj_Latn-eng_Latn",
        "languages": [
          "kpj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00706845238095238,
        "precision": 0.006159855769230769,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04019344229900632,
        "hf_subset": "eng_Latn-kpr_Latn",
        "languages": [
          "eng-Latn",
          "kpr-Latn"
        ],
        "main_score": 0.04019344229900632,
        "precision": 0.03625241562971342,
        "recall": 0.0625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025551835317460317,
        "hf_subset": "kpr_Latn-eng_Latn",
        "languages": [
          "kpr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025551835317460317,
        "precision": 0.02268105158730159,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.00978284553531264,
        "hf_subset": "eng_Latn-kpw_Latn",
        "languages": [
          "eng-Latn",
          "kpw-Latn"
        ],
        "main_score": 0.00978284553531264,
        "precision": 0.007577553910818713,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00022977941176470588,
        "hf_subset": "kpw_Latn-eng_Latn",
        "languages": [
          "kpw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00022977941176470588,
        "precision": 0.00011837121212121212,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00458829365079365,
        "hf_subset": "eng_Latn-kpx_Latn",
        "languages": [
          "eng-Latn",
          "kpx-Latn"
        ],
        "main_score": 0.00458829365079365,
        "precision": 0.0030924479166666665,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "kpx_Latn-eng_Latn",
        "languages": [
          "kpx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.06349206349206349,
        "f1": 0.03262786596119929,
        "hf_subset": "eng_Latn-kqa_Latn",
        "languages": [
          "eng-Latn",
          "kqa-Latn"
        ],
        "main_score": 0.03262786596119929,
        "precision": 0.02632275132275132,
        "recall": 0.06349206349206349
      },
      {
        "accuracy": 0.015873015873015872,
        "f1": 0.000962000962000962,
        "hf_subset": "kqa_Latn-eng_Latn",
        "languages": [
          "kqa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.000962000962000962,
        "precision": 0.000496031746031746,
        "recall": 0.015873015873015872
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.0631390056022409,
        "hf_subset": "eng_Latn-kqc_Latn",
        "languages": [
          "eng-Latn",
          "kqc-Latn"
        ],
        "main_score": 0.0631390056022409,
        "precision": 0.055437126318330365,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.03936962182971015,
        "hf_subset": "kqc_Latn-eng_Latn",
        "languages": [
          "kqc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03936962182971015,
        "precision": 0.03374509604978355,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04584646358543417,
        "hf_subset": "eng_Latn-kqf_Latn",
        "languages": [
          "eng-Latn",
          "kqf-Latn"
        ],
        "main_score": 0.04584646358543417,
        "precision": 0.04138997395833333,
        "recall": 0.0625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01735213418385504,
        "hf_subset": "kqf_Latn-eng_Latn",
        "languages": [
          "kqf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01735213418385504,
        "precision": 0.015354904484221919,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.05714285714285714,
        "f1": 0.025578231292517007,
        "hf_subset": "eng_Latn-kql_Latn",
        "languages": [
          "eng-Latn",
          "kql-Latn"
        ],
        "main_score": 0.025578231292517007,
        "precision": 0.019266381766381763,
        "recall": 0.05714285714285714
      },
      {
        "accuracy": 0.03571428571428571,
        "f1": 0.012369614512471656,
        "hf_subset": "kql_Latn-eng_Latn",
        "languages": [
          "kql-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012369614512471656,
        "precision": 0.010213369445118171,
        "recall": 0.03571428571428571
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004464285714285714,
        "hf_subset": "eng_Latn-kqw_Latn",
        "languages": [
          "eng-Latn",
          "kqw-Latn"
        ],
        "main_score": 0.004464285714285714,
        "precision": 0.004206730769230769,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00439453125,
        "hf_subset": "kqw_Latn-eng_Latn",
        "languages": [
          "kqw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00439453125,
        "precision": 0.004166666666666667,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.027320498511904764,
        "hf_subset": "eng_Latn-ksd_Latn",
        "languages": [
          "eng-Latn",
          "ksd-Latn"
        ],
        "main_score": 0.027320498511904764,
        "precision": 0.023530891307390812,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016967147435897435,
        "hf_subset": "ksd_Latn-eng_Latn",
        "languages": [
          "ksd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016967147435897435,
        "precision": 0.016349976053639848,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.042598684210526316,
        "hf_subset": "eng_Latn-ksj_Latn",
        "languages": [
          "eng-Latn",
          "ksj-Latn"
        ],
        "main_score": 0.042598684210526316,
        "precision": 0.038256448412698416,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.017127222620623713,
        "hf_subset": "ksj_Latn-eng_Latn",
        "languages": [
          "ksj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017127222620623713,
        "precision": 0.01389860971562538,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0071351066468253975,
        "hf_subset": "eng_Latn-ksr_Latn",
        "languages": [
          "eng-Latn",
          "ksr-Latn"
        ],
        "main_score": 0.0071351066468253975,
        "precision": 0.004653645833333333,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0007413176872469636,
        "hf_subset": "ksr_Latn-eng_Latn",
        "languages": [
          "ksr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007413176872469636,
        "precision": 0.00038909313725490197,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.109375,
        "f1": 0.0715365395684789,
        "hf_subset": "eng_Latn-ktm_Latn",
        "languages": [
          "eng-Latn",
          "ktm-Latn"
        ],
        "main_score": 0.0715365395684789,
        "precision": 0.06184353298611111,
        "recall": 0.109375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03156717996180649,
        "hf_subset": "ktm_Latn-eng_Latn",
        "languages": [
          "ktm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03156717996180649,
        "precision": 0.02706177286255411,
        "recall": 0.0625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007533482142857142,
        "hf_subset": "eng_Latn-kto_Latn",
        "languages": [
          "eng-Latn",
          "kto-Latn"
        ],
        "main_score": 0.007533482142857142,
        "precision": 0.006159855769230769,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012024378926327812,
        "hf_subset": "kto_Latn-eng_Latn",
        "languages": [
          "kto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012024378926327812,
        "precision": 0.011875417780748663,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004506340579710145,
        "hf_subset": "eng_Latn-kud_Latn",
        "languages": [
          "eng-Latn",
          "kud-Latn"
        ],
        "main_score": 0.004506340579710145,
        "precision": 0.002716619318181818,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00023674242424242425,
        "hf_subset": "kud_Latn-eng_Latn",
        "languages": [
          "kud-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00023674242424242425,
        "precision": 0.0001220703125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.016458953373015874,
        "hf_subset": "eng_Latn-kue_Latn",
        "languages": [
          "eng-Latn",
          "kue-Latn"
        ],
        "main_score": 0.016458953373015874,
        "precision": 0.012981094426406926,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0036658653846153846,
        "hf_subset": "kue_Latn-eng_Latn",
        "languages": [
          "kue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0036658653846153846,
        "precision": 0.0021692270658263306,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013020833333333333,
        "hf_subset": "eng_Latn-kup_Latn",
        "languages": [
          "eng-Latn",
          "kup-Latn"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.00078125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016601562500000002,
        "hf_subset": "kup_Latn-eng_Latn",
        "languages": [
          "kup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0016601562500000002,
        "precision": 0.0010260087025316456,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0109375,
        "hf_subset": "eng_Latn-kvg_Latn",
        "languages": [
          "eng-Latn",
          "kvg-Latn"
        ],
        "main_score": 0.0109375,
        "precision": 0.008463541666666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0041598152815343,
        "hf_subset": "kvg_Latn-eng_Latn",
        "languages": [
          "kvg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0041598152815343,
        "precision": 0.004035267403455284,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "eng_Latn-kvn_Latn",
        "languages": [
          "eng-Latn",
          "kvn-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008069521503210527,
        "hf_subset": "kvn_Latn-eng_Latn",
        "languages": [
          "kvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008069521503210527,
        "precision": 0.006408131798756799,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013715277777777778,
        "hf_subset": "eng_Latn-kwd_Latn",
        "languages": [
          "eng-Latn",
          "kwd-Latn"
        ],
        "main_score": 0.013715277777777778,
        "precision": 0.010676038881461675,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0160945197044335,
        "hf_subset": "kwd_Latn-eng_Latn",
        "languages": [
          "kwd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0160945197044335,
        "precision": 0.014391447368421052,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.041141069613821135,
        "hf_subset": "eng_Latn-kwf_Latn",
        "languages": [
          "eng-Latn",
          "kwf-Latn"
        ],
        "main_score": 0.041141069613821135,
        "precision": 0.036788504464285714,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02001488095238095,
        "hf_subset": "kwf_Latn-eng_Latn",
        "languages": [
          "kwf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02001488095238095,
        "precision": 0.018324122639985226,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01935392023657289,
        "hf_subset": "eng_Latn-kwi_Latn",
        "languages": [
          "eng-Latn",
          "kwi-Latn"
        ],
        "main_score": 0.01935392023657289,
        "precision": 0.017906816490800864,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009144176136363636,
        "hf_subset": "kwi_Latn-eng_Latn",
        "languages": [
          "kwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009144176136363636,
        "precision": 0.00855654761904762,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003255208333333333,
        "hf_subset": "eng_Latn-kwj_Latn",
        "languages": [
          "eng-Latn",
          "kwj-Latn"
        ],
        "main_score": 0.003255208333333333,
        "precision": 0.0020833333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00243246336996337,
        "hf_subset": "kwj_Latn-eng_Latn",
        "languages": [
          "kwj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00243246336996337,
        "precision": 0.001549555311890838,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004846643518518518,
        "hf_subset": "eng_Latn-kyc_Latn",
        "languages": [
          "eng-Latn",
          "kyc-Latn"
        ],
        "main_score": 0.004846643518518518,
        "precision": 0.003405448717948718,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0015500992063492063,
        "hf_subset": "kyc_Latn-eng_Latn",
        "languages": [
          "kyc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0015500992063492063,
        "precision": 0.0008808210784313725,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.000990715579710145,
        "hf_subset": "eng_Latn-kyf_Latn",
        "languages": [
          "eng-Latn",
          "kyf-Latn"
        ],
        "main_score": 0.000990715579710145,
        "precision": 0.0005326704545454545,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.677350427350428e-05,
        "hf_subset": "kyf_Latn-eng_Latn",
        "languages": [
          "kyf-Latn",
          "eng-Latn"
        ],
        "main_score": 6.677350427350428e-05,
        "precision": 3.367456896551724e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0061197916666666675,
        "hf_subset": "eng_Latn-kyg_Latn",
        "languages": [
          "eng-Latn",
          "kyg-Latn"
        ],
        "main_score": 0.0061197916666666675,
        "precision": 0.005237926136363636,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 9.889240506329114e-05,
        "hf_subset": "kyg_Latn-eng_Latn",
        "languages": [
          "kyg-Latn",
          "eng-Latn"
        ],
        "main_score": 9.889240506329114e-05,
        "precision": 5.0080128205128203e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012065972222222221,
        "hf_subset": "eng_Latn-kyq_Latn",
        "languages": [
          "eng-Latn",
          "kyq-Latn"
        ],
        "main_score": 0.012065972222222221,
        "precision": 0.010337611607142859,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0026008450255102043,
        "hf_subset": "kyq_Latn-eng_Latn",
        "languages": [
          "kyq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026008450255102043,
        "precision": 0.0016438802083333331,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00915130876068376,
        "hf_subset": "eng_Latn-kyz_Latn",
        "languages": [
          "eng-Latn",
          "kyz-Latn"
        ],
        "main_score": 0.00915130876068376,
        "precision": 0.007082403273809523,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "kyz_Latn-eng_Latn",
        "languages": [
          "kyz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008333333333333333,
        "hf_subset": "eng_Latn-kze_Latn",
        "languages": [
          "eng-Latn",
          "kze-Latn"
        ],
        "main_score": 0.008333333333333333,
        "precision": 0.008091517857142856,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "kze_Latn-eng_Latn",
        "languages": [
          "kze-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004383680555555556,
        "hf_subset": "eng_Latn-lac_Latn",
        "languages": [
          "eng-Latn",
          "lac-Latn"
        ],
        "main_score": 0.004383680555555556,
        "precision": 0.002766927083333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004344512195121952,
        "hf_subset": "lac_Latn-eng_Latn",
        "languages": [
          "lac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004344512195121952,
        "precision": 0.004135806829189538,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.375,
        "f1": 0.2859532828282828,
        "hf_subset": "eng_Latn-lat_Latn",
        "languages": [
          "eng-Latn",
          "lat-Latn"
        ],
        "main_score": 0.2859532828282828,
        "precision": 0.2552053740530303,
        "recall": 0.375
      },
      {
        "accuracy": 0.29296875,
        "f1": 0.23579471393861512,
        "hf_subset": "lat_Latn-eng_Latn",
        "languages": [
          "lat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.23579471393861512,
        "precision": 0.21843903662008282,
        "recall": 0.29296875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.019225387242965367,
        "hf_subset": "eng_Latn-lbb_Latn",
        "languages": [
          "eng-Latn",
          "lbb-Latn"
        ],
        "main_score": 0.019225387242965367,
        "precision": 0.01533868167562724,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010638688568376069,
        "hf_subset": "lbb_Latn-eng_Latn",
        "languages": [
          "lbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010638688568376069,
        "precision": 0.008223765794695071,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.026627604166666666,
        "hf_subset": "eng_Latn-lbk_Latn",
        "languages": [
          "eng-Latn",
          "lbk-Latn"
        ],
        "main_score": 0.026627604166666666,
        "precision": 0.02458389945652174,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019345238095238096,
        "hf_subset": "lbk_Latn-eng_Latn",
        "languages": [
          "lbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019345238095238096,
        "precision": 0.016276041666666668,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012170175906183368,
        "hf_subset": "eng_Latn-lcm_Latn",
        "languages": [
          "eng-Latn",
          "lcm-Latn"
        ],
        "main_score": 0.012170175906183368,
        "precision": 0.01075487012987013,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014464962121212122,
        "hf_subset": "lcm_Latn-eng_Latn",
        "languages": [
          "lcm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014464962121212122,
        "precision": 0.013744212962962963,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004837740384615385,
        "hf_subset": "eng_Latn-leu_Latn",
        "languages": [
          "eng-Latn",
          "leu-Latn"
        ],
        "main_score": 0.004837740384615385,
        "precision": 0.00441687091503268,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005650436046511628,
        "hf_subset": "leu_Latn-eng_Latn",
        "languages": [
          "leu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005650436046511628,
        "precision": 0.004975818452380952,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016817434210526314,
        "hf_subset": "eng_Latn-lex_Latn",
        "languages": [
          "eng-Latn",
          "lex-Latn"
        ],
        "main_score": 0.016817434210526314,
        "precision": 0.013972594246031745,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011682992371705964,
        "hf_subset": "lex_Latn-eng_Latn",
        "languages": [
          "lex-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011682992371705964,
        "precision": 0.010129442401960783,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.046875,
        "f1": 0.0369047619047619,
        "hf_subset": "eng_Latn-lgl_Latn",
        "languages": [
          "eng-Latn",
          "lgl-Latn"
        ],
        "main_score": 0.0369047619047619,
        "precision": 0.0350562118902439,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.018973971240380853,
        "hf_subset": "lgl_Latn-eng_Latn",
        "languages": [
          "lgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018973971240380853,
        "precision": 0.016488609218358395,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020329437669376692,
        "hf_subset": "eng_Latn-lid_Latn",
        "languages": [
          "eng-Latn",
          "lid-Latn"
        ],
        "main_score": 0.020329437669376692,
        "precision": 0.017621527777777778,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007866379310344828,
        "hf_subset": "lid_Latn-eng_Latn",
        "languages": [
          "lid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007866379310344828,
        "precision": 0.007839626736111112,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007151380288957688,
        "hf_subset": "eng_Latn-lif_Deva",
        "languages": [
          "eng-Latn",
          "lif-Deva"
        ],
        "main_score": 0.007151380288957688,
        "precision": 0.006194760101010101,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011160714285714285,
        "hf_subset": "lif_Deva-eng_Latn",
        "languages": [
          "lif-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0011160714285714285,
        "precision": 0.0006510416666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010882675438596492,
        "hf_subset": "eng_Latn-lin_Latn",
        "languages": [
          "eng-Latn",
          "lin-Latn"
        ],
        "main_score": 0.010882675438596492,
        "precision": 0.008834022600186392,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006745793269230769,
        "hf_subset": "lin_Latn-eng_Latn",
        "languages": [
          "lin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006745793269230769,
        "precision": 0.005597098214285714,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019850852272727273,
        "hf_subset": "eng_Latn-lit_Latn",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ],
        "main_score": 0.019850852272727273,
        "precision": 0.0158203125,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0017447916666666666,
        "hf_subset": "lit_Latn-eng_Latn",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0017447916666666666,
        "precision": 0.0009519018308080808,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007626488095238095,
        "hf_subset": "eng_Latn-llg_Latn",
        "languages": [
          "eng-Latn",
          "llg-Latn"
        ],
        "main_score": 0.007626488095238095,
        "precision": 0.006119791666666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0028417968749999997,
        "hf_subset": "llg_Latn-eng_Latn",
        "languages": [
          "llg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0028417968749999997,
        "precision": 0.002073962808807734,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009765625,
        "hf_subset": "eng_Latn-lug_Latn",
        "languages": [
          "eng-Latn",
          "lug-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.007942708333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005478050595238095,
        "hf_subset": "lug_Latn-eng_Latn",
        "languages": [
          "lug-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005478050595238095,
        "precision": 0.0032056051587301586,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016240530303030302,
        "hf_subset": "eng_Latn-luo_Latn",
        "languages": [
          "eng-Latn",
          "luo-Latn"
        ],
        "main_score": 0.016240530303030302,
        "precision": 0.01353236607142857,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0069320436507936505,
        "hf_subset": "luo_Latn-eng_Latn",
        "languages": [
          "luo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0069320436507936505,
        "precision": 0.004601182116104869,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-lww_Latn",
        "languages": [
          "eng-Latn",
          "lww-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "lww_Latn-eng_Latn",
        "languages": [
          "lww-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013654932469064933,
        "hf_subset": "eng_Latn-maa_Latn",
        "languages": [
          "eng-Latn",
          "maa-Latn"
        ],
        "main_score": 0.013654932469064933,
        "precision": 0.010599550189393939,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010475852272727272,
        "hf_subset": "maa_Latn-eng_Latn",
        "languages": [
          "maa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010475852272727272,
        "precision": 0.008298399390243901,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01332586684149184,
        "hf_subset": "eng_Latn-maj_Latn",
        "languages": [
          "eng-Latn",
          "maj-Latn"
        ],
        "main_score": 0.01332586684149184,
        "precision": 0.011579241071428572,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00427827380952381,
        "hf_subset": "maj_Latn-eng_Latn",
        "languages": [
          "maj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00427827380952381,
        "precision": 0.002514022435897436,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02133584731240981,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.02133584731240981,
        "precision": 0.016637720429080724,
        "recall": 0.046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0068182984400656805,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.0068182984400656805,
        "precision": 0.006018221799858558,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.010885074460077825,
        "hf_subset": "eng_Latn-mam_Latn",
        "languages": [
          "eng-Latn",
          "mam-Latn"
        ],
        "main_score": 0.010885074460077825,
        "precision": 0.009452708920739348,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.005793251101595516,
        "hf_subset": "mam_Latn-eng_Latn",
        "languages": [
          "mam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005793251101595516,
        "precision": 0.004204479888597109,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011842757936507936,
        "hf_subset": "eng_Latn-maq_Latn",
        "languages": [
          "eng-Latn",
          "maq-Latn"
        ],
        "main_score": 0.011842757936507936,
        "precision": 0.00906629178113553,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004340600422861452,
        "hf_subset": "maq_Latn-eng_Latn",
        "languages": [
          "maq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004340600422861452,
        "precision": 0.002911706349206349,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004361979166666667,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.004361979166666667,
        "precision": 0.002945188492063492,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020833333333333333,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0020833333333333333,
        "precision": 0.0012152777777777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02185641325592834,
        "hf_subset": "eng_Latn-mau_Latn",
        "languages": [
          "eng-Latn",
          "mau-Latn"
        ],
        "main_score": 0.02185641325592834,
        "precision": 0.019786342412870944,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022852926865034928,
        "hf_subset": "mau_Latn-eng_Latn",
        "languages": [
          "mau-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022852926865034928,
        "precision": 0.021858281282943284,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008072916666666666,
        "hf_subset": "eng_Latn-mav_Latn",
        "languages": [
          "eng-Latn",
          "mav-Latn"
        ],
        "main_score": 0.008072916666666666,
        "precision": 0.0068359375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0011574074074074073,
        "hf_subset": "mav_Latn-eng_Latn",
        "languages": [
          "mav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011574074074074073,
        "precision": 0.0006385216346153846,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03912760416666666,
        "hf_subset": "eng_Latn-maz_Latn",
        "languages": [
          "eng-Latn",
          "maz-Latn"
        ],
        "main_score": 0.03912760416666666,
        "precision": 0.03334883432539683,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017218527086948137,
        "hf_subset": "maz_Latn-eng_Latn",
        "languages": [
          "maz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017218527086948137,
        "precision": 0.014471893768768769,
        "recall": 0.03125
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.06825810185185185,
        "hf_subset": "eng_Latn-mbb_Latn",
        "languages": [
          "eng-Latn",
          "mbb-Latn"
        ],
        "main_score": 0.06825810185185185,
        "precision": 0.06109468131466487,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.09375,
        "f1": 0.06075995692992643,
        "hf_subset": "mbb_Latn-eng_Latn",
        "languages": [
          "mbb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06075995692992643,
        "precision": 0.05118946305374002,
        "recall": 0.09375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007347470238095238,
        "hf_subset": "eng_Latn-mbc_Latn",
        "languages": [
          "eng-Latn",
          "mbc-Latn"
        ],
        "main_score": 0.007347470238095238,
        "precision": 0.005303607723577236,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0059836647727272724,
        "hf_subset": "mbc_Latn-eng_Latn",
        "languages": [
          "mbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0059836647727272724,
        "precision": 0.003661334325396825,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019097222222222224,
        "hf_subset": "eng_Latn-mbh_Latn",
        "languages": [
          "eng-Latn",
          "mbh-Latn"
        ],
        "main_score": 0.019097222222222224,
        "precision": 0.015406436011904761,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013306781045751634,
        "hf_subset": "mbh_Latn-eng_Latn",
        "languages": [
          "mbh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013306781045751634,
        "precision": 0.011474609375,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013941271551724137,
        "hf_subset": "eng_Latn-mbj_Latn",
        "languages": [
          "eng-Latn",
          "mbj-Latn"
        ],
        "main_score": 0.013941271551724137,
        "precision": 0.010686383928571429,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012734211215932914,
        "hf_subset": "mbj_Latn-eng_Latn",
        "languages": [
          "mbj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012734211215932914,
        "precision": 0.012282151442307692,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003608630952380952,
        "hf_subset": "eng_Latn-mbl_Latn",
        "languages": [
          "eng-Latn",
          "mbl-Latn"
        ],
        "main_score": 0.003608630952380952,
        "precision": 0.002232499201787995,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0006859046690126479,
        "hf_subset": "mbl_Latn-eng_Latn",
        "languages": [
          "mbl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006859046690126479,
        "precision": 0.00036068870907738097,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013663736979166667,
        "hf_subset": "eng_Latn-mbs_Latn",
        "languages": [
          "eng-Latn",
          "mbs-Latn"
        ],
        "main_score": 0.013663736979166667,
        "precision": 0.009306795634920633,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0030799278846153845,
        "hf_subset": "mbs_Latn-eng_Latn",
        "languages": [
          "mbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0030799278846153845,
        "precision": 0.0019367121848739494,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01798673273657289,
        "hf_subset": "eng_Latn-mbt_Latn",
        "languages": [
          "eng-Latn",
          "mbt-Latn"
        ],
        "main_score": 0.01798673273657289,
        "precision": 0.015070134943181818,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009796626984126984,
        "hf_subset": "mbt_Latn-eng_Latn",
        "languages": [
          "mbt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009796626984126984,
        "precision": 0.008951822916666668,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023484002976190476,
        "hf_subset": "eng_Latn-mca_Latn",
        "languages": [
          "eng-Latn",
          "mca-Latn"
        ],
        "main_score": 0.023484002976190476,
        "precision": 0.019763764880952384,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012822432888669301,
        "hf_subset": "mca_Latn-eng_Latn",
        "languages": [
          "mca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012822432888669301,
        "precision": 0.01009750939849624,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0021005306603773585,
        "hf_subset": "eng_Latn-mcb_Latn",
        "languages": [
          "eng-Latn",
          "mcb-Latn"
        ],
        "main_score": 0.0021005306603773585,
        "precision": 0.0013772035256410255,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0003578825536062378,
        "hf_subset": "mcb_Latn-eng_Latn",
        "languages": [
          "mcb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0003578825536062378,
        "precision": 0.00018480896868618108,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007421875,
        "hf_subset": "eng_Latn-mcd_Latn",
        "languages": [
          "eng-Latn",
          "mcd-Latn"
        ],
        "main_score": 0.007421875,
        "precision": 0.006184895833333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0027624991912525883,
        "hf_subset": "mcd_Latn-eng_Latn",
        "languages": [
          "mcd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027624991912525883,
        "precision": 0.001555290715076353,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007466491841491842,
        "hf_subset": "eng_Latn-mcf_Latn",
        "languages": [
          "eng-Latn",
          "mcf-Latn"
        ],
        "main_score": 0.007466491841491842,
        "precision": 0.006370907738095238,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00032637746710526314,
        "hf_subset": "mcf_Latn-eng_Latn",
        "languages": [
          "mcf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00032637746710526314,
        "precision": 0.00016756391557995882,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013253348214285714,
        "hf_subset": "eng_Latn-mco_Latn",
        "languages": [
          "eng-Latn",
          "mco-Latn"
        ],
        "main_score": 0.013253348214285714,
        "precision": 0.012577266483516482,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007917714783281734,
        "hf_subset": "mco_Latn-eng_Latn",
        "languages": [
          "mco-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007917714783281734,
        "precision": 0.00638828204154002,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.020613219246031746,
        "hf_subset": "eng_Latn-mcp_Latn",
        "languages": [
          "eng-Latn",
          "mcp-Latn"
        ],
        "main_score": 0.020613219246031746,
        "precision": 0.016049868100649352,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006119048493369146,
        "hf_subset": "mcp_Latn-eng_Latn",
        "languages": [
          "mcp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006119048493369146,
        "precision": 0.0053412543402777775,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005611359126984126,
        "hf_subset": "eng_Latn-mcq_Latn",
        "languages": [
          "eng-Latn",
          "mcq-Latn"
        ],
        "main_score": 0.005611359126984126,
        "precision": 0.0038387639735772356,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008358470077220077,
        "hf_subset": "mcq_Latn-eng_Latn",
        "languages": [
          "mcq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008358470077220077,
        "precision": 0.006618923611111111,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005433505639097743,
        "hf_subset": "eng_Latn-mcr_Latn",
        "languages": [
          "eng-Latn",
          "mcr-Latn"
        ],
        "main_score": 0.005433505639097743,
        "precision": 0.003472222222222222,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007893880208333334,
        "hf_subset": "mcr_Latn-eng_Latn",
        "languages": [
          "mcr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007893880208333334,
        "precision": 0.007853618421052632,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002687278368794326,
        "hf_subset": "eng_Latn-mdy_Latn",
        "languages": [
          "eng-Latn",
          "mdy-Latn"
        ],
        "main_score": 0.002687278368794326,
        "precision": 0.001995127688172043,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00026041666666666666,
        "hf_subset": "mdy_Latn-eng_Latn",
        "languages": [
          "mdy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00026041666666666666,
        "precision": 0.00013469827586206896,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01044766865079365,
        "hf_subset": "eng_Latn-med_Latn",
        "languages": [
          "eng-Latn",
          "med-Latn"
        ],
        "main_score": 0.01044766865079365,
        "precision": 0.00830078125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004280520330112721,
        "hf_subset": "med_Latn-eng_Latn",
        "languages": [
          "med-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004280520330112721,
        "precision": 0.004099416208791209,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018258759469696968,
        "hf_subset": "eng_Latn-mee_Latn",
        "languages": [
          "eng-Latn",
          "mee-Latn"
        ],
        "main_score": 0.018258759469696968,
        "precision": 0.015978422619047618,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00078125,
        "hf_subset": "mee_Latn-eng_Latn",
        "languages": [
          "mee-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00078125,
        "precision": 0.00043402777777777775,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.023581821824009322,
        "hf_subset": "eng_Latn-mek_Latn",
        "languages": [
          "eng-Latn",
          "mek-Latn"
        ],
        "main_score": 0.023581821824009322,
        "precision": 0.019722855532373133,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006751552483974358,
        "hf_subset": "mek_Latn-eng_Latn",
        "languages": [
          "mek-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006751552483974358,
        "precision": 0.005564619374827985,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014973958333333334,
        "hf_subset": "eng_Latn-meq_Latn",
        "languages": [
          "eng-Latn",
          "meq-Latn"
        ],
        "main_score": 0.014973958333333334,
        "precision": 0.011655336850649352,
        "recall": 0.03125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "meq_Latn-eng_Latn",
        "languages": [
          "meq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013764880952380952,
        "hf_subset": "eng_Latn-met_Latn",
        "languages": [
          "eng-Latn",
          "met-Latn"
        ],
        "main_score": 0.013764880952380952,
        "precision": 0.009218051255589955,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006108267016045549,
        "hf_subset": "met_Latn-eng_Latn",
        "languages": [
          "met-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006108267016045549,
        "precision": 0.003797743055555555,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.011970682709059233,
        "hf_subset": "eng_Latn-meu_Latn",
        "languages": [
          "eng-Latn",
          "meu-Latn"
        ],
        "main_score": 0.011970682709059233,
        "precision": 0.008696056547619048,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004152856691919192,
        "hf_subset": "meu_Latn-eng_Latn",
        "languages": [
          "meu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004152856691919192,
        "precision": 0.002534412202380952,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.026583059210526318,
        "hf_subset": "eng_Latn-mgc_Latn",
        "languages": [
          "eng-Latn",
          "mgc-Latn"
        ],
        "main_score": 0.026583059210526318,
        "precision": 0.024443655303030304,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014409722222222221,
        "hf_subset": "mgc_Latn-eng_Latn",
        "languages": [
          "mgc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014409722222222221,
        "precision": 0.013715765449438203,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01848958333333333,
        "hf_subset": "eng_Latn-mgh_Latn",
        "languages": [
          "eng-Latn",
          "mgh-Latn"
        ],
        "main_score": 0.01848958333333333,
        "precision": 0.015299479166666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.007111855158730159,
        "hf_subset": "mgh_Latn-eng_Latn",
        "languages": [
          "mgh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007111855158730159,
        "precision": 0.004268734737484737,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.07655502392344497,
        "f1": 0.052722715880610616,
        "hf_subset": "eng_Latn-mgw_Latn",
        "languages": [
          "eng-Latn",
          "mgw-Latn"
        ],
        "main_score": 0.052722715880610616,
        "precision": 0.046677299308878255,
        "recall": 0.07655502392344497
      },
      {
        "accuracy": 0.03349282296650718,
        "f1": 0.020554226475279103,
        "hf_subset": "mgw_Latn-eng_Latn",
        "languages": [
          "mgw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020554226475279103,
        "precision": 0.018256418171528527,
        "recall": 0.03349282296650718
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012328869047619049,
        "hf_subset": "eng_Latn-mhl_Latn",
        "languages": [
          "eng-Latn",
          "mhl-Latn"
        ],
        "main_score": 0.012328869047619049,
        "precision": 0.009484818566849816,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009191934818481847,
        "hf_subset": "mhl_Latn-eng_Latn",
        "languages": [
          "mhl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009191934818481847,
        "precision": 0.0086328125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03549107142857143,
        "hf_subset": "eng_Latn-mib_Latn",
        "languages": [
          "eng-Latn",
          "mib-Latn"
        ],
        "main_score": 0.03549107142857143,
        "precision": 0.0303030303030303,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016621866805551666,
        "hf_subset": "mib_Latn-eng_Latn",
        "languages": [
          "mib-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016621866805551666,
        "precision": 0.014950707966602365,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00475761217948718,
        "hf_subset": "eng_Latn-mic_Latn",
        "languages": [
          "eng-Latn",
          "mic-Latn"
        ],
        "main_score": 0.00475761217948718,
        "precision": 0.0033580043859649123,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006594422043010752,
        "hf_subset": "mic_Latn-eng_Latn",
        "languages": [
          "mic-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006594422043010752,
        "precision": 0.005901834239130435,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020762310606060607,
        "hf_subset": "eng_Latn-mie_Latn",
        "languages": [
          "eng-Latn",
          "mie-Latn"
        ],
        "main_score": 0.020762310606060607,
        "precision": 0.01650094696969697,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012561207086267605,
        "hf_subset": "mie_Latn-eng_Latn",
        "languages": [
          "mie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012561207086267605,
        "precision": 0.010858894969278034,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021092602452996476,
        "hf_subset": "eng_Latn-mig_Latn",
        "languages": [
          "eng-Latn",
          "mig-Latn"
        ],
        "main_score": 0.021092602452996476,
        "precision": 0.019278675011671333,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.026624015748031495,
        "hf_subset": "mig_Latn-eng_Latn",
        "languages": [
          "mig-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026624015748031495,
        "precision": 0.025421626984126984,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02768429487179487,
        "hf_subset": "eng_Latn-mih_Latn",
        "languages": [
          "eng-Latn",
          "mih-Latn"
        ],
        "main_score": 0.02768429487179487,
        "precision": 0.02398142446633826,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01952706695716564,
        "hf_subset": "mih_Latn-eng_Latn",
        "languages": [
          "mih-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01952706695716564,
        "precision": 0.017262553528048386,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022172619047619045,
        "hf_subset": "eng_Latn-mil_Latn",
        "languages": [
          "eng-Latn",
          "mil-Latn"
        ],
        "main_score": 0.022172619047619045,
        "precision": 0.019093883547008545,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010383219117267209,
        "hf_subset": "mil_Latn-eng_Latn",
        "languages": [
          "mil-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010383219117267209,
        "precision": 0.008496633538013304,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02059347587719298,
        "hf_subset": "eng_Latn-mio_Latn",
        "languages": [
          "eng-Latn",
          "mio-Latn"
        ],
        "main_score": 0.02059347587719298,
        "precision": 0.017609126984126984,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013587706717302304,
        "hf_subset": "mio_Latn-eng_Latn",
        "languages": [
          "mio-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013587706717302304,
        "precision": 0.011715125780195682,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00789741847826087,
        "hf_subset": "eng_Latn-mir_Latn",
        "languages": [
          "eng-Latn",
          "mir-Latn"
        ],
        "main_score": 0.00789741847826087,
        "precision": 0.007855425824175824,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.004410217660628844,
        "hf_subset": "mir_Latn-eng_Latn",
        "languages": [
          "mir-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004410217660628844,
        "precision": 0.002670225853092536,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022093141233766232,
        "hf_subset": "eng_Latn-mit_Latn",
        "languages": [
          "eng-Latn",
          "mit-Latn"
        ],
        "main_score": 0.022093141233766232,
        "precision": 0.02115071614583333,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006136246565934066,
        "hf_subset": "mit_Latn-eng_Latn",
        "languages": [
          "mit-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006136246565934066,
        "precision": 0.004057140775890776,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.027537920321637425,
        "hf_subset": "eng_Latn-miz_Latn",
        "languages": [
          "eng-Latn",
          "miz-Latn"
        ],
        "main_score": 0.027537920321637425,
        "precision": 0.02518637663398693,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018001302083333334,
        "hf_subset": "miz_Latn-eng_Latn",
        "languages": [
          "miz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018001302083333334,
        "precision": 0.01603363253546099,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01729910714285714,
        "hf_subset": "eng_Latn-mjc_Latn",
        "languages": [
          "eng-Latn",
          "mjc-Latn"
        ],
        "main_score": 0.01729910714285714,
        "precision": 0.015404647435897437,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007415099709041855,
        "hf_subset": "mjc_Latn-eng_Latn",
        "languages": [
          "mjc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007415099709041855,
        "precision": 0.006329502203525641,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.17578125,
        "f1": 0.12498664529914529,
        "hf_subset": "eng_Latn-mkj_Latn",
        "languages": [
          "eng-Latn",
          "mkj-Latn"
        ],
        "main_score": 0.12498664529914529,
        "precision": 0.10817057291666665,
        "recall": 0.17578125
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.09714218073593073,
        "hf_subset": "mkj_Latn-eng_Latn",
        "languages": [
          "mkj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09714218073593073,
        "precision": 0.08565616942799847,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004245923913043478,
        "hf_subset": "eng_Latn-mkl_Latn",
        "languages": [
          "eng-Latn",
          "mkl-Latn"
        ],
        "main_score": 0.004245923913043478,
        "precision": 0.004083806818181818,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0001166044776119403,
        "hf_subset": "mkl_Latn-eng_Latn",
        "languages": [
          "mkl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0001166044776119403,
        "precision": 5.918560606060606e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017308501683501683,
        "hf_subset": "eng_Latn-mkn_Latn",
        "languages": [
          "eng-Latn",
          "mkn-Latn"
        ],
        "main_score": 0.017308501683501683,
        "precision": 0.013346814809355345,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006699810606060607,
        "hf_subset": "mkn_Latn-eng_Latn",
        "languages": [
          "mkn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006699810606060607,
        "precision": 0.005552455357142857,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022066735347985346,
        "hf_subset": "eng_Latn-mks_Latn",
        "languages": [
          "eng-Latn",
          "mks-Latn"
        ],
        "main_score": 0.022066735347985346,
        "precision": 0.019831730769230768,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02367070895522388,
        "hf_subset": "mks_Latn-eng_Latn",
        "languages": [
          "mks-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02367070895522388,
        "precision": 0.023555871212121212,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00407318376068376,
        "hf_subset": "eng_Latn-mle_Latn",
        "languages": [
          "eng-Latn",
          "mle-Latn"
        ],
        "main_score": 0.00407318376068376,
        "precision": 0.0027669270833333335,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00041118421052631577,
        "hf_subset": "mle_Latn-eng_Latn",
        "languages": [
          "mle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00041118421052631577,
        "precision": 0.00021701388888888888,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012328869047619049,
        "hf_subset": "eng_Latn-mlh_Latn",
        "languages": [
          "eng-Latn",
          "mlh-Latn"
        ],
        "main_score": 0.012328869047619049,
        "precision": 0.009484818566849816,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009191934818481847,
        "hf_subset": "mlh_Latn-eng_Latn",
        "languages": [
          "mlh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009191934818481847,
        "precision": 0.0086328125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009902686403508772,
        "hf_subset": "eng_Latn-mlp_Latn",
        "languages": [
          "eng-Latn",
          "mlp-Latn"
        ],
        "main_score": 0.009902686403508772,
        "precision": 0.009184337797619048,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009202118347338934,
        "hf_subset": "mlp_Latn-eng_Latn",
        "languages": [
          "mlp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009202118347338934,
        "precision": 0.007405598958333334,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007698074494949495,
        "hf_subset": "eng_Latn-mmo_Latn",
        "languages": [
          "eng-Latn",
          "mmo-Latn"
        ],
        "main_score": 0.007698074494949495,
        "precision": 0.005110677083333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0033668154761904764,
        "hf_subset": "mmo_Latn-eng_Latn",
        "languages": [
          "mmo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0033668154761904764,
        "precision": 0.002139945652173913,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014290364583333333,
        "hf_subset": "eng_Latn-mmx_Latn",
        "languages": [
          "eng-Latn",
          "mmx-Latn"
        ],
        "main_score": 0.014290364583333333,
        "precision": 0.011281622023809524,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.010416666666666666,
        "hf_subset": "mmx_Latn-eng_Latn",
        "languages": [
          "mmx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.009765625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018523065476190474,
        "hf_subset": "eng_Latn-mna_Latn",
        "languages": [
          "eng-Latn",
          "mna-Latn"
        ],
        "main_score": 0.018523065476190474,
        "precision": 0.015111678685897436,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008572173475258918,
        "hf_subset": "mna_Latn-eng_Latn",
        "languages": [
          "mna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008572173475258918,
        "precision": 0.008228005573248407,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010839272660818713,
        "hf_subset": "eng_Latn-mop_Latn",
        "languages": [
          "eng-Latn",
          "mop-Latn"
        ],
        "main_score": 0.010839272660818713,
        "precision": 0.008536563907657658,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.009752174908424909,
        "hf_subset": "mop_Latn-eng_Latn",
        "languages": [
          "mop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009752174908424909,
        "precision": 0.0065396613190730835,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012333622685185184,
        "hf_subset": "eng_Latn-mox_Latn",
        "languages": [
          "eng-Latn",
          "mox-Latn"
        ],
        "main_score": 0.012333622685185184,
        "precision": 0.009822859432234432,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009602864583333332,
        "hf_subset": "mox_Latn-eng_Latn",
        "languages": [
          "mox-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009602864583333332,
        "precision": 0.008072916666666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.07228915662650602,
        "f1": 0.04497991967871486,
        "hf_subset": "eng_Latn-mph_Latn",
        "languages": [
          "eng-Latn",
          "mph-Latn"
        ],
        "main_score": 0.04497991967871486,
        "precision": 0.03882195448460509,
        "recall": 0.07228915662650602
      },
      {
        "accuracy": 0.04819277108433735,
        "f1": 0.014172003328629834,
        "hf_subset": "mph_Latn-eng_Latn",
        "languages": [
          "mph-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014172003328629834,
        "precision": 0.00886880856760375,
        "recall": 0.04819277108433735
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0028236607142857143,
        "hf_subset": "eng_Latn-mpj_Latn",
        "languages": [
          "eng-Latn",
          "mpj-Latn"
        ],
        "main_score": 0.0028236607142857143,
        "precision": 0.001765324519230769,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "mpj_Latn-eng_Latn",
        "languages": [
          "mpj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020736607142857143,
        "hf_subset": "eng_Latn-mpm_Latn",
        "languages": [
          "eng-Latn",
          "mpm-Latn"
        ],
        "main_score": 0.020736607142857143,
        "precision": 0.020168340773809523,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016428964475839476,
        "hf_subset": "mpm_Latn-eng_Latn",
        "languages": [
          "mpm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016428964475839476,
        "precision": 0.016048371154371275,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01328125,
        "hf_subset": "eng_Latn-mpp_Latn",
        "languages": [
          "eng-Latn",
          "mpp-Latn"
        ],
        "main_score": 0.01328125,
        "precision": 0.010221354166666665,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006103515625,
        "hf_subset": "mpp_Latn-eng_Latn",
        "languages": [
          "mpp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006103515625,
        "precision": 0.005334341397849462,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00420673076923077,
        "hf_subset": "eng_Latn-mps_Latn",
        "languages": [
          "eng-Latn",
          "mps-Latn"
        ],
        "main_score": 0.00420673076923077,
        "precision": 0.0025434027777777777,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0010693801812222863,
        "hf_subset": "mps_Latn-eng_Latn",
        "languages": [
          "mps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010693801812222863,
        "precision": 0.0005682251776001776,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007340512896273637,
        "hf_subset": "eng_Latn-mpt_Latn",
        "languages": [
          "eng-Latn",
          "mpt-Latn"
        ],
        "main_score": 0.007340512896273637,
        "precision": 0.006295421511627907,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0014009757383966245,
        "hf_subset": "mpt_Latn-eng_Latn",
        "languages": [
          "mpt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0014009757383966245,
        "precision": 0.0008313301282051283,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016197344322344324,
        "hf_subset": "eng_Latn-mpx_Latn",
        "languages": [
          "eng-Latn",
          "mpx-Latn"
        ],
        "main_score": 0.016197344322344324,
        "precision": 0.014751233552631578,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012996031746031745,
        "hf_subset": "mpx_Latn-eng_Latn",
        "languages": [
          "mpx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012996031746031745,
        "precision": 0.01081814236111111,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020532949243886742,
        "hf_subset": "eng_Latn-mqb_Latn",
        "languages": [
          "eng-Latn",
          "mqb-Latn"
        ],
        "main_score": 0.020532949243886742,
        "precision": 0.017652811598124096,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00818975924392936,
        "hf_subset": "mqb_Latn-eng_Latn",
        "languages": [
          "mqb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00818975924392936,
        "precision": 0.008008378623188405,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.014747925685425685,
        "hf_subset": "eng_Latn-mqj_Latn",
        "languages": [
          "eng-Latn",
          "mqj-Latn"
        ],
        "main_score": 0.014747925685425685,
        "precision": 0.01045377148892774,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016496048850574714,
        "hf_subset": "mqj_Latn-eng_Latn",
        "languages": [
          "mqj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016496048850574714,
        "precision": 0.014972876868770763,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.046875,
        "hf_subset": "eng_Latn-msb_Latn",
        "languages": [
          "eng-Latn",
          "msb-Latn"
        ],
        "main_score": 0.046875,
        "precision": 0.042261904761904764,
        "recall": 0.0625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.034375,
        "hf_subset": "msb_Latn-eng_Latn",
        "languages": [
          "msb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.034375,
        "precision": 0.029836309523809522,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.057657490079365076,
        "hf_subset": "eng_Latn-msc_Latn",
        "languages": [
          "eng-Latn",
          "msc-Latn"
        ],
        "main_score": 0.057657490079365076,
        "precision": 0.04972563244047619,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04223090277777778,
        "hf_subset": "msc_Latn-eng_Latn",
        "languages": [
          "msc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04223090277777778,
        "precision": 0.037498955548128335,
        "recall": 0.0625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006141493055555555,
        "hf_subset": "eng_Latn-msk_Latn",
        "languages": [
          "eng-Latn",
          "msk-Latn"
        ],
        "main_score": 0.006141493055555555,
        "precision": 0.005158159069548872,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009269043329637842,
        "hf_subset": "msk_Latn-eng_Latn",
        "languages": [
          "msk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009269043329637842,
        "precision": 0.007600308641975309,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023768446180555555,
        "hf_subset": "eng_Latn-msm_Latn",
        "languages": [
          "eng-Latn",
          "msm-Latn"
        ],
        "main_score": 0.023768446180555555,
        "precision": 0.02014553931451613,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01502081360479798,
        "hf_subset": "msm_Latn-eng_Latn",
        "languages": [
          "msm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01502081360479798,
        "precision": 0.012585317960349462,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.006826261123136123,
        "hf_subset": "eng_Latn-msy_Latn",
        "languages": [
          "eng-Latn",
          "msy-Latn"
        ],
        "main_score": 0.006826261123136123,
        "precision": 0.004146760867808661,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007787240561118064,
        "hf_subset": "msy_Latn-eng_Latn",
        "languages": [
          "msy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007787240561118064,
        "precision": 0.006318642436594203,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021514545223577236,
        "hf_subset": "eng_Latn-mti_Latn",
        "languages": [
          "eng-Latn",
          "mti-Latn"
        ],
        "main_score": 0.021514545223577236,
        "precision": 0.017562937159291327,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011837121212121212,
        "hf_subset": "mti_Latn-eng_Latn",
        "languages": [
          "mti-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011837121212121212,
        "precision": 0.011778846153846154,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01654110863095238,
        "hf_subset": "eng_Latn-mto_Latn",
        "languages": [
          "eng-Latn",
          "mto-Latn"
        ],
        "main_score": 0.01654110863095238,
        "precision": 0.01240985576923077,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012680611559139784,
        "hf_subset": "mto_Latn-eng_Latn",
        "languages": [
          "mto-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012680611559139784,
        "precision": 0.010116511093073592,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003720238095238095,
        "hf_subset": "eng_Latn-mux_Latn",
        "languages": [
          "eng-Latn",
          "mux-Latn"
        ],
        "main_score": 0.003720238095238095,
        "precision": 0.0026041666666666665,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004123883928571428,
        "hf_subset": "mux_Latn-eng_Latn",
        "languages": [
          "mux-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004123883928571428,
        "precision": 0.004016729797979798,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011805555555555555,
        "hf_subset": "eng_Latn-muy_Latn",
        "languages": [
          "eng-Latn",
          "muy-Latn"
        ],
        "main_score": 0.011805555555555555,
        "precision": 0.010532924107142856,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005859375,
        "hf_subset": "muy_Latn-eng_Latn",
        "languages": [
          "muy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005208333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004774305555555556,
        "hf_subset": "eng_Latn-mva_Latn",
        "languages": [
          "eng-Latn",
          "mva-Latn"
        ],
        "main_score": 0.004774305555555556,
        "precision": 0.0028320312500000003,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004483657614781636,
        "hf_subset": "mva_Latn-eng_Latn",
        "languages": [
          "mva-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004483657614781636,
        "precision": 0.004208182367149759,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013020833333333332,
        "hf_subset": "eng_Latn-mvn_Latn",
        "languages": [
          "eng-Latn",
          "mvn-Latn"
        ],
        "main_score": 0.013020833333333332,
        "precision": 0.010416666666666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009324551316738816,
        "hf_subset": "mvn_Latn-eng_Latn",
        "languages": [
          "mvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009324551316738816,
        "precision": 0.007349629819032876,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.23046875,
        "f1": 0.1723293812543133,
        "hf_subset": "eng_Latn-mwc_Latn",
        "languages": [
          "eng-Latn",
          "mwc-Latn"
        ],
        "main_score": 0.1723293812543133,
        "precision": 0.15819791102994227,
        "recall": 0.23046875
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.1392071933994583,
        "hf_subset": "mwc_Latn-eng_Latn",
        "languages": [
          "mwc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.1392071933994583,
        "precision": 0.12647284789862914,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006770833333333333,
        "hf_subset": "eng_Latn-mwe_Latn",
        "languages": [
          "eng-Latn",
          "mwe-Latn"
        ],
        "main_score": 0.006770833333333333,
        "precision": 0.0044921875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005473090277777778,
        "hf_subset": "mwe_Latn-eng_Latn",
        "languages": [
          "mwe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005473090277777778,
        "precision": 0.004773784513805522,
        "recall": 0.015625
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.08379080325311943,
        "hf_subset": "eng_Latn-mwf_Latn",
        "languages": [
          "eng-Latn",
          "mwf-Latn"
        ],
        "main_score": 0.08379080325311943,
        "precision": 0.07490234374999999,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.0859375,
        "f1": 0.057982057005494504,
        "hf_subset": "mwf_Latn-eng_Latn",
        "languages": [
          "mwf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.057982057005494504,
        "precision": 0.05081845238095238,
        "recall": 0.0859375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01498898237179487,
        "hf_subset": "eng_Latn-mwp_Latn",
        "languages": [
          "eng-Latn",
          "mwp-Latn"
        ],
        "main_score": 0.01498898237179487,
        "precision": 0.010236855158730159,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00494700611888112,
        "hf_subset": "mwp_Latn-eng_Latn",
        "languages": [
          "mwp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00494700611888112,
        "precision": 0.003235687466772993,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022460937499999997,
        "hf_subset": "eng_Latn-mxb_Latn",
        "languages": [
          "eng-Latn",
          "mxb-Latn"
        ],
        "main_score": 0.022460937499999997,
        "precision": 0.02021949404761905,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01762932655010303,
        "hf_subset": "mxb_Latn-eng_Latn",
        "languages": [
          "mxb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01762932655010303,
        "precision": 0.015687154783622176,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01078622347480106,
        "hf_subset": "eng_Latn-mxp_Latn",
        "languages": [
          "eng-Latn",
          "mxp-Latn"
        ],
        "main_score": 0.01078622347480106,
        "precision": 0.008263156114718614,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01613377700617284,
        "hf_subset": "mxp_Latn-eng_Latn",
        "languages": [
          "mxp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01613377700617284,
        "precision": 0.012437220982142857,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004923282657657658,
        "hf_subset": "eng_Latn-mxq_Latn",
        "languages": [
          "eng-Latn",
          "mxq-Latn"
        ],
        "main_score": 0.004923282657657658,
        "precision": 0.003443416883168005,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0027405753968253966,
        "hf_subset": "mxq_Latn-eng_Latn",
        "languages": [
          "mxq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027405753968253966,
        "precision": 0.0016588541666666665,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0212828621031746,
        "hf_subset": "eng_Latn-mxt_Latn",
        "languages": [
          "eng-Latn",
          "mxt-Latn"
        ],
        "main_score": 0.0212828621031746,
        "precision": 0.018554278382907415,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015042613636363635,
        "hf_subset": "mxt_Latn-eng_Latn",
        "languages": [
          "mxt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015042613636363635,
        "precision": 0.013715361566924067,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-mya_Latn",
        "languages": [
          "eng-Latn",
          "mya-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.0517578125e-05,
        "hf_subset": "mya_Latn-eng_Latn",
        "languages": [
          "mya-Latn",
          "eng-Latn"
        ],
        "main_score": 3.0517578125e-05,
        "precision": 1.5318627450980392e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007509995791245791,
        "hf_subset": "eng_Latn-myk_Latn",
        "languages": [
          "eng-Latn",
          "myk-Latn"
        ],
        "main_score": 0.007509995791245791,
        "precision": 0.004707532051282051,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027947154471544716,
        "hf_subset": "myk_Latn-eng_Latn",
        "languages": [
          "myk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027947154471544716,
        "precision": 0.00205078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01566220238095238,
        "hf_subset": "eng_Latn-myu_Latn",
        "languages": [
          "eng-Latn",
          "myu-Latn"
        ],
        "main_score": 0.01566220238095238,
        "precision": 0.013234508547008545,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013484515182884748,
        "hf_subset": "myu_Latn-eng_Latn",
        "languages": [
          "myu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013484515182884748,
        "precision": 0.012740560850439883,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003314393939393939,
        "hf_subset": "eng_Latn-myw_Latn",
        "languages": [
          "eng-Latn",
          "myw-Latn"
        ],
        "main_score": 0.003314393939393939,
        "precision": 0.00234375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00033967391304347825,
        "hf_subset": "myw_Latn-eng_Latn",
        "languages": [
          "myw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00033967391304347825,
        "precision": 0.0001775568181818182,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0185546875,
        "hf_subset": "eng_Latn-myy_Latn",
        "languages": [
          "eng-Latn",
          "myy-Latn"
        ],
        "main_score": 0.0185546875,
        "precision": 0.017485119047619048,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026526915113871635,
        "hf_subset": "myy_Latn-eng_Latn",
        "languages": [
          "myy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0026526915113871635,
        "precision": 0.0019775390625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.056,
        "f1": 0.03532121212121213,
        "hf_subset": "eng_Latn-mzz_Latn",
        "languages": [
          "eng-Latn",
          "mzz-Latn"
        ],
        "main_score": 0.03532121212121213,
        "precision": 0.029466666666666665,
        "recall": 0.056
      },
      {
        "accuracy": 0.032,
        "f1": 0.011429599640125954,
        "hf_subset": "mzz_Latn-eng_Latn",
        "languages": [
          "mzz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011429599640125954,
        "precision": 0.009882882882882882,
        "recall": 0.032
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-nab_Latn",
        "languages": [
          "eng-Latn",
          "nab-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 5.0080128205128203e-05,
        "hf_subset": "nab_Latn-eng_Latn",
        "languages": [
          "nab-Latn",
          "eng-Latn"
        ],
        "main_score": 5.0080128205128203e-05,
        "precision": 2.5201612903225806e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0021071213942307696,
        "hf_subset": "eng_Latn-naf_Latn",
        "languages": [
          "eng-Latn",
          "naf-Latn"
        ],
        "main_score": 0.0021071213942307696,
        "precision": 0.0012588205645161288,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0009334415584415584,
        "hf_subset": "naf_Latn-eng_Latn",
        "languages": [
          "naf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0009334415584415584,
        "precision": 0.000505514705882353,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01503314393939394,
        "hf_subset": "eng_Latn-nak_Latn",
        "languages": [
          "eng-Latn",
          "nak-Latn"
        ],
        "main_score": 0.01503314393939394,
        "precision": 0.012890625000000001,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006262889475620008,
        "hf_subset": "nak_Latn-eng_Latn",
        "languages": [
          "nak-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006262889475620008,
        "precision": 0.005247961956521738,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004631696428571429,
        "hf_subset": "eng_Latn-nas_Latn",
        "languages": [
          "eng-Latn",
          "nas-Latn"
        ],
        "main_score": 0.004631696428571429,
        "precision": 0.0029296874999999996,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008838512542715128,
        "hf_subset": "nas_Latn-eng_Latn",
        "languages": [
          "nas-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008838512542715128,
        "precision": 0.008360632838907667,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01654958858543417,
        "hf_subset": "eng_Latn-nbq_Latn",
        "languages": [
          "eng-Latn",
          "nbq-Latn"
        ],
        "main_score": 0.01654958858543417,
        "precision": 0.013352993577602952,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.024090069933489826,
        "hf_subset": "nbq_Latn-eng_Latn",
        "languages": [
          "nbq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024090069933489826,
        "precision": 0.022290567505411255,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0023858048654244305,
        "hf_subset": "eng_Latn-nca_Latn",
        "languages": [
          "eng-Latn",
          "nca-Latn"
        ],
        "main_score": 0.0023858048654244305,
        "precision": 0.0015267034045271996,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00036151592548076925,
        "hf_subset": "nca_Latn-eng_Latn",
        "languages": [
          "nca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00036151592548076925,
        "precision": 0.00018700787401574803,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017899576822916666,
        "hf_subset": "eng_Latn-nch_Latn",
        "languages": [
          "eng-Latn",
          "nch-Latn"
        ],
        "main_score": 0.017899576822916666,
        "precision": 0.015590653707349082,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004610558712121212,
        "hf_subset": "nch_Latn-eng_Latn",
        "languages": [
          "nch-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004610558712121212,
        "precision": 0.0026709618506493508,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01337770061728395,
        "hf_subset": "eng_Latn-ncj_Latn",
        "languages": [
          "eng-Latn",
          "ncj-Latn"
        ],
        "main_score": 0.01337770061728395,
        "precision": 0.012744140625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005931102667493796,
        "hf_subset": "ncj_Latn-eng_Latn",
        "languages": [
          "ncj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005931102667493796,
        "precision": 0.003989955357142857,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011536683802308802,
        "hf_subset": "eng_Latn-ncl_Latn",
        "languages": [
          "eng-Latn",
          "ncl-Latn"
        ],
        "main_score": 0.011536683802308802,
        "precision": 0.01001922843992248,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.007255114676989676,
        "hf_subset": "ncl_Latn-eng_Latn",
        "languages": [
          "ncl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007255114676989676,
        "precision": 0.005785731690336953,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006194196428571429,
        "hf_subset": "eng_Latn-ncu_Latn",
        "languages": [
          "eng-Latn",
          "ncu-Latn"
        ],
        "main_score": 0.006194196428571429,
        "precision": 0.00390625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.734913793103448e-05,
        "hf_subset": "ncu_Latn-eng_Latn",
        "languages": [
          "ncu-Latn",
          "eng-Latn"
        ],
        "main_score": 6.734913793103448e-05,
        "precision": 3.3967391304347826e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.026728291582321182,
        "hf_subset": "eng_Latn-ndg_Latn",
        "languages": [
          "eng-Latn",
          "ndg-Latn"
        ],
        "main_score": 0.026728291582321182,
        "precision": 0.024538070436507936,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010044642857142856,
        "hf_subset": "ndg_Latn-eng_Latn",
        "languages": [
          "ndg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010044642857142856,
        "precision": 0.00830829326923077,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016335227272727272,
        "hf_subset": "eng_Latn-ndj_Latn",
        "languages": [
          "eng-Latn",
          "ndj-Latn"
        ],
        "main_score": 0.016335227272727272,
        "precision": 0.012760416666666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005667892156862745,
        "hf_subset": "ndj_Latn-eng_Latn",
        "languages": [
          "ndj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005667892156862745,
        "precision": 0.004931640625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.022959592490842493,
        "hf_subset": "eng_Latn-nfa_Latn",
        "languages": [
          "eng-Latn",
          "nfa-Latn"
        ],
        "main_score": 0.022959592490842493,
        "precision": 0.015599959935897436,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012426403985507246,
        "hf_subset": "nfa_Latn-eng_Latn",
        "languages": [
          "nfa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012426403985507246,
        "precision": 0.011096221107055961,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "eng_Latn-ngp_Latn",
        "languages": [
          "eng-Latn",
          "ngp-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0031125992063492066,
        "hf_subset": "ngp_Latn-eng_Latn",
        "languages": [
          "ngp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0031125992063492066,
        "precision": 0.0018573835784313725,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.018289514847132034,
        "hf_subset": "eng_Latn-ngu_Latn",
        "languages": [
          "eng-Latn",
          "ngu-Latn"
        ],
        "main_score": 0.018289514847132034,
        "precision": 0.014791046626984126,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02326228459040959,
        "hf_subset": "ngu_Latn-eng_Latn",
        "languages": [
          "ngu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02326228459040959,
        "precision": 0.0193414692489528,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0077306547619047615,
        "hf_subset": "eng_Latn-nhe_Latn",
        "languages": [
          "eng-Latn",
          "nhe-Latn"
        ],
        "main_score": 0.0077306547619047615,
        "precision": 0.006563203828828829,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01006007201884461,
        "hf_subset": "nhe_Latn-eng_Latn",
        "languages": [
          "nhe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01006007201884461,
        "precision": 0.009265016581086864,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02963654891304348,
        "hf_subset": "eng_Latn-nhg_Latn",
        "languages": [
          "eng-Latn",
          "nhg-Latn"
        ],
        "main_score": 0.02963654891304348,
        "precision": 0.026349431818181817,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.022918429569334174,
        "hf_subset": "nhg_Latn-eng_Latn",
        "languages": [
          "nhg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022918429569334174,
        "precision": 0.018243755225752507,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.023475713675621762,
        "hf_subset": "eng_Latn-nhi_Latn",
        "languages": [
          "eng-Latn",
          "nhi-Latn"
        ],
        "main_score": 0.023475713675621762,
        "precision": 0.019533575148809525,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01388578869047619,
        "hf_subset": "nhi_Latn-eng_Latn",
        "languages": [
          "nhi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01388578869047619,
        "precision": 0.011905118249407041,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.058789062499999996,
        "hf_subset": "eng_Latn-nho_Latn",
        "languages": [
          "eng-Latn",
          "nho-Latn"
        ],
        "main_score": 0.058789062499999996,
        "precision": 0.05309495192307692,
        "recall": 0.078125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05001158015289449,
        "hf_subset": "nho_Latn-eng_Latn",
        "languages": [
          "nho-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05001158015289449,
        "precision": 0.044866608001373626,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019699648522603485,
        "hf_subset": "eng_Latn-nhr_Latn",
        "languages": [
          "eng-Latn",
          "nhr-Latn"
        ],
        "main_score": 0.019699648522603485,
        "precision": 0.016959191157464845,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0049479166666666664,
        "hf_subset": "nhr_Latn-eng_Latn",
        "languages": [
          "nhr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0049479166666666664,
        "precision": 0.004466955741626795,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "eng_Latn-nhu_Latn",
        "languages": [
          "eng-Latn",
          "nhu-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.300403225806451e-05,
        "hf_subset": "nhu_Latn-eng_Latn",
        "languages": [
          "nhu-Latn",
          "eng-Latn"
        ],
        "main_score": 6.300403225806451e-05,
        "precision": 3.1758130081300816e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009177587365591397,
        "hf_subset": "eng_Latn-nhw_Latn",
        "languages": [
          "eng-Latn",
          "nhw-Latn"
        ],
        "main_score": 0.009177587365591397,
        "precision": 0.007844258130081301,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.007917906746031746,
        "hf_subset": "nhw_Latn-eng_Latn",
        "languages": [
          "nhw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007917906746031746,
        "precision": 0.00507516571969697,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016509660008071025,
        "hf_subset": "eng_Latn-nhy_Latn",
        "languages": [
          "eng-Latn",
          "nhy-Latn"
        ],
        "main_score": 0.016509660008071025,
        "precision": 0.01498230502136752,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012306215766823161,
        "hf_subset": "nhy_Latn-eng_Latn",
        "languages": [
          "nhy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012306215766823161,
        "precision": 0.010635230654761903,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02605624167142585,
        "hf_subset": "eng_Latn-nif_Latn",
        "languages": [
          "eng-Latn",
          "nif-Latn"
        ],
        "main_score": 0.02605624167142585,
        "precision": 0.02493521497140523,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01389192241636798,
        "hf_subset": "nif_Latn-eng_Latn",
        "languages": [
          "nif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01389192241636798,
        "precision": 0.011056625026271543,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008072916666666666,
        "hf_subset": "eng_Latn-nii_Latn",
        "languages": [
          "eng-Latn",
          "nii-Latn"
        ],
        "main_score": 0.008072916666666666,
        "precision": 0.0068359375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006923776455026455,
        "hf_subset": "nii_Latn-eng_Latn",
        "languages": [
          "nii-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0006923776455026455,
        "precision": 0.00037589156189555124,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009796626984126984,
        "hf_subset": "eng_Latn-nin_Latn",
        "languages": [
          "eng-Latn",
          "nin-Latn"
        ],
        "main_score": 0.009796626984126984,
        "precision": 0.007649739583333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00929626937984496,
        "hf_subset": "nin_Latn-eng_Latn",
        "languages": [
          "nin-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00929626937984496,
        "precision": 0.007905505952380952,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019436975784632035,
        "hf_subset": "eng_Latn-nko_Latn",
        "languages": [
          "eng-Latn",
          "nko-Latn"
        ],
        "main_score": 0.019436975784632035,
        "precision": 0.016643254823481116,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017432303450226245,
        "hf_subset": "nko_Latn-eng_Latn",
        "languages": [
          "nko-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017432303450226245,
        "precision": 0.016626927759740256,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.1484375,
        "f1": 0.10312051914642376,
        "hf_subset": "eng_Latn-nld_Latn",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ],
        "main_score": 0.10312051914642376,
        "precision": 0.09201371978715728,
        "recall": 0.1484375
      },
      {
        "accuracy": 0.17578125,
        "f1": 0.14304315476190477,
        "hf_subset": "nld_Latn-eng_Latn",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.14304315476190477,
        "precision": 0.1340690593671679,
        "recall": 0.17578125
      },
      {
        "accuracy": 0.140625,
        "f1": 0.10255529295051354,
        "hf_subset": "eng_Latn-nlg_Latn",
        "languages": [
          "eng-Latn",
          "nlg-Latn"
        ],
        "main_score": 0.10255529295051354,
        "precision": 0.09382804153311966,
        "recall": 0.140625
      },
      {
        "accuracy": 0.10546875,
        "f1": 0.06277675594081844,
        "hf_subset": "nlg_Latn-eng_Latn",
        "languages": [
          "nlg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06277675594081844,
        "precision": 0.055682685370185364,
        "recall": 0.10546875
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.13694917597720907,
        "hf_subset": "eng_Latn-nna_Latn",
        "languages": [
          "eng-Latn",
          "nna-Latn"
        ],
        "main_score": 0.13694917597720907,
        "precision": 0.12243512238629425,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.12571314802874173,
        "hf_subset": "nna_Latn-eng_Latn",
        "languages": [
          "nna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12571314802874173,
        "precision": 0.11635372899159666,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01328125,
        "hf_subset": "eng_Latn-nnq_Latn",
        "languages": [
          "eng-Latn",
          "nnq-Latn"
        ],
        "main_score": 0.01328125,
        "precision": 0.0107421875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006221064814814815,
        "hf_subset": "nnq_Latn-eng_Latn",
        "languages": [
          "nnq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006221064814814815,
        "precision": 0.005249484080188679,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.024244791666666664,
        "hf_subset": "eng_Latn-noa_Latn",
        "languages": [
          "eng-Latn",
          "noa-Latn"
        ],
        "main_score": 0.024244791666666664,
        "precision": 0.020913052721088433,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020287024456521738,
        "hf_subset": "noa_Latn-eng_Latn",
        "languages": [
          "noa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020287024456521738,
        "precision": 0.01750924667874396,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.018229166666666664,
        "hf_subset": "eng_Latn-nop_Latn",
        "languages": [
          "eng-Latn",
          "nop-Latn"
        ],
        "main_score": 0.018229166666666664,
        "precision": 0.017578125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006440986641749723,
        "hf_subset": "nop_Latn-eng_Latn",
        "languages": [
          "nop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006440986641749723,
        "precision": 0.004198685711932994,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-not_Latn",
        "languages": [
          "eng-Latn",
          "not-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006164538183694531,
        "hf_subset": "not_Latn-eng_Latn",
        "languages": [
          "not-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006164538183694531,
        "precision": 0.004409213393588393,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.07421875,
        "f1": 0.045106139520202024,
        "hf_subset": "eng_Latn-nou_Latn",
        "languages": [
          "eng-Latn",
          "nou-Latn"
        ],
        "main_score": 0.045106139520202024,
        "precision": 0.041398499503968254,
        "recall": 0.07421875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03955056151558985,
        "hf_subset": "nou_Latn-eng_Latn",
        "languages": [
          "nou-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03955056151558985,
        "precision": 0.035604631987983276,
        "recall": 0.0625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007031249999999999,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.007031249999999999,
        "precision": 0.005859375,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004678499423963134,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.004678499423963134,
        "precision": 0.004315397635479848,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01248816287878788,
        "hf_subset": "eng_Latn-npl_Latn",
        "languages": [
          "eng-Latn",
          "npl-Latn"
        ],
        "main_score": 0.01248816287878788,
        "precision": 0.009895833333333333,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012920673076923076,
        "hf_subset": "npl_Latn-eng_Latn",
        "languages": [
          "npl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012920673076923076,
        "precision": 0.012369791666666668,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02911182281894934,
        "hf_subset": "eng_Latn-nsn_Latn",
        "languages": [
          "eng-Latn",
          "nsn-Latn"
        ],
        "main_score": 0.02911182281894934,
        "precision": 0.025069754464285714,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.023637820512820512,
        "hf_subset": "nsn_Latn-eng_Latn",
        "languages": [
          "nsn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.023637820512820512,
        "precision": 0.02236842105263158,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.034774730477855474,
        "hf_subset": "eng_Latn-nss_Latn",
        "languages": [
          "eng-Latn",
          "nss-Latn"
        ],
        "main_score": 0.034774730477855474,
        "precision": 0.03098958333333333,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01989669763107263,
        "hf_subset": "nss_Latn-eng_Latn",
        "languages": [
          "nss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01989669763107263,
        "precision": 0.01704298305860806,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011160714285714285,
        "hf_subset": "eng_Latn-ntj_Latn",
        "languages": [
          "eng-Latn",
          "ntj-Latn"
        ],
        "main_score": 0.0011160714285714285,
        "precision": 0.0006510416666666666,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "ntj_Latn-eng_Latn",
        "languages": [
          "ntj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0072862951998981405,
        "hf_subset": "eng_Latn-ntp_Latn",
        "languages": [
          "eng-Latn",
          "ntp-Latn"
        ],
        "main_score": 0.0072862951998981405,
        "precision": 0.006283103813559322,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00025528706672774473,
        "hf_subset": "ntp_Latn-eng_Latn",
        "languages": [
          "ntp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00025528706672774473,
        "precision": 0.00013070154671717172,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013541666666666667,
        "hf_subset": "eng_Latn-ntu_Latn",
        "languages": [
          "eng-Latn",
          "ntu-Latn"
        ],
        "main_score": 0.013541666666666667,
        "precision": 0.010825892857142857,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006727430555555556,
        "hf_subset": "ntu_Latn-eng_Latn",
        "languages": [
          "ntu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006727430555555556,
        "precision": 0.005696614583333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03393853032365396,
        "hf_subset": "eng_Latn-nuy_Latn",
        "languages": [
          "eng-Latn",
          "nuy-Latn"
        ],
        "main_score": 0.03393853032365396,
        "precision": 0.028695604086229086,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019635416666666666,
        "hf_subset": "nuy_Latn-eng_Latn",
        "languages": [
          "nuy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019635416666666666,
        "precision": 0.017334984131859132,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005208333333333333,
        "hf_subset": "eng_Latn-nvm_Latn",
        "languages": [
          "eng-Latn",
          "nvm-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.004619295634920635,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008680555555555555,
        "hf_subset": "nvm_Latn-eng_Latn",
        "languages": [
          "nvm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0008680555555555555,
        "precision": 0.00048828125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01513671875,
        "hf_subset": "eng_Latn-nwi_Latn",
        "languages": [
          "eng-Latn",
          "nwi-Latn"
        ],
        "main_score": 0.01513671875,
        "precision": 0.012642297308188265,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015525793650793651,
        "hf_subset": "nwi_Latn-eng_Latn",
        "languages": [
          "nwi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015525793650793651,
        "precision": 0.012858072916666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.022410857371794872,
        "hf_subset": "eng_Latn-nya_Latn",
        "languages": [
          "eng-Latn",
          "nya-Latn"
        ],
        "main_score": 0.022410857371794872,
        "precision": 0.018471961152882205,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013020833333333333,
        "hf_subset": "nya_Latn-eng_Latn",
        "languages": [
          "nya-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.0007278726708074534,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.18032786885245902,
        "f1": 0.12522177276275637,
        "hf_subset": "eng_Latn-nys_Latn",
        "languages": [
          "eng-Latn",
          "nys-Latn"
        ],
        "main_score": 0.12522177276275637,
        "precision": 0.11519300371759388,
        "recall": 0.18032786885245902
      },
      {
        "accuracy": 0.14754098360655737,
        "f1": 0.09917793116671458,
        "hf_subset": "nys_Latn-eng_Latn",
        "languages": [
          "nys-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09917793116671458,
        "precision": 0.08905352388958945,
        "recall": 0.14754098360655737
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013708600427350427,
        "hf_subset": "eng_Latn-nyu_Latn",
        "languages": [
          "eng-Latn",
          "nyu-Latn"
        ],
        "main_score": 0.013708600427350427,
        "precision": 0.010188802083333334,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013773970170454545,
        "hf_subset": "nyu_Latn-eng_Latn",
        "languages": [
          "nyu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013773970170454545,
        "precision": 0.011830872210786526,
        "recall": 0.03125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03150365708285967,
        "hf_subset": "eng_Latn-obo_Latn",
        "languages": [
          "eng-Latn",
          "obo-Latn"
        ],
        "main_score": 0.03150365708285967,
        "precision": 0.027639508928571428,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.020153569240196078,
        "hf_subset": "obo_Latn-eng_Latn",
        "languages": [
          "obo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020153569240196078,
        "precision": 0.016733502327127663,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.09825487012987011,
        "hf_subset": "eng_Latn-okv_Latn",
        "languages": [
          "eng-Latn",
          "okv-Latn"
        ],
        "main_score": 0.09825487012987011,
        "precision": 0.08190915689192343,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.09319768772893772,
        "hf_subset": "okv_Latn-eng_Latn",
        "languages": [
          "okv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.09319768772893772,
        "precision": 0.0872851305171278,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005815972222222222,
        "hf_subset": "eng_Latn-omw_Latn",
        "languages": [
          "eng-Latn",
          "omw-Latn"
        ],
        "main_score": 0.005815972222222222,
        "precision": 0.003949081688596491,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.441629955947137e-05,
        "hf_subset": "omw_Latn-eng_Latn",
        "languages": [
          "omw-Latn",
          "eng-Latn"
        ],
        "main_score": 3.441629955947137e-05,
        "precision": 1.728429203539823e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01837177579365079,
        "hf_subset": "eng_Latn-ong_Latn",
        "languages": [
          "eng-Latn",
          "ong-Latn"
        ],
        "main_score": 0.01837177579365079,
        "precision": 0.014867810235507248,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004136029411764706,
        "hf_subset": "ong_Latn-eng_Latn",
        "languages": [
          "ong-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004136029411764706,
        "precision": 0.004024621212121212,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020999968998015872,
        "hf_subset": "eng_Latn-ons_Latn",
        "languages": [
          "eng-Latn",
          "ons-Latn"
        ],
        "main_score": 0.020999968998015872,
        "precision": 0.018109439499484004,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0166655993852459,
        "hf_subset": "ons_Latn-eng_Latn",
        "languages": [
          "ons-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0166655993852459,
        "precision": 0.016215318772136954,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02648206241956242,
        "hf_subset": "eng_Latn-ood_Latn",
        "languages": [
          "eng-Latn",
          "ood-Latn"
        ],
        "main_score": 0.02648206241956242,
        "precision": 0.02297017694063927,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.019736842105263157,
        "hf_subset": "ood_Latn-eng_Latn",
        "languages": [
          "ood-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019736842105263157,
        "precision": 0.019636824324324325,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004464285714285714,
        "hf_subset": "eng_Latn-opm_Latn",
        "languages": [
          "eng-Latn",
          "opm-Latn"
        ],
        "main_score": 0.004464285714285714,
        "precision": 0.004206730769230769,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005452473958333333,
        "hf_subset": "opm_Latn-eng_Latn",
        "languages": [
          "opm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005452473958333333,
        "precision": 0.004813508064516129,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009114583333333332,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.009114583333333332,
        "precision": 0.0078125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005022321428571428,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.005022321428571428,
        "precision": 0.004557291666666667,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.01642127403846154,
        "hf_subset": "eng_Latn-ote_Latn",
        "languages": [
          "eng-Latn",
          "ote-Latn"
        ],
        "main_score": 0.01642127403846154,
        "precision": 0.010844494047619047,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004896965579710144,
        "hf_subset": "ote_Latn-eng_Latn",
        "languages": [
          "ote-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004896965579710144,
        "precision": 0.003432765151515151,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021259973404255318,
        "hf_subset": "eng_Latn-otm_Latn",
        "languages": [
          "eng-Latn",
          "otm-Latn"
        ],
        "main_score": 0.021259973404255318,
        "precision": 0.01942085597826087,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00578125,
        "hf_subset": "otm_Latn-eng_Latn",
        "languages": [
          "otm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00578125,
        "precision": 0.005045572916666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02089251893939394,
        "hf_subset": "eng_Latn-otn_Latn",
        "languages": [
          "eng-Latn",
          "otn-Latn"
        ],
        "main_score": 0.02089251893939394,
        "precision": 0.01809895833333333,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006336805555555556,
        "hf_subset": "otn_Latn-eng_Latn",
        "languages": [
          "otn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006336805555555556,
        "precision": 0.004069010416666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0125,
        "hf_subset": "eng_Latn-otq_Latn",
        "languages": [
          "eng-Latn",
          "otq-Latn"
        ],
        "main_score": 0.0125,
        "precision": 0.010850694444444444,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003977272727272727,
        "hf_subset": "otq_Latn-eng_Latn",
        "languages": [
          "otq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003977272727272727,
        "precision": 0.0039420871559633025,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004666248025623026,
        "hf_subset": "eng_Latn-ots_Latn",
        "languages": [
          "eng-Latn",
          "ots-Latn"
        ],
        "main_score": 0.004666248025623026,
        "precision": 0.0028312880517503804,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012796431737588652,
        "hf_subset": "ots_Latn-eng_Latn",
        "languages": [
          "ots-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012796431737588652,
        "precision": 0.011287325087456272,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008087940705128204,
        "hf_subset": "eng_Latn-pab_Latn",
        "languages": [
          "eng-Latn",
          "pab-Latn"
        ],
        "main_score": 0.008087940705128204,
        "precision": 0.005571056547619048,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008078497023809523,
        "hf_subset": "pab_Latn-eng_Latn",
        "languages": [
          "pab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008078497023809523,
        "precision": 0.006724847056878307,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0078125,
        "hf_subset": "eng_Latn-pad_Latn",
        "languages": [
          "eng-Latn",
          "pad-Latn"
        ],
        "main_score": 0.0078125,
        "precision": 0.0078125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014941608436853,
        "hf_subset": "pad_Latn-eng_Latn",
        "languages": [
          "pad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014941608436853,
        "precision": 0.013698179713804715,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0026041666666666665,
        "hf_subset": "eng_Latn-pah_Latn",
        "languages": [
          "eng-Latn",
          "pah-Latn"
        ],
        "main_score": 0.0026041666666666665,
        "precision": 0.001953125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015904017857142856,
        "hf_subset": "pah_Latn-eng_Latn",
        "languages": [
          "pah-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015904017857142856,
        "precision": 0.014565292419678716,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006510416666666666,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.006510416666666666,
        "precision": 0.005859375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0031128416799680765,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.0031128416799680765,
        "precision": 0.001975070224719101,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.032009548611111105,
        "hf_subset": "eng_Latn-pao_Latn",
        "languages": [
          "eng-Latn",
          "pao-Latn"
        ],
        "main_score": 0.032009548611111105,
        "precision": 0.02813156512605042,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.031901041666666664,
        "hf_subset": "pao_Latn-eng_Latn",
        "languages": [
          "pao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.031901041666666664,
        "precision": 0.026692708333333332,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-pes_Arab",
        "languages": [
          "eng-Latn",
          "pes-Arab"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "pes_Arab-eng_Latn",
        "languages": [
          "pes-Arab",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008370535714285714,
        "hf_subset": "eng_Latn-pib_Latn",
        "languages": [
          "eng-Latn",
          "pib-Latn"
        ],
        "main_score": 0.008370535714285714,
        "precision": 0.006941105769230769,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001006155303030303,
        "hf_subset": "pib_Latn-eng_Latn",
        "languages": [
          "pib-Latn",
          "eng-Latn"
        ],
        "main_score": 0.001006155303030303,
        "precision": 0.0005411255411255411,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008502239947552446,
        "hf_subset": "eng_Latn-pio_Latn",
        "languages": [
          "eng-Latn",
          "pio-Latn"
        ],
        "main_score": 0.008502239947552446,
        "precision": 0.00701104525862069,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015196851908866995,
        "hf_subset": "pio_Latn-eng_Latn",
        "languages": [
          "pio-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015196851908866995,
        "precision": 0.01180935292777398,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012684461805555556,
        "hf_subset": "eng_Latn-pir_Latn",
        "languages": [
          "eng-Latn",
          "pir-Latn"
        ],
        "main_score": 0.012684461805555556,
        "precision": 0.011114211309523808,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005967881944444444,
        "hf_subset": "pir_Latn-eng_Latn",
        "languages": [
          "pir-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005967881944444444,
        "precision": 0.005263350938967136,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-piu_Latn",
        "languages": [
          "eng-Latn",
          "piu-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0025775935374149662,
        "hf_subset": "piu_Latn-eng_Latn",
        "languages": [
          "piu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0025775935374149662,
        "precision": 0.001513671875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014467592592592593,
        "hf_subset": "eng_Latn-pjt_Latn",
        "languages": [
          "eng-Latn",
          "pjt-Latn"
        ],
        "main_score": 0.014467592592592593,
        "precision": 0.012147566466552316,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010724659455128205,
        "hf_subset": "pjt_Latn-eng_Latn",
        "languages": [
          "pjt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010724659455128205,
        "precision": 0.008677455357142858,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017643229166666666,
        "hf_subset": "eng_Latn-pls_Latn",
        "languages": [
          "eng-Latn",
          "pls-Latn"
        ],
        "main_score": 0.017643229166666666,
        "precision": 0.01433841765873016,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015778662008281576,
        "hf_subset": "pls_Latn-eng_Latn",
        "languages": [
          "pls-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015778662008281576,
        "precision": 0.013032670454545453,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006882440476190476,
        "hf_subset": "eng_Latn-plu_Latn",
        "languages": [
          "eng-Latn",
          "plu-Latn"
        ],
        "main_score": 0.006882440476190476,
        "precision": 0.0060546875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007102272727272727,
        "hf_subset": "plu_Latn-eng_Latn",
        "languages": [
          "plu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007102272727272727,
        "precision": 0.000390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01209077380952381,
        "hf_subset": "eng_Latn-pma_Latn",
        "languages": [
          "eng-Latn",
          "pma-Latn"
        ],
        "main_score": 0.01209077380952381,
        "precision": 0.0119140625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006729910714285714,
        "hf_subset": "pma_Latn-eng_Latn",
        "languages": [
          "pma-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006729910714285714,
        "precision": 0.005505854822261073,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.013771847208498025,
        "hf_subset": "eng_Latn-poe_Latn",
        "languages": [
          "eng-Latn",
          "poe-Latn"
        ],
        "main_score": 0.013771847208498025,
        "precision": 0.011822500785266744,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009158713954574717,
        "hf_subset": "poe_Latn-eng_Latn",
        "languages": [
          "poe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009158713954574717,
        "precision": 0.007522969052224371,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-poh_Latn",
        "languages": [
          "eng-Latn",
          "poh-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004185267857142857,
        "hf_subset": "poh_Latn-eng_Latn",
        "languages": [
          "poh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004185267857142857,
        "precision": 0.004050925925925926,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017392113095238096,
        "hf_subset": "eng_Latn-poi_Latn",
        "languages": [
          "eng-Latn",
          "poi-Latn"
        ],
        "main_score": 0.017392113095238096,
        "precision": 0.015505071271929825,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009281517094017094,
        "hf_subset": "poi_Latn-eng_Latn",
        "languages": [
          "poi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009281517094017094,
        "precision": 0.007324218749999999,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006451794733044733,
        "hf_subset": "eng_Latn-pol_Latn",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ],
        "main_score": 0.006451794733044733,
        "precision": 0.004112413194444445,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015707064075630252,
        "hf_subset": "pol_Latn-eng_Latn",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015707064075630252,
        "precision": 0.014185855263157895,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014186399157616263,
        "hf_subset": "eng_Latn-pon_Latn",
        "languages": [
          "eng-Latn",
          "pon-Latn"
        ],
        "main_score": 0.014186399157616263,
        "precision": 0.009612045940170939,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00572406045751634,
        "hf_subset": "pon_Latn-eng_Latn",
        "languages": [
          "pon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00572406045751634,
        "precision": 0.0037589201163419914,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.28125,
        "f1": 0.2086583772130647,
        "hf_subset": "eng_Latn-por_Latn",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ],
        "main_score": 0.2086583772130647,
        "precision": 0.18651427782287155,
        "recall": 0.28125
      },
      {
        "accuracy": 0.3515625,
        "f1": 0.28710035624098124,
        "hf_subset": "por_Latn-eng_Latn",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ],
        "main_score": 0.28710035624098124,
        "precision": 0.2660946800595238,
        "recall": 0.3515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006845238095238095,
        "hf_subset": "eng_Latn-poy_Latn",
        "languages": [
          "eng-Latn",
          "poy-Latn"
        ],
        "main_score": 0.006845238095238095,
        "precision": 0.004557291666666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "poy_Latn-eng_Latn",
        "languages": [
          "poy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010906779852092352,
        "hf_subset": "eng_Latn-ppo_Latn",
        "languages": [
          "eng-Latn",
          "ppo-Latn"
        ],
        "main_score": 0.010906779852092352,
        "precision": 0.008436908143939395,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004038665254237288,
        "hf_subset": "ppo_Latn-eng_Latn",
        "languages": [
          "ppo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004038665254237288,
        "precision": 0.0028017241379310344,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03515625,
        "hf_subset": "eng_Latn-prf_Latn",
        "languages": [
          "eng-Latn",
          "prf-Latn"
        ],
        "main_score": 0.03515625,
        "precision": 0.03261910232843137,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015079646915584414,
        "hf_subset": "prf_Latn-eng_Latn",
        "languages": [
          "prf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015079646915584414,
        "precision": 0.01166580815018315,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01734250992063492,
        "hf_subset": "eng_Latn-pri_Latn",
        "languages": [
          "eng-Latn",
          "pri-Latn"
        ],
        "main_score": 0.01734250992063492,
        "precision": 0.015203737745098039,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.014322916666666666,
        "hf_subset": "pri_Latn-eng_Latn",
        "languages": [
          "pri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014322916666666666,
        "precision": 0.013671875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025154532967032964,
        "hf_subset": "eng_Latn-ptp_Latn",
        "languages": [
          "eng-Latn",
          "ptp-Latn"
        ],
        "main_score": 0.025154532967032964,
        "precision": 0.0212890625,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0059694102112676055,
        "hf_subset": "ptp_Latn-eng_Latn",
        "languages": [
          "ptp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0059694102112676055,
        "precision": 0.005098417207792208,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.020717234262125902,
        "hf_subset": "eng_Latn-ptu_Latn",
        "languages": [
          "eng-Latn",
          "ptu-Latn"
        ],
        "main_score": 0.020717234262125902,
        "precision": 0.01593920358568796,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.03002717391304348,
        "hf_subset": "ptu_Latn-eng_Latn",
        "languages": [
          "ptu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03002717391304348,
        "precision": 0.028931897095959593,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02482638888888889,
        "hf_subset": "eng_Latn-pwg_Latn",
        "languages": [
          "eng-Latn",
          "pwg-Latn"
        ],
        "main_score": 0.02482638888888889,
        "precision": 0.02017144097222222,
        "recall": 0.046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.012369791666666668,
        "hf_subset": "pwg_Latn-eng_Latn",
        "languages": [
          "pwg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012369791666666668,
        "precision": 0.012073863636363636,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010320453612479474,
        "hf_subset": "eng_Latn-qub_Latn",
        "languages": [
          "eng-Latn",
          "qub-Latn"
        ],
        "main_score": 0.010320453612479474,
        "precision": 0.009290213178294574,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004526289682539682,
        "hf_subset": "qub_Latn-eng_Latn",
        "languages": [
          "qub-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004526289682539682,
        "precision": 0.0026386335784313727,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0027610844017094014,
        "hf_subset": "eng_Latn-quc_Latn",
        "languages": [
          "eng-Latn",
          "quc-Latn"
        ],
        "main_score": 0.0027610844017094014,
        "precision": 0.001514916992635062,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.003875655936716792,
        "hf_subset": "quc_Latn-eng_Latn",
        "languages": [
          "quc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003875655936716792,
        "precision": 0.002355557138635596,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007952008928571428,
        "hf_subset": "eng_Latn-quf_Latn",
        "languages": [
          "eng-Latn",
          "quf-Latn"
        ],
        "main_score": 0.007952008928571428,
        "precision": 0.006417410714285714,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "quf_Latn-eng_Latn",
        "languages": [
          "quf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020667251275510203,
        "hf_subset": "eng_Latn-quh_Latn",
        "languages": [
          "eng-Latn",
          "quh-Latn"
        ],
        "main_score": 0.020667251275510203,
        "precision": 0.019131425498188404,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012266147778555867,
        "hf_subset": "quh_Latn-eng_Latn",
        "languages": [
          "quh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012266147778555867,
        "precision": 0.009609170756159163,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02141593215811966,
        "hf_subset": "eng_Latn-qul_Latn",
        "languages": [
          "eng-Latn",
          "qul-Latn"
        ],
        "main_score": 0.02141593215811966,
        "precision": 0.01823815724206349,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00991639254385965,
        "hf_subset": "qul_Latn-eng_Latn",
        "languages": [
          "qul-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00991639254385965,
        "precision": 0.0076171875,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008282066637630661,
        "hf_subset": "eng_Latn-qup_Latn",
        "languages": [
          "eng-Latn",
          "qup-Latn"
        ],
        "main_score": 0.008282066637630661,
        "precision": 0.006101707175925926,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0055461480569239194,
        "hf_subset": "qup_Latn-eng_Latn",
        "languages": [
          "qup-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0055461480569239194,
        "precision": 0.00483249259005928,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00043402777777777775,
        "hf_subset": "eng_Latn-qvc_Latn",
        "languages": [
          "eng-Latn",
          "qvc-Latn"
        ],
        "main_score": 0.00043402777777777775,
        "precision": 0.00022977941176470588,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "qvc_Latn-eng_Latn",
        "languages": [
          "qvc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.013544528388278387,
        "hf_subset": "eng_Latn-qve_Latn",
        "languages": [
          "eng-Latn",
          "qve-Latn"
        ],
        "main_score": 0.013544528388278387,
        "precision": 0.010330862713675214,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019003395629084967,
        "hf_subset": "qve_Latn-eng_Latn",
        "languages": [
          "qve-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019003395629084967,
        "precision": 0.016422526041666666,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02140151515151515,
        "hf_subset": "eng_Latn-qvh_Latn",
        "languages": [
          "eng-Latn",
          "qvh-Latn"
        ],
        "main_score": 0.02140151515151515,
        "precision": 0.018428516634366926,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011588541666666667,
        "hf_subset": "qvh_Latn-eng_Latn",
        "languages": [
          "qvh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011588541666666667,
        "precision": 0.01016522988505747,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.024256234217171716,
        "hf_subset": "eng_Latn-qvm_Latn",
        "languages": [
          "eng-Latn",
          "qvm-Latn"
        ],
        "main_score": 0.024256234217171716,
        "precision": 0.02102441829004329,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013736979166666666,
        "hf_subset": "qvm_Latn-eng_Latn",
        "languages": [
          "qvm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013736979166666666,
        "precision": 0.010602678571428572,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01423329274891775,
        "hf_subset": "eng_Latn-qvn_Latn",
        "languages": [
          "eng-Latn",
          "qvn-Latn"
        ],
        "main_score": 0.01423329274891775,
        "precision": 0.013093828914141414,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007332785087719298,
        "hf_subset": "qvn_Latn-eng_Latn",
        "languages": [
          "qvn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007332785087719298,
        "precision": 0.004991319444444444,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011328125,
        "hf_subset": "eng_Latn-qvs_Latn",
        "languages": [
          "eng-Latn",
          "qvs-Latn"
        ],
        "main_score": 0.011328125,
        "precision": 0.007972301136363637,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0029660443722943726,
        "hf_subset": "qvs_Latn-eng_Latn",
        "languages": [
          "qvs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0029660443722943726,
        "precision": 0.0018092105263157895,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013020833333333333,
        "hf_subset": "eng_Latn-qvw_Latn",
        "languages": [
          "eng-Latn",
          "qvw-Latn"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.00078125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007634943181818182,
        "hf_subset": "qvw_Latn-eng_Latn",
        "languages": [
          "qvw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007634943181818182,
        "precision": 0.006175595238095239,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011067708333333332,
        "hf_subset": "eng_Latn-qvz_Latn",
        "languages": [
          "eng-Latn",
          "qvz-Latn"
        ],
        "main_score": 0.011067708333333332,
        "precision": 0.009895833333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006053057101414954,
        "hf_subset": "qvz_Latn-eng_Latn",
        "languages": [
          "qvz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006053057101414954,
        "precision": 0.003958953373015873,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009242702762923351,
        "hf_subset": "eng_Latn-qwh_Latn",
        "languages": [
          "eng-Latn",
          "qwh-Latn"
        ],
        "main_score": 0.009242702762923351,
        "precision": 0.007470703125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009114583333333332,
        "hf_subset": "qwh_Latn-eng_Latn",
        "languages": [
          "qwh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009114583333333332,
        "precision": 0.006569602272727273,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015755208333333333,
        "hf_subset": "eng_Latn-qxh_Latn",
        "languages": [
          "eng-Latn",
          "qxh-Latn"
        ],
        "main_score": 0.015755208333333333,
        "precision": 0.012044270833333332,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011400440858161446,
        "hf_subset": "qxh_Latn-eng_Latn",
        "languages": [
          "qxh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011400440858161446,
        "precision": 0.009079706101190476,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.030303819444444442,
        "hf_subset": "eng_Latn-qxn_Latn",
        "languages": [
          "eng-Latn",
          "qxn-Latn"
        ],
        "main_score": 0.030303819444444442,
        "precision": 0.02558785232843137,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.012326670725108223,
        "hf_subset": "qxn_Latn-eng_Latn",
        "languages": [
          "qxn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012326670725108223,
        "precision": 0.009373255806472603,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.016214037698412696,
        "hf_subset": "eng_Latn-qxo_Latn",
        "languages": [
          "eng-Latn",
          "qxo-Latn"
        ],
        "main_score": 0.016214037698412696,
        "precision": 0.012898137019230769,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.011074049648268398,
        "hf_subset": "qxo_Latn-eng_Latn",
        "languages": [
          "qxo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011074049648268398,
        "precision": 0.00832594756652661,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.025520833333333336,
        "hf_subset": "eng_Latn-rai_Latn",
        "languages": [
          "eng-Latn",
          "rai-Latn"
        ],
        "main_score": 0.025520833333333336,
        "precision": 0.02268099547511312,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.025390625,
        "hf_subset": "rai_Latn-eng_Latn",
        "languages": [
          "rai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.025390625,
        "precision": 0.024619654605263157,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021104600694444444,
        "hf_subset": "eng_Latn-reg_Latn",
        "languages": [
          "eng-Latn",
          "reg-Latn"
        ],
        "main_score": 0.021104600694444444,
        "precision": 0.01921968005952381,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.022214114010989012,
        "hf_subset": "reg_Latn-eng_Latn",
        "languages": [
          "reg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.022214114010989012,
        "precision": 0.019113051470588234,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011607142857142858,
        "hf_subset": "eng_Latn-rgu_Latn",
        "languages": [
          "eng-Latn",
          "rgu-Latn"
        ],
        "main_score": 0.011607142857142858,
        "precision": 0.010091145833333332,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.003347393644957983,
        "hf_subset": "rgu_Latn-eng_Latn",
        "languages": [
          "rgu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003347393644957983,
        "precision": 0.002341986217775548,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001761642156862745,
        "hf_subset": "eng_Latn-rkb_Latn",
        "languages": [
          "eng-Latn",
          "rkb-Latn"
        ],
        "main_score": 0.001761642156862745,
        "precision": 0.001025390625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0010187596450617284,
        "hf_subset": "rkb_Latn-eng_Latn",
        "languages": [
          "rkb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010187596450617284,
        "precision": 0.0005390242034313726,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.023616096565315315,
        "hf_subset": "eng_Latn-rmc_Latn",
        "languages": [
          "eng-Latn",
          "rmc-Latn"
        ],
        "main_score": 0.023616096565315315,
        "precision": 0.020985243055555554,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.020185352991118077,
        "hf_subset": "rmc_Latn-eng_Latn",
        "languages": [
          "rmc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020185352991118077,
        "precision": 0.015454489087301588,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013415287990196078,
        "hf_subset": "eng_Latn-rmy_Latn",
        "languages": [
          "eng-Latn",
          "rmy-Latn"
        ],
        "main_score": 0.013415287990196078,
        "precision": 0.010505123414855072,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01784928902116402,
        "hf_subset": "rmy_Latn-eng_Latn",
        "languages": [
          "rmy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01784928902116402,
        "precision": 0.015861463246855348,
        "recall": 0.03125
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.10335006248092185,
        "hf_subset": "eng_Latn-ron_Latn",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ],
        "main_score": 0.10335006248092185,
        "precision": 0.09069322422280959,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.0964613835157409,
        "hf_subset": "ron_Latn-eng_Latn",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0964613835157409,
        "precision": 0.08632967509920635,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004427083333333333,
        "hf_subset": "eng_Latn-roo_Latn",
        "languages": [
          "eng-Latn",
          "roo-Latn"
        ],
        "main_score": 0.004427083333333333,
        "precision": 0.0027684577455590388,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012467447916666666,
        "hf_subset": "roo_Latn-eng_Latn",
        "languages": [
          "roo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012467447916666666,
        "precision": 0.011002604166666666,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02220714433416046,
        "hf_subset": "eng_Latn-rop_Latn",
        "languages": [
          "eng-Latn",
          "rop-Latn"
        ],
        "main_score": 0.02220714433416046,
        "precision": 0.01849407327586207,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01438344995256167,
        "hf_subset": "rop_Latn-eng_Latn",
        "languages": [
          "rop-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01438344995256167,
        "precision": 0.013395182291666667,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0189453125,
        "hf_subset": "eng_Latn-row_Latn",
        "languages": [
          "eng-Latn",
          "row-Latn"
        ],
        "main_score": 0.0189453125,
        "precision": 0.015119667658730157,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009557291666666665,
        "hf_subset": "row_Latn-eng_Latn",
        "languages": [
          "row-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009557291666666665,
        "precision": 0.008881306732869233,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009679472117794486,
        "hf_subset": "eng_Latn-rro_Latn",
        "languages": [
          "eng-Latn",
          "rro-Latn"
        ],
        "main_score": 0.009679472117794486,
        "precision": 0.007531693566849816,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0081338328460039,
        "hf_subset": "rro_Latn-eng_Latn",
        "languages": [
          "rro-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0081338328460039,
        "precision": 0.00640815845893971,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008984375,
        "hf_subset": "eng_Latn-ruf_Latn",
        "languages": [
          "eng-Latn",
          "ruf-Latn"
        ],
        "main_score": 0.008984375,
        "precision": 0.007298820970695971,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01488095238095238,
        "hf_subset": "ruf_Latn-eng_Latn",
        "languages": [
          "ruf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01488095238095238,
        "precision": 0.01367642773892774,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021527777777777778,
        "hf_subset": "eng_Latn-rug_Latn",
        "languages": [
          "eng-Latn",
          "rug-Latn"
        ],
        "main_score": 0.021527777777777778,
        "precision": 0.01953125,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006530145202020202,
        "hf_subset": "rug_Latn-eng_Latn",
        "languages": [
          "rug-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006530145202020202,
        "precision": 0.005560183057598039,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008227449633699634,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.008227449633699634,
        "precision": 0.0056640625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005715543426358234,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.005715543426358234,
        "precision": 0.0049472994140477445,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008494543650793652,
        "hf_subset": "eng_Latn-rwo_Latn",
        "languages": [
          "eng-Latn",
          "rwo-Latn"
        ],
        "main_score": 0.008494543650793652,
        "precision": 0.006998697916666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0010767227564102565,
        "hf_subset": "rwo_Latn-eng_Latn",
        "languages": [
          "rwo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010767227564102565,
        "precision": 0.0006087662337662338,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01181640625,
        "hf_subset": "eng_Latn-sab_Latn",
        "languages": [
          "eng-Latn",
          "sab-Latn"
        ],
        "main_score": 0.01181640625,
        "precision": 0.010596321202531647,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011116747835497834,
        "hf_subset": "sab_Latn-eng_Latn",
        "languages": [
          "sab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011116747835497834,
        "precision": 0.010138443732193733,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004138764880952381,
        "hf_subset": "eng_Latn-san_Latn",
        "languages": [
          "eng-Latn",
          "san-Latn"
        ],
        "main_score": 0.004138764880952381,
        "precision": 0.002553651059085842,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0005453067974452555,
        "hf_subset": "san_Latn-eng_Latn",
        "languages": [
          "san-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005453067974452555,
        "precision": 0.0002891390931372549,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01556205220812779,
        "hf_subset": "eng_Latn-sbe_Latn",
        "languages": [
          "eng-Latn",
          "sbe-Latn"
        ],
        "main_score": 0.01556205220812779,
        "precision": 0.01312468998015873,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007906626506024098,
        "hf_subset": "sbe_Latn-eng_Latn",
        "languages": [
          "sbe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007906626506024098,
        "precision": 0.007860137195121951,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013997395833333332,
        "hf_subset": "eng_Latn-sbk_Latn",
        "languages": [
          "eng-Latn",
          "sbk-Latn"
        ],
        "main_score": 0.013997395833333332,
        "precision": 0.012276785714285714,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010807291666666666,
        "hf_subset": "sbk_Latn-eng_Latn",
        "languages": [
          "sbk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010807291666666666,
        "precision": 0.008278508771929824,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01712239583333333,
        "hf_subset": "eng_Latn-sbs_Latn",
        "languages": [
          "eng-Latn",
          "sbs-Latn"
        ],
        "main_score": 0.01712239583333333,
        "precision": 0.013988095238095237,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008955627705627705,
        "hf_subset": "sbs_Latn-eng_Latn",
        "languages": [
          "sbs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008955627705627705,
        "precision": 0.007025435273790537,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022352430555555552,
        "hf_subset": "eng_Latn-seh_Latn",
        "languages": [
          "eng-Latn",
          "seh-Latn"
        ],
        "main_score": 0.022352430555555552,
        "precision": 0.020149739583333333,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01068046536796537,
        "hf_subset": "seh_Latn-eng_Latn",
        "languages": [
          "seh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01068046536796537,
        "precision": 0.009489889705882354,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.018883590367965365,
        "hf_subset": "eng_Latn-sey_Latn",
        "languages": [
          "eng-Latn",
          "sey-Latn"
        ],
        "main_score": 0.018883590367965365,
        "precision": 0.015134862930148946,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018471756611027755,
        "hf_subset": "sey_Latn-eng_Latn",
        "languages": [
          "sey-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018471756611027755,
        "precision": 0.01731664105191257,
        "recall": 0.03125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.030876876120071683,
        "hf_subset": "eng_Latn-sgb_Latn",
        "languages": [
          "eng-Latn",
          "sgb-Latn"
        ],
        "main_score": 0.030876876120071683,
        "precision": 0.027477541349531613,
        "recall": 0.046875
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.021306259827044025,
        "hf_subset": "sgb_Latn-eng_Latn",
        "languages": [
          "sgb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021306259827044025,
        "precision": 0.018110665376290375,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.019910037878787878,
        "hf_subset": "eng_Latn-sgz_Latn",
        "languages": [
          "eng-Latn",
          "sgz-Latn"
        ],
        "main_score": 0.019910037878787878,
        "precision": 0.0173828125,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013089037698412699,
        "hf_subset": "sgz_Latn-eng_Latn",
        "languages": [
          "sgz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013089037698412699,
        "precision": 0.012466596881808279,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.04395604395604396,
        "f1": 0.01813186813186813,
        "hf_subset": "eng_Latn-shj_Latn",
        "languages": [
          "eng-Latn",
          "shj-Latn"
        ],
        "main_score": 0.01813186813186813,
        "precision": 0.012009419152276296,
        "recall": 0.04395604395604396
      },
      {
        "accuracy": 0.054945054945054944,
        "f1": 0.024661011503116764,
        "hf_subset": "shj_Latn-eng_Latn",
        "languages": [
          "shj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024661011503116764,
        "precision": 0.020037502180359323,
        "recall": 0.054945054945054944
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010725277326839828,
        "hf_subset": "eng_Latn-shp_Latn",
        "languages": [
          "eng-Latn",
          "shp-Latn"
        ],
        "main_score": 0.010725277326839828,
        "precision": 0.009470432194616976,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0064453125,
        "hf_subset": "shp_Latn-eng_Latn",
        "languages": [
          "shp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0064453125,
        "precision": 0.004401607789855072,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006975446428571428,
        "hf_subset": "eng_Latn-sim_Latn",
        "languages": [
          "eng-Latn",
          "sim-Latn"
        ],
        "main_score": 0.006975446428571428,
        "precision": 0.0046875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006119791666666666,
        "hf_subset": "sim_Latn-eng_Latn",
        "languages": [
          "sim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006119791666666666,
        "precision": 0.004231770833333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017903645833333332,
        "hf_subset": "eng_Latn-sja_Latn",
        "languages": [
          "eng-Latn",
          "sja-Latn"
        ],
        "main_score": 0.017903645833333332,
        "precision": 0.01488095238095238,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.004239004629629629,
        "hf_subset": "sja_Latn-eng_Latn",
        "languages": [
          "sja-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004239004629629629,
        "precision": 0.002670266479042764,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00045955882352941176,
        "hf_subset": "eng_Latn-sll_Latn",
        "languages": [
          "eng-Latn",
          "sll-Latn"
        ],
        "main_score": 0.00045955882352941176,
        "precision": 0.000244140625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "sll_Latn-eng_Latn",
        "languages": [
          "sll-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.030154736682808714,
        "hf_subset": "eng_Latn-smk_Latn",
        "languages": [
          "eng-Latn",
          "smk-Latn"
        ],
        "main_score": 0.030154736682808714,
        "precision": 0.0266949533045977,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01248857821637427,
        "hf_subset": "smk_Latn-eng_Latn",
        "languages": [
          "smk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01248857821637427,
        "precision": 0.010705517426565218,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015373883928571428,
        "hf_subset": "eng_Latn-snc_Latn",
        "languages": [
          "eng-Latn",
          "snc-Latn"
        ],
        "main_score": 0.015373883928571428,
        "precision": 0.01390438988095238,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007040355477855477,
        "hf_subset": "snc_Latn-eng_Latn",
        "languages": [
          "snc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007040355477855477,
        "precision": 0.004622395833333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016329025057603686,
        "hf_subset": "eng_Latn-snn_Latn",
        "languages": [
          "eng-Latn",
          "snn-Latn"
        ],
        "main_score": 0.016329025057603686,
        "precision": 0.014522879464285716,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005533854166666666,
        "hf_subset": "snn_Latn-eng_Latn",
        "languages": [
          "snn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005533854166666666,
        "precision": 0.003693315319548872,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008950077700077701,
        "hf_subset": "eng_Latn-snp_Latn",
        "languages": [
          "eng-Latn",
          "snp-Latn"
        ],
        "main_score": 0.008950077700077701,
        "precision": 0.006868489583333333,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0018446180555555555,
        "hf_subset": "snp_Latn-eng_Latn",
        "languages": [
          "snp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0018446180555555555,
        "precision": 0.0010463169642857143,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.09285714285714286,
        "f1": 0.04704431417957254,
        "hf_subset": "eng_Latn-snx_Latn",
        "languages": [
          "eng-Latn",
          "snx-Latn"
        ],
        "main_score": 0.04704431417957254,
        "precision": 0.038259020999704234,
        "recall": 0.09285714285714286
      },
      {
        "accuracy": 0.07857142857142857,
        "f1": 0.0351479308026163,
        "hf_subset": "snx_Latn-eng_Latn",
        "languages": [
          "snx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0351479308026163,
        "precision": 0.029997165532879816,
        "recall": 0.07857142857142857
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011292880639097745,
        "hf_subset": "eng_Latn-sny_Latn",
        "languages": [
          "eng-Latn",
          "sny-Latn"
        ],
        "main_score": 0.011292880639097745,
        "precision": 0.009982638888888888,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013770767405063292,
        "hf_subset": "sny_Latn-eng_Latn",
        "languages": [
          "sny-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013770767405063292,
        "precision": 0.013070913461538462,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006510416666666666,
        "hf_subset": "eng_Latn-som_Latn",
        "languages": [
          "eng-Latn",
          "som-Latn"
        ],
        "main_score": 0.0006510416666666666,
        "precision": 0.0003551136363636364,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0036374327956989246,
        "hf_subset": "som_Latn-eng_Latn",
        "languages": [
          "som-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0036374327956989246,
        "precision": 0.002517361111111111,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "eng_Latn-soq_Latn",
        "languages": [
          "eng-Latn",
          "soq-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010068951231060606,
        "hf_subset": "soq_Latn-eng_Latn",
        "languages": [
          "soq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010068951231060606,
        "precision": 0.00832913306451613,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009765625,
        "hf_subset": "eng_Latn-soy_Latn",
        "languages": [
          "eng-Latn",
          "soy-Latn"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0005580357142857143,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "soy_Latn-eng_Latn",
        "languages": [
          "soy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.3984375,
        "f1": 0.32687136316502124,
        "hf_subset": "eng_Latn-spa_Latn",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ],
        "main_score": 0.32687136316502124,
        "precision": 0.30430850074404764,
        "recall": 0.3984375
      },
      {
        "accuracy": 0.4375,
        "f1": 0.3550474048520924,
        "hf_subset": "spa_Latn-eng_Latn",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3550474048520924,
        "precision": 0.32787853422619045,
        "recall": 0.4375
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-spl_Latn",
        "languages": [
          "eng-Latn",
          "spl-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00015024038461538462,
        "hf_subset": "spl_Latn-eng_Latn",
        "languages": [
          "spl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00015024038461538462,
        "precision": 7.659313725490196e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.040829613095238096,
        "hf_subset": "eng_Latn-spm_Latn",
        "languages": [
          "eng-Latn",
          "spm-Latn"
        ],
        "main_score": 0.040829613095238096,
        "precision": 0.0390625,
        "recall": 0.046875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03154911494755244,
        "hf_subset": "spm_Latn-eng_Latn",
        "languages": [
          "spm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03154911494755244,
        "precision": 0.027532499424526184,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004507211538461538,
        "hf_subset": "eng_Latn-spp_Latn",
        "languages": [
          "eng-Latn",
          "spp-Latn"
        ],
        "main_score": 0.004507211538461538,
        "precision": 0.004231770833333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0005580357142857143,
        "hf_subset": "spp_Latn-eng_Latn",
        "languages": [
          "spp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0005580357142857143,
        "precision": 0.00030048076923076925,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005921375921375921,
        "hf_subset": "eng_Latn-sps_Latn",
        "languages": [
          "eng-Latn",
          "sps-Latn"
        ],
        "main_score": 0.005921375921375921,
        "precision": 0.005002170138888889,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006070523648648648,
        "hf_subset": "sps_Latn-eng_Latn",
        "languages": [
          "sps-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006070523648648648,
        "precision": 0.005316840277777777,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003205128205128205,
        "hf_subset": "eng_Latn-spy_Latn",
        "languages": [
          "eng-Latn",
          "spy-Latn"
        ],
        "main_score": 0.003205128205128205,
        "precision": 0.0022786458333333335,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005126953125,
        "hf_subset": "spy_Latn-eng_Latn",
        "languages": [
          "spy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005126953125,
        "precision": 0.004590293778801843,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017274305555555557,
        "hf_subset": "eng_Latn-sri_Latn",
        "languages": [
          "eng-Latn",
          "sri-Latn"
        ],
        "main_score": 0.017274305555555557,
        "precision": 0.014594184027777778,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "sri_Latn-eng_Latn",
        "languages": [
          "sri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016316344246031747,
        "hf_subset": "eng_Latn-srm_Latn",
        "languages": [
          "eng-Latn",
          "srm-Latn"
        ],
        "main_score": 0.016316344246031747,
        "precision": 0.01360927483974359,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00954483695652174,
        "hf_subset": "srm_Latn-eng_Latn",
        "languages": [
          "srm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00954483695652174,
        "precision": 0.008875868055555555,
        "recall": 0.015625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.045731026785714286,
        "hf_subset": "eng_Latn-srn_Latn",
        "languages": [
          "eng-Latn",
          "srn-Latn"
        ],
        "main_score": 0.045731026785714286,
        "precision": 0.03768666952260702,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.030618990384615383,
        "hf_subset": "srn_Latn-eng_Latn",
        "languages": [
          "srn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.030618990384615383,
        "precision": 0.027178527661064426,
        "recall": 0.046875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010462225819238901,
        "hf_subset": "eng_Latn-srp_Latn",
        "languages": [
          "eng-Latn",
          "srp-Latn"
        ],
        "main_score": 0.010462225819238901,
        "precision": 0.008248954020013802,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.020100144698030727,
        "hf_subset": "srp_Latn-eng_Latn",
        "languages": [
          "srp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020100144698030727,
        "precision": 0.015968191964285713,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019387415213178293,
        "hf_subset": "eng_Latn-srq_Latn",
        "languages": [
          "eng-Latn",
          "srq-Latn"
        ],
        "main_score": 0.019387415213178293,
        "precision": 0.018229166666666668,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009765625,
        "hf_subset": "srq_Latn-eng_Latn",
        "languages": [
          "srq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.006640625,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.017260514018691588,
        "hf_subset": "eng_Latn-ssd_Latn",
        "languages": [
          "eng-Latn",
          "ssd-Latn"
        ],
        "main_score": 0.017260514018691588,
        "precision": 0.01663841391509434,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0037781879578754575,
        "hf_subset": "ssd_Latn-eng_Latn",
        "languages": [
          "ssd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0037781879578754575,
        "precision": 0.0026111758109040716,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019460752071204655,
        "hf_subset": "eng_Latn-ssg_Latn",
        "languages": [
          "eng-Latn",
          "ssg-Latn"
        ],
        "main_score": 0.019460752071204655,
        "precision": 0.016863141741071428,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014583333333333332,
        "hf_subset": "ssg_Latn-eng_Latn",
        "languages": [
          "ssg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014583333333333332,
        "precision": 0.0126953125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01171875,
        "hf_subset": "eng_Latn-ssx_Latn",
        "languages": [
          "eng-Latn",
          "ssx-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.010546875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0029563728749478517,
        "hf_subset": "ssx_Latn-eng_Latn",
        "languages": [
          "ssx-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0029563728749478517,
        "precision": 0.0018345424107142857,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005065724206349207,
        "hf_subset": "eng_Latn-stp_Latn",
        "languages": [
          "eng-Latn",
          "stp-Latn"
        ],
        "main_score": 0.005065724206349207,
        "precision": 0.003159466911764706,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006843813004032258,
        "hf_subset": "stp_Latn-eng_Latn",
        "languages": [
          "stp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006843813004032258,
        "precision": 0.006030701754385965,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "eng_Latn-sua_Latn",
        "languages": [
          "eng-Latn",
          "sua-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0033645669806384093,
        "hf_subset": "sua_Latn-eng_Latn",
        "languages": [
          "sua-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0033645669806384093,
        "precision": 0.0023600260416666665,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018012152777777776,
        "hf_subset": "eng_Latn-sue_Latn",
        "languages": [
          "eng-Latn",
          "sue-Latn"
        ],
        "main_score": 0.018012152777777776,
        "precision": 0.015873579545454545,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.016354955808080808,
        "hf_subset": "sue_Latn-eng_Latn",
        "languages": [
          "sue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016354955808080808,
        "precision": 0.015013818027210885,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00015943877551020407,
        "hf_subset": "eng_Latn-sus_Arab",
        "languages": [
          "eng-Latn",
          "sus-Arab"
        ],
        "main_score": 0.00015943877551020407,
        "precision": 8.138020833333333e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0029429883512544805,
        "hf_subset": "sus_Arab-eng_Latn",
        "languages": [
          "sus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0029429883512544805,
        "precision": 0.0021272237827715357,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005867533416875522,
        "hf_subset": "eng_Latn-suz_Latn",
        "languages": [
          "eng-Latn",
          "suz-Latn"
        ],
        "main_score": 0.005867533416875522,
        "precision": 0.003702001633986928,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "suz_Latn-eng_Latn",
        "languages": [
          "suz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.055253648999493414,
        "hf_subset": "eng_Latn-swe_Latn",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ],
        "main_score": 0.055253648999493414,
        "precision": 0.04875493335921325,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.04992229992229992,
        "hf_subset": "swe_Latn-eng_Latn",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04992229992229992,
        "precision": 0.04356398809523809,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.015075787927350428,
        "hf_subset": "eng_Latn-swh_Latn",
        "languages": [
          "eng-Latn",
          "swh-Latn"
        ],
        "main_score": 0.015075787927350428,
        "precision": 0.01029110863095238,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009905133928571428,
        "hf_subset": "swh_Latn-eng_Latn",
        "languages": [
          "swh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009905133928571428,
        "precision": 0.007982336956521738,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.02727434257285004,
        "hf_subset": "eng_Latn-swp_Latn",
        "languages": [
          "eng-Latn",
          "swp-Latn"
        ],
        "main_score": 0.02727434257285004,
        "precision": 0.023626893939393937,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00988343253968254,
        "hf_subset": "swp_Latn-eng_Latn",
        "languages": [
          "swp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00988343253968254,
        "precision": 0.007670255602240896,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013603193681318682,
        "hf_subset": "eng_Latn-sxb_Latn",
        "languages": [
          "eng-Latn",
          "sxb-Latn"
        ],
        "main_score": 0.013603193681318682,
        "precision": 0.011368189102564102,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010026041666666666,
        "hf_subset": "sxb_Latn-eng_Latn",
        "languages": [
          "sxb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010026041666666666,
        "precision": 0.008138020833333332,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0077008928571428575,
        "hf_subset": "eng_Latn-tac_Latn",
        "languages": [
          "eng-Latn",
          "tac-Latn"
        ],
        "main_score": 0.0077008928571428575,
        "precision": 0.006329571759259259,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0004926108374384236,
        "hf_subset": "tac_Latn-eng_Latn",
        "languages": [
          "tac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0004926108374384236,
        "precision": 0.0002543986344537815,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002773268398268398,
        "hf_subset": "eng_Latn-taj_Deva",
        "languages": [
          "eng-Latn",
          "taj-Deva"
        ],
        "main_score": 0.002773268398268398,
        "precision": 0.0016183035714285713,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002325317604355717,
        "hf_subset": "taj_Deva-eng_Latn",
        "languages": [
          "taj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.002325317604355717,
        "precision": 0.0014936755952380952,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005334821428571428,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.005334821428571428,
        "precision": 0.004720052083333334,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.001171875,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.001171875,
        "precision": 0.0006110687013894132,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02489035087719298,
        "hf_subset": "eng_Latn-tav_Latn",
        "languages": [
          "eng-Latn",
          "tav-Latn"
        ],
        "main_score": 0.02489035087719298,
        "precision": 0.021809895833333332,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005208333333333333,
        "hf_subset": "tav_Latn-eng_Latn",
        "languages": [
          "tav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.00390625,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014503380847953216,
        "hf_subset": "eng_Latn-taw_Latn",
        "languages": [
          "eng-Latn",
          "taw-Latn"
        ],
        "main_score": 0.014503380847953216,
        "precision": 0.012343804709383753,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016577743902439026,
        "hf_subset": "taw_Latn-eng_Latn",
        "languages": [
          "taw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0016577743902439026,
        "precision": 0.0010247878086419753,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0076832261762360445,
        "hf_subset": "eng_Latn-tbc_Latn",
        "languages": [
          "eng-Latn",
          "tbc-Latn"
        ],
        "main_score": 0.0076832261762360445,
        "precision": 0.0062267485119047615,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0011941964285714286,
        "hf_subset": "tbc_Latn-eng_Latn",
        "languages": [
          "tbc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011941964285714286,
        "precision": 0.0006904987373737374,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019713684752747252,
        "hf_subset": "eng_Latn-tbf_Latn",
        "languages": [
          "eng-Latn",
          "tbf-Latn"
        ],
        "main_score": 0.019713684752747252,
        "precision": 0.016809037316849816,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005720766129032258,
        "hf_subset": "tbf_Latn-eng_Latn",
        "languages": [
          "tbf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005720766129032258,
        "precision": 0.005013020833333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.018055555555555554,
        "hf_subset": "eng_Latn-tbg_Latn",
        "languages": [
          "eng-Latn",
          "tbg-Latn"
        ],
        "main_score": 0.018055555555555554,
        "precision": 0.01708984375,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008380565767973856,
        "hf_subset": "tbg_Latn-eng_Latn",
        "languages": [
          "tbg-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008380565767973856,
        "precision": 0.008111658230633803,
        "recall": 0.015625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02682553991147741,
        "hf_subset": "eng_Latn-tbo_Latn",
        "languages": [
          "eng-Latn",
          "tbo-Latn"
        ],
        "main_score": 0.02682553991147741,
        "precision": 0.02292323179271708,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017940848214285713,
        "hf_subset": "tbo_Latn-eng_Latn",
        "languages": [
          "tbo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.017940848214285713,
        "precision": 0.015830328525641025,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009114583333333332,
        "hf_subset": "eng_Latn-tbz_Latn",
        "languages": [
          "eng-Latn",
          "tbz-Latn"
        ],
        "main_score": 0.009114583333333332,
        "precision": 0.0078125,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015625,
        "hf_subset": "tbz_Latn-eng_Latn",
        "languages": [
          "tbz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0015625,
        "precision": 0.0009765625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006316137566137566,
        "hf_subset": "eng_Latn-tca_Latn",
        "languages": [
          "eng-Latn",
          "tca-Latn"
        ],
        "main_score": 0.006316137566137566,
        "precision": 0.005333533653846154,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0009818412162162162,
        "hf_subset": "tca_Latn-eng_Latn",
        "languages": [
          "tca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0009818412162162162,
        "precision": 0.0005357467685327855,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.018689827967171717,
        "hf_subset": "eng_Latn-tcs_Latn",
        "languages": [
          "eng-Latn",
          "tcs-Latn"
        ],
        "main_score": 0.018689827967171717,
        "precision": 0.014878216911764705,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01427486359126984,
        "hf_subset": "tcs_Latn-eng_Latn",
        "languages": [
          "tcs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01427486359126984,
        "precision": 0.011655118977259935,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04459362252331002,
        "hf_subset": "eng_Latn-tcz_Latn",
        "languages": [
          "eng-Latn",
          "tcz-Latn"
        ],
        "main_score": 0.04459362252331002,
        "precision": 0.03938585790420819,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.03085345643939394,
        "hf_subset": "tcz_Latn-eng_Latn",
        "languages": [
          "tcz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03085345643939394,
        "precision": 0.02687872023809524,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.025986763152841784,
        "hf_subset": "eng_Latn-tdt_Latn",
        "languages": [
          "eng-Latn",
          "tdt-Latn"
        ],
        "main_score": 0.025986763152841784,
        "precision": 0.022575363005050503,
        "recall": 0.046875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.021339710636585636,
        "hf_subset": "tdt_Latn-eng_Latn",
        "languages": [
          "tdt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.021339710636585636,
        "precision": 0.01751536151319502,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.014623397435897436,
        "hf_subset": "eng_Latn-tee_Latn",
        "languages": [
          "eng-Latn",
          "tee-Latn"
        ],
        "main_score": 0.014623397435897436,
        "precision": 0.013828125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.004963653346328785,
        "hf_subset": "tee_Latn-eng_Latn",
        "languages": [
          "tee-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004963653346328785,
        "precision": 0.0033457698985042733,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006315949675324675,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.006315949675324675,
        "precision": 0.005443852282515073,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0043359374999999995,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.0043359374999999995,
        "precision": 0.0026703085296835294,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006998697916666666,
        "hf_subset": "eng_Latn-ter_Latn",
        "languages": [
          "eng-Latn",
          "ter-Latn"
        ],
        "main_score": 0.006998697916666666,
        "precision": 0.006119791666666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "ter_Latn-eng_Latn",
        "languages": [
          "ter-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014885179924242422,
        "hf_subset": "eng_Latn-tet_Latn",
        "languages": [
          "eng-Latn",
          "tet-Latn"
        ],
        "main_score": 0.014885179924242422,
        "precision": 0.011747814360119048,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010677083333333332,
        "hf_subset": "tet_Latn-eng_Latn",
        "languages": [
          "tet-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010677083333333332,
        "precision": 0.0087890625,
        "recall": 0.015625
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.09301336684149183,
        "hf_subset": "eng_Latn-tew_Latn",
        "languages": [
          "eng-Latn",
          "tew-Latn"
        ],
        "main_score": 0.09301336684149183,
        "precision": 0.08725987554112555,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07126828385178904,
        "hf_subset": "tew_Latn-eng_Latn",
        "languages": [
          "tew-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07126828385178904,
        "precision": 0.06548665364583334,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008993487863925046,
        "hf_subset": "eng_Latn-tfr_Latn",
        "languages": [
          "eng-Latn",
          "tfr-Latn"
        ],
        "main_score": 0.008993487863925046,
        "precision": 0.007433748000336785,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01072766551796157,
        "hf_subset": "tfr_Latn-eng_Latn",
        "languages": [
          "tfr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01072766551796157,
        "precision": 0.00952759400025025,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015625,
        "hf_subset": "eng_Latn-tgk_Cyrl",
        "languages": [
          "eng-Latn",
          "tgk-Cyrl"
        ],
        "main_score": 0.0015625,
        "precision": 0.0009765625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.000373637611437269,
        "hf_subset": "tgk_Cyrl-eng_Latn",
        "languages": [
          "tgk-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.000373637611437269,
        "precision": 0.0001900951343251795,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03767206101190476,
        "hf_subset": "eng_Latn-tgl_Latn",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ],
        "main_score": 0.03767206101190476,
        "precision": 0.03377916824974671,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03815104166666666,
        "hf_subset": "tgl_Latn-eng_Latn",
        "languages": [
          "tgl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03815104166666666,
        "precision": 0.03731496710526316,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010498046875,
        "hf_subset": "eng_Latn-tgo_Latn",
        "languages": [
          "eng-Latn",
          "tgo-Latn"
        ],
        "main_score": 0.010498046875,
        "precision": 0.009501008064516129,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0028044871794871795,
        "hf_subset": "tgo_Latn-eng_Latn",
        "languages": [
          "tgo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0028044871794871795,
        "precision": 0.002055921052631579,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07657845438076416,
        "hf_subset": "eng_Latn-tgp_Latn",
        "languages": [
          "eng-Latn",
          "tgp-Latn"
        ],
        "main_score": 0.07657845438076416,
        "precision": 0.07225748697916666,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.05056893338143338,
        "hf_subset": "tgp_Latn-eng_Latn",
        "languages": [
          "tgp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05056893338143338,
        "precision": 0.0420168698489011,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013822115384615385,
        "hf_subset": "eng_Latn-tha_Thai",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ],
        "main_score": 0.0013822115384615385,
        "precision": 0.000759548611111111,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 3.7380382775119616e-05,
        "hf_subset": "tha_Thai-eng_Latn",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ],
        "main_score": 3.7380382775119616e-05,
        "precision": 1.8780048076923078e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01404389880952381,
        "hf_subset": "eng_Latn-tif_Latn",
        "languages": [
          "eng-Latn",
          "tif-Latn"
        ],
        "main_score": 0.01404389880952381,
        "precision": 0.013216145833333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006504945728291317,
        "hf_subset": "tif_Latn-eng_Latn",
        "languages": [
          "tif-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006504945728291317,
        "precision": 0.005547748348577236,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007508680555555556,
        "hf_subset": "eng_Latn-tim_Latn",
        "languages": [
          "eng-Latn",
          "tim-Latn"
        ],
        "main_score": 0.007508680555555556,
        "precision": 0.006130642361111111,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003983601485148515,
        "hf_subset": "tim_Latn-eng_Latn",
        "languages": [
          "tim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003983601485148515,
        "precision": 0.0039453125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.12093023255813953,
        "f1": 0.07983019564414914,
        "hf_subset": "eng_Latn-tiw_Latn",
        "languages": [
          "eng-Latn",
          "tiw-Latn"
        ],
        "main_score": 0.07983019564414914,
        "precision": 0.07028994261552401,
        "recall": 0.12093023255813953
      },
      {
        "accuracy": 0.08837209302325581,
        "f1": 0.05658101279888306,
        "hf_subset": "tiw_Latn-eng_Latn",
        "languages": [
          "tiw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05658101279888306,
        "precision": 0.05074750830564784,
        "recall": 0.08837209302325581
      },
      {
        "accuracy": 0.015625,
        "f1": 0.013020833333333332,
        "hf_subset": "eng_Latn-tiy_Latn",
        "languages": [
          "eng-Latn",
          "tiy-Latn"
        ],
        "main_score": 0.013020833333333332,
        "precision": 0.01171875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0074972587719298244,
        "hf_subset": "tiy_Latn-eng_Latn",
        "languages": [
          "tiy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0074972587719298244,
        "precision": 0.006398977102102102,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.02608695652173913,
        "hf_subset": "eng_Latn-tke_Latn",
        "languages": [
          "eng-Latn",
          "tke-Latn"
        ],
        "main_score": 0.02608695652173913,
        "precision": 0.024456521739130436,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.043478260869565216,
        "f1": 0.012000439174352218,
        "hf_subset": "tke_Latn-eng_Latn",
        "languages": [
          "tke-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012000439174352218,
        "precision": 0.007276570048309179,
        "recall": 0.043478260869565216
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012125651041666666,
        "hf_subset": "eng_Latn-tku_Latn",
        "languages": [
          "eng-Latn",
          "tku-Latn"
        ],
        "main_score": 0.012125651041666666,
        "precision": 0.010494987468671679,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.013380954982517483,
        "hf_subset": "tku_Latn-eng_Latn",
        "languages": [
          "tku-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013380954982517483,
        "precision": 0.010206891518569149,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009938759157509155,
        "hf_subset": "eng_Latn-tlf_Latn",
        "languages": [
          "eng-Latn",
          "tlf-Latn"
        ],
        "main_score": 0.009938759157509155,
        "precision": 0.008252910539215686,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003976004464285714,
        "hf_subset": "tlf_Latn-eng_Latn",
        "languages": [
          "tlf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003976004464285714,
        "precision": 0.003941441441441441,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004774305555555556,
        "hf_subset": "eng_Latn-tmd_Latn",
        "languages": [
          "eng-Latn",
          "tmd-Latn"
        ],
        "main_score": 0.004774305555555556,
        "precision": 0.00439453125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "tmd_Latn-eng_Latn",
        "languages": [
          "tmd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017456896551724138,
        "hf_subset": "eng_Latn-tna_Latn",
        "languages": [
          "eng-Latn",
          "tna-Latn"
        ],
        "main_score": 0.017456896551724138,
        "precision": 0.015899207204433496,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.008031994047619048,
        "hf_subset": "tna_Latn-eng_Latn",
        "languages": [
          "tna-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008031994047619048,
        "precision": 0.006399447190038222,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.027374751984126984,
        "hf_subset": "eng_Latn-tnc_Latn",
        "languages": [
          "eng-Latn",
          "tnc-Latn"
        ],
        "main_score": 0.027374751984126984,
        "precision": 0.02587890625,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0130859375,
        "hf_subset": "tnc_Latn-eng_Latn",
        "languages": [
          "tnc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0130859375,
        "precision": 0.011446886446886444,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.018547712053571426,
        "hf_subset": "eng_Latn-tnk_Latn",
        "languages": [
          "eng-Latn",
          "tnk-Latn"
        ],
        "main_score": 0.018547712053571426,
        "precision": 0.014123403897849463,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.009799252471666265,
        "hf_subset": "tnk_Latn-eng_Latn",
        "languages": [
          "tnk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009799252471666265,
        "precision": 0.0077798514990126836,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009974888392857142,
        "hf_subset": "eng_Latn-tnn_Latn",
        "languages": [
          "eng-Latn",
          "tnn-Latn"
        ],
        "main_score": 0.009974888392857142,
        "precision": 0.009024439102564102,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008928571428571428,
        "hf_subset": "tnn_Latn-eng_Latn",
        "languages": [
          "tnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008928571428571428,
        "precision": 0.007291666666666667,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012760416666666666,
        "hf_subset": "eng_Latn-tnp_Latn",
        "languages": [
          "eng-Latn",
          "tnp-Latn"
        ],
        "main_score": 0.012760416666666666,
        "precision": 0.011176215277777778,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010858769379844962,
        "hf_subset": "tnp_Latn-eng_Latn",
        "languages": [
          "tnp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010858769379844962,
        "precision": 0.008882068452380952,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007631340579710145,
        "hf_subset": "eng_Latn-toc_Latn",
        "languages": [
          "eng-Latn",
          "toc-Latn"
        ],
        "main_score": 0.007631340579710145,
        "precision": 0.006450647951186744,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.006434695373272959,
        "hf_subset": "toc_Latn-eng_Latn",
        "languages": [
          "toc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006434695373272959,
        "precision": 0.004248843604312354,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.078125,
        "f1": 0.04619896162864913,
        "hf_subset": "eng_Latn-tod_Latn",
        "languages": [
          "eng-Latn",
          "tod-Latn"
        ],
        "main_score": 0.04619896162864913,
        "precision": 0.04067547931763285,
        "recall": 0.078125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03632019134395101,
        "hf_subset": "tod_Latn-eng_Latn",
        "languages": [
          "tod-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03632019134395101,
        "precision": 0.033435991725721086,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.01328125,
        "hf_subset": "eng_Latn-tof_Latn",
        "languages": [
          "eng-Latn",
          "tof-Latn"
        ],
        "main_score": 0.01328125,
        "precision": 0.0126953125,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005208333333333333,
        "hf_subset": "tof_Latn-eng_Latn",
        "languages": [
          "tof-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.0033854166666666668,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02331749231950845,
        "hf_subset": "eng_Latn-toj_Latn",
        "languages": [
          "eng-Latn",
          "toj-Latn"
        ],
        "main_score": 0.02331749231950845,
        "precision": 0.019806134259259256,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014885265700483092,
        "hf_subset": "toj_Latn-eng_Latn",
        "languages": [
          "toj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014885265700483092,
        "precision": 0.012279549877206128,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.011067708333333332,
        "hf_subset": "eng_Latn-ton_Latn",
        "languages": [
          "eng-Latn",
          "ton-Latn"
        ],
        "main_score": 0.011067708333333332,
        "precision": 0.009895833333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00785423344017094,
        "hf_subset": "ton_Latn-eng_Latn",
        "languages": [
          "ton-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00785423344017094,
        "precision": 0.00633124343487395,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020505047458172457,
        "hf_subset": "eng_Latn-too_Latn",
        "languages": [
          "eng-Latn",
          "too-Latn"
        ],
        "main_score": 0.020505047458172457,
        "precision": 0.019045327596618356,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.019639737688553684,
        "hf_subset": "too_Latn-eng_Latn",
        "languages": [
          "too-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019639737688553684,
        "precision": 0.015818832859848486,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009602864583333332,
        "hf_subset": "eng_Latn-top_Latn",
        "languages": [
          "eng-Latn",
          "top-Latn"
        ],
        "main_score": 0.009602864583333332,
        "precision": 0.008072916666666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01195384837962963,
        "hf_subset": "top_Latn-eng_Latn",
        "languages": [
          "top-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01195384837962963,
        "precision": 0.009366085813696107,
        "recall": 0.03125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017463699494949497,
        "hf_subset": "eng_Latn-tos_Latn",
        "languages": [
          "eng-Latn",
          "tos-Latn"
        ],
        "main_score": 0.017463699494949497,
        "precision": 0.014355468750000001,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.007901465004105091,
        "hf_subset": "tos_Latn-eng_Latn",
        "languages": [
          "tos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007901465004105091,
        "precision": 0.0062131209017697985,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.1773049645390071,
        "f1": 0.12539119666779242,
        "hf_subset": "eng_Latn-tpa_Latn",
        "languages": [
          "eng-Latn",
          "tpa-Latn"
        ],
        "main_score": 0.12539119666779242,
        "precision": 0.1142125408082855,
        "recall": 0.1773049645390071
      },
      {
        "accuracy": 0.1347517730496454,
        "f1": 0.08539651837524179,
        "hf_subset": "tpa_Latn-eng_Latn",
        "languages": [
          "tpa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08539651837524179,
        "precision": 0.07709414305158986,
        "recall": 0.1347517730496454
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.057886904761904764,
        "hf_subset": "eng_Latn-tpi_Latn",
        "languages": [
          "eng-Latn",
          "tpi-Latn"
        ],
        "main_score": 0.057886904761904764,
        "precision": 0.051508778899048466,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.05216668416346725,
        "hf_subset": "tpi_Latn-eng_Latn",
        "languages": [
          "tpi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05216668416346725,
        "precision": 0.04660487367540407,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01784271501068376,
        "hf_subset": "eng_Latn-tpt_Latn",
        "languages": [
          "eng-Latn",
          "tpt-Latn"
        ],
        "main_score": 0.01784271501068376,
        "precision": 0.01455078125,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011130208333333332,
        "hf_subset": "tpt_Latn-eng_Latn",
        "languages": [
          "tpt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011130208333333332,
        "precision": 0.009146085349462365,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005616155660377358,
        "hf_subset": "eng_Latn-tpz_Latn",
        "languages": [
          "eng-Latn",
          "tpz-Latn"
        ],
        "main_score": 0.005616155660377358,
        "precision": 0.004957932692307692,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0030153508771929823,
        "hf_subset": "tpz_Latn-eng_Latn",
        "languages": [
          "tpz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0030153508771929823,
        "precision": 0.002170138888888889,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.032622195512820515,
        "hf_subset": "eng_Latn-trc_Latn",
        "languages": [
          "eng-Latn",
          "trc-Latn"
        ],
        "main_score": 0.032622195512820515,
        "precision": 0.02874862938596491,
        "recall": 0.046875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.006559750258799172,
        "hf_subset": "trc_Latn-eng_Latn",
        "languages": [
          "trc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006559750258799172,
        "precision": 0.004461348684210526,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015624999999999998,
        "hf_subset": "eng_Latn-tsw_Latn",
        "languages": [
          "eng-Latn",
          "tsw-Latn"
        ],
        "main_score": 0.015624999999999998,
        "precision": 0.0125,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010988562091503267,
        "hf_subset": "tsw_Latn-eng_Latn",
        "languages": [
          "tsw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010988562091503267,
        "precision": 0.010070341870300752,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.020511272141706925,
        "hf_subset": "eng_Latn-ttc_Latn",
        "languages": [
          "eng-Latn",
          "ttc-Latn"
        ],
        "main_score": 0.020511272141706925,
        "precision": 0.016513087606837607,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027056277056277055,
        "hf_subset": "ttc_Latn-eng_Latn",
        "languages": [
          "ttc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0027056277056277055,
        "precision": 0.0020045230263157896,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0126953125,
        "hf_subset": "eng_Latn-tte_Latn",
        "languages": [
          "eng-Latn",
          "tte-Latn"
        ],
        "main_score": 0.0126953125,
        "precision": 0.012252938034188034,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009765625,
        "hf_subset": "tte_Latn-eng_Latn",
        "languages": [
          "tte-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.009114583333333332,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.010517831035923141,
        "hf_subset": "eng_Latn-tuc_Latn",
        "languages": [
          "eng-Latn",
          "tuc-Latn"
        ],
        "main_score": 0.010517831035923141,
        "precision": 0.006646586920024419,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014782913154051145,
        "hf_subset": "tuc_Latn-eng_Latn",
        "languages": [
          "tuc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014782913154051145,
        "precision": 0.013613448183760682,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.02493489583333333,
        "hf_subset": "eng_Latn-tue_Latn",
        "languages": [
          "eng-Latn",
          "tue-Latn"
        ],
        "main_score": 0.02493489583333333,
        "precision": 0.024274553571428572,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01246279761904762,
        "hf_subset": "tue_Latn-eng_Latn",
        "languages": [
          "tue-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01246279761904762,
        "precision": 0.011114771586345381,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008928571428571428,
        "hf_subset": "eng_Latn-tuf_Latn",
        "languages": [
          "eng-Latn",
          "tuf-Latn"
        ],
        "main_score": 0.008928571428571428,
        "precision": 0.008463541666666668,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012417194700460828,
        "hf_subset": "tuf_Latn-eng_Latn",
        "languages": [
          "tuf-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012417194700460828,
        "precision": 0.010967670223577235,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01863219246031746,
        "hf_subset": "eng_Latn-tuo_Latn",
        "languages": [
          "eng-Latn",
          "tuo-Latn"
        ],
        "main_score": 0.01863219246031746,
        "precision": 0.01630859375,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008203125,
        "hf_subset": "tuo_Latn-eng_Latn",
        "languages": [
          "tuo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008203125,
        "precision": 0.008018092105263157,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01443738553113553,
        "hf_subset": "eng_Latn-tur_Latn",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.01443738553113553,
        "precision": 0.012526041666666668,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00769503692680776,
        "hf_subset": "tur_Latn-eng_Latn",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00769503692680776,
        "precision": 0.006216101777882206,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008370535714285714,
        "hf_subset": "eng_Latn-tvk_Latn",
        "languages": [
          "eng-Latn",
          "tvk-Latn"
        ],
        "main_score": 0.008370535714285714,
        "precision": 0.006159855769230769,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002754407051282051,
        "hf_subset": "tvk_Latn-eng_Latn",
        "languages": [
          "tvk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002754407051282051,
        "precision": 0.002029718137254902,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.018217495331465917,
        "hf_subset": "eng_Latn-twi_Latn",
        "languages": [
          "eng-Latn",
          "twi-Latn"
        ],
        "main_score": 0.018217495331465917,
        "precision": 0.013481880958872781,
        "recall": 0.046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007084396258503402,
        "hf_subset": "twi_Latn-eng_Latn",
        "languages": [
          "twi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007084396258503402,
        "precision": 0.0058861301369863015,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011991932189542483,
        "hf_subset": "eng_Latn-txq_Latn",
        "languages": [
          "eng-Latn",
          "txq-Latn"
        ],
        "main_score": 0.011991932189542483,
        "precision": 0.010288572104978355,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013135723039215685,
        "hf_subset": "txq_Latn-eng_Latn",
        "languages": [
          "txq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013135723039215685,
        "precision": 0.011777052238805971,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00546875,
        "hf_subset": "eng_Latn-txu_Latn",
        "languages": [
          "eng-Latn",
          "txu-Latn"
        ],
        "main_score": 0.00546875,
        "precision": 0.0048828125,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0015066964285714284,
        "hf_subset": "txu_Latn-eng_Latn",
        "languages": [
          "txu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0015066964285714284,
        "precision": 0.0008566337719298245,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.019771230493886745,
        "hf_subset": "eng_Latn-tzj_Latn",
        "languages": [
          "eng-Latn",
          "tzj-Latn"
        ],
        "main_score": 0.019771230493886745,
        "precision": 0.016734299942564743,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009386119021624749,
        "hf_subset": "tzj_Latn-eng_Latn",
        "languages": [
          "tzj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009386119021624749,
        "precision": 0.008678093905472636,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013302844183721477,
        "hf_subset": "eng_Latn-tzo_Latn",
        "languages": [
          "eng-Latn",
          "tzo-Latn"
        ],
        "main_score": 0.013302844183721477,
        "precision": 0.010452835648148149,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005290412712287713,
        "hf_subset": "tzo_Latn-eng_Latn",
        "languages": [
          "tzo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005290412712287713,
        "precision": 0.004644607843137255,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06993999923687423,
        "hf_subset": "eng_Latn-ubr_Latn",
        "languages": [
          "eng-Latn",
          "ubr-Latn"
        ],
        "main_score": 0.06993999923687423,
        "precision": 0.06389330070970696,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.03900650131118881,
        "hf_subset": "ubr_Latn-eng_Latn",
        "languages": [
          "ubr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03900650131118881,
        "precision": 0.0338379917184265,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005667892156862745,
        "hf_subset": "eng_Latn-ubu_Latn",
        "languages": [
          "eng-Latn",
          "ubu-Latn"
        ],
        "main_score": 0.005667892156862745,
        "precision": 0.004150390625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.005727212878904089,
        "hf_subset": "ubu_Latn-eng_Latn",
        "languages": [
          "ubu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005727212878904089,
        "precision": 0.004908501750949668,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026726973684210523,
        "hf_subset": "eng_Latn-udu_Latn",
        "languages": [
          "eng-Latn",
          "udu-Latn"
        ],
        "main_score": 0.0026726973684210523,
        "precision": 0.0019876935840707965,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009765625,
        "hf_subset": "udu_Latn-eng_Latn",
        "languages": [
          "udu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.008948863636363637,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017965029761904762,
        "hf_subset": "eng_Latn-uig_Latn",
        "languages": [
          "eng-Latn",
          "uig-Latn"
        ],
        "main_score": 0.017965029761904762,
        "precision": 0.014645478219696969,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010668682795698924,
        "hf_subset": "uig_Latn-eng_Latn",
        "languages": [
          "uig-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010668682795698924,
        "precision": 0.009895833333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005953414351851851,
        "hf_subset": "eng_Latn-ukr_Cyrl",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ],
        "main_score": 0.005953414351851851,
        "precision": 0.005048553876678877,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006416524943310657,
        "hf_subset": "ukr_Cyrl-eng_Latn",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.006416524943310657,
        "precision": 0.005411364368556701,
        "recall": 0.015625
      },
      {
        "accuracy": 0.09375,
        "f1": 0.06619388640873015,
        "hf_subset": "eng_Latn-uli_Latn",
        "languages": [
          "eng-Latn",
          "uli-Latn"
        ],
        "main_score": 0.06619388640873015,
        "precision": 0.05850360576923077,
        "recall": 0.09375
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.05930825455182073,
        "hf_subset": "uli_Latn-eng_Latn",
        "languages": [
          "uli-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05930825455182073,
        "precision": 0.05244465369788801,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.07329842931937172,
        "f1": 0.04462727499376714,
        "hf_subset": "eng_Latn-ulk_Latn",
        "languages": [
          "eng-Latn",
          "ulk-Latn"
        ],
        "main_score": 0.04462727499376714,
        "precision": 0.03954451345755693,
        "recall": 0.07329842931937172
      },
      {
        "accuracy": 0.03664921465968586,
        "f1": 0.01982049364248317,
        "hf_subset": "ulk_Latn-eng_Latn",
        "languages": [
          "ulk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01982049364248317,
        "precision": 0.016593184532010655,
        "recall": 0.03664921465968586
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008680555555555556,
        "hf_subset": "eng_Latn-upv_Latn",
        "languages": [
          "eng-Latn",
          "upv-Latn"
        ],
        "main_score": 0.008680555555555556,
        "precision": 0.006969975490196078,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.015624999999999998,
        "hf_subset": "upv_Latn-eng_Latn",
        "languages": [
          "upv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015624999999999998,
        "precision": 0.013671875,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007220643939393939,
        "hf_subset": "eng_Latn-ura_Latn",
        "languages": [
          "eng-Latn",
          "ura-Latn"
        ],
        "main_score": 0.007220643939393939,
        "precision": 0.00625,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0004345238095238095,
        "hf_subset": "ura_Latn-eng_Latn",
        "languages": [
          "ura-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0004345238095238095,
        "precision": 0.00022681451612903227,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.001948799141749723,
        "hf_subset": "eng_Latn-urb_Latn",
        "languages": [
          "eng-Latn",
          "urb-Latn"
        ],
        "main_score": 0.001948799141749723,
        "precision": 0.001084338000172846,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00037706611570247935,
        "hf_subset": "urb_Latn-eng_Latn",
        "languages": [
          "urb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00037706611570247935,
        "precision": 0.00019531249999999998,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005412946428571428,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.005412946428571428,
        "precision": 0.003363715277777778,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009765625,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.009765625,
        "precision": 0.007942708333333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03968253968253968,
        "f1": 0.02053630282912819,
        "hf_subset": "eng_Latn-uri_Latn",
        "languages": [
          "eng-Latn",
          "uri-Latn"
        ],
        "main_score": 0.02053630282912819,
        "precision": 0.01856575963718821,
        "recall": 0.03968253968253968
      },
      {
        "accuracy": 0.031746031746031744,
        "f1": 0.01608181799752681,
        "hf_subset": "uri_Latn-eng_Latn",
        "languages": [
          "uri-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01608181799752681,
        "precision": 0.014531723045012079,
        "recall": 0.031746031746031744
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007621017156862745,
        "hf_subset": "eng_Latn-urt_Latn",
        "languages": [
          "eng-Latn",
          "urt-Latn"
        ],
        "main_score": 0.007621017156862745,
        "precision": 0.006233723958333333,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006108940972222222,
        "hf_subset": "urt_Latn-eng_Latn",
        "languages": [
          "urt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006108940972222222,
        "precision": 0.005335810023310023,
        "recall": 0.015625
      },
      {
        "accuracy": 0.05555555555555555,
        "f1": 0.02400909681611436,
        "hf_subset": "eng_Latn-urw_Latn",
        "languages": [
          "eng-Latn",
          "urw-Latn"
        ],
        "main_score": 0.02400909681611436,
        "precision": 0.01904320987654321,
        "recall": 0.05555555555555555
      },
      {
        "accuracy": 0.05555555555555555,
        "f1": 0.02901234567901234,
        "hf_subset": "urw_Latn-eng_Latn",
        "languages": [
          "urw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02901234567901234,
        "precision": 0.023148148148148143,
        "recall": 0.05555555555555555
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013612689393939395,
        "hf_subset": "eng_Latn-usa_Latn",
        "languages": [
          "eng-Latn",
          "usa-Latn"
        ],
        "main_score": 0.0013612689393939395,
        "precision": 0.0007457386363636364,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "usa_Latn-eng_Latn",
        "languages": [
          "usa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011096897893772892,
        "hf_subset": "eng_Latn-usp_Latn",
        "languages": [
          "eng-Latn",
          "usp-Latn"
        ],
        "main_score": 0.011096897893772892,
        "precision": 0.008704058071862348,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009951636904761904,
        "hf_subset": "usp_Latn-eng_Latn",
        "languages": [
          "usp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009951636904761904,
        "precision": 0.009209857723577236,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004231770833333333,
        "hf_subset": "eng_Latn-uvh_Latn",
        "languages": [
          "eng-Latn",
          "uvh-Latn"
        ],
        "main_score": 0.004231770833333333,
        "precision": 0.0026413690476190478,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002975991532976827,
        "hf_subset": "uvh_Latn-eng_Latn",
        "languages": [
          "uvh-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002975991532976827,
        "precision": 0.0021438341750841753,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006633947649572649,
        "hf_subset": "eng_Latn-uvl_Latn",
        "languages": [
          "eng-Latn",
          "uvl-Latn"
        ],
        "main_score": 0.006633947649572649,
        "precision": 0.005622632575757575,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008954831932773109,
        "hf_subset": "uvl_Latn-eng_Latn",
        "languages": [
          "uvl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008954831932773109,
        "precision": 0.008415670955882353,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006194760101010101,
        "hf_subset": "eng_Latn-vid_Latn",
        "languages": [
          "eng-Latn",
          "vid-Latn"
        ],
        "main_score": 0.006194760101010101,
        "precision": 0.005175781250000001,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002968586215932914,
        "hf_subset": "vid_Latn-eng_Latn",
        "languages": [
          "vid-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002968586215932914,
        "precision": 0.0018654847756410255,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009339755639097743,
        "hf_subset": "eng_Latn-vie_Latn",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ],
        "main_score": 0.009339755639097743,
        "precision": 0.006336805555555556,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013834635416666665,
        "hf_subset": "vie_Latn-eng_Latn",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0013834635416666665,
        "precision": 0.0008223684210526316,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0011255871890952537,
        "hf_subset": "eng_Latn-viv_Latn",
        "languages": [
          "eng-Latn",
          "viv-Latn"
        ],
        "main_score": 0.0011255871890952537,
        "precision": 0.0006049022698612864,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "viv_Latn-eng_Latn",
        "languages": [
          "viv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01050290854978355,
        "hf_subset": "eng_Latn-vmy_Latn",
        "languages": [
          "eng-Latn",
          "vmy-Latn"
        ],
        "main_score": 0.01050290854978355,
        "precision": 0.008019536238825032,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006135574494949495,
        "hf_subset": "vmy_Latn-eng_Latn",
        "languages": [
          "vmy-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006135574494949495,
        "precision": 0.004408482142857143,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007761984392419175,
        "hf_subset": "eng_Latn-waj_Latn",
        "languages": [
          "eng-Latn",
          "waj-Latn"
        ],
        "main_score": 0.007761984392419175,
        "precision": 0.006536458333333333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00390625,
        "hf_subset": "waj_Latn-eng_Latn",
        "languages": [
          "waj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.002734375,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008147126311188812,
        "hf_subset": "eng_Latn-wal_Ethi",
        "languages": [
          "eng-Latn",
          "wal-Ethi"
        ],
        "main_score": 0.008147126311188812,
        "precision": 0.006482514880952381,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.014322916666666666,
        "hf_subset": "wal_Ethi-eng_Latn",
        "languages": [
          "wal-Ethi",
          "eng-Latn"
        ],
        "main_score": 0.014322916666666666,
        "precision": 0.013671875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.09375,
        "f1": 0.07529141865079364,
        "hf_subset": "eng_Latn-wap_Latn",
        "languages": [
          "eng-Latn",
          "wap-Latn"
        ],
        "main_score": 0.07529141865079364,
        "precision": 0.07025824652777778,
        "recall": 0.09375
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.06412906308356676,
        "hf_subset": "wap_Latn-eng_Latn",
        "languages": [
          "wap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06412906308356676,
        "precision": 0.058219777259378554,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.046875,
        "f1": 0.031511548913043474,
        "hf_subset": "eng_Latn-wat_Latn",
        "languages": [
          "eng-Latn",
          "wat-Latn"
        ],
        "main_score": 0.031511548913043474,
        "precision": 0.028790838068181817,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01886667578537282,
        "hf_subset": "wat_Latn-eng_Latn",
        "languages": [
          "wat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01886667578537282,
        "precision": 0.015306064415708812,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01366595643939394,
        "hf_subset": "eng_Latn-wbi_Latn",
        "languages": [
          "eng-Latn",
          "wbi-Latn"
        ],
        "main_score": 0.01366595643939394,
        "precision": 0.010518973214285715,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01466641865079365,
        "hf_subset": "wbi_Latn-eng_Latn",
        "languages": [
          "wbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01466641865079365,
        "precision": 0.012369791666666668,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00044719827586206897,
        "hf_subset": "eng_Latn-wbp_Latn",
        "languages": [
          "eng-Latn",
          "wbp-Latn"
        ],
        "main_score": 0.00044719827586206897,
        "precision": 0.00023129111842105262,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0011600378787878789,
        "hf_subset": "wbp_Latn-eng_Latn",
        "languages": [
          "wbp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011600378787878789,
        "precision": 0.000637155812937063,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.08404792906746031,
        "hf_subset": "eng_Latn-wed_Latn",
        "languages": [
          "eng-Latn",
          "wed-Latn"
        ],
        "main_score": 0.08404792906746031,
        "precision": 0.0743195064484127,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.109375,
        "f1": 0.06603213728673288,
        "hf_subset": "wed_Latn-eng_Latn",
        "languages": [
          "wed-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06603213728673288,
        "precision": 0.058050440228174606,
        "recall": 0.109375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006148726851851851,
        "hf_subset": "eng_Latn-wer_Latn",
        "languages": [
          "eng-Latn",
          "wer-Latn"
        ],
        "main_score": 0.006148726851851851,
        "precision": 0.005358573717948718,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007064224837662337,
        "hf_subset": "wer_Latn-eng_Latn",
        "languages": [
          "wer-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007064224837662337,
        "precision": 0.004732399425287356,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0625,
        "f1": 0.04010450977162934,
        "hf_subset": "eng_Latn-wim_Latn",
        "languages": [
          "eng-Latn",
          "wim-Latn"
        ],
        "main_score": 0.04010450977162934,
        "precision": 0.035921294417388165,
        "recall": 0.0625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.026106770833333334,
        "hf_subset": "wim_Latn-eng_Latn",
        "languages": [
          "wim-Latn",
          "eng-Latn"
        ],
        "main_score": 0.026106770833333334,
        "precision": 0.021499875992063492,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004166666666666667,
        "hf_subset": "eng_Latn-wiu_Latn",
        "languages": [
          "eng-Latn",
          "wiu-Latn"
        ],
        "main_score": 0.004166666666666667,
        "precision": 0.0029296875,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0010416666666666667,
        "hf_subset": "wiu_Latn-eng_Latn",
        "languages": [
          "wiu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0010416666666666667,
        "precision": 0.0005580357142857143,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017127403846153848,
        "hf_subset": "eng_Latn-wiv_Latn",
        "languages": [
          "eng-Latn",
          "wiv-Latn"
        ],
        "main_score": 0.017127403846153848,
        "precision": 0.01533717105263158,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00872831937799043,
        "hf_subset": "wiv_Latn-eng_Latn",
        "languages": [
          "wiv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00872831937799043,
        "precision": 0.008308699324324324,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013020833333333333,
        "hf_subset": "eng_Latn-wmt_Latn",
        "languages": [
          "eng-Latn",
          "wmt-Latn"
        ],
        "main_score": 0.0013020833333333333,
        "precision": 0.00078125,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "wmt_Latn-eng_Latn",
        "languages": [
          "wmt-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017466517857142858,
        "hf_subset": "eng_Latn-wmw_Latn",
        "languages": [
          "eng-Latn",
          "wmw-Latn"
        ],
        "main_score": 0.017466517857142858,
        "precision": 0.015574363425925926,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006649925595238095,
        "hf_subset": "wmw_Latn-eng_Latn",
        "languages": [
          "wmw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006649925595238095,
        "precision": 0.005930397727272727,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009765625,
        "hf_subset": "eng_Latn-wnc_Latn",
        "languages": [
          "eng-Latn",
          "wnc-Latn"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0005580357142857143,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0016799868295019156,
        "hf_subset": "wnc_Latn-eng_Latn",
        "languages": [
          "wnc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0016799868295019156,
        "precision": 0.0009757765342052314,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018787915070242658,
        "hf_subset": "eng_Latn-wnu_Latn",
        "languages": [
          "eng-Latn",
          "wnu-Latn"
        ],
        "main_score": 0.018787915070242658,
        "precision": 0.017867874313186812,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0028591234697320222,
        "hf_subset": "wnu_Latn-eng_Latn",
        "languages": [
          "wnu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0028591234697320222,
        "precision": 0.0016055999811387743,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01111111111111111,
        "hf_subset": "eng_Latn-wol_Latn",
        "languages": [
          "eng-Latn",
          "wol-Latn"
        ],
        "main_score": 0.01111111111111111,
        "precision": 0.00859375,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01221770917131312,
        "hf_subset": "wol_Latn-eng_Latn",
        "languages": [
          "wol-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01221770917131312,
        "precision": 0.011973813668823483,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010091145833333332,
        "hf_subset": "eng_Latn-wos_Latn",
        "languages": [
          "eng-Latn",
          "wos-Latn"
        ],
        "main_score": 0.010091145833333332,
        "precision": 0.008370535714285714,
        "recall": 0.015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00390625,
        "hf_subset": "wos_Latn-eng_Latn",
        "languages": [
          "wos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00390625,
        "precision": 0.00390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0006458166131621187,
        "hf_subset": "eng_Latn-wrk_Latn",
        "languages": [
          "eng-Latn",
          "wrk-Latn"
        ],
        "main_score": 0.0006458166131621187,
        "precision": 0.0003448699737762238,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00011322463768115942,
        "hf_subset": "wrk_Latn-eng_Latn",
        "languages": [
          "wrk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00011322463768115942,
        "precision": 5.744485294117647e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1484375,
        "f1": 0.08822850103583099,
        "hf_subset": "eng_Latn-wro_Latn",
        "languages": [
          "eng-Latn",
          "wro-Latn"
        ],
        "main_score": 0.08822850103583099,
        "precision": 0.07576046446256449,
        "recall": 0.1484375
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.0852046607905983,
        "hf_subset": "wro_Latn-eng_Latn",
        "languages": [
          "wro-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0852046607905983,
        "precision": 0.07740475087464896,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001767113095238095,
        "hf_subset": "eng_Latn-wrs_Latn",
        "languages": [
          "eng-Latn",
          "wrs-Latn"
        ],
        "main_score": 0.001767113095238095,
        "precision": 0.001006155303030303,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005222800925925925,
        "hf_subset": "wrs_Latn-eng_Latn",
        "languages": [
          "wrs-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005222800925925925,
        "precision": 0.0036079290206648693,
        "recall": 0.015625
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.0685952719155844,
        "hf_subset": "eng_Latn-wsk_Latn",
        "languages": [
          "eng-Latn",
          "wsk-Latn"
        ],
        "main_score": 0.0685952719155844,
        "precision": 0.05965730042016806,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.0730203111946533,
        "hf_subset": "wsk_Latn-eng_Latn",
        "languages": [
          "wsk-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0730203111946533,
        "precision": 0.06401583666871921,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.09933636242229991,
        "hf_subset": "eng_Latn-wuv_Latn",
        "languages": [
          "eng-Latn",
          "wuv-Latn"
        ],
        "main_score": 0.09933636242229991,
        "precision": 0.09180344012605042,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.109375,
        "f1": 0.06725367731227105,
        "hf_subset": "wuv_Latn-eng_Latn",
        "languages": [
          "wuv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06725367731227105,
        "precision": 0.06014627544858524,
        "recall": 0.109375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011067708333333334,
        "hf_subset": "eng_Latn-xav_Latn",
        "languages": [
          "eng-Latn",
          "xav-Latn"
        ],
        "main_score": 0.011067708333333334,
        "precision": 0.009730113636363637,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005208333333333333,
        "hf_subset": "xav_Latn-eng_Latn",
        "languages": [
          "xav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005208333333333333,
        "precision": 0.0046875,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014020412457912457,
        "hf_subset": "eng_Latn-xbi_Latn",
        "languages": [
          "eng-Latn",
          "xbi-Latn"
        ],
        "main_score": 0.014020412457912457,
        "precision": 0.010957532051282052,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.005207837131945801,
        "hf_subset": "xbi_Latn-eng_Latn",
        "languages": [
          "xbi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005207837131945801,
        "precision": 0.003012598370559039,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01384548611111111,
        "hf_subset": "eng_Latn-xed_Latn",
        "languages": [
          "eng-Latn",
          "xed-Latn"
        ],
        "main_score": 0.01384548611111111,
        "precision": 0.009854403409090908,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0091281328320802,
        "hf_subset": "xed_Latn-eng_Latn",
        "languages": [
          "xed-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0091281328320802,
        "precision": 0.008564798147081415,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0069010416666666664,
        "hf_subset": "eng_Latn-xla_Latn",
        "languages": [
          "eng-Latn",
          "xla-Latn"
        ],
        "main_score": 0.0069010416666666664,
        "precision": 0.006064967105263158,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002147080962760455,
        "hf_subset": "xla_Latn-eng_Latn",
        "languages": [
          "xla-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002147080962760455,
        "precision": 0.0014003314393939393,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.012064830043859647,
        "hf_subset": "eng_Latn-xnn_Latn",
        "languages": [
          "eng-Latn",
          "xnn-Latn"
        ],
        "main_score": 0.012064830043859647,
        "precision": 0.010675372879036672,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011194243077324974,
        "hf_subset": "xnn_Latn-eng_Latn",
        "languages": [
          "xnn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.011194243077324974,
        "precision": 0.010190217391304348,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.01778922032828283,
        "hf_subset": "eng_Latn-xon_Latn",
        "languages": [
          "eng-Latn",
          "xon-Latn"
        ],
        "main_score": 0.01778922032828283,
        "precision": 0.013871837797619049,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008022280092592593,
        "hf_subset": "xon_Latn-eng_Latn",
        "languages": [
          "xon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008022280092592593,
        "precision": 0.00791902846044078,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0070149739583333336,
        "hf_subset": "eng_Latn-xsi_Latn",
        "languages": [
          "eng-Latn",
          "xsi-Latn"
        ],
        "main_score": 0.0070149739583333336,
        "precision": 0.006120081340378198,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004083806818181818,
        "hf_subset": "xsi_Latn-eng_Latn",
        "languages": [
          "xsi-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004083806818181818,
        "precision": 0.003997093023255814,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01675347222222222,
        "hf_subset": "eng_Latn-xtd_Latn",
        "languages": [
          "eng-Latn",
          "xtd-Latn"
        ],
        "main_score": 0.01675347222222222,
        "precision": 0.015115158279220779,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007040998217468805,
        "hf_subset": "xtd_Latn-eng_Latn",
        "languages": [
          "xtd-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007040998217468805,
        "precision": 0.0061393527809633025,
        "recall": 0.015625
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03184121621621622,
        "hf_subset": "eng_Latn-xtm_Latn",
        "languages": [
          "eng-Latn",
          "xtm-Latn"
        ],
        "main_score": 0.03184121621621622,
        "precision": 0.029611404220779222,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.009823697009291522,
        "hf_subset": "xtm_Latn-eng_Latn",
        "languages": [
          "xtm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009823697009291522,
        "precision": 0.0074433598975652635,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.011749639759750054,
        "hf_subset": "eng_Latn-yaa_Latn",
        "languages": [
          "eng-Latn",
          "yaa-Latn"
        ],
        "main_score": 0.011749639759750054,
        "precision": 0.010187815656565655,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008857421875,
        "hf_subset": "yaa_Latn-eng_Latn",
        "languages": [
          "yaa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008857421875,
        "precision": 0.008361685147849462,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005119554924242424,
        "hf_subset": "eng_Latn-yad_Latn",
        "languages": [
          "eng-Latn",
          "yad-Latn"
        ],
        "main_score": 0.005119554924242424,
        "precision": 0.004586356026785714,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.00685525919485361,
        "hf_subset": "yad_Latn-eng_Latn",
        "languages": [
          "yad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.00685525919485361,
        "precision": 0.005725987532400744,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006537543402777778,
        "hf_subset": "eng_Latn-yal_Latn",
        "languages": [
          "eng-Latn",
          "yal-Latn"
        ],
        "main_score": 0.006537543402777778,
        "precision": 0.005564120809614169,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "yal_Latn-eng_Latn",
        "languages": [
          "yal-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05407187213827838,
        "hf_subset": "eng_Latn-yap_Latn",
        "languages": [
          "eng-Latn",
          "yap-Latn"
        ],
        "main_score": 0.05407187213827838,
        "precision": 0.04757396708683473,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0703125,
        "f1": 0.047815018418892054,
        "hf_subset": "yap_Latn-eng_Latn",
        "languages": [
          "yap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.047815018418892054,
        "precision": 0.04204195825289575,
        "recall": 0.0703125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005859375,
        "hf_subset": "eng_Latn-yaq_Latn",
        "languages": [
          "eng-Latn",
          "yaq-Latn"
        ],
        "main_score": 0.005859375,
        "precision": 0.005208333333333333,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.002900229173517893,
        "hf_subset": "yaq_Latn-eng_Latn",
        "languages": [
          "yaq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002900229173517893,
        "precision": 0.001805449695121951,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010416666666666666,
        "hf_subset": "eng_Latn-yby_Latn",
        "languages": [
          "eng-Latn",
          "yby-Latn"
        ],
        "main_score": 0.010416666666666666,
        "precision": 0.008463541666666666,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.002212629233689016,
        "hf_subset": "yby_Latn-eng_Latn",
        "languages": [
          "yby-Latn",
          "eng-Latn"
        ],
        "main_score": 0.002212629233689016,
        "precision": 0.0012508024042950515,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013151041666666667,
        "hf_subset": "eng_Latn-ycn_Latn",
        "languages": [
          "eng-Latn",
          "ycn-Latn"
        ],
        "main_score": 0.013151041666666667,
        "precision": 0.011501736111111112,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004478536626344086,
        "hf_subset": "ycn_Latn-eng_Latn",
        "languages": [
          "ycn-Latn",
          "eng-Latn"
        ],
        "main_score": 0.004478536626344086,
        "precision": 0.004209125905797102,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.017838541666666666,
        "hf_subset": "eng_Latn-yka_Latn",
        "languages": [
          "eng-Latn",
          "yka-Latn"
        ],
        "main_score": 0.017838541666666666,
        "precision": 0.014388020833333334,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009000211148648648,
        "hf_subset": "yka_Latn-eng_Latn",
        "languages": [
          "yka-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009000211148648648,
        "precision": 0.008479042658730158,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.013888888888888888,
        "hf_subset": "eng_Latn-yle_Latn",
        "languages": [
          "eng-Latn",
          "yle-Latn"
        ],
        "main_score": 0.013888888888888888,
        "precision": 0.01220703125,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0019596163245356795,
        "hf_subset": "yle_Latn-eng_Latn",
        "languages": [
          "yle-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0019596163245356795,
        "precision": 0.0011836892696267696,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001953125,
        "hf_subset": "eng_Latn-yml_Latn",
        "languages": [
          "eng-Latn",
          "yml-Latn"
        ],
        "main_score": 0.001953125,
        "precision": 0.0013020833333333333,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005809294871794872,
        "hf_subset": "yml_Latn-eng_Latn",
        "languages": [
          "yml-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005809294871794872,
        "precision": 0.0037109375,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01889436141304348,
        "hf_subset": "eng_Latn-yon_Latn",
        "languages": [
          "eng-Latn",
          "yon-Latn"
        ],
        "main_score": 0.01889436141304348,
        "precision": 0.015709550865800864,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009249281609195402,
        "hf_subset": "yon_Latn-eng_Latn",
        "languages": [
          "yon-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009249281609195402,
        "precision": 0.008662280701754387,
        "recall": 0.015625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.04366196878460686,
        "hf_subset": "eng_Latn-yor_Latn",
        "languages": [
          "eng-Latn",
          "yor-Latn"
        ],
        "main_score": 0.04366196878460686,
        "precision": 0.0394931891025641,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02092792913105413,
        "hf_subset": "yor_Latn-eng_Latn",
        "languages": [
          "yor-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02092792913105413,
        "precision": 0.018107556996855345,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004321199633699634,
        "hf_subset": "eng_Latn-yrb_Latn",
        "languages": [
          "eng-Latn",
          "yrb-Latn"
        ],
        "main_score": 0.004321199633699634,
        "precision": 0.0029296875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0011191662969330597,
        "hf_subset": "yrb_Latn-eng_Latn",
        "languages": [
          "yrb-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0011191662969330597,
        "precision": 0.0005967881944444445,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00012807377049180329,
        "hf_subset": "eng_Latn-yre_Latn",
        "languages": [
          "eng-Latn",
          "yre-Latn"
        ],
        "main_score": 0.00012807377049180329,
        "precision": 6.510416666666667e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0002565701602765556,
        "hf_subset": "yre_Latn-eng_Latn",
        "languages": [
          "yre-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0002565701602765556,
        "precision": 0.00013135051169590643,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013435132575757576,
        "hf_subset": "eng_Latn-yss_Latn",
        "languages": [
          "eng-Latn",
          "yss-Latn"
        ],
        "main_score": 0.013435132575757576,
        "precision": 0.009717518472906403,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003255208333333333,
        "hf_subset": "yss_Latn-eng_Latn",
        "languages": [
          "yss-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003255208333333333,
        "precision": 0.0023082386363636365,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018823982007575756,
        "hf_subset": "eng_Latn-yuj_Latn",
        "languages": [
          "eng-Latn",
          "yuj-Latn"
        ],
        "main_score": 0.018823982007575756,
        "precision": 0.017588588169642854,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008151612998348667,
        "hf_subset": "yuj_Latn-eng_Latn",
        "languages": [
          "yuj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008151612998348667,
        "precision": 0.007987780448717948,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015335062415654521,
        "hf_subset": "eng_Latn-yut_Latn",
        "languages": [
          "eng-Latn",
          "yut-Latn"
        ],
        "main_score": 0.015335062415654521,
        "precision": 0.011740451388888889,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005631510416666667,
        "hf_subset": "yut_Latn-eng_Latn",
        "languages": [
          "yut-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005631510416666667,
        "precision": 0.004125533159053384,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005433505639097744,
        "hf_subset": "eng_Latn-yuw_Latn",
        "languages": [
          "eng-Latn",
          "yuw-Latn"
        ],
        "main_score": 0.005433505639097744,
        "precision": 0.004774305555555556,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0040536556603773585,
        "hf_subset": "yuw_Latn-eng_Latn",
        "languages": [
          "yuw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0040536556603773585,
        "precision": 0.003981370192307692,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016104041048237476,
        "hf_subset": "eng_Latn-yva_Latn",
        "languages": [
          "eng-Latn",
          "yva-Latn"
        ],
        "main_score": 0.016104041048237476,
        "precision": 0.014469401041666666,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003995028409090909,
        "hf_subset": "yva_Latn-eng_Latn",
        "languages": [
          "yva-Latn",
          "eng-Latn"
        ],
        "main_score": 0.003995028409090909,
        "precision": 0.003951149425287357,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.016595643939393938,
        "hf_subset": "eng_Latn-zaa_Latn",
        "languages": [
          "eng-Latn",
          "zaa-Latn"
        ],
        "main_score": 0.016595643939393938,
        "precision": 0.01279000946969697,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.008602430555555554,
        "hf_subset": "zaa_Latn-eng_Latn",
        "languages": [
          "zaa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008602430555555554,
        "precision": 0.005600873161764705,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.018574451264880953,
        "hf_subset": "eng_Latn-zab_Latn",
        "languages": [
          "eng-Latn",
          "zab-Latn"
        ],
        "main_score": 0.018574451264880953,
        "precision": 0.01775501867413632,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.01114397878841295,
        "hf_subset": "zab_Latn-eng_Latn",
        "languages": [
          "zab-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01114397878841295,
        "precision": 0.009711371527777778,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019280133928571426,
        "hf_subset": "eng_Latn-zac_Latn",
        "languages": [
          "eng-Latn",
          "zac-Latn"
        ],
        "main_score": 0.019280133928571426,
        "precision": 0.015336681547619049,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014356078970049558,
        "hf_subset": "zac_Latn-eng_Latn",
        "languages": [
          "zac-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014356078970049558,
        "precision": 0.012065686677631578,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01209077380952381,
        "hf_subset": "eng_Latn-zad_Latn",
        "languages": [
          "eng-Latn",
          "zad-Latn"
        ],
        "main_score": 0.01209077380952381,
        "precision": 0.010611979166666665,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008723958333333334,
        "hf_subset": "zad_Latn-eng_Latn",
        "languages": [
          "zad-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008723958333333334,
        "precision": 0.007191051136363636,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.022030784970238096,
        "hf_subset": "eng_Latn-zai_Latn",
        "languages": [
          "eng-Latn",
          "zai-Latn"
        ],
        "main_score": 0.022030784970238096,
        "precision": 0.0202234100877193,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012342789938556066,
        "hf_subset": "zai_Latn-eng_Latn",
        "languages": [
          "zai-Latn",
          "eng-Latn"
        ],
        "main_score": 0.012342789938556066,
        "precision": 0.009795217803030304,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007626488095238094,
        "hf_subset": "eng_Latn-zaj_Latn",
        "languages": [
          "eng-Latn",
          "zaj-Latn"
        ],
        "main_score": 0.007626488095238094,
        "precision": 0.006510416666666667,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007102272727272727,
        "hf_subset": "zaj_Latn-eng_Latn",
        "languages": [
          "zaj-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007102272727272727,
        "precision": 0.000390625,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012906461148648648,
        "hf_subset": "eng_Latn-zam_Latn",
        "languages": [
          "eng-Latn",
          "zam-Latn"
        ],
        "main_score": 0.012906461148648648,
        "precision": 0.012385292658730158,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.016670612373737372,
        "hf_subset": "zam_Latn-eng_Latn",
        "languages": [
          "zam-Latn",
          "eng-Latn"
        ],
        "main_score": 0.016670612373737372,
        "precision": 0.014250999273255814,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.01171875,
        "hf_subset": "eng_Latn-zao_Latn",
        "languages": [
          "eng-Latn",
          "zao-Latn"
        ],
        "main_score": 0.01171875,
        "precision": 0.01171875,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010520833333333333,
        "hf_subset": "zao_Latn-eng_Latn",
        "languages": [
          "zao-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010520833333333333,
        "precision": 0.009427787162162162,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02291666666666667,
        "hf_subset": "eng_Latn-zap_Latn",
        "languages": [
          "eng-Latn",
          "zap-Latn"
        ],
        "main_score": 0.02291666666666667,
        "precision": 0.01948474702380952,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.013311476934523808,
        "hf_subset": "zap_Latn-eng_Latn",
        "languages": [
          "zap-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013311476934523808,
        "precision": 0.010644981278801844,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0048828125,
        "hf_subset": "eng_Latn-zar_Latn",
        "languages": [
          "eng-Latn",
          "zar-Latn"
        ],
        "main_score": 0.0048828125,
        "precision": 0.004464285714285714,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007136418269230769,
        "hf_subset": "zar_Latn-eng_Latn",
        "languages": [
          "zar-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007136418269230769,
        "precision": 0.005922619047619047,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.012841356981981982,
        "hf_subset": "eng_Latn-zas_Latn",
        "languages": [
          "eng-Latn",
          "zas-Latn"
        ],
        "main_score": 0.012841356981981982,
        "precision": 0.010075849215404553,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01032924107142857,
        "hf_subset": "zas_Latn-eng_Latn",
        "languages": [
          "zas-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01032924107142857,
        "precision": 0.009240950116459628,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.014322916666666666,
        "hf_subset": "eng_Latn-zat_Latn",
        "languages": [
          "eng-Latn",
          "zat-Latn"
        ],
        "main_score": 0.014322916666666666,
        "precision": 0.013671875,
        "recall": 0.015625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005129602713178295,
        "hf_subset": "zat_Latn-eng_Latn",
        "languages": [
          "zat-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005129602713178295,
        "precision": 0.00345672123015873,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.015127144607843137,
        "hf_subset": "eng_Latn-zav_Latn",
        "languages": [
          "eng-Latn",
          "zav-Latn"
        ],
        "main_score": 0.015127144607843137,
        "precision": 0.013098958333333334,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0048828125,
        "hf_subset": "zav_Latn-eng_Latn",
        "languages": [
          "zav-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0048828125,
        "precision": 0.004464285714285714,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03103298611111111,
        "hf_subset": "eng_Latn-zaw_Latn",
        "languages": [
          "eng-Latn",
          "zaw-Latn"
        ],
        "main_score": 0.03103298611111111,
        "precision": 0.02775804924242424,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.014763874299719888,
        "hf_subset": "zaw_Latn-eng_Latn",
        "languages": [
          "zaw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014763874299719888,
        "precision": 0.011486563529896424,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020976524315738026,
        "hf_subset": "eng_Latn-zca_Latn",
        "languages": [
          "eng-Latn",
          "zca-Latn"
        ],
        "main_score": 0.020976524315738026,
        "precision": 0.019313292572463767,
        "recall": 0.03125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.010534354967948717,
        "hf_subset": "zca_Latn-eng_Latn",
        "languages": [
          "zca-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010534354967948717,
        "precision": 0.00859673531048252,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.009135142543859649,
        "hf_subset": "eng_Latn-zga_Latn",
        "languages": [
          "eng-Latn",
          "zga-Latn"
        ],
        "main_score": 0.009135142543859649,
        "precision": 0.006236190025252525,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007022046084546084,
        "hf_subset": "zga_Latn-eng_Latn",
        "languages": [
          "zga-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007022046084546084,
        "precision": 0.006124131944444444,
        "recall": 0.015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021152935606060606,
        "hf_subset": "eng_Latn-zia_Latn",
        "languages": [
          "eng-Latn",
          "zia-Latn"
        ],
        "main_score": 0.021152935606060606,
        "precision": 0.019300426136363638,
        "recall": 0.03125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.009461805555555557,
        "hf_subset": "zia_Latn-eng_Latn",
        "languages": [
          "zia-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009461805555555557,
        "precision": 0.008832952949438203,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00353422619047619,
        "hf_subset": "eng_Latn-ziw_Latn",
        "languages": [
          "eng-Latn",
          "ziw-Latn"
        ],
        "main_score": 0.00353422619047619,
        "precision": 0.0020833333333333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0036272321428571425,
        "hf_subset": "ziw_Latn-eng_Latn",
        "languages": [
          "ziw-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0036272321428571425,
        "precision": 0.0025035511363636367,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.02494210752482811,
        "hf_subset": "eng_Latn-zlm_Latn",
        "languages": [
          "eng-Latn",
          "zlm-Latn"
        ],
        "main_score": 0.02494210752482811,
        "precision": 0.019514973958333334,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.013522744766009853,
        "hf_subset": "zlm_Latn-eng_Latn",
        "languages": [
          "zlm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013522744766009853,
        "precision": 0.012716775412087912,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.012258837197159565,
        "hf_subset": "eng_Latn-zos_Latn",
        "languages": [
          "eng-Latn",
          "zos-Latn"
        ],
        "main_score": 0.012258837197159565,
        "precision": 0.00976789343786295,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.006516723053181387,
        "hf_subset": "zos_Latn-eng_Latn",
        "languages": [
          "zos-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006516723053181387,
        "precision": 0.005427564538043478,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.03125,
        "f1": 0.018522135416666665,
        "hf_subset": "eng_Latn-zpc_Latn",
        "languages": [
          "eng-Latn",
          "zpc-Latn"
        ],
        "main_score": 0.018522135416666665,
        "precision": 0.01549109781323877,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.0064127604166666664,
        "hf_subset": "zpc_Latn-eng_Latn",
        "languages": [
          "zpc-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0064127604166666664,
        "precision": 0.004550067443754454,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.010603926043219077,
        "hf_subset": "eng_Latn-zpl_Latn",
        "languages": [
          "eng-Latn",
          "zpl-Latn"
        ],
        "main_score": 0.010603926043219077,
        "precision": 0.008268229166666667,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010930203843390805,
        "hf_subset": "zpl_Latn-eng_Latn",
        "languages": [
          "zpl-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010930203843390805,
        "precision": 0.010031141993087557,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.01583614864864865,
        "hf_subset": "eng_Latn-zpm_Latn",
        "languages": [
          "eng-Latn",
          "zpm-Latn"
        ],
        "main_score": 0.01583614864864865,
        "precision": 0.015733506944444444,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.010771780303030302,
        "hf_subset": "zpm_Latn-eng_Latn",
        "languages": [
          "zpm-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010771780303030302,
        "precision": 0.009951636904761904,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012239583333333331,
        "hf_subset": "eng_Latn-zpo_Latn",
        "languages": [
          "eng-Latn",
          "zpo-Latn"
        ],
        "main_score": 0.012239583333333331,
        "precision": 0.010044642857142856,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014576569264069264,
        "hf_subset": "zpo_Latn-eng_Latn",
        "languages": [
          "zpo-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014576569264069264,
        "precision": 0.013800825281803543,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005484532828282828,
        "hf_subset": "eng_Latn-zpq_Latn",
        "languages": [
          "eng-Latn",
          "zpq-Latn"
        ],
        "main_score": 0.005484532828282828,
        "precision": 0.004763595779220779,
        "recall": 0.015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0035807291666666665,
        "hf_subset": "zpq_Latn-eng_Latn",
        "languages": [
          "zpq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0035807291666666665,
        "precision": 0.0024739583333333332,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0625,
        "f1": 0.03036387759503568,
        "hf_subset": "eng_Latn-zpu_Latn",
        "languages": [
          "eng-Latn",
          "zpu-Latn"
        ],
        "main_score": 0.03036387759503568,
        "precision": 0.025874792525183148,
        "recall": 0.0625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.02108534946236559,
        "hf_subset": "zpu_Latn-eng_Latn",
        "languages": [
          "zpu-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02108534946236559,
        "precision": 0.019661458333333333,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.01911695075757576,
        "hf_subset": "eng_Latn-zpv_Latn",
        "languages": [
          "eng-Latn",
          "zpv-Latn"
        ],
        "main_score": 0.01911695075757576,
        "precision": 0.016540495801033592,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.019063120039682538,
        "hf_subset": "zpv_Latn-eng_Latn",
        "languages": [
          "zpv-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019063120039682538,
        "precision": 0.01648034553495311,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.015569196428571427,
        "hf_subset": "eng_Latn-zpz_Latn",
        "languages": [
          "eng-Latn",
          "zpz-Latn"
        ],
        "main_score": 0.015569196428571427,
        "precision": 0.0107421875,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010255297364672365,
        "hf_subset": "zpz_Latn-eng_Latn",
        "languages": [
          "zpz-Latn",
          "eng-Latn"
        ],
        "main_score": 0.010255297364672365,
        "precision": 0.009367619770580298,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003988486842105263,
        "hf_subset": "eng_Latn-zsr_Latn",
        "languages": [
          "eng-Latn",
          "zsr-Latn"
        ],
        "main_score": 0.003988486842105263,
        "precision": 0.00394780585106383,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.0025984432234432233,
        "hf_subset": "zsr_Latn-eng_Latn",
        "languages": [
          "zsr-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0025984432234432233,
        "precision": 0.0014613207972582973,
        "recall": 0.015625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.017299107142857144,
        "hf_subset": "eng_Latn-ztq_Latn",
        "languages": [
          "eng-Latn",
          "ztq-Latn"
        ],
        "main_score": 0.017299107142857144,
        "precision": 0.015299479166666668,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.019398952762923354,
        "hf_subset": "ztq_Latn-eng_Latn",
        "languages": [
          "ztq-Latn",
          "eng-Latn"
        ],
        "main_score": 0.019398952762923354,
        "precision": 0.018212890625,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011818910256410256,
        "hf_subset": "eng_Latn-zty_Latn",
        "languages": [
          "eng-Latn",
          "zty-Latn"
        ],
        "main_score": 0.011818910256410256,
        "precision": 0.010597605519480519,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0029947916666666664,
        "hf_subset": "zty_Latn-eng_Latn",
        "languages": [
          "zty-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0029947916666666664,
        "precision": 0.0021587171052631577,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.023912559815592902,
        "hf_subset": "eng_Latn-zyp_Latn",
        "languages": [
          "eng-Latn",
          "zyp-Latn"
        ],
        "main_score": 0.023912559815592902,
        "precision": 0.019822019853614523,
        "recall": 0.046875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.014800347222222222,
        "hf_subset": "zyp_Latn-eng_Latn",
        "languages": [
          "zyp-Latn",
          "eng-Latn"
        ],
        "main_score": 0.014800347222222222,
        "precision": 0.012285925954433497,
        "recall": 0.03125
      }
    ]
  },
  "task_name": "BibleNLPBitextMining"
}