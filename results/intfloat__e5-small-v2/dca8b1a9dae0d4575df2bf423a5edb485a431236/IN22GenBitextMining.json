{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 39.263569831848145,
  "kg_co2_emissions": 0.0013047590605828059,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.078125,
        "f1": 0.054833350243506496,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.054833350243506496,
        "precision": 0.04747090560207336,
        "recall": 0.078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007100210125402331,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0007100210125402331,
        "precision": 0.0005181962245561226,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0016064255810549336,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.0016064255810549336,
        "precision": 0.0010667464769027269,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.399416461916462e-06,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 2.399416461916462e-06,
        "precision": 1.2011838868388684e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00013685442464512232,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.00013685442464512232,
        "precision": 7.036870788367026e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0015050789337474118,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0015050789337474118,
        "precision": 0.0010840676275879662,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0020773359262056404,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.0020773359262056404,
        "precision": 0.0020165617701500696,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004927603837754314,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.004927603837754314,
        "precision": 0.004226670380641735,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003163126973732248,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.0003163126973732248,
        "precision": 0.00018155304490883085,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002188892295604483,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.002188892295604483,
        "precision": 0.0017485332602953255,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00014793591970792183,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.00014793591970792183,
        "precision": 7.606449281477951e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010497616291887126,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0010497616291887126,
        "precision": 0.0006889360235898443,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0032216680396742166,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0032216680396742166,
        "precision": 0.002750674856945025,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0026597905812593588,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0026597905812593588,
        "precision": 0.001973560689381002,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004278314601608187,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.004278314601608187,
        "precision": 0.0035284878126072717,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00422859214888487,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.00422859214888487,
        "precision": 0.003743350471866097,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002397968881762762,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.002397968881762762,
        "precision": 0.0022035779278978826,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.922367125984252e-06,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 1.922367125984252e-06,
        "precision": 9.621305418719211e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0003184415452177882,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0003184415452177882,
        "precision": 0.00017358987387622188,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010201957273091565,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0010201957273091565,
        "precision": 0.0009986752369364755,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001704643116146775,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.001704643116146775,
        "precision": 0.001428535657051282,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005326859211672474,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.0005326859211672474,
        "precision": 0.0003480635862299465,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.03860475131255599,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.03860475131255599,
        "precision": 0.034643369867979244,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0024988511029411763,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0024988511029411763,
        "precision": 0.002308238636363636,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0023946869083900845,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.0023946869083900845,
        "precision": 0.00222292548412504,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0009765625,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0009765625,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0001436694498337029,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.0001436694498337029,
        "precision": 7.467920979812238e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0024510751856435644,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0024510751856435644,
        "precision": 0.0022835043532338306,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002959908820159661,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.002959908820159661,
        "precision": 0.0029449371246246248,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013761058789954338,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0013761058789954338,
        "precision": 0.0008996619361620794,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009827044025157233,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.0009827044025157233,
        "precision": 0.0009796431388012618,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005600979577557829,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.005600979577557829,
        "precision": 0.004291790939680381,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0021593016228292567,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0021593016228292567,
        "precision": 0.002060288791732451,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001579733455882353,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.001579733455882353,
        "precision": 0.0013631184895833333,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0020337720533033033,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0020337720533033033,
        "precision": 0.0019944043542074364,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0021026401505204353,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0021026401505204353,
        "precision": 0.0017522736836055684,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014049264537545788,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0014049264537545788,
        "precision": 0.0009641617063492063,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0029391686893203883,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0029391686893203883,
        "precision": 0.002934451219512195,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004176526448886362,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.004176526448886362,
        "precision": 0.0034761759518585787,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9054878048780488e-06,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 1.9054878048780488e-06,
        "precision": 9.5367431640625e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000988328313253012,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.000988328313253012,
        "precision": 0.0009824810606060606,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009789857320099255,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0009789857320099255,
        "precision": 0.0009777756211180124,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009927712852961432,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.0009927712852961432,
        "precision": 0.00098470066212087,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 8.311170212765958e-06,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 8.311170212765958e-06,
        "precision": 4.1733440170940175e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005845805548454397,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.005845805548454397,
        "precision": 0.005468428709647702,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004727968936716667,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.004727968936716667,
        "precision": 0.003753908038576007,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.3291015625,
        "f1": 0.3021357105681155,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.3021357105681155,
        "precision": 0.29433479203996826,
        "recall": 0.3291015625
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.03681342396794221,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.03681342396794221,
        "precision": 0.03485257648912033,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.279296875,
        "f1": 0.25509751112906953,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.25509751112906953,
        "precision": 0.2478240898546936,
        "recall": 0.279296875
      },
      {
        "accuracy": 0.046875,
        "f1": 0.024022779882154878,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.024022779882154878,
        "precision": 0.019706982323014887,
        "recall": 0.046875
      },
      {
        "accuracy": 0.3251953125,
        "f1": 0.297899005049113,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.297899005049113,
        "precision": 0.2902628991939694,
        "recall": 0.3251953125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0039040775981925616,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0039040775981925616,
        "precision": 0.002989113814596351,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.2255859375,
        "f1": 0.19187715033559347,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.19187715033559347,
        "precision": 0.1817698768087011,
        "recall": 0.2255859375
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.0697657862941066,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.0697657862941066,
        "precision": 0.06341913087466611,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.1630859375,
        "f1": 0.12859820448680453,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.12859820448680453,
        "precision": 0.11794332825153474,
        "recall": 0.1630859375
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.03871622550081484,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.03871622550081484,
        "precision": 0.034352460890032854,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003045205785108497,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003045205785108497,
        "precision": 0.0022569824158668638,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0791015625,
        "f1": 0.054482921914562533,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.054482921914562533,
        "precision": 0.04840337342778749,
        "recall": 0.0791015625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005028477081151227,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.005028477081151227,
        "precision": 0.00411766915996531,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.2080078125,
        "f1": 0.18815322029496392,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.18815322029496392,
        "precision": 0.18204637698428183,
        "recall": 0.2080078125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.05334204889868953,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.05334204889868953,
        "precision": 0.047629620840062496,
        "recall": 0.078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0015805831925001994,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0015805831925001994,
        "precision": 0.0009927767565721785,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.318359375,
        "f1": 0.2868673422554197,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2868673422554197,
        "precision": 0.2779951402955194,
        "recall": 0.318359375
      },
      {
        "accuracy": 0.1923828125,
        "f1": 0.1615467572005849,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.1615467572005849,
        "precision": 0.15121765391669278,
        "recall": 0.1923828125
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.16254986847345407,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.16254986847345407,
        "precision": 0.152988447922109,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.2095827132936508,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2095827132936508,
        "precision": 0.19968148984262266,
        "recall": 0.23828125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003581120340867052,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.003581120340867052,
        "precision": 0.0032877014276905263,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005577851633940667,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.005577851633940667,
        "precision": 0.004783700980462331,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.345703125,
        "f1": 0.3114136549597257,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.3114136549597257,
        "precision": 0.3029440199536595,
        "recall": 0.345703125
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.04759845161433057,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.04759845161433057,
        "precision": 0.044390014421035726,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.3720703125,
        "f1": 0.3346891208133166,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3346891208133166,
        "precision": 0.32371540627284356,
        "recall": 0.3720703125
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.02295886653798008,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.02295886653798008,
        "precision": 0.018416317452774895,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.5703125,
        "f1": 0.5172595796130952,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.5172595796130952,
        "precision": 0.49773220486111114,
        "recall": 0.5703125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003778508346273292,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.003778508346273292,
        "precision": 0.002786856930272109,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.23046875,
        "f1": 0.20212918820770046,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.20212918820770046,
        "precision": 0.19307478506180864,
        "recall": 0.23046875
      },
      {
        "accuracy": 0.345703125,
        "f1": 0.2813433663775461,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.2813433663775461,
        "precision": 0.2595370205965909,
        "recall": 0.345703125
      },
      {
        "accuracy": 0.1630859375,
        "f1": 0.1290521821642585,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.1290521821642585,
        "precision": 0.11947180423742923,
        "recall": 0.1630859375
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.09975408163490104,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09975408163490104,
        "precision": 0.09228871433158936,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0029238518323996265,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0029238518323996265,
        "precision": 0.002185194876395534,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.2626953125,
        "f1": 0.20118434625270562,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.20118434625270562,
        "precision": 0.18084979256854256,
        "recall": 0.2626953125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0029619097266479722,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0029619097266479722,
        "precision": 0.002548944382440476,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.2255859375,
        "f1": 0.2070785736169468,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.2070785736169468,
        "precision": 0.20073065229272014,
        "recall": 0.2255859375
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.08869184833540301,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.08869184833540301,
        "precision": 0.08081879901890547,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0037173646236646814,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0037173646236646814,
        "precision": 0.002768296970965547,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.455078125,
        "f1": 0.4095619593936308,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4095619593936308,
        "precision": 0.3938457890850469,
        "recall": 0.455078125
      },
      {
        "accuracy": 0.2060546875,
        "f1": 0.1770517405771312,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.1770517405771312,
        "precision": 0.16728731290976534,
        "recall": 0.2060546875
      },
      {
        "accuracy": 0.208984375,
        "f1": 0.17649287123888377,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.17649287123888377,
        "precision": 0.16633961852970353,
        "recall": 0.208984375
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.20610620550303455,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.20610620550303455,
        "precision": 0.1967354314522283,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001511447092326139,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.001511447092326139,
        "precision": 0.001287458484299517,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001667002521494709,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.001667002521494709,
        "precision": 0.0013568768853695324,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.130859375,
        "f1": 0.08520594485879264,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.08520594485879264,
        "precision": 0.07283980349643562,
        "recall": 0.130859375
      },
      {
        "accuracy": 0.169921875,
        "f1": 0.12015435612596401,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.12015435612596401,
        "precision": 0.10686831383422032,
        "recall": 0.169921875
      },
      {
        "accuracy": 0.154296875,
        "f1": 0.11967166756344147,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.11967166756344147,
        "precision": 0.10803695138411935,
        "recall": 0.154296875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.008455122417594897,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.008455122417594897,
        "precision": 0.006136792202593751,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.1611328125,
        "f1": 0.1215863869724913,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.1215863869724913,
        "precision": 0.11098031153440462,
        "recall": 0.1611328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0017063691970577873,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.0017063691970577873,
        "precision": 0.0010585966564360119,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1181640625,
        "f1": 0.07424893679159796,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.07424893679159796,
        "precision": 0.06532913384336612,
        "recall": 0.1181640625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00470743620414673,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.00470743620414673,
        "precision": 0.0034686944102353583,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.055401011061127346,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.055401011061127346,
        "precision": 0.048675157119426694,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005533854166666667,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.005533854166666667,
        "precision": 0.004557291666666666,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007544484619279701,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.0007544484619279701,
        "precision": 0.00045030381944444447,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006369251950306637,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.006369251950306637,
        "precision": 0.00436937129502964,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009545755665204678,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0009545755665204678,
        "precision": 0.0005599733382936508,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.09424116040095684,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.09424116040095684,
        "precision": 0.08358821711000988,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005250249138116785,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.005250249138116785,
        "precision": 0.004059516059027778,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0023061751553663853,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0023061751553663853,
        "precision": 0.0014686371550344636,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.11037154577193639,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.11037154577193639,
        "precision": 0.09853086908750971,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.06890845203018638,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.06890845203018638,
        "precision": 0.05790832431457431,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.099609375,
        "f1": 0.06054982664383364,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.06054982664383364,
        "precision": 0.05121438348977411,
        "recall": 0.099609375
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.07353333229891733,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.07353333229891733,
        "precision": 0.0641159364181825,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005852059675261839,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.005852059675261839,
        "precision": 0.005251791023532388,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.004571622927741095,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.004571622927741095,
        "precision": 0.0038801228791463162,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.29296875,
        "f1": 0.25898316902800833,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.25898316902800833,
        "precision": 0.24866233445132438,
        "recall": 0.29296875
      },
      {
        "accuracy": 0.3447265625,
        "f1": 0.30864059458347276,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.30864059458347276,
        "precision": 0.2987827973537328,
        "recall": 0.3447265625
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.043847494831112464,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.043847494831112464,
        "precision": 0.04005886861648373,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.02417015554614377,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.02417015554614377,
        "precision": 0.019733261984299946,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.40234375,
        "f1": 0.36413373498890356,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.36413373498890356,
        "precision": 0.35307617275868375,
        "recall": 0.40234375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004920723739734954,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.004920723739734954,
        "precision": 0.0038250541185629325,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.21484375,
        "f1": 0.18527562600165798,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.18527562600165798,
        "precision": 0.174897187319403,
        "recall": 0.21484375
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.11654515541491281,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.11654515541491281,
        "precision": 0.10505498910196613,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.12136315165028483,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.12136315165028483,
        "precision": 0.11082322125794591,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.427734375,
        "f1": 0.3608142671130952,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.3608142671130952,
        "precision": 0.3357293991815476,
        "recall": 0.427734375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003958594611863526,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003958594611863526,
        "precision": 0.003247881869026089,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.1201171875,
        "f1": 0.08350061496010336,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.08350061496010336,
        "precision": 0.07437793477024182,
        "recall": 0.1201171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0032595159774436093,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0032595159774436093,
        "precision": 0.002529793975779967,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.2275390625,
        "f1": 0.2026469063115856,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.2026469063115856,
        "precision": 0.19489147258254716,
        "recall": 0.2275390625
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07525255865577282,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.07525255865577282,
        "precision": 0.06784709611190148,
        "recall": 0.109375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0024315889550264548,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0024315889550264548,
        "precision": 0.001927937641402715,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.33984375,
        "f1": 0.3072709958180406,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.3072709958180406,
        "precision": 0.29782829926872895,
        "recall": 0.33984375
      },
      {
        "accuracy": 0.1982421875,
        "f1": 0.16570224737030226,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.16570224737030226,
        "precision": 0.15531450744131048,
        "recall": 0.1982421875
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.1518362756443477,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.1518362756443477,
        "precision": 0.14054798401374563,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.2216796875,
        "f1": 0.19502475259667432,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.19502475259667432,
        "precision": 0.18542960819769616,
        "recall": 0.2216796875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.00406319543996259,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.00406319543996259,
        "precision": 0.003986284371576254,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003435936134880254,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.003435936134880254,
        "precision": 0.0026325831098249577,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.03325315399236935,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.03325315399236935,
        "precision": 0.03180794458303338,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.03035978790897651,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.03035978790897651,
        "precision": 0.029536429813915025,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.004578993055555555,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.004578993055555555,
        "precision": 0.004405503862359551,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.02928530648029766,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.02928530648029766,
        "precision": 0.028400501857597356,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.03023339077108327,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.03023339077108327,
        "precision": 0.029358717982341118,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.158203125,
        "f1": 0.12848539806547618,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.12848539806547618,
        "precision": 0.11830283160849567,
        "recall": 0.158203125
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.024246901801715307,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.024246901801715307,
        "precision": 0.02344962377080895,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001407047193877551,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.001407047193877551,
        "precision": 0.0009155273437499999,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07754281850961539,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.07754281850961539,
        "precision": 0.0711746830643315,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0021651412473504793,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.0021651412473504793,
        "precision": 0.001717554024805577,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.06949497992312259,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.06949497992312259,
        "precision": 0.06057673202448593,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004501876354835911,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.004501876354835911,
        "precision": 0.0039736340326574525,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.014528366394902938,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.014528366394902938,
        "precision": 0.01252868972565171,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.056615665280454294,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.056615665280454294,
        "precision": 0.05341429264574537,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0015272580611908298,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.0015272580611908298,
        "precision": 0.0013055216374969494,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.0454735343919514,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.0454735343919514,
        "precision": 0.039991591747968125,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.03126178284869691,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.03126178284869691,
        "precision": 0.030587499798087486,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.03955325062061331,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.03955325062061331,
        "precision": 0.03903871692511189,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.11328125,
        "f1": 0.09160753919521752,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.09160753919521752,
        "precision": 0.0860729927624459,
        "recall": 0.11328125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.023427152683691402,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.023427152683691402,
        "precision": 0.02274408721487723,
        "recall": 0.03125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005434526437177154,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.005434526437177154,
        "precision": 0.004242039304280656,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.0077443129507912935,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0077443129507912935,
        "precision": 0.006839161419550909,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.330078125,
        "f1": 0.2981221014310329,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2981221014310329,
        "precision": 0.28867399953872563,
        "recall": 0.330078125
      },
      {
        "accuracy": 0.572265625,
        "f1": 0.5178865947420634,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5178865947420634,
        "precision": 0.4974403742958431,
        "recall": 0.572265625
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.038718908903812646,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.038718908903812646,
        "precision": 0.036130933687106806,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.404296875,
        "f1": 0.3653470916875522,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3653470916875522,
        "precision": 0.3533956051259801,
        "recall": 0.404296875
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.0210875160757977,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0210875160757977,
        "precision": 0.016604633601960905,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0022661007537186782,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0022661007537186782,
        "precision": 0.001754972727886197,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.2197265625,
        "f1": 0.18576010482317928,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.18576010482317928,
        "precision": 0.17436232068585011,
        "recall": 0.2197265625
      },
      {
        "accuracy": 0.482421875,
        "f1": 0.4110724290900072,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4110724290900072,
        "precision": 0.38423239087301586,
        "recall": 0.482421875
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.11731622869318181,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11731622869318181,
        "precision": 0.10786779928879581,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.1449018620710897,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.1449018620710897,
        "precision": 0.13344191677688888,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003987572262683144,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003987572262683144,
        "precision": 0.0035696349558397254,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.39453125,
        "f1": 0.3250868760146104,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.3250868760146104,
        "precision": 0.29915406858766236,
        "recall": 0.39453125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0037866782817926547,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0037866782817926547,
        "precision": 0.003277179052618157,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.21875,
        "f1": 0.1997980623584768,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.1997980623584768,
        "precision": 0.19281090735524686,
        "recall": 0.21875
      },
      {
        "accuracy": 0.16796875,
        "f1": 0.13411539612106804,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.13411539612106804,
        "precision": 0.12440218337435135,
        "recall": 0.16796875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002613744900461459,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002613744900461459,
        "precision": 0.0019758414538530466,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.4658203125,
        "f1": 0.4198366900027056,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.4198366900027056,
        "precision": 0.4047789422558131,
        "recall": 0.4658203125
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.16292712896146255,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.16292712896146255,
        "precision": 0.15323169528040037,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.1923828125,
        "f1": 0.15716102265675663,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.15716102265675663,
        "precision": 0.14638353376688257,
        "recall": 0.1923828125
      },
      {
        "accuracy": 0.234375,
        "f1": 0.2109635661419173,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.2109635661419173,
        "precision": 0.20259772732174228,
        "recall": 0.234375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0028536185014874384,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.0028536185014874384,
        "precision": 0.0025706863174320316,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0038952768056389453,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0038952768056389453,
        "precision": 0.0034869463997680237,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.007081611832726816,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.007081611832726816,
        "precision": 0.006012213139148542,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004110804106261955,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.004110804106261955,
        "precision": 0.0036586213601686266,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004034745065789474,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.0004034745065789474,
        "precision": 0.0002506079263245033,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.005544423024891774,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.005544423024891774,
        "precision": 0.0052584532076719575,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.11078559027777776,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.11078559027777776,
        "precision": 0.09784328170687134,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002049298186140241,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.002049298186140241,
        "precision": 0.0015875983694003544,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002998323512298785,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.002998323512298785,
        "precision": 0.002403631907308378,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0028186819899299284,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.0028186819899299284,
        "precision": 0.002136722231506239,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0869140625,
        "f1": 0.06175672743055555,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.06175672743055555,
        "precision": 0.05413182466405122,
        "recall": 0.0869140625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.0039016522439095118,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.0039016522439095118,
        "precision": 0.003128163654042825,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.109375,
        "f1": 0.07538909658050283,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.07538909658050283,
        "precision": 0.06525673220009158,
        "recall": 0.109375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008099612937471499,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.008099612937471499,
        "precision": 0.006268414151407705,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.024775437565378283,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.024775437565378283,
        "precision": 0.022865805247662827,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.017520101968344155,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.017520101968344155,
        "precision": 0.014229203536730333,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002438759858911513,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.002438759858911513,
        "precision": 0.0019398655631149917,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.029891408975020684,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.029891408975020684,
        "precision": 0.02514981626047575,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0048228689146755255,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.0048228689146755255,
        "precision": 0.003941877133026302,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0018480992026441152,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.0018480992026441152,
        "precision": 0.00145995323416723,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.08685229104662698,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.08685229104662698,
        "precision": 0.0785299390279859,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0011958648783263375,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.0011958648783263375,
        "precision": 0.0010907426820255767,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014054275191413726,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0014054275191413726,
        "precision": 0.0010302522997835497,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00184697451137038,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.00184697451137038,
        "precision": 0.0015073177900613562,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.201171875,
        "f1": 0.18025266434698878,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.18025266434698878,
        "precision": 0.17349230421519576,
        "recall": 0.201171875
      },
      {
        "accuracy": 0.1962890625,
        "f1": 0.17847567396436492,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.17847567396436492,
        "precision": 0.17287382797475026,
        "recall": 0.1962890625
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.036560117517148764,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.036560117517148764,
        "precision": 0.03435625691465795,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.1671107700892857,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.1671107700892857,
        "precision": 0.163379329004329,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.01795042117225678,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.01795042117225678,
        "precision": 0.01581817995461511,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.17951270105492448,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.17951270105492448,
        "precision": 0.17283279592366912,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002886848923434289,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.002886848923434289,
        "precision": 0.002606002310463659,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00043092757936507935,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.00043092757936507935,
        "precision": 0.00024206022869674182,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1240234375,
        "f1": 0.09917540930840016,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.09917540930840016,
        "precision": 0.09302322039373129,
        "recall": 0.1240234375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019589378720238095,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0019589378720238095,
        "precision": 0.0016630713619402984,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0013313745023916146,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0013313745023916146,
        "precision": 0.0008521683379881153,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002475931186868687,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.002475931186868687,
        "precision": 0.002243768601190476,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008210627710656753,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0008210627710656753,
        "precision": 0.0005807035490162822,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.1787087467238807,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.1787087467238807,
        "precision": 0.17254698634777949,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000517432369402985,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.000517432369402985,
        "precision": 0.0003403172348484848,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006957769858674464,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0006957769858674464,
        "precision": 0.0005110089949921038,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.17479727644876963,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.17479727644876963,
        "precision": 0.16896053962707283,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.1572265625,
        "f1": 0.13149286038112107,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.13149286038112107,
        "precision": 0.12300379300717501,
        "recall": 0.1572265625
      },
      {
        "accuracy": 0.158203125,
        "f1": 0.13548778651399818,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.13548778651399818,
        "precision": 0.12809675697968384,
        "recall": 0.158203125
      },
      {
        "accuracy": 0.400390625,
        "f1": 0.35339291459408645,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.35339291459408645,
        "precision": 0.33882381995174965,
        "recall": 0.400390625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007657839752906976,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.007657839752906976,
        "precision": 0.007069091639455882,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.008468663980827337,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.008468663980827337,
        "precision": 0.007418033307120344,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.05054884164597498,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.05054884164597498,
        "precision": 0.04510490100593465,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.2626953125,
        "f1": 0.2008185445197164,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2008185445197164,
        "precision": 0.1813416907166907,
        "recall": 0.2626953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010557087418300653,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0010557087418300653,
        "precision": 0.0010171279153898536,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1318359375,
        "f1": 0.09155056098415473,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.09155056098415473,
        "precision": 0.0823596097192088,
        "recall": 0.1318359375
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.007372554587957568,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.007372554587957568,
        "precision": 0.006620635926439537,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.3642578125,
        "f1": 0.2851634368235931,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2851634368235931,
        "precision": 0.25885265179698774,
        "recall": 0.3642578125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0024491144556699593,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0024491144556699593,
        "precision": 0.0016624291842827167,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003377126928316294,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.003377126928316294,
        "precision": 0.0027852026823962043,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004852585565476191,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.004852585565476191,
        "precision": 0.004259917371553884,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1689453125,
        "f1": 0.12839041590776273,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.12839041590776273,
        "precision": 0.11796731240799412,
        "recall": 0.1689453125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004872290614478114,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.004872290614478114,
        "precision": 0.00415142853973007,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.408203125,
        "f1": 0.3403793092757937,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.3403793092757937,
        "precision": 0.31635090441242786,
        "recall": 0.408203125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006271751748740679,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.006271751748740679,
        "precision": 0.005176258069669219,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004375962249445607,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.004375962249445607,
        "precision": 0.003914922640350045,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1806640625,
        "f1": 0.13655996681156013,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.13655996681156013,
        "precision": 0.12354949466765873,
        "recall": 0.1806640625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002093687452666883,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002093687452666883,
        "precision": 0.0016789647211840162,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.0897787820457697,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.0897787820457697,
        "precision": 0.0798512467902978,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.007594177660210961,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.007594177660210961,
        "precision": 0.0066069614952206515,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003163783501490881,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.003163783501490881,
        "precision": 0.0025664453276757963,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0024112372452122902,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0024112372452122902,
        "precision": 0.002201901888765,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0041525959137991494,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.0041525959137991494,
        "precision": 0.003785689492591964,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.00332079824778108,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.00332079824778108,
        "precision": 0.0027904203188753294,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.12174587384628367,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.12174587384628367,
        "precision": 0.11814649115028739,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.140625,
        "f1": 0.12316330945033338,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.12316330945033338,
        "precision": 0.11815957827004536,
        "recall": 0.140625
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.0227947695035461,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.0227947695035461,
        "precision": 0.02142034397893773,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.12251539279598793,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.12251539279598793,
        "precision": 0.11707178750692938,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.07819546989468863,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.07819546989468863,
        "precision": 0.06918201264880952,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.140625,
        "f1": 0.11921229452903484,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.11921229452903484,
        "precision": 0.11296148777326322,
        "recall": 0.140625
      },
      {
        "accuracy": 0.09765625,
        "f1": 0.07577298280423281,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.07577298280423281,
        "precision": 0.06883331958584715,
        "recall": 0.09765625
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.10105230598394661,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.10105230598394661,
        "precision": 0.09562757460996864,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0020331780097405097,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.0020331780097405097,
        "precision": 0.0013179420405982907,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0034574254740020786,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.0034574254740020786,
        "precision": 0.002899376058096308,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.03377759965211585,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.03377759965211585,
        "precision": 0.028728117766203702,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0047932605031120335,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.0047932605031120335,
        "precision": 0.0036987304687499997,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.0171532028721319,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.0171532028721319,
        "precision": 0.015311306409869553,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.1706717571707806,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.1706717571707806,
        "precision": 0.16533435639880953,
        "recall": 0.189453125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0030602011559042806,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0030602011559042806,
        "precision": 0.0024056705740342884,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.01429870769045251,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.01429870769045251,
        "precision": 0.01195732141405545,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.11988864275950024,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.11988864275950024,
        "precision": 0.11405078113092422,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.1474609375,
        "f1": 0.13750289884697803,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.13750289884697803,
        "precision": 0.13466797728713176,
        "recall": 0.1474609375
      },
      {
        "accuracy": 0.220703125,
        "f1": 0.1965731415315538,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.1965731415315538,
        "precision": 0.1887573120239136,
        "recall": 0.220703125
      },
      {
        "accuracy": 0.125,
        "f1": 0.10754814417763495,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.10754814417763495,
        "precision": 0.10370185122485037,
        "recall": 0.125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0041646612585343485,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0041646612585343485,
        "precision": 0.003424492173591605,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.009959077888004049,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.009959077888004049,
        "precision": 0.00860717708541002,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.03368920853009619,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.03368920853009619,
        "precision": 0.029403369191562376,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.05354716731990454,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.05354716731990454,
        "precision": 0.047956595611783795,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0005074832592458355,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0005074832592458355,
        "precision": 0.00027278574473267565,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.3369140625,
        "f1": 0.2603005112064014,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.2603005112064014,
        "precision": 0.23295204415809884,
        "recall": 0.3369140625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006652387981269781,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.006652387981269781,
        "precision": 0.00558050199455418,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.1494140625,
        "f1": 0.10719312935226907,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.10719312935226907,
        "precision": 0.09752899773780221,
        "recall": 0.1494140625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.007716267816812491,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.007716267816812491,
        "precision": 0.006314793582447486,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005681690119395712,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.005681690119395712,
        "precision": 0.004889524644277528,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.14182909094156795,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.14182909094156795,
        "precision": 0.1301720001833327,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003990944762958732,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.003990944762958732,
        "precision": 0.003561148986556321,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.005995231454604972,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005995231454604972,
        "precision": 0.004915506491474019,
        "recall": 0.015625
      },
      {
        "accuracy": 0.173828125,
        "f1": 0.12731068532704273,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.12731068532704273,
        "precision": 0.11563831345766254,
        "recall": 0.173828125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00555416086271465,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.00555416086271465,
        "precision": 0.004933484506070039,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0032752092054887647,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0032752092054887647,
        "precision": 0.002789411396660937,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.119140625,
        "f1": 0.08188866255272505,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.08188866255272505,
        "precision": 0.07335882198273244,
        "recall": 0.119140625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004950129814088449,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004950129814088449,
        "precision": 0.004256460433218246,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.04684174680472377,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.04684174680472377,
        "precision": 0.04166860940280617,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.008089192708333335,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.008089192708333335,
        "precision": 0.00651853832703835,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004432020744469346,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.004432020744469346,
        "precision": 0.003608161838036159,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014297379282522343,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0014297379282522343,
        "precision": 0.0012525040064102564,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003915434252061371,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.003915434252061371,
        "precision": 0.0035949819632090122,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0024293518083927565,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0024293518083927565,
        "precision": 0.0019040806213420983,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0018118274954212455,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0018118274954212455,
        "precision": 0.0011738478535353535,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0031808131680194822,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0031808131680194822,
        "precision": 0.002490454324026394,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.704976876045151e-05,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 3.704976876045151e-05,
        "precision": 1.8778047432619578e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001308367519305019,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.001308367519305019,
        "precision": 0.0011664496527777778,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.06577197694344969,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.06577197694344969,
        "precision": 0.059547912083119735,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0029219787805794973,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0029219787805794973,
        "precision": 0.0025215736876561274,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.09375,
        "f1": 0.07043626945970696,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.07043626945970696,
        "precision": 0.06378735739087302,
        "recall": 0.09375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0020271156604421406,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0020271156604421406,
        "precision": 0.001990766869742702,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005436085377052722,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0005436085377052722,
        "precision": 0.00032689433895921236,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.0232820315248684,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0232820315248684,
        "precision": 0.021353248378108716,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.001964923729070735,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.001964923729070735,
        "precision": 0.001565921689681701,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0035929424483166924,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0035929424483166924,
        "precision": 0.0030423792625629393,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.020306844965305885,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.020306844965305885,
        "precision": 0.018577268261025483,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03568507430298137,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.03568507430298137,
        "precision": 0.031151112788865544,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00255916572459087,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.00255916572459087,
        "precision": 0.0023394574175824175,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0849609375,
        "f1": 0.06487076400162337,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.06487076400162337,
        "precision": 0.05858213383760956,
        "recall": 0.0849609375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.003407738095238095,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.003407738095238095,
        "precision": 0.0032066743030459478,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0010029020175742736,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0010029020175742736,
        "precision": 0.0006826667967355972,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.02850614680054996,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.02850614680054996,
        "precision": 0.023685999053587585,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0014797083341151012,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0014797083341151012,
        "precision": 0.001255407984202225,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008046102289323748,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.008046102289323748,
        "precision": 0.006791124310712764,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.007688074981714085,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.007688074981714085,
        "precision": 0.006796636576252816,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.04629351932387371,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.04629351932387371,
        "precision": 0.04103989814439034,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.2021484375,
        "f1": 0.15053813724827053,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.15053813724827053,
        "precision": 0.13520303792089752,
        "recall": 0.2021484375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002761270796934562,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.002761270796934562,
        "precision": 0.002455010246561665,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.06575849797110958,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.06575849797110958,
        "precision": 0.060307934296035655,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004553574037434048,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.004553574037434048,
        "precision": 0.0037837847459557985,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.2998046875,
        "f1": 0.2290807372541408,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.2290807372541408,
        "precision": 0.2065179168895851,
        "recall": 0.2998046875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007706419023825654,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.007706419023825654,
        "precision": 0.006441165569156022,
        "recall": 0.015625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006185199349261849,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.006185199349261849,
        "precision": 0.00540403335813492,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.41796875,
        "f1": 0.3539590238320707,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.3539590238320707,
        "precision": 0.3303357693738553,
        "recall": 0.41796875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0025246895280286756,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0025246895280286756,
        "precision": 0.0020436528898059615,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1728515625,
        "f1": 0.14011911225149254,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.14011911225149254,
        "precision": 0.13108896069891013,
        "recall": 0.1728515625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005401081265126781,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005401081265126781,
        "precision": 0.004529810112211782,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.009184696566973355,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.009184696566973355,
        "precision": 0.007805171500341572,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004203930235745614,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.004203930235745614,
        "precision": 0.0034895402179911696,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1591796875,
        "f1": 0.12790631677350428,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.12790631677350428,
        "precision": 0.11840165043290043,
        "recall": 0.1591796875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004811028814935065,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004811028814935065,
        "precision": 0.00400067546135212,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.06956704771902258,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.06956704771902258,
        "precision": 0.061896218608691156,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.008414021821348157,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.008414021821348157,
        "precision": 0.007046575980862775,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004112336713778756,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.004112336713778756,
        "precision": 0.0033734616980088494,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004132863935110028,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.004132863935110028,
        "precision": 0.0034180812572004605,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0015172615784252298,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.0015172615784252298,
        "precision": 0.0012768980733653633,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004646143885787781,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.004646143885787781,
        "precision": 0.004334012341824842,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002468569893235072,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.002468569893235072,
        "precision": 0.0016994308854101081,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0025707352361606746,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.0025707352361606746,
        "precision": 0.002302346770296392,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004006410256410257,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0004006410256410257,
        "precision": 0.0002491744523195876,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011189132771164021,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.0011189132771164021,
        "precision": 0.001050434086668928,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.04355010766143578,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.04355010766143578,
        "precision": 0.038044047737715504,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.00266484210371602,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.00266484210371602,
        "precision": 0.0020189671357400164,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.060919904016969784,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.060919904016969784,
        "precision": 0.056001131770643045,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0013470959047944724,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.0013470959047944724,
        "precision": 0.000926726689034744,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0019005098287549482,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.0019005098287549482,
        "precision": 0.0016188197975435907,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.022191750298028865,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.022191750298028865,
        "precision": 0.018706334007864294,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002289800528866026,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.002289800528866026,
        "precision": 0.0017562095565025254,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0693359375,
        "f1": 0.04496193129857073,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.04496193129857073,
        "precision": 0.03923582632927911,
        "recall": 0.0693359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0034793839508094645,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.0034793839508094645,
        "precision": 0.0027985607328869047,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.003967102147682552,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.003967102147682552,
        "precision": 0.0032330484505661236,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0032404408028455286,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0032404408028455286,
        "precision": 0.003093456353679359,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0062392193100358415,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0062392193100358415,
        "precision": 0.005808986996223432,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00193936788512493,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.00193936788512493,
        "precision": 0.00164407920755577,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0050628816725260695,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.0050628816725260695,
        "precision": 0.00434916068708586,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01853751717032967,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.01853751717032967,
        "precision": 0.015896100199142962,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0010812836252289378,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.0010812836252289378,
        "precision": 0.0007370963181862125,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003608667849578306,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.003608667849578306,
        "precision": 0.0033255760705442304,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003935336943149443,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.003935336943149443,
        "precision": 0.003605548952955597,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.2099609375,
        "f1": 0.1863941121953167,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.1863941121953167,
        "precision": 0.1787349715365791,
        "recall": 0.2099609375
      },
      {
        "accuracy": 0.2236328125,
        "f1": 0.20233554359243697,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.20233554359243697,
        "precision": 0.19445545014880952,
        "recall": 0.2236328125
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.029853683897801547,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.029853683897801547,
        "precision": 0.02749542587104885,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.2119140625,
        "f1": 0.18743267298565147,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.18743267298565147,
        "precision": 0.18047193578969756,
        "recall": 0.2119140625
      },
      {
        "accuracy": 0.08203125,
        "f1": 0.05226138797436987,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.05226138797436987,
        "precision": 0.04532342092791962,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.2119140625,
        "f1": 0.18810722835186533,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.18810722835186533,
        "precision": 0.1804042795503618,
        "recall": 0.2119140625
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.021921939606087824,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.021921939606087824,
        "precision": 0.018451059845102813,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.1884765625,
        "f1": 0.15814770953758045,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.15814770953758045,
        "precision": 0.14957979389620574,
        "recall": 0.1884765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0022350682323367945,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.0022350682323367945,
        "precision": 0.001752960449778064,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.16156561808417277,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.16156561808417277,
        "precision": 0.15238514874442952,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0017920142658223413,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.0017920142658223413,
        "precision": 0.0014303513682054133,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.03979917557533046,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.03979917557533046,
        "precision": 0.035071515940656564,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0027319787862403297,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.0027319787862403297,
        "precision": 0.0024093960932418594,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.01707662050889848,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.01707662050889848,
        "precision": 0.01600144350161331,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0036100872137460236,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0036100872137460236,
        "precision": 0.003052789217391983,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.03426338914877155,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.03426338914877155,
        "precision": 0.029962760542118154,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.2216796875,
        "f1": 0.19437393858438237,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.19437393858438237,
        "precision": 0.18660350646817753,
        "recall": 0.2216796875
      },
      {
        "accuracy": 0.19921875,
        "f1": 0.17515500992063493,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.17515500992063493,
        "precision": 0.1667454037571225,
        "recall": 0.19921875
      },
      {
        "accuracy": 0.2333984375,
        "f1": 0.209130859375,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.209130859375,
        "precision": 0.19952101934523808,
        "recall": 0.2333984375
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.15892624750360557,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.15892624750360557,
        "precision": 0.1489845448237201,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.008709959946696186,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.008709959946696186,
        "precision": 0.007848722562041268,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004908269898504273,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.004908269898504273,
        "precision": 0.004255750373496192,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.04098514663282161,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.04098514663282161,
        "precision": 0.03624934682842352,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.06562576533111286,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.06562576533111286,
        "precision": 0.05833327371413309,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009765625,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0009765625,
        "precision": 0.0006674688543703161,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.06704590306597248,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.06704590306597248,
        "precision": 0.06086551472516571,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013684625816052225,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0013684625816052225,
        "precision": 0.001197791377108577,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1181640625,
        "f1": 0.08542204323454322,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.08542204323454322,
        "precision": 0.07663745170326353,
        "recall": 0.1181640625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004784028905122655,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.004784028905122655,
        "precision": 0.004159038088550027,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.00377801452020202,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.00377801452020202,
        "precision": 0.0032177403454944713,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.1262533141422554,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.1262533141422554,
        "precision": 0.11553545196123322,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002410496702981651,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.002410496702981651,
        "precision": 0.0022101831183862436,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.125,
        "f1": 0.09351918964354396,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.09351918964354396,
        "precision": 0.08546169677761475,
        "recall": 0.125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0029518008889411027,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0029518008889411027,
        "precision": 0.002528976199963947,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1484375,
        "f1": 0.11693573253888838,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.11693573253888838,
        "precision": 0.10807912790334664,
        "recall": 0.1484375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005641189464219355,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.005641189464219355,
        "precision": 0.004687366312866504,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0018802366394927534,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0018802366394927534,
        "precision": 0.0016086171436369306,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002610143744114878,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002610143744114878,
        "precision": 0.002320319934645096,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.04672470530983858,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.04672470530983858,
        "precision": 0.04125926473338583,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004791611288321815,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.004791611288321815,
        "precision": 0.0038412638950390803,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004465919602638352,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.004465919602638352,
        "precision": 0.003689236111111111,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004603794642857143,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0004603794642857143,
        "precision": 0.0002803096064814815,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002737257129568174,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.002737257129568174,
        "precision": 0.0024069258789617526,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004437099358974359,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.004437099358974359,
        "precision": 0.0038668526340709733,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0018649936099658505,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0018649936099658505,
        "precision": 0.00148633529344297,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004066353103741496,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.004066353103741496,
        "precision": 0.003710882735034229,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010357246197089946,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0010357246197089946,
        "precision": 0.0010067970454855429,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0013932406444394276,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0013932406444394276,
        "precision": 0.0012184927462709765,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.03526223140749732,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.03526223140749732,
        "precision": 0.0313369111383158,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0010670978692547241,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0010670978692547241,
        "precision": 0.000668241921478204,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.02965599125267094,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.02965599125267094,
        "precision": 0.026270163527307853,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0013798084652336794,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0013798084652336794,
        "precision": 0.0012010404893869015,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011414321229301653,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0011414321229301653,
        "precision": 0.0008148578265765765,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.014908481883216005,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.014908481883216005,
        "precision": 0.01337484003893109,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0024126895526403827,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.0024126895526403827,
        "precision": 0.0019063467233848665,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.05806826636904762,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.05806826636904762,
        "precision": 0.049301715537067095,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.006498499551642042,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.006498499551642042,
        "precision": 0.005956538701324225,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.012247796648710226,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.012247796648710226,
        "precision": 0.01138273980909886,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01657551357806666,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.01657551357806666,
        "precision": 0.013390257891139179,
        "recall": 0.03125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00227460302814414,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.00227460302814414,
        "precision": 0.002124291723901099,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0048828125,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0048828125,
        "precision": 0.00458984375,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003964317698233139,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.003964317698233139,
        "precision": 0.0035800083850807463,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.021403465126001296,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.021403465126001296,
        "precision": 0.01832276131540593,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0008033414019876369,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0008033414019876369,
        "precision": 0.0004929969483466975,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0052576980311355315,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0052576980311355315,
        "precision": 0.004810160024154589,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0052236588578911045,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0052236588578911045,
        "precision": 0.0045043603091270675,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.3212890625,
        "f1": 0.291438743233093,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.291438743233093,
        "precision": 0.2824953394045191,
        "recall": 0.3212890625
      },
      {
        "accuracy": 0.4736328125,
        "f1": 0.4368993365575397,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.4368993365575397,
        "precision": 0.4252400042640162,
        "recall": 0.4736328125
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.05026692075939919,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.05026692075939919,
        "precision": 0.047217246782296066,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.3701171875,
        "f1": 0.3394072640557463,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.3394072640557463,
        "precision": 0.33061351896801117,
        "recall": 0.3701171875
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.024870772575358496,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.024870772575358496,
        "precision": 0.020090952180757075,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.4599609375,
        "f1": 0.4254408377273566,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.4254408377273566,
        "precision": 0.41388919910695254,
        "recall": 0.4599609375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0061442405367835755,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0061442405367835755,
        "precision": 0.00508105762012012,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.2158203125,
        "f1": 0.18665496106902357,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.18665496106902357,
        "precision": 0.17580049954927884,
        "recall": 0.2158203125
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.15069457609162584,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.15069457609162584,
        "precision": 0.14044097845367376,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.11805237120272186,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.11805237120272186,
        "precision": 0.1090846187660795,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.125,
        "f1": 0.08986234373445873,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.08986234373445873,
        "precision": 0.08173426197813519,
        "recall": 0.125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.00397367128849526,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00397367128849526,
        "precision": 0.002872156725270236,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.1279296875,
        "f1": 0.09159782446172249,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.09159782446172249,
        "precision": 0.0818047931482479,
        "recall": 0.1279296875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006547289823008849,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.006547289823008849,
        "precision": 0.005454639285384331,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.2236328125,
        "f1": 0.20411594397597,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.20411594397597,
        "precision": 0.19719961099249483,
        "recall": 0.2236328125
      },
      {
        "accuracy": 0.095703125,
        "f1": 0.07123602092352092,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.07123602092352092,
        "precision": 0.06455664222612935,
        "recall": 0.095703125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0038123497596153845,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0038123497596153845,
        "precision": 0.0028033544146825393,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.1636297329167174,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.1636297329167174,
        "precision": 0.15355904268257783,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.1962890625,
        "f1": 0.16496079294802002,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.16496079294802002,
        "precision": 0.15503544903350447,
        "recall": 0.1962890625
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.21600945819665585,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.21600945819665585,
        "precision": 0.20825476294283737,
        "recall": 0.23828125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003977721544662045,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.003977721544662045,
        "precision": 0.0035198877728174604,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.003071265367942952,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.003071265367942952,
        "precision": 0.003003312372562763,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1630859375,
        "f1": 0.14835955839201875,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.14835955839201875,
        "precision": 0.14350233530721412,
        "recall": 0.1630859375
      },
      {
        "accuracy": 0.185546875,
        "f1": 0.16566162211503221,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.16566162211503221,
        "precision": 0.15973180736364329,
        "recall": 0.185546875
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.03623684343789221,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.03623684343789221,
        "precision": 0.033459629573929076,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.16082711283537315,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.16082711283537315,
        "precision": 0.156022094631874,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.031992741834996195,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.031992741834996195,
        "precision": 0.025425269175269175,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.1630859375,
        "f1": 0.14600562686011903,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.14600562686011903,
        "precision": 0.1402879757988722,
        "recall": 0.1630859375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.007984095753935392,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.007984095753935392,
        "precision": 0.006263919614103437,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.15625,
        "f1": 0.13010094970188169,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.13010094970188169,
        "precision": 0.12240995776377918,
        "recall": 0.15625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.004329784977303014,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.004329784977303014,
        "precision": 0.0034013112681671055,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.17578125,
        "f1": 0.15143822902367768,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.15143822902367768,
        "precision": 0.1446108034855425,
        "recall": 0.17578125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.002532489895558849,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.002532489895558849,
        "precision": 0.0016754317455754863,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.011414856206905839,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.011414856206905839,
        "precision": 0.009772497106481481,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003652252695221445,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.003652252695221445,
        "precision": 0.0029843284970238098,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.00711092158341117,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.00711092158341117,
        "precision": 0.006421956164598125,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.1943359375,
        "f1": 0.17489438465882928,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.17489438465882928,
        "precision": 0.1691031224672119,
        "recall": 0.1943359375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.003549431940393984,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.003549431940393984,
        "precision": 0.002569646698064667,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006189589395284296,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.006189589395284296,
        "precision": 0.005056632278311966,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.177734375,
        "f1": 0.16038428543835684,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.16038428543835684,
        "precision": 0.15506761770895186,
        "recall": 0.177734375
      },
      {
        "accuracy": 0.1953125,
        "f1": 0.17319227898521988,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.17319227898521988,
        "precision": 0.16690841352226232,
        "recall": 0.1953125
      },
      {
        "accuracy": 0.150390625,
        "f1": 0.13050543674650855,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.13050543674650855,
        "precision": 0.12407545561574479,
        "recall": 0.150390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004026922352712818,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.004026922352712818,
        "precision": 0.003968385247528501,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002834230785089377,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.002834230785089377,
        "precision": 0.0022028079495230108,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1806640625,
        "f1": 0.16117110906862744,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.16117110906862744,
        "precision": 0.15419983084045585,
        "recall": 0.1806640625
      },
      {
        "accuracy": 0.181640625,
        "f1": 0.1618742219049294,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.1618742219049294,
        "precision": 0.1556964727984817,
        "recall": 0.181640625
      },
      {
        "accuracy": 0.0400390625,
        "f1": 0.03206454864948881,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.03206454864948881,
        "precision": 0.030255259063852815,
        "recall": 0.0400390625
      },
      {
        "accuracy": 0.1787109375,
        "f1": 0.16207324314210655,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.16207324314210655,
        "precision": 0.15557570684523808,
        "recall": 0.1787109375
      },
      {
        "accuracy": 0.130859375,
        "f1": 0.09065524861423298,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.09065524861423298,
        "precision": 0.07922564089556278,
        "recall": 0.130859375
      },
      {
        "accuracy": 0.181640625,
        "f1": 0.15878552798586537,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.15878552798586537,
        "precision": 0.15164707026364577,
        "recall": 0.181640625
      },
      {
        "accuracy": 0.12109375,
        "f1": 0.0903243512130231,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.0903243512130231,
        "precision": 0.07967238653273809,
        "recall": 0.12109375
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.13238511490380428,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.13238511490380428,
        "precision": 0.12602199983207107,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001465977968931475,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.001465977968931475,
        "precision": 0.0009033203125,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.2373046875,
        "f1": 0.2057369171626984,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.2057369171626984,
        "precision": 0.19361397879464284,
        "recall": 0.2373046875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002535574385109141,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.002535574385109141,
        "precision": 0.001971468875536768,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.039615329874118935,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.039615329874118935,
        "precision": 0.03469891350267944,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004381446589052287,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.004381446589052287,
        "precision": 0.003609265083874459,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.015797204362508543,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.015797204362508543,
        "precision": 0.014383051557052016,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.2353515625,
        "f1": 0.21863924641855811,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.21863924641855811,
        "precision": 0.2138431677469139,
        "recall": 0.2353515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0020837139100326365,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.0020837139100326365,
        "precision": 0.0014327451363857155,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.05078125,
        "f1": 0.031527608676046176,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.031527608676046176,
        "precision": 0.026608829538517037,
        "recall": 0.05078125
      },
      {
        "accuracy": 0.1845703125,
        "f1": 0.16382097782483263,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.16382097782483263,
        "precision": 0.15750978394264903,
        "recall": 0.1845703125
      },
      {
        "accuracy": 0.181640625,
        "f1": 0.16695257744394137,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.16695257744394137,
        "precision": 0.16268894610461707,
        "recall": 0.181640625
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.13533457967501045,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.13533457967501045,
        "precision": 0.12870715470317828,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0016938425522648082,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.0016938425522648082,
        "precision": 0.0014078776041666667,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003056000865048365,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.003056000865048365,
        "precision": 0.002584102258158924,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.2041015625,
        "f1": 0.17926094296935524,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.17926094296935524,
        "precision": 0.17128525834867747,
        "recall": 0.2041015625
      },
      {
        "accuracy": 0.212890625,
        "f1": 0.1955728625121007,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.1955728625121007,
        "precision": 0.1903465950927345,
        "recall": 0.212890625
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.023140891436299667,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.023140891436299667,
        "precision": 0.020581771870763578,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.1806640625,
        "f1": 0.16480006167763156,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.16480006167763156,
        "precision": 0.15930292038690474,
        "recall": 0.1806640625
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.019191967682791328,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.019191967682791328,
        "precision": 0.016312788262412378,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.2177734375,
        "f1": 0.19568697555155426,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.19568697555155426,
        "precision": 0.18905370221005066,
        "recall": 0.2177734375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009808084239130435,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0009808084239130435,
        "precision": 0.0009786900871459694,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.4189453125,
        "f1": 0.3713297526041667,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.3713297526041667,
        "precision": 0.354759942748224,
        "recall": 0.4189453125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0014647584374146874,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0014647584374146874,
        "precision": 0.0012440672647241707,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.130859375,
        "f1": 0.10418801113523402,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.10418801113523402,
        "precision": 0.09640207817483355,
        "recall": 0.130859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0015977868438502344,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0015977868438502344,
        "precision": 0.0013176764641608392,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 4.04735292030374e-05,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 4.04735292030374e-05,
        "precision": 2.0521965579710144e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0008835565476190476,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.0008835565476190476,
        "precision": 0.0005262268603372434,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00087890625,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.00087890625,
        "precision": 0.0005696614583333333,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.2001953125,
        "f1": 0.17640198038766436,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.17640198038766436,
        "precision": 0.16926000688593204,
        "recall": 0.2001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00033345369397759104,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.00033345369397759104,
        "precision": 0.00017853599181149734,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004980959484924624,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0004980959484924624,
        "precision": 0.00033045296717171713,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.2080078125,
        "f1": 0.18937150521427557,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.18937150521427557,
        "precision": 0.1836295079703283,
        "recall": 0.2080078125
      },
      {
        "accuracy": 0.158203125,
        "f1": 0.13132091387952088,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.13132091387952088,
        "precision": 0.12284211943240836,
        "recall": 0.158203125
      },
      {
        "accuracy": 0.1689453125,
        "f1": 0.14172494333431526,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.14172494333431526,
        "precision": 0.13267251130816882,
        "recall": 0.1689453125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}