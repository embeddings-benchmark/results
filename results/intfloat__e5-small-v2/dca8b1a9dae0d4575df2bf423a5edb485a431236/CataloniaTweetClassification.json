{
  "dataset_revision": "cf24d44e517efa534f048e5fc5981f399ed25bee",
  "evaluation_time": 25.122992992401123,
  "kg_co2_emissions": 0.0007785245133464573,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.4805555555555556,
        "f1": 0.4907948257412498,
        "f1_weighted": 0.4732552014450263,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.4805555555555556,
        "scores_per_experiment": [
          {
            "accuracy": 0.5362103174603174,
            "f1": 0.5442326777363182,
            "f1_weighted": 0.5336551491828236
          },
          {
            "accuracy": 0.4816468253968254,
            "f1": 0.48734118057612696,
            "f1_weighted": 0.47344316011448956
          },
          {
            "accuracy": 0.40773809523809523,
            "f1": 0.4041719018527549,
            "f1_weighted": 0.3932489343386812
          },
          {
            "accuracy": 0.48759920634920634,
            "f1": 0.5115343268245418,
            "f1_weighted": 0.48580344195346975
          },
          {
            "accuracy": 0.46279761904761907,
            "f1": 0.47274403807349014,
            "f1_weighted": 0.4468231337822833
          },
          {
            "accuracy": 0.5342261904761905,
            "f1": 0.5476580911489733,
            "f1_weighted": 0.5302795169363342
          },
          {
            "accuracy": 0.5009920634920635,
            "f1": 0.5145142988750008,
            "f1_weighted": 0.49956655326452204
          },
          {
            "accuracy": 0.4623015873015873,
            "f1": 0.4679320594237771,
            "f1_weighted": 0.4519355166786863
          },
          {
            "accuracy": 0.4632936507936508,
            "f1": 0.4720524602136842,
            "f1_weighted": 0.45761746842123807
          },
          {
            "accuracy": 0.46875,
            "f1": 0.48576722268782985,
            "f1_weighted": 0.4601791397777354
          }
        ]
      },
      {
        "accuracy": 0.46069651741293527,
        "f1": 0.45647625359847055,
        "f1_weighted": 0.4595716905003068,
        "hf_subset": "catalan",
        "languages": [
          "cat-Latn"
        ],
        "main_score": 0.46069651741293527,
        "scores_per_experiment": [
          {
            "accuracy": 0.4557213930348259,
            "f1": 0.4541500699172307,
            "f1_weighted": 0.45751365932221316
          },
          {
            "accuracy": 0.4263681592039801,
            "f1": 0.42133150339400105,
            "f1_weighted": 0.42747695536382657
          },
          {
            "accuracy": 0.46368159203980097,
            "f1": 0.4565516894651849,
            "f1_weighted": 0.4566665918090508
          },
          {
            "accuracy": 0.490547263681592,
            "f1": 0.48856555119600625,
            "f1_weighted": 0.4899649455476015
          },
          {
            "accuracy": 0.4412935323383085,
            "f1": 0.4404545591355582,
            "f1_weighted": 0.44617220944533964
          },
          {
            "accuracy": 0.4552238805970149,
            "f1": 0.45540444120634466,
            "f1_weighted": 0.4545344288236091
          },
          {
            "accuracy": 0.4671641791044776,
            "f1": 0.45422374084739675,
            "f1_weighted": 0.4646826486310357
          },
          {
            "accuracy": 0.4208955223880597,
            "f1": 0.42184383961744665,
            "f1_weighted": 0.41425977710545153
          },
          {
            "accuracy": 0.4855721393034826,
            "f1": 0.4821318372796595,
            "f1_weighted": 0.48747123089966843
          },
          {
            "accuracy": 0.5004975124378109,
            "f1": 0.4901053039258767,
            "f1_weighted": 0.49697445805527096
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.4776178660049628,
        "f1": 0.4859213812080777,
        "f1_weighted": 0.4717169059012932,
        "hf_subset": "spanish",
        "languages": [
          "spa-Latn"
        ],
        "main_score": 0.4776178660049628,
        "scores_per_experiment": [
          {
            "accuracy": 0.5235732009925558,
            "f1": 0.5311076048196851,
            "f1_weighted": 0.520018183257231
          },
          {
            "accuracy": 0.48833746898263025,
            "f1": 0.49554700247279176,
            "f1_weighted": 0.4821695627132619
          },
          {
            "accuracy": 0.41836228287841193,
            "f1": 0.4156170003037893,
            "f1_weighted": 0.40312389974298596
          },
          {
            "accuracy": 0.49627791563275436,
            "f1": 0.5138497487066813,
            "f1_weighted": 0.49503717909069284
          },
          {
            "accuracy": 0.486848635235732,
            "f1": 0.5004712543440162,
            "f1_weighted": 0.4772471266198386
          },
          {
            "accuracy": 0.5146401985111663,
            "f1": 0.5240495663051327,
            "f1_weighted": 0.5125290096837446
          },
          {
            "accuracy": 0.48883374689826303,
            "f1": 0.498534076538726,
            "f1_weighted": 0.4880788212068481
          },
          {
            "accuracy": 0.45806451612903226,
            "f1": 0.4606309770071246,
            "f1_weighted": 0.44946565452957504
          },
          {
            "accuracy": 0.4436724565756824,
            "f1": 0.45196600461918884,
            "f1_weighted": 0.4368435666316926
          },
          {
            "accuracy": 0.4575682382133995,
            "f1": 0.467440576963641,
            "f1_weighted": 0.4526560555370623
          }
        ]
      },
      {
        "accuracy": 0.45263681592039795,
        "f1": 0.44832579190938293,
        "f1_weighted": 0.4518878363646935,
        "hf_subset": "catalan",
        "languages": [
          "cat-Latn"
        ],
        "main_score": 0.45263681592039795,
        "scores_per_experiment": [
          {
            "accuracy": 0.4606965174129353,
            "f1": 0.45972471747319615,
            "f1_weighted": 0.4630099733151109
          },
          {
            "accuracy": 0.4318407960199005,
            "f1": 0.42159438315790104,
            "f1_weighted": 0.4342927878345254
          },
          {
            "accuracy": 0.45223880597014926,
            "f1": 0.4469191583338355,
            "f1_weighted": 0.44495057196060095
          },
          {
            "accuracy": 0.48955223880597015,
            "f1": 0.4843389006313288,
            "f1_weighted": 0.48998059146845235
          },
          {
            "accuracy": 0.4263681592039801,
            "f1": 0.42589092613704427,
            "f1_weighted": 0.4320166498589067
          },
          {
            "accuracy": 0.445771144278607,
            "f1": 0.4451387857538441,
            "f1_weighted": 0.4446492773084628
          },
          {
            "accuracy": 0.4711442786069652,
            "f1": 0.4612226465967826,
            "f1_weighted": 0.4689794688757489
          },
          {
            "accuracy": 0.4064676616915423,
            "f1": 0.4062254735790017,
            "f1_weighted": 0.3978034425667643
          },
          {
            "accuracy": 0.4582089552238806,
            "f1": 0.4537286419270061,
            "f1_weighted": 0.46260376574790285
          },
          {
            "accuracy": 0.48407960199004973,
            "f1": 0.47847428550389,
            "f1_weighted": 0.4805918347104596
          }
        ]
      }
    ]
  },
  "task_name": "CataloniaTweetClassification"
}