{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 304.4728813171387,
  "kg_co2_emissions": 0.010338863368664943,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.011862854084321474,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.011862854084321474,
        "precision": 0.011860287515867037,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.08596837944664032,
        "f1": 0.04048316526857503,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.04048316526857503,
        "precision": 0.03272507908619405,
        "recall": 0.08596837944664032
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.02549940019819538,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.02549940019819538,
        "precision": 0.02457721661685856,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.0958498023715415,
        "f1": 0.05298424686975631,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.05298424686975631,
        "precision": 0.04399224190962462,
        "recall": 0.0958498023715415
      },
      {
        "accuracy": 0.044466403162055336,
        "f1": 0.0339924152340539,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0339924152340539,
        "precision": 0.03182873300842034,
        "recall": 0.044466403162055336
      },
      {
        "accuracy": 0.12450592885375494,
        "f1": 0.08223641000840919,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.08223641000840919,
        "precision": 0.07141947949884292,
        "recall": 0.12450592885375494
      },
      {
        "accuracy": 0.03359683794466403,
        "f1": 0.026597102946460654,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.026597102946460654,
        "precision": 0.02561721189438581,
        "recall": 0.03359683794466403
      },
      {
        "accuracy": 0.11264822134387352,
        "f1": 0.06602297981991656,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.06602297981991656,
        "precision": 0.05541442030580647,
        "recall": 0.11264822134387352
      },
      {
        "accuracy": 0.03162055335968379,
        "f1": 0.02389751324230125,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.02389751324230125,
        "precision": 0.023371217978248475,
        "recall": 0.03162055335968379
      },
      {
        "accuracy": 0.09980237154150198,
        "f1": 0.059194601844968046,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.059194601844968046,
        "precision": 0.0509901820667371,
        "recall": 0.09980237154150198
      },
      {
        "accuracy": 0.04743083003952569,
        "f1": 0.0363887571886033,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0363887571886033,
        "precision": 0.034131222776328324,
        "recall": 0.04743083003952569
      },
      {
        "accuracy": 0.11758893280632411,
        "f1": 0.07663653397173141,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.07663653397173141,
        "precision": 0.06625897982123279,
        "recall": 0.11758893280632411
      },
      {
        "accuracy": 0.04841897233201581,
        "f1": 0.03622365806704205,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.03622365806704205,
        "precision": 0.03372117008303993,
        "recall": 0.04841897233201581
      },
      {
        "accuracy": 0.12845849802371542,
        "f1": 0.07264427492612435,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.07264427492612435,
        "precision": 0.06063249843823364,
        "recall": 0.12845849802371542
      },
      {
        "accuracy": 0.07905138339920949,
        "f1": 0.07220674917934666,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.07220674917934666,
        "precision": 0.07048206680410928,
        "recall": 0.07905138339920949
      },
      {
        "accuracy": 0.1551383399209486,
        "f1": 0.09021387791106832,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.09021387791106832,
        "precision": 0.07600698735827194,
        "recall": 0.1551383399209486
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.024223752440534922,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.024223752440534922,
        "precision": 0.023527829891785014,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.09881422924901186,
        "f1": 0.05738378387013156,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.05738378387013156,
        "precision": 0.04913074839457474,
        "recall": 0.09881422924901186
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.011596474490027712,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.011596474490027712,
        "precision": 0.011398927159796724,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.07509881422924901,
        "f1": 0.03450610671858918,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.03450610671858918,
        "precision": 0.027150505945102366,
        "recall": 0.07509881422924901
      },
      {
        "accuracy": 0.05434782608695652,
        "f1": 0.04355972699877201,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.04355972699877201,
        "precision": 0.04100285792795991,
        "recall": 0.05434782608695652
      },
      {
        "accuracy": 0.1373517786561265,
        "f1": 0.09678354880854756,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.09678354880854756,
        "precision": 0.08597299891330348,
        "recall": 0.1373517786561265
      },
      {
        "accuracy": 0.06027667984189723,
        "f1": 0.05120602192293082,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.05120602192293082,
        "precision": 0.049334943956424515,
        "recall": 0.06027667984189723
      },
      {
        "accuracy": 0.1492094861660079,
        "f1": 0.09262274275448601,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.09262274275448601,
        "precision": 0.07871627408965343,
        "recall": 0.1492094861660079
      },
      {
        "accuracy": 0.040513833992094864,
        "f1": 0.0321718740197001,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.0321718740197001,
        "precision": 0.030250082078942208,
        "recall": 0.040513833992094864
      },
      {
        "accuracy": 0.11857707509881422,
        "f1": 0.06881204947176446,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.06881204947176446,
        "precision": 0.05756929862705922,
        "recall": 0.11857707509881422
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.029026287721939895,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.029026287721939895,
        "precision": 0.02769468399409111,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.11067193675889328,
        "f1": 0.06513046249448552,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.06513046249448552,
        "precision": 0.05651734116537112,
        "recall": 0.11067193675889328
      },
      {
        "accuracy": 0.09288537549407115,
        "f1": 0.0852759438483024,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.0852759438483024,
        "precision": 0.0835320256303243,
        "recall": 0.09288537549407115
      },
      {
        "accuracy": 0.17687747035573123,
        "f1": 0.11100205078044344,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.11100205078044344,
        "precision": 0.09414929994327573,
        "recall": 0.17687747035573123
      },
      {
        "accuracy": 0.06027667984189723,
        "f1": 0.04696872748690589,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.04696872748690589,
        "precision": 0.043942624167151396,
        "recall": 0.06027667984189723
      },
      {
        "accuracy": 0.12055335968379446,
        "f1": 0.0660984099408303,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.0660984099408303,
        "precision": 0.05496329781613785,
        "recall": 0.12055335968379446
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.02013820119381239,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.02013820119381239,
        "precision": 0.0188563237643728,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.11462450592885376,
        "f1": 0.07003505222777184,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.07003505222777184,
        "precision": 0.060076901530770895,
        "recall": 0.11462450592885376
      },
      {
        "accuracy": 0.024703557312252964,
        "f1": 0.018072775135919164,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.018072775135919164,
        "precision": 0.01682762559896462,
        "recall": 0.024703557312252964
      },
      {
        "accuracy": 0.10968379446640317,
        "f1": 0.06876572592975755,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.06876572592975755,
        "precision": 0.058118218951378926,
        "recall": 0.10968379446640317
      },
      {
        "accuracy": 0.029644268774703556,
        "f1": 0.02541268427278374,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.02541268427278374,
        "precision": 0.024582052408139363,
        "recall": 0.029644268774703556
      },
      {
        "accuracy": 0.08498023715415019,
        "f1": 0.04379664805408637,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.04379664805408637,
        "precision": 0.035954609773075116,
        "recall": 0.08498023715415019
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.017239619022165472,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.017239619022165472,
        "precision": 0.015934467694442258,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.1225296442687747,
        "f1": 0.0715566761597834,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.0715566761597834,
        "precision": 0.06012372837965723,
        "recall": 0.1225296442687747
      },
      {
        "accuracy": 0.03359683794466403,
        "f1": 0.026130164514897317,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.026130164514897317,
        "precision": 0.024799718026747783,
        "recall": 0.03359683794466403
      },
      {
        "accuracy": 0.11857707509881422,
        "f1": 0.07201346819440135,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.07201346819440135,
        "precision": 0.06129236620372403,
        "recall": 0.11857707509881422
      },
      {
        "accuracy": 0.06719367588932806,
        "f1": 0.05547476875549439,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.05547476875549439,
        "precision": 0.052533105875065385,
        "recall": 0.06719367588932806
      },
      {
        "accuracy": 0.16996047430830039,
        "f1": 0.11879376401486084,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.11879376401486084,
        "precision": 0.10595120459250894,
        "recall": 0.16996047430830039
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.011590433430566408,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.011590433430566408,
        "precision": 0.010217772972254019,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.09881422924901186,
        "f1": 0.058642127799736495,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.058642127799736495,
        "precision": 0.04876351426026503,
        "recall": 0.09881422924901186
      },
      {
        "accuracy": 0.040513833992094864,
        "f1": 0.032916746497609166,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.032916746497609166,
        "precision": 0.030682528610917355,
        "recall": 0.040513833992094864
      },
      {
        "accuracy": 0.13142292490118576,
        "f1": 0.08138445154721388,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.08138445154721388,
        "precision": 0.06885409964667541,
        "recall": 0.13142292490118576
      },
      {
        "accuracy": 0.046442687747035576,
        "f1": 0.0372812454946564,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0372812454946564,
        "precision": 0.03510561356639104,
        "recall": 0.046442687747035576
      },
      {
        "accuracy": 0.1422924901185771,
        "f1": 0.09147811996258719,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.09147811996258719,
        "precision": 0.07949095993649587,
        "recall": 0.1422924901185771
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.018774703557312252,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.018774703557312252,
        "precision": 0.017786561264822136,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.116600790513834,
        "f1": 0.06523762195761089,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.06523762195761089,
        "precision": 0.05501186644033593,
        "recall": 0.116600790513834
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.017739624296239036,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.017739624296239036,
        "precision": 0.01633953032380314,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.11067193675889328,
        "f1": 0.06949516456680488,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.06949516456680488,
        "precision": 0.05879357589520605,
        "recall": 0.11067193675889328
      },
      {
        "accuracy": 0.039525691699604744,
        "f1": 0.031590246018009714,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.031590246018009714,
        "precision": 0.029557952153246973,
        "recall": 0.039525691699604744
      },
      {
        "accuracy": 0.1324110671936759,
        "f1": 0.08302555928804109,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.08302555928804109,
        "precision": 0.07145286449737184,
        "recall": 0.1324110671936759
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.007257196963800429,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.007257196963800429,
        "precision": 0.0064283498973089735,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.008111751942688596,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.008111751942688596,
        "precision": 0.0061270547634183995,
        "recall": 0.022727272727272728
      }
    ],
    "validation": [
      {
        "accuracy": 0.01905717151454363,
        "f1": 0.015137158915368055,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.015137158915368055,
        "precision": 0.014520283669277226,
        "recall": 0.01905717151454363
      },
      {
        "accuracy": 0.08324974924774323,
        "f1": 0.041159325291949114,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.041159325291949114,
        "precision": 0.033601644302056394,
        "recall": 0.08324974924774323
      },
      {
        "accuracy": 0.037111334002006016,
        "f1": 0.028951955766591025,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.028951955766591025,
        "precision": 0.027788377664321285,
        "recall": 0.037111334002006016
      },
      {
        "accuracy": 0.08726178535606821,
        "f1": 0.05111325362983028,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.05111325362983028,
        "precision": 0.0434384521068486,
        "recall": 0.08726178535606821
      },
      {
        "accuracy": 0.05416248746238716,
        "f1": 0.046285089409267136,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.046285089409267136,
        "precision": 0.044404045469742554,
        "recall": 0.05416248746238716
      },
      {
        "accuracy": 0.13640922768304914,
        "f1": 0.09580658517948648,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.09580658517948648,
        "precision": 0.08450097768051629,
        "recall": 0.13640922768304914
      },
      {
        "accuracy": 0.04212637913741224,
        "f1": 0.03355428604654543,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.03355428604654543,
        "precision": 0.03180699419461076,
        "recall": 0.04212637913741224
      },
      {
        "accuracy": 0.10330992978936811,
        "f1": 0.05557229441678574,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.05557229441678574,
        "precision": 0.045444278075259255,
        "recall": 0.10330992978936811
      },
      {
        "accuracy": 0.04312938816449348,
        "f1": 0.03191317443370008,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.03191317443370008,
        "precision": 0.029327638339674448,
        "recall": 0.04312938816449348
      },
      {
        "accuracy": 0.11133400200601805,
        "f1": 0.06954750448841042,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.06954750448841042,
        "precision": 0.060012062031219754,
        "recall": 0.11133400200601805
      },
      {
        "accuracy": 0.04312938816449348,
        "f1": 0.03433419945627958,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.03433419945627958,
        "precision": 0.03247916872137749,
        "recall": 0.04312938816449348
      },
      {
        "accuracy": 0.11534603811434303,
        "f1": 0.07509565859763512,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.07509565859763512,
        "precision": 0.06433680349449773,
        "recall": 0.11534603811434303
      },
      {
        "accuracy": 0.06318956870611836,
        "f1": 0.05080364302070517,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.05080364302070517,
        "precision": 0.04842402343551532,
        "recall": 0.06318956870611836
      },
      {
        "accuracy": 0.13039117352056168,
        "f1": 0.07467937672038939,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.07467937672038939,
        "precision": 0.06271468290147278,
        "recall": 0.13039117352056168
      },
      {
        "accuracy": 0.08425275827482448,
        "f1": 0.07714375517876765,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.07714375517876765,
        "precision": 0.07502003364591128,
        "recall": 0.08425275827482448
      },
      {
        "accuracy": 0.13841524573721165,
        "f1": 0.07596772427063543,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.07596772427063543,
        "precision": 0.06310053401887729,
        "recall": 0.13841524573721165
      },
      {
        "accuracy": 0.04513540621865597,
        "f1": 0.034559936765366346,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.034559936765366346,
        "precision": 0.03252508624904883,
        "recall": 0.04513540621865597
      },
      {
        "accuracy": 0.12337011033099297,
        "f1": 0.07750845665992075,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.07750845665992075,
        "precision": 0.06750672324787066,
        "recall": 0.12337011033099297
      },
      {
        "accuracy": 0.02708124373119358,
        "f1": 0.02131213446669248,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.02131213446669248,
        "precision": 0.02029514093337141,
        "recall": 0.02708124373119358
      },
      {
        "accuracy": 0.08224674022066199,
        "f1": 0.044547041173763444,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.044547041173763444,
        "precision": 0.03780477291834161,
        "recall": 0.08224674022066199
      },
      {
        "accuracy": 0.07422266800401203,
        "f1": 0.06391368485215583,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06391368485215583,
        "precision": 0.061032030637033774,
        "recall": 0.07422266800401203
      },
      {
        "accuracy": 0.1624874623871615,
        "f1": 0.11781381566214325,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.11781381566214325,
        "precision": 0.10577771363760911,
        "recall": 0.1624874623871615
      },
      {
        "accuracy": 0.0732196589769308,
        "f1": 0.06324295265150871,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.06324295265150871,
        "precision": 0.06088462296936785,
        "recall": 0.0732196589769308
      },
      {
        "accuracy": 0.14944834503510532,
        "f1": 0.08958217233876374,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.08958217233876374,
        "precision": 0.07640930113900496,
        "recall": 0.14944834503510532
      },
      {
        "accuracy": 0.04012036108324975,
        "f1": 0.032917952168742506,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.032917952168742506,
        "precision": 0.03095427518019977,
        "recall": 0.04012036108324975
      },
      {
        "accuracy": 0.11835506519558676,
        "f1": 0.07148806998715791,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.07148806998715791,
        "precision": 0.061574171541557685,
        "recall": 0.11835506519558676
      },
      {
        "accuracy": 0.03911735205616851,
        "f1": 0.03269586699227591,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.03269586699227591,
        "precision": 0.03125615183123586,
        "recall": 0.03911735205616851
      },
      {
        "accuracy": 0.11835506519558676,
        "f1": 0.0772569448944385,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.0772569448944385,
        "precision": 0.06854178075031037,
        "recall": 0.11835506519558676
      },
      {
        "accuracy": 0.13941825476429287,
        "f1": 0.12520521686094838,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.12520521686094838,
        "precision": 0.12255176657954069,
        "recall": 0.13941825476429287
      },
      {
        "accuracy": 0.20160481444332998,
        "f1": 0.1276525090812001,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.1276525090812001,
        "precision": 0.10932861744296048,
        "recall": 0.20160481444332998
      },
      {
        "accuracy": 0.05616850551654965,
        "f1": 0.045046866338763765,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.045046866338763765,
        "precision": 0.04287320729842126,
        "recall": 0.05616850551654965
      },
      {
        "accuracy": 0.12938816449348045,
        "f1": 0.07147396055954147,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.07147396055954147,
        "precision": 0.058824752807358514,
        "recall": 0.12938816449348045
      },
      {
        "accuracy": 0.033099297893681046,
        "f1": 0.025801011257380366,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.025801011257380366,
        "precision": 0.024174714838143478,
        "recall": 0.033099297893681046
      },
      {
        "accuracy": 0.12938816449348045,
        "f1": 0.08321122601290691,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.08321122601290691,
        "precision": 0.07126882442279854,
        "recall": 0.12938816449348045
      },
      {
        "accuracy": 0.044132397191574725,
        "f1": 0.03729084394356071,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.03729084394356071,
        "precision": 0.035795492216137474,
        "recall": 0.044132397191574725
      },
      {
        "accuracy": 0.14343029087261785,
        "f1": 0.094250673156254,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.094250673156254,
        "precision": 0.08249064171832478,
        "recall": 0.14343029087261785
      },
      {
        "accuracy": 0.02708124373119358,
        "f1": 0.022220507676876784,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.022220507676876784,
        "precision": 0.021066981950084978,
        "recall": 0.02708124373119358
      },
      {
        "accuracy": 0.10030090270812438,
        "f1": 0.04994266282908749,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.04994266282908749,
        "precision": 0.04121185390100063,
        "recall": 0.10030090270812438
      },
      {
        "accuracy": 0.02708124373119358,
        "f1": 0.0213797114306399,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0213797114306399,
        "precision": 0.020596832544859334,
        "recall": 0.02708124373119358
      },
      {
        "accuracy": 0.11835506519558676,
        "f1": 0.07170948948501284,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.07170948948501284,
        "precision": 0.060988758307344265,
        "recall": 0.11835506519558676
      },
      {
        "accuracy": 0.04312938816449348,
        "f1": 0.035424202700608184,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.035424202700608184,
        "precision": 0.03361396464143331,
        "recall": 0.04312938816449348
      },
      {
        "accuracy": 0.1283851554663992,
        "f1": 0.08146825650955689,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.08146825650955689,
        "precision": 0.0701856311246983,
        "recall": 0.1283851554663992
      },
      {
        "accuracy": 0.07823470411233702,
        "f1": 0.0650805203933669,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0650805203933669,
        "precision": 0.06200186325172864,
        "recall": 0.07823470411233702
      },
      {
        "accuracy": 0.16649949849548645,
        "f1": 0.11676221427187881,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.11676221427187881,
        "precision": 0.10233294204140568,
        "recall": 0.16649949849548645
      },
      {
        "accuracy": 0.03009027081243731,
        "f1": 0.024627244146106075,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.024627244146106075,
        "precision": 0.023516336555453907,
        "recall": 0.03009027081243731
      },
      {
        "accuracy": 0.11334002006018054,
        "f1": 0.07260373078806641,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.07260373078806641,
        "precision": 0.062247922232840217,
        "recall": 0.11334002006018054
      },
      {
        "accuracy": 0.05015045135406219,
        "f1": 0.04323084694198034,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.04323084694198034,
        "precision": 0.041710940768672974,
        "recall": 0.05015045135406219
      },
      {
        "accuracy": 0.1514543630892678,
        "f1": 0.09577117237457324,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.09577117237457324,
        "precision": 0.08251828090587016,
        "recall": 0.1514543630892678
      },
      {
        "accuracy": 0.05215646940822467,
        "f1": 0.045547816634260316,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.045547816634260316,
        "precision": 0.04370578294541194,
        "recall": 0.05215646940822467
      },
      {
        "accuracy": 0.15747241725175526,
        "f1": 0.10470254354169256,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.10470254354169256,
        "precision": 0.09145340617256363,
        "recall": 0.15747241725175526
      },
      {
        "accuracy": 0.0320962888665998,
        "f1": 0.027540454824356644,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.027540454824356644,
        "precision": 0.026488940405404737,
        "recall": 0.0320962888665998
      },
      {
        "accuracy": 0.11634904714142427,
        "f1": 0.05913925219912441,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.05913925219912441,
        "precision": 0.048176298423052086,
        "recall": 0.11634904714142427
      },
      {
        "accuracy": 0.0320962888665998,
        "f1": 0.026125845755322417,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.026125845755322417,
        "precision": 0.024901833928915176,
        "recall": 0.0320962888665998
      },
      {
        "accuracy": 0.1283851554663992,
        "f1": 0.0892346830050184,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.0892346830050184,
        "precision": 0.07897106138890315,
        "recall": 0.1283851554663992
      },
      {
        "accuracy": 0.03610832497492478,
        "f1": 0.028970760218613365,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.028970760218613365,
        "precision": 0.02759405025034725,
        "recall": 0.03610832497492478
      },
      {
        "accuracy": 0.15045135406218657,
        "f1": 0.10323301905202338,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.10323301905202338,
        "precision": 0.0914438753841881,
        "recall": 0.15045135406218657
      },
      {
        "accuracy": 0.009027081243731194,
        "f1": 0.007101576839361623,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.007101576839361623,
        "precision": 0.0070625196325869435,
        "recall": 0.009027081243731194
      },
      {
        "accuracy": 0.02106318956870612,
        "f1": 0.0067958537617514555,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0067958537617514555,
        "precision": 0.004968842591711197,
        "recall": 0.02106318956870612
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}