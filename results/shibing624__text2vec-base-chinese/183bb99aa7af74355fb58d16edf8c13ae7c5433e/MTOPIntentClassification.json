{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "task_name": "MTOPIntentClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.402479,
        "f1": 0.254762,
        "f1_weighted": 0.452533,
        "scores_per_experiment": [
          {
            "accuracy": 0.418182,
            "f1": 0.259742,
            "f1_weighted": 0.467523
          },
          {
            "accuracy": 0.397245,
            "f1": 0.264272,
            "f1_weighted": 0.447854
          },
          {
            "accuracy": 0.395592,
            "f1": 0.236848,
            "f1_weighted": 0.441514
          },
          {
            "accuracy": 0.358678,
            "f1": 0.232302,
            "f1_weighted": 0.403917
          },
          {
            "accuracy": 0.426997,
            "f1": 0.265485,
            "f1_weighted": 0.47786
          },
          {
            "accuracy": 0.385124,
            "f1": 0.25084,
            "f1_weighted": 0.433741
          },
          {
            "accuracy": 0.423691,
            "f1": 0.257616,
            "f1_weighted": 0.474955
          },
          {
            "accuracy": 0.407713,
            "f1": 0.263936,
            "f1_weighted": 0.464985
          },
          {
            "accuracy": 0.395592,
            "f1": 0.266786,
            "f1_weighted": 0.448315
          },
          {
            "accuracy": 0.415978,
            "f1": 0.249791,
            "f1_weighted": 0.464671
          }
        ],
        "main_score": 0.402479,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.415441,
        "f1": 0.288625,
        "f1_weighted": 0.465783,
        "scores_per_experiment": [
          {
            "accuracy": 0.428008,
            "f1": 0.303038,
            "f1_weighted": 0.477407
          },
          {
            "accuracy": 0.399267,
            "f1": 0.284694,
            "f1_weighted": 0.452935
          },
          {
            "accuracy": 0.412229,
            "f1": 0.292975,
            "f1_weighted": 0.460516
          },
          {
            "accuracy": 0.377008,
            "f1": 0.26559,
            "f1_weighted": 0.421918
          },
          {
            "accuracy": 0.451677,
            "f1": 0.294793,
            "f1_weighted": 0.505805
          },
          {
            "accuracy": 0.387433,
            "f1": 0.274113,
            "f1_weighted": 0.433816
          },
          {
            "accuracy": 0.43308,
            "f1": 0.297841,
            "f1_weighted": 0.480044
          },
          {
            "accuracy": 0.4204,
            "f1": 0.291613,
            "f1_weighted": 0.477482
          },
          {
            "accuracy": 0.418146,
            "f1": 0.297993,
            "f1_weighted": 0.473927
          },
          {
            "accuracy": 0.427163,
            "f1": 0.283596,
            "f1_weighted": 0.473983
          }
        ],
        "main_score": 0.415441,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 60.48908448219299,
  "kg_co2_emissions": null
}