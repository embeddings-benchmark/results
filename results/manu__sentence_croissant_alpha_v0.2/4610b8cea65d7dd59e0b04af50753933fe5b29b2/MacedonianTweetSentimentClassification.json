{
  "dataset_revision": "957e075ba35e4417ba7837987fd7053a6533a1a2",
  "task_name": "MacedonianTweetSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.426251,
        "f1": 0.390617,
        "f1_weighted": 0.421034,
        "scores_per_experiment": [
          {
            "accuracy": 0.446883,
            "f1": 0.408359,
            "f1_weighted": 0.444398
          },
          {
            "accuracy": 0.420544,
            "f1": 0.39371,
            "f1_weighted": 0.430353
          },
          {
            "accuracy": 0.395961,
            "f1": 0.377453,
            "f1_weighted": 0.395545
          },
          {
            "accuracy": 0.423178,
            "f1": 0.389283,
            "f1_weighted": 0.406154
          },
          {
            "accuracy": 0.460053,
            "f1": 0.432422,
            "f1_weighted": 0.45834
          },
          {
            "accuracy": 0.400351,
            "f1": 0.338844,
            "f1_weighted": 0.366562
          },
          {
            "accuracy": 0.43986,
            "f1": 0.401756,
            "f1_weighted": 0.438234
          },
          {
            "accuracy": 0.430202,
            "f1": 0.411427,
            "f1_weighted": 0.440878
          },
          {
            "accuracy": 0.421422,
            "f1": 0.35609,
            "f1_weighted": 0.395885
          },
          {
            "accuracy": 0.424056,
            "f1": 0.396828,
            "f1_weighted": 0.433992
          }
        ],
        "main_score": 0.426251,
        "hf_subset": "default",
        "languages": [
          "mkd-Cyrl"
        ]
      }
    ]
  },
  "evaluation_time": 12.184520244598389,
  "kg_co2_emissions": 0.0006221586539816527
}