{
  "dataset_revision": "3e0319203c7162b9c9f8015b594441f979c199bc",
  "task_name": "ToxicChatClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.720361,
        "f1": 0.613133,
        "f1_weighted": 0.761471,
        "ap": 0.249306,
        "ap_weighted": 0.249306,
        "scores_per_experiment": [
          {
            "accuracy": 0.627148,
            "f1": 0.544427,
            "f1_weighted": 0.689856,
            "ap": 0.204531,
            "ap_weighted": 0.204531
          },
          {
            "accuracy": 0.841924,
            "f1": 0.680006,
            "f1_weighted": 0.850529,
            "ap": 0.268357,
            "ap_weighted": 0.268357
          },
          {
            "accuracy": 0.825601,
            "f1": 0.697777,
            "f1_weighted": 0.84502,
            "ap": 0.310829,
            "ap_weighted": 0.310829
          },
          {
            "accuracy": 0.648625,
            "f1": 0.56474,
            "f1_weighted": 0.707887,
            "ap": 0.221694,
            "ap_weighted": 0.221694
          },
          {
            "accuracy": 0.530928,
            "f1": 0.468827,
            "f1_weighted": 0.604887,
            "ap": 0.1646,
            "ap_weighted": 0.1646
          },
          {
            "accuracy": 0.823883,
            "f1": 0.695976,
            "f1_weighted": 0.843705,
            "ap": 0.308752,
            "ap_weighted": 0.308752
          },
          {
            "accuracy": 0.729381,
            "f1": 0.621709,
            "f1_weighted": 0.772901,
            "ap": 0.251707,
            "ap_weighted": 0.251707
          },
          {
            "accuracy": 0.60567,
            "f1": 0.536015,
            "f1_weighted": 0.670691,
            "ap": 0.21116,
            "ap_weighted": 0.21116
          },
          {
            "accuracy": 0.792096,
            "f1": 0.657312,
            "f1_weighted": 0.818314,
            "ap": 0.262133,
            "ap_weighted": 0.262133
          },
          {
            "accuracy": 0.778351,
            "f1": 0.664535,
            "f1_weighted": 0.810917,
            "ap": 0.289296,
            "ap_weighted": 0.289296
          }
        ],
        "main_score": 0.720361,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 25.41139507293701,
  "kg_co2_emissions": 0.0014403552478274072
}