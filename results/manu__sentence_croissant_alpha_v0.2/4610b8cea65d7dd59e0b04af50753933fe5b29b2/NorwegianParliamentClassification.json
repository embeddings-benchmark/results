{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.550167,
        "f1": 0.546274,
        "f1_weighted": 0.546274,
        "ap": 0.528268,
        "ap_weighted": 0.528268,
        "scores_per_experiment": [
          {
            "accuracy": 0.526667,
            "f1": 0.519153,
            "f1_weighted": 0.519153,
            "ap": 0.514281,
            "ap_weighted": 0.514281
          },
          {
            "accuracy": 0.518333,
            "f1": 0.50823,
            "f1_weighted": 0.50823,
            "ap": 0.509428,
            "ap_weighted": 0.509428
          },
          {
            "accuracy": 0.573333,
            "f1": 0.573291,
            "f1_weighted": 0.573291,
            "ap": 0.542154,
            "ap_weighted": 0.542154
          },
          {
            "accuracy": 0.585833,
            "f1": 0.58575,
            "f1_weighted": 0.58575,
            "ap": 0.550499,
            "ap_weighted": 0.550499
          },
          {
            "accuracy": 0.576667,
            "f1": 0.575221,
            "f1_weighted": 0.575221,
            "ap": 0.543597,
            "ap_weighted": 0.543597
          },
          {
            "accuracy": 0.5225,
            "f1": 0.51743,
            "f1_weighted": 0.51743,
            "ap": 0.51167,
            "ap_weighted": 0.51167
          },
          {
            "accuracy": 0.544167,
            "f1": 0.543276,
            "f1_weighted": 0.543276,
            "ap": 0.523876,
            "ap_weighted": 0.523876
          },
          {
            "accuracy": 0.529167,
            "f1": 0.518206,
            "f1_weighted": 0.518206,
            "ap": 0.515237,
            "ap_weighted": 0.515237
          },
          {
            "accuracy": 0.585833,
            "f1": 0.585024,
            "f1_weighted": 0.585024,
            "ap": 0.550998,
            "ap_weighted": 0.550998
          },
          {
            "accuracy": 0.539167,
            "f1": 0.537161,
            "f1_weighted": 0.537161,
            "ap": 0.520939,
            "ap_weighted": 0.520939
          }
        ],
        "main_score": 0.550167,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.548583,
        "f1": 0.544707,
        "f1_weighted": 0.544707,
        "ap": 0.528397,
        "ap_weighted": 0.528397,
        "scores_per_experiment": [
          {
            "accuracy": 0.508333,
            "f1": 0.500946,
            "f1_weighted": 0.500946,
            "ap": 0.504258,
            "ap_weighted": 0.504258
          },
          {
            "accuracy": 0.501667,
            "f1": 0.492182,
            "f1_weighted": 0.492182,
            "ap": 0.500836,
            "ap_weighted": 0.500836
          },
          {
            "accuracy": 0.595,
            "f1": 0.594945,
            "f1_weighted": 0.594945,
            "ap": 0.556741,
            "ap_weighted": 0.556741
          },
          {
            "accuracy": 0.600833,
            "f1": 0.600753,
            "f1_weighted": 0.600753,
            "ap": 0.560881,
            "ap_weighted": 0.560881
          },
          {
            "accuracy": 0.571667,
            "f1": 0.569657,
            "f1_weighted": 0.569657,
            "ap": 0.540352,
            "ap_weighted": 0.540352
          },
          {
            "accuracy": 0.485833,
            "f1": 0.480374,
            "f1_weighted": 0.480374,
            "ap": 0.493083,
            "ap_weighted": 0.493083
          },
          {
            "accuracy": 0.546667,
            "f1": 0.546514,
            "f1_weighted": 0.546514,
            "ap": 0.525434,
            "ap_weighted": 0.525434
          },
          {
            "accuracy": 0.518333,
            "f1": 0.505948,
            "f1_weighted": 0.505948,
            "ap": 0.509422,
            "ap_weighted": 0.509422
          },
          {
            "accuracy": 0.608333,
            "f1": 0.608264,
            "f1_weighted": 0.608264,
            "ap": 0.566224,
            "ap_weighted": 0.566224
          },
          {
            "accuracy": 0.549167,
            "f1": 0.547492,
            "f1_weighted": 0.547492,
            "ap": 0.526738,
            "ap_weighted": 0.526738
          }
        ],
        "main_score": 0.548583,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 127.47369861602783,
  "kg_co2_emissions": 0.01020144346604069
}