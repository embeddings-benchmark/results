{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.788428,
        "f1": 0.787356,
        "f1_weighted": 0.787348,
        "ap": 0.730514,
        "ap_weighted": 0.730514,
        "scores_per_experiment": [
          {
            "accuracy": 0.776367,
            "f1": 0.776254,
            "f1_weighted": 0.776269,
            "ap": 0.712672,
            "ap_weighted": 0.712672
          },
          {
            "accuracy": 0.796875,
            "f1": 0.796868,
            "f1_weighted": 0.796865,
            "ap": 0.73911,
            "ap_weighted": 0.73911
          },
          {
            "accuracy": 0.782227,
            "f1": 0.780569,
            "f1_weighted": 0.780513,
            "ap": 0.739356,
            "ap_weighted": 0.739356
          },
          {
            "accuracy": 0.755371,
            "f1": 0.752219,
            "f1_weighted": 0.752137,
            "ap": 0.713823,
            "ap_weighted": 0.713823
          },
          {
            "accuracy": 0.740723,
            "f1": 0.737724,
            "f1_weighted": 0.737641,
            "ap": 0.695951,
            "ap_weighted": 0.695951
          },
          {
            "accuracy": 0.809082,
            "f1": 0.808783,
            "f1_weighted": 0.808805,
            "ap": 0.744397,
            "ap_weighted": 0.744397
          },
          {
            "accuracy": 0.78418,
            "f1": 0.782787,
            "f1_weighted": 0.782838,
            "ap": 0.712909,
            "ap_weighted": 0.712909
          },
          {
            "accuracy": 0.826172,
            "f1": 0.825865,
            "f1_weighted": 0.825886,
            "ap": 0.762544,
            "ap_weighted": 0.762544
          },
          {
            "accuracy": 0.789062,
            "f1": 0.78905,
            "f1_weighted": 0.789054,
            "ap": 0.728245,
            "ap_weighted": 0.728245
          },
          {
            "accuracy": 0.824219,
            "f1": 0.82344,
            "f1_weighted": 0.823475,
            "ap": 0.756133,
            "ap_weighted": 0.756133
          }
        ],
        "main_score": 0.788428,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.772412,
        "f1": 0.771155,
        "f1_weighted": 0.771145,
        "ap": 0.714536,
        "ap_weighted": 0.714536,
        "scores_per_experiment": [
          {
            "accuracy": 0.775879,
            "f1": 0.77578,
            "f1_weighted": 0.775789,
            "ap": 0.711912,
            "ap_weighted": 0.711912
          },
          {
            "accuracy": 0.787598,
            "f1": 0.787495,
            "f1_weighted": 0.787486,
            "ap": 0.731347,
            "ap_weighted": 0.731347
          },
          {
            "accuracy": 0.75293,
            "f1": 0.750739,
            "f1_weighted": 0.750693,
            "ap": 0.706422,
            "ap_weighted": 0.706422
          },
          {
            "accuracy": 0.744141,
            "f1": 0.740144,
            "f1_weighted": 0.740081,
            "ap": 0.702646,
            "ap_weighted": 0.702646
          },
          {
            "accuracy": 0.738281,
            "f1": 0.734258,
            "f1_weighted": 0.734194,
            "ap": 0.695752,
            "ap_weighted": 0.695752
          },
          {
            "accuracy": 0.782715,
            "f1": 0.782468,
            "f1_weighted": 0.782482,
            "ap": 0.717141,
            "ap_weighted": 0.717141
          },
          {
            "accuracy": 0.768066,
            "f1": 0.76693,
            "f1_weighted": 0.766962,
            "ap": 0.697919,
            "ap_weighted": 0.697919
          },
          {
            "accuracy": 0.811523,
            "f1": 0.81125,
            "f1_weighted": 0.811264,
            "ap": 0.746826,
            "ap_weighted": 0.746826
          },
          {
            "accuracy": 0.77002,
            "f1": 0.77001,
            "f1_weighted": 0.770007,
            "ap": 0.709852,
            "ap_weighted": 0.709852
          },
          {
            "accuracy": 0.792969,
            "f1": 0.792474,
            "f1_weighted": 0.792494,
            "ap": 0.725546,
            "ap_weighted": 0.725546
          }
        ],
        "main_score": 0.772412,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 73.41975378990173,
  "kg_co2_emissions": 0.004880180706298246
}