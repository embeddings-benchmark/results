{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "2.3.2",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.589666,
            "f1": 0.516477,
            "f1_weighted": 0.657709,
            "precision": 0.579456,
            "precision_weighted": 0.859645,
            "recall": 0.681953,
            "recall_weighted": 0.589666,
            "ap": 0.918583,
            "ap_weighted": 0.918583
          },
          {
            "accuracy": 0.680851,
            "f1": 0.560815,
            "f1_weighted": 0.733193,
            "precision": 0.576858,
            "precision_weighted": 0.841666,
            "recall": 0.660823,
            "recall_weighted": 0.680851,
            "ap": 0.912641,
            "ap_weighted": 0.912641
          },
          {
            "accuracy": 0.62614,
            "f1": 0.485526,
            "f1_weighted": 0.687454,
            "precision": 0.516938,
            "precision_weighted": 0.795009,
            "recall": 0.535442,
            "recall_weighted": 0.62614,
            "ap": 0.883218,
            "ap_weighted": 0.883218
          },
          {
            "accuracy": 0.620061,
            "f1": 0.490302,
            "f1_weighted": 0.683377,
            "precision": 0.524729,
            "precision_weighted": 0.801752,
            "recall": 0.552888,
            "recall_weighted": 0.620061,
            "ap": 0.887161,
            "ap_weighted": 0.887161
          },
          {
            "accuracy": 0.714286,
            "f1": 0.586285,
            "f1_weighted": 0.759051,
            "precision": 0.590327,
            "precision_weighted": 0.847619,
            "recall": 0.67992,
            "recall_weighted": 0.714286,
            "ap": 0.91722,
            "ap_weighted": 0.91722
          },
          {
            "accuracy": 0.714286,
            "f1": 0.554586,
            "f1_weighted": 0.754819,
            "precision": 0.558177,
            "precision_weighted": 0.820482,
            "recall": 0.606707,
            "recall_weighted": 0.714286,
            "ap": 0.899517,
            "ap_weighted": 0.899517
          },
          {
            "accuracy": 0.465046,
            "f1": 0.422807,
            "f1_weighted": 0.540031,
            "precision": 0.545787,
            "precision_weighted": 0.834816,
            "recall": 0.600313,
            "recall_weighted": 0.465046,
            "ap": 0.898651,
            "ap_weighted": 0.898651
          },
          {
            "accuracy": 0.674772,
            "f1": 0.552449,
            "f1_weighted": 0.72811,
            "precision": 0.5702,
            "precision_weighted": 0.836481,
            "recall": 0.646892,
            "recall_weighted": 0.674772,
            "ap": 0.909241,
            "ap_weighted": 0.909241
          },
          {
            "accuracy": 0.738602,
            "f1": 0.58293,
            "f1_weighted": 0.774228,
            "precision": 0.579367,
            "precision_weighted": 0.833115,
            "recall": 0.641514,
            "recall_weighted": 0.738602,
            "ap": 0.907736,
            "ap_weighted": 0.907736
          },
          {
            "accuracy": 0.6231,
            "f1": 0.508245,
            "f1_weighted": 0.686668,
            "precision": 0.544147,
            "precision_weighted": 0.818815,
            "recall": 0.59646,
            "recall_weighted": 0.6231,
            "ap": 0.897258,
            "ap_weighted": 0.897258
          }
        ],
        "accuracy": 0.644681,
        "f1": 0.526042,
        "f1_weighted": 0.700464,
        "precision": 0.558599,
        "precision_weighted": 0.82894,
        "recall": 0.620291,
        "recall_weighted": 0.644681,
        "ap": 0.903123,
        "ap_weighted": 0.903123,
        "main_score": 0.644681,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 46.73143672943115,
  "kg_co2_emissions": null
}