{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "task_name": "AmazonReviewsClassification",
  "mteb_version": "1.36.14",
  "scores": {
    "test": [
      {
        "accuracy": 0.4842,
        "f1": 0.479485,
        "f1_weighted": 0.479485,
        "scores_per_experiment": [
          {
            "accuracy": 0.487,
            "f1": 0.480001,
            "f1_weighted": 0.480001
          },
          {
            "accuracy": 0.4828,
            "f1": 0.480348,
            "f1_weighted": 0.480348
          },
          {
            "accuracy": 0.4782,
            "f1": 0.47929,
            "f1_weighted": 0.47929
          },
          {
            "accuracy": 0.493,
            "f1": 0.491971,
            "f1_weighted": 0.491971
          },
          {
            "accuracy": 0.503,
            "f1": 0.483271,
            "f1_weighted": 0.483271
          },
          {
            "accuracy": 0.4588,
            "f1": 0.460443,
            "f1_weighted": 0.460443
          },
          {
            "accuracy": 0.4842,
            "f1": 0.479369,
            "f1_weighted": 0.479369
          },
          {
            "accuracy": 0.5074,
            "f1": 0.506669,
            "f1_weighted": 0.506669
          },
          {
            "accuracy": 0.4736,
            "f1": 0.473166,
            "f1_weighted": 0.473166
          },
          {
            "accuracy": 0.474,
            "f1": 0.460318,
            "f1_weighted": 0.460318
          }
        ],
        "main_score": 0.4842,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.231053352355957,
  "kg_co2_emissions": null
}