{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 3e-06,
        "recall": 0.001003,
        "f1": 7e-06,
        "accuracy": 0.001003,
        "main_score": 7e-06,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00525,
        "recall": 0.014042,
        "f1": 0.006688,
        "accuracy": 0.014042,
        "main_score": 0.006688,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.003211,
        "recall": 0.005015,
        "f1": 0.003346,
        "accuracy": 0.005015,
        "main_score": 0.003346,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016465,
        "recall": 0.043129,
        "f1": 0.018974,
        "accuracy": 0.043129,
        "main_score": 0.018974,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001005,
        "accuracy": 0.002006,
        "main_score": 0.001005,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024932,
        "recall": 0.038114,
        "f1": 0.027464,
        "accuracy": 0.038114,
        "main_score": 0.027464,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001005,
        "accuracy": 0.002006,
        "main_score": 0.001005,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023144,
        "recall": 0.056169,
        "f1": 0.02663,
        "accuracy": 0.056169,
        "main_score": 0.02663,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002008,
        "accuracy": 0.003009,
        "main_score": 0.002008,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022434,
        "recall": 0.051153,
        "f1": 0.026181,
        "accuracy": 0.051153,
        "main_score": 0.026181,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001005,
        "accuracy": 0.002006,
        "main_score": 0.001005,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016103,
        "recall": 0.027081,
        "f1": 0.018215,
        "accuracy": 0.027081,
        "main_score": 0.018215,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005517,
        "recall": 0.006018,
        "f1": 0.005684,
        "accuracy": 0.006018,
        "main_score": 0.005684,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017612,
        "recall": 0.029087,
        "f1": 0.018959,
        "accuracy": 0.029087,
        "main_score": 0.018959,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.031295,
        "recall": 0.033099,
        "f1": 0.03143,
        "accuracy": 0.033099,
        "main_score": 0.03143,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.035029,
        "recall": 0.091274,
        "f1": 0.04343,
        "accuracy": 0.091274,
        "main_score": 0.04343,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.00301,
        "recall": 0.004012,
        "f1": 0.003011,
        "accuracy": 0.004012,
        "main_score": 0.003011,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021777,
        "recall": 0.039117,
        "f1": 0.025241,
        "accuracy": 0.039117,
        "main_score": 0.025241,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001006,
        "accuracy": 0.002006,
        "main_score": 0.001006,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011975,
        "recall": 0.024072,
        "f1": 0.013322,
        "accuracy": 0.024072,
        "main_score": 0.013322,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.00301,
        "recall": 0.004012,
        "f1": 0.003011,
        "accuracy": 0.004012,
        "main_score": 0.003011,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.033477,
        "recall": 0.057172,
        "f1": 0.037899,
        "accuracy": 0.057172,
        "main_score": 0.037899,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.004013,
        "recall": 0.005015,
        "f1": 0.004014,
        "accuracy": 0.005015,
        "main_score": 0.004014,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030299,
        "recall": 0.059178,
        "f1": 0.036203,
        "accuracy": 0.059178,
        "main_score": 0.036203,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.005661,
        "recall": 0.008024,
        "f1": 0.005937,
        "accuracy": 0.008024,
        "main_score": 0.005937,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025289,
        "recall": 0.058175,
        "f1": 0.029595,
        "accuracy": 0.058175,
        "main_score": 0.029595,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.004348,
        "recall": 0.006018,
        "f1": 0.004516,
        "accuracy": 0.006018,
        "main_score": 0.004516,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019354,
        "recall": 0.048144,
        "f1": 0.023029,
        "accuracy": 0.048144,
        "main_score": 0.023029,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.010031,
        "recall": 0.011033,
        "f1": 0.010032,
        "accuracy": 0.011033,
        "main_score": 0.010032,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.08185,
        "recall": 0.142427,
        "f1": 0.093312,
        "accuracy": 0.142427,
        "main_score": 0.093312,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.006019,
        "recall": 0.007021,
        "f1": 0.00602,
        "accuracy": 0.007021,
        "main_score": 0.00602,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025792,
        "recall": 0.051153,
        "f1": 0.029508,
        "accuracy": 0.051153,
        "main_score": 0.029508,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014227,
        "recall": 0.029087,
        "f1": 0.016324,
        "accuracy": 0.029087,
        "main_score": 0.016324,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001005,
        "accuracy": 0.002006,
        "main_score": 0.001005,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012103,
        "recall": 0.026078,
        "f1": 0.014068,
        "accuracy": 0.026078,
        "main_score": 0.014068,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.001024,
        "recall": 0.003009,
        "f1": 0.001044,
        "accuracy": 0.003009,
        "main_score": 0.001044,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014756,
        "recall": 0.031093,
        "f1": 0.017174,
        "accuracy": 0.031093,
        "main_score": 0.017174,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015825,
        "recall": 0.029087,
        "f1": 0.017709,
        "accuracy": 0.029087,
        "main_score": 0.017709,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002008,
        "accuracy": 0.003009,
        "main_score": 0.002008,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019049,
        "recall": 0.035105,
        "f1": 0.02174,
        "accuracy": 0.035105,
        "main_score": 0.02174,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.003211,
        "recall": 0.005015,
        "f1": 0.003346,
        "accuracy": 0.005015,
        "main_score": 0.003346,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025519,
        "recall": 0.046138,
        "f1": 0.028308,
        "accuracy": 0.046138,
        "main_score": 0.028308,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006322,
        "recall": 0.013039,
        "f1": 0.007345,
        "accuracy": 0.013039,
        "main_score": 0.007345,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026734,
        "recall": 0.046138,
        "f1": 0.030742,
        "accuracy": 0.046138,
        "main_score": 0.030742,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001005,
        "accuracy": 0.002006,
        "main_score": 0.001005,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028448,
        "recall": 0.05015,
        "f1": 0.032468,
        "accuracy": 0.05015,
        "main_score": 0.032468,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002008,
        "accuracy": 0.003009,
        "main_score": 0.002008,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0072,
        "recall": 0.013039,
        "f1": 0.007846,
        "accuracy": 0.013039,
        "main_score": 0.007846,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010461,
        "recall": 0.022066,
        "f1": 0.012413,
        "accuracy": 0.022066,
        "main_score": 0.012413,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020257,
        "recall": 0.033099,
        "f1": 0.021949,
        "accuracy": 0.033099,
        "main_score": 0.021949,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003853,
        "recall": 0.017051,
        "f1": 0.004886,
        "accuracy": 0.017051,
        "main_score": 0.004886,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.001327,
        "recall": 0.003953,
        "f1": 0.0015,
        "accuracy": 0.003953,
        "main_score": 0.0015,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006293,
        "recall": 0.013834,
        "f1": 0.007686,
        "accuracy": 0.013834,
        "main_score": 0.007686,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001977,
        "recall": 0.002964,
        "f1": 0.001978,
        "accuracy": 0.002964,
        "main_score": 0.001978,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019654,
        "recall": 0.048419,
        "f1": 0.023266,
        "accuracy": 0.048419,
        "main_score": 0.023266,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018574,
        "recall": 0.036561,
        "f1": 0.021475,
        "accuracy": 0.036561,
        "main_score": 0.021475,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003707,
        "recall": 0.005929,
        "f1": 0.00402,
        "accuracy": 0.005929,
        "main_score": 0.00402,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016995,
        "recall": 0.049407,
        "f1": 0.021811,
        "accuracy": 0.049407,
        "main_score": 0.021811,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001977,
        "recall": 0.002964,
        "f1": 0.001978,
        "accuracy": 0.002964,
        "main_score": 0.001978,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012203,
        "recall": 0.034585,
        "f1": 0.014944,
        "accuracy": 0.034585,
        "main_score": 0.014944,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011791,
        "recall": 0.025692,
        "f1": 0.014039,
        "accuracy": 0.025692,
        "main_score": 0.014039,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00593,
        "recall": 0.006917,
        "f1": 0.005932,
        "accuracy": 0.006917,
        "main_score": 0.005932,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01438,
        "recall": 0.025692,
        "f1": 0.01639,
        "accuracy": 0.025692,
        "main_score": 0.01639,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.027998,
        "recall": 0.030632,
        "f1": 0.028493,
        "accuracy": 0.030632,
        "main_score": 0.028493,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.054033,
        "recall": 0.113636,
        "f1": 0.064003,
        "accuracy": 0.113636,
        "main_score": 0.064003,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002966,
        "recall": 0.003953,
        "f1": 0.002967,
        "accuracy": 0.003953,
        "main_score": 0.002967,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008094,
        "recall": 0.02668,
        "f1": 0.010258,
        "accuracy": 0.02668,
        "main_score": 0.010258,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000988,
        "recall": 0.000988,
        "f1": 0.000988,
        "accuracy": 0.000988,
        "main_score": 0.000988,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006741,
        "recall": 0.017787,
        "f1": 0.008125,
        "accuracy": 0.017787,
        "main_score": 0.008125,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.002965,
        "recall": 0.003953,
        "f1": 0.002966,
        "accuracy": 0.003953,
        "main_score": 0.002966,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.032952,
        "recall": 0.056324,
        "f1": 0.037257,
        "accuracy": 0.056324,
        "main_score": 0.037257,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.006424,
        "recall": 0.007905,
        "f1": 0.00659,
        "accuracy": 0.007905,
        "main_score": 0.00659,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.033327,
        "recall": 0.062253,
        "f1": 0.039053,
        "accuracy": 0.062253,
        "main_score": 0.039053,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.003295,
        "recall": 0.005929,
        "f1": 0.00379,
        "accuracy": 0.005929,
        "main_score": 0.00379,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017811,
        "recall": 0.049407,
        "f1": 0.021697,
        "accuracy": 0.049407,
        "main_score": 0.021697,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.004942,
        "recall": 0.005929,
        "f1": 0.004943,
        "accuracy": 0.005929,
        "main_score": 0.004943,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022376,
        "recall": 0.052372,
        "f1": 0.026102,
        "accuracy": 0.052372,
        "main_score": 0.026102,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019767,
        "recall": 0.021739,
        "f1": 0.019771,
        "accuracy": 0.021739,
        "main_score": 0.019771,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.067275,
        "recall": 0.123518,
        "f1": 0.07749,
        "accuracy": 0.123518,
        "main_score": 0.07749,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.005018,
        "recall": 0.006917,
        "f1": 0.005084,
        "accuracy": 0.006917,
        "main_score": 0.005084,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024298,
        "recall": 0.05336,
        "f1": 0.029161,
        "accuracy": 0.05336,
        "main_score": 0.029161,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002965,
        "recall": 0.003953,
        "f1": 0.002966,
        "accuracy": 0.003953,
        "main_score": 0.002966,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014835,
        "recall": 0.032609,
        "f1": 0.018046,
        "accuracy": 0.032609,
        "main_score": 0.018046,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003957,
        "recall": 0.016798,
        "f1": 0.005995,
        "accuracy": 0.016798,
        "main_score": 0.005995,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00984,
        "recall": 0.02668,
        "f1": 0.012762,
        "accuracy": 0.02668,
        "main_score": 0.012762,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.001977,
        "recall": 0.002964,
        "f1": 0.001978,
        "accuracy": 0.002964,
        "main_score": 0.001978,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016959,
        "recall": 0.033597,
        "f1": 0.01968,
        "accuracy": 0.033597,
        "main_score": 0.01968,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.001483,
        "recall": 0.002964,
        "f1": 0.001649,
        "accuracy": 0.002964,
        "main_score": 0.001649,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020142,
        "recall": 0.035573,
        "f1": 0.023128,
        "accuracy": 0.035573,
        "main_score": 0.023128,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.004448,
        "recall": 0.005929,
        "f1": 0.004613,
        "accuracy": 0.005929,
        "main_score": 0.004613,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.033758,
        "recall": 0.056324,
        "f1": 0.037337,
        "accuracy": 0.056324,
        "main_score": 0.037337,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010571,
        "recall": 0.019763,
        "f1": 0.012032,
        "accuracy": 0.019763,
        "main_score": 0.012032,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.001977,
        "recall": 0.003953,
        "f1": 0.002308,
        "accuracy": 0.003953,
        "main_score": 0.002308,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023777,
        "recall": 0.043478,
        "f1": 0.027519,
        "accuracy": 0.043478,
        "main_score": 0.027519,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.001483,
        "recall": 0.002964,
        "f1": 0.001649,
        "accuracy": 0.002964,
        "main_score": 0.001649,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026234,
        "recall": 0.050395,
        "f1": 0.030615,
        "accuracy": 0.050395,
        "main_score": 0.030615,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.00223,
        "recall": 0.004941,
        "f1": 0.002385,
        "accuracy": 0.004941,
        "main_score": 0.002385,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008567,
        "recall": 0.017787,
        "f1": 0.009906,
        "accuracy": 0.017787,
        "main_score": 0.009906,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.001977,
        "recall": 0.002964,
        "f1": 0.001978,
        "accuracy": 0.002964,
        "main_score": 0.001978,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011651,
        "recall": 0.028656,
        "f1": 0.014756,
        "accuracy": 0.028656,
        "main_score": 0.014756,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.000495,
        "recall": 0.001976,
        "f1": 0.000661,
        "accuracy": 0.001976,
        "main_score": 0.000661,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020041,
        "recall": 0.043478,
        "f1": 0.024552,
        "accuracy": 0.043478,
        "main_score": 0.024552,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006221,
        "recall": 0.019763,
        "f1": 0.007907,
        "accuracy": 0.019763,
        "main_score": 0.007907,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 46.15502882003784,
  "kg_co2_emissions": 0.0018362251897132424
}