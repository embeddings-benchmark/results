{
  "dataset_revision": "bd27d0058bea2ad52470d9072a3b5da6b97c1ac3",
  "task_name": "VaccinChatNLClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.216239,
            "f1": 0.237205,
            "f1_weighted": 0.195687,
            "precision": 0.307772,
            "precision_weighted": 0.417425,
            "recall": 0.395848,
            "recall_weighted": 0.216239,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.266667,
            "f1": 0.280196,
            "f1_weighted": 0.240879,
            "precision": 0.328258,
            "precision_weighted": 0.468521,
            "recall": 0.441009,
            "recall_weighted": 0.266667,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.25812,
            "f1": 0.296552,
            "f1_weighted": 0.232593,
            "precision": 0.35311,
            "precision_weighted": 0.421386,
            "recall": 0.427185,
            "recall_weighted": 0.25812,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.249573,
            "f1": 0.244747,
            "f1_weighted": 0.222385,
            "precision": 0.265478,
            "precision_weighted": 0.350181,
            "recall": 0.390679,
            "recall_weighted": 0.249573,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.253846,
            "f1": 0.266429,
            "f1_weighted": 0.222327,
            "precision": 0.308509,
            "precision_weighted": 0.370752,
            "recall": 0.407525,
            "recall_weighted": 0.253846,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.252137,
            "f1": 0.262806,
            "f1_weighted": 0.232877,
            "precision": 0.302996,
            "precision_weighted": 0.385401,
            "recall": 0.405442,
            "recall_weighted": 0.252137,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.254701,
            "f1": 0.260708,
            "f1_weighted": 0.216477,
            "precision": 0.293366,
            "precision_weighted": 0.301108,
            "recall": 0.39285,
            "recall_weighted": 0.254701,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.223077,
            "f1": 0.236326,
            "f1_weighted": 0.190725,
            "precision": 0.273142,
            "precision_weighted": 0.31296,
            "recall": 0.376475,
            "recall_weighted": 0.223077,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.251282,
            "f1": 0.26791,
            "f1_weighted": 0.210695,
            "precision": 0.307427,
            "precision_weighted": 0.325557,
            "recall": 0.419655,
            "recall_weighted": 0.251282,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.232479,
            "f1": 0.249264,
            "f1_weighted": 0.196521,
            "precision": 0.2852,
            "precision_weighted": 0.342018,
            "recall": 0.399173,
            "recall_weighted": 0.232479,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.245812,
        "f1": 0.260214,
        "f1_weighted": 0.216117,
        "precision": 0.302526,
        "precision_weighted": 0.369531,
        "recall": 0.405584,
        "recall_weighted": 0.245812,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.260214,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 25.927684783935547,
  "kg_co2_emissions": null
}