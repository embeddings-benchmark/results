{
  "dataset_revision": "55caf0e52693a1ea63b15a4980a73fc137fb862b",
  "task_name": "IsiZuluNewsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.24016,
        "f1": 0.187977,
        "f1_weighted": 0.241796,
        "scores_per_experiment": [
          {
            "accuracy": 0.227394,
            "f1": 0.168538,
            "f1_weighted": 0.234503
          },
          {
            "accuracy": 0.275266,
            "f1": 0.190692,
            "f1_weighted": 0.294821
          },
          {
            "accuracy": 0.231383,
            "f1": 0.179915,
            "f1_weighted": 0.227178
          },
          {
            "accuracy": 0.211436,
            "f1": 0.169273,
            "f1_weighted": 0.205763
          },
          {
            "accuracy": 0.284574,
            "f1": 0.223198,
            "f1_weighted": 0.295054
          },
          {
            "accuracy": 0.25,
            "f1": 0.197906,
            "f1_weighted": 0.250506
          },
          {
            "accuracy": 0.198138,
            "f1": 0.182023,
            "f1_weighted": 0.185828
          },
          {
            "accuracy": 0.231383,
            "f1": 0.175708,
            "f1_weighted": 0.233173
          },
          {
            "accuracy": 0.246011,
            "f1": 0.191788,
            "f1_weighted": 0.237293
          },
          {
            "accuracy": 0.246011,
            "f1": 0.200731,
            "f1_weighted": 0.253837
          }
        ],
        "main_score": 0.24016,
        "hf_subset": "default",
        "languages": [
          "zul-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 6.5574986934661865,
  "kg_co2_emissions": 0.00018733619693037763
}