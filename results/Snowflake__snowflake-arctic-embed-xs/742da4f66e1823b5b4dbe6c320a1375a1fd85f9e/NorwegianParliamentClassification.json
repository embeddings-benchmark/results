{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.5415,
        "f1": 0.535449,
        "f1_weighted": 0.535449,
        "ap": 0.522746,
        "ap_weighted": 0.522746,
        "scores_per_experiment": [
          {
            "accuracy": 0.5425,
            "f1": 0.539615,
            "f1_weighted": 0.539615,
            "ap": 0.522809,
            "ap_weighted": 0.522809
          },
          {
            "accuracy": 0.538333,
            "f1": 0.53367,
            "f1_weighted": 0.53367,
            "ap": 0.521003,
            "ap_weighted": 0.521003
          },
          {
            "accuracy": 0.58,
            "f1": 0.571603,
            "f1_weighted": 0.571603,
            "ap": 0.545,
            "ap_weighted": 0.545
          },
          {
            "accuracy": 0.566667,
            "f1": 0.553244,
            "f1_weighted": 0.553244,
            "ap": 0.536634,
            "ap_weighted": 0.536634
          },
          {
            "accuracy": 0.545833,
            "f1": 0.543089,
            "f1_weighted": 0.543089,
            "ap": 0.524735,
            "ap_weighted": 0.524735
          },
          {
            "accuracy": 0.508333,
            "f1": 0.504467,
            "f1_weighted": 0.504467,
            "ap": 0.504226,
            "ap_weighted": 0.504226
          },
          {
            "accuracy": 0.531667,
            "f1": 0.513482,
            "f1_weighted": 0.513482,
            "ap": 0.516556,
            "ap_weighted": 0.516556
          },
          {
            "accuracy": 0.494167,
            "f1": 0.493023,
            "f1_weighted": 0.493023,
            "ap": 0.497121,
            "ap_weighted": 0.497121
          },
          {
            "accuracy": 0.561667,
            "f1": 0.561607,
            "f1_weighted": 0.561607,
            "ap": 0.534727,
            "ap_weighted": 0.534727
          },
          {
            "accuracy": 0.545833,
            "f1": 0.540689,
            "f1_weighted": 0.540689,
            "ap": 0.52465,
            "ap_weighted": 0.52465
          }
        ],
        "main_score": 0.5415,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.55275,
        "f1": 0.546597,
        "f1_weighted": 0.546597,
        "ap": 0.53019,
        "ap_weighted": 0.53019,
        "scores_per_experiment": [
          {
            "accuracy": 0.5375,
            "f1": 0.531922,
            "f1_weighted": 0.531922,
            "ap": 0.519904,
            "ap_weighted": 0.519904
          },
          {
            "accuracy": 0.535833,
            "f1": 0.531681,
            "f1_weighted": 0.531681,
            "ap": 0.519499,
            "ap_weighted": 0.519499
          },
          {
            "accuracy": 0.605,
            "f1": 0.597294,
            "f1_weighted": 0.597294,
            "ap": 0.561136,
            "ap_weighted": 0.561136
          },
          {
            "accuracy": 0.5825,
            "f1": 0.568386,
            "f1_weighted": 0.568386,
            "ap": 0.546248,
            "ap_weighted": 0.546248
          },
          {
            "accuracy": 0.5975,
            "f1": 0.594628,
            "f1_weighted": 0.594628,
            "ap": 0.556887,
            "ap_weighted": 0.556887
          },
          {
            "accuracy": 0.5425,
            "f1": 0.540609,
            "f1_weighted": 0.540609,
            "ap": 0.522851,
            "ap_weighted": 0.522851
          },
          {
            "accuracy": 0.515833,
            "f1": 0.499152,
            "f1_weighted": 0.499152,
            "ap": 0.5081,
            "ap_weighted": 0.5081
          },
          {
            "accuracy": 0.4825,
            "f1": 0.482491,
            "f1_weighted": 0.482491,
            "ap": 0.491559,
            "ap_weighted": 0.491559
          },
          {
            "accuracy": 0.600833,
            "f1": 0.60032,
            "f1_weighted": 0.60032,
            "ap": 0.561369,
            "ap_weighted": 0.561369
          },
          {
            "accuracy": 0.5275,
            "f1": 0.519483,
            "f1_weighted": 0.519483,
            "ap": 0.514351,
            "ap_weighted": 0.514351
          }
        ],
        "main_score": 0.55275,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 14.102915287017822,
  "kg_co2_emissions": 0.00045095459492357714
}