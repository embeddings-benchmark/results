{
  "dataset_revision": "f333c1fcfa3ab43f008a327c8bd0140441354d34",
  "task_name": "BrazilianToxicTweetsClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.209717,
        "f1": 0.155552,
        "lrap": 0.791368,
        "scores_per_experiment": [
          {
            "accuracy": 0.179199,
            "f1": 0.170606,
            "lrap": 0.841105
          },
          {
            "accuracy": 0.113281,
            "f1": 0.160249,
            "lrap": 0.801568
          },
          {
            "accuracy": 0.167969,
            "f1": 0.164052,
            "lrap": 0.828478
          },
          {
            "accuracy": 0.328613,
            "f1": 0.145528,
            "lrap": 0.77653
          },
          {
            "accuracy": 0.32373,
            "f1": 0.147569,
            "lrap": 0.781508
          },
          {
            "accuracy": 0.233398,
            "f1": 0.159572,
            "lrap": 0.792521
          },
          {
            "accuracy": 0.123535,
            "f1": 0.124876,
            "lrap": 0.749037
          },
          {
            "accuracy": 0.107422,
            "f1": 0.188177,
            "lrap": 0.781413
          },
          {
            "accuracy": 0.274902,
            "f1": 0.160106,
            "lrap": 0.767782
          },
          {
            "accuracy": 0.245117,
            "f1": 0.13479,
            "lrap": 0.793742
          }
        ],
        "main_score": 0.209717,
        "hf_subset": "default",
        "languages": [
          "por-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 4.205421447753906,
  "kg_co2_emissions": 0.00017036785322559723
}