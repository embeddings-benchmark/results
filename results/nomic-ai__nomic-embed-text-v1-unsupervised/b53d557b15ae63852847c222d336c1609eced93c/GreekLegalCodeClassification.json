{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.054395,
        "f1": 0.034913,
        "f1_weighted": 0.044205,
        "scores_per_experiment": [
          {
            "accuracy": 0.052734,
            "f1": 0.031617,
            "f1_weighted": 0.036751
          },
          {
            "accuracy": 0.056641,
            "f1": 0.036826,
            "f1_weighted": 0.044333
          },
          {
            "accuracy": 0.053711,
            "f1": 0.039641,
            "f1_weighted": 0.044877
          },
          {
            "accuracy": 0.04834,
            "f1": 0.032187,
            "f1_weighted": 0.040109
          },
          {
            "accuracy": 0.05127,
            "f1": 0.032594,
            "f1_weighted": 0.044022
          },
          {
            "accuracy": 0.056641,
            "f1": 0.032713,
            "f1_weighted": 0.044828
          },
          {
            "accuracy": 0.062012,
            "f1": 0.036395,
            "f1_weighted": 0.051052
          },
          {
            "accuracy": 0.048828,
            "f1": 0.033687,
            "f1_weighted": 0.041977
          },
          {
            "accuracy": 0.060547,
            "f1": 0.036852,
            "f1_weighted": 0.049574
          },
          {
            "accuracy": 0.053223,
            "f1": 0.036618,
            "f1_weighted": 0.044526
          }
        ],
        "main_score": 0.054395,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.050537,
        "f1": 0.035487,
        "f1_weighted": 0.038229,
        "scores_per_experiment": [
          {
            "accuracy": 0.049805,
            "f1": 0.032659,
            "f1_weighted": 0.029186
          },
          {
            "accuracy": 0.053711,
            "f1": 0.04025,
            "f1_weighted": 0.038285
          },
          {
            "accuracy": 0.052246,
            "f1": 0.039226,
            "f1_weighted": 0.037755
          },
          {
            "accuracy": 0.04834,
            "f1": 0.032589,
            "f1_weighted": 0.040817
          },
          {
            "accuracy": 0.05127,
            "f1": 0.037262,
            "f1_weighted": 0.041585
          },
          {
            "accuracy": 0.049805,
            "f1": 0.027925,
            "f1_weighted": 0.037713
          },
          {
            "accuracy": 0.05127,
            "f1": 0.035479,
            "f1_weighted": 0.03945
          },
          {
            "accuracy": 0.047852,
            "f1": 0.039042,
            "f1_weighted": 0.039874
          },
          {
            "accuracy": 0.048828,
            "f1": 0.033504,
            "f1_weighted": 0.037179
          },
          {
            "accuracy": 0.052246,
            "f1": 0.036935,
            "f1_weighted": 0.040447
          }
        ],
        "main_score": 0.050537,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 1750.9230508804321,
  "kg_co2_emissions": 0.1544516425456502
}