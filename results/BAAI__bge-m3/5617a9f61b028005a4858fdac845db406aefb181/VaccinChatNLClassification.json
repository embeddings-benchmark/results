{
  "dataset_revision": "bd27d0058bea2ad52470d9072a3b5da6b97c1ac3",
  "task_name": "VaccinChatNLClassification",
  "mteb_version": "2.1.1",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.476068,
            "f1": 0.521575,
            "f1_weighted": 0.447321,
            "precision": 0.526851,
            "precision_weighted": 0.612136,
            "recall": 0.6801,
            "recall_weighted": 0.476068,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.48547,
            "f1": 0.530949,
            "f1_weighted": 0.453271,
            "precision": 0.548776,
            "precision_weighted": 0.677763,
            "recall": 0.681754,
            "recall_weighted": 0.48547,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.474359,
            "f1": 0.516048,
            "f1_weighted": 0.43313,
            "precision": 0.519053,
            "precision_weighted": 0.555365,
            "recall": 0.676214,
            "recall_weighted": 0.474359,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.494017,
            "f1": 0.519912,
            "f1_weighted": 0.46949,
            "precision": 0.528935,
            "precision_weighted": 0.629503,
            "recall": 0.666039,
            "recall_weighted": 0.494017,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.492308,
            "f1": 0.521121,
            "f1_weighted": 0.468566,
            "precision": 0.522075,
            "precision_weighted": 0.649794,
            "recall": 0.666138,
            "recall_weighted": 0.492308,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.499145,
            "f1": 0.527419,
            "f1_weighted": 0.475351,
            "precision": 0.531708,
            "precision_weighted": 0.650736,
            "recall": 0.685003,
            "recall_weighted": 0.499145,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.505983,
            "f1": 0.547872,
            "f1_weighted": 0.476644,
            "precision": 0.556767,
            "precision_weighted": 0.658719,
            "recall": 0.699919,
            "recall_weighted": 0.505983,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.487179,
            "f1": 0.517199,
            "f1_weighted": 0.452341,
            "precision": 0.525521,
            "precision_weighted": 0.599398,
            "recall": 0.664368,
            "recall_weighted": 0.487179,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.488034,
            "f1": 0.514743,
            "f1_weighted": 0.458167,
            "precision": 0.508908,
            "precision_weighted": 0.588417,
            "recall": 0.668475,
            "recall_weighted": 0.488034,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.518803,
            "f1": 0.524809,
            "f1_weighted": 0.498442,
            "precision": 0.522221,
            "precision_weighted": 0.664153,
            "recall": 0.679348,
            "recall_weighted": 0.518803,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.492137,
        "f1": 0.524165,
        "f1_weighted": 0.463272,
        "precision": 0.529081,
        "precision_weighted": 0.628599,
        "recall": 0.676736,
        "recall_weighted": 0.492137,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.524165,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 24.557223796844482,
  "kg_co2_emissions": null
}