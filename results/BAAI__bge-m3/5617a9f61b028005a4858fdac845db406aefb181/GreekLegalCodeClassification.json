{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "evaluation_time": 3868.845217704773,
  "kg_co2_emissions": 0.31393226025436516,
  "mteb_version": "1.12.75",
  "scores": {
    "test": [
      {
        "accuracy": 0.38916015625,
        "f1": 0.3453546800699595,
        "f1_weighted": 0.3892293858146126,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.38916015625,
        "scores_per_experiment": [
          {
            "accuracy": 0.38720703125,
            "f1": 0.3434522609944592,
            "f1_weighted": 0.39450478741910194
          },
          {
            "accuracy": 0.39404296875,
            "f1": 0.3558445919327975,
            "f1_weighted": 0.38736010056677395
          },
          {
            "accuracy": 0.39501953125,
            "f1": 0.3461367829840347,
            "f1_weighted": 0.4000081258125594
          },
          {
            "accuracy": 0.38720703125,
            "f1": 0.3383804184967955,
            "f1_weighted": 0.382054705090319
          },
          {
            "accuracy": 0.3876953125,
            "f1": 0.35474105496149305,
            "f1_weighted": 0.3786126533403004
          },
          {
            "accuracy": 0.38330078125,
            "f1": 0.33530679242432254,
            "f1_weighted": 0.3819923022736404
          },
          {
            "accuracy": 0.40380859375,
            "f1": 0.344881136989409,
            "f1_weighted": 0.41265444817660146
          },
          {
            "accuracy": 0.38232421875,
            "f1": 0.339847056339415,
            "f1_weighted": 0.3822922181712528
          },
          {
            "accuracy": 0.384765625,
            "f1": 0.35099127039266204,
            "f1_weighted": 0.3900877832293528
          },
          {
            "accuracy": 0.38623046875,
            "f1": 0.3439654351842065,
            "f1_weighted": 0.38272673406622326
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.393505859375,
        "f1": 0.33760653304548494,
        "f1_weighted": 0.39228464856622913,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.393505859375,
        "scores_per_experiment": [
          {
            "accuracy": 0.3779296875,
            "f1": 0.3226033153026797,
            "f1_weighted": 0.3779191199173451
          },
          {
            "accuracy": 0.38720703125,
            "f1": 0.33576583547242683,
            "f1_weighted": 0.38488030973588205
          },
          {
            "accuracy": 0.39501953125,
            "f1": 0.3310797207166151,
            "f1_weighted": 0.3934632238512782
          },
          {
            "accuracy": 0.3916015625,
            "f1": 0.33456524981073255,
            "f1_weighted": 0.3885163762519462
          },
          {
            "accuracy": 0.3916015625,
            "f1": 0.32979561985715666,
            "f1_weighted": 0.3808496509799707
          },
          {
            "accuracy": 0.390625,
            "f1": 0.33257615559963266,
            "f1_weighted": 0.3896503147051751
          },
          {
            "accuracy": 0.4072265625,
            "f1": 0.34414445728854887,
            "f1_weighted": 0.4114702538774092
          },
          {
            "accuracy": 0.3896484375,
            "f1": 0.34325925103621124,
            "f1_weighted": 0.3898855122334465
          },
          {
            "accuracy": 0.40283203125,
            "f1": 0.35135531736352005,
            "f1_weighted": 0.4025827504868986
          },
          {
            "accuracy": 0.4013671875,
            "f1": 0.3509204080073256,
            "f1_weighted": 0.4036289736229397
          }
        ]
      }
    ]
  },
  "task_name": "GreekLegalCodeClassification"
}