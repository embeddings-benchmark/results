{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "task_name": "MTOPDomainClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.904848,
        "f1": 0.896445,
        "f1_weighted": 0.904566,
        "scores_per_experiment": [
          {
            "accuracy": 0.888705,
            "f1": 0.883251,
            "f1_weighted": 0.888924
          },
          {
            "accuracy": 0.905234,
            "f1": 0.894371,
            "f1_weighted": 0.90487
          },
          {
            "accuracy": 0.907989,
            "f1": 0.899887,
            "f1_weighted": 0.907398
          },
          {
            "accuracy": 0.912397,
            "f1": 0.904507,
            "f1_weighted": 0.911696
          },
          {
            "accuracy": 0.905785,
            "f1": 0.895272,
            "f1_weighted": 0.904943
          },
          {
            "accuracy": 0.906887,
            "f1": 0.895359,
            "f1_weighted": 0.90575
          },
          {
            "accuracy": 0.905785,
            "f1": 0.897953,
            "f1_weighted": 0.905034
          },
          {
            "accuracy": 0.898072,
            "f1": 0.894061,
            "f1_weighted": 0.899223
          },
          {
            "accuracy": 0.902479,
            "f1": 0.894367,
            "f1_weighted": 0.902354
          },
          {
            "accuracy": 0.915152,
            "f1": 0.905425,
            "f1_weighted": 0.915466
          }
        ],
        "main_score": 0.904848,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.912229,
        "f1": 0.902667,
        "f1_weighted": 0.911946,
        "scores_per_experiment": [
          {
            "accuracy": 0.899408,
            "f1": 0.892616,
            "f1_weighted": 0.899651
          },
          {
            "accuracy": 0.911524,
            "f1": 0.901484,
            "f1_weighted": 0.910879
          },
          {
            "accuracy": 0.915187,
            "f1": 0.904778,
            "f1_weighted": 0.914295
          },
          {
            "accuracy": 0.912651,
            "f1": 0.90301,
            "f1_weighted": 0.911949
          },
          {
            "accuracy": 0.917723,
            "f1": 0.905485,
            "f1_weighted": 0.91666
          },
          {
            "accuracy": 0.912933,
            "f1": 0.900559,
            "f1_weighted": 0.912304
          },
          {
            "accuracy": 0.918287,
            "f1": 0.907105,
            "f1_weighted": 0.917834
          },
          {
            "accuracy": 0.897999,
            "f1": 0.891261,
            "f1_weighted": 0.899309
          },
          {
            "accuracy": 0.913215,
            "f1": 0.90552,
            "f1_weighted": 0.912925
          },
          {
            "accuracy": 0.923359,
            "f1": 0.914857,
            "f1_weighted": 0.923654
          }
        ],
        "main_score": 0.912229,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 17.621785640716553,
  "kg_co2_emissions": null
}