{
  "dataset_revision": "a74d7350ea12af010cfb1c21e34f1f81fd2e615b",
  "evaluation_time": 17.594677209854126,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.89",
  "scores": {
    "test": [
      {
        "accuracy": 0.732843137254902,
        "f1": 0.7162212154259895,
        "f1_weighted": 0.7302511710248989,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.732843137254902,
        "scores_per_experiment": [
          {
            "accuracy": 0.7254901960784313,
            "f1": 0.7008125115962646,
            "f1_weighted": 0.7258006235303819
          },
          {
            "accuracy": 0.7745098039215687,
            "f1": 0.7562832458033955,
            "f1_weighted": 0.7703291020142926
          },
          {
            "accuracy": 0.6715686274509803,
            "f1": 0.662859934703995,
            "f1_weighted": 0.6627778040982077
          },
          {
            "accuracy": 0.7549019607843137,
            "f1": 0.730000325295519,
            "f1_weighted": 0.7519518841152308
          },
          {
            "accuracy": 0.7450980392156863,
            "f1": 0.7351821015698244,
            "f1_weighted": 0.7474818128716262
          },
          {
            "accuracy": 0.7058823529411765,
            "f1": 0.6952586551989318,
            "f1_weighted": 0.7088374581727359
          },
          {
            "accuracy": 0.7401960784313726,
            "f1": 0.7317518461296902,
            "f1_weighted": 0.7376487230707304
          },
          {
            "accuracy": 0.7450980392156863,
            "f1": 0.7238362356305291,
            "f1_weighted": 0.7400386883445007
          },
          {
            "accuracy": 0.7009803921568627,
            "f1": 0.6763168699551123,
            "f1_weighted": 0.6968893458270847
          },
          {
            "accuracy": 0.7647058823529411,
            "f1": 0.7499104283766325,
            "f1_weighted": 0.760756268204197
          }
        ]
      }
    ],
    "train": [
      {
        "accuracy": 0.6970042796005707,
        "f1": 0.6835224605287646,
        "f1_weighted": 0.6978074522374641,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.6970042796005707,
        "scores_per_experiment": [
          {
            "accuracy": 0.7104136947218259,
            "f1": 0.6870787947063972,
            "f1_weighted": 0.7147112868661686
          },
          {
            "accuracy": 0.6833095577746077,
            "f1": 0.6682762174191259,
            "f1_weighted": 0.6838147035370106
          },
          {
            "accuracy": 0.6804564907275321,
            "f1": 0.6710909806578294,
            "f1_weighted": 0.6794858165104377
          },
          {
            "accuracy": 0.703281027104137,
            "f1": 0.6885628999851401,
            "f1_weighted": 0.7044075788888572
          },
          {
            "accuracy": 0.7146932952924394,
            "f1": 0.7037400657610091,
            "f1_weighted": 0.7155832089515887
          },
          {
            "accuracy": 0.6804564907275321,
            "f1": 0.6737017814917403,
            "f1_weighted": 0.684275540605224
          },
          {
            "accuracy": 0.6975748930099858,
            "f1": 0.6866195150279493,
            "f1_weighted": 0.6962006711992255
          },
          {
            "accuracy": 0.6761768901569187,
            "f1": 0.6582280837106972,
            "f1_weighted": 0.676177175293997
          },
          {
            "accuracy": 0.6904422253922967,
            "f1": 0.6780665145784578,
            "f1_weighted": 0.6912718073461509
          },
          {
            "accuracy": 0.7332382310984308,
            "f1": 0.719859751949301,
            "f1_weighted": 0.7321467331759806
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.6909090909090908,
        "f1": 0.672813210805477,
        "f1_weighted": 0.6918061340192919,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.6909090909090908,
        "scores_per_experiment": [
          {
            "accuracy": 0.7373737373737373,
            "f1": 0.7196950534546442,
            "f1_weighted": 0.7395036396431421
          },
          {
            "accuracy": 0.696969696969697,
            "f1": 0.6905341719060696,
            "f1_weighted": 0.7046166594243808
          },
          {
            "accuracy": 0.6161616161616161,
            "f1": 0.6097582972582972,
            "f1_weighted": 0.6128430772370166
          },
          {
            "accuracy": 0.7474747474747475,
            "f1": 0.7296671231400296,
            "f1_weighted": 0.7435403944024633
          },
          {
            "accuracy": 0.6767676767676768,
            "f1": 0.6556369556369556,
            "f1_weighted": 0.6799096376874154
          },
          {
            "accuracy": 0.6161616161616161,
            "f1": 0.6146907221231384,
            "f1_weighted": 0.6180893486987226
          },
          {
            "accuracy": 0.6363636363636364,
            "f1": 0.6145200715473719,
            "f1_weighted": 0.6379156619068376
          },
          {
            "accuracy": 0.7373737373737373,
            "f1": 0.7080603451511147,
            "f1_weighted": 0.7377506018197585
          },
          {
            "accuracy": 0.7070707070707071,
            "f1": 0.6941303003414804,
            "f1_weighted": 0.7128151456214697
          },
          {
            "accuracy": 0.7373737373737373,
            "f1": 0.6914390674956686,
            "f1_weighted": 0.7310771737517124
          }
        ]
      }
    ]
  },
  "task_name": "SIB200Classification"
}