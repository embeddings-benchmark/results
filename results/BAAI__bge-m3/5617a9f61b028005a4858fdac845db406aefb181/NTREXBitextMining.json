{
  "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
  "evaluation_time": 295.0524272918701,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.89",
  "scores": {
    "test": [
      {
        "accuracy": 0.9744616925388082,
        "f1": 0.9674011016524787,
        "hf_subset": "arb_Arab-rus_Cyrl",
        "languages": [
          "arb-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.9674011016524787,
        "precision": 0.9642380237022201,
        "recall": 0.9744616925388082
      },
      {
        "accuracy": 0.9804707060590886,
        "f1": 0.9742947754965782,
        "hf_subset": "bel_Cyrl-rus_Cyrl",
        "languages": [
          "bel-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.9742947754965782,
        "precision": 0.9712902687364379,
        "recall": 0.9804707060590886
      },
      {
        "accuracy": 0.9804707060590886,
        "f1": 0.9747120681021533,
        "hf_subset": "ben_Beng-rus_Cyrl",
        "languages": [
          "ben-Beng",
          "rus-Cyrl"
        ],
        "main_score": 0.9747120681021533,
        "precision": 0.971957936905358,
        "recall": 0.9804707060590886
      },
      {
        "accuracy": 0.9839759639459189,
        "f1": 0.9790519112001335,
        "hf_subset": "bos_Latn-rus_Cyrl",
        "languages": [
          "bos-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9790519112001335,
        "precision": 0.9766316140877984,
        "recall": 0.9839759639459189
      },
      {
        "accuracy": 0.985478217325989,
        "f1": 0.9813052912702386,
        "hf_subset": "bul_Cyrl-rus_Cyrl",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.9813052912702386,
        "precision": 0.9793857452845935,
        "recall": 0.985478217325989
      },
      {
        "accuracy": 0.985478217325989,
        "f1": 0.9812552161575696,
        "hf_subset": "ces_Latn-rus_Cyrl",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9812552161575696,
        "precision": 0.9792605575029211,
        "recall": 0.985478217325989
      },
      {
        "accuracy": 0.985478217325989,
        "f1": 0.9810549157068936,
        "hf_subset": "deu_Latn-rus_Cyrl",
        "languages": [
          "deu-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9810549157068936,
        "precision": 0.9789684526790186,
        "recall": 0.985478217325989
      },
      {
        "accuracy": 0.9844767150726089,
        "f1": 0.9795526623268236,
        "hf_subset": "ell_Grek-rus_Cyrl",
        "languages": [
          "ell-Grek",
          "rus-Cyrl"
        ],
        "main_score": 0.9795526623268236,
        "precision": 0.9771323652144883,
        "recall": 0.9844767150726089
      },
      {
        "accuracy": 0.9889834752128193,
        "f1": 0.9853947588048739,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9853947588048739,
        "precision": 0.9836421298614589,
        "recall": 0.9889834752128193
      },
      {
        "accuracy": 0.9779669504256384,
        "f1": 0.970789517609748,
        "hf_subset": "fas_Arab-rus_Cyrl",
        "languages": [
          "fas-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.970789517609748,
        "precision": 0.9672842597229176,
        "recall": 0.9779669504256384
      },
      {
        "accuracy": 0.9804707060590886,
        "f1": 0.9751293607077284,
        "hf_subset": "fin_Latn-rus_Cyrl",
        "languages": [
          "fin-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9751293607077284,
        "precision": 0.9725421465531631,
        "recall": 0.9804707060590886
      },
      {
        "accuracy": 0.985478217325989,
        "f1": 0.9808879986646636,
        "hf_subset": "fra_Latn-rus_Cyrl",
        "languages": [
          "fra-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9808879986646636,
        "precision": 0.9787180771156735,
        "recall": 0.985478217325989
      },
      {
        "accuracy": 0.9844767150726089,
        "f1": 0.9798864964112836,
        "hf_subset": "heb_Hebr-rus_Cyrl",
        "languages": [
          "heb-Hebr",
          "rus-Cyrl"
        ],
        "main_score": 0.9798864964112836,
        "precision": 0.9777165748622935,
        "recall": 0.9844767150726089
      },
      {
        "accuracy": 0.9769654481722584,
        "f1": 0.969871473877483,
        "hf_subset": "hin_Deva-rus_Cyrl",
        "languages": [
          "hin-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.969871473877483,
        "precision": 0.9664496745117677,
        "recall": 0.9769654481722584
      },
      {
        "accuracy": 0.985478217325989,
        "f1": 0.9809714571857787,
        "hf_subset": "hrv_Latn-rus_Cyrl",
        "languages": [
          "hrv-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9809714571857787,
        "precision": 0.9788015356367884,
        "recall": 0.985478217325989
      },
      {
        "accuracy": 0.9789684526790186,
        "f1": 0.9721248539475881,
        "hf_subset": "hun_Latn-rus_Cyrl",
        "languages": [
          "hun-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9721248539475881,
        "precision": 0.9687865131029877,
        "recall": 0.9789684526790186
      },
      {
        "accuracy": 0.9849774661992989,
        "f1": 0.9803371724253046,
        "hf_subset": "ind_Latn-rus_Cyrl",
        "languages": [
          "ind-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9803371724253046,
        "precision": 0.978175596728426,
        "recall": 0.9849774661992989
      },
      {
        "accuracy": 0.9784677015523285,
        "f1": 0.971707561342013,
        "hf_subset": "jpn_Jpan-rus_Cyrl",
        "languages": [
          "jpn-Jpan",
          "rus-Cyrl"
        ],
        "main_score": 0.971707561342013,
        "precision": 0.9684526790185278,
        "recall": 0.9784677015523285
      },
      {
        "accuracy": 0.9794692038057086,
        "f1": 0.9733600400600902,
        "hf_subset": "kor_Hang-rus_Cyrl",
        "languages": [
          "kor-Hang",
          "rus-Cyrl"
        ],
        "main_score": 0.9733600400600902,
        "precision": 0.9704556835252879,
        "recall": 0.9794692038057086
      },
      {
        "accuracy": 0.9799699549323986,
        "f1": 0.9739108662994492,
        "hf_subset": "lit_Latn-rus_Cyrl",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9739108662994492,
        "precision": 0.9710816224336505,
        "recall": 0.9799699549323986
      },
      {
        "accuracy": 0.9799699549323986,
        "f1": 0.9740443999332331,
        "hf_subset": "mkd_Cyrl-rus_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.9740443999332331,
        "precision": 0.971206810215323,
        "recall": 0.9799699549323986
      },
      {
        "accuracy": 0.985478217325989,
        "f1": 0.9807210816224337,
        "hf_subset": "nld_Latn-rus_Cyrl",
        "languages": [
          "nld-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9807210816224337,
        "precision": 0.9783842430312135,
        "recall": 0.985478217325989
      },
      {
        "accuracy": 0.9804707060590886,
        "f1": 0.9743782340176933,
        "hf_subset": "pol_Latn-rus_Cyrl",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9743782340176933,
        "precision": 0.971457185778668,
        "recall": 0.9804707060590886
      },
      {
        "accuracy": 0.9839759639459189,
        "f1": 0.9790852946085794,
        "hf_subset": "por_Latn-rus_Cyrl",
        "languages": [
          "por-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9790852946085794,
        "precision": 0.9767568018694708,
        "recall": 0.9839759639459189
      },
      {
        "accuracy": 0.9754631947921882,
        "f1": 0.9683692204974127,
        "hf_subset": "rus_Cyrl-arb_Arab",
        "languages": [
          "rus-Cyrl",
          "arb-Arab"
        ],
        "main_score": 0.9683692204974127,
        "precision": 0.9651143381739276,
        "recall": 0.9754631947921882
      },
      {
        "accuracy": 0.9809714571857787,
        "f1": 0.9751293607077284,
        "hf_subset": "rus_Cyrl-bel_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bel-Cyrl"
        ],
        "main_score": 0.9751293607077284,
        "precision": 0.972375229510933,
        "recall": 0.9809714571857787
      },
      {
        "accuracy": 0.9754631947921882,
        "f1": 0.9678851610749457,
        "hf_subset": "rus_Cyrl-ben_Beng",
        "languages": [
          "rus-Cyrl",
          "ben-Beng"
        ],
        "main_score": 0.9678851610749457,
        "precision": 0.964321482223335,
        "recall": 0.9754631947921882
      },
      {
        "accuracy": 0.985478217325989,
        "f1": 0.9808879986646637,
        "hf_subset": "rus_Cyrl-bos_Latn",
        "languages": [
          "rus-Cyrl",
          "bos-Latn"
        ],
        "main_score": 0.9808879986646637,
        "precision": 0.9786346185945585,
        "recall": 0.985478217325989
      },
      {
        "accuracy": 0.985478217325989,
        "f1": 0.9808879986646636,
        "hf_subset": "rus_Cyrl-bul_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bul-Cyrl"
        ],
        "main_score": 0.9808879986646636,
        "precision": 0.9786346185945585,
        "recall": 0.985478217325989
      },
      {
        "accuracy": 0.9849774661992989,
        "f1": 0.9801368719746287,
        "hf_subset": "rus_Cyrl-ces_Latn",
        "languages": [
          "rus-Cyrl",
          "ces-Latn"
        ],
        "main_score": 0.9801368719746287,
        "precision": 0.9778000333834084,
        "recall": 0.9849774661992989
      },
      {
        "accuracy": 0.9849774661992989,
        "f1": 0.9803872475379736,
        "hf_subset": "rus_Cyrl-deu_Latn",
        "languages": [
          "rus-Cyrl",
          "deu-Latn"
        ],
        "main_score": 0.9803872475379736,
        "precision": 0.9781338674678686,
        "recall": 0.9849774661992989
      },
      {
        "accuracy": 0.9889834752128193,
        "f1": 0.9853113002837589,
        "hf_subset": "rus_Cyrl-ell_Grek",
        "languages": [
          "rus-Cyrl",
          "ell-Grek"
        ],
        "main_score": 0.9853113002837589,
        "precision": 0.9834752128192289,
        "recall": 0.9889834752128193
      },
      {
        "accuracy": 0.9894842263395093,
        "f1": 0.9859789684526791,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.9859789684526791,
        "precision": 0.9842263395092639,
        "recall": 0.9894842263395093
      },
      {
        "accuracy": 0.9839759639459189,
        "f1": 0.9790519112001335,
        "hf_subset": "rus_Cyrl-fas_Arab",
        "languages": [
          "rus-Cyrl",
          "fas-Arab"
        ],
        "main_score": 0.9790519112001335,
        "precision": 0.9766316140877983,
        "recall": 0.9839759639459189
      },
      {
        "accuracy": 0.9824737105658488,
        "f1": 0.9773827407778334,
        "hf_subset": "rus_Cyrl-fin_Latn",
        "languages": [
          "rus-Cyrl",
          "fin-Latn"
        ],
        "main_score": 0.9773827407778334,
        "precision": 0.9748789851443832,
        "recall": 0.9824737105658488
      },
      {
        "accuracy": 0.9844767150726089,
        "f1": 0.9794692038057086,
        "hf_subset": "rus_Cyrl-fra_Latn",
        "languages": [
          "rus-Cyrl",
          "fra-Latn"
        ],
        "main_score": 0.9794692038057086,
        "precision": 0.9770489066933734,
        "recall": 0.9844767150726089
      },
      {
        "accuracy": 0.985478217325989,
        "f1": 0.9811383742280088,
        "hf_subset": "rus_Cyrl-heb_Hebr",
        "languages": [
          "rus-Cyrl",
          "heb-Hebr"
        ],
        "main_score": 0.9811383742280088,
        "precision": 0.9791353697212485,
        "recall": 0.985478217325989
      },
      {
        "accuracy": 0.9769654481722584,
        "f1": 0.9697045568352529,
        "hf_subset": "rus_Cyrl-hin_Deva",
        "languages": [
          "rus-Cyrl",
          "hin-Deva"
        ],
        "main_score": 0.9697045568352529,
        "precision": 0.9661158404273076,
        "recall": 0.9769654481722584
      },
      {
        "accuracy": 0.9844767150726089,
        "f1": 0.9798364212986146,
        "hf_subset": "rus_Cyrl-hrv_Latn",
        "languages": [
          "rus-Cyrl",
          "hrv-Latn"
        ],
        "main_score": 0.9798364212986146,
        "precision": 0.977674845601736,
        "recall": 0.9844767150726089
      },
      {
        "accuracy": 0.9844767150726089,
        "f1": 0.9796695042563847,
        "hf_subset": "rus_Cyrl-hun_Latn",
        "languages": [
          "rus-Cyrl",
          "hun-Latn"
        ],
        "main_score": 0.9796695042563847,
        "precision": 0.9773410115172759,
        "recall": 0.9844767150726089
      },
      {
        "accuracy": 0.9904857285928893,
        "f1": 0.9873977633116341,
        "hf_subset": "rus_Cyrl-ind_Latn",
        "languages": [
          "rus-Cyrl",
          "ind-Latn"
        ],
        "main_score": 0.9873977633116341,
        "precision": 0.985895509931564,
        "recall": 0.9904857285928893
      },
      {
        "accuracy": 0.9734601902854282,
        "f1": 0.9651143381739276,
        "hf_subset": "rus_Cyrl-jpn_Jpan",
        "languages": [
          "rus-Cyrl",
          "jpn-Jpan"
        ],
        "main_score": 0.9651143381739276,
        "precision": 0.9610248706392922,
        "recall": 0.9734601902854282
      },
      {
        "accuracy": 0.9754631947921882,
        "f1": 0.9689534301452178,
        "hf_subset": "rus_Cyrl-kor_Hang",
        "languages": [
          "rus-Cyrl",
          "kor-Hang"
        ],
        "main_score": 0.9689534301452178,
        "precision": 0.9658654648639627,
        "recall": 0.9754631947921882
      },
      {
        "accuracy": 0.9824737105658488,
        "f1": 0.9768819896511435,
        "hf_subset": "rus_Cyrl-lit_Latn",
        "languages": [
          "rus-Cyrl",
          "lit-Latn"
        ],
        "main_score": 0.9768819896511435,
        "precision": 0.9742113169754631,
        "recall": 0.9824737105658488
      },
      {
        "accuracy": 0.985478217325989,
        "f1": 0.9815556668335836,
        "hf_subset": "rus_Cyrl-mkd_Cyrl",
        "languages": [
          "rus-Cyrl",
          "mkd-Cyrl"
        ],
        "main_score": 0.9815556668335836,
        "precision": 0.9796361208479385,
        "recall": 0.985478217325989
      },
      {
        "accuracy": 0.9869804707060591,
        "f1": 0.9828910031714237,
        "hf_subset": "rus_Cyrl-nld_Latn",
        "languages": [
          "rus-Cyrl",
          "nld-Latn"
        ],
        "main_score": 0.9828910031714237,
        "precision": 0.9809714571857787,
        "recall": 0.9869804707060591
      },
      {
        "accuracy": 0.9814722083124687,
        "f1": 0.9766649974962444,
        "hf_subset": "rus_Cyrl-pol_Latn",
        "languages": [
          "rus-Cyrl",
          "pol-Latn"
        ],
        "main_score": 0.9766649974962444,
        "precision": 0.9744199632782506,
        "recall": 0.9814722083124687
      },
      {
        "accuracy": 0.9834752128192289,
        "f1": 0.9781338674678686,
        "hf_subset": "rus_Cyrl-por_Latn",
        "languages": [
          "rus-Cyrl",
          "por-Latn"
        ],
        "main_score": 0.9781338674678686,
        "precision": 0.9755466533133033,
        "recall": 0.9834752128192289
      },
      {
        "accuracy": 0.9849774661992989,
        "f1": 0.9804707060590886,
        "hf_subset": "rus_Cyrl-slk_Latn",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ],
        "main_score": 0.9804707060590886,
        "precision": 0.9783007845100984,
        "recall": 0.9849774661992989
      },
      {
        "accuracy": 0.9829744616925388,
        "f1": 0.9783007845100984,
        "hf_subset": "rus_Cyrl-slv_Latn",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ],
        "main_score": 0.9783007845100984,
        "precision": 0.9762310131864463,
        "recall": 0.9829744616925388
      },
      {
        "accuracy": 0.9834752128192289,
        "f1": 0.9784677015523285,
        "hf_subset": "rus_Cyrl-spa_Latn",
        "languages": [
          "rus-Cyrl",
          "spa-Latn"
        ],
        "main_score": 0.9784677015523285,
        "precision": 0.9759639459188784,
        "recall": 0.9834752128192289
      },
      {
        "accuracy": 0.9694541812719079,
        "f1": 0.9605241195126022,
        "hf_subset": "rus_Cyrl-srp_Cyrl",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ],
        "main_score": 0.9605241195126022,
        "precision": 0.956384576865298,
        "recall": 0.9694541812719079
      },
      {
        "accuracy": 0.9849774661992989,
        "f1": 0.9802203304957436,
        "hf_subset": "rus_Cyrl-srp_Latn",
        "languages": [
          "rus-Cyrl",
          "srp-Latn"
        ],
        "main_score": 0.9802203304957436,
        "precision": 0.9779669504256384,
        "recall": 0.9849774661992989
      },
      {
        "accuracy": 0.9734601902854282,
        "f1": 0.9651143381739277,
        "hf_subset": "rus_Cyrl-swa_Latn",
        "languages": [
          "rus-Cyrl",
          "swa-Latn"
        ],
        "main_score": 0.9651143381739277,
        "precision": 0.9611083291604072,
        "recall": 0.9734601902854282
      },
      {
        "accuracy": 0.9869804707060591,
        "f1": 0.9828075446503087,
        "hf_subset": "rus_Cyrl-swe_Latn",
        "languages": [
          "rus-Cyrl",
          "swe-Latn"
        ],
        "main_score": 0.9828075446503087,
        "precision": 0.9808045401435487,
        "recall": 0.9869804707060591
      },
      {
        "accuracy": 0.9549323985978968,
        "f1": 0.9414717314066338,
        "hf_subset": "rus_Cyrl-tam_Taml",
        "languages": [
          "rus-Cyrl",
          "tam-Taml"
        ],
        "main_score": 0.9414717314066338,
        "precision": 0.9350692705725254,
        "recall": 0.9549323985978968
      },
      {
        "accuracy": 0.9789684526790186,
        "f1": 0.9727090635953931,
        "hf_subset": "rus_Cyrl-tur_Latn",
        "languages": [
          "rus-Cyrl",
          "tur-Latn"
        ],
        "main_score": 0.9727090635953931,
        "precision": 0.9697045568352529,
        "recall": 0.9789684526790186
      },
      {
        "accuracy": 0.9874812218327491,
        "f1": 0.9837589717910198,
        "hf_subset": "rus_Cyrl-ukr_Cyrl",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ],
        "main_score": 0.9837589717910198,
        "precision": 0.9820146886997163,
        "recall": 0.9874812218327491
      },
      {
        "accuracy": 0.9799699549323986,
        "f1": 0.9742113169754631,
        "hf_subset": "rus_Cyrl-vie_Latn",
        "languages": [
          "rus-Cyrl",
          "vie-Latn"
        ],
        "main_score": 0.9742113169754631,
        "precision": 0.9715406442997829,
        "recall": 0.9799699549323986
      },
      {
        "accuracy": 0.970956434651978,
        "f1": 0.9625605074278084,
        "hf_subset": "rus_Cyrl-zho_Hant",
        "languages": [
          "rus-Cyrl",
          "zho-Hant"
        ],
        "main_score": 0.9625605074278084,
        "precision": 0.9585628442663996,
        "recall": 0.970956434651978
      },
      {
        "accuracy": 0.8698047070605909,
        "f1": 0.8367173776537823,
        "hf_subset": "rus_Cyrl-zul_Latn",
        "languages": [
          "rus-Cyrl",
          "zul-Latn"
        ],
        "main_score": 0.8367173776537823,
        "precision": 0.8225594343896798,
        "recall": 0.8698047070605909
      },
      {
        "accuracy": 0.9844767150726089,
        "f1": 0.9799699549323986,
        "hf_subset": "slk_Latn-rus_Cyrl",
        "languages": [
          "slk-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9799699549323986,
        "precision": 0.9778000333834085,
        "recall": 0.9844767150726089
      },
      {
        "accuracy": 0.9834752128192289,
        "f1": 0.9788849941579035,
        "hf_subset": "slv_Latn-rus_Cyrl",
        "languages": [
          "slv-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9788849941579035,
        "precision": 0.9767150726089133,
        "recall": 0.9834752128192289
      },
      {
        "accuracy": 0.9849774661992989,
        "f1": 0.9809714571857787,
        "hf_subset": "spa_Latn-rus_Cyrl",
        "languages": [
          "spa-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9809714571857787,
        "precision": 0.9790519112001335,
        "recall": 0.9849774661992989
      },
      {
        "accuracy": 0.9784677015523285,
        "f1": 0.9724920714404941,
        "hf_subset": "srp_Cyrl-rus_Cyrl",
        "languages": [
          "srp-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.9724920714404941,
        "precision": 0.9697462860958104,
        "recall": 0.9784677015523285
      },
      {
        "accuracy": 0.9834752128192289,
        "f1": 0.9783842430312135,
        "hf_subset": "srp_Latn-rus_Cyrl",
        "languages": [
          "srp-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9783842430312135,
        "precision": 0.9758804873977633,
        "recall": 0.9834752128192289
      },
      {
        "accuracy": 0.9764646970455684,
        "f1": 0.9697140949519517,
        "hf_subset": "swa_Latn-rus_Cyrl",
        "languages": [
          "swa-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9697140949519517,
        "precision": 0.9665748622934401,
        "recall": 0.9764646970455684
      },
      {
        "accuracy": 0.9874812218327491,
        "f1": 0.9833917542981139,
        "hf_subset": "swe_Latn-rus_Cyrl",
        "languages": [
          "swe-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9833917542981139,
        "precision": 0.9813887497913537,
        "recall": 0.9874812218327491
      },
      {
        "accuracy": 0.9654481722583875,
        "f1": 0.9545151059923217,
        "hf_subset": "tam_Taml-rus_Cyrl",
        "languages": [
          "tam-Taml",
          "rus-Cyrl"
        ],
        "main_score": 0.9545151059923217,
        "precision": 0.9491737606409615,
        "recall": 0.9654481722583875
      },
      {
        "accuracy": 0.9774661992989484,
        "f1": 0.9707060590886329,
        "hf_subset": "tur_Latn-rus_Cyrl",
        "languages": [
          "tur-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9707060590886329,
        "precision": 0.9674511767651477,
        "recall": 0.9774661992989484
      },
      {
        "accuracy": 0.9839759639459189,
        "f1": 0.9791353697212485,
        "hf_subset": "ukr_Cyrl-rus_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.9791353697212485,
        "precision": 0.9767985311300285,
        "recall": 0.9839759639459189
      },
      {
        "accuracy": 0.9794692038057086,
        "f1": 0.9732932732431981,
        "hf_subset": "vie_Latn-rus_Cyrl",
        "languages": [
          "vie-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.9732932732431981,
        "precision": 0.9702053079619429,
        "recall": 0.9794692038057086
      },
      {
        "accuracy": 0.9739609414121182,
        "f1": 0.9660657653146385,
        "hf_subset": "zho_Hant-rus_Cyrl",
        "languages": [
          "zho-Hant",
          "rus-Cyrl"
        ],
        "main_score": 0.9660657653146385,
        "precision": 0.96223501919546,
        "recall": 0.9739609414121182
      },
      {
        "accuracy": 0.8818227341011518,
        "f1": 0.855173236044543,
        "hf_subset": "zul_Latn-rus_Cyrl",
        "languages": [
          "zul-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.855173236044543,
        "precision": 0.8436873258605857,
        "recall": 0.8818227341011518
      }
    ]
  },
  "task_name": "NTREXBitextMining"
}