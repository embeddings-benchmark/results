{
  "dataset_revision": "ff6d88107a89abeb10aa28751b31d78831d7d503",
  "task_name": "SynPerTextToneClassification.v3",
  "mteb_version": "1.38.38",
  "scores": {
    "test": [
      {
        "accuracy": 0.726264,
        "f1": 0.694942,
        "f1_weighted": 0.736217,
        "ap": 0.825932,
        "ap_weighted": 0.825932,
        "scores_per_experiment": [
          {
            "accuracy": 0.733265,
            "f1": 0.695345,
            "f1_weighted": 0.741671,
            "ap": 0.819166,
            "ap_weighted": 0.819166
          },
          {
            "accuracy": 0.76776,
            "f1": 0.720121,
            "f1_weighted": 0.769889,
            "ap": 0.823671,
            "ap_weighted": 0.823671
          },
          {
            "accuracy": 0.679645,
            "f1": 0.665308,
            "f1_weighted": 0.695164,
            "ap": 0.831061,
            "ap_weighted": 0.831061
          },
          {
            "accuracy": 0.681352,
            "f1": 0.659798,
            "f1_weighted": 0.696706,
            "ap": 0.816282,
            "ap_weighted": 0.816282
          },
          {
            "accuracy": 0.773566,
            "f1": 0.731667,
            "f1_weighted": 0.777368,
            "ap": 0.833351,
            "ap_weighted": 0.833351
          },
          {
            "accuracy": 0.769467,
            "f1": 0.731503,
            "f1_weighted": 0.775019,
            "ap": 0.836865,
            "ap_weighted": 0.836865
          },
          {
            "accuracy": 0.718921,
            "f1": 0.691907,
            "f1_weighted": 0.731228,
            "ap": 0.82801,
            "ap_weighted": 0.82801
          },
          {
            "accuracy": 0.70526,
            "f1": 0.679167,
            "f1_weighted": 0.718602,
            "ap": 0.821954,
            "ap_weighted": 0.821954
          },
          {
            "accuracy": 0.718921,
            "f1": 0.681214,
            "f1_weighted": 0.728469,
            "ap": 0.812168,
            "ap_weighted": 0.812168
          },
          {
            "accuracy": 0.714481,
            "f1": 0.693386,
            "f1_weighted": 0.72805,
            "ap": 0.83679,
            "ap_weighted": 0.83679
          }
        ],
        "main_score": 0.726264,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 36.304033517837524,
  "kg_co2_emissions": null
}