{
  "dataset_revision": "1f7e6a9d6fa6e64c53d146e428565640410c0df1",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "2.2.0",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.746781,
            "f1": 0.609959,
            "f1_weighted": 0.795363,
            "precision": 0.609472,
            "precision_weighted": 0.897975,
            "recall": 0.762733,
            "recall_weighted": 0.746781,
            "ap": 0.217111,
            "ap_weighted": 0.217111
          },
          {
            "accuracy": 0.753219,
            "f1": 0.588184,
            "f1_weighted": 0.797415,
            "precision": 0.585607,
            "precision_weighted": 0.875824,
            "recall": 0.688872,
            "recall_weighted": 0.753219,
            "ap": 0.174974,
            "ap_weighted": 0.174974
          },
          {
            "accuracy": 0.742489,
            "f1": 0.586879,
            "f1_weighted": 0.790369,
            "precision": 0.587844,
            "precision_weighted": 0.879952,
            "recall": 0.702277,
            "recall_weighted": 0.742489,
            "ap": 0.180344,
            "ap_weighted": 0.180344
          },
          {
            "accuracy": 0.77897,
            "f1": 0.620734,
            "f1_weighted": 0.817346,
            "precision": 0.608638,
            "precision_weighted": 0.888042,
            "recall": 0.732195,
            "recall_weighted": 0.77897,
            "ap": 0.207746,
            "ap_weighted": 0.207746
          },
          {
            "accuracy": 0.806867,
            "f1": 0.638548,
            "f1_weighted": 0.836508,
            "precision": 0.618805,
            "precision_weighted": 0.88726,
            "recall": 0.728313,
            "recall_weighted": 0.806867,
            "ap": 0.215722,
            "ap_weighted": 0.215722
          },
          {
            "accuracy": 0.76824,
            "f1": 0.618415,
            "f1_weighted": 0.810315,
            "precision": 0.609675,
            "precision_weighted": 0.892072,
            "recall": 0.7456,
            "recall_weighted": 0.76824,
            "ap": 0.212849,
            "ap_weighted": 0.212849
          },
          {
            "accuracy": 0.77897,
            "f1": 0.617079,
            "f1_weighted": 0.816905,
            "precision": 0.605282,
            "precision_weighted": 0.885279,
            "recall": 0.722516,
            "recall_weighted": 0.77897,
            "ap": 0.201559,
            "ap_weighted": 0.201559
          },
          {
            "accuracy": 0.7103,
            "f1": 0.555504,
            "f1_weighted": 0.766027,
            "precision": 0.568514,
            "precision_weighted": 0.86981,
            "recall": 0.665062,
            "recall_weighted": 0.7103,
            "ap": 0.156168,
            "ap_weighted": 0.156168
          },
          {
            "accuracy": 0.607296,
            "f1": 0.503583,
            "f1_weighted": 0.68569,
            "precision": 0.563306,
            "precision_weighted": 0.879699,
            "recall": 0.675673,
            "recall_weighted": 0.607296,
            "ap": 0.152255,
            "ap_weighted": 0.152255
          },
          {
            "accuracy": 0.787554,
            "f1": 0.620842,
            "f1_weighted": 0.822622,
            "precision": 0.606687,
            "precision_weighted": 0.883917,
            "recall": 0.717598,
            "recall_weighted": 0.787554,
            "ap": 0.201189,
            "ap_weighted": 0.201189
          }
        ],
        "accuracy": 0.748069,
        "f1": 0.595973,
        "f1_weighted": 0.793856,
        "precision": 0.596383,
        "precision_weighted": 0.883983,
        "recall": 0.714084,
        "recall_weighted": 0.748069,
        "ap": 0.191992,
        "ap_weighted": 0.191992,
        "main_score": 0.748069,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.775161,
            "f1": 0.641725,
            "f1_weighted": 0.815425,
            "precision": 0.629392,
            "precision_weighted": 0.901151,
            "recall": 0.78708,
            "recall_weighted": 0.775161,
            "ap": 0.250792,
            "ap_weighted": 0.250792
          },
          {
            "accuracy": 0.788009,
            "f1": 0.642395,
            "f1_weighted": 0.823679,
            "precision": 0.625842,
            "precision_weighted": 0.893237,
            "recall": 0.761958,
            "recall_weighted": 0.788009,
            "ap": 0.238753,
            "ap_weighted": 0.238753
          },
          {
            "accuracy": 0.735546,
            "f1": 0.599017,
            "f1_weighted": 0.784897,
            "precision": 0.60166,
            "precision_weighted": 0.88713,
            "recall": 0.737333,
            "recall_weighted": 0.735546,
            "ap": 0.205983,
            "ap_weighted": 0.205983
          },
          {
            "accuracy": 0.77409,
            "f1": 0.624932,
            "f1_weighted": 0.812836,
            "precision": 0.61337,
            "precision_weighted": 0.886889,
            "recall": 0.740366,
            "recall_weighted": 0.77409,
            "ap": 0.218842,
            "ap_weighted": 0.218842
          },
          {
            "accuracy": 0.814775,
            "f1": 0.661051,
            "f1_weighted": 0.842392,
            "precision": 0.637205,
            "precision_weighted": 0.892548,
            "recall": 0.758428,
            "recall_weighted": 0.814775,
            "ap": 0.249225,
            "ap_weighted": 0.249225
          },
          {
            "accuracy": 0.779443,
            "f1": 0.631334,
            "f1_weighted": 0.816971,
            "precision": 0.617863,
            "precision_weighted": 0.889113,
            "recall": 0.747961,
            "recall_weighted": 0.779443,
            "ap": 0.225778,
            "ap_weighted": 0.225778
          },
          {
            "accuracy": 0.804069,
            "f1": 0.652362,
            "f1_weighted": 0.834803,
            "precision": 0.631247,
            "precision_weighted": 0.891884,
            "recall": 0.757073,
            "recall_weighted": 0.804069,
            "ap": 0.242635,
            "ap_weighted": 0.242635
          },
          {
            "accuracy": 0.700214,
            "f1": 0.569982,
            "f1_weighted": 0.757983,
            "precision": 0.586713,
            "precision_weighted": 0.881181,
            "recall": 0.713032,
            "recall_weighted": 0.700214,
            "ap": 0.185373,
            "ap_weighted": 0.185373
          },
          {
            "accuracy": 0.658458,
            "f1": 0.547186,
            "f1_weighted": 0.72551,
            "precision": 0.583444,
            "precision_weighted": 0.885946,
            "recall": 0.717432,
            "recall_weighted": 0.658458,
            "ap": 0.181858,
            "ap_weighted": 0.181858
          },
          {
            "accuracy": 0.778373,
            "f1": 0.626999,
            "f1_weighted": 0.815771,
            "precision": 0.614095,
            "precision_weighted": 0.88618,
            "recall": 0.738141,
            "recall_weighted": 0.778373,
            "ap": 0.218848,
            "ap_weighted": 0.218848
          }
        ],
        "accuracy": 0.760814,
        "f1": 0.619698,
        "f1_weighted": 0.803027,
        "precision": 0.614083,
        "precision_weighted": 0.889526,
        "recall": 0.745881,
        "recall_weighted": 0.760814,
        "ap": 0.221809,
        "ap_weighted": 0.221809,
        "main_score": 0.760814,
        "hf_subset": "ja",
        "languages": [
          "jpn-Jpan"
        ]
      }
    ]
  },
  "evaluation_time": 4.7782275676727295,
  "kg_co2_emissions": null
}