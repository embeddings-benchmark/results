{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "task_name": "IN22ConvBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.03997,
        "recall": 0.066534,
        "f1": 0.046004,
        "accuracy": 0.066534,
        "main_score": 0.046004,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.032216,
        "recall": 0.053892,
        "f1": 0.036748,
        "accuracy": 0.053892,
        "main_score": 0.036748,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.02893,
        "recall": 0.045243,
        "f1": 0.032808,
        "accuracy": 0.045243,
        "main_score": 0.032808,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001874,
        "recall": 0.009315,
        "f1": 0.002507,
        "accuracy": 0.009315,
        "main_score": 0.002507,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027391,
        "recall": 0.04857,
        "f1": 0.030613,
        "accuracy": 0.04857,
        "main_score": 0.030613,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.022731,
        "recall": 0.040585,
        "f1": 0.026092,
        "accuracy": 0.040585,
        "main_score": 0.026092,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.033007,
        "recall": 0.053227,
        "f1": 0.036773,
        "accuracy": 0.053227,
        "main_score": 0.036773,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.021404,
        "recall": 0.033932,
        "f1": 0.023984,
        "accuracy": 0.033932,
        "main_score": 0.023984,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004143,
        "recall": 0.011976,
        "f1": 0.005038,
        "accuracy": 0.011976,
        "main_score": 0.005038,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.028814,
        "recall": 0.049235,
        "f1": 0.033415,
        "accuracy": 0.049235,
        "main_score": 0.033415,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.012296,
        "recall": 0.023287,
        "f1": 0.014005,
        "accuracy": 0.023287,
        "main_score": 0.014005,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.026278,
        "recall": 0.045243,
        "f1": 0.029994,
        "accuracy": 0.045243,
        "main_score": 0.029994,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.035981,
        "recall": 0.05988,
        "f1": 0.04133,
        "accuracy": 0.05988,
        "main_score": 0.04133,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.041059,
        "recall": 0.063872,
        "f1": 0.045679,
        "accuracy": 0.063872,
        "main_score": 0.045679,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.040651,
        "recall": 0.064538,
        "f1": 0.045586,
        "accuracy": 0.064538,
        "main_score": 0.045586,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.025685,
        "recall": 0.045908,
        "f1": 0.03014,
        "accuracy": 0.045908,
        "main_score": 0.03014,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.025366,
        "recall": 0.044578,
        "f1": 0.029197,
        "accuracy": 0.044578,
        "main_score": 0.029197,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.03364,
        "recall": 0.04857,
        "f1": 0.036679,
        "accuracy": 0.04857,
        "main_score": 0.036679,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.022604,
        "recall": 0.041251,
        "f1": 0.026066,
        "accuracy": 0.041251,
        "main_score": 0.026066,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.010957,
        "recall": 0.023952,
        "f1": 0.012205,
        "accuracy": 0.023952,
        "main_score": 0.012205,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.011854,
        "recall": 0.025948,
        "f1": 0.014295,
        "accuracy": 0.025948,
        "main_score": 0.014295,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004803,
        "recall": 0.013972,
        "f1": 0.006102,
        "accuracy": 0.013972,
        "main_score": 0.006102,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.036031,
        "recall": 0.063872,
        "f1": 0.042321,
        "accuracy": 0.063872,
        "main_score": 0.042321,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.024561,
        "recall": 0.045243,
        "f1": 0.028529,
        "accuracy": 0.045243,
        "main_score": 0.028529,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.02709,
        "recall": 0.043912,
        "f1": 0.031196,
        "accuracy": 0.043912,
        "main_score": 0.031196,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002554,
        "recall": 0.007319,
        "f1": 0.002911,
        "accuracy": 0.007319,
        "main_score": 0.002911,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022182,
        "recall": 0.042582,
        "f1": 0.025682,
        "accuracy": 0.042582,
        "main_score": 0.025682,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.019528,
        "recall": 0.035928,
        "f1": 0.022656,
        "accuracy": 0.035928,
        "main_score": 0.022656,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.028362,
        "recall": 0.047904,
        "f1": 0.032706,
        "accuracy": 0.047904,
        "main_score": 0.032706,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.018484,
        "recall": 0.02994,
        "f1": 0.020831,
        "accuracy": 0.02994,
        "main_score": 0.020831,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006867,
        "recall": 0.013972,
        "f1": 0.00773,
        "accuracy": 0.013972,
        "main_score": 0.00773,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.024136,
        "recall": 0.045243,
        "f1": 0.028672,
        "accuracy": 0.045243,
        "main_score": 0.028672,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.011232,
        "recall": 0.023952,
        "f1": 0.013081,
        "accuracy": 0.023952,
        "main_score": 0.013081,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.022984,
        "recall": 0.038589,
        "f1": 0.025926,
        "accuracy": 0.038589,
        "main_score": 0.025926,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.028582,
        "recall": 0.046574,
        "f1": 0.032549,
        "accuracy": 0.046574,
        "main_score": 0.032549,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.036457,
        "recall": 0.060546,
        "f1": 0.041443,
        "accuracy": 0.060546,
        "main_score": 0.041443,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.034446,
        "recall": 0.055888,
        "f1": 0.038615,
        "accuracy": 0.055888,
        "main_score": 0.038615,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.0232,
        "recall": 0.041916,
        "f1": 0.026958,
        "accuracy": 0.041916,
        "main_score": 0.026958,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.020073,
        "recall": 0.037259,
        "f1": 0.023319,
        "accuracy": 0.037259,
        "main_score": 0.023319,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.031631,
        "recall": 0.049235,
        "f1": 0.035194,
        "accuracy": 0.049235,
        "main_score": 0.035194,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.016939,
        "recall": 0.033932,
        "f1": 0.020332,
        "accuracy": 0.033932,
        "main_score": 0.020332,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.009871,
        "recall": 0.022621,
        "f1": 0.012091,
        "accuracy": 0.022621,
        "main_score": 0.012091,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.014656,
        "recall": 0.026613,
        "f1": 0.016658,
        "accuracy": 0.026613,
        "main_score": 0.016658,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.005809,
        "recall": 0.013307,
        "f1": 0.006941,
        "accuracy": 0.013307,
        "main_score": 0.006941,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.034135,
        "recall": 0.057884,
        "f1": 0.039022,
        "accuracy": 0.057884,
        "main_score": 0.039022,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.031936,
        "recall": 0.051896,
        "f1": 0.035345,
        "accuracy": 0.051896,
        "main_score": 0.035345,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.046852,
        "recall": 0.065868,
        "f1": 0.05075,
        "accuracy": 0.065868,
        "main_score": 0.05075,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.021367,
        "recall": 0.030605,
        "f1": 0.022849,
        "accuracy": 0.030605,
        "main_score": 0.022849,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.056361,
        "recall": 0.075848,
        "f1": 0.060585,
        "accuracy": 0.075848,
        "main_score": 0.060585,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.031889,
        "recall": 0.047239,
        "f1": 0.034911,
        "accuracy": 0.047239,
        "main_score": 0.034911,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.056368,
        "recall": 0.073852,
        "f1": 0.060298,
        "accuracy": 0.073852,
        "main_score": 0.060298,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.019664,
        "recall": 0.032601,
        "f1": 0.02216,
        "accuracy": 0.032601,
        "main_score": 0.02216,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.023726,
        "recall": 0.034597,
        "f1": 0.025595,
        "accuracy": 0.034597,
        "main_score": 0.025595,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.019039,
        "recall": 0.037924,
        "f1": 0.02285,
        "accuracy": 0.037924,
        "main_score": 0.02285,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.03973,
        "recall": 0.053227,
        "f1": 0.042321,
        "accuracy": 0.053227,
        "main_score": 0.042321,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.020283,
        "recall": 0.038589,
        "f1": 0.023207,
        "accuracy": 0.038589,
        "main_score": 0.023207,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.028889,
        "recall": 0.051231,
        "f1": 0.033721,
        "accuracy": 0.051231,
        "main_score": 0.033721,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.034155,
        "recall": 0.059215,
        "f1": 0.038625,
        "accuracy": 0.059215,
        "main_score": 0.038625,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.028508,
        "recall": 0.0499,
        "f1": 0.032594,
        "accuracy": 0.0499,
        "main_score": 0.032594,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.055,
        "recall": 0.073852,
        "f1": 0.058254,
        "accuracy": 0.073852,
        "main_score": 0.058254,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.020927,
        "recall": 0.042582,
        "f1": 0.025084,
        "accuracy": 0.042582,
        "main_score": 0.025084,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.021586,
        "recall": 0.032601,
        "f1": 0.023822,
        "accuracy": 0.032601,
        "main_score": 0.023822,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.046023,
        "recall": 0.061876,
        "f1": 0.049369,
        "accuracy": 0.061876,
        "main_score": 0.049369,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.03356,
        "recall": 0.049235,
        "f1": 0.036202,
        "accuracy": 0.049235,
        "main_score": 0.036202,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.043866,
        "recall": 0.05988,
        "f1": 0.046969,
        "accuracy": 0.05988,
        "main_score": 0.046969,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.035218,
        "recall": 0.044578,
        "f1": 0.037286,
        "accuracy": 0.044578,
        "main_score": 0.037286,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.027314,
        "recall": 0.047239,
        "f1": 0.031514,
        "accuracy": 0.047239,
        "main_score": 0.031514,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.027559,
        "recall": 0.047239,
        "f1": 0.03178,
        "accuracy": 0.047239,
        "main_score": 0.03178,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.04522,
        "recall": 0.062542,
        "f1": 0.048856,
        "accuracy": 0.062542,
        "main_score": 0.048856,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.02937,
        "recall": 0.041251,
        "f1": 0.030926,
        "accuracy": 0.041251,
        "main_score": 0.030926,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.049429,
        "recall": 0.069195,
        "f1": 0.052752,
        "accuracy": 0.069195,
        "main_score": 0.052752,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.039494,
        "recall": 0.062542,
        "f1": 0.043902,
        "accuracy": 0.062542,
        "main_score": 0.043902,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.084459,
        "recall": 0.11976,
        "f1": 0.092549,
        "accuracy": 0.11976,
        "main_score": 0.092549,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016556,
        "recall": 0.025948,
        "f1": 0.017609,
        "accuracy": 0.025948,
        "main_score": 0.017609,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.033345,
        "recall": 0.049235,
        "f1": 0.03606,
        "accuracy": 0.049235,
        "main_score": 0.03606,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.034691,
        "recall": 0.06853,
        "f1": 0.04131,
        "accuracy": 0.06853,
        "main_score": 0.04131,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.034929,
        "recall": 0.046574,
        "f1": 0.036854,
        "accuracy": 0.046574,
        "main_score": 0.036854,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.022883,
        "recall": 0.040585,
        "f1": 0.025294,
        "accuracy": 0.040585,
        "main_score": 0.025294,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.025368,
        "recall": 0.042582,
        "f1": 0.029037,
        "accuracy": 0.042582,
        "main_score": 0.029037,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.030404,
        "recall": 0.056554,
        "f1": 0.035841,
        "accuracy": 0.056554,
        "main_score": 0.035841,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.030144,
        "recall": 0.0499,
        "f1": 0.034243,
        "accuracy": 0.0499,
        "main_score": 0.034243,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.085368,
        "recall": 0.11976,
        "f1": 0.092344,
        "accuracy": 0.11976,
        "main_score": 0.092344,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.013461,
        "recall": 0.025948,
        "f1": 0.015584,
        "accuracy": 0.025948,
        "main_score": 0.015584,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.035948,
        "recall": 0.05988,
        "f1": 0.041037,
        "accuracy": 0.05988,
        "main_score": 0.041037,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.058212,
        "recall": 0.091151,
        "f1": 0.064993,
        "accuracy": 0.091151,
        "main_score": 0.064993,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.033127,
        "recall": 0.044578,
        "f1": 0.0349,
        "accuracy": 0.044578,
        "main_score": 0.0349,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.041547,
        "recall": 0.055888,
        "f1": 0.0443,
        "accuracy": 0.055888,
        "main_score": 0.0443,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.04717,
        "recall": 0.061876,
        "f1": 0.049417,
        "accuracy": 0.061876,
        "main_score": 0.049417,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.007212,
        "recall": 0.018629,
        "f1": 0.008687,
        "accuracy": 0.018629,
        "main_score": 0.008687,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.006938,
        "recall": 0.021291,
        "f1": 0.008644,
        "accuracy": 0.021291,
        "main_score": 0.008644,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.029443,
        "recall": 0.04857,
        "f1": 0.032227,
        "accuracy": 0.04857,
        "main_score": 0.032227,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.034277,
        "recall": 0.055888,
        "f1": 0.038003,
        "accuracy": 0.055888,
        "main_score": 0.038003,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.041675,
        "recall": 0.065868,
        "f1": 0.04526,
        "accuracy": 0.065868,
        "main_score": 0.04526,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.018868,
        "recall": 0.041916,
        "f1": 0.022422,
        "accuracy": 0.041916,
        "main_score": 0.022422,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.036877,
        "recall": 0.059215,
        "f1": 0.040301,
        "accuracy": 0.059215,
        "main_score": 0.040301,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004822,
        "recall": 0.015303,
        "f1": 0.006158,
        "accuracy": 0.015303,
        "main_score": 0.006158,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.021735,
        "recall": 0.043247,
        "f1": 0.024606,
        "accuracy": 0.043247,
        "main_score": 0.024606,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.005203,
        "recall": 0.017299,
        "f1": 0.006266,
        "accuracy": 0.017299,
        "main_score": 0.006266,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.026425,
        "recall": 0.041251,
        "f1": 0.029,
        "accuracy": 0.041251,
        "main_score": 0.029,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.00943,
        "recall": 0.022621,
        "f1": 0.011476,
        "accuracy": 0.022621,
        "main_score": 0.011476,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.007278,
        "recall": 0.020625,
        "f1": 0.008703,
        "accuracy": 0.020625,
        "main_score": 0.008703,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.006168,
        "recall": 0.015968,
        "f1": 0.007414,
        "accuracy": 0.015968,
        "main_score": 0.007414,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.007138,
        "recall": 0.018629,
        "f1": 0.008648,
        "accuracy": 0.018629,
        "main_score": 0.008648,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.038773,
        "recall": 0.061876,
        "f1": 0.042746,
        "accuracy": 0.061876,
        "main_score": 0.042746,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.003993,
        "recall": 0.012641,
        "f1": 0.004621,
        "accuracy": 0.012641,
        "main_score": 0.004621,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.004872,
        "recall": 0.019295,
        "f1": 0.006455,
        "accuracy": 0.019295,
        "main_score": 0.006455,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.033641,
        "recall": 0.055888,
        "f1": 0.036875,
        "accuracy": 0.055888,
        "main_score": 0.036875,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.029585,
        "recall": 0.045908,
        "f1": 0.032226,
        "accuracy": 0.045908,
        "main_score": 0.032226,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.040861,
        "recall": 0.05855,
        "f1": 0.044579,
        "accuracy": 0.05855,
        "main_score": 0.044579,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.029072,
        "recall": 0.046574,
        "f1": 0.031501,
        "accuracy": 0.046574,
        "main_score": 0.031501,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.02751,
        "recall": 0.045243,
        "f1": 0.030472,
        "accuracy": 0.045243,
        "main_score": 0.030472,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.02749,
        "recall": 0.04857,
        "f1": 0.031772,
        "accuracy": 0.04857,
        "main_score": 0.031772,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.048926,
        "recall": 0.072522,
        "f1": 0.054003,
        "accuracy": 0.072522,
        "main_score": 0.054003,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.052251,
        "recall": 0.069195,
        "f1": 0.055936,
        "accuracy": 0.069195,
        "main_score": 0.055936,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.027855,
        "recall": 0.039255,
        "f1": 0.029487,
        "accuracy": 0.039255,
        "main_score": 0.029487,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.04425,
        "recall": 0.06986,
        "f1": 0.049825,
        "accuracy": 0.06986,
        "main_score": 0.049825,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.054566,
        "recall": 0.073187,
        "f1": 0.058063,
        "accuracy": 0.073187,
        "main_score": 0.058063,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.034764,
        "recall": 0.055223,
        "f1": 0.038794,
        "accuracy": 0.055223,
        "main_score": 0.038794,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.028147,
        "recall": 0.041916,
        "f1": 0.030974,
        "accuracy": 0.041916,
        "main_score": 0.030974,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.020265,
        "recall": 0.037924,
        "f1": 0.023272,
        "accuracy": 0.037924,
        "main_score": 0.023272,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.046702,
        "recall": 0.064538,
        "f1": 0.050804,
        "accuracy": 0.064538,
        "main_score": 0.050804,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.037831,
        "recall": 0.061876,
        "f1": 0.042259,
        "accuracy": 0.061876,
        "main_score": 0.042259,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.021113,
        "recall": 0.037924,
        "f1": 0.024562,
        "accuracy": 0.037924,
        "main_score": 0.024562,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.030182,
        "recall": 0.047904,
        "f1": 0.03342,
        "accuracy": 0.047904,
        "main_score": 0.03342,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.024914,
        "recall": 0.040585,
        "f1": 0.0277,
        "accuracy": 0.040585,
        "main_score": 0.0277,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.060145,
        "recall": 0.075183,
        "f1": 0.063062,
        "accuracy": 0.075183,
        "main_score": 0.063062,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.018479,
        "recall": 0.035263,
        "f1": 0.021456,
        "accuracy": 0.035263,
        "main_score": 0.021456,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.018507,
        "recall": 0.039255,
        "f1": 0.02136,
        "accuracy": 0.039255,
        "main_score": 0.02136,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.047432,
        "recall": 0.061876,
        "f1": 0.050815,
        "accuracy": 0.061876,
        "main_score": 0.050815,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.047086,
        "recall": 0.070526,
        "f1": 0.051688,
        "accuracy": 0.070526,
        "main_score": 0.051688,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.061167,
        "recall": 0.084498,
        "f1": 0.066239,
        "accuracy": 0.084498,
        "main_score": 0.066239,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.039068,
        "recall": 0.051231,
        "f1": 0.041737,
        "accuracy": 0.051231,
        "main_score": 0.041737,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.02249,
        "recall": 0.037259,
        "f1": 0.025254,
        "accuracy": 0.037259,
        "main_score": 0.025254,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.02308,
        "recall": 0.041251,
        "f1": 0.026544,
        "accuracy": 0.041251,
        "main_score": 0.026544,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.030354,
        "recall": 0.044578,
        "f1": 0.033086,
        "accuracy": 0.044578,
        "main_score": 0.033086,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.03664,
        "recall": 0.054558,
        "f1": 0.040227,
        "accuracy": 0.054558,
        "main_score": 0.040227,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.016971,
        "recall": 0.024617,
        "f1": 0.017588,
        "accuracy": 0.024617,
        "main_score": 0.017588,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.048769,
        "recall": 0.06986,
        "f1": 0.053514,
        "accuracy": 0.06986,
        "main_score": 0.053514,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.045513,
        "recall": 0.069195,
        "f1": 0.049813,
        "accuracy": 0.069195,
        "main_score": 0.049813,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.023999,
        "recall": 0.035263,
        "f1": 0.026451,
        "accuracy": 0.035263,
        "main_score": 0.026451,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.02017,
        "recall": 0.02994,
        "f1": 0.021991,
        "accuracy": 0.02994,
        "main_score": 0.021991,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.017657,
        "recall": 0.041251,
        "f1": 0.021741,
        "accuracy": 0.041251,
        "main_score": 0.021741,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.027218,
        "recall": 0.036593,
        "f1": 0.029439,
        "accuracy": 0.036593,
        "main_score": 0.029439,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.044221,
        "recall": 0.06986,
        "f1": 0.049732,
        "accuracy": 0.06986,
        "main_score": 0.049732,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.020877,
        "recall": 0.033932,
        "f1": 0.023815,
        "accuracy": 0.033932,
        "main_score": 0.023815,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.020791,
        "recall": 0.037259,
        "f1": 0.024097,
        "accuracy": 0.037259,
        "main_score": 0.024097,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.026029,
        "recall": 0.043912,
        "f1": 0.029602,
        "accuracy": 0.043912,
        "main_score": 0.029602,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.033977,
        "recall": 0.051231,
        "f1": 0.036792,
        "accuracy": 0.051231,
        "main_score": 0.036792,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.011741,
        "recall": 0.023952,
        "f1": 0.013975,
        "accuracy": 0.023952,
        "main_score": 0.013975,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.017586,
        "recall": 0.035928,
        "f1": 0.020831,
        "accuracy": 0.035928,
        "main_score": 0.020831,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.03809,
        "recall": 0.053227,
        "f1": 0.041337,
        "accuracy": 0.053227,
        "main_score": 0.041337,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.023791,
        "recall": 0.033932,
        "f1": 0.02562,
        "accuracy": 0.033932,
        "main_score": 0.02562,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.034589,
        "recall": 0.046574,
        "f1": 0.037166,
        "accuracy": 0.046574,
        "main_score": 0.037166,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.023294,
        "recall": 0.033267,
        "f1": 0.02495,
        "accuracy": 0.033267,
        "main_score": 0.02495,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.032222,
        "recall": 0.053227,
        "f1": 0.036617,
        "accuracy": 0.053227,
        "main_score": 0.036617,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.033148,
        "recall": 0.054558,
        "f1": 0.037438,
        "accuracy": 0.054558,
        "main_score": 0.037438,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.055039,
        "recall": 0.077844,
        "f1": 0.060237,
        "accuracy": 0.077844,
        "main_score": 0.060237,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.085206,
        "recall": 0.11843,
        "f1": 0.093564,
        "accuracy": 0.11843,
        "main_score": 0.093564,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.030304,
        "recall": 0.043247,
        "f1": 0.032069,
        "accuracy": 0.043247,
        "main_score": 0.032069,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.05443,
        "recall": 0.076514,
        "f1": 0.058702,
        "accuracy": 0.076514,
        "main_score": 0.058702,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.047104,
        "recall": 0.073852,
        "f1": 0.052586,
        "accuracy": 0.073852,
        "main_score": 0.052586,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.01897,
        "recall": 0.036593,
        "f1": 0.021891,
        "accuracy": 0.036593,
        "main_score": 0.021891,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.029408,
        "recall": 0.043247,
        "f1": 0.032606,
        "accuracy": 0.043247,
        "main_score": 0.032606,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.03782,
        "recall": 0.067199,
        "f1": 0.044026,
        "accuracy": 0.067199,
        "main_score": 0.044026,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.039635,
        "recall": 0.053892,
        "f1": 0.042501,
        "accuracy": 0.053892,
        "main_score": 0.042501,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.023863,
        "recall": 0.039255,
        "f1": 0.026606,
        "accuracy": 0.039255,
        "main_score": 0.026606,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.028515,
        "recall": 0.051231,
        "f1": 0.03367,
        "accuracy": 0.051231,
        "main_score": 0.03367,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.025368,
        "recall": 0.04857,
        "f1": 0.029776,
        "accuracy": 0.04857,
        "main_score": 0.029776,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.031904,
        "recall": 0.052562,
        "f1": 0.036286,
        "accuracy": 0.052562,
        "main_score": 0.036286,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.084057,
        "recall": 0.121756,
        "f1": 0.091843,
        "accuracy": 0.121756,
        "main_score": 0.091843,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.01694,
        "recall": 0.031271,
        "f1": 0.019892,
        "accuracy": 0.031271,
        "main_score": 0.019892,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.031822,
        "recall": 0.053892,
        "f1": 0.036739,
        "accuracy": 0.053892,
        "main_score": 0.036739,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.074107,
        "recall": 0.102462,
        "f1": 0.080093,
        "accuracy": 0.102462,
        "main_score": 0.080093,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.032309,
        "recall": 0.045243,
        "f1": 0.034716,
        "accuracy": 0.045243,
        "main_score": 0.034716,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.04339,
        "recall": 0.055223,
        "f1": 0.045755,
        "accuracy": 0.055223,
        "main_score": 0.045755,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.046337,
        "recall": 0.065868,
        "f1": 0.049538,
        "accuracy": 0.065868,
        "main_score": 0.049538,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.020119,
        "recall": 0.039255,
        "f1": 0.02374,
        "accuracy": 0.039255,
        "main_score": 0.02374,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.022696,
        "recall": 0.039255,
        "f1": 0.025772,
        "accuracy": 0.039255,
        "main_score": 0.025772,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.013425,
        "recall": 0.035263,
        "f1": 0.016853,
        "accuracy": 0.035263,
        "main_score": 0.016853,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.014391,
        "recall": 0.025948,
        "f1": 0.016403,
        "accuracy": 0.025948,
        "main_score": 0.016403,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002011,
        "recall": 0.007319,
        "f1": 0.002399,
        "accuracy": 0.007319,
        "main_score": 0.002399,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031496,
        "recall": 0.055223,
        "f1": 0.036491,
        "accuracy": 0.055223,
        "main_score": 0.036491,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.020898,
        "recall": 0.035263,
        "f1": 0.023837,
        "accuracy": 0.035263,
        "main_score": 0.023837,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.016123,
        "recall": 0.02994,
        "f1": 0.018862,
        "accuracy": 0.02994,
        "main_score": 0.018862,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004185,
        "recall": 0.010645,
        "f1": 0.005044,
        "accuracy": 0.010645,
        "main_score": 0.005044,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.013459,
        "recall": 0.027944,
        "f1": 0.015919,
        "accuracy": 0.027944,
        "main_score": 0.015919,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.02056,
        "recall": 0.039255,
        "f1": 0.023946,
        "accuracy": 0.039255,
        "main_score": 0.023946,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.02739,
        "recall": 0.049235,
        "f1": 0.031497,
        "accuracy": 0.049235,
        "main_score": 0.031497,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.020219,
        "recall": 0.042582,
        "f1": 0.023838,
        "accuracy": 0.042582,
        "main_score": 0.023838,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.018387,
        "recall": 0.035263,
        "f1": 0.021396,
        "accuracy": 0.035263,
        "main_score": 0.021396,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.01854,
        "recall": 0.034597,
        "f1": 0.021599,
        "accuracy": 0.034597,
        "main_score": 0.021599,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.013375,
        "recall": 0.027279,
        "f1": 0.015741,
        "accuracy": 0.027279,
        "main_score": 0.015741,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.017237,
        "recall": 0.029275,
        "f1": 0.019602,
        "accuracy": 0.029275,
        "main_score": 0.019602,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.016416,
        "recall": 0.030605,
        "f1": 0.018733,
        "accuracy": 0.030605,
        "main_score": 0.018733,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.014661,
        "recall": 0.027944,
        "f1": 0.017028,
        "accuracy": 0.027944,
        "main_score": 0.017028,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.016112,
        "recall": 0.037259,
        "f1": 0.019327,
        "accuracy": 0.037259,
        "main_score": 0.019327,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.027181,
        "recall": 0.052562,
        "f1": 0.032474,
        "accuracy": 0.052562,
        "main_score": 0.032474,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004629,
        "recall": 0.011976,
        "f1": 0.005616,
        "accuracy": 0.011976,
        "main_score": 0.005616,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.004802,
        "recall": 0.013307,
        "f1": 0.005903,
        "accuracy": 0.013307,
        "main_score": 0.005903,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.005619,
        "recall": 0.014637,
        "f1": 0.006733,
        "accuracy": 0.014637,
        "main_score": 0.006733,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.027022,
        "recall": 0.034597,
        "f1": 0.028382,
        "accuracy": 0.034597,
        "main_score": 0.028382,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.034103,
        "recall": 0.041251,
        "f1": 0.035703,
        "accuracy": 0.041251,
        "main_score": 0.035703,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.025637,
        "recall": 0.030605,
        "f1": 0.026415,
        "accuracy": 0.030605,
        "main_score": 0.026415,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026681,
        "recall": 0.030605,
        "f1": 0.027086,
        "accuracy": 0.030605,
        "main_score": 0.027086,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.015831,
        "recall": 0.021956,
        "f1": 0.016903,
        "accuracy": 0.021956,
        "main_score": 0.016903,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.034696,
        "recall": 0.041916,
        "f1": 0.036253,
        "accuracy": 0.041916,
        "main_score": 0.036253,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.005195,
        "recall": 0.011311,
        "f1": 0.006051,
        "accuracy": 0.011311,
        "main_score": 0.006051,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006715,
        "recall": 0.015968,
        "f1": 0.008143,
        "accuracy": 0.015968,
        "main_score": 0.008143,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.020978,
        "recall": 0.027279,
        "f1": 0.021968,
        "accuracy": 0.027279,
        "main_score": 0.021968,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.0061,
        "recall": 0.011976,
        "f1": 0.006965,
        "accuracy": 0.011976,
        "main_score": 0.006965,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.007947,
        "recall": 0.015303,
        "f1": 0.00941,
        "accuracy": 0.015303,
        "main_score": 0.00941,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.007957,
        "recall": 0.015303,
        "f1": 0.008903,
        "accuracy": 0.015303,
        "main_score": 0.008903,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.006431,
        "recall": 0.012641,
        "f1": 0.007395,
        "accuracy": 0.012641,
        "main_score": 0.007395,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.035702,
        "recall": 0.044578,
        "f1": 0.037224,
        "accuracy": 0.044578,
        "main_score": 0.037224,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.004106,
        "recall": 0.00998,
        "f1": 0.004556,
        "accuracy": 0.00998,
        "main_score": 0.004556,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.007217,
        "recall": 0.017299,
        "f1": 0.008923,
        "accuracy": 0.017299,
        "main_score": 0.008923,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.03142,
        "recall": 0.038589,
        "f1": 0.033054,
        "accuracy": 0.038589,
        "main_score": 0.033054,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.022349,
        "recall": 0.029275,
        "f1": 0.023276,
        "accuracy": 0.029275,
        "main_score": 0.023276,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.025071,
        "recall": 0.029275,
        "f1": 0.025788,
        "accuracy": 0.029275,
        "main_score": 0.025788,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.039472,
        "recall": 0.045243,
        "f1": 0.040796,
        "accuracy": 0.045243,
        "main_score": 0.040796,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.030837,
        "recall": 0.042582,
        "f1": 0.033393,
        "accuracy": 0.042582,
        "main_score": 0.033393,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.028365,
        "recall": 0.043247,
        "f1": 0.031359,
        "accuracy": 0.043247,
        "main_score": 0.031359,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.017692,
        "recall": 0.028609,
        "f1": 0.019782,
        "accuracy": 0.028609,
        "main_score": 0.019782,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.038249,
        "recall": 0.056554,
        "f1": 0.041451,
        "accuracy": 0.056554,
        "main_score": 0.041451,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002017,
        "recall": 0.00998,
        "f1": 0.002789,
        "accuracy": 0.00998,
        "main_score": 0.002789,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019189,
        "recall": 0.029275,
        "f1": 0.020903,
        "accuracy": 0.029275,
        "main_score": 0.020903,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.024442,
        "recall": 0.037924,
        "f1": 0.026772,
        "accuracy": 0.037924,
        "main_score": 0.026772,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.042582,
        "recall": 0.05988,
        "f1": 0.046345,
        "accuracy": 0.05988,
        "main_score": 0.046345,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.012201,
        "recall": 0.022621,
        "f1": 0.014032,
        "accuracy": 0.022621,
        "main_score": 0.014032,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004847,
        "recall": 0.012641,
        "f1": 0.005736,
        "accuracy": 0.012641,
        "main_score": 0.005736,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.008296,
        "recall": 0.013972,
        "f1": 0.00908,
        "accuracy": 0.013972,
        "main_score": 0.00908,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.022863,
        "recall": 0.033267,
        "f1": 0.024788,
        "accuracy": 0.033267,
        "main_score": 0.024788,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.021723,
        "recall": 0.033267,
        "f1": 0.024168,
        "accuracy": 0.033267,
        "main_score": 0.024168,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.034868,
        "recall": 0.051896,
        "f1": 0.037987,
        "accuracy": 0.051896,
        "main_score": 0.037987,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.031213,
        "recall": 0.042582,
        "f1": 0.033324,
        "accuracy": 0.042582,
        "main_score": 0.033324,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.03435,
        "recall": 0.053892,
        "f1": 0.03792,
        "accuracy": 0.053892,
        "main_score": 0.03792,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.018342,
        "recall": 0.026613,
        "f1": 0.01994,
        "accuracy": 0.026613,
        "main_score": 0.01994,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.030678,
        "recall": 0.04857,
        "f1": 0.034234,
        "accuracy": 0.04857,
        "main_score": 0.034234,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.025658,
        "recall": 0.042582,
        "f1": 0.029405,
        "accuracy": 0.042582,
        "main_score": 0.029405,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.006029,
        "recall": 0.014637,
        "f1": 0.007032,
        "accuracy": 0.014637,
        "main_score": 0.007032,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.010693,
        "recall": 0.021291,
        "f1": 0.012302,
        "accuracy": 0.021291,
        "main_score": 0.012302,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006563,
        "recall": 0.014637,
        "f1": 0.00782,
        "accuracy": 0.014637,
        "main_score": 0.00782,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.008875,
        "recall": 0.023287,
        "f1": 0.011181,
        "accuracy": 0.023287,
        "main_score": 0.011181,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.011797,
        "recall": 0.025283,
        "f1": 0.014104,
        "accuracy": 0.025283,
        "main_score": 0.014104,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.031826,
        "recall": 0.046574,
        "f1": 0.034702,
        "accuracy": 0.046574,
        "main_score": 0.034702,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.033105,
        "recall": 0.045243,
        "f1": 0.035025,
        "accuracy": 0.045243,
        "main_score": 0.035025,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.021982,
        "recall": 0.02994,
        "f1": 0.023322,
        "accuracy": 0.02994,
        "main_score": 0.023322,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.045933,
        "recall": 0.061211,
        "f1": 0.049305,
        "accuracy": 0.061211,
        "main_score": 0.049305,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.02119,
        "recall": 0.036593,
        "f1": 0.024359,
        "accuracy": 0.036593,
        "main_score": 0.024359,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.036584,
        "recall": 0.049235,
        "f1": 0.038736,
        "accuracy": 0.049235,
        "main_score": 0.038736,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.023525,
        "recall": 0.044578,
        "f1": 0.027041,
        "accuracy": 0.044578,
        "main_score": 0.027041,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.019365,
        "recall": 0.027279,
        "f1": 0.020989,
        "accuracy": 0.027279,
        "main_score": 0.020989,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.00796,
        "recall": 0.020625,
        "f1": 0.009973,
        "accuracy": 0.020625,
        "main_score": 0.009973,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.013816,
        "recall": 0.029275,
        "f1": 0.016674,
        "accuracy": 0.029275,
        "main_score": 0.016674,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.012354,
        "recall": 0.024617,
        "f1": 0.014397,
        "accuracy": 0.024617,
        "main_score": 0.014397,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.011061,
        "recall": 0.024617,
        "f1": 0.012945,
        "accuracy": 0.024617,
        "main_score": 0.012945,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.016682,
        "recall": 0.02994,
        "f1": 0.019432,
        "accuracy": 0.02994,
        "main_score": 0.019432,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.035285,
        "recall": 0.045243,
        "f1": 0.037167,
        "accuracy": 0.045243,
        "main_score": 0.037167,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.015637,
        "recall": 0.031271,
        "f1": 0.018079,
        "accuracy": 0.031271,
        "main_score": 0.018079,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.007043,
        "recall": 0.021956,
        "f1": 0.009182,
        "accuracy": 0.021956,
        "main_score": 0.009182,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.032397,
        "recall": 0.045243,
        "f1": 0.034232,
        "accuracy": 0.045243,
        "main_score": 0.034232,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.036023,
        "recall": 0.04857,
        "f1": 0.038583,
        "accuracy": 0.04857,
        "main_score": 0.038583,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.045886,
        "recall": 0.065868,
        "f1": 0.049343,
        "accuracy": 0.065868,
        "main_score": 0.049343,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.027801,
        "recall": 0.034597,
        "f1": 0.029346,
        "accuracy": 0.034597,
        "main_score": 0.029346,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.021737,
        "recall": 0.037259,
        "f1": 0.024859,
        "accuracy": 0.037259,
        "main_score": 0.024859,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.024371,
        "recall": 0.041916,
        "f1": 0.027949,
        "accuracy": 0.041916,
        "main_score": 0.027949,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.017772,
        "recall": 0.033267,
        "f1": 0.020693,
        "accuracy": 0.033267,
        "main_score": 0.020693,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.020884,
        "recall": 0.034597,
        "f1": 0.023669,
        "accuracy": 0.034597,
        "main_score": 0.023669,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002381,
        "recall": 0.007984,
        "f1": 0.002885,
        "accuracy": 0.007984,
        "main_score": 0.002885,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.035353,
        "recall": 0.061876,
        "f1": 0.040578,
        "accuracy": 0.061876,
        "main_score": 0.040578,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.036957,
        "recall": 0.063872,
        "f1": 0.042938,
        "accuracy": 0.063872,
        "main_score": 0.042938,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.021349,
        "recall": 0.037924,
        "f1": 0.024244,
        "accuracy": 0.037924,
        "main_score": 0.024244,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.028263,
        "recall": 0.045243,
        "f1": 0.03155,
        "accuracy": 0.045243,
        "main_score": 0.03155,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.007373,
        "recall": 0.015968,
        "f1": 0.008458,
        "accuracy": 0.015968,
        "main_score": 0.008458,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.017897,
        "recall": 0.038589,
        "f1": 0.021906,
        "accuracy": 0.038589,
        "main_score": 0.021906,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.013767,
        "recall": 0.027944,
        "f1": 0.016381,
        "accuracy": 0.027944,
        "main_score": 0.016381,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.018558,
        "recall": 0.031271,
        "f1": 0.020888,
        "accuracy": 0.031271,
        "main_score": 0.020888,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.022416,
        "recall": 0.041251,
        "f1": 0.026247,
        "accuracy": 0.041251,
        "main_score": 0.026247,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.020925,
        "recall": 0.039255,
        "f1": 0.024505,
        "accuracy": 0.039255,
        "main_score": 0.024505,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.019466,
        "recall": 0.032601,
        "f1": 0.022103,
        "accuracy": 0.032601,
        "main_score": 0.022103,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.014872,
        "recall": 0.029275,
        "f1": 0.017482,
        "accuracy": 0.029275,
        "main_score": 0.017482,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.016578,
        "recall": 0.036593,
        "f1": 0.020043,
        "accuracy": 0.036593,
        "main_score": 0.020043,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.016007,
        "recall": 0.02994,
        "f1": 0.018545,
        "accuracy": 0.02994,
        "main_score": 0.018545,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.012488,
        "recall": 0.023287,
        "f1": 0.014264,
        "accuracy": 0.023287,
        "main_score": 0.014264,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.020735,
        "recall": 0.037259,
        "f1": 0.024307,
        "accuracy": 0.037259,
        "main_score": 0.024307,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.005982,
        "recall": 0.012641,
        "f1": 0.006996,
        "accuracy": 0.012641,
        "main_score": 0.006996,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.036016,
        "recall": 0.05855,
        "f1": 0.040455,
        "accuracy": 0.05855,
        "main_score": 0.040455,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.032838,
        "recall": 0.054558,
        "f1": 0.037338,
        "accuracy": 0.054558,
        "main_score": 0.037338,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.025114,
        "recall": 0.050566,
        "f1": 0.030017,
        "accuracy": 0.050566,
        "main_score": 0.030017,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.029328,
        "recall": 0.043247,
        "f1": 0.03224,
        "accuracy": 0.043247,
        "main_score": 0.03224,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001242,
        "recall": 0.006653,
        "f1": 0.001665,
        "accuracy": 0.006653,
        "main_score": 0.001665,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.02657,
        "recall": 0.045243,
        "f1": 0.029049,
        "accuracy": 0.045243,
        "main_score": 0.029049,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.0198,
        "recall": 0.036593,
        "f1": 0.022934,
        "accuracy": 0.036593,
        "main_score": 0.022934,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.029733,
        "recall": 0.047239,
        "f1": 0.033171,
        "accuracy": 0.047239,
        "main_score": 0.033171,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.022186,
        "recall": 0.037259,
        "f1": 0.024624,
        "accuracy": 0.037259,
        "main_score": 0.024624,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006055,
        "recall": 0.012641,
        "f1": 0.007042,
        "accuracy": 0.012641,
        "main_score": 0.007042,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.024215,
        "recall": 0.045243,
        "f1": 0.028791,
        "accuracy": 0.045243,
        "main_score": 0.028791,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.013414,
        "recall": 0.021956,
        "f1": 0.014707,
        "accuracy": 0.021956,
        "main_score": 0.014707,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.021454,
        "recall": 0.038589,
        "f1": 0.024173,
        "accuracy": 0.038589,
        "main_score": 0.024173,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.037346,
        "recall": 0.059215,
        "f1": 0.041797,
        "accuracy": 0.059215,
        "main_score": 0.041797,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.032519,
        "recall": 0.057884,
        "f1": 0.037854,
        "accuracy": 0.057884,
        "main_score": 0.037854,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.025087,
        "recall": 0.040585,
        "f1": 0.028118,
        "accuracy": 0.040585,
        "main_score": 0.028118,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.0237,
        "recall": 0.040585,
        "f1": 0.027221,
        "accuracy": 0.040585,
        "main_score": 0.027221,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.029078,
        "recall": 0.045243,
        "f1": 0.032247,
        "accuracy": 0.045243,
        "main_score": 0.032247,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.023349,
        "recall": 0.036593,
        "f1": 0.025974,
        "accuracy": 0.036593,
        "main_score": 0.025974,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.013085,
        "recall": 0.027279,
        "f1": 0.014699,
        "accuracy": 0.027279,
        "main_score": 0.014699,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.017925,
        "recall": 0.033267,
        "f1": 0.020877,
        "accuracy": 0.033267,
        "main_score": 0.020877,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006438,
        "recall": 0.015968,
        "f1": 0.007742,
        "accuracy": 0.015968,
        "main_score": 0.007742,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.038945,
        "recall": 0.05988,
        "f1": 0.042891,
        "accuracy": 0.05988,
        "main_score": 0.042891,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.039429,
        "recall": 0.060546,
        "f1": 0.044272,
        "accuracy": 0.060546,
        "main_score": 0.044272,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.026284,
        "recall": 0.046574,
        "f1": 0.030665,
        "accuracy": 0.046574,
        "main_score": 0.030665,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.028859,
        "recall": 0.049235,
        "f1": 0.032911,
        "accuracy": 0.049235,
        "main_score": 0.032911,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001869,
        "recall": 0.007319,
        "f1": 0.002483,
        "accuracy": 0.007319,
        "main_score": 0.002483,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020544,
        "recall": 0.035928,
        "f1": 0.0234,
        "accuracy": 0.035928,
        "main_score": 0.0234,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.017595,
        "recall": 0.032601,
        "f1": 0.02037,
        "accuracy": 0.032601,
        "main_score": 0.02037,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.027885,
        "recall": 0.043912,
        "f1": 0.031163,
        "accuracy": 0.043912,
        "main_score": 0.031163,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.023646,
        "recall": 0.035263,
        "f1": 0.026121,
        "accuracy": 0.035263,
        "main_score": 0.026121,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004825,
        "recall": 0.013307,
        "f1": 0.006085,
        "accuracy": 0.013307,
        "main_score": 0.006085,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.030161,
        "recall": 0.0499,
        "f1": 0.034276,
        "accuracy": 0.0499,
        "main_score": 0.034276,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.010391,
        "recall": 0.017964,
        "f1": 0.011637,
        "accuracy": 0.017964,
        "main_score": 0.011637,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.025412,
        "recall": 0.03992,
        "f1": 0.027839,
        "accuracy": 0.03992,
        "main_score": 0.027839,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.032652,
        "recall": 0.052562,
        "f1": 0.036882,
        "accuracy": 0.052562,
        "main_score": 0.036882,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.0359,
        "recall": 0.059215,
        "f1": 0.040162,
        "accuracy": 0.059215,
        "main_score": 0.040162,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.027909,
        "recall": 0.045908,
        "f1": 0.031608,
        "accuracy": 0.045908,
        "main_score": 0.031608,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.022722,
        "recall": 0.044578,
        "f1": 0.026763,
        "accuracy": 0.044578,
        "main_score": 0.026763,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.03151,
        "recall": 0.047239,
        "f1": 0.034671,
        "accuracy": 0.047239,
        "main_score": 0.034671,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.018227,
        "recall": 0.036593,
        "f1": 0.021634,
        "accuracy": 0.036593,
        "main_score": 0.021634,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.011714,
        "recall": 0.024617,
        "f1": 0.013351,
        "accuracy": 0.024617,
        "main_score": 0.013351,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.015382,
        "recall": 0.027944,
        "f1": 0.01755,
        "accuracy": 0.027944,
        "main_score": 0.01755,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.005614,
        "recall": 0.017299,
        "f1": 0.007127,
        "accuracy": 0.017299,
        "main_score": 0.007127,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.033198,
        "recall": 0.063207,
        "f1": 0.039193,
        "accuracy": 0.063207,
        "main_score": 0.039193,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.029455,
        "recall": 0.060546,
        "f1": 0.035581,
        "accuracy": 0.060546,
        "main_score": 0.035581,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.025654,
        "recall": 0.049235,
        "f1": 0.03039,
        "accuracy": 0.049235,
        "main_score": 0.03039,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.026426,
        "recall": 0.047239,
        "f1": 0.031168,
        "accuracy": 0.047239,
        "main_score": 0.031168,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002292,
        "recall": 0.008649,
        "f1": 0.002788,
        "accuracy": 0.008649,
        "main_score": 0.002788,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022238,
        "recall": 0.044578,
        "f1": 0.026452,
        "accuracy": 0.044578,
        "main_score": 0.026452,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.024682,
        "recall": 0.044578,
        "f1": 0.028839,
        "accuracy": 0.044578,
        "main_score": 0.028839,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.028488,
        "recall": 0.052562,
        "f1": 0.033271,
        "accuracy": 0.052562,
        "main_score": 0.033271,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.024523,
        "recall": 0.043912,
        "f1": 0.027777,
        "accuracy": 0.043912,
        "main_score": 0.027777,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004467,
        "recall": 0.013307,
        "f1": 0.005737,
        "accuracy": 0.013307,
        "main_score": 0.005737,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.02527,
        "recall": 0.0499,
        "f1": 0.029921,
        "accuracy": 0.0499,
        "main_score": 0.029921,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.014632,
        "recall": 0.025283,
        "f1": 0.016357,
        "accuracy": 0.025283,
        "main_score": 0.016357,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.027123,
        "recall": 0.045243,
        "f1": 0.03082,
        "accuracy": 0.045243,
        "main_score": 0.03082,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.029613,
        "recall": 0.055888,
        "f1": 0.034514,
        "accuracy": 0.055888,
        "main_score": 0.034514,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.03623,
        "recall": 0.069195,
        "f1": 0.042816,
        "accuracy": 0.069195,
        "main_score": 0.042816,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.02517,
        "recall": 0.047239,
        "f1": 0.029001,
        "accuracy": 0.047239,
        "main_score": 0.029001,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.022559,
        "recall": 0.042582,
        "f1": 0.026552,
        "accuracy": 0.042582,
        "main_score": 0.026552,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.029656,
        "recall": 0.053892,
        "f1": 0.034498,
        "accuracy": 0.053892,
        "main_score": 0.034498,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.020301,
        "recall": 0.041251,
        "f1": 0.024357,
        "accuracy": 0.041251,
        "main_score": 0.024357,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.010646,
        "recall": 0.027279,
        "f1": 0.012956,
        "accuracy": 0.027279,
        "main_score": 0.012956,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.013047,
        "recall": 0.02994,
        "f1": 0.016034,
        "accuracy": 0.02994,
        "main_score": 0.016034,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004837,
        "recall": 0.013972,
        "f1": 0.006088,
        "accuracy": 0.013972,
        "main_score": 0.006088,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.029722,
        "recall": 0.0499,
        "f1": 0.034126,
        "accuracy": 0.0499,
        "main_score": 0.034126,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.024712,
        "recall": 0.041251,
        "f1": 0.028449,
        "accuracy": 0.041251,
        "main_score": 0.028449,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.053668,
        "recall": 0.073852,
        "f1": 0.058292,
        "accuracy": 0.073852,
        "main_score": 0.058292,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.079219,
        "recall": 0.113772,
        "f1": 0.086706,
        "accuracy": 0.113772,
        "main_score": 0.086706,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.028791,
        "recall": 0.040585,
        "f1": 0.030503,
        "accuracy": 0.040585,
        "main_score": 0.030503,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.060315,
        "recall": 0.07984,
        "f1": 0.064196,
        "accuracy": 0.07984,
        "main_score": 0.064196,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.0385,
        "recall": 0.063872,
        "f1": 0.043968,
        "accuracy": 0.063872,
        "main_score": 0.043968,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.087224,
        "recall": 0.117764,
        "f1": 0.094369,
        "accuracy": 0.117764,
        "main_score": 0.094369,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.018173,
        "recall": 0.030605,
        "f1": 0.020117,
        "accuracy": 0.030605,
        "main_score": 0.020117,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.031131,
        "recall": 0.046574,
        "f1": 0.034457,
        "accuracy": 0.046574,
        "main_score": 0.034457,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.030133,
        "recall": 0.055223,
        "f1": 0.035348,
        "accuracy": 0.055223,
        "main_score": 0.035348,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.03554,
        "recall": 0.047239,
        "f1": 0.038066,
        "accuracy": 0.047239,
        "main_score": 0.038066,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.023715,
        "recall": 0.038589,
        "f1": 0.026591,
        "accuracy": 0.038589,
        "main_score": 0.026591,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.026203,
        "recall": 0.045908,
        "f1": 0.03048,
        "accuracy": 0.045908,
        "main_score": 0.03048,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.026278,
        "recall": 0.051896,
        "f1": 0.031807,
        "accuracy": 0.051896,
        "main_score": 0.031807,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.028029,
        "recall": 0.045243,
        "f1": 0.031686,
        "accuracy": 0.045243,
        "main_score": 0.031686,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.014132,
        "recall": 0.025948,
        "f1": 0.016321,
        "accuracy": 0.025948,
        "main_score": 0.016321,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.038007,
        "recall": 0.063872,
        "f1": 0.04422,
        "accuracy": 0.063872,
        "main_score": 0.04422,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.059291,
        "recall": 0.084498,
        "f1": 0.065051,
        "accuracy": 0.084498,
        "main_score": 0.065051,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.03402,
        "recall": 0.046574,
        "f1": 0.036145,
        "accuracy": 0.046574,
        "main_score": 0.036145,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.045546,
        "recall": 0.062542,
        "f1": 0.049147,
        "accuracy": 0.062542,
        "main_score": 0.049147,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.042463,
        "recall": 0.05988,
        "f1": 0.045637,
        "accuracy": 0.05988,
        "main_score": 0.045637,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.02224,
        "recall": 0.045243,
        "f1": 0.025746,
        "accuracy": 0.045243,
        "main_score": 0.025746,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.022675,
        "recall": 0.040585,
        "f1": 0.025798,
        "accuracy": 0.040585,
        "main_score": 0.025798,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.015777,
        "recall": 0.031271,
        "f1": 0.018373,
        "accuracy": 0.031271,
        "main_score": 0.018373,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.011177,
        "recall": 0.023287,
        "f1": 0.012925,
        "accuracy": 0.023287,
        "main_score": 0.012925,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002431,
        "recall": 0.007984,
        "f1": 0.003076,
        "accuracy": 0.007984,
        "main_score": 0.003076,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020655,
        "recall": 0.035263,
        "f1": 0.022928,
        "accuracy": 0.035263,
        "main_score": 0.022928,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.014887,
        "recall": 0.025948,
        "f1": 0.017045,
        "accuracy": 0.025948,
        "main_score": 0.017045,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.017497,
        "recall": 0.032601,
        "f1": 0.020171,
        "accuracy": 0.032601,
        "main_score": 0.020171,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.021364,
        "recall": 0.036593,
        "f1": 0.023925,
        "accuracy": 0.036593,
        "main_score": 0.023925,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.002934,
        "recall": 0.008649,
        "f1": 0.003424,
        "accuracy": 0.008649,
        "main_score": 0.003424,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.012962,
        "recall": 0.027944,
        "f1": 0.015416,
        "accuracy": 0.027944,
        "main_score": 0.015416,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.012653,
        "recall": 0.025283,
        "f1": 0.014465,
        "accuracy": 0.025283,
        "main_score": 0.014465,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.017455,
        "recall": 0.02994,
        "f1": 0.019229,
        "accuracy": 0.02994,
        "main_score": 0.019229,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.022961,
        "recall": 0.038589,
        "f1": 0.025915,
        "accuracy": 0.038589,
        "main_score": 0.025915,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.023339,
        "recall": 0.045243,
        "f1": 0.026703,
        "accuracy": 0.045243,
        "main_score": 0.026703,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.024099,
        "recall": 0.042582,
        "f1": 0.027523,
        "accuracy": 0.042582,
        "main_score": 0.027523,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.012662,
        "recall": 0.027279,
        "f1": 0.014581,
        "accuracy": 0.027279,
        "main_score": 0.014581,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.01317,
        "recall": 0.025948,
        "f1": 0.014934,
        "accuracy": 0.025948,
        "main_score": 0.014934,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.009045,
        "recall": 0.01996,
        "f1": 0.010605,
        "accuracy": 0.01996,
        "main_score": 0.010605,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.009898,
        "recall": 0.019295,
        "f1": 0.011117,
        "accuracy": 0.019295,
        "main_score": 0.011117,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.010827,
        "recall": 0.021291,
        "f1": 0.012212,
        "accuracy": 0.021291,
        "main_score": 0.012212,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004656,
        "recall": 0.008649,
        "f1": 0.005072,
        "accuracy": 0.008649,
        "main_score": 0.005072,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.026607,
        "recall": 0.04857,
        "f1": 0.031228,
        "accuracy": 0.04857,
        "main_score": 0.031228,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.025798,
        "recall": 0.045243,
        "f1": 0.029555,
        "accuracy": 0.045243,
        "main_score": 0.029555,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.014307,
        "recall": 0.028609,
        "f1": 0.016936,
        "accuracy": 0.028609,
        "main_score": 0.016936,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.033277,
        "recall": 0.053892,
        "f1": 0.038248,
        "accuracy": 0.053892,
        "main_score": 0.038248,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001094,
        "recall": 0.007319,
        "f1": 0.00162,
        "accuracy": 0.007319,
        "main_score": 0.00162,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018179,
        "recall": 0.030605,
        "f1": 0.019938,
        "accuracy": 0.030605,
        "main_score": 0.019938,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.019661,
        "recall": 0.037259,
        "f1": 0.022682,
        "accuracy": 0.037259,
        "main_score": 0.022682,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.025748,
        "recall": 0.043247,
        "f1": 0.029154,
        "accuracy": 0.043247,
        "main_score": 0.029154,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.009757,
        "recall": 0.019295,
        "f1": 0.011389,
        "accuracy": 0.019295,
        "main_score": 0.011389,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004315,
        "recall": 0.011311,
        "f1": 0.005388,
        "accuracy": 0.011311,
        "main_score": 0.005388,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.027931,
        "recall": 0.047904,
        "f1": 0.031515,
        "accuracy": 0.047904,
        "main_score": 0.031515,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.004809,
        "recall": 0.012641,
        "f1": 0.00577,
        "accuracy": 0.012641,
        "main_score": 0.00577,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.018338,
        "recall": 0.032601,
        "f1": 0.02042,
        "accuracy": 0.032601,
        "main_score": 0.02042,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.024369,
        "recall": 0.045243,
        "f1": 0.029025,
        "accuracy": 0.045243,
        "main_score": 0.029025,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.026573,
        "recall": 0.04857,
        "f1": 0.031204,
        "accuracy": 0.04857,
        "main_score": 0.031204,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.030242,
        "recall": 0.049235,
        "f1": 0.033976,
        "accuracy": 0.049235,
        "main_score": 0.033976,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.030954,
        "recall": 0.053892,
        "f1": 0.035626,
        "accuracy": 0.053892,
        "main_score": 0.035626,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.011943,
        "recall": 0.025283,
        "f1": 0.014045,
        "accuracy": 0.025283,
        "main_score": 0.014045,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.011544,
        "recall": 0.023287,
        "f1": 0.013903,
        "accuracy": 0.023287,
        "main_score": 0.013903,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.006415,
        "recall": 0.014637,
        "f1": 0.007573,
        "accuracy": 0.014637,
        "main_score": 0.007573,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.010599,
        "recall": 0.01996,
        "f1": 0.01211,
        "accuracy": 0.01996,
        "main_score": 0.01211,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004912,
        "recall": 0.009315,
        "f1": 0.005675,
        "accuracy": 0.009315,
        "main_score": 0.005675,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.016305,
        "recall": 0.028609,
        "f1": 0.018875,
        "accuracy": 0.028609,
        "main_score": 0.018875,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.022239,
        "recall": 0.03992,
        "f1": 0.025864,
        "accuracy": 0.03992,
        "main_score": 0.025864,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.041992,
        "recall": 0.059215,
        "f1": 0.045558,
        "accuracy": 0.059215,
        "main_score": 0.045558,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.054422,
        "recall": 0.081836,
        "f1": 0.060038,
        "accuracy": 0.081836,
        "main_score": 0.060038,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.022625,
        "recall": 0.032601,
        "f1": 0.024178,
        "accuracy": 0.032601,
        "main_score": 0.024178,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.044279,
        "recall": 0.05988,
        "f1": 0.047135,
        "accuracy": 0.05988,
        "main_score": 0.047135,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.033304,
        "recall": 0.053227,
        "f1": 0.037716,
        "accuracy": 0.053227,
        "main_score": 0.037716,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.073955,
        "recall": 0.097804,
        "f1": 0.079115,
        "accuracy": 0.097804,
        "main_score": 0.079115,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.012792,
        "recall": 0.025283,
        "f1": 0.014853,
        "accuracy": 0.025283,
        "main_score": 0.014853,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.026071,
        "recall": 0.035928,
        "f1": 0.028571,
        "accuracy": 0.035928,
        "main_score": 0.028571,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.022833,
        "recall": 0.041916,
        "f1": 0.027236,
        "accuracy": 0.041916,
        "main_score": 0.027236,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.032824,
        "recall": 0.045908,
        "f1": 0.035079,
        "accuracy": 0.045908,
        "main_score": 0.035079,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.016541,
        "recall": 0.030605,
        "f1": 0.019183,
        "accuracy": 0.030605,
        "main_score": 0.019183,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.023388,
        "recall": 0.037259,
        "f1": 0.026423,
        "accuracy": 0.037259,
        "main_score": 0.026423,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.019249,
        "recall": 0.035263,
        "f1": 0.022436,
        "accuracy": 0.035263,
        "main_score": 0.022436,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.023355,
        "recall": 0.041251,
        "f1": 0.026365,
        "accuracy": 0.041251,
        "main_score": 0.026365,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.059793,
        "recall": 0.087159,
        "f1": 0.065058,
        "accuracy": 0.087159,
        "main_score": 0.065058,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.010701,
        "recall": 0.021956,
        "f1": 0.012714,
        "accuracy": 0.021956,
        "main_score": 0.012714,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.014915,
        "recall": 0.028609,
        "f1": 0.017803,
        "accuracy": 0.028609,
        "main_score": 0.017803,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.029241,
        "recall": 0.040585,
        "f1": 0.031297,
        "accuracy": 0.040585,
        "main_score": 0.031297,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.036296,
        "recall": 0.047239,
        "f1": 0.03852,
        "accuracy": 0.047239,
        "main_score": 0.03852,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.044876,
        "recall": 0.05988,
        "f1": 0.047274,
        "accuracy": 0.05988,
        "main_score": 0.047274,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.008761,
        "recall": 0.019295,
        "f1": 0.0101,
        "accuracy": 0.019295,
        "main_score": 0.0101,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.010791,
        "recall": 0.021291,
        "f1": 0.012483,
        "accuracy": 0.021291,
        "main_score": 0.012483,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.028829,
        "recall": 0.042582,
        "f1": 0.030947,
        "accuracy": 0.042582,
        "main_score": 0.030947,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.030171,
        "recall": 0.03992,
        "f1": 0.032067,
        "accuracy": 0.03992,
        "main_score": 0.032067,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.023005,
        "recall": 0.031271,
        "f1": 0.024311,
        "accuracy": 0.031271,
        "main_score": 0.024311,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.048695,
        "recall": 0.065203,
        "f1": 0.051966,
        "accuracy": 0.065203,
        "main_score": 0.051966,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.020972,
        "recall": 0.033267,
        "f1": 0.023537,
        "accuracy": 0.033267,
        "main_score": 0.023537,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.035082,
        "recall": 0.04857,
        "f1": 0.037279,
        "accuracy": 0.04857,
        "main_score": 0.037279,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016019,
        "recall": 0.035928,
        "f1": 0.019402,
        "accuracy": 0.035928,
        "main_score": 0.019402,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.025452,
        "recall": 0.034597,
        "f1": 0.02737,
        "accuracy": 0.034597,
        "main_score": 0.02737,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.007474,
        "recall": 0.015968,
        "f1": 0.008787,
        "accuracy": 0.015968,
        "main_score": 0.008787,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.033377,
        "recall": 0.046574,
        "f1": 0.036199,
        "accuracy": 0.046574,
        "main_score": 0.036199,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.013403,
        "recall": 0.025948,
        "f1": 0.015229,
        "accuracy": 0.025948,
        "main_score": 0.015229,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.009756,
        "recall": 0.018629,
        "f1": 0.011121,
        "accuracy": 0.018629,
        "main_score": 0.011121,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.012524,
        "recall": 0.024617,
        "f1": 0.014463,
        "accuracy": 0.024617,
        "main_score": 0.014463,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.011231,
        "recall": 0.021291,
        "f1": 0.012462,
        "accuracy": 0.021291,
        "main_score": 0.012462,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.03521,
        "recall": 0.045243,
        "f1": 0.037063,
        "accuracy": 0.045243,
        "main_score": 0.037063,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.008013,
        "recall": 0.01996,
        "f1": 0.009732,
        "accuracy": 0.01996,
        "main_score": 0.009732,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.009464,
        "recall": 0.021956,
        "f1": 0.010868,
        "accuracy": 0.021956,
        "main_score": 0.010868,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.027888,
        "recall": 0.039255,
        "f1": 0.029773,
        "accuracy": 0.039255,
        "main_score": 0.029773,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.047684,
        "recall": 0.066534,
        "f1": 0.051715,
        "accuracy": 0.066534,
        "main_score": 0.051715,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.030221,
        "recall": 0.037924,
        "f1": 0.031909,
        "accuracy": 0.037924,
        "main_score": 0.031909,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.015535,
        "recall": 0.02994,
        "f1": 0.01761,
        "accuracy": 0.02994,
        "main_score": 0.01761,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.015761,
        "recall": 0.030605,
        "f1": 0.018303,
        "accuracy": 0.030605,
        "main_score": 0.018303,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.043222,
        "recall": 0.05855,
        "f1": 0.046078,
        "accuracy": 0.05855,
        "main_score": 0.046078,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.040755,
        "recall": 0.054558,
        "f1": 0.043421,
        "accuracy": 0.054558,
        "main_score": 0.043421,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.025654,
        "recall": 0.033267,
        "f1": 0.026743,
        "accuracy": 0.033267,
        "main_score": 0.026743,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.064443,
        "recall": 0.086494,
        "f1": 0.068936,
        "accuracy": 0.086494,
        "main_score": 0.068936,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.031303,
        "recall": 0.04857,
        "f1": 0.034847,
        "accuracy": 0.04857,
        "main_score": 0.034847,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.042616,
        "recall": 0.055888,
        "f1": 0.044911,
        "accuracy": 0.055888,
        "main_score": 0.044911,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.03328,
        "recall": 0.053892,
        "f1": 0.037208,
        "accuracy": 0.053892,
        "main_score": 0.037208,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.026144,
        "recall": 0.033932,
        "f1": 0.027926,
        "accuracy": 0.033932,
        "main_score": 0.027926,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.012182,
        "recall": 0.022621,
        "f1": 0.014161,
        "accuracy": 0.022621,
        "main_score": 0.014161,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.040873,
        "recall": 0.063207,
        "f1": 0.045105,
        "accuracy": 0.063207,
        "main_score": 0.045105,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.019818,
        "recall": 0.038589,
        "f1": 0.023206,
        "accuracy": 0.038589,
        "main_score": 0.023206,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.016007,
        "recall": 0.029275,
        "f1": 0.018507,
        "accuracy": 0.029275,
        "main_score": 0.018507,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.022683,
        "recall": 0.038589,
        "f1": 0.025611,
        "accuracy": 0.038589,
        "main_score": 0.025611,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.018808,
        "recall": 0.032601,
        "f1": 0.021376,
        "accuracy": 0.032601,
        "main_score": 0.021376,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.04722,
        "recall": 0.059215,
        "f1": 0.049323,
        "accuracy": 0.059215,
        "main_score": 0.049323,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.014552,
        "recall": 0.028609,
        "f1": 0.017131,
        "accuracy": 0.028609,
        "main_score": 0.017131,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.015487,
        "recall": 0.028609,
        "f1": 0.017342,
        "accuracy": 0.028609,
        "main_score": 0.017342,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.039703,
        "recall": 0.051896,
        "f1": 0.042163,
        "accuracy": 0.051896,
        "main_score": 0.042163,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.050699,
        "recall": 0.06986,
        "f1": 0.054239,
        "accuracy": 0.06986,
        "main_score": 0.054239,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.032514,
        "recall": 0.041916,
        "f1": 0.034568,
        "accuracy": 0.041916,
        "main_score": 0.034568,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.005148,
        "recall": 0.00998,
        "f1": 0.006038,
        "accuracy": 0.00998,
        "main_score": 0.006038,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.006568,
        "recall": 0.012641,
        "f1": 0.007527,
        "accuracy": 0.012641,
        "main_score": 0.007527,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.033161,
        "recall": 0.042582,
        "f1": 0.035162,
        "accuracy": 0.042582,
        "main_score": 0.035162,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.042777,
        "recall": 0.059215,
        "f1": 0.045976,
        "accuracy": 0.059215,
        "main_score": 0.045976,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.025865,
        "recall": 0.033932,
        "f1": 0.027547,
        "accuracy": 0.033932,
        "main_score": 0.027547,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.035393,
        "recall": 0.042582,
        "f1": 0.03673,
        "accuracy": 0.042582,
        "main_score": 0.03673,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.017679,
        "recall": 0.027279,
        "f1": 0.019361,
        "accuracy": 0.027279,
        "main_score": 0.019361,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.043768,
        "recall": 0.05988,
        "f1": 0.04683,
        "accuracy": 0.05988,
        "main_score": 0.04683,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.005309,
        "recall": 0.008649,
        "f1": 0.005627,
        "accuracy": 0.008649,
        "main_score": 0.005627,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.034535,
        "recall": 0.046574,
        "f1": 0.037468,
        "accuracy": 0.046574,
        "main_score": 0.037468,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.007294,
        "recall": 0.017299,
        "f1": 0.008842,
        "accuracy": 0.017299,
        "main_score": 0.008842,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.028907,
        "recall": 0.037259,
        "f1": 0.030635,
        "accuracy": 0.037259,
        "main_score": 0.030635,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.007343,
        "recall": 0.012641,
        "f1": 0.007994,
        "accuracy": 0.012641,
        "main_score": 0.007994,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004965,
        "recall": 0.00998,
        "f1": 0.005807,
        "accuracy": 0.00998,
        "main_score": 0.005807,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.008351,
        "recall": 0.015303,
        "f1": 0.009508,
        "accuracy": 0.015303,
        "main_score": 0.009508,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.005361,
        "recall": 0.011311,
        "f1": 0.006403,
        "accuracy": 0.011311,
        "main_score": 0.006403,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.044845,
        "recall": 0.055223,
        "f1": 0.046914,
        "accuracy": 0.055223,
        "main_score": 0.046914,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.005319,
        "recall": 0.008649,
        "f1": 0.00574,
        "accuracy": 0.008649,
        "main_score": 0.00574,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005543,
        "recall": 0.012641,
        "f1": 0.006909,
        "accuracy": 0.012641,
        "main_score": 0.006909,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.041116,
        "recall": 0.056554,
        "f1": 0.043457,
        "accuracy": 0.056554,
        "main_score": 0.043457,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.02681,
        "recall": 0.033267,
        "f1": 0.028448,
        "accuracy": 0.033267,
        "main_score": 0.028448,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.031403,
        "recall": 0.039255,
        "f1": 0.033087,
        "accuracy": 0.039255,
        "main_score": 0.033087,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 160.31599354743958,
  "kg_co2_emissions": 0.004660625815913187
}