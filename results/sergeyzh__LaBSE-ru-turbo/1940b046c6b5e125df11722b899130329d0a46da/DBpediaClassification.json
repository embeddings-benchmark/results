{
  "dataset_revision": "9abd46cf7fc8b4c64290f26993c540b92aa145ac",
  "task_name": "DBpediaClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.876514,
        "f1": 0.870451,
        "f1_weighted": 0.870521,
        "scores_per_experiment": [
          {
            "accuracy": 0.862305,
            "f1": 0.855438,
            "f1_weighted": 0.855537
          },
          {
            "accuracy": 0.87793,
            "f1": 0.871471,
            "f1_weighted": 0.871538
          },
          {
            "accuracy": 0.882324,
            "f1": 0.876702,
            "f1_weighted": 0.876785
          },
          {
            "accuracy": 0.885254,
            "f1": 0.880598,
            "f1_weighted": 0.880655
          },
          {
            "accuracy": 0.886719,
            "f1": 0.882181,
            "f1_weighted": 0.882266
          },
          {
            "accuracy": 0.897949,
            "f1": 0.894981,
            "f1_weighted": 0.894997
          },
          {
            "accuracy": 0.883301,
            "f1": 0.878819,
            "f1_weighted": 0.878889
          },
          {
            "accuracy": 0.871582,
            "f1": 0.866361,
            "f1_weighted": 0.86644
          },
          {
            "accuracy": 0.865234,
            "f1": 0.858839,
            "f1_weighted": 0.858844
          },
          {
            "accuracy": 0.852539,
            "f1": 0.839116,
            "f1_weighted": 0.839256
          }
        ],
        "main_score": 0.876514,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 9.461786985397339,
  "kg_co2_emissions": 0.0003534078676126275
}