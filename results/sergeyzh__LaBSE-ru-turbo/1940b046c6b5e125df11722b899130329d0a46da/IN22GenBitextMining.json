{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.112779,
        "recall": 0.158203,
        "f1": 0.125423,
        "accuracy": 0.158203,
        "main_score": 0.125423,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.086618,
        "recall": 0.136719,
        "f1": 0.098157,
        "accuracy": 0.136719,
        "main_score": 0.098157,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.053033,
        "recall": 0.089844,
        "f1": 0.061053,
        "accuracy": 0.089844,
        "main_score": 0.061053,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001109,
        "recall": 0.003906,
        "f1": 0.001214,
        "accuracy": 0.003906,
        "main_score": 0.001214,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.048925,
        "recall": 0.080078,
        "f1": 0.055246,
        "accuracy": 0.080078,
        "main_score": 0.055246,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.085449,
        "recall": 0.130859,
        "f1": 0.095319,
        "accuracy": 0.130859,
        "main_score": 0.095319,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.057098,
        "recall": 0.099609,
        "f1": 0.066951,
        "accuracy": 0.099609,
        "main_score": 0.066951,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.078849,
        "recall": 0.107422,
        "f1": 0.085515,
        "accuracy": 0.107422,
        "main_score": 0.085515,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.011076,
        "recall": 0.03125,
        "f1": 0.014118,
        "accuracy": 0.03125,
        "main_score": 0.014118,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.10469,
        "recall": 0.142578,
        "f1": 0.114024,
        "accuracy": 0.142578,
        "main_score": 0.114024,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.032012,
        "recall": 0.056641,
        "f1": 0.036173,
        "accuracy": 0.056641,
        "main_score": 0.036173,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.087662,
        "recall": 0.126953,
        "f1": 0.096387,
        "accuracy": 0.126953,
        "main_score": 0.096387,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.122131,
        "recall": 0.162109,
        "f1": 0.132105,
        "accuracy": 0.162109,
        "main_score": 0.132105,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.104372,
        "recall": 0.145508,
        "f1": 0.114132,
        "accuracy": 0.145508,
        "main_score": 0.114132,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.11962,
        "recall": 0.164062,
        "f1": 0.130532,
        "accuracy": 0.164062,
        "main_score": 0.130532,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.025435,
        "recall": 0.056641,
        "f1": 0.030937,
        "accuracy": 0.056641,
        "main_score": 0.030937,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.045732,
        "recall": 0.073242,
        "f1": 0.050986,
        "accuracy": 0.073242,
        "main_score": 0.050986,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.076505,
        "recall": 0.111328,
        "f1": 0.084599,
        "accuracy": 0.111328,
        "main_score": 0.084599,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.04551,
        "recall": 0.083008,
        "f1": 0.054193,
        "accuracy": 0.083008,
        "main_score": 0.054193,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.030932,
        "recall": 0.060547,
        "f1": 0.036954,
        "accuracy": 0.060547,
        "main_score": 0.036954,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.035566,
        "recall": 0.06543,
        "f1": 0.041016,
        "accuracy": 0.06543,
        "main_score": 0.041016,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.010457,
        "recall": 0.025391,
        "f1": 0.012723,
        "accuracy": 0.025391,
        "main_score": 0.012723,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.121424,
        "recall": 0.161133,
        "f1": 0.131952,
        "accuracy": 0.161133,
        "main_score": 0.131952,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.053002,
        "recall": 0.099609,
        "f1": 0.0638,
        "accuracy": 0.099609,
        "main_score": 0.0638,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.033523,
        "recall": 0.066406,
        "f1": 0.040446,
        "accuracy": 0.066406,
        "main_score": 0.040446,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003062,
        "recall": 0.005859,
        "f1": 0.003167,
        "accuracy": 0.005859,
        "main_score": 0.003167,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.038735,
        "recall": 0.076172,
        "f1": 0.046726,
        "accuracy": 0.076172,
        "main_score": 0.046726,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.065633,
        "recall": 0.101562,
        "f1": 0.07341,
        "accuracy": 0.101562,
        "main_score": 0.07341,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.049618,
        "recall": 0.080078,
        "f1": 0.056927,
        "accuracy": 0.080078,
        "main_score": 0.056927,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.069122,
        "recall": 0.092773,
        "f1": 0.075031,
        "accuracy": 0.092773,
        "main_score": 0.075031,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.010804,
        "recall": 0.032227,
        "f1": 0.014053,
        "accuracy": 0.032227,
        "main_score": 0.014053,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.094132,
        "recall": 0.130859,
        "f1": 0.103127,
        "accuracy": 0.130859,
        "main_score": 0.103127,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.030553,
        "recall": 0.050781,
        "f1": 0.034202,
        "accuracy": 0.050781,
        "main_score": 0.034202,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.072964,
        "recall": 0.109375,
        "f1": 0.079669,
        "accuracy": 0.109375,
        "main_score": 0.079669,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.089983,
        "recall": 0.120117,
        "f1": 0.097534,
        "accuracy": 0.120117,
        "main_score": 0.097534,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.112958,
        "recall": 0.151367,
        "f1": 0.123131,
        "accuracy": 0.151367,
        "main_score": 0.123131,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.091588,
        "recall": 0.124023,
        "f1": 0.099164,
        "accuracy": 0.124023,
        "main_score": 0.099164,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.022855,
        "recall": 0.055664,
        "f1": 0.028176,
        "accuracy": 0.055664,
        "main_score": 0.028176,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.038716,
        "recall": 0.0625,
        "f1": 0.043682,
        "accuracy": 0.0625,
        "main_score": 0.043682,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.110988,
        "recall": 0.164062,
        "f1": 0.124214,
        "accuracy": 0.164062,
        "main_score": 0.124214,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.033682,
        "recall": 0.0625,
        "f1": 0.039561,
        "accuracy": 0.0625,
        "main_score": 0.039561,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.039751,
        "recall": 0.064453,
        "f1": 0.04456,
        "accuracy": 0.064453,
        "main_score": 0.04456,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.031881,
        "recall": 0.057617,
        "f1": 0.03725,
        "accuracy": 0.057617,
        "main_score": 0.03725,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006875,
        "recall": 0.025391,
        "f1": 0.009553,
        "accuracy": 0.025391,
        "main_score": 0.009553,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.108567,
        "recall": 0.154297,
        "f1": 0.119666,
        "accuracy": 0.154297,
        "main_score": 0.119666,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.069795,
        "recall": 0.110352,
        "f1": 0.07929,
        "accuracy": 0.110352,
        "main_score": 0.07929,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.291372,
        "recall": 0.325195,
        "f1": 0.29976,
        "accuracy": 0.325195,
        "main_score": 0.29976,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.097327,
        "recall": 0.125,
        "f1": 0.103349,
        "accuracy": 0.125,
        "main_score": 0.103349,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.310796,
        "recall": 0.345703,
        "f1": 0.320132,
        "accuracy": 0.345703,
        "main_score": 0.320132,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.088029,
        "recall": 0.136719,
        "f1": 0.098735,
        "accuracy": 0.136719,
        "main_score": 0.098735,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.314289,
        "recall": 0.34668,
        "f1": 0.323194,
        "accuracy": 0.34668,
        "main_score": 0.323194,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.077422,
        "recall": 0.108398,
        "f1": 0.084174,
        "accuracy": 0.108398,
        "main_score": 0.084174,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.233638,
        "recall": 0.265625,
        "f1": 0.241332,
        "accuracy": 0.265625,
        "main_score": 0.241332,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.075594,
        "recall": 0.113281,
        "f1": 0.08344,
        "accuracy": 0.113281,
        "main_score": 0.08344,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.180427,
        "recall": 0.22168,
        "f1": 0.191746,
        "accuracy": 0.22168,
        "main_score": 0.191746,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.066334,
        "recall": 0.09668,
        "f1": 0.072966,
        "accuracy": 0.09668,
        "main_score": 0.072966,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.077737,
        "recall": 0.109375,
        "f1": 0.084467,
        "accuracy": 0.109375,
        "main_score": 0.084467,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.069738,
        "recall": 0.105469,
        "f1": 0.078194,
        "accuracy": 0.105469,
        "main_score": 0.078194,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.089807,
        "recall": 0.130859,
        "f1": 0.100415,
        "accuracy": 0.130859,
        "main_score": 0.100415,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.25232,
        "recall": 0.286133,
        "f1": 0.260243,
        "accuracy": 0.286133,
        "main_score": 0.260243,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.032637,
        "recall": 0.053711,
        "f1": 0.036781,
        "accuracy": 0.053711,
        "main_score": 0.036781,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.03324,
        "recall": 0.063477,
        "f1": 0.039316,
        "accuracy": 0.063477,
        "main_score": 0.039316,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.301631,
        "recall": 0.334961,
        "f1": 0.310243,
        "accuracy": 0.334961,
        "main_score": 0.310243,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.182226,
        "recall": 0.231445,
        "f1": 0.195134,
        "accuracy": 0.231445,
        "main_score": 0.195134,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.226083,
        "recall": 0.27832,
        "f1": 0.240115,
        "accuracy": 0.27832,
        "main_score": 0.240115,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.257211,
        "recall": 0.277344,
        "f1": 0.26186,
        "accuracy": 0.277344,
        "main_score": 0.26186,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.055742,
        "recall": 0.080078,
        "f1": 0.060955,
        "accuracy": 0.080078,
        "main_score": 0.060955,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.048379,
        "recall": 0.074219,
        "f1": 0.053922,
        "accuracy": 0.074219,
        "main_score": 0.053922,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.293325,
        "recall": 0.321289,
        "f1": 0.300625,
        "accuracy": 0.321289,
        "main_score": 0.300625,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.12065,
        "recall": 0.151367,
        "f1": 0.127648,
        "accuracy": 0.151367,
        "main_score": 0.127648,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.257778,
        "recall": 0.28418,
        "f1": 0.26404,
        "accuracy": 0.28418,
        "main_score": 0.26404,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.052559,
        "recall": 0.09375,
        "f1": 0.060386,
        "accuracy": 0.09375,
        "main_score": 0.060386,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.3433,
        "recall": 0.386719,
        "f1": 0.355306,
        "accuracy": 0.386719,
        "main_score": 0.355306,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.039572,
        "recall": 0.055664,
        "f1": 0.042611,
        "accuracy": 0.055664,
        "main_score": 0.042611,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.257694,
        "recall": 0.288086,
        "f1": 0.264943,
        "accuracy": 0.288086,
        "main_score": 0.264943,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.085322,
        "recall": 0.123047,
        "f1": 0.093729,
        "accuracy": 0.123047,
        "main_score": 0.093729,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.156295,
        "recall": 0.194336,
        "f1": 0.165964,
        "accuracy": 0.194336,
        "main_score": 0.165964,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.041696,
        "recall": 0.066406,
        "f1": 0.046429,
        "accuracy": 0.066406,
        "main_score": 0.046429,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.052286,
        "recall": 0.081055,
        "f1": 0.058423,
        "accuracy": 0.081055,
        "main_score": 0.058423,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.060423,
        "recall": 0.085938,
        "f1": 0.066191,
        "accuracy": 0.085938,
        "main_score": 0.066191,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.058566,
        "recall": 0.086914,
        "f1": 0.064507,
        "accuracy": 0.086914,
        "main_score": 0.064507,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.295649,
        "recall": 0.350586,
        "f1": 0.308472,
        "accuracy": 0.350586,
        "main_score": 0.308472,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.017373,
        "recall": 0.03125,
        "f1": 0.01953,
        "accuracy": 0.03125,
        "main_score": 0.01953,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.070518,
        "recall": 0.100586,
        "f1": 0.077904,
        "accuracy": 0.100586,
        "main_score": 0.077904,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.332049,
        "recall": 0.380859,
        "f1": 0.344852,
        "accuracy": 0.380859,
        "main_score": 0.344852,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.185098,
        "recall": 0.228516,
        "f1": 0.19638,
        "accuracy": 0.228516,
        "main_score": 0.19638,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.228607,
        "recall": 0.263672,
        "f1": 0.23737,
        "accuracy": 0.263672,
        "main_score": 0.23737,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.286582,
        "recall": 0.311523,
        "f1": 0.292172,
        "accuracy": 0.311523,
        "main_score": 0.292172,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.004011,
        "recall": 0.011719,
        "f1": 0.004894,
        "accuracy": 0.011719,
        "main_score": 0.004894,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.003124,
        "recall": 0.010742,
        "f1": 0.003939,
        "accuracy": 0.010742,
        "main_score": 0.003939,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.168506,
        "recall": 0.208008,
        "f1": 0.176933,
        "accuracy": 0.208008,
        "main_score": 0.176933,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.176268,
        "recall": 0.225586,
        "f1": 0.186198,
        "accuracy": 0.225586,
        "main_score": 0.186198,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.175444,
        "recall": 0.210938,
        "f1": 0.182807,
        "accuracy": 0.210938,
        "main_score": 0.182807,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.022941,
        "recall": 0.047852,
        "f1": 0.027651,
        "accuracy": 0.047852,
        "main_score": 0.027651,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.172334,
        "recall": 0.209961,
        "f1": 0.179853,
        "accuracy": 0.209961,
        "main_score": 0.179853,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003791,
        "recall": 0.012695,
        "f1": 0.004723,
        "accuracy": 0.012695,
        "main_score": 0.004723,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.158343,
        "recall": 0.205078,
        "f1": 0.168361,
        "accuracy": 0.205078,
        "main_score": 0.168361,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.002957,
        "recall": 0.014648,
        "f1": 0.003996,
        "accuracy": 0.014648,
        "main_score": 0.003996,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.108444,
        "recall": 0.152344,
        "f1": 0.117946,
        "accuracy": 0.152344,
        "main_score": 0.117946,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.00308,
        "recall": 0.009766,
        "f1": 0.003718,
        "accuracy": 0.009766,
        "main_score": 0.003718,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003087,
        "recall": 0.008789,
        "f1": 0.003953,
        "accuracy": 0.008789,
        "main_score": 0.003953,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.002471,
        "recall": 0.014648,
        "f1": 0.003562,
        "accuracy": 0.014648,
        "main_score": 0.003562,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.003001,
        "recall": 0.011719,
        "f1": 0.003721,
        "accuracy": 0.011719,
        "main_score": 0.003721,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.161319,
        "recall": 0.204102,
        "f1": 0.169916,
        "accuracy": 0.204102,
        "main_score": 0.169916,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.002617,
        "recall": 0.007812,
        "f1": 0.003258,
        "accuracy": 0.007812,
        "main_score": 0.003258,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001624,
        "recall": 0.009766,
        "f1": 0.002446,
        "accuracy": 0.009766,
        "main_score": 0.002446,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.164685,
        "recall": 0.202148,
        "f1": 0.17268,
        "accuracy": 0.202148,
        "main_score": 0.17268,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.128621,
        "recall": 0.173828,
        "f1": 0.138535,
        "accuracy": 0.173828,
        "main_score": 0.138535,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.156281,
        "recall": 0.199219,
        "f1": 0.165248,
        "accuracy": 0.199219,
        "main_score": 0.165248,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.164599,
        "recall": 0.203125,
        "f1": 0.172263,
        "accuracy": 0.203125,
        "main_score": 0.172263,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.043783,
        "recall": 0.076172,
        "f1": 0.050159,
        "accuracy": 0.076172,
        "main_score": 0.050159,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.044341,
        "recall": 0.066406,
        "f1": 0.049156,
        "accuracy": 0.066406,
        "main_score": 0.049156,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.284789,
        "recall": 0.323242,
        "f1": 0.295079,
        "accuracy": 0.323242,
        "main_score": 0.295079,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.255436,
        "recall": 0.299805,
        "f1": 0.265875,
        "accuracy": 0.299805,
        "main_score": 0.265875,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.104241,
        "recall": 0.129883,
        "f1": 0.110121,
        "accuracy": 0.129883,
        "main_score": 0.110121,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.108869,
        "recall": 0.167969,
        "f1": 0.122009,
        "accuracy": 0.167969,
        "main_score": 0.122009,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.287097,
        "recall": 0.327148,
        "f1": 0.296619,
        "accuracy": 0.327148,
        "main_score": 0.296619,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.109856,
        "recall": 0.144531,
        "f1": 0.118521,
        "accuracy": 0.144531,
        "main_score": 0.118521,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.2094,
        "recall": 0.238281,
        "f1": 0.216817,
        "accuracy": 0.238281,
        "main_score": 0.216817,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.042195,
        "recall": 0.075195,
        "f1": 0.048947,
        "accuracy": 0.075195,
        "main_score": 0.048947,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.187855,
        "recall": 0.242188,
        "f1": 0.202691,
        "accuracy": 0.242188,
        "main_score": 0.202691,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.090494,
        "recall": 0.123047,
        "f1": 0.098679,
        "accuracy": 0.123047,
        "main_score": 0.098679,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.046587,
        "recall": 0.073242,
        "f1": 0.051859,
        "accuracy": 0.073242,
        "main_score": 0.051859,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.045309,
        "recall": 0.079102,
        "f1": 0.0528,
        "accuracy": 0.079102,
        "main_score": 0.0528,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.060788,
        "recall": 0.092773,
        "f1": 0.067774,
        "accuracy": 0.092773,
        "main_score": 0.067774,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.241825,
        "recall": 0.28125,
        "f1": 0.250844,
        "accuracy": 0.28125,
        "main_score": 0.250844,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.030954,
        "recall": 0.057617,
        "f1": 0.035486,
        "accuracy": 0.057617,
        "main_score": 0.035486,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.022738,
        "recall": 0.044922,
        "f1": 0.026821,
        "accuracy": 0.044922,
        "main_score": 0.026821,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.263752,
        "recall": 0.294922,
        "f1": 0.270772,
        "accuracy": 0.294922,
        "main_score": 0.270772,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.210261,
        "recall": 0.264648,
        "f1": 0.224252,
        "accuracy": 0.264648,
        "main_score": 0.224252,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.248767,
        "recall": 0.299805,
        "f1": 0.262826,
        "accuracy": 0.299805,
        "main_score": 0.262826,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.2388,
        "recall": 0.260742,
        "f1": 0.244552,
        "accuracy": 0.260742,
        "main_score": 0.244552,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.061083,
        "recall": 0.098633,
        "f1": 0.06942,
        "accuracy": 0.098633,
        "main_score": 0.06942,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.047037,
        "recall": 0.077148,
        "f1": 0.053423,
        "accuracy": 0.077148,
        "main_score": 0.053423,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.075343,
        "recall": 0.109375,
        "f1": 0.082537,
        "accuracy": 0.109375,
        "main_score": 0.082537,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.061524,
        "recall": 0.092773,
        "f1": 0.066969,
        "accuracy": 0.092773,
        "main_score": 0.066969,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.017712,
        "recall": 0.021484,
        "f1": 0.017818,
        "accuracy": 0.021484,
        "main_score": 0.017818,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.108564,
        "recall": 0.155273,
        "f1": 0.119375,
        "accuracy": 0.155273,
        "main_score": 0.119375,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.08109,
        "recall": 0.116211,
        "f1": 0.088236,
        "accuracy": 0.116211,
        "main_score": 0.088236,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.101257,
        "recall": 0.139648,
        "f1": 0.111169,
        "accuracy": 0.139648,
        "main_score": 0.111169,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.039425,
        "recall": 0.054688,
        "f1": 0.041895,
        "accuracy": 0.054688,
        "main_score": 0.041895,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.061368,
        "recall": 0.09375,
        "f1": 0.068815,
        "accuracy": 0.09375,
        "main_score": 0.068815,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.064429,
        "recall": 0.087891,
        "f1": 0.069736,
        "accuracy": 0.087891,
        "main_score": 0.069736,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.108828,
        "recall": 0.15332,
        "f1": 0.119852,
        "accuracy": 0.15332,
        "main_score": 0.119852,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.063566,
        "recall": 0.099609,
        "f1": 0.071281,
        "accuracy": 0.099609,
        "main_score": 0.071281,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.036391,
        "recall": 0.067383,
        "f1": 0.042394,
        "accuracy": 0.067383,
        "main_score": 0.042394,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.075876,
        "recall": 0.114258,
        "f1": 0.084838,
        "accuracy": 0.114258,
        "main_score": 0.084838,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.048679,
        "recall": 0.075195,
        "f1": 0.053405,
        "accuracy": 0.075195,
        "main_score": 0.053405,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.02382,
        "recall": 0.047852,
        "f1": 0.027959,
        "accuracy": 0.047852,
        "main_score": 0.027959,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.036111,
        "recall": 0.0625,
        "f1": 0.041355,
        "accuracy": 0.0625,
        "main_score": 0.041355,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.066696,
        "recall": 0.091797,
        "f1": 0.070835,
        "accuracy": 0.091797,
        "main_score": 0.070835,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.073826,
        "recall": 0.095703,
        "f1": 0.078072,
        "accuracy": 0.095703,
        "main_score": 0.078072,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.077741,
        "recall": 0.107422,
        "f1": 0.083685,
        "accuracy": 0.107422,
        "main_score": 0.083685,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.040594,
        "recall": 0.054688,
        "f1": 0.04272,
        "accuracy": 0.054688,
        "main_score": 0.04272,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.074378,
        "recall": 0.106445,
        "f1": 0.081989,
        "accuracy": 0.106445,
        "main_score": 0.081989,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.05982,
        "recall": 0.091797,
        "f1": 0.066971,
        "accuracy": 0.091797,
        "main_score": 0.066971,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.304039,
        "recall": 0.332031,
        "f1": 0.311744,
        "accuracy": 0.332031,
        "main_score": 0.311744,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.337951,
        "recall": 0.384766,
        "f1": 0.350903,
        "accuracy": 0.384766,
        "main_score": 0.350903,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.097188,
        "recall": 0.130859,
        "f1": 0.104978,
        "accuracy": 0.130859,
        "main_score": 0.104978,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.270001,
        "recall": 0.301758,
        "f1": 0.277734,
        "accuracy": 0.301758,
        "main_score": 0.277734,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.084083,
        "recall": 0.125977,
        "f1": 0.092871,
        "accuracy": 0.125977,
        "main_score": 0.092871,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.038155,
        "recall": 0.058594,
        "f1": 0.042327,
        "accuracy": 0.058594,
        "main_score": 0.042327,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.245377,
        "recall": 0.280273,
        "f1": 0.253238,
        "accuracy": 0.280273,
        "main_score": 0.253238,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.083155,
        "recall": 0.12207,
        "f1": 0.09254,
        "accuracy": 0.12207,
        "main_score": 0.09254,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.155023,
        "recall": 0.197266,
        "f1": 0.165941,
        "accuracy": 0.197266,
        "main_score": 0.165941,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.041672,
        "recall": 0.063477,
        "f1": 0.046261,
        "accuracy": 0.063477,
        "main_score": 0.046261,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.069409,
        "recall": 0.098633,
        "f1": 0.076174,
        "accuracy": 0.098633,
        "main_score": 0.076174,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.041571,
        "recall": 0.066406,
        "f1": 0.046974,
        "accuracy": 0.066406,
        "main_score": 0.046974,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.071859,
        "recall": 0.101562,
        "f1": 0.078992,
        "accuracy": 0.101562,
        "main_score": 0.078992,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.280392,
        "recall": 0.325195,
        "f1": 0.29095,
        "accuracy": 0.325195,
        "main_score": 0.29095,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.018976,
        "recall": 0.036133,
        "f1": 0.022011,
        "accuracy": 0.036133,
        "main_score": 0.022011,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.050743,
        "recall": 0.073242,
        "f1": 0.055975,
        "accuracy": 0.073242,
        "main_score": 0.055975,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.37985,
        "recall": 0.423828,
        "f1": 0.391935,
        "accuracy": 0.423828,
        "main_score": 0.391935,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.17378,
        "recall": 0.216797,
        "f1": 0.184997,
        "accuracy": 0.216797,
        "main_score": 0.184997,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.212545,
        "recall": 0.255859,
        "f1": 0.223116,
        "accuracy": 0.255859,
        "main_score": 0.223116,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.297231,
        "recall": 0.325195,
        "f1": 0.303589,
        "accuracy": 0.325195,
        "main_score": 0.303589,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.071042,
        "recall": 0.107422,
        "f1": 0.078432,
        "accuracy": 0.107422,
        "main_score": 0.078432,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.062259,
        "recall": 0.097656,
        "f1": 0.069101,
        "accuracy": 0.097656,
        "main_score": 0.069101,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.045455,
        "recall": 0.089844,
        "f1": 0.053852,
        "accuracy": 0.089844,
        "main_score": 0.053852,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.028,
        "recall": 0.056641,
        "f1": 0.033419,
        "accuracy": 0.056641,
        "main_score": 0.033419,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000983,
        "recall": 0.003906,
        "f1": 0.001315,
        "accuracy": 0.003906,
        "main_score": 0.001315,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.076287,
        "recall": 0.132812,
        "f1": 0.090464,
        "accuracy": 0.132812,
        "main_score": 0.090464,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.100928,
        "recall": 0.151367,
        "f1": 0.114435,
        "accuracy": 0.151367,
        "main_score": 0.114435,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.027139,
        "recall": 0.057617,
        "f1": 0.032989,
        "accuracy": 0.057617,
        "main_score": 0.032989,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.005648,
        "recall": 0.020508,
        "f1": 0.00782,
        "accuracy": 0.020508,
        "main_score": 0.00782,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.051433,
        "recall": 0.091797,
        "f1": 0.059782,
        "accuracy": 0.091797,
        "main_score": 0.059782,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.061909,
        "recall": 0.100586,
        "f1": 0.070929,
        "accuracy": 0.100586,
        "main_score": 0.070929,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.125896,
        "recall": 0.168945,
        "f1": 0.137752,
        "accuracy": 0.168945,
        "main_score": 0.137752,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.055408,
        "recall": 0.092773,
        "f1": 0.063021,
        "accuracy": 0.092773,
        "main_score": 0.063021,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.064676,
        "recall": 0.105469,
        "f1": 0.073633,
        "accuracy": 0.105469,
        "main_score": 0.073633,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.090729,
        "recall": 0.139648,
        "f1": 0.102194,
        "accuracy": 0.139648,
        "main_score": 0.102194,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.015025,
        "recall": 0.040039,
        "f1": 0.018286,
        "accuracy": 0.040039,
        "main_score": 0.018286,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.051917,
        "recall": 0.088867,
        "f1": 0.05909,
        "accuracy": 0.088867,
        "main_score": 0.05909,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.037886,
        "recall": 0.06543,
        "f1": 0.042649,
        "accuracy": 0.06543,
        "main_score": 0.042649,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.018462,
        "recall": 0.041016,
        "f1": 0.022075,
        "accuracy": 0.041016,
        "main_score": 0.022075,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.060557,
        "recall": 0.094727,
        "f1": 0.068292,
        "accuracy": 0.094727,
        "main_score": 0.068292,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.076422,
        "recall": 0.115234,
        "f1": 0.085736,
        "accuracy": 0.115234,
        "main_score": 0.085736,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006799,
        "recall": 0.019531,
        "f1": 0.008609,
        "accuracy": 0.019531,
        "main_score": 0.008609,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.018958,
        "recall": 0.033203,
        "f1": 0.021022,
        "accuracy": 0.033203,
        "main_score": 0.021022,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.018847,
        "recall": 0.038086,
        "f1": 0.021854,
        "accuracy": 0.038086,
        "main_score": 0.021854,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.22402,
        "recall": 0.249023,
        "f1": 0.229358,
        "accuracy": 0.249023,
        "main_score": 0.229358,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.246654,
        "recall": 0.273438,
        "f1": 0.252481,
        "accuracy": 0.273438,
        "main_score": 0.252481,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.120574,
        "recall": 0.147461,
        "f1": 0.126744,
        "accuracy": 0.147461,
        "main_score": 0.126744,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.204116,
        "recall": 0.224609,
        "f1": 0.209267,
        "accuracy": 0.224609,
        "main_score": 0.209267,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.027546,
        "recall": 0.057617,
        "f1": 0.033075,
        "accuracy": 0.057617,
        "main_score": 0.033075,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.234823,
        "recall": 0.264648,
        "f1": 0.241767,
        "accuracy": 0.264648,
        "main_score": 0.241767,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.012086,
        "recall": 0.022461,
        "f1": 0.013819,
        "accuracy": 0.022461,
        "main_score": 0.013819,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.021468,
        "recall": 0.046875,
        "f1": 0.025257,
        "accuracy": 0.046875,
        "main_score": 0.025257,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.140153,
        "recall": 0.172852,
        "f1": 0.147931,
        "accuracy": 0.172852,
        "main_score": 0.147931,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.009528,
        "recall": 0.023438,
        "f1": 0.011188,
        "accuracy": 0.023438,
        "main_score": 0.011188,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.0138,
        "recall": 0.029297,
        "f1": 0.015854,
        "accuracy": 0.029297,
        "main_score": 0.015854,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.019746,
        "recall": 0.037109,
        "f1": 0.022894,
        "accuracy": 0.037109,
        "main_score": 0.022894,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.015275,
        "recall": 0.032227,
        "f1": 0.017754,
        "accuracy": 0.032227,
        "main_score": 0.017754,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.216957,
        "recall": 0.245117,
        "f1": 0.22321,
        "accuracy": 0.245117,
        "main_score": 0.22321,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.006258,
        "recall": 0.018555,
        "f1": 0.007709,
        "accuracy": 0.018555,
        "main_score": 0.007709,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.01886,
        "recall": 0.041016,
        "f1": 0.02264,
        "accuracy": 0.041016,
        "main_score": 0.02264,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.226288,
        "recall": 0.253906,
        "f1": 0.231754,
        "accuracy": 0.253906,
        "main_score": 0.231754,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.147958,
        "recall": 0.179688,
        "f1": 0.155893,
        "accuracy": 0.179688,
        "main_score": 0.155893,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.179304,
        "recall": 0.209961,
        "f1": 0.186344,
        "accuracy": 0.209961,
        "main_score": 0.186344,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.276761,
        "recall": 0.303711,
        "f1": 0.284134,
        "accuracy": 0.303711,
        "main_score": 0.284134,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.094862,
        "recall": 0.135742,
        "f1": 0.104445,
        "accuracy": 0.135742,
        "main_score": 0.104445,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.093613,
        "recall": 0.135742,
        "f1": 0.10367,
        "accuracy": 0.135742,
        "main_score": 0.10367,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.052318,
        "recall": 0.09082,
        "f1": 0.059734,
        "accuracy": 0.09082,
        "main_score": 0.059734,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.065597,
        "recall": 0.105469,
        "f1": 0.074396,
        "accuracy": 0.105469,
        "main_score": 0.074396,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003079,
        "recall": 0.005859,
        "f1": 0.003194,
        "accuracy": 0.005859,
        "main_score": 0.003194,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.037746,
        "recall": 0.072266,
        "f1": 0.04465,
        "accuracy": 0.072266,
        "main_score": 0.04465,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.075844,
        "recall": 0.114258,
        "f1": 0.08426,
        "accuracy": 0.114258,
        "main_score": 0.08426,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.062088,
        "recall": 0.09668,
        "f1": 0.071072,
        "accuracy": 0.09668,
        "main_score": 0.071072,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.062164,
        "recall": 0.083008,
        "f1": 0.066971,
        "accuracy": 0.083008,
        "main_score": 0.066971,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.022811,
        "recall": 0.045898,
        "f1": 0.026942,
        "accuracy": 0.045898,
        "main_score": 0.026942,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.027378,
        "recall": 0.042969,
        "f1": 0.030234,
        "accuracy": 0.042969,
        "main_score": 0.030234,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.078757,
        "recall": 0.108398,
        "f1": 0.083984,
        "accuracy": 0.108398,
        "main_score": 0.083984,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.092792,
        "recall": 0.128906,
        "f1": 0.101717,
        "accuracy": 0.128906,
        "main_score": 0.101717,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.109851,
        "recall": 0.146484,
        "f1": 0.118737,
        "accuracy": 0.146484,
        "main_score": 0.118737,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.104893,
        "recall": 0.138672,
        "f1": 0.112592,
        "accuracy": 0.138672,
        "main_score": 0.112592,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.026851,
        "recall": 0.053711,
        "f1": 0.031433,
        "accuracy": 0.053711,
        "main_score": 0.031433,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.035017,
        "recall": 0.053711,
        "f1": 0.038184,
        "accuracy": 0.053711,
        "main_score": 0.038184,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.084517,
        "recall": 0.119141,
        "f1": 0.093464,
        "accuracy": 0.119141,
        "main_score": 0.093464,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.051307,
        "recall": 0.080078,
        "f1": 0.058075,
        "accuracy": 0.080078,
        "main_score": 0.058075,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.029061,
        "recall": 0.052734,
        "f1": 0.03372,
        "accuracy": 0.052734,
        "main_score": 0.03372,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.030985,
        "recall": 0.055664,
        "f1": 0.035081,
        "accuracy": 0.055664,
        "main_score": 0.035081,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.016435,
        "recall": 0.03418,
        "f1": 0.019232,
        "accuracy": 0.03418,
        "main_score": 0.019232,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.03404,
        "recall": 0.051758,
        "f1": 0.037692,
        "accuracy": 0.051758,
        "main_score": 0.037692,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.035663,
        "recall": 0.06543,
        "f1": 0.042196,
        "accuracy": 0.06543,
        "main_score": 0.042196,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.191489,
        "recall": 0.224609,
        "f1": 0.199452,
        "accuracy": 0.224609,
        "main_score": 0.199452,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.163648,
        "recall": 0.191406,
        "f1": 0.17026,
        "accuracy": 0.191406,
        "main_score": 0.17026,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.062337,
        "recall": 0.079102,
        "f1": 0.066007,
        "accuracy": 0.079102,
        "main_score": 0.066007,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.199281,
        "recall": 0.230469,
        "f1": 0.207545,
        "accuracy": 0.230469,
        "main_score": 0.207545,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.058985,
        "recall": 0.097656,
        "f1": 0.067692,
        "accuracy": 0.097656,
        "main_score": 0.067692,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.168204,
        "recall": 0.202148,
        "f1": 0.176078,
        "accuracy": 0.202148,
        "main_score": 0.176078,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.084522,
        "recall": 0.114258,
        "f1": 0.091205,
        "accuracy": 0.114258,
        "main_score": 0.091205,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.142936,
        "recall": 0.166992,
        "f1": 0.148525,
        "accuracy": 0.166992,
        "main_score": 0.148525,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.027173,
        "recall": 0.050781,
        "f1": 0.031549,
        "accuracy": 0.050781,
        "main_score": 0.031549,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.05035,
        "recall": 0.073242,
        "f1": 0.05529,
        "accuracy": 0.073242,
        "main_score": 0.05529,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.032818,
        "recall": 0.060547,
        "f1": 0.038338,
        "accuracy": 0.060547,
        "main_score": 0.038338,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.034827,
        "recall": 0.061523,
        "f1": 0.039735,
        "accuracy": 0.061523,
        "main_score": 0.039735,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.035208,
        "recall": 0.055664,
        "f1": 0.039563,
        "accuracy": 0.055664,
        "main_score": 0.039563,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.154868,
        "recall": 0.179688,
        "f1": 0.160728,
        "accuracy": 0.179688,
        "main_score": 0.160728,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.025582,
        "recall": 0.048828,
        "f1": 0.029808,
        "accuracy": 0.048828,
        "main_score": 0.029808,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.011468,
        "recall": 0.03125,
        "f1": 0.014412,
        "accuracy": 0.03125,
        "main_score": 0.014412,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.153633,
        "recall": 0.181641,
        "f1": 0.160115,
        "accuracy": 0.181641,
        "main_score": 0.160115,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.191874,
        "recall": 0.228516,
        "f1": 0.202107,
        "accuracy": 0.228516,
        "main_score": 0.202107,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.195739,
        "recall": 0.229492,
        "f1": 0.204635,
        "accuracy": 0.229492,
        "main_score": 0.204635,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.151991,
        "recall": 0.172852,
        "f1": 0.15724,
        "accuracy": 0.172852,
        "main_score": 0.15724,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.076553,
        "recall": 0.112305,
        "f1": 0.084471,
        "accuracy": 0.112305,
        "main_score": 0.084471,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.058056,
        "recall": 0.088867,
        "f1": 0.064999,
        "accuracy": 0.088867,
        "main_score": 0.064999,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.036917,
        "recall": 0.072266,
        "f1": 0.044093,
        "accuracy": 0.072266,
        "main_score": 0.044093,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.030355,
        "recall": 0.061523,
        "f1": 0.035293,
        "accuracy": 0.061523,
        "main_score": 0.035293,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00111,
        "recall": 0.004883,
        "f1": 0.001216,
        "accuracy": 0.004883,
        "main_score": 0.001216,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.072475,
        "recall": 0.12793,
        "f1": 0.084445,
        "accuracy": 0.12793,
        "main_score": 0.084445,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.12205,
        "recall": 0.179688,
        "f1": 0.136605,
        "accuracy": 0.179688,
        "main_score": 0.136605,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.035612,
        "recall": 0.063477,
        "f1": 0.041401,
        "accuracy": 0.063477,
        "main_score": 0.041401,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.132351,
        "recall": 0.168945,
        "f1": 0.141818,
        "accuracy": 0.168945,
        "main_score": 0.141818,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.008627,
        "recall": 0.020508,
        "f1": 0.010398,
        "accuracy": 0.020508,
        "main_score": 0.010398,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.056065,
        "recall": 0.088867,
        "f1": 0.063205,
        "accuracy": 0.088867,
        "main_score": 0.063205,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.039287,
        "recall": 0.066406,
        "f1": 0.044854,
        "accuracy": 0.066406,
        "main_score": 0.044854,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.054345,
        "recall": 0.087891,
        "f1": 0.061601,
        "accuracy": 0.087891,
        "main_score": 0.061601,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.058619,
        "recall": 0.098633,
        "f1": 0.066454,
        "accuracy": 0.098633,
        "main_score": 0.066454,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.096553,
        "recall": 0.133789,
        "f1": 0.105337,
        "accuracy": 0.133789,
        "main_score": 0.105337,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.017484,
        "recall": 0.045898,
        "f1": 0.02112,
        "accuracy": 0.045898,
        "main_score": 0.02112,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.03655,
        "recall": 0.066406,
        "f1": 0.041588,
        "accuracy": 0.066406,
        "main_score": 0.041588,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.040639,
        "recall": 0.063477,
        "f1": 0.044878,
        "accuracy": 0.063477,
        "main_score": 0.044878,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.01916,
        "recall": 0.041992,
        "f1": 0.022518,
        "accuracy": 0.041992,
        "main_score": 0.022518,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.049337,
        "recall": 0.083008,
        "f1": 0.056963,
        "accuracy": 0.083008,
        "main_score": 0.056963,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.059914,
        "recall": 0.101562,
        "f1": 0.069988,
        "accuracy": 0.101562,
        "main_score": 0.069988,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006834,
        "recall": 0.019531,
        "f1": 0.008505,
        "accuracy": 0.019531,
        "main_score": 0.008505,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.107483,
        "recall": 0.157227,
        "f1": 0.120099,
        "accuracy": 0.157227,
        "main_score": 0.120099,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.085453,
        "recall": 0.120117,
        "f1": 0.093736,
        "accuracy": 0.120117,
        "main_score": 0.093736,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.061479,
        "recall": 0.103516,
        "f1": 0.070593,
        "accuracy": 0.103516,
        "main_score": 0.070593,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.043543,
        "recall": 0.075195,
        "f1": 0.05072,
        "accuracy": 0.075195,
        "main_score": 0.05072,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002102,
        "recall": 0.005859,
        "f1": 0.002223,
        "accuracy": 0.005859,
        "main_score": 0.002223,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.041769,
        "recall": 0.080078,
        "f1": 0.048782,
        "accuracy": 0.080078,
        "main_score": 0.048782,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.078375,
        "recall": 0.121094,
        "f1": 0.087853,
        "accuracy": 0.121094,
        "main_score": 0.087853,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.051366,
        "recall": 0.092773,
        "f1": 0.061568,
        "accuracy": 0.092773,
        "main_score": 0.061568,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.061728,
        "recall": 0.09375,
        "f1": 0.06903,
        "accuracy": 0.09375,
        "main_score": 0.06903,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.013265,
        "recall": 0.036133,
        "f1": 0.016635,
        "accuracy": 0.036133,
        "main_score": 0.016635,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.10108,
        "recall": 0.140625,
        "f1": 0.111063,
        "accuracy": 0.140625,
        "main_score": 0.111063,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.028403,
        "recall": 0.045898,
        "f1": 0.031269,
        "accuracy": 0.045898,
        "main_score": 0.031269,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.070957,
        "recall": 0.105469,
        "f1": 0.078715,
        "accuracy": 0.105469,
        "main_score": 0.078715,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.092393,
        "recall": 0.133789,
        "f1": 0.103235,
        "accuracy": 0.133789,
        "main_score": 0.103235,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.098575,
        "recall": 0.137695,
        "f1": 0.108501,
        "accuracy": 0.137695,
        "main_score": 0.108501,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.02603,
        "recall": 0.058594,
        "f1": 0.032227,
        "accuracy": 0.058594,
        "main_score": 0.032227,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.041917,
        "recall": 0.0625,
        "f1": 0.045543,
        "accuracy": 0.0625,
        "main_score": 0.045543,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.069291,
        "recall": 0.100586,
        "f1": 0.076764,
        "accuracy": 0.100586,
        "main_score": 0.076764,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.05507,
        "recall": 0.082031,
        "f1": 0.061215,
        "accuracy": 0.082031,
        "main_score": 0.061215,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.030861,
        "recall": 0.056641,
        "f1": 0.036007,
        "accuracy": 0.056641,
        "main_score": 0.036007,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.031273,
        "recall": 0.066406,
        "f1": 0.037194,
        "accuracy": 0.066406,
        "main_score": 0.037194,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.009091,
        "recall": 0.027344,
        "f1": 0.012126,
        "accuracy": 0.027344,
        "main_score": 0.012126,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.103591,
        "recall": 0.141602,
        "f1": 0.112878,
        "accuracy": 0.141602,
        "main_score": 0.112878,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.109154,
        "recall": 0.146484,
        "f1": 0.118866,
        "accuracy": 0.146484,
        "main_score": 0.118866,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.055445,
        "recall": 0.094727,
        "f1": 0.064183,
        "accuracy": 0.094727,
        "main_score": 0.064183,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.048385,
        "recall": 0.077148,
        "f1": 0.054905,
        "accuracy": 0.077148,
        "main_score": 0.054905,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00355,
        "recall": 0.006836,
        "f1": 0.003817,
        "accuracy": 0.006836,
        "main_score": 0.003817,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.034923,
        "recall": 0.070312,
        "f1": 0.041751,
        "accuracy": 0.070312,
        "main_score": 0.041751,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.063892,
        "recall": 0.101562,
        "f1": 0.071822,
        "accuracy": 0.101562,
        "main_score": 0.071822,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.034317,
        "recall": 0.061523,
        "f1": 0.040454,
        "accuracy": 0.061523,
        "main_score": 0.040454,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.08025,
        "recall": 0.115234,
        "f1": 0.087397,
        "accuracy": 0.115234,
        "main_score": 0.087397,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.013161,
        "recall": 0.037109,
        "f1": 0.016686,
        "accuracy": 0.037109,
        "main_score": 0.016686,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.107383,
        "recall": 0.154297,
        "f1": 0.119303,
        "accuracy": 0.154297,
        "main_score": 0.119303,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.029237,
        "recall": 0.043945,
        "f1": 0.031867,
        "accuracy": 0.043945,
        "main_score": 0.031867,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.080207,
        "recall": 0.117188,
        "f1": 0.088256,
        "accuracy": 0.117188,
        "main_score": 0.088256,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.111606,
        "recall": 0.146484,
        "f1": 0.120865,
        "accuracy": 0.146484,
        "main_score": 0.120865,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.101798,
        "recall": 0.140625,
        "f1": 0.111388,
        "accuracy": 0.140625,
        "main_score": 0.111388,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.024311,
        "recall": 0.054688,
        "f1": 0.029558,
        "accuracy": 0.054688,
        "main_score": 0.029558,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.045523,
        "recall": 0.070312,
        "f1": 0.05038,
        "accuracy": 0.070312,
        "main_score": 0.05038,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.068678,
        "recall": 0.105469,
        "f1": 0.077995,
        "accuracy": 0.105469,
        "main_score": 0.077995,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.031496,
        "recall": 0.051758,
        "f1": 0.035918,
        "accuracy": 0.051758,
        "main_score": 0.035918,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.039559,
        "recall": 0.067383,
        "f1": 0.045846,
        "accuracy": 0.067383,
        "main_score": 0.045846,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.040942,
        "recall": 0.071289,
        "f1": 0.046031,
        "accuracy": 0.071289,
        "main_score": 0.046031,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.009549,
        "recall": 0.023438,
        "f1": 0.011992,
        "accuracy": 0.023438,
        "main_score": 0.011992,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.122515,
        "recall": 0.178711,
        "f1": 0.137154,
        "accuracy": 0.178711,
        "main_score": 0.137154,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.093931,
        "recall": 0.144531,
        "f1": 0.106932,
        "accuracy": 0.144531,
        "main_score": 0.106932,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.079439,
        "recall": 0.12793,
        "f1": 0.091233,
        "accuracy": 0.12793,
        "main_score": 0.091233,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.049749,
        "recall": 0.088867,
        "f1": 0.058148,
        "accuracy": 0.088867,
        "main_score": 0.058148,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002101,
        "recall": 0.006836,
        "f1": 0.002221,
        "accuracy": 0.006836,
        "main_score": 0.002221,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.067847,
        "recall": 0.119141,
        "f1": 0.079324,
        "accuracy": 0.119141,
        "main_score": 0.079324,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.099827,
        "recall": 0.147461,
        "f1": 0.11164,
        "accuracy": 0.147461,
        "main_score": 0.11164,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.059433,
        "recall": 0.107422,
        "f1": 0.069708,
        "accuracy": 0.107422,
        "main_score": 0.069708,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.122728,
        "recall": 0.168945,
        "f1": 0.134355,
        "accuracy": 0.168945,
        "main_score": 0.134355,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.008581,
        "recall": 0.026367,
        "f1": 0.010934,
        "accuracy": 0.026367,
        "main_score": 0.010934,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.10528,
        "recall": 0.161133,
        "f1": 0.118484,
        "accuracy": 0.161133,
        "main_score": 0.118484,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.032583,
        "recall": 0.056641,
        "f1": 0.036761,
        "accuracy": 0.056641,
        "main_score": 0.036761,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.110584,
        "recall": 0.157227,
        "f1": 0.122537,
        "accuracy": 0.157227,
        "main_score": 0.122537,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.108979,
        "recall": 0.157227,
        "f1": 0.121443,
        "accuracy": 0.157227,
        "main_score": 0.121443,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.104218,
        "recall": 0.157227,
        "f1": 0.116667,
        "accuracy": 0.157227,
        "main_score": 0.116667,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.026313,
        "recall": 0.067383,
        "f1": 0.033139,
        "accuracy": 0.067383,
        "main_score": 0.033139,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.05154,
        "recall": 0.085938,
        "f1": 0.059141,
        "accuracy": 0.085938,
        "main_score": 0.059141,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.057908,
        "recall": 0.091797,
        "f1": 0.065195,
        "accuracy": 0.091797,
        "main_score": 0.065195,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.051265,
        "recall": 0.097656,
        "f1": 0.060684,
        "accuracy": 0.097656,
        "main_score": 0.060684,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.034846,
        "recall": 0.061523,
        "f1": 0.039554,
        "accuracy": 0.061523,
        "main_score": 0.039554,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.037021,
        "recall": 0.066406,
        "f1": 0.042783,
        "accuracy": 0.066406,
        "main_score": 0.042783,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007164,
        "recall": 0.025391,
        "f1": 0.009875,
        "accuracy": 0.025391,
        "main_score": 0.009875,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.046414,
        "recall": 0.073242,
        "f1": 0.05221,
        "accuracy": 0.073242,
        "main_score": 0.05221,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.048111,
        "recall": 0.074219,
        "f1": 0.053792,
        "accuracy": 0.074219,
        "main_score": 0.053792,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.29099,
        "recall": 0.319336,
        "f1": 0.298425,
        "accuracy": 0.319336,
        "main_score": 0.298425,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.335708,
        "recall": 0.368164,
        "f1": 0.344576,
        "accuracy": 0.368164,
        "main_score": 0.344576,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.115759,
        "recall": 0.151367,
        "f1": 0.123726,
        "accuracy": 0.151367,
        "main_score": 0.123726,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.270398,
        "recall": 0.299805,
        "f1": 0.277895,
        "accuracy": 0.299805,
        "main_score": 0.277895,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.056516,
        "recall": 0.103516,
        "f1": 0.065943,
        "accuracy": 0.103516,
        "main_score": 0.065943,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.324926,
        "recall": 0.363281,
        "f1": 0.335341,
        "accuracy": 0.363281,
        "main_score": 0.335341,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.031249,
        "recall": 0.051758,
        "f1": 0.03543,
        "accuracy": 0.051758,
        "main_score": 0.03543,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.245719,
        "recall": 0.283203,
        "f1": 0.254719,
        "accuracy": 0.283203,
        "main_score": 0.254719,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.047699,
        "recall": 0.084961,
        "f1": 0.056049,
        "accuracy": 0.084961,
        "main_score": 0.056049,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.163219,
        "recall": 0.204102,
        "f1": 0.173722,
        "accuracy": 0.204102,
        "main_score": 0.173722,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.036707,
        "recall": 0.056641,
        "f1": 0.040286,
        "accuracy": 0.056641,
        "main_score": 0.040286,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.049939,
        "recall": 0.070312,
        "f1": 0.054072,
        "accuracy": 0.070312,
        "main_score": 0.054072,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.048665,
        "recall": 0.072266,
        "f1": 0.053864,
        "accuracy": 0.072266,
        "main_score": 0.053864,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.059738,
        "recall": 0.089844,
        "f1": 0.066518,
        "accuracy": 0.089844,
        "main_score": 0.066518,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.017811,
        "recall": 0.035156,
        "f1": 0.020534,
        "accuracy": 0.035156,
        "main_score": 0.020534,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.041406,
        "recall": 0.066406,
        "f1": 0.046916,
        "accuracy": 0.066406,
        "main_score": 0.046916,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.307535,
        "recall": 0.34375,
        "f1": 0.317241,
        "accuracy": 0.34375,
        "main_score": 0.317241,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.181485,
        "recall": 0.21875,
        "f1": 0.190901,
        "accuracy": 0.21875,
        "main_score": 0.190901,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.215227,
        "recall": 0.255859,
        "f1": 0.225973,
        "accuracy": 0.255859,
        "main_score": 0.225973,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.274861,
        "recall": 0.298828,
        "f1": 0.280999,
        "accuracy": 0.298828,
        "main_score": 0.280999,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.039495,
        "recall": 0.064453,
        "f1": 0.04474,
        "accuracy": 0.064453,
        "main_score": 0.04474,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.040421,
        "recall": 0.067383,
        "f1": 0.045652,
        "accuracy": 0.067383,
        "main_score": 0.045652,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.026746,
        "recall": 0.050781,
        "f1": 0.030743,
        "accuracy": 0.050781,
        "main_score": 0.030743,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.01056,
        "recall": 0.024414,
        "f1": 0.012782,
        "accuracy": 0.024414,
        "main_score": 0.012782,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001094,
        "recall": 0.003906,
        "f1": 0.001189,
        "accuracy": 0.003906,
        "main_score": 0.001189,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.037752,
        "recall": 0.061523,
        "f1": 0.04121,
        "accuracy": 0.061523,
        "main_score": 0.04121,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.035946,
        "recall": 0.058594,
        "f1": 0.039823,
        "accuracy": 0.058594,
        "main_score": 0.039823,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.014282,
        "recall": 0.03418,
        "f1": 0.017338,
        "accuracy": 0.03418,
        "main_score": 0.017338,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.063051,
        "recall": 0.09082,
        "f1": 0.068368,
        "accuracy": 0.09082,
        "main_score": 0.068368,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.003252,
        "recall": 0.013672,
        "f1": 0.00464,
        "accuracy": 0.013672,
        "main_score": 0.00464,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.032506,
        "recall": 0.057617,
        "f1": 0.037155,
        "accuracy": 0.057617,
        "main_score": 0.037155,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.027412,
        "recall": 0.051758,
        "f1": 0.031725,
        "accuracy": 0.051758,
        "main_score": 0.031725,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.048808,
        "recall": 0.078125,
        "f1": 0.054578,
        "accuracy": 0.078125,
        "main_score": 0.054578,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.036649,
        "recall": 0.066406,
        "f1": 0.042707,
        "accuracy": 0.066406,
        "main_score": 0.042707,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.034916,
        "recall": 0.060547,
        "f1": 0.039106,
        "accuracy": 0.060547,
        "main_score": 0.039106,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.056879,
        "recall": 0.088867,
        "f1": 0.063311,
        "accuracy": 0.088867,
        "main_score": 0.063311,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.005976,
        "recall": 0.020508,
        "f1": 0.007666,
        "accuracy": 0.020508,
        "main_score": 0.007666,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.028346,
        "recall": 0.053711,
        "f1": 0.0326,
        "accuracy": 0.053711,
        "main_score": 0.0326,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.016425,
        "recall": 0.036133,
        "f1": 0.019806,
        "accuracy": 0.036133,
        "main_score": 0.019806,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.016526,
        "recall": 0.036133,
        "f1": 0.019899,
        "accuracy": 0.036133,
        "main_score": 0.019899,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.020659,
        "recall": 0.040039,
        "f1": 0.023184,
        "accuracy": 0.040039,
        "main_score": 0.023184,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001959,
        "recall": 0.005859,
        "f1": 0.002572,
        "accuracy": 0.005859,
        "main_score": 0.002572,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.058243,
        "recall": 0.091797,
        "f1": 0.065218,
        "accuracy": 0.091797,
        "main_score": 0.065218,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.088487,
        "recall": 0.125,
        "f1": 0.097366,
        "accuracy": 0.125,
        "main_score": 0.097366,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.022285,
        "recall": 0.051758,
        "f1": 0.02739,
        "accuracy": 0.051758,
        "main_score": 0.02739,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.048143,
        "recall": 0.083984,
        "f1": 0.05646,
        "accuracy": 0.083984,
        "main_score": 0.05646,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002947,
        "recall": 0.004883,
        "f1": 0.002964,
        "accuracy": 0.004883,
        "main_score": 0.002964,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022401,
        "recall": 0.041992,
        "f1": 0.026282,
        "accuracy": 0.041992,
        "main_score": 0.026282,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.040479,
        "recall": 0.066406,
        "f1": 0.045527,
        "accuracy": 0.066406,
        "main_score": 0.045527,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.034585,
        "recall": 0.071289,
        "f1": 0.042637,
        "accuracy": 0.071289,
        "main_score": 0.042637,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.031709,
        "recall": 0.047852,
        "f1": 0.034877,
        "accuracy": 0.047852,
        "main_score": 0.034877,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.013952,
        "recall": 0.03418,
        "f1": 0.017125,
        "accuracy": 0.03418,
        "main_score": 0.017125,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.071004,
        "recall": 0.099609,
        "f1": 0.078328,
        "accuracy": 0.099609,
        "main_score": 0.078328,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.0115,
        "recall": 0.022461,
        "f1": 0.012935,
        "accuracy": 0.022461,
        "main_score": 0.012935,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.043635,
        "recall": 0.063477,
        "f1": 0.047742,
        "accuracy": 0.063477,
        "main_score": 0.047742,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.045814,
        "recall": 0.082031,
        "f1": 0.054717,
        "accuracy": 0.082031,
        "main_score": 0.054717,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.064221,
        "recall": 0.098633,
        "f1": 0.072072,
        "accuracy": 0.098633,
        "main_score": 0.072072,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.053328,
        "recall": 0.084961,
        "f1": 0.059771,
        "accuracy": 0.084961,
        "main_score": 0.059771,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.017034,
        "recall": 0.045898,
        "f1": 0.021616,
        "accuracy": 0.045898,
        "main_score": 0.021616,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.024129,
        "recall": 0.037109,
        "f1": 0.026246,
        "accuracy": 0.037109,
        "main_score": 0.026246,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.024918,
        "recall": 0.043945,
        "f1": 0.029152,
        "accuracy": 0.043945,
        "main_score": 0.029152,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.022048,
        "recall": 0.037109,
        "f1": 0.024978,
        "accuracy": 0.037109,
        "main_score": 0.024978,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.020701,
        "recall": 0.041016,
        "f1": 0.024354,
        "accuracy": 0.041016,
        "main_score": 0.024354,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.009737,
        "recall": 0.023438,
        "f1": 0.012458,
        "accuracy": 0.023438,
        "main_score": 0.012458,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.04983,
        "recall": 0.082031,
        "f1": 0.056603,
        "accuracy": 0.082031,
        "main_score": 0.056603,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.039046,
        "recall": 0.068359,
        "f1": 0.045016,
        "accuracy": 0.068359,
        "main_score": 0.045016,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.302571,
        "recall": 0.334961,
        "f1": 0.311463,
        "accuracy": 0.334961,
        "main_score": 0.311463,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.330904,
        "recall": 0.376953,
        "f1": 0.343697,
        "accuracy": 0.376953,
        "main_score": 0.343697,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.108228,
        "recall": 0.136719,
        "f1": 0.11479,
        "accuracy": 0.136719,
        "main_score": 0.11479,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.278022,
        "recall": 0.307617,
        "f1": 0.286339,
        "accuracy": 0.307617,
        "main_score": 0.286339,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.09214,
        "recall": 0.130859,
        "f1": 0.100146,
        "accuracy": 0.130859,
        "main_score": 0.100146,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.394892,
        "recall": 0.4375,
        "f1": 0.406836,
        "accuracy": 0.4375,
        "main_score": 0.406836,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0487,
        "recall": 0.070312,
        "f1": 0.05363,
        "accuracy": 0.070312,
        "main_score": 0.05363,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.242324,
        "recall": 0.273438,
        "f1": 0.250914,
        "accuracy": 0.273438,
        "main_score": 0.250914,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.060859,
        "recall": 0.091797,
        "f1": 0.068231,
        "accuracy": 0.091797,
        "main_score": 0.068231,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.157557,
        "recall": 0.198242,
        "f1": 0.168549,
        "accuracy": 0.198242,
        "main_score": 0.168549,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.038368,
        "recall": 0.064453,
        "f1": 0.04363,
        "accuracy": 0.064453,
        "main_score": 0.04363,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.059071,
        "recall": 0.088867,
        "f1": 0.066156,
        "accuracy": 0.088867,
        "main_score": 0.066156,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.036378,
        "recall": 0.063477,
        "f1": 0.042235,
        "accuracy": 0.063477,
        "main_score": 0.042235,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.074188,
        "recall": 0.109375,
        "f1": 0.082337,
        "accuracy": 0.109375,
        "main_score": 0.082337,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.275393,
        "recall": 0.324219,
        "f1": 0.287461,
        "accuracy": 0.324219,
        "main_score": 0.287461,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.024342,
        "recall": 0.040039,
        "f1": 0.026735,
        "accuracy": 0.040039,
        "main_score": 0.026735,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.031326,
        "recall": 0.049805,
        "f1": 0.03556,
        "accuracy": 0.049805,
        "main_score": 0.03556,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.168358,
        "recall": 0.214844,
        "f1": 0.18026,
        "accuracy": 0.214844,
        "main_score": 0.18026,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.217384,
        "recall": 0.253906,
        "f1": 0.227313,
        "accuracy": 0.253906,
        "main_score": 0.227313,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.28434,
        "recall": 0.308594,
        "f1": 0.290647,
        "accuracy": 0.308594,
        "main_score": 0.290647,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.032101,
        "recall": 0.054688,
        "f1": 0.036256,
        "accuracy": 0.054688,
        "main_score": 0.036256,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.037447,
        "recall": 0.06543,
        "f1": 0.043567,
        "accuracy": 0.06543,
        "main_score": 0.043567,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.201112,
        "recall": 0.229492,
        "f1": 0.207391,
        "accuracy": 0.229492,
        "main_score": 0.207391,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.190268,
        "recall": 0.220703,
        "f1": 0.19795,
        "accuracy": 0.220703,
        "main_score": 0.19795,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.08067,
        "recall": 0.101562,
        "f1": 0.085111,
        "accuracy": 0.101562,
        "main_score": 0.085111,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.225012,
        "recall": 0.267578,
        "f1": 0.23573,
        "accuracy": 0.267578,
        "main_score": 0.23573,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.068317,
        "recall": 0.117188,
        "f1": 0.079366,
        "accuracy": 0.117188,
        "main_score": 0.079366,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.184123,
        "recall": 0.213867,
        "f1": 0.1916,
        "accuracy": 0.213867,
        "main_score": 0.1916,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.07611,
        "recall": 0.113281,
        "f1": 0.085189,
        "accuracy": 0.113281,
        "main_score": 0.085189,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.163614,
        "recall": 0.1875,
        "f1": 0.169358,
        "accuracy": 0.1875,
        "main_score": 0.169358,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.029123,
        "recall": 0.053711,
        "f1": 0.033666,
        "accuracy": 0.053711,
        "main_score": 0.033666,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.200606,
        "recall": 0.236328,
        "f1": 0.210745,
        "accuracy": 0.236328,
        "main_score": 0.210745,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.06361,
        "recall": 0.085938,
        "f1": 0.068604,
        "accuracy": 0.085938,
        "main_score": 0.068604,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.030966,
        "recall": 0.050781,
        "f1": 0.034116,
        "accuracy": 0.050781,
        "main_score": 0.034116,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.042041,
        "recall": 0.076172,
        "f1": 0.049619,
        "accuracy": 0.076172,
        "main_score": 0.049619,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.040441,
        "recall": 0.058594,
        "f1": 0.044719,
        "accuracy": 0.058594,
        "main_score": 0.044719,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.180214,
        "recall": 0.208008,
        "f1": 0.18586,
        "accuracy": 0.208008,
        "main_score": 0.18586,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.016133,
        "recall": 0.039062,
        "f1": 0.01997,
        "accuracy": 0.039062,
        "main_score": 0.01997,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.02285,
        "recall": 0.050781,
        "f1": 0.02797,
        "accuracy": 0.050781,
        "main_score": 0.02797,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.176027,
        "recall": 0.201172,
        "f1": 0.181956,
        "accuracy": 0.201172,
        "main_score": 0.181956,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.248858,
        "recall": 0.289062,
        "f1": 0.259675,
        "accuracy": 0.289062,
        "main_score": 0.259675,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.171706,
        "recall": 0.195312,
        "f1": 0.17709,
        "accuracy": 0.195312,
        "main_score": 0.17709,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.037309,
        "recall": 0.057617,
        "f1": 0.041142,
        "accuracy": 0.057617,
        "main_score": 0.041142,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.031999,
        "recall": 0.058594,
        "f1": 0.037897,
        "accuracy": 0.058594,
        "main_score": 0.037897,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.234775,
        "recall": 0.268555,
        "f1": 0.242769,
        "accuracy": 0.268555,
        "main_score": 0.242769,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.224172,
        "recall": 0.261719,
        "f1": 0.232787,
        "accuracy": 0.261719,
        "main_score": 0.232787,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.092486,
        "recall": 0.115234,
        "f1": 0.097636,
        "accuracy": 0.115234,
        "main_score": 0.097636,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.263871,
        "recall": 0.306641,
        "f1": 0.27544,
        "accuracy": 0.306641,
        "main_score": 0.27544,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.07112,
        "recall": 0.124023,
        "f1": 0.082487,
        "accuracy": 0.124023,
        "main_score": 0.082487,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.223349,
        "recall": 0.258789,
        "f1": 0.231904,
        "accuracy": 0.258789,
        "main_score": 0.231904,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.082846,
        "recall": 0.119141,
        "f1": 0.092067,
        "accuracy": 0.119141,
        "main_score": 0.092067,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.180648,
        "recall": 0.210938,
        "f1": 0.187753,
        "accuracy": 0.210938,
        "main_score": 0.187753,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.034431,
        "recall": 0.063477,
        "f1": 0.040039,
        "accuracy": 0.063477,
        "main_score": 0.040039,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.191512,
        "recall": 0.235352,
        "f1": 0.203602,
        "accuracy": 0.235352,
        "main_score": 0.203602,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.072699,
        "recall": 0.102539,
        "f1": 0.080672,
        "accuracy": 0.102539,
        "main_score": 0.080672,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.033343,
        "recall": 0.052734,
        "f1": 0.036929,
        "accuracy": 0.052734,
        "main_score": 0.036929,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.046795,
        "recall": 0.076172,
        "f1": 0.053278,
        "accuracy": 0.076172,
        "main_score": 0.053278,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.045927,
        "recall": 0.073242,
        "f1": 0.052297,
        "accuracy": 0.073242,
        "main_score": 0.052297,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.210159,
        "recall": 0.244141,
        "f1": 0.217112,
        "accuracy": 0.244141,
        "main_score": 0.217112,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.023575,
        "recall": 0.046875,
        "f1": 0.027661,
        "accuracy": 0.046875,
        "main_score": 0.027661,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.020784,
        "recall": 0.040039,
        "f1": 0.024799,
        "accuracy": 0.040039,
        "main_score": 0.024799,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.22218,
        "recall": 0.250977,
        "f1": 0.228405,
        "accuracy": 0.250977,
        "main_score": 0.228405,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.239136,
        "recall": 0.290039,
        "f1": 0.253543,
        "accuracy": 0.290039,
        "main_score": 0.253543,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.203883,
        "recall": 0.225586,
        "f1": 0.209106,
        "accuracy": 0.225586,
        "main_score": 0.209106,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.013354,
        "recall": 0.024414,
        "f1": 0.015119,
        "accuracy": 0.024414,
        "main_score": 0.015119,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.011198,
        "recall": 0.023438,
        "f1": 0.01291,
        "accuracy": 0.023438,
        "main_score": 0.01291,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.230416,
        "recall": 0.255859,
        "f1": 0.23637,
        "accuracy": 0.255859,
        "main_score": 0.23637,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.249156,
        "recall": 0.28125,
        "f1": 0.256739,
        "accuracy": 0.28125,
        "main_score": 0.256739,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.10815,
        "recall": 0.138672,
        "f1": 0.115197,
        "accuracy": 0.138672,
        "main_score": 0.115197,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.212005,
        "recall": 0.238281,
        "f1": 0.218987,
        "accuracy": 0.238281,
        "main_score": 0.218987,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.024288,
        "recall": 0.054688,
        "f1": 0.029531,
        "accuracy": 0.054688,
        "main_score": 0.029531,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.26027,
        "recall": 0.287109,
        "f1": 0.26668,
        "accuracy": 0.287109,
        "main_score": 0.26668,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.006428,
        "recall": 0.009766,
        "f1": 0.006989,
        "accuracy": 0.009766,
        "main_score": 0.006989,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.25723,
        "recall": 0.293945,
        "f1": 0.267456,
        "accuracy": 0.293945,
        "main_score": 0.267456,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.019276,
        "recall": 0.040039,
        "f1": 0.022878,
        "accuracy": 0.040039,
        "main_score": 0.022878,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.137823,
        "recall": 0.175781,
        "f1": 0.14714,
        "accuracy": 0.175781,
        "main_score": 0.14714,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.007211,
        "recall": 0.018555,
        "f1": 0.009083,
        "accuracy": 0.018555,
        "main_score": 0.009083,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.011589,
        "recall": 0.020508,
        "f1": 0.013263,
        "accuracy": 0.020508,
        "main_score": 0.013263,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.015483,
        "recall": 0.023438,
        "f1": 0.01679,
        "accuracy": 0.023438,
        "main_score": 0.01679,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.014189,
        "recall": 0.027344,
        "f1": 0.016339,
        "accuracy": 0.027344,
        "main_score": 0.016339,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.227028,
        "recall": 0.257812,
        "f1": 0.233528,
        "accuracy": 0.257812,
        "main_score": 0.233528,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.003628,
        "recall": 0.010742,
        "f1": 0.004592,
        "accuracy": 0.010742,
        "main_score": 0.004592,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.011377,
        "recall": 0.024414,
        "f1": 0.013698,
        "accuracy": 0.024414,
        "main_score": 0.013698,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.245687,
        "recall": 0.277344,
        "f1": 0.252257,
        "accuracy": 0.277344,
        "main_score": 0.252257,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.142993,
        "recall": 0.181641,
        "f1": 0.153112,
        "accuracy": 0.181641,
        "main_score": 0.153112,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.178801,
        "recall": 0.214844,
        "f1": 0.187496,
        "accuracy": 0.214844,
        "main_score": 0.187496,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 38.034019947052,
  "kg_co2_emissions": 0.0014176474637806534
}