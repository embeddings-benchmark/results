{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.02124,
        "f1": 0.011065,
        "f1_weighted": 0.013175,
        "scores_per_experiment": [
          {
            "accuracy": 0.017578,
            "f1": 0.007839,
            "f1_weighted": 0.008186
          },
          {
            "accuracy": 0.022461,
            "f1": 0.011594,
            "f1_weighted": 0.014165
          },
          {
            "accuracy": 0.020508,
            "f1": 0.012725,
            "f1_weighted": 0.013723
          },
          {
            "accuracy": 0.015625,
            "f1": 0.007256,
            "f1_weighted": 0.00989
          },
          {
            "accuracy": 0.021973,
            "f1": 0.009661,
            "f1_weighted": 0.01456
          },
          {
            "accuracy": 0.023926,
            "f1": 0.012375,
            "f1_weighted": 0.015357
          },
          {
            "accuracy": 0.01709,
            "f1": 0.006807,
            "f1_weighted": 0.00942
          },
          {
            "accuracy": 0.024902,
            "f1": 0.013115,
            "f1_weighted": 0.014647
          },
          {
            "accuracy": 0.027344,
            "f1": 0.016938,
            "f1_weighted": 0.017493
          },
          {
            "accuracy": 0.020996,
            "f1": 0.012339,
            "f1_weighted": 0.014311
          }
        ],
        "main_score": 0.02124,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.021777,
        "f1": 0.010377,
        "f1_weighted": 0.011839,
        "scores_per_experiment": [
          {
            "accuracy": 0.018066,
            "f1": 0.007307,
            "f1_weighted": 0.008192
          },
          {
            "accuracy": 0.024902,
            "f1": 0.011071,
            "f1_weighted": 0.012285
          },
          {
            "accuracy": 0.02002,
            "f1": 0.011298,
            "f1_weighted": 0.010902
          },
          {
            "accuracy": 0.012695,
            "f1": 0.005851,
            "f1_weighted": 0.004961
          },
          {
            "accuracy": 0.023926,
            "f1": 0.015714,
            "f1_weighted": 0.017779
          },
          {
            "accuracy": 0.021484,
            "f1": 0.011185,
            "f1_weighted": 0.010441
          },
          {
            "accuracy": 0.024414,
            "f1": 0.009852,
            "f1_weighted": 0.015842
          },
          {
            "accuracy": 0.026367,
            "f1": 0.011307,
            "f1_weighted": 0.015639
          },
          {
            "accuracy": 0.020508,
            "f1": 0.007203,
            "f1_weighted": 0.01029
          },
          {
            "accuracy": 0.025391,
            "f1": 0.012978,
            "f1_weighted": 0.012061
          }
        ],
        "main_score": 0.021777,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 271.16423082351685,
  "kg_co2_emissions": 0.01331958742472953
}