{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.577979,
        "f1": 0.573283,
        "f1_weighted": 0.579171,
        "ap": 0.46691,
        "ap_weighted": 0.46691,
        "scores_per_experiment": [
          {
            "accuracy": 0.605957,
            "f1": 0.604958,
            "f1_weighted": 0.608159,
            "ap": 0.488659,
            "ap_weighted": 0.488659
          },
          {
            "accuracy": 0.519043,
            "f1": 0.51879,
            "f1_weighted": 0.51701,
            "ap": 0.438555,
            "ap_weighted": 0.438555
          },
          {
            "accuracy": 0.52832,
            "f1": 0.519204,
            "f1_weighted": 0.529872,
            "ap": 0.429483,
            "ap_weighted": 0.429483
          },
          {
            "accuracy": 0.609375,
            "f1": 0.607696,
            "f1_weighted": 0.611832,
            "ap": 0.489807,
            "ap_weighted": 0.489807
          },
          {
            "accuracy": 0.583984,
            "f1": 0.575352,
            "f1_weighted": 0.585108,
            "ap": 0.46388,
            "ap_weighted": 0.46388
          },
          {
            "accuracy": 0.525879,
            "f1": 0.519443,
            "f1_weighted": 0.528404,
            "ap": 0.430065,
            "ap_weighted": 0.430065
          },
          {
            "accuracy": 0.583496,
            "f1": 0.583479,
            "f1_weighted": 0.583905,
            "ap": 0.476619,
            "ap_weighted": 0.476619
          },
          {
            "accuracy": 0.630371,
            "f1": 0.626989,
            "f1_weighted": 0.632712,
            "ap": 0.503563,
            "ap_weighted": 0.503563
          },
          {
            "accuracy": 0.615723,
            "f1": 0.602829,
            "f1_weighted": 0.61436,
            "ap": 0.484059,
            "ap_weighted": 0.484059
          },
          {
            "accuracy": 0.577637,
            "f1": 0.574086,
            "f1_weighted": 0.580352,
            "ap": 0.464406,
            "ap_weighted": 0.464406
          }
        ],
        "main_score": 0.573283,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.3029396533966064,
  "kg_co2_emissions": 0.00022901356407898613
}