{"name": "laion/CLIP-ViT-L-14-laion2B-s32B-b82K", "revision": "1627032197142fbe2a7cfec626f4ced3ae60d07a", "release_date": "2022-09-15", "languages": ["eng_Latn"], "n_parameters": 428000000, "memory_usage_mb": 1631.0, "max_tokens": 77.0, "embed_dim": 768, "license": "mit", "open_weights": true, "public_training_code": "https://github.com/mlfoundations/open_clip", "public_training_data": "https://laion.ai/blog/laion-5b/", "framework": ["PyTorch"], "reference": "https://huggingface.co/laion/CLIP-ViT-L-14-laion2B-s32B-b82K", "similarity_fn_name": null, "use_instructions": false, "training_datasets": {}, "adapted_from": null, "superseded_by": null, "is_cross_encoder": null, "modalities": ["image", "text"], "loader": "openclip_loader"}