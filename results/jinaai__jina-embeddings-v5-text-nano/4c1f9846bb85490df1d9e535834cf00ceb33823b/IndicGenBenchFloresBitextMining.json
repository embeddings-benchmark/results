{
  "dataset_revision": "07dcc23c08a2540ba37ebe1e487da9dc497cc15c",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "2.3.11",
  "scores": {
    "validation": [
      {
        "precision": 0.996991,
        "recall": 0.997994,
        "f1": 0.997325,
        "accuracy": 0.997994,
        "main_score": 0.997325,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.996991,
        "recall": 0.997994,
        "f1": 0.997325,
        "accuracy": 0.997994,
        "main_score": 0.997325,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.941324,
        "recall": 0.95988,
        "f1": 0.947342,
        "accuracy": 0.95988,
        "main_score": 0.947342,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.939652,
        "recall": 0.958877,
        "f1": 0.946005,
        "accuracy": 0.958877,
        "main_score": 0.946005,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.96874,
        "recall": 0.978937,
        "f1": 0.972083,
        "accuracy": 0.978937,
        "main_score": 0.972083,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.970996,
        "recall": 0.97994,
        "f1": 0.973821,
        "accuracy": 0.97994,
        "main_score": 0.973821,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.977432,
        "recall": 0.984955,
        "f1": 0.97994,
        "accuracy": 0.984955,
        "main_score": 0.97994,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.970244,
        "recall": 0.97994,
        "f1": 0.97342,
        "accuracy": 0.97994,
        "main_score": 0.97342,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.989468,
        "recall": 0.992979,
        "f1": 0.990639,
        "accuracy": 0.992979,
        "main_score": 0.990639,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.986459,
        "recall": 0.990973,
        "f1": 0.987964,
        "accuracy": 0.990973,
        "main_score": 0.987964,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.960465,
        "recall": 0.972919,
        "f1": 0.96446,
        "accuracy": 0.972919,
        "main_score": 0.96446,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.968238,
        "recall": 0.977934,
        "f1": 0.971414,
        "accuracy": 0.977934,
        "main_score": 0.971414,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.95545,
        "recall": 0.968907,
        "f1": 0.959612,
        "accuracy": 0.968907,
        "main_score": 0.959612,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.951354,
        "recall": 0.966901,
        "f1": 0.956369,
        "accuracy": 0.966901,
        "main_score": 0.956369,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.990973,
        "recall": 0.993982,
        "f1": 0.991976,
        "accuracy": 0.993982,
        "main_score": 0.991976,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.991474,
        "recall": 0.993982,
        "f1": 0.99231,
        "accuracy": 0.993982,
        "main_score": 0.99231,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.954781,
        "recall": 0.968907,
        "f1": 0.959278,
        "accuracy": 0.968907,
        "main_score": 0.959278,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.947844,
        "recall": 0.963892,
        "f1": 0.953026,
        "accuracy": 0.963892,
        "main_score": 0.953026,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.987964,
        "recall": 0.991976,
        "f1": 0.989301,
        "accuracy": 0.991976,
        "main_score": 0.989301,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.973253,
        "recall": 0.981946,
        "f1": 0.976095,
        "accuracy": 0.981946,
        "main_score": 0.976095,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.980441,
        "recall": 0.985958,
        "f1": 0.98228,
        "accuracy": 0.985958,
        "main_score": 0.98228,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.97108,
        "recall": 0.97994,
        "f1": 0.973922,
        "accuracy": 0.97994,
        "main_score": 0.973922,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.966232,
        "recall": 0.976931,
        "f1": 0.969743,
        "accuracy": 0.976931,
        "main_score": 0.969743,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.957706,
        "recall": 0.970913,
        "f1": 0.962053,
        "accuracy": 0.970913,
        "main_score": 0.962053,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.949432,
        "recall": 0.963892,
        "f1": 0.953928,
        "accuracy": 0.963892,
        "main_score": 0.953928,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.941825,
        "recall": 0.960883,
        "f1": 0.948178,
        "accuracy": 0.960883,
        "main_score": 0.948178,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.866165,
        "recall": 0.904714,
        "f1": 0.878053,
        "accuracy": 0.904714,
        "main_score": 0.878053,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.865346,
        "recall": 0.905717,
        "f1": 0.878201,
        "accuracy": 0.905717,
        "main_score": 0.878201,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.936142,
        "recall": 0.955868,
        "f1": 0.942446,
        "accuracy": 0.955868,
        "main_score": 0.942446,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.928034,
        "recall": 0.94985,
        "f1": 0.935038,
        "accuracy": 0.94985,
        "main_score": 0.935038,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.991976,
        "recall": 0.993982,
        "f1": 0.992645,
        "accuracy": 0.993982,
        "main_score": 0.992645,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.9888,
        "recall": 0.990973,
        "f1": 0.989468,
        "accuracy": 0.990973,
        "main_score": 0.989468,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.993982,
        "recall": 0.995988,
        "f1": 0.994651,
        "accuracy": 0.995988,
        "main_score": 0.994651,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.989468,
        "recall": 0.992979,
        "f1": 0.990639,
        "accuracy": 0.992979,
        "main_score": 0.990639,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.103636,
        "recall": 0.135406,
        "f1": 0.110044,
        "accuracy": 0.135406,
        "main_score": 0.110044,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.110521,
        "recall": 0.174524,
        "f1": 0.122943,
        "accuracy": 0.174524,
        "main_score": 0.122943,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.312462,
        "recall": 0.358074,
        "f1": 0.323582,
        "accuracy": 0.358074,
        "main_score": 0.323582,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.312312,
        "recall": 0.408225,
        "f1": 0.335952,
        "accuracy": 0.408225,
        "main_score": 0.335952,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.990973,
        "recall": 0.993982,
        "f1": 0.991976,
        "accuracy": 0.993982,
        "main_score": 0.991976,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.98228,
        "recall": 0.987964,
        "f1": 0.984119,
        "accuracy": 0.987964,
        "main_score": 0.984119,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.818783,
        "recall": 0.863591,
        "f1": 0.831426,
        "accuracy": 0.863591,
        "main_score": 0.831426,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.826229,
        "recall": 0.877633,
        "f1": 0.842227,
        "accuracy": 0.877633,
        "main_score": 0.842227,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.981277,
        "recall": 0.986961,
        "f1": 0.983116,
        "accuracy": 0.986961,
        "main_score": 0.983116,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.978937,
        "recall": 0.985958,
        "f1": 0.981277,
        "accuracy": 0.985958,
        "main_score": 0.981277,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.990973,
        "recall": 0.993982,
        "f1": 0.991976,
        "accuracy": 0.993982,
        "main_score": 0.991976,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.984955,
        "recall": 0.98997,
        "f1": 0.986627,
        "accuracy": 0.98997,
        "main_score": 0.986627,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.998495,
        "recall": 0.998997,
        "f1": 0.998663,
        "accuracy": 0.998997,
        "main_score": 0.998663,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.992477,
        "recall": 0.994985,
        "f1": 0.993313,
        "accuracy": 0.994985,
        "main_score": 0.993313,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.353169,
        "recall": 0.400201,
        "f1": 0.36418,
        "accuracy": 0.400201,
        "main_score": 0.36418,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.367588,
        "recall": 0.470411,
        "f1": 0.396134,
        "accuracy": 0.470411,
        "main_score": 0.396134,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.995486,
        "recall": 0.996991,
        "f1": 0.995988,
        "accuracy": 0.996991,
        "main_score": 0.995988,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.989468,
        "recall": 0.992979,
        "f1": 0.990639,
        "accuracy": 0.992979,
        "main_score": 0.990639,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.990973,
        "recall": 0.993982,
        "f1": 0.991976,
        "accuracy": 0.993982,
        "main_score": 0.991976,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.986459,
        "recall": 0.990973,
        "f1": 0.987964,
        "accuracy": 0.990973,
        "main_score": 0.987964,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.005636,
        "recall": 0.012036,
        "f1": 0.006248,
        "accuracy": 0.012036,
        "main_score": 0.006248,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004816,
        "recall": 0.018054,
        "f1": 0.006023,
        "accuracy": 0.018054,
        "main_score": 0.006023,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.998518,
        "recall": 0.999012,
        "f1": 0.998682,
        "accuracy": 0.999012,
        "main_score": 0.998682,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.992589,
        "recall": 0.995059,
        "f1": 0.993412,
        "accuracy": 0.995059,
        "main_score": 0.993412,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.954381,
        "recall": 0.969368,
        "f1": 0.959321,
        "accuracy": 0.969368,
        "main_score": 0.959321,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.934124,
        "recall": 0.955534,
        "f1": 0.941206,
        "accuracy": 0.955534,
        "main_score": 0.941206,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.997036,
        "recall": 0.998024,
        "f1": 0.997365,
        "accuracy": 0.998024,
        "main_score": 0.997365,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.956357,
        "recall": 0.970356,
        "f1": 0.960968,
        "accuracy": 0.970356,
        "main_score": 0.960968,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.941041,
        "recall": 0.960474,
        "f1": 0.947464,
        "accuracy": 0.960474,
        "main_score": 0.947464,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.98666,
        "recall": 0.991107,
        "f1": 0.988142,
        "accuracy": 0.991107,
        "main_score": 0.988142,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.977767,
        "recall": 0.985178,
        "f1": 0.980237,
        "accuracy": 0.985178,
        "main_score": 0.980237,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.992589,
        "recall": 0.995059,
        "f1": 0.993412,
        "accuracy": 0.995059,
        "main_score": 0.993412,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.97365,
        "recall": 0.982213,
        "f1": 0.976449,
        "accuracy": 0.982213,
        "main_score": 0.976449,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.982213,
        "recall": 0.988142,
        "f1": 0.98419,
        "accuracy": 0.988142,
        "main_score": 0.98419,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.96031,
        "recall": 0.97332,
        "f1": 0.964592,
        "accuracy": 0.97332,
        "main_score": 0.964592,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.952569,
        "recall": 0.967391,
        "f1": 0.957345,
        "accuracy": 0.967391,
        "main_score": 0.957345,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.939806,
        "recall": 0.958498,
        "f1": 0.945718,
        "accuracy": 0.958498,
        "main_score": 0.945718,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.994071,
        "recall": 0.996047,
        "f1": 0.99473,
        "accuracy": 0.996047,
        "main_score": 0.99473,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.988142,
        "recall": 0.992095,
        "f1": 0.98946,
        "accuracy": 0.992095,
        "main_score": 0.98946,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.945026,
        "recall": 0.961462,
        "f1": 0.950099,
        "accuracy": 0.961462,
        "main_score": 0.950099,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.949852,
        "recall": 0.965415,
        "f1": 0.954776,
        "accuracy": 0.965415,
        "main_score": 0.954776,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.980731,
        "recall": 0.987154,
        "f1": 0.982872,
        "accuracy": 0.987154,
        "main_score": 0.982872,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.979249,
        "recall": 0.986166,
        "f1": 0.981555,
        "accuracy": 0.986166,
        "main_score": 0.981555,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.982708,
        "recall": 0.988142,
        "f1": 0.984519,
        "accuracy": 0.988142,
        "main_score": 0.984519,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.97892,
        "recall": 0.985178,
        "f1": 0.980896,
        "accuracy": 0.985178,
        "main_score": 0.980896,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.96138,
        "recall": 0.97332,
        "f1": 0.965152,
        "accuracy": 0.97332,
        "main_score": 0.965152,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.963768,
        "recall": 0.975296,
        "f1": 0.967556,
        "accuracy": 0.975296,
        "main_score": 0.967556,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.948287,
        "recall": 0.964427,
        "f1": 0.953393,
        "accuracy": 0.964427,
        "main_score": 0.953393,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.937088,
        "recall": 0.956522,
        "f1": 0.943347,
        "accuracy": 0.956522,
        "main_score": 0.943347,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.892598,
        "recall": 0.922925,
        "f1": 0.902256,
        "accuracy": 0.922925,
        "main_score": 0.902256,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.861248,
        "recall": 0.902174,
        "f1": 0.873998,
        "accuracy": 0.902174,
        "main_score": 0.873998,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.935112,
        "recall": 0.955534,
        "f1": 0.9417,
        "accuracy": 0.955534,
        "main_score": 0.9417,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.921607,
        "recall": 0.94664,
        "f1": 0.929842,
        "accuracy": 0.94664,
        "main_score": 0.929842,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.986907,
        "recall": 0.990119,
        "f1": 0.987879,
        "accuracy": 0.990119,
        "main_score": 0.987879,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.980484,
        "recall": 0.985178,
        "f1": 0.98195,
        "accuracy": 0.985178,
        "main_score": 0.98195,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.994071,
        "recall": 0.996047,
        "f1": 0.99473,
        "accuracy": 0.996047,
        "main_score": 0.99473,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.988142,
        "recall": 0.992095,
        "f1": 0.98946,
        "accuracy": 0.992095,
        "main_score": 0.98946,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.08361,
        "recall": 0.110672,
        "f1": 0.088939,
        "accuracy": 0.110672,
        "main_score": 0.088939,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.107304,
        "recall": 0.173913,
        "f1": 0.120797,
        "accuracy": 0.173913,
        "main_score": 0.120797,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.276701,
        "recall": 0.332016,
        "f1": 0.289512,
        "accuracy": 0.332016,
        "main_score": 0.289512,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.285007,
        "recall": 0.37747,
        "f1": 0.307951,
        "accuracy": 0.37747,
        "main_score": 0.307951,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.992589,
        "recall": 0.995059,
        "f1": 0.993412,
        "accuracy": 0.995059,
        "main_score": 0.993412,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.983696,
        "recall": 0.98913,
        "f1": 0.985507,
        "accuracy": 0.98913,
        "main_score": 0.985507,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.838282,
        "recall": 0.878458,
        "f1": 0.850202,
        "accuracy": 0.878458,
        "main_score": 0.850202,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.821723,
        "recall": 0.873518,
        "f1": 0.837931,
        "accuracy": 0.873518,
        "main_score": 0.837931,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.987154,
        "recall": 0.991107,
        "f1": 0.988472,
        "accuracy": 0.991107,
        "main_score": 0.988472,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.975791,
        "recall": 0.983202,
        "f1": 0.978261,
        "accuracy": 0.983202,
        "main_score": 0.978261,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.988142,
        "recall": 0.992095,
        "f1": 0.98946,
        "accuracy": 0.992095,
        "main_score": 0.98946,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.986989,
        "recall": 0.991107,
        "f1": 0.988307,
        "accuracy": 0.991107,
        "main_score": 0.988307,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.998518,
        "recall": 0.999012,
        "f1": 0.998682,
        "accuracy": 0.999012,
        "main_score": 0.998682,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.992589,
        "recall": 0.995059,
        "f1": 0.993412,
        "accuracy": 0.995059,
        "main_score": 0.993412,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.330067,
        "recall": 0.386364,
        "f1": 0.343259,
        "accuracy": 0.386364,
        "main_score": 0.343259,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.366393,
        "recall": 0.460474,
        "f1": 0.391619,
        "accuracy": 0.460474,
        "main_score": 0.391619,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.991107,
        "recall": 0.994071,
        "f1": 0.992095,
        "accuracy": 0.994071,
        "main_score": 0.992095,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.989625,
        "recall": 0.993083,
        "f1": 0.990777,
        "accuracy": 0.993083,
        "main_score": 0.990777,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.988142,
        "recall": 0.992095,
        "f1": 0.98946,
        "accuracy": 0.992095,
        "main_score": 0.98946,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.980731,
        "recall": 0.987154,
        "f1": 0.982872,
        "accuracy": 0.987154,
        "main_score": 0.982872,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.010386,
        "recall": 0.013834,
        "f1": 0.010891,
        "accuracy": 0.013834,
        "main_score": 0.010891,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003587,
        "recall": 0.022727,
        "f1": 0.005735,
        "accuracy": 0.022727,
        "main_score": 0.005735,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 239.41485738754272,
  "kg_co2_emissions": null
}