{
  "dataset_revision": "cec3923e16519efe51d535497e711932b8f1dc44",
  "task_name": "PunjabiNewsClassification",
  "mteb_version": "2.3.11",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.77707,
            "f1": 0.652501,
            "f1_weighted": 0.791647,
            "precision": 0.639189,
            "precision_weighted": 0.813617,
            "recall": 0.681445,
            "recall_weighted": 0.77707,
            "ap": 0.280175,
            "ap_weighted": 0.280175
          },
          {
            "accuracy": 0.808917,
            "f1": 0.682786,
            "f1_weighted": 0.816562,
            "precision": 0.67075,
            "precision_weighted": 0.826745,
            "recall": 0.700528,
            "recall_weighted": 0.808917,
            "ap": 0.31201,
            "ap_weighted": 0.31201
          },
          {
            "accuracy": 0.789809,
            "f1": 0.672358,
            "f1_weighted": 0.803553,
            "precision": 0.656869,
            "precision_weighted": 0.825046,
            "recall": 0.704492,
            "recall_weighted": 0.789809,
            "ap": 0.303951,
            "ap_weighted": 0.303951
          },
          {
            "accuracy": 0.757962,
            "f1": 0.618152,
            "f1_weighted": 0.772679,
            "precision": 0.608815,
            "precision_weighted": 0.793055,
            "recall": 0.639166,
            "recall_weighted": 0.757962,
            "ap": 0.243018,
            "ap_weighted": 0.243018
          },
          {
            "accuracy": 0.802548,
            "f1": 0.705904,
            "f1_weighted": 0.818655,
            "precision": 0.685029,
            "precision_weighted": 0.849555,
            "recall": 0.758368,
            "recall_weighted": 0.802548,
            "ap": 0.354895,
            "ap_weighted": 0.354895
          },
          {
            "accuracy": 0.840764,
            "f1": 0.675754,
            "f1_weighted": 0.830451,
            "precision": 0.705187,
            "precision_weighted": 0.824814,
            "recall": 0.657957,
            "recall_weighted": 0.840764,
            "ap": 0.30434,
            "ap_weighted": 0.30434
          },
          {
            "accuracy": 0.821656,
            "f1": 0.718638,
            "f1_weighted": 0.8325,
            "precision": 0.698921,
            "precision_weighted": 0.850535,
            "recall": 0.754404,
            "recall_weighted": 0.821656,
            "ap": 0.366086,
            "ap_weighted": 0.366086
          },
          {
            "accuracy": 0.828025,
            "f1": 0.702422,
            "f1_weighted": 0.83172,
            "precision": 0.694504,
            "precision_weighted": 0.836118,
            "recall": 0.711979,
            "recall_weighted": 0.828025,
            "ap": 0.33638,
            "ap_weighted": 0.33638
          },
          {
            "accuracy": 0.808917,
            "f1": 0.698541,
            "f1_weighted": 0.820536,
            "precision": 0.6809,
            "precision_weighted": 0.839039,
            "recall": 0.731356,
            "recall_weighted": 0.808917,
            "ap": 0.337199,
            "ap_weighted": 0.337199
          },
          {
            "accuracy": 0.808917,
            "f1": 0.690945,
            "f1_weighted": 0.818647,
            "precision": 0.675873,
            "precision_weighted": 0.832835,
            "recall": 0.715942,
            "recall_weighted": 0.808917,
            "ap": 0.324589,
            "ap_weighted": 0.324589
          }
        ],
        "accuracy": 0.804459,
        "f1": 0.6818,
        "f1_weighted": 0.813695,
        "precision": 0.671604,
        "precision_weighted": 0.829136,
        "recall": 0.705564,
        "recall_weighted": 0.804459,
        "ap": 0.316264,
        "ap_weighted": 0.316264,
        "main_score": 0.804459,
        "hf_subset": "default",
        "languages": [
          "pan-Guru"
        ]
      }
    ]
  },
  "evaluation_time": 11.344698667526245,
  "kg_co2_emissions": null
}