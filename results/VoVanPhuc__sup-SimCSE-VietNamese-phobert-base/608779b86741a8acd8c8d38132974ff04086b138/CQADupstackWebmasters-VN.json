{
    "dataset_revision": "482d6e560d977b137e435d33379c5a8049e70e8d",
    "mteb_dataset_name": "CQADupstackWebmasters-VN",
    "mteb_version": "1.38.41",
    "task_name": "CQADupstackWebmasters-VN",
    "scores": {
        "test": [
            {
                "evaluation_time": 15.66,
                "map_at_1": 0.05459,
                "map_at_10": 0.08977,
                "map_at_100": 0.09764,
                "map_at_1000": 0.09927,
                "map_at_20": 0.0942,
                "map_at_3": 0.07832,
                "map_at_5": 0.08513,
                "mrr_at_1": 0.07,
                "mrr_at_10": 0.10783,
                "mrr_at_100": 0.11579,
                "mrr_at_1000": 0.11698,
                "mrr_at_20": 0.11293,
                "mrr_at_3": 0.09667,
                "mrr_at_5": 0.10317,
                "ndcg_at_1": 0.07,
                "ndcg_at_10": 0.11413,
                "ndcg_at_100": 0.15096,
                "ndcg_at_1000": 0.18866,
                "ndcg_at_20": 0.12904,
                "ndcg_at_3": 0.09427,
                "ndcg_at_5": 0.10427,
                "precision_at_1": 0.07,
                "precision_at_10": 0.02475,
                "precision_at_100": 0.00657,
                "precision_at_1000": 0.00151,
                "precision_at_20": 0.01862,
                "precision_at_3": 0.04917,
                "precision_at_5": 0.038,
                "recall_at_1": 0.05459,
                "recall_at_10": 0.16124,
                "recall_at_100": 0.33496,
                "recall_at_1000": 0.59641,
                "recall_at_20": 0.21754,
                "recall_at_3": 0.10346,
                "recall_at_5": 0.12918,
                "hf_subset": "default",
                "main_score": 0.11413,
                "languages": [
                    "vie-Latn"
                ]
            }
        ]
    },
    "evaluation_time": null
}