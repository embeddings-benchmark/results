{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.679736,
        "f1": 0.677542,
        "f1_weighted": 0.67758,
        "ap": 0.622718,
        "ap_weighted": 0.622718,
        "scores_per_experiment": [
          {
            "accuracy": 0.661133,
            "f1": 0.649571,
            "f1_weighted": 0.649757,
            "ap": 0.600673,
            "ap_weighted": 0.600673
          },
          {
            "accuracy": 0.691406,
            "f1": 0.691377,
            "f1_weighted": 0.691386,
            "ap": 0.633079,
            "ap_weighted": 0.633079
          },
          {
            "accuracy": 0.678711,
            "f1": 0.678335,
            "f1_weighted": 0.678367,
            "ap": 0.620629,
            "ap_weighted": 0.620629
          },
          {
            "accuracy": 0.691406,
            "f1": 0.690271,
            "f1_weighted": 0.690216,
            "ap": 0.639039,
            "ap_weighted": 0.639039
          },
          {
            "accuracy": 0.678711,
            "f1": 0.677912,
            "f1_weighted": 0.677959,
            "ap": 0.619741,
            "ap_weighted": 0.619741
          },
          {
            "accuracy": 0.685547,
            "f1": 0.68545,
            "f1_weighted": 0.685433,
            "ap": 0.629974,
            "ap_weighted": 0.629974
          },
          {
            "accuracy": 0.695312,
            "f1": 0.695289,
            "f1_weighted": 0.695281,
            "ap": 0.63798,
            "ap_weighted": 0.63798
          },
          {
            "accuracy": 0.691406,
            "f1": 0.691349,
            "f1_weighted": 0.691361,
            "ap": 0.632796,
            "ap_weighted": 0.632796
          },
          {
            "accuracy": 0.633301,
            "f1": 0.625531,
            "f1_weighted": 0.625689,
            "ap": 0.581606,
            "ap_weighted": 0.581606
          },
          {
            "accuracy": 0.69043,
            "f1": 0.690334,
            "f1_weighted": 0.69035,
            "ap": 0.631667,
            "ap_weighted": 0.631667
          }
        ],
        "main_score": 0.679736,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.687939,
        "f1": 0.685848,
        "f1_weighted": 0.685873,
        "ap": 0.628711,
        "ap_weighted": 0.628711,
        "scores_per_experiment": [
          {
            "accuracy": 0.676758,
            "f1": 0.665358,
            "f1_weighted": 0.665478,
            "ap": 0.611891,
            "ap_weighted": 0.611891
          },
          {
            "accuracy": 0.709961,
            "f1": 0.709899,
            "f1_weighted": 0.709907,
            "ap": 0.648759,
            "ap_weighted": 0.648759
          },
          {
            "accuracy": 0.689941,
            "f1": 0.689273,
            "f1_weighted": 0.689301,
            "ap": 0.628882,
            "ap_weighted": 0.628882
          },
          {
            "accuracy": 0.695801,
            "f1": 0.694872,
            "f1_weighted": 0.694839,
            "ap": 0.642084,
            "ap_weighted": 0.642084
          },
          {
            "accuracy": 0.684082,
            "f1": 0.682901,
            "f1_weighted": 0.682939,
            "ap": 0.623114,
            "ap_weighted": 0.623114
          },
          {
            "accuracy": 0.676758,
            "f1": 0.676498,
            "f1_weighted": 0.67648,
            "ap": 0.622529,
            "ap_weighted": 0.622529
          },
          {
            "accuracy": 0.689453,
            "f1": 0.689429,
            "f1_weighted": 0.689424,
            "ap": 0.632256,
            "ap_weighted": 0.632256
          },
          {
            "accuracy": 0.694336,
            "f1": 0.693978,
            "f1_weighted": 0.693999,
            "ap": 0.633434,
            "ap_weighted": 0.633434
          },
          {
            "accuracy": 0.656738,
            "f1": 0.650712,
            "f1_weighted": 0.650802,
            "ap": 0.598603,
            "ap_weighted": 0.598603
          },
          {
            "accuracy": 0.705566,
            "f1": 0.705558,
            "f1_weighted": 0.705561,
            "ap": 0.64556,
            "ap_weighted": 0.64556
          }
        ],
        "main_score": 0.687939,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 19.420533895492554,
  "kg_co2_emissions": 0.0007620791242713859
}