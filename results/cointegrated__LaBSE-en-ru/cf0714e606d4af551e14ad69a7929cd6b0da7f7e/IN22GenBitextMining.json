{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.101534,
        "recall": 0.128906,
        "f1": 0.108549,
        "accuracy": 0.128906,
        "main_score": 0.108549,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.054909,
        "recall": 0.094727,
        "f1": 0.064226,
        "accuracy": 0.094727,
        "main_score": 0.064226,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.048314,
        "recall": 0.082031,
        "f1": 0.055506,
        "accuracy": 0.082031,
        "main_score": 0.055506,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003998,
        "recall": 0.008789,
        "f1": 0.004509,
        "accuracy": 0.008789,
        "main_score": 0.004509,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031097,
        "recall": 0.053711,
        "f1": 0.035082,
        "accuracy": 0.053711,
        "main_score": 0.035082,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.043756,
        "recall": 0.071289,
        "f1": 0.049119,
        "accuracy": 0.071289,
        "main_score": 0.049119,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.054052,
        "recall": 0.092773,
        "f1": 0.062917,
        "accuracy": 0.092773,
        "main_score": 0.062917,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.047586,
        "recall": 0.074219,
        "f1": 0.053116,
        "accuracy": 0.074219,
        "main_score": 0.053116,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.016975,
        "recall": 0.037109,
        "f1": 0.020586,
        "accuracy": 0.037109,
        "main_score": 0.020586,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.077551,
        "recall": 0.112305,
        "f1": 0.086985,
        "accuracy": 0.112305,
        "main_score": 0.086985,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.01628,
        "recall": 0.032227,
        "f1": 0.018999,
        "accuracy": 0.032227,
        "main_score": 0.018999,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.0518,
        "recall": 0.076172,
        "f1": 0.05702,
        "accuracy": 0.076172,
        "main_score": 0.05702,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.08733,
        "recall": 0.125977,
        "f1": 0.096827,
        "accuracy": 0.125977,
        "main_score": 0.096827,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.079413,
        "recall": 0.115234,
        "f1": 0.088361,
        "accuracy": 0.115234,
        "main_score": 0.088361,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.090662,
        "recall": 0.131836,
        "f1": 0.101453,
        "accuracy": 0.131836,
        "main_score": 0.101453,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.023775,
        "recall": 0.046875,
        "f1": 0.028085,
        "accuracy": 0.046875,
        "main_score": 0.028085,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.029262,
        "recall": 0.048828,
        "f1": 0.033253,
        "accuracy": 0.048828,
        "main_score": 0.033253,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.06413,
        "recall": 0.099609,
        "f1": 0.072223,
        "accuracy": 0.099609,
        "main_score": 0.072223,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.045474,
        "recall": 0.080078,
        "f1": 0.053396,
        "accuracy": 0.080078,
        "main_score": 0.053396,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.025097,
        "recall": 0.042969,
        "f1": 0.028614,
        "accuracy": 0.042969,
        "main_score": 0.028614,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.023093,
        "recall": 0.045898,
        "f1": 0.027352,
        "accuracy": 0.045898,
        "main_score": 0.027352,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.014579,
        "recall": 0.035156,
        "f1": 0.017996,
        "accuracy": 0.035156,
        "main_score": 0.017996,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.086331,
        "recall": 0.12793,
        "f1": 0.096501,
        "accuracy": 0.12793,
        "main_score": 0.096501,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.042916,
        "recall": 0.083008,
        "f1": 0.051256,
        "accuracy": 0.083008,
        "main_score": 0.051256,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.038974,
        "recall": 0.070312,
        "f1": 0.046437,
        "accuracy": 0.070312,
        "main_score": 0.046437,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.006196,
        "recall": 0.011719,
        "f1": 0.006855,
        "accuracy": 0.011719,
        "main_score": 0.006855,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.034769,
        "recall": 0.064453,
        "f1": 0.04076,
        "accuracy": 0.064453,
        "main_score": 0.04076,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.056351,
        "recall": 0.086914,
        "f1": 0.062184,
        "accuracy": 0.086914,
        "main_score": 0.062184,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.050687,
        "recall": 0.089844,
        "f1": 0.060282,
        "accuracy": 0.089844,
        "main_score": 0.060282,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.056972,
        "recall": 0.083008,
        "f1": 0.062165,
        "accuracy": 0.083008,
        "main_score": 0.062165,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.014544,
        "recall": 0.039062,
        "f1": 0.018709,
        "accuracy": 0.039062,
        "main_score": 0.018709,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.093841,
        "recall": 0.130859,
        "f1": 0.102227,
        "accuracy": 0.130859,
        "main_score": 0.102227,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.022069,
        "recall": 0.041992,
        "f1": 0.025753,
        "accuracy": 0.041992,
        "main_score": 0.025753,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.062375,
        "recall": 0.094727,
        "f1": 0.068861,
        "accuracy": 0.094727,
        "main_score": 0.068861,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.081142,
        "recall": 0.117188,
        "f1": 0.090278,
        "accuracy": 0.117188,
        "main_score": 0.090278,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.103695,
        "recall": 0.142578,
        "f1": 0.114204,
        "accuracy": 0.142578,
        "main_score": 0.114204,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.075429,
        "recall": 0.120117,
        "f1": 0.0864,
        "accuracy": 0.120117,
        "main_score": 0.0864,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.020148,
        "recall": 0.044922,
        "f1": 0.024426,
        "accuracy": 0.044922,
        "main_score": 0.024426,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.032173,
        "recall": 0.051758,
        "f1": 0.036423,
        "accuracy": 0.051758,
        "main_score": 0.036423,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.136324,
        "recall": 0.191406,
        "f1": 0.149882,
        "accuracy": 0.191406,
        "main_score": 0.149882,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.039521,
        "recall": 0.074219,
        "f1": 0.047131,
        "accuracy": 0.074219,
        "main_score": 0.047131,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.030295,
        "recall": 0.053711,
        "f1": 0.034733,
        "accuracy": 0.053711,
        "main_score": 0.034733,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.029233,
        "recall": 0.048828,
        "f1": 0.033173,
        "accuracy": 0.048828,
        "main_score": 0.033173,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.016287,
        "recall": 0.041016,
        "f1": 0.020771,
        "accuracy": 0.041016,
        "main_score": 0.020771,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.077454,
        "recall": 0.123047,
        "f1": 0.088607,
        "accuracy": 0.123047,
        "main_score": 0.088607,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.064271,
        "recall": 0.098633,
        "f1": 0.07209,
        "accuracy": 0.098633,
        "main_score": 0.07209,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.300214,
        "recall": 0.323242,
        "f1": 0.306357,
        "accuracy": 0.323242,
        "main_score": 0.306357,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.174472,
        "recall": 0.200195,
        "f1": 0.180462,
        "accuracy": 0.200195,
        "main_score": 0.180462,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.262772,
        "recall": 0.292969,
        "f1": 0.271152,
        "accuracy": 0.292969,
        "main_score": 0.271152,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.068089,
        "recall": 0.107422,
        "f1": 0.076212,
        "accuracy": 0.107422,
        "main_score": 0.076212,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.302544,
        "recall": 0.334961,
        "f1": 0.31121,
        "accuracy": 0.334961,
        "main_score": 0.31121,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.043468,
        "recall": 0.067383,
        "f1": 0.048154,
        "accuracy": 0.067383,
        "main_score": 0.048154,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.23845,
        "recall": 0.270508,
        "f1": 0.245985,
        "accuracy": 0.270508,
        "main_score": 0.245985,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.066686,
        "recall": 0.108398,
        "f1": 0.076181,
        "accuracy": 0.108398,
        "main_score": 0.076181,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.164469,
        "recall": 0.203125,
        "f1": 0.174124,
        "accuracy": 0.203125,
        "main_score": 0.174124,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.042339,
        "recall": 0.072266,
        "f1": 0.04905,
        "accuracy": 0.072266,
        "main_score": 0.04905,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.061449,
        "recall": 0.09375,
        "f1": 0.068873,
        "accuracy": 0.09375,
        "main_score": 0.068873,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.068065,
        "recall": 0.098633,
        "f1": 0.075617,
        "accuracy": 0.098633,
        "main_score": 0.075617,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.077121,
        "recall": 0.112305,
        "f1": 0.086325,
        "accuracy": 0.112305,
        "main_score": 0.086325,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.267087,
        "recall": 0.291016,
        "f1": 0.272825,
        "accuracy": 0.291016,
        "main_score": 0.272825,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.027491,
        "recall": 0.041992,
        "f1": 0.030008,
        "accuracy": 0.041992,
        "main_score": 0.030008,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.044657,
        "recall": 0.073242,
        "f1": 0.050719,
        "accuracy": 0.073242,
        "main_score": 0.050719,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.300802,
        "recall": 0.328125,
        "f1": 0.307941,
        "accuracy": 0.328125,
        "main_score": 0.307941,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.179136,
        "recall": 0.220703,
        "f1": 0.189817,
        "accuracy": 0.220703,
        "main_score": 0.189817,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.219404,
        "recall": 0.258789,
        "f1": 0.230169,
        "accuracy": 0.258789,
        "main_score": 0.230169,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.27224,
        "recall": 0.291992,
        "f1": 0.27656,
        "accuracy": 0.291992,
        "main_score": 0.27656,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.053834,
        "recall": 0.089844,
        "f1": 0.063093,
        "accuracy": 0.089844,
        "main_score": 0.063093,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.071128,
        "recall": 0.100586,
        "f1": 0.078533,
        "accuracy": 0.100586,
        "main_score": 0.078533,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.292492,
        "recall": 0.317383,
        "f1": 0.299127,
        "accuracy": 0.317383,
        "main_score": 0.299127,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.179179,
        "recall": 0.204102,
        "f1": 0.185193,
        "accuracy": 0.204102,
        "main_score": 0.185193,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.266905,
        "recall": 0.302734,
        "f1": 0.275653,
        "accuracy": 0.302734,
        "main_score": 0.275653,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.05669,
        "recall": 0.099609,
        "f1": 0.064935,
        "accuracy": 0.099609,
        "main_score": 0.064935,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.344428,
        "recall": 0.387695,
        "f1": 0.356349,
        "accuracy": 0.387695,
        "main_score": 0.356349,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.044791,
        "recall": 0.067383,
        "f1": 0.049307,
        "accuracy": 0.067383,
        "main_score": 0.049307,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.262701,
        "recall": 0.292969,
        "f1": 0.269838,
        "accuracy": 0.292969,
        "main_score": 0.269838,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.088366,
        "recall": 0.134766,
        "f1": 0.100172,
        "accuracy": 0.134766,
        "main_score": 0.100172,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.172551,
        "recall": 0.208984,
        "f1": 0.181329,
        "accuracy": 0.208984,
        "main_score": 0.181329,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.043288,
        "recall": 0.070312,
        "f1": 0.048673,
        "accuracy": 0.070312,
        "main_score": 0.048673,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.066781,
        "recall": 0.099609,
        "f1": 0.07471,
        "accuracy": 0.099609,
        "main_score": 0.07471,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.080204,
        "recall": 0.119141,
        "f1": 0.089986,
        "accuracy": 0.119141,
        "main_score": 0.089986,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.068362,
        "recall": 0.098633,
        "f1": 0.076018,
        "accuracy": 0.098633,
        "main_score": 0.076018,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.303452,
        "recall": 0.345703,
        "f1": 0.312727,
        "accuracy": 0.345703,
        "main_score": 0.312727,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.022716,
        "recall": 0.037109,
        "f1": 0.025038,
        "accuracy": 0.037109,
        "main_score": 0.025038,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.066619,
        "recall": 0.104492,
        "f1": 0.076094,
        "accuracy": 0.104492,
        "main_score": 0.076094,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.342946,
        "recall": 0.386719,
        "f1": 0.354955,
        "accuracy": 0.386719,
        "main_score": 0.354955,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.188665,
        "recall": 0.227539,
        "f1": 0.199148,
        "accuracy": 0.227539,
        "main_score": 0.199148,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.221603,
        "recall": 0.254883,
        "f1": 0.230531,
        "accuracy": 0.254883,
        "main_score": 0.230531,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.29829,
        "recall": 0.321289,
        "f1": 0.303235,
        "accuracy": 0.321289,
        "main_score": 0.303235,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.005734,
        "recall": 0.024414,
        "f1": 0.007877,
        "accuracy": 0.024414,
        "main_score": 0.007877,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.006745,
        "recall": 0.021484,
        "f1": 0.008304,
        "accuracy": 0.021484,
        "main_score": 0.008304,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.126327,
        "recall": 0.230469,
        "f1": 0.146,
        "accuracy": 0.230469,
        "main_score": 0.146,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.127579,
        "recall": 0.248047,
        "f1": 0.150852,
        "accuracy": 0.248047,
        "main_score": 0.150852,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.124094,
        "recall": 0.223633,
        "f1": 0.143799,
        "accuracy": 0.223633,
        "main_score": 0.143799,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.017341,
        "recall": 0.060547,
        "f1": 0.022352,
        "accuracy": 0.060547,
        "main_score": 0.022352,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.122647,
        "recall": 0.235352,
        "f1": 0.144559,
        "accuracy": 0.235352,
        "main_score": 0.144559,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.008578,
        "recall": 0.024414,
        "f1": 0.01045,
        "accuracy": 0.024414,
        "main_score": 0.01045,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.126509,
        "recall": 0.224609,
        "f1": 0.144659,
        "accuracy": 0.224609,
        "main_score": 0.144659,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.009244,
        "recall": 0.032227,
        "f1": 0.012081,
        "accuracy": 0.032227,
        "main_score": 0.012081,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.084756,
        "recall": 0.169922,
        "f1": 0.100608,
        "accuracy": 0.169922,
        "main_score": 0.100608,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.007215,
        "recall": 0.032227,
        "f1": 0.009893,
        "accuracy": 0.032227,
        "main_score": 0.009893,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002523,
        "recall": 0.020508,
        "f1": 0.0041,
        "accuracy": 0.020508,
        "main_score": 0.0041,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.006588,
        "recall": 0.029297,
        "f1": 0.008992,
        "accuracy": 0.029297,
        "main_score": 0.008992,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.005687,
        "recall": 0.023438,
        "f1": 0.007747,
        "accuracy": 0.023438,
        "main_score": 0.007747,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.127815,
        "recall": 0.24707,
        "f1": 0.151444,
        "accuracy": 0.24707,
        "main_score": 0.151444,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.009001,
        "recall": 0.026367,
        "f1": 0.011319,
        "accuracy": 0.026367,
        "main_score": 0.011319,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.004254,
        "recall": 0.024414,
        "f1": 0.006064,
        "accuracy": 0.024414,
        "main_score": 0.006064,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.131344,
        "recall": 0.24707,
        "f1": 0.154493,
        "accuracy": 0.24707,
        "main_score": 0.154493,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.093104,
        "recall": 0.186523,
        "f1": 0.109953,
        "accuracy": 0.186523,
        "main_score": 0.109953,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.097401,
        "recall": 0.205078,
        "f1": 0.118445,
        "accuracy": 0.205078,
        "main_score": 0.118445,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.121515,
        "recall": 0.232422,
        "f1": 0.143167,
        "accuracy": 0.232422,
        "main_score": 0.143167,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.047702,
        "recall": 0.087891,
        "f1": 0.05627,
        "accuracy": 0.087891,
        "main_score": 0.05627,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.060711,
        "recall": 0.102539,
        "f1": 0.071294,
        "accuracy": 0.102539,
        "main_score": 0.071294,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.280599,
        "recall": 0.326172,
        "f1": 0.291277,
        "accuracy": 0.326172,
        "main_score": 0.291277,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.28339,
        "recall": 0.323242,
        "f1": 0.293809,
        "accuracy": 0.323242,
        "main_score": 0.293809,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.178135,
        "recall": 0.207031,
        "f1": 0.185385,
        "accuracy": 0.207031,
        "main_score": 0.185385,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.114793,
        "recall": 0.172852,
        "f1": 0.12803,
        "accuracy": 0.172852,
        "main_score": 0.12803,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.294656,
        "recall": 0.333984,
        "f1": 0.304688,
        "accuracy": 0.333984,
        "main_score": 0.304688,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.095834,
        "recall": 0.147461,
        "f1": 0.109475,
        "accuracy": 0.147461,
        "main_score": 0.109475,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.225222,
        "recall": 0.255859,
        "f1": 0.23392,
        "accuracy": 0.255859,
        "main_score": 0.23392,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.069139,
        "recall": 0.107422,
        "f1": 0.078477,
        "accuracy": 0.107422,
        "main_score": 0.078477,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.18446,
        "recall": 0.233398,
        "f1": 0.196331,
        "accuracy": 0.233398,
        "main_score": 0.196331,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.092808,
        "recall": 0.141602,
        "f1": 0.105218,
        "accuracy": 0.141602,
        "main_score": 0.105218,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.056986,
        "recall": 0.09668,
        "f1": 0.066276,
        "accuracy": 0.09668,
        "main_score": 0.066276,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.068383,
        "recall": 0.113281,
        "f1": 0.079037,
        "accuracy": 0.113281,
        "main_score": 0.079037,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.072961,
        "recall": 0.118164,
        "f1": 0.084311,
        "accuracy": 0.118164,
        "main_score": 0.084311,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.263649,
        "recall": 0.299805,
        "f1": 0.27225,
        "accuracy": 0.299805,
        "main_score": 0.27225,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.026409,
        "recall": 0.055664,
        "f1": 0.031392,
        "accuracy": 0.055664,
        "main_score": 0.031392,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.051264,
        "recall": 0.089844,
        "f1": 0.060303,
        "accuracy": 0.089844,
        "main_score": 0.060303,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.290131,
        "recall": 0.325195,
        "f1": 0.299876,
        "accuracy": 0.325195,
        "main_score": 0.299876,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.219898,
        "recall": 0.274414,
        "f1": 0.233975,
        "accuracy": 0.274414,
        "main_score": 0.233975,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.269518,
        "recall": 0.320312,
        "f1": 0.283894,
        "accuracy": 0.320312,
        "main_score": 0.283894,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.261463,
        "recall": 0.287109,
        "f1": 0.267719,
        "accuracy": 0.287109,
        "main_score": 0.267719,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.058455,
        "recall": 0.094727,
        "f1": 0.066567,
        "accuracy": 0.094727,
        "main_score": 0.066567,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.070018,
        "recall": 0.107422,
        "f1": 0.07876,
        "accuracy": 0.107422,
        "main_score": 0.07876,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.081316,
        "recall": 0.114258,
        "f1": 0.087612,
        "accuracy": 0.114258,
        "main_score": 0.087612,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.083628,
        "recall": 0.111328,
        "f1": 0.090085,
        "accuracy": 0.111328,
        "main_score": 0.090085,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.032962,
        "recall": 0.040039,
        "f1": 0.034158,
        "accuracy": 0.040039,
        "main_score": 0.034158,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.104472,
        "recall": 0.144531,
        "f1": 0.113729,
        "accuracy": 0.144531,
        "main_score": 0.113729,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.084297,
        "recall": 0.12793,
        "f1": 0.094534,
        "accuracy": 0.12793,
        "main_score": 0.094534,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.11108,
        "recall": 0.152344,
        "f1": 0.121859,
        "accuracy": 0.152344,
        "main_score": 0.121859,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.056455,
        "recall": 0.076172,
        "f1": 0.060039,
        "accuracy": 0.076172,
        "main_score": 0.060039,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.084048,
        "recall": 0.125,
        "f1": 0.094134,
        "accuracy": 0.125,
        "main_score": 0.094134,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.067965,
        "recall": 0.09082,
        "f1": 0.072791,
        "accuracy": 0.09082,
        "main_score": 0.072791,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.115556,
        "recall": 0.154297,
        "f1": 0.125349,
        "accuracy": 0.154297,
        "main_score": 0.125349,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.073654,
        "recall": 0.109375,
        "f1": 0.082076,
        "accuracy": 0.109375,
        "main_score": 0.082076,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.082516,
        "recall": 0.120117,
        "f1": 0.091346,
        "accuracy": 0.120117,
        "main_score": 0.091346,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.072261,
        "recall": 0.113281,
        "f1": 0.082042,
        "accuracy": 0.113281,
        "main_score": 0.082042,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.06189,
        "recall": 0.085938,
        "f1": 0.066751,
        "accuracy": 0.085938,
        "main_score": 0.066751,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.017751,
        "recall": 0.041992,
        "f1": 0.021387,
        "accuracy": 0.041992,
        "main_score": 0.021387,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.061115,
        "recall": 0.092773,
        "f1": 0.06926,
        "accuracy": 0.092773,
        "main_score": 0.06926,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.084692,
        "recall": 0.115234,
        "f1": 0.091038,
        "accuracy": 0.115234,
        "main_score": 0.091038,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.08038,
        "recall": 0.104492,
        "f1": 0.085657,
        "accuracy": 0.104492,
        "main_score": 0.085657,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.090988,
        "recall": 0.125,
        "f1": 0.098384,
        "accuracy": 0.125,
        "main_score": 0.098384,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.056192,
        "recall": 0.073242,
        "f1": 0.059075,
        "accuracy": 0.073242,
        "main_score": 0.059075,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.064743,
        "recall": 0.102539,
        "f1": 0.073751,
        "accuracy": 0.102539,
        "main_score": 0.073751,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.059612,
        "recall": 0.094727,
        "f1": 0.06793,
        "accuracy": 0.094727,
        "main_score": 0.06793,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.284393,
        "recall": 0.322266,
        "f1": 0.294653,
        "accuracy": 0.322266,
        "main_score": 0.294653,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.337241,
        "recall": 0.382812,
        "f1": 0.349695,
        "accuracy": 0.382812,
        "main_score": 0.349695,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.17804,
        "recall": 0.204102,
        "f1": 0.184323,
        "accuracy": 0.204102,
        "main_score": 0.184323,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.274097,
        "recall": 0.30957,
        "f1": 0.282774,
        "accuracy": 0.30957,
        "main_score": 0.282774,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.067192,
        "recall": 0.109375,
        "f1": 0.075934,
        "accuracy": 0.109375,
        "main_score": 0.075934,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.051263,
        "recall": 0.080078,
        "f1": 0.056782,
        "accuracy": 0.080078,
        "main_score": 0.056782,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.254021,
        "recall": 0.290039,
        "f1": 0.263042,
        "accuracy": 0.290039,
        "main_score": 0.263042,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.094765,
        "recall": 0.138672,
        "f1": 0.106191,
        "accuracy": 0.138672,
        "main_score": 0.106191,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.16046,
        "recall": 0.202148,
        "f1": 0.17042,
        "accuracy": 0.202148,
        "main_score": 0.17042,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.051437,
        "recall": 0.083008,
        "f1": 0.058128,
        "accuracy": 0.083008,
        "main_score": 0.058128,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.076173,
        "recall": 0.113281,
        "f1": 0.08532,
        "accuracy": 0.113281,
        "main_score": 0.08532,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.073216,
        "recall": 0.108398,
        "f1": 0.08213,
        "accuracy": 0.108398,
        "main_score": 0.08213,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.072111,
        "recall": 0.106445,
        "f1": 0.080532,
        "accuracy": 0.106445,
        "main_score": 0.080532,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.286508,
        "recall": 0.328125,
        "f1": 0.295838,
        "accuracy": 0.328125,
        "main_score": 0.295838,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.018917,
        "recall": 0.039062,
        "f1": 0.022142,
        "accuracy": 0.039062,
        "main_score": 0.022142,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.069503,
        "recall": 0.102539,
        "f1": 0.077885,
        "accuracy": 0.102539,
        "main_score": 0.077885,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.377313,
        "recall": 0.419922,
        "f1": 0.38877,
        "accuracy": 0.419922,
        "main_score": 0.38877,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.177557,
        "recall": 0.214844,
        "f1": 0.187075,
        "accuracy": 0.214844,
        "main_score": 0.187075,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.217031,
        "recall": 0.261719,
        "f1": 0.228089,
        "accuracy": 0.261719,
        "main_score": 0.228089,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.315959,
        "recall": 0.341797,
        "f1": 0.321581,
        "accuracy": 0.341797,
        "main_score": 0.321581,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.047207,
        "recall": 0.091797,
        "f1": 0.057462,
        "accuracy": 0.091797,
        "main_score": 0.057462,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.071153,
        "recall": 0.108398,
        "f1": 0.080093,
        "accuracy": 0.108398,
        "main_score": 0.080093,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.034452,
        "recall": 0.084961,
        "f1": 0.044143,
        "accuracy": 0.084961,
        "main_score": 0.044143,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.033335,
        "recall": 0.073242,
        "f1": 0.04205,
        "accuracy": 0.073242,
        "main_score": 0.04205,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.006995,
        "recall": 0.015625,
        "f1": 0.008073,
        "accuracy": 0.015625,
        "main_score": 0.008073,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.074236,
        "recall": 0.131836,
        "f1": 0.088692,
        "accuracy": 0.131836,
        "main_score": 0.088692,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.09467,
        "recall": 0.144531,
        "f1": 0.107697,
        "accuracy": 0.144531,
        "main_score": 0.107697,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.033164,
        "recall": 0.069336,
        "f1": 0.040937,
        "accuracy": 0.069336,
        "main_score": 0.040937,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.011027,
        "recall": 0.027344,
        "f1": 0.013546,
        "accuracy": 0.027344,
        "main_score": 0.013546,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.080745,
        "recall": 0.119141,
        "f1": 0.091309,
        "accuracy": 0.119141,
        "main_score": 0.091309,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.043657,
        "recall": 0.081055,
        "f1": 0.052601,
        "accuracy": 0.081055,
        "main_score": 0.052601,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.118693,
        "recall": 0.171875,
        "f1": 0.133588,
        "accuracy": 0.171875,
        "main_score": 0.133588,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.06872,
        "recall": 0.115234,
        "f1": 0.080311,
        "accuracy": 0.115234,
        "main_score": 0.080311,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.082398,
        "recall": 0.126953,
        "f1": 0.093339,
        "accuracy": 0.126953,
        "main_score": 0.093339,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.084174,
        "recall": 0.136719,
        "f1": 0.096625,
        "accuracy": 0.136719,
        "main_score": 0.096625,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.016819,
        "recall": 0.041016,
        "f1": 0.020402,
        "accuracy": 0.041016,
        "main_score": 0.020402,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.038917,
        "recall": 0.069336,
        "f1": 0.044611,
        "accuracy": 0.069336,
        "main_score": 0.044611,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.054313,
        "recall": 0.089844,
        "f1": 0.062192,
        "accuracy": 0.089844,
        "main_score": 0.062192,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.035707,
        "recall": 0.071289,
        "f1": 0.042805,
        "accuracy": 0.071289,
        "main_score": 0.042805,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.066916,
        "recall": 0.111328,
        "f1": 0.077896,
        "accuracy": 0.111328,
        "main_score": 0.077896,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.076264,
        "recall": 0.125,
        "f1": 0.088422,
        "accuracy": 0.125,
        "main_score": 0.088422,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.01014,
        "recall": 0.02832,
        "f1": 0.01315,
        "accuracy": 0.02832,
        "main_score": 0.01315,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.019793,
        "recall": 0.037109,
        "f1": 0.022632,
        "accuracy": 0.037109,
        "main_score": 0.022632,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.021412,
        "recall": 0.044922,
        "f1": 0.024925,
        "accuracy": 0.044922,
        "main_score": 0.024925,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.241212,
        "recall": 0.261719,
        "f1": 0.244929,
        "accuracy": 0.261719,
        "main_score": 0.244929,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.241739,
        "recall": 0.269531,
        "f1": 0.247093,
        "accuracy": 0.269531,
        "main_score": 0.247093,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.165035,
        "recall": 0.1875,
        "f1": 0.170375,
        "accuracy": 0.1875,
        "main_score": 0.170375,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.219054,
        "recall": 0.241211,
        "f1": 0.224498,
        "accuracy": 0.241211,
        "main_score": 0.224498,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.032169,
        "recall": 0.05957,
        "f1": 0.037172,
        "accuracy": 0.05957,
        "main_score": 0.037172,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.245131,
        "recall": 0.274414,
        "f1": 0.251851,
        "accuracy": 0.274414,
        "main_score": 0.251851,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015955,
        "recall": 0.030273,
        "f1": 0.018615,
        "accuracy": 0.030273,
        "main_score": 0.018615,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.031062,
        "recall": 0.057617,
        "f1": 0.035872,
        "accuracy": 0.057617,
        "main_score": 0.035872,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.145277,
        "recall": 0.178711,
        "f1": 0.153199,
        "accuracy": 0.178711,
        "main_score": 0.153199,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.015434,
        "recall": 0.032227,
        "f1": 0.01831,
        "accuracy": 0.032227,
        "main_score": 0.01831,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.017486,
        "recall": 0.040039,
        "f1": 0.020949,
        "accuracy": 0.040039,
        "main_score": 0.020949,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.021948,
        "recall": 0.041992,
        "f1": 0.025011,
        "accuracy": 0.041992,
        "main_score": 0.025011,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.020555,
        "recall": 0.033203,
        "f1": 0.02267,
        "accuracy": 0.033203,
        "main_score": 0.02267,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.237505,
        "recall": 0.258789,
        "f1": 0.241855,
        "accuracy": 0.258789,
        "main_score": 0.241855,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.00919,
        "recall": 0.020508,
        "f1": 0.010504,
        "accuracy": 0.020508,
        "main_score": 0.010504,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.021433,
        "recall": 0.046875,
        "f1": 0.025395,
        "accuracy": 0.046875,
        "main_score": 0.025395,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.237397,
        "recall": 0.262695,
        "f1": 0.242288,
        "accuracy": 0.262695,
        "main_score": 0.242288,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.150351,
        "recall": 0.1875,
        "f1": 0.158503,
        "accuracy": 0.1875,
        "main_score": 0.158503,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.179017,
        "recall": 0.212891,
        "f1": 0.186817,
        "accuracy": 0.212891,
        "main_score": 0.186817,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.289722,
        "recall": 0.314453,
        "f1": 0.29642,
        "accuracy": 0.314453,
        "main_score": 0.29642,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.066946,
        "recall": 0.109375,
        "f1": 0.075582,
        "accuracy": 0.109375,
        "main_score": 0.075582,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.090845,
        "recall": 0.125977,
        "f1": 0.099749,
        "accuracy": 0.125977,
        "main_score": 0.099749,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.043919,
        "recall": 0.080078,
        "f1": 0.050163,
        "accuracy": 0.080078,
        "main_score": 0.050163,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.058373,
        "recall": 0.09668,
        "f1": 0.067157,
        "accuracy": 0.09668,
        "main_score": 0.067157,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.006692,
        "recall": 0.011719,
        "f1": 0.00712,
        "accuracy": 0.011719,
        "main_score": 0.00712,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.038075,
        "recall": 0.068359,
        "f1": 0.044215,
        "accuracy": 0.068359,
        "main_score": 0.044215,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.056661,
        "recall": 0.084961,
        "f1": 0.063001,
        "accuracy": 0.084961,
        "main_score": 0.063001,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.066927,
        "recall": 0.107422,
        "f1": 0.077341,
        "accuracy": 0.107422,
        "main_score": 0.077341,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.065819,
        "recall": 0.089844,
        "f1": 0.070827,
        "accuracy": 0.089844,
        "main_score": 0.070827,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.022202,
        "recall": 0.054688,
        "f1": 0.028723,
        "accuracy": 0.054688,
        "main_score": 0.028723,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.024485,
        "recall": 0.040039,
        "f1": 0.027625,
        "accuracy": 0.040039,
        "main_score": 0.027625,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.063809,
        "recall": 0.097656,
        "f1": 0.071068,
        "accuracy": 0.097656,
        "main_score": 0.071068,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.090269,
        "recall": 0.134766,
        "f1": 0.101464,
        "accuracy": 0.134766,
        "main_score": 0.101464,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.112719,
        "recall": 0.157227,
        "f1": 0.124128,
        "accuracy": 0.157227,
        "main_score": 0.124128,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.084448,
        "recall": 0.124023,
        "f1": 0.093386,
        "accuracy": 0.124023,
        "main_score": 0.093386,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.02635,
        "recall": 0.053711,
        "f1": 0.031503,
        "accuracy": 0.053711,
        "main_score": 0.031503,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.028641,
        "recall": 0.049805,
        "f1": 0.0324,
        "accuracy": 0.049805,
        "main_score": 0.0324,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.076111,
        "recall": 0.111328,
        "f1": 0.085278,
        "accuracy": 0.111328,
        "main_score": 0.085278,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.049635,
        "recall": 0.082031,
        "f1": 0.057094,
        "accuracy": 0.082031,
        "main_score": 0.057094,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.033471,
        "recall": 0.051758,
        "f1": 0.037353,
        "accuracy": 0.051758,
        "main_score": 0.037353,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.033434,
        "recall": 0.057617,
        "f1": 0.038119,
        "accuracy": 0.057617,
        "main_score": 0.038119,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.027779,
        "recall": 0.054688,
        "f1": 0.033898,
        "accuracy": 0.054688,
        "main_score": 0.033898,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.027201,
        "recall": 0.051758,
        "f1": 0.032149,
        "accuracy": 0.051758,
        "main_score": 0.032149,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.035667,
        "recall": 0.061523,
        "f1": 0.040913,
        "accuracy": 0.061523,
        "main_score": 0.040913,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.182677,
        "recall": 0.210938,
        "f1": 0.189256,
        "accuracy": 0.210938,
        "main_score": 0.189256,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.171856,
        "recall": 0.195312,
        "f1": 0.177277,
        "accuracy": 0.195312,
        "main_score": 0.177277,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.125557,
        "recall": 0.140625,
        "f1": 0.128829,
        "accuracy": 0.140625,
        "main_score": 0.128829,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.199493,
        "recall": 0.232422,
        "f1": 0.208237,
        "accuracy": 0.232422,
        "main_score": 0.208237,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.061252,
        "recall": 0.102539,
        "f1": 0.070907,
        "accuracy": 0.102539,
        "main_score": 0.070907,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.177427,
        "recall": 0.206055,
        "f1": 0.183579,
        "accuracy": 0.206055,
        "main_score": 0.183579,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.064134,
        "recall": 0.094727,
        "f1": 0.072074,
        "accuracy": 0.094727,
        "main_score": 0.072074,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.147954,
        "recall": 0.168945,
        "f1": 0.15327,
        "accuracy": 0.168945,
        "main_score": 0.15327,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.036145,
        "recall": 0.061523,
        "f1": 0.04086,
        "accuracy": 0.061523,
        "main_score": 0.04086,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.055867,
        "recall": 0.083008,
        "f1": 0.062275,
        "accuracy": 0.083008,
        "main_score": 0.062275,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.03052,
        "recall": 0.056641,
        "f1": 0.036013,
        "accuracy": 0.056641,
        "main_score": 0.036013,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.035551,
        "recall": 0.060547,
        "f1": 0.040673,
        "accuracy": 0.060547,
        "main_score": 0.040673,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.032613,
        "recall": 0.058594,
        "f1": 0.038507,
        "accuracy": 0.058594,
        "main_score": 0.038507,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.168342,
        "recall": 0.191406,
        "f1": 0.173648,
        "accuracy": 0.191406,
        "main_score": 0.173648,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.010698,
        "recall": 0.03418,
        "f1": 0.014392,
        "accuracy": 0.03418,
        "main_score": 0.014392,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.020001,
        "recall": 0.040039,
        "f1": 0.024209,
        "accuracy": 0.040039,
        "main_score": 0.024209,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.167356,
        "recall": 0.195312,
        "f1": 0.174114,
        "accuracy": 0.195312,
        "main_score": 0.174114,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.198491,
        "recall": 0.230469,
        "f1": 0.206872,
        "accuracy": 0.230469,
        "main_score": 0.206872,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.195057,
        "recall": 0.228516,
        "f1": 0.203876,
        "accuracy": 0.228516,
        "main_score": 0.203876,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.160112,
        "recall": 0.183594,
        "f1": 0.165514,
        "accuracy": 0.183594,
        "main_score": 0.165514,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.054639,
        "recall": 0.092773,
        "f1": 0.063227,
        "accuracy": 0.092773,
        "main_score": 0.063227,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.080769,
        "recall": 0.117188,
        "f1": 0.089336,
        "accuracy": 0.117188,
        "main_score": 0.089336,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.032697,
        "recall": 0.070312,
        "f1": 0.040064,
        "accuracy": 0.070312,
        "main_score": 0.040064,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.035133,
        "recall": 0.072266,
        "f1": 0.042853,
        "accuracy": 0.072266,
        "main_score": 0.042853,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.005592,
        "recall": 0.013672,
        "f1": 0.006399,
        "accuracy": 0.013672,
        "main_score": 0.006399,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.066123,
        "recall": 0.119141,
        "f1": 0.078538,
        "accuracy": 0.119141,
        "main_score": 0.078538,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.106924,
        "recall": 0.160156,
        "f1": 0.120576,
        "accuracy": 0.160156,
        "main_score": 0.120576,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.034044,
        "recall": 0.070312,
        "f1": 0.042144,
        "accuracy": 0.070312,
        "main_score": 0.042144,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.132373,
        "recall": 0.175781,
        "f1": 0.144334,
        "accuracy": 0.175781,
        "main_score": 0.144334,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.013017,
        "recall": 0.032227,
        "f1": 0.016211,
        "accuracy": 0.032227,
        "main_score": 0.016211,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.09141,
        "recall": 0.132812,
        "f1": 0.101146,
        "accuracy": 0.132812,
        "main_score": 0.101146,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.037229,
        "recall": 0.072266,
        "f1": 0.044424,
        "accuracy": 0.072266,
        "main_score": 0.044424,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.082434,
        "recall": 0.117188,
        "f1": 0.091397,
        "accuracy": 0.117188,
        "main_score": 0.091397,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.085982,
        "recall": 0.128906,
        "f1": 0.096243,
        "accuracy": 0.128906,
        "main_score": 0.096243,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.082636,
        "recall": 0.123047,
        "f1": 0.092822,
        "accuracy": 0.123047,
        "main_score": 0.092822,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.019599,
        "recall": 0.047852,
        "f1": 0.02384,
        "accuracy": 0.047852,
        "main_score": 0.02384,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.022454,
        "recall": 0.044922,
        "f1": 0.025825,
        "accuracy": 0.044922,
        "main_score": 0.025825,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.063576,
        "recall": 0.102539,
        "f1": 0.072731,
        "accuracy": 0.102539,
        "main_score": 0.072731,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.038107,
        "recall": 0.072266,
        "f1": 0.04474,
        "accuracy": 0.072266,
        "main_score": 0.04474,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.049242,
        "recall": 0.079102,
        "f1": 0.056242,
        "accuracy": 0.079102,
        "main_score": 0.056242,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.056624,
        "recall": 0.098633,
        "f1": 0.066943,
        "accuracy": 0.098633,
        "main_score": 0.066943,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.011628,
        "recall": 0.032227,
        "f1": 0.015026,
        "accuracy": 0.032227,
        "main_score": 0.015026,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.063321,
        "recall": 0.113281,
        "f1": 0.074805,
        "accuracy": 0.113281,
        "main_score": 0.074805,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.073962,
        "recall": 0.113281,
        "f1": 0.08351,
        "accuracy": 0.113281,
        "main_score": 0.08351,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.0366,
        "recall": 0.075195,
        "f1": 0.044019,
        "accuracy": 0.075195,
        "main_score": 0.044019,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.04174,
        "recall": 0.075195,
        "f1": 0.049641,
        "accuracy": 0.075195,
        "main_score": 0.049641,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003649,
        "recall": 0.008789,
        "f1": 0.003991,
        "accuracy": 0.008789,
        "main_score": 0.003991,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031924,
        "recall": 0.067383,
        "f1": 0.038838,
        "accuracy": 0.067383,
        "main_score": 0.038838,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.058485,
        "recall": 0.09375,
        "f1": 0.066143,
        "accuracy": 0.09375,
        "main_score": 0.066143,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.047592,
        "recall": 0.091797,
        "f1": 0.058622,
        "accuracy": 0.091797,
        "main_score": 0.058622,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.059503,
        "recall": 0.09082,
        "f1": 0.066944,
        "accuracy": 0.09082,
        "main_score": 0.066944,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.01992,
        "recall": 0.041016,
        "f1": 0.023992,
        "accuracy": 0.041016,
        "main_score": 0.023992,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.101041,
        "recall": 0.136719,
        "f1": 0.10978,
        "accuracy": 0.136719,
        "main_score": 0.10978,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.023891,
        "recall": 0.041992,
        "f1": 0.027249,
        "accuracy": 0.041992,
        "main_score": 0.027249,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.059052,
        "recall": 0.092773,
        "f1": 0.066554,
        "accuracy": 0.092773,
        "main_score": 0.066554,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.101876,
        "recall": 0.137695,
        "f1": 0.111577,
        "accuracy": 0.137695,
        "main_score": 0.111577,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.081292,
        "recall": 0.119141,
        "f1": 0.090531,
        "accuracy": 0.119141,
        "main_score": 0.090531,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.027491,
        "recall": 0.058594,
        "f1": 0.033036,
        "accuracy": 0.058594,
        "main_score": 0.033036,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.029332,
        "recall": 0.048828,
        "f1": 0.032606,
        "accuracy": 0.048828,
        "main_score": 0.032606,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.072659,
        "recall": 0.108398,
        "f1": 0.082086,
        "accuracy": 0.108398,
        "main_score": 0.082086,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.049743,
        "recall": 0.083984,
        "f1": 0.057934,
        "accuracy": 0.083984,
        "main_score": 0.057934,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.027342,
        "recall": 0.046875,
        "f1": 0.031465,
        "accuracy": 0.046875,
        "main_score": 0.031465,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.030423,
        "recall": 0.063477,
        "f1": 0.03634,
        "accuracy": 0.063477,
        "main_score": 0.03634,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.014606,
        "recall": 0.03418,
        "f1": 0.0183,
        "accuracy": 0.03418,
        "main_score": 0.0183,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.072289,
        "recall": 0.116211,
        "f1": 0.082683,
        "accuracy": 0.116211,
        "main_score": 0.082683,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.10874,
        "recall": 0.146484,
        "f1": 0.118133,
        "accuracy": 0.146484,
        "main_score": 0.118133,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.044518,
        "recall": 0.081055,
        "f1": 0.052134,
        "accuracy": 0.081055,
        "main_score": 0.052134,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.056735,
        "recall": 0.091797,
        "f1": 0.064555,
        "accuracy": 0.091797,
        "main_score": 0.064555,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.007165,
        "recall": 0.012695,
        "f1": 0.007795,
        "accuracy": 0.012695,
        "main_score": 0.007795,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.041826,
        "recall": 0.071289,
        "f1": 0.047872,
        "accuracy": 0.071289,
        "main_score": 0.047872,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.061391,
        "recall": 0.091797,
        "f1": 0.067783,
        "accuracy": 0.091797,
        "main_score": 0.067783,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.043589,
        "recall": 0.080078,
        "f1": 0.052273,
        "accuracy": 0.080078,
        "main_score": 0.052273,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.063251,
        "recall": 0.092773,
        "f1": 0.069256,
        "accuracy": 0.092773,
        "main_score": 0.069256,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.019044,
        "recall": 0.045898,
        "f1": 0.024011,
        "accuracy": 0.045898,
        "main_score": 0.024011,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.108375,
        "recall": 0.154297,
        "f1": 0.119653,
        "accuracy": 0.154297,
        "main_score": 0.119653,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.02227,
        "recall": 0.038086,
        "f1": 0.024915,
        "accuracy": 0.038086,
        "main_score": 0.024915,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.066707,
        "recall": 0.097656,
        "f1": 0.073862,
        "accuracy": 0.097656,
        "main_score": 0.073862,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.10495,
        "recall": 0.147461,
        "f1": 0.115817,
        "accuracy": 0.147461,
        "main_score": 0.115817,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.107745,
        "recall": 0.154297,
        "f1": 0.119405,
        "accuracy": 0.154297,
        "main_score": 0.119405,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.027514,
        "recall": 0.052734,
        "f1": 0.031656,
        "accuracy": 0.052734,
        "main_score": 0.031656,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.029477,
        "recall": 0.052734,
        "f1": 0.034211,
        "accuracy": 0.052734,
        "main_score": 0.034211,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.082119,
        "recall": 0.120117,
        "f1": 0.092043,
        "accuracy": 0.120117,
        "main_score": 0.092043,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.041121,
        "recall": 0.066406,
        "f1": 0.046558,
        "accuracy": 0.066406,
        "main_score": 0.046558,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.034898,
        "recall": 0.061523,
        "f1": 0.040242,
        "accuracy": 0.061523,
        "main_score": 0.040242,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.040855,
        "recall": 0.069336,
        "f1": 0.045799,
        "accuracy": 0.069336,
        "main_score": 0.045799,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.018876,
        "recall": 0.038086,
        "f1": 0.022258,
        "accuracy": 0.038086,
        "main_score": 0.022258,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.085853,
        "recall": 0.135742,
        "f1": 0.098176,
        "accuracy": 0.135742,
        "main_score": 0.098176,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.075982,
        "recall": 0.113281,
        "f1": 0.084938,
        "accuracy": 0.113281,
        "main_score": 0.084938,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.055357,
        "recall": 0.091797,
        "f1": 0.063526,
        "accuracy": 0.091797,
        "main_score": 0.063526,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.048248,
        "recall": 0.086914,
        "f1": 0.056645,
        "accuracy": 0.086914,
        "main_score": 0.056645,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003212,
        "recall": 0.010742,
        "f1": 0.003876,
        "accuracy": 0.010742,
        "main_score": 0.003876,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.032933,
        "recall": 0.061523,
        "f1": 0.037976,
        "accuracy": 0.061523,
        "main_score": 0.037976,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.05274,
        "recall": 0.082031,
        "f1": 0.059389,
        "accuracy": 0.082031,
        "main_score": 0.059389,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.056753,
        "recall": 0.099609,
        "f1": 0.066347,
        "accuracy": 0.099609,
        "main_score": 0.066347,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.059305,
        "recall": 0.091797,
        "f1": 0.066453,
        "accuracy": 0.091797,
        "main_score": 0.066453,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.016119,
        "recall": 0.038086,
        "f1": 0.019671,
        "accuracy": 0.038086,
        "main_score": 0.019671,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.098543,
        "recall": 0.139648,
        "f1": 0.108703,
        "accuracy": 0.139648,
        "main_score": 0.108703,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.020838,
        "recall": 0.042969,
        "f1": 0.024689,
        "accuracy": 0.042969,
        "main_score": 0.024689,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.063533,
        "recall": 0.097656,
        "f1": 0.071915,
        "accuracy": 0.097656,
        "main_score": 0.071915,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.093622,
        "recall": 0.125977,
        "f1": 0.102589,
        "accuracy": 0.125977,
        "main_score": 0.102589,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.101469,
        "recall": 0.144531,
        "f1": 0.111669,
        "accuracy": 0.144531,
        "main_score": 0.111669,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.027545,
        "recall": 0.063477,
        "f1": 0.033538,
        "accuracy": 0.063477,
        "main_score": 0.033538,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.036621,
        "recall": 0.057617,
        "f1": 0.040662,
        "accuracy": 0.057617,
        "main_score": 0.040662,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.063639,
        "recall": 0.09668,
        "f1": 0.072194,
        "accuracy": 0.09668,
        "main_score": 0.072194,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.056816,
        "recall": 0.09668,
        "f1": 0.065442,
        "accuracy": 0.09668,
        "main_score": 0.065442,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.025432,
        "recall": 0.046875,
        "f1": 0.02947,
        "accuracy": 0.046875,
        "main_score": 0.02947,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.027634,
        "recall": 0.053711,
        "f1": 0.03198,
        "accuracy": 0.053711,
        "main_score": 0.03198,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.018816,
        "recall": 0.041016,
        "f1": 0.02212,
        "accuracy": 0.041016,
        "main_score": 0.02212,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.051185,
        "recall": 0.084961,
        "f1": 0.059789,
        "accuracy": 0.084961,
        "main_score": 0.059789,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.049593,
        "recall": 0.081055,
        "f1": 0.056822,
        "accuracy": 0.081055,
        "main_score": 0.056822,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.28139,
        "recall": 0.313477,
        "f1": 0.289782,
        "accuracy": 0.313477,
        "main_score": 0.289782,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.326928,
        "recall": 0.365234,
        "f1": 0.336387,
        "accuracy": 0.365234,
        "main_score": 0.336387,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.185452,
        "recall": 0.212891,
        "f1": 0.192024,
        "accuracy": 0.212891,
        "main_score": 0.192024,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.273418,
        "recall": 0.302734,
        "f1": 0.281038,
        "accuracy": 0.302734,
        "main_score": 0.281038,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.056107,
        "recall": 0.097656,
        "f1": 0.064265,
        "accuracy": 0.097656,
        "main_score": 0.064265,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.326414,
        "recall": 0.362305,
        "f1": 0.336189,
        "accuracy": 0.362305,
        "main_score": 0.336189,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.037335,
        "recall": 0.066406,
        "f1": 0.043363,
        "accuracy": 0.066406,
        "main_score": 0.043363,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.247295,
        "recall": 0.283203,
        "f1": 0.256934,
        "accuracy": 0.283203,
        "main_score": 0.256934,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.070495,
        "recall": 0.113281,
        "f1": 0.080821,
        "accuracy": 0.113281,
        "main_score": 0.080821,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.161966,
        "recall": 0.202148,
        "f1": 0.171451,
        "accuracy": 0.202148,
        "main_score": 0.171451,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.03928,
        "recall": 0.0625,
        "f1": 0.044137,
        "accuracy": 0.0625,
        "main_score": 0.044137,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.054206,
        "recall": 0.084961,
        "f1": 0.061267,
        "accuracy": 0.084961,
        "main_score": 0.061267,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.051325,
        "recall": 0.083008,
        "f1": 0.059155,
        "accuracy": 0.083008,
        "main_score": 0.059155,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.060424,
        "recall": 0.089844,
        "f1": 0.06769,
        "accuracy": 0.089844,
        "main_score": 0.06769,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.01772,
        "recall": 0.036133,
        "f1": 0.021274,
        "accuracy": 0.036133,
        "main_score": 0.021274,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.0427,
        "recall": 0.071289,
        "f1": 0.048881,
        "accuracy": 0.071289,
        "main_score": 0.048881,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.323595,
        "recall": 0.360352,
        "f1": 0.333438,
        "accuracy": 0.360352,
        "main_score": 0.333438,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.18221,
        "recall": 0.22168,
        "f1": 0.192024,
        "accuracy": 0.22168,
        "main_score": 0.192024,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.213814,
        "recall": 0.249023,
        "f1": 0.222857,
        "accuracy": 0.249023,
        "main_score": 0.222857,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.287622,
        "recall": 0.316406,
        "f1": 0.294658,
        "accuracy": 0.316406,
        "main_score": 0.294658,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.028434,
        "recall": 0.046875,
        "f1": 0.032175,
        "accuracy": 0.046875,
        "main_score": 0.032175,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.032784,
        "recall": 0.054688,
        "f1": 0.036705,
        "accuracy": 0.054688,
        "main_score": 0.036705,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.011445,
        "recall": 0.030273,
        "f1": 0.014018,
        "accuracy": 0.030273,
        "main_score": 0.014018,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.014665,
        "recall": 0.032227,
        "f1": 0.017839,
        "accuracy": 0.032227,
        "main_score": 0.017839,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001832,
        "recall": 0.005859,
        "f1": 0.002197,
        "accuracy": 0.005859,
        "main_score": 0.002197,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014423,
        "recall": 0.029297,
        "f1": 0.016375,
        "accuracy": 0.029297,
        "main_score": 0.016375,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.018529,
        "recall": 0.041016,
        "f1": 0.022532,
        "accuracy": 0.041016,
        "main_score": 0.022532,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.008411,
        "recall": 0.029297,
        "f1": 0.011378,
        "accuracy": 0.029297,
        "main_score": 0.011378,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.033895,
        "recall": 0.051758,
        "f1": 0.037103,
        "accuracy": 0.051758,
        "main_score": 0.037103,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.005316,
        "recall": 0.014648,
        "f1": 0.006447,
        "accuracy": 0.014648,
        "main_score": 0.006447,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.02762,
        "recall": 0.046875,
        "f1": 0.031573,
        "accuracy": 0.046875,
        "main_score": 0.031573,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.014313,
        "recall": 0.024414,
        "f1": 0.015816,
        "accuracy": 0.024414,
        "main_score": 0.015816,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.029847,
        "recall": 0.049805,
        "f1": 0.032934,
        "accuracy": 0.049805,
        "main_score": 0.032934,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.03509,
        "recall": 0.057617,
        "f1": 0.039524,
        "accuracy": 0.057617,
        "main_score": 0.039524,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.035938,
        "recall": 0.058594,
        "f1": 0.040013,
        "accuracy": 0.058594,
        "main_score": 0.040013,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.038296,
        "recall": 0.066406,
        "f1": 0.042828,
        "accuracy": 0.066406,
        "main_score": 0.042828,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.007126,
        "recall": 0.017578,
        "f1": 0.008508,
        "accuracy": 0.017578,
        "main_score": 0.008508,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.038433,
        "recall": 0.071289,
        "f1": 0.044707,
        "accuracy": 0.071289,
        "main_score": 0.044707,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.01327,
        "recall": 0.03125,
        "f1": 0.016012,
        "accuracy": 0.03125,
        "main_score": 0.016012,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.014028,
        "recall": 0.024414,
        "f1": 0.015642,
        "accuracy": 0.024414,
        "main_score": 0.015642,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.01243,
        "recall": 0.023438,
        "f1": 0.014131,
        "accuracy": 0.023438,
        "main_score": 0.014131,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.005686,
        "recall": 0.013672,
        "f1": 0.006995,
        "accuracy": 0.013672,
        "main_score": 0.006995,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.036997,
        "recall": 0.076172,
        "f1": 0.045041,
        "accuracy": 0.076172,
        "main_score": 0.045041,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.083817,
        "recall": 0.126953,
        "f1": 0.093862,
        "accuracy": 0.126953,
        "main_score": 0.093862,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.022032,
        "recall": 0.053711,
        "f1": 0.027632,
        "accuracy": 0.053711,
        "main_score": 0.027632,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.032941,
        "recall": 0.074219,
        "f1": 0.041231,
        "accuracy": 0.074219,
        "main_score": 0.041231,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.004347,
        "recall": 0.008789,
        "f1": 0.00467,
        "accuracy": 0.008789,
        "main_score": 0.00467,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021368,
        "recall": 0.044922,
        "f1": 0.025724,
        "accuracy": 0.044922,
        "main_score": 0.025724,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.043637,
        "recall": 0.070312,
        "f1": 0.048394,
        "accuracy": 0.070312,
        "main_score": 0.048394,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.036329,
        "recall": 0.077148,
        "f1": 0.044689,
        "accuracy": 0.077148,
        "main_score": 0.044689,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.035844,
        "recall": 0.05957,
        "f1": 0.040004,
        "accuracy": 0.05957,
        "main_score": 0.040004,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.01597,
        "recall": 0.035156,
        "f1": 0.019275,
        "accuracy": 0.035156,
        "main_score": 0.019275,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.067687,
        "recall": 0.105469,
        "f1": 0.077188,
        "accuracy": 0.105469,
        "main_score": 0.077188,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.009715,
        "recall": 0.023438,
        "f1": 0.011727,
        "accuracy": 0.023438,
        "main_score": 0.011727,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.043743,
        "recall": 0.064453,
        "f1": 0.04797,
        "accuracy": 0.064453,
        "main_score": 0.04797,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.045543,
        "recall": 0.082031,
        "f1": 0.054098,
        "accuracy": 0.082031,
        "main_score": 0.054098,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.062823,
        "recall": 0.102539,
        "f1": 0.072602,
        "accuracy": 0.102539,
        "main_score": 0.072602,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.04483,
        "recall": 0.076172,
        "f1": 0.051324,
        "accuracy": 0.076172,
        "main_score": 0.051324,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.015797,
        "recall": 0.043945,
        "f1": 0.019857,
        "accuracy": 0.043945,
        "main_score": 0.019857,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.014875,
        "recall": 0.027344,
        "f1": 0.016204,
        "accuracy": 0.027344,
        "main_score": 0.016204,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.02694,
        "recall": 0.056641,
        "f1": 0.03326,
        "accuracy": 0.056641,
        "main_score": 0.03326,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.018994,
        "recall": 0.042969,
        "f1": 0.022938,
        "accuracy": 0.042969,
        "main_score": 0.022938,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.015607,
        "recall": 0.039062,
        "f1": 0.019744,
        "accuracy": 0.039062,
        "main_score": 0.019744,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.015524,
        "recall": 0.030273,
        "f1": 0.018603,
        "accuracy": 0.030273,
        "main_score": 0.018603,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.045619,
        "recall": 0.075195,
        "f1": 0.052365,
        "accuracy": 0.075195,
        "main_score": 0.052365,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.056885,
        "recall": 0.084961,
        "f1": 0.063596,
        "accuracy": 0.084961,
        "main_score": 0.063596,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.286438,
        "recall": 0.320312,
        "f1": 0.295178,
        "accuracy": 0.320312,
        "main_score": 0.295178,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.330016,
        "recall": 0.376953,
        "f1": 0.343242,
        "accuracy": 0.376953,
        "main_score": 0.343242,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.183915,
        "recall": 0.208984,
        "f1": 0.190071,
        "accuracy": 0.208984,
        "main_score": 0.190071,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.285393,
        "recall": 0.3125,
        "f1": 0.292921,
        "accuracy": 0.3125,
        "main_score": 0.292921,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.079906,
        "recall": 0.125,
        "f1": 0.089709,
        "accuracy": 0.125,
        "main_score": 0.089709,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.390699,
        "recall": 0.436523,
        "f1": 0.403106,
        "accuracy": 0.436523,
        "main_score": 0.403106,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.057227,
        "recall": 0.083984,
        "f1": 0.063018,
        "accuracy": 0.083984,
        "main_score": 0.063018,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.258941,
        "recall": 0.288086,
        "f1": 0.26679,
        "accuracy": 0.288086,
        "main_score": 0.26679,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.084295,
        "recall": 0.120117,
        "f1": 0.093644,
        "accuracy": 0.120117,
        "main_score": 0.093644,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.160274,
        "recall": 0.198242,
        "f1": 0.169722,
        "accuracy": 0.198242,
        "main_score": 0.169722,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.053109,
        "recall": 0.083008,
        "f1": 0.059632,
        "accuracy": 0.083008,
        "main_score": 0.059632,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.073505,
        "recall": 0.107422,
        "f1": 0.081934,
        "accuracy": 0.107422,
        "main_score": 0.081934,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.065702,
        "recall": 0.09668,
        "f1": 0.073723,
        "accuracy": 0.09668,
        "main_score": 0.073723,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.0755,
        "recall": 0.112305,
        "f1": 0.084592,
        "accuracy": 0.112305,
        "main_score": 0.084592,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.291278,
        "recall": 0.331055,
        "f1": 0.300946,
        "accuracy": 0.331055,
        "main_score": 0.300946,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.020716,
        "recall": 0.036133,
        "f1": 0.023232,
        "accuracy": 0.036133,
        "main_score": 0.023232,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.058212,
        "recall": 0.088867,
        "f1": 0.065569,
        "accuracy": 0.088867,
        "main_score": 0.065569,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.175046,
        "recall": 0.21582,
        "f1": 0.18538,
        "accuracy": 0.21582,
        "main_score": 0.18538,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.216347,
        "recall": 0.258789,
        "f1": 0.227646,
        "accuracy": 0.258789,
        "main_score": 0.227646,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.307426,
        "recall": 0.329102,
        "f1": 0.312454,
        "accuracy": 0.329102,
        "main_score": 0.312454,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.041558,
        "recall": 0.069336,
        "f1": 0.04757,
        "accuracy": 0.069336,
        "main_score": 0.04757,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.046069,
        "recall": 0.073242,
        "f1": 0.05216,
        "accuracy": 0.073242,
        "main_score": 0.05216,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.203817,
        "recall": 0.233398,
        "f1": 0.210351,
        "accuracy": 0.233398,
        "main_score": 0.210351,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.195384,
        "recall": 0.22168,
        "f1": 0.201456,
        "accuracy": 0.22168,
        "main_score": 0.201456,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.150758,
        "recall": 0.168945,
        "f1": 0.154706,
        "accuracy": 0.168945,
        "main_score": 0.154706,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.22533,
        "recall": 0.271484,
        "f1": 0.236811,
        "accuracy": 0.271484,
        "main_score": 0.236811,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.06641,
        "recall": 0.114258,
        "f1": 0.077365,
        "accuracy": 0.114258,
        "main_score": 0.077365,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.196601,
        "recall": 0.230469,
        "f1": 0.205027,
        "accuracy": 0.230469,
        "main_score": 0.205027,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.090283,
        "recall": 0.132812,
        "f1": 0.101289,
        "accuracy": 0.132812,
        "main_score": 0.101289,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.174296,
        "recall": 0.201172,
        "f1": 0.181386,
        "accuracy": 0.201172,
        "main_score": 0.181386,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.047246,
        "recall": 0.082031,
        "f1": 0.055457,
        "accuracy": 0.082031,
        "main_score": 0.055457,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.20115,
        "recall": 0.235352,
        "f1": 0.210779,
        "accuracy": 0.235352,
        "main_score": 0.210779,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.062469,
        "recall": 0.095703,
        "f1": 0.071248,
        "accuracy": 0.095703,
        "main_score": 0.071248,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.036254,
        "recall": 0.0625,
        "f1": 0.041626,
        "accuracy": 0.0625,
        "main_score": 0.041626,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.050291,
        "recall": 0.086914,
        "f1": 0.05879,
        "accuracy": 0.086914,
        "main_score": 0.05879,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.051974,
        "recall": 0.078125,
        "f1": 0.057915,
        "accuracy": 0.078125,
        "main_score": 0.057915,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.189653,
        "recall": 0.216797,
        "f1": 0.196107,
        "accuracy": 0.216797,
        "main_score": 0.196107,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.02099,
        "recall": 0.045898,
        "f1": 0.024964,
        "accuracy": 0.045898,
        "main_score": 0.024964,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.038997,
        "recall": 0.073242,
        "f1": 0.046677,
        "accuracy": 0.073242,
        "main_score": 0.046677,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.192817,
        "recall": 0.217773,
        "f1": 0.198861,
        "accuracy": 0.217773,
        "main_score": 0.198861,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.245001,
        "recall": 0.288086,
        "f1": 0.25608,
        "accuracy": 0.288086,
        "main_score": 0.25608,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.191112,
        "recall": 0.213867,
        "f1": 0.196427,
        "accuracy": 0.213867,
        "main_score": 0.196427,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.03761,
        "recall": 0.070312,
        "f1": 0.045062,
        "accuracy": 0.070312,
        "main_score": 0.045062,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.049534,
        "recall": 0.082031,
        "f1": 0.057113,
        "accuracy": 0.082031,
        "main_score": 0.057113,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.234375,
        "recall": 0.277344,
        "f1": 0.244578,
        "accuracy": 0.277344,
        "main_score": 0.244578,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.239541,
        "recall": 0.269531,
        "f1": 0.247008,
        "accuracy": 0.269531,
        "main_score": 0.247008,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.162756,
        "recall": 0.183594,
        "f1": 0.16776,
        "accuracy": 0.183594,
        "main_score": 0.16776,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.268736,
        "recall": 0.316406,
        "f1": 0.282013,
        "accuracy": 0.316406,
        "main_score": 0.282013,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.08676,
        "recall": 0.143555,
        "f1": 0.09938,
        "accuracy": 0.143555,
        "main_score": 0.09938,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.242991,
        "recall": 0.274414,
        "f1": 0.250559,
        "accuracy": 0.274414,
        "main_score": 0.250559,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.110596,
        "recall": 0.15625,
        "f1": 0.123503,
        "accuracy": 0.15625,
        "main_score": 0.123503,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.199765,
        "recall": 0.227539,
        "f1": 0.207503,
        "accuracy": 0.227539,
        "main_score": 0.207503,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.05873,
        "recall": 0.095703,
        "f1": 0.067391,
        "accuracy": 0.095703,
        "main_score": 0.067391,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.197835,
        "recall": 0.237305,
        "f1": 0.208696,
        "accuracy": 0.237305,
        "main_score": 0.208696,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.080876,
        "recall": 0.121094,
        "f1": 0.092076,
        "accuracy": 0.121094,
        "main_score": 0.092076,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.059011,
        "recall": 0.09082,
        "f1": 0.066171,
        "accuracy": 0.09082,
        "main_score": 0.066171,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.066805,
        "recall": 0.107422,
        "f1": 0.076591,
        "accuracy": 0.107422,
        "main_score": 0.076591,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.062981,
        "recall": 0.101562,
        "f1": 0.072655,
        "accuracy": 0.101562,
        "main_score": 0.072655,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.221322,
        "recall": 0.248047,
        "f1": 0.227715,
        "accuracy": 0.248047,
        "main_score": 0.227715,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.023256,
        "recall": 0.050781,
        "f1": 0.027903,
        "accuracy": 0.050781,
        "main_score": 0.027903,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.041012,
        "recall": 0.072266,
        "f1": 0.048614,
        "accuracy": 0.072266,
        "main_score": 0.048614,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.233664,
        "recall": 0.266602,
        "f1": 0.241365,
        "accuracy": 0.266602,
        "main_score": 0.241365,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.24117,
        "recall": 0.288086,
        "f1": 0.254032,
        "accuracy": 0.288086,
        "main_score": 0.254032,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.221255,
        "recall": 0.244141,
        "f1": 0.226566,
        "accuracy": 0.244141,
        "main_score": 0.226566,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.019392,
        "recall": 0.036133,
        "f1": 0.022311,
        "accuracy": 0.036133,
        "main_score": 0.022311,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.019749,
        "recall": 0.038086,
        "f1": 0.022806,
        "accuracy": 0.038086,
        "main_score": 0.022806,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.241616,
        "recall": 0.266602,
        "f1": 0.247396,
        "accuracy": 0.266602,
        "main_score": 0.247396,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.261664,
        "recall": 0.290039,
        "f1": 0.267662,
        "accuracy": 0.290039,
        "main_score": 0.267662,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.163327,
        "recall": 0.1875,
        "f1": 0.169243,
        "accuracy": 0.1875,
        "main_score": 0.169243,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.228239,
        "recall": 0.254883,
        "f1": 0.234576,
        "accuracy": 0.254883,
        "main_score": 0.234576,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.02857,
        "recall": 0.056641,
        "f1": 0.033467,
        "accuracy": 0.056641,
        "main_score": 0.033467,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.270473,
        "recall": 0.297852,
        "f1": 0.277214,
        "accuracy": 0.297852,
        "main_score": 0.277214,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015693,
        "recall": 0.029297,
        "f1": 0.018326,
        "accuracy": 0.029297,
        "main_score": 0.018326,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.268187,
        "recall": 0.303711,
        "f1": 0.278233,
        "accuracy": 0.303711,
        "main_score": 0.278233,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.019258,
        "recall": 0.041016,
        "f1": 0.023014,
        "accuracy": 0.041016,
        "main_score": 0.023014,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.154539,
        "recall": 0.194336,
        "f1": 0.163902,
        "accuracy": 0.194336,
        "main_score": 0.163902,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.019652,
        "recall": 0.037109,
        "f1": 0.022859,
        "accuracy": 0.037109,
        "main_score": 0.022859,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.020811,
        "recall": 0.037109,
        "f1": 0.023594,
        "accuracy": 0.037109,
        "main_score": 0.023594,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.026219,
        "recall": 0.042969,
        "f1": 0.028974,
        "accuracy": 0.042969,
        "main_score": 0.028974,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.015249,
        "recall": 0.030273,
        "f1": 0.017823,
        "accuracy": 0.030273,
        "main_score": 0.017823,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.251052,
        "recall": 0.274414,
        "f1": 0.256263,
        "accuracy": 0.274414,
        "main_score": 0.256263,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.005365,
        "recall": 0.011719,
        "f1": 0.00616,
        "accuracy": 0.011719,
        "main_score": 0.00616,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.014809,
        "recall": 0.030273,
        "f1": 0.017496,
        "accuracy": 0.030273,
        "main_score": 0.017496,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.259672,
        "recall": 0.288086,
        "f1": 0.265301,
        "accuracy": 0.288086,
        "main_score": 0.265301,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.155499,
        "recall": 0.197266,
        "f1": 0.165555,
        "accuracy": 0.197266,
        "main_score": 0.165555,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.197634,
        "recall": 0.232422,
        "f1": 0.205893,
        "accuracy": 0.232422,
        "main_score": 0.205893,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 29.435643196105957,
  "kg_co2_emissions": 0.0011047768174317107
}