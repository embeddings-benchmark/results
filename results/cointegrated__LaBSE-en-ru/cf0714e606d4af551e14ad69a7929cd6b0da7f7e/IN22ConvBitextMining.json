{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "task_name": "IN22ConvBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.032668,
        "recall": 0.057219,
        "f1": 0.037432,
        "accuracy": 0.057219,
        "main_score": 0.037432,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.025448,
        "recall": 0.042582,
        "f1": 0.029022,
        "accuracy": 0.042582,
        "main_score": 0.029022,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.02358,
        "recall": 0.037259,
        "f1": 0.026533,
        "accuracy": 0.037259,
        "main_score": 0.026533,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.004575,
        "recall": 0.008649,
        "f1": 0.005094,
        "accuracy": 0.008649,
        "main_score": 0.005094,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01825,
        "recall": 0.037259,
        "f1": 0.021005,
        "accuracy": 0.037259,
        "main_score": 0.021005,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.018094,
        "recall": 0.036593,
        "f1": 0.021102,
        "accuracy": 0.036593,
        "main_score": 0.021102,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.028911,
        "recall": 0.04857,
        "f1": 0.032569,
        "accuracy": 0.04857,
        "main_score": 0.032569,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015888,
        "recall": 0.029275,
        "f1": 0.018094,
        "accuracy": 0.029275,
        "main_score": 0.018094,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.00378,
        "recall": 0.011976,
        "f1": 0.004949,
        "accuracy": 0.011976,
        "main_score": 0.004949,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.024621,
        "recall": 0.041916,
        "f1": 0.02821,
        "accuracy": 0.041916,
        "main_score": 0.02821,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.007946,
        "recall": 0.017299,
        "f1": 0.009281,
        "accuracy": 0.017299,
        "main_score": 0.009281,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.018121,
        "recall": 0.034597,
        "f1": 0.020936,
        "accuracy": 0.034597,
        "main_score": 0.020936,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.02545,
        "recall": 0.045908,
        "f1": 0.029738,
        "accuracy": 0.045908,
        "main_score": 0.029738,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.031701,
        "recall": 0.054558,
        "f1": 0.036338,
        "accuracy": 0.054558,
        "main_score": 0.036338,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.0292,
        "recall": 0.04857,
        "f1": 0.033339,
        "accuracy": 0.04857,
        "main_score": 0.033339,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.023449,
        "recall": 0.041916,
        "f1": 0.027292,
        "accuracy": 0.041916,
        "main_score": 0.027292,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.018582,
        "recall": 0.036593,
        "f1": 0.021735,
        "accuracy": 0.036593,
        "main_score": 0.021735,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.028966,
        "recall": 0.042582,
        "f1": 0.031598,
        "accuracy": 0.042582,
        "main_score": 0.031598,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.011847,
        "recall": 0.027944,
        "f1": 0.014761,
        "accuracy": 0.027944,
        "main_score": 0.014761,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.004798,
        "recall": 0.016633,
        "f1": 0.005838,
        "accuracy": 0.016633,
        "main_score": 0.005838,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009101,
        "recall": 0.020625,
        "f1": 0.01051,
        "accuracy": 0.020625,
        "main_score": 0.01051,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.005553,
        "recall": 0.013972,
        "f1": 0.006612,
        "accuracy": 0.013972,
        "main_score": 0.006612,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.032178,
        "recall": 0.057219,
        "f1": 0.037854,
        "accuracy": 0.057219,
        "main_score": 0.037854,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.017929,
        "recall": 0.036593,
        "f1": 0.021184,
        "accuracy": 0.036593,
        "main_score": 0.021184,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.020922,
        "recall": 0.038589,
        "f1": 0.024618,
        "accuracy": 0.038589,
        "main_score": 0.024618,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003488,
        "recall": 0.006653,
        "f1": 0.003825,
        "accuracy": 0.006653,
        "main_score": 0.003825,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020005,
        "recall": 0.038589,
        "f1": 0.023333,
        "accuracy": 0.038589,
        "main_score": 0.023333,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.017864,
        "recall": 0.036593,
        "f1": 0.021592,
        "accuracy": 0.036593,
        "main_score": 0.021592,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.031901,
        "recall": 0.047904,
        "f1": 0.035348,
        "accuracy": 0.047904,
        "main_score": 0.035348,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015191,
        "recall": 0.026613,
        "f1": 0.01748,
        "accuracy": 0.026613,
        "main_score": 0.01748,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006431,
        "recall": 0.013307,
        "f1": 0.007287,
        "accuracy": 0.013307,
        "main_score": 0.007287,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.023186,
        "recall": 0.041251,
        "f1": 0.027169,
        "accuracy": 0.041251,
        "main_score": 0.027169,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.009949,
        "recall": 0.022621,
        "f1": 0.011995,
        "accuracy": 0.022621,
        "main_score": 0.011995,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.018643,
        "recall": 0.038589,
        "f1": 0.02226,
        "accuracy": 0.038589,
        "main_score": 0.02226,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.02782,
        "recall": 0.046574,
        "f1": 0.031608,
        "accuracy": 0.046574,
        "main_score": 0.031608,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.037552,
        "recall": 0.062542,
        "f1": 0.042878,
        "accuracy": 0.062542,
        "main_score": 0.042878,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.03092,
        "recall": 0.052562,
        "f1": 0.034846,
        "accuracy": 0.052562,
        "main_score": 0.034846,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.02233,
        "recall": 0.040585,
        "f1": 0.02597,
        "accuracy": 0.040585,
        "main_score": 0.02597,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.017111,
        "recall": 0.032601,
        "f1": 0.019931,
        "accuracy": 0.032601,
        "main_score": 0.019931,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.028346,
        "recall": 0.047239,
        "f1": 0.031782,
        "accuracy": 0.047239,
        "main_score": 0.031782,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.017435,
        "recall": 0.033267,
        "f1": 0.020663,
        "accuracy": 0.033267,
        "main_score": 0.020663,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.006123,
        "recall": 0.017964,
        "f1": 0.007862,
        "accuracy": 0.017964,
        "main_score": 0.007862,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.011313,
        "recall": 0.024617,
        "f1": 0.013386,
        "accuracy": 0.024617,
        "main_score": 0.013386,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007011,
        "recall": 0.014637,
        "f1": 0.008062,
        "accuracy": 0.014637,
        "main_score": 0.008062,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.031169,
        "recall": 0.053227,
        "f1": 0.03558,
        "accuracy": 0.053227,
        "main_score": 0.03558,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.022485,
        "recall": 0.038589,
        "f1": 0.02539,
        "accuracy": 0.038589,
        "main_score": 0.02539,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.044443,
        "recall": 0.05988,
        "f1": 0.047951,
        "accuracy": 0.05988,
        "main_score": 0.047951,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.025184,
        "recall": 0.032601,
        "f1": 0.026629,
        "accuracy": 0.032601,
        "main_score": 0.026629,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.046456,
        "recall": 0.065203,
        "f1": 0.049974,
        "accuracy": 0.065203,
        "main_score": 0.049974,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.026411,
        "recall": 0.045908,
        "f1": 0.030072,
        "accuracy": 0.045908,
        "main_score": 0.030072,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.053779,
        "recall": 0.069195,
        "f1": 0.057209,
        "accuracy": 0.069195,
        "main_score": 0.057209,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016406,
        "recall": 0.026613,
        "f1": 0.018359,
        "accuracy": 0.026613,
        "main_score": 0.018359,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.025655,
        "recall": 0.035928,
        "f1": 0.027403,
        "accuracy": 0.035928,
        "main_score": 0.027403,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.017298,
        "recall": 0.029275,
        "f1": 0.019799,
        "accuracy": 0.029275,
        "main_score": 0.019799,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.031999,
        "recall": 0.045908,
        "f1": 0.034252,
        "accuracy": 0.045908,
        "main_score": 0.034252,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.017168,
        "recall": 0.033932,
        "f1": 0.019731,
        "accuracy": 0.033932,
        "main_score": 0.019731,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.023485,
        "recall": 0.041916,
        "f1": 0.027238,
        "accuracy": 0.041916,
        "main_score": 0.027238,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.026273,
        "recall": 0.045243,
        "f1": 0.029765,
        "accuracy": 0.045243,
        "main_score": 0.029765,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.024846,
        "recall": 0.03992,
        "f1": 0.027461,
        "accuracy": 0.03992,
        "main_score": 0.027461,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.049921,
        "recall": 0.063207,
        "f1": 0.05255,
        "accuracy": 0.063207,
        "main_score": 0.05255,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.015533,
        "recall": 0.032601,
        "f1": 0.018743,
        "accuracy": 0.032601,
        "main_score": 0.018743,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.013307,
        "recall": 0.025283,
        "f1": 0.015496,
        "accuracy": 0.025283,
        "main_score": 0.015496,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.042393,
        "recall": 0.056554,
        "f1": 0.045508,
        "accuracy": 0.056554,
        "main_score": 0.045508,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.029859,
        "recall": 0.040585,
        "f1": 0.031557,
        "accuracy": 0.040585,
        "main_score": 0.031557,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.037166,
        "recall": 0.050566,
        "f1": 0.03959,
        "accuracy": 0.050566,
        "main_score": 0.03959,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.036682,
        "recall": 0.045243,
        "f1": 0.038051,
        "accuracy": 0.045243,
        "main_score": 0.038051,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.023599,
        "recall": 0.043247,
        "f1": 0.027664,
        "accuracy": 0.043247,
        "main_score": 0.027664,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.023792,
        "recall": 0.044578,
        "f1": 0.027982,
        "accuracy": 0.044578,
        "main_score": 0.027982,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.043976,
        "recall": 0.061876,
        "f1": 0.04781,
        "accuracy": 0.061876,
        "main_score": 0.04781,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.029162,
        "recall": 0.035263,
        "f1": 0.030558,
        "accuracy": 0.035263,
        "main_score": 0.030558,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.048488,
        "recall": 0.067864,
        "f1": 0.05146,
        "accuracy": 0.067864,
        "main_score": 0.05146,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.033254,
        "recall": 0.055223,
        "f1": 0.037709,
        "accuracy": 0.055223,
        "main_score": 0.037709,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.086259,
        "recall": 0.119095,
        "f1": 0.093697,
        "accuracy": 0.119095,
        "main_score": 0.093697,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.01393,
        "recall": 0.027279,
        "f1": 0.015949,
        "accuracy": 0.027279,
        "main_score": 0.015949,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.033685,
        "recall": 0.047239,
        "f1": 0.036333,
        "accuracy": 0.047239,
        "main_score": 0.036333,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.032071,
        "recall": 0.063872,
        "f1": 0.038208,
        "accuracy": 0.063872,
        "main_score": 0.038208,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.031224,
        "recall": 0.043912,
        "f1": 0.03354,
        "accuracy": 0.043912,
        "main_score": 0.03354,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.021628,
        "recall": 0.037924,
        "f1": 0.024116,
        "accuracy": 0.037924,
        "main_score": 0.024116,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.023586,
        "recall": 0.039255,
        "f1": 0.026963,
        "accuracy": 0.039255,
        "main_score": 0.026963,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.030281,
        "recall": 0.051231,
        "f1": 0.034798,
        "accuracy": 0.051231,
        "main_score": 0.034798,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.02853,
        "recall": 0.046574,
        "f1": 0.032488,
        "accuracy": 0.046574,
        "main_score": 0.032488,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.077116,
        "recall": 0.10845,
        "f1": 0.083643,
        "accuracy": 0.10845,
        "main_score": 0.083643,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.013138,
        "recall": 0.024617,
        "f1": 0.015261,
        "accuracy": 0.024617,
        "main_score": 0.015261,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.035779,
        "recall": 0.055888,
        "f1": 0.040568,
        "accuracy": 0.055888,
        "main_score": 0.040568,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.056874,
        "recall": 0.083167,
        "f1": 0.062321,
        "accuracy": 0.083167,
        "main_score": 0.062321,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.030444,
        "recall": 0.042582,
        "f1": 0.032258,
        "accuracy": 0.042582,
        "main_score": 0.032258,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.036267,
        "recall": 0.04857,
        "f1": 0.038138,
        "accuracy": 0.04857,
        "main_score": 0.038138,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.046419,
        "recall": 0.05855,
        "f1": 0.048193,
        "accuracy": 0.05855,
        "main_score": 0.048193,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.00124,
        "recall": 0.007984,
        "f1": 0.001874,
        "accuracy": 0.007984,
        "main_score": 0.001874,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.001592,
        "recall": 0.006653,
        "f1": 0.001815,
        "accuracy": 0.006653,
        "main_score": 0.001815,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.011622,
        "recall": 0.036593,
        "f1": 0.015108,
        "accuracy": 0.036593,
        "main_score": 0.015108,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.010573,
        "recall": 0.041916,
        "f1": 0.014407,
        "accuracy": 0.041916,
        "main_score": 0.014407,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.011074,
        "recall": 0.043247,
        "f1": 0.015636,
        "accuracy": 0.043247,
        "main_score": 0.015636,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.003082,
        "recall": 0.019295,
        "f1": 0.004336,
        "accuracy": 0.019295,
        "main_score": 0.004336,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.012713,
        "recall": 0.043247,
        "f1": 0.016482,
        "accuracy": 0.043247,
        "main_score": 0.016482,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00109,
        "recall": 0.006653,
        "f1": 0.001605,
        "accuracy": 0.006653,
        "main_score": 0.001605,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004942,
        "recall": 0.033932,
        "f1": 0.007766,
        "accuracy": 0.033932,
        "main_score": 0.007766,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.000776,
        "recall": 0.005323,
        "f1": 0.001201,
        "accuracy": 0.005323,
        "main_score": 0.001201,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.005318,
        "recall": 0.032601,
        "f1": 0.007911,
        "accuracy": 0.032601,
        "main_score": 0.007911,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001189,
        "recall": 0.009315,
        "f1": 0.001815,
        "accuracy": 0.009315,
        "main_score": 0.001815,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001108,
        "recall": 0.006653,
        "f1": 0.00141,
        "accuracy": 0.006653,
        "main_score": 0.00141,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.002316,
        "recall": 0.007984,
        "f1": 0.002799,
        "accuracy": 0.007984,
        "main_score": 0.002799,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.000213,
        "recall": 0.004657,
        "f1": 0.000393,
        "accuracy": 0.004657,
        "main_score": 0.000393,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.012711,
        "recall": 0.045908,
        "f1": 0.017608,
        "accuracy": 0.045908,
        "main_score": 0.017608,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000986,
        "recall": 0.007984,
        "f1": 0.001248,
        "accuracy": 0.007984,
        "main_score": 0.001248,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001223,
        "recall": 0.009315,
        "f1": 0.001662,
        "accuracy": 0.009315,
        "main_score": 0.001662,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.008832,
        "recall": 0.037259,
        "f1": 0.012827,
        "accuracy": 0.037259,
        "main_score": 0.012827,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.007022,
        "recall": 0.035928,
        "f1": 0.010354,
        "accuracy": 0.035928,
        "main_score": 0.010354,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.007646,
        "recall": 0.038589,
        "f1": 0.01138,
        "accuracy": 0.038589,
        "main_score": 0.01138,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.010211,
        "recall": 0.038589,
        "f1": 0.013478,
        "accuracy": 0.038589,
        "main_score": 0.013478,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.022543,
        "recall": 0.037259,
        "f1": 0.0254,
        "accuracy": 0.037259,
        "main_score": 0.0254,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.026156,
        "recall": 0.043247,
        "f1": 0.029858,
        "accuracy": 0.043247,
        "main_score": 0.029858,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.048461,
        "recall": 0.06853,
        "f1": 0.052608,
        "accuracy": 0.06853,
        "main_score": 0.052608,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.0496,
        "recall": 0.064538,
        "f1": 0.052876,
        "accuracy": 0.064538,
        "main_score": 0.052876,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.027805,
        "recall": 0.035263,
        "f1": 0.029529,
        "accuracy": 0.035263,
        "main_score": 0.029529,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.042783,
        "recall": 0.067864,
        "f1": 0.048063,
        "accuracy": 0.067864,
        "main_score": 0.048063,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.052472,
        "recall": 0.067864,
        "f1": 0.05563,
        "accuracy": 0.067864,
        "main_score": 0.05563,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.033094,
        "recall": 0.052562,
        "f1": 0.036822,
        "accuracy": 0.052562,
        "main_score": 0.036822,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.027739,
        "recall": 0.038589,
        "f1": 0.029992,
        "accuracy": 0.038589,
        "main_score": 0.029992,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.01603,
        "recall": 0.028609,
        "f1": 0.018662,
        "accuracy": 0.028609,
        "main_score": 0.018662,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.043985,
        "recall": 0.061876,
        "f1": 0.048001,
        "accuracy": 0.061876,
        "main_score": 0.048001,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.033945,
        "recall": 0.054558,
        "f1": 0.038182,
        "accuracy": 0.054558,
        "main_score": 0.038182,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.027127,
        "recall": 0.043247,
        "f1": 0.030395,
        "accuracy": 0.043247,
        "main_score": 0.030395,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.036062,
        "recall": 0.057219,
        "f1": 0.040098,
        "accuracy": 0.057219,
        "main_score": 0.040098,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.024543,
        "recall": 0.041251,
        "f1": 0.027723,
        "accuracy": 0.041251,
        "main_score": 0.027723,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.057489,
        "recall": 0.070526,
        "f1": 0.059891,
        "accuracy": 0.070526,
        "main_score": 0.059891,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.02193,
        "recall": 0.037259,
        "f1": 0.024716,
        "accuracy": 0.037259,
        "main_score": 0.024716,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.017743,
        "recall": 0.032601,
        "f1": 0.020834,
        "accuracy": 0.032601,
        "main_score": 0.020834,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.042405,
        "recall": 0.052562,
        "f1": 0.044804,
        "accuracy": 0.052562,
        "main_score": 0.044804,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.043441,
        "recall": 0.067864,
        "f1": 0.04807,
        "accuracy": 0.067864,
        "main_score": 0.04807,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.055982,
        "recall": 0.07984,
        "f1": 0.060838,
        "accuracy": 0.07984,
        "main_score": 0.060838,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.040864,
        "recall": 0.047904,
        "f1": 0.042245,
        "accuracy": 0.047904,
        "main_score": 0.042245,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.020287,
        "recall": 0.042582,
        "f1": 0.024403,
        "accuracy": 0.042582,
        "main_score": 0.024403,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.024413,
        "recall": 0.046574,
        "f1": 0.028847,
        "accuracy": 0.046574,
        "main_score": 0.028847,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.027015,
        "recall": 0.044578,
        "f1": 0.029956,
        "accuracy": 0.044578,
        "main_score": 0.029956,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.039241,
        "recall": 0.052562,
        "f1": 0.042068,
        "accuracy": 0.052562,
        "main_score": 0.042068,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.013978,
        "recall": 0.018629,
        "f1": 0.014728,
        "accuracy": 0.018629,
        "main_score": 0.014728,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.045275,
        "recall": 0.069195,
        "f1": 0.050189,
        "accuracy": 0.069195,
        "main_score": 0.050189,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.046287,
        "recall": 0.069195,
        "f1": 0.051468,
        "accuracy": 0.069195,
        "main_score": 0.051468,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.018355,
        "recall": 0.02994,
        "f1": 0.021019,
        "accuracy": 0.02994,
        "main_score": 0.021019,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.020613,
        "recall": 0.027944,
        "f1": 0.022015,
        "accuracy": 0.027944,
        "main_score": 0.022015,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.02326,
        "recall": 0.037924,
        "f1": 0.02581,
        "accuracy": 0.037924,
        "main_score": 0.02581,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.024597,
        "recall": 0.034597,
        "f1": 0.026733,
        "accuracy": 0.034597,
        "main_score": 0.026733,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.039462,
        "recall": 0.061876,
        "f1": 0.044423,
        "accuracy": 0.061876,
        "main_score": 0.044423,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.024732,
        "recall": 0.045243,
        "f1": 0.029046,
        "accuracy": 0.045243,
        "main_score": 0.029046,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.028831,
        "recall": 0.050566,
        "f1": 0.03317,
        "accuracy": 0.050566,
        "main_score": 0.03317,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.025707,
        "recall": 0.042582,
        "f1": 0.028528,
        "accuracy": 0.042582,
        "main_score": 0.028528,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.040269,
        "recall": 0.055888,
        "f1": 0.042805,
        "accuracy": 0.055888,
        "main_score": 0.042805,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.016132,
        "recall": 0.031271,
        "f1": 0.018819,
        "accuracy": 0.031271,
        "main_score": 0.018819,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.025419,
        "recall": 0.045243,
        "f1": 0.029191,
        "accuracy": 0.045243,
        "main_score": 0.029191,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.031954,
        "recall": 0.049235,
        "f1": 0.035601,
        "accuracy": 0.049235,
        "main_score": 0.035601,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.023368,
        "recall": 0.035263,
        "f1": 0.025347,
        "accuracy": 0.035263,
        "main_score": 0.025347,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.032386,
        "recall": 0.045243,
        "f1": 0.03474,
        "accuracy": 0.045243,
        "main_score": 0.03474,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.022548,
        "recall": 0.031936,
        "f1": 0.023869,
        "accuracy": 0.031936,
        "main_score": 0.023869,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.025952,
        "recall": 0.046574,
        "f1": 0.030398,
        "accuracy": 0.046574,
        "main_score": 0.030398,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.028702,
        "recall": 0.052562,
        "f1": 0.034081,
        "accuracy": 0.052562,
        "main_score": 0.034081,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.049339,
        "recall": 0.072522,
        "f1": 0.05444,
        "accuracy": 0.072522,
        "main_score": 0.05444,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.082726,
        "recall": 0.117099,
        "f1": 0.090438,
        "accuracy": 0.117099,
        "main_score": 0.090438,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.030769,
        "recall": 0.039255,
        "f1": 0.032717,
        "accuracy": 0.039255,
        "main_score": 0.032717,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.051991,
        "recall": 0.074518,
        "f1": 0.055969,
        "accuracy": 0.074518,
        "main_score": 0.055969,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.040406,
        "recall": 0.066534,
        "f1": 0.045623,
        "accuracy": 0.066534,
        "main_score": 0.045623,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.016322,
        "recall": 0.035263,
        "f1": 0.019588,
        "accuracy": 0.035263,
        "main_score": 0.019588,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.031572,
        "recall": 0.045908,
        "f1": 0.034534,
        "accuracy": 0.045908,
        "main_score": 0.034534,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.035129,
        "recall": 0.063207,
        "f1": 0.041345,
        "accuracy": 0.063207,
        "main_score": 0.041345,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.035021,
        "recall": 0.047904,
        "f1": 0.037528,
        "accuracy": 0.047904,
        "main_score": 0.037528,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.022465,
        "recall": 0.036593,
        "f1": 0.02509,
        "accuracy": 0.036593,
        "main_score": 0.02509,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.026145,
        "recall": 0.045908,
        "f1": 0.030646,
        "accuracy": 0.045908,
        "main_score": 0.030646,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.027938,
        "recall": 0.0499,
        "f1": 0.032428,
        "accuracy": 0.0499,
        "main_score": 0.032428,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.028832,
        "recall": 0.047239,
        "f1": 0.032894,
        "accuracy": 0.047239,
        "main_score": 0.032894,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.084647,
        "recall": 0.120426,
        "f1": 0.091851,
        "accuracy": 0.120426,
        "main_score": 0.091851,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019523,
        "recall": 0.031936,
        "f1": 0.022035,
        "accuracy": 0.031936,
        "main_score": 0.022035,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.0312,
        "recall": 0.046574,
        "f1": 0.034736,
        "accuracy": 0.046574,
        "main_score": 0.034736,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.067703,
        "recall": 0.094478,
        "f1": 0.073651,
        "accuracy": 0.094478,
        "main_score": 0.073651,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.031066,
        "recall": 0.045243,
        "f1": 0.03345,
        "accuracy": 0.045243,
        "main_score": 0.03345,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.039478,
        "recall": 0.053892,
        "f1": 0.042456,
        "accuracy": 0.053892,
        "main_score": 0.042456,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.050272,
        "recall": 0.065203,
        "f1": 0.052699,
        "accuracy": 0.065203,
        "main_score": 0.052699,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.018901,
        "recall": 0.034597,
        "f1": 0.021895,
        "accuracy": 0.034597,
        "main_score": 0.021895,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.017436,
        "recall": 0.030605,
        "f1": 0.020224,
        "accuracy": 0.030605,
        "main_score": 0.020224,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.014338,
        "recall": 0.031936,
        "f1": 0.017414,
        "accuracy": 0.031936,
        "main_score": 0.017414,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.012138,
        "recall": 0.01996,
        "f1": 0.013522,
        "accuracy": 0.01996,
        "main_score": 0.013522,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.005152,
        "recall": 0.008649,
        "f1": 0.005458,
        "accuracy": 0.008649,
        "main_score": 0.005458,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031541,
        "recall": 0.052562,
        "f1": 0.036016,
        "accuracy": 0.052562,
        "main_score": 0.036016,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.016274,
        "recall": 0.02994,
        "f1": 0.019093,
        "accuracy": 0.02994,
        "main_score": 0.019093,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.00957,
        "recall": 0.018629,
        "f1": 0.011169,
        "accuracy": 0.018629,
        "main_score": 0.011169,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004362,
        "recall": 0.010645,
        "f1": 0.005218,
        "accuracy": 0.010645,
        "main_score": 0.005218,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.010644,
        "recall": 0.01996,
        "f1": 0.012249,
        "accuracy": 0.01996,
        "main_score": 0.012249,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.019409,
        "recall": 0.03992,
        "f1": 0.023299,
        "accuracy": 0.03992,
        "main_score": 0.023299,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.02228,
        "recall": 0.041251,
        "f1": 0.025841,
        "accuracy": 0.041251,
        "main_score": 0.025841,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.019997,
        "recall": 0.03992,
        "f1": 0.023596,
        "accuracy": 0.03992,
        "main_score": 0.023596,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.02076,
        "recall": 0.034597,
        "f1": 0.022989,
        "accuracy": 0.034597,
        "main_score": 0.022989,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.018809,
        "recall": 0.034597,
        "f1": 0.021492,
        "accuracy": 0.034597,
        "main_score": 0.021492,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.009374,
        "recall": 0.019295,
        "f1": 0.011132,
        "accuracy": 0.019295,
        "main_score": 0.011132,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.021198,
        "recall": 0.033932,
        "f1": 0.023365,
        "accuracy": 0.033932,
        "main_score": 0.023365,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.012505,
        "recall": 0.022621,
        "f1": 0.014175,
        "accuracy": 0.022621,
        "main_score": 0.014175,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.009754,
        "recall": 0.017299,
        "f1": 0.011274,
        "accuracy": 0.017299,
        "main_score": 0.011274,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.012023,
        "recall": 0.032601,
        "f1": 0.01506,
        "accuracy": 0.032601,
        "main_score": 0.01506,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.028829,
        "recall": 0.053892,
        "f1": 0.034095,
        "accuracy": 0.053892,
        "main_score": 0.034095,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.005524,
        "recall": 0.00998,
        "f1": 0.00607,
        "accuracy": 0.00998,
        "main_score": 0.00607,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.004752,
        "recall": 0.012641,
        "f1": 0.005571,
        "accuracy": 0.012641,
        "main_score": 0.005571,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.005257,
        "recall": 0.015303,
        "f1": 0.006595,
        "accuracy": 0.015303,
        "main_score": 0.006595,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.026754,
        "recall": 0.033932,
        "f1": 0.027922,
        "accuracy": 0.033932,
        "main_score": 0.027922,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.032292,
        "recall": 0.03992,
        "f1": 0.033854,
        "accuracy": 0.03992,
        "main_score": 0.033854,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.023564,
        "recall": 0.027944,
        "f1": 0.024884,
        "accuracy": 0.027944,
        "main_score": 0.024884,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027854,
        "recall": 0.032601,
        "f1": 0.028467,
        "accuracy": 0.032601,
        "main_score": 0.028467,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.016094,
        "recall": 0.021956,
        "f1": 0.01724,
        "accuracy": 0.021956,
        "main_score": 0.01724,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.034596,
        "recall": 0.041916,
        "f1": 0.036164,
        "accuracy": 0.041916,
        "main_score": 0.036164,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0074,
        "recall": 0.013307,
        "f1": 0.008288,
        "accuracy": 0.013307,
        "main_score": 0.008288,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.008714,
        "recall": 0.015968,
        "f1": 0.009707,
        "accuracy": 0.015968,
        "main_score": 0.009707,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.018116,
        "recall": 0.024617,
        "f1": 0.01918,
        "accuracy": 0.024617,
        "main_score": 0.01918,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.007304,
        "recall": 0.013307,
        "f1": 0.008219,
        "accuracy": 0.013307,
        "main_score": 0.008219,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.007392,
        "recall": 0.014637,
        "f1": 0.008642,
        "accuracy": 0.014637,
        "main_score": 0.008642,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.008862,
        "recall": 0.015303,
        "f1": 0.009635,
        "accuracy": 0.015303,
        "main_score": 0.009635,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.009188,
        "recall": 0.013972,
        "f1": 0.00988,
        "accuracy": 0.013972,
        "main_score": 0.00988,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.033966,
        "recall": 0.044578,
        "f1": 0.035726,
        "accuracy": 0.044578,
        "main_score": 0.035726,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.005238,
        "recall": 0.011311,
        "f1": 0.005666,
        "accuracy": 0.011311,
        "main_score": 0.005666,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.008717,
        "recall": 0.015968,
        "f1": 0.009864,
        "accuracy": 0.015968,
        "main_score": 0.009864,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.030593,
        "recall": 0.038589,
        "f1": 0.032354,
        "accuracy": 0.038589,
        "main_score": 0.032354,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.021815,
        "recall": 0.028609,
        "f1": 0.022903,
        "accuracy": 0.028609,
        "main_score": 0.022903,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.025293,
        "recall": 0.030605,
        "f1": 0.026199,
        "accuracy": 0.030605,
        "main_score": 0.026199,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.04053,
        "recall": 0.046574,
        "f1": 0.041796,
        "accuracy": 0.046574,
        "main_score": 0.041796,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.024602,
        "recall": 0.036593,
        "f1": 0.027067,
        "accuracy": 0.036593,
        "main_score": 0.027067,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.026216,
        "recall": 0.043247,
        "f1": 0.029606,
        "accuracy": 0.043247,
        "main_score": 0.029606,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.010571,
        "recall": 0.01996,
        "f1": 0.012042,
        "accuracy": 0.01996,
        "main_score": 0.012042,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.031571,
        "recall": 0.056554,
        "f1": 0.036167,
        "accuracy": 0.056554,
        "main_score": 0.036167,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002845,
        "recall": 0.005988,
        "f1": 0.003263,
        "accuracy": 0.005988,
        "main_score": 0.003263,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012442,
        "recall": 0.025283,
        "f1": 0.014194,
        "accuracy": 0.025283,
        "main_score": 0.014194,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.021417,
        "recall": 0.036593,
        "f1": 0.024056,
        "accuracy": 0.036593,
        "main_score": 0.024056,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.041081,
        "recall": 0.05855,
        "f1": 0.044572,
        "accuracy": 0.05855,
        "main_score": 0.044572,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.010426,
        "recall": 0.01996,
        "f1": 0.011894,
        "accuracy": 0.01996,
        "main_score": 0.011894,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006691,
        "recall": 0.012641,
        "f1": 0.00763,
        "accuracy": 0.012641,
        "main_score": 0.00763,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.005467,
        "recall": 0.011311,
        "f1": 0.006274,
        "accuracy": 0.011311,
        "main_score": 0.006274,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.020801,
        "recall": 0.033267,
        "f1": 0.023067,
        "accuracy": 0.033267,
        "main_score": 0.023067,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.019383,
        "recall": 0.02994,
        "f1": 0.021859,
        "accuracy": 0.02994,
        "main_score": 0.021859,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.03185,
        "recall": 0.04857,
        "f1": 0.035309,
        "accuracy": 0.04857,
        "main_score": 0.035309,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.024168,
        "recall": 0.037924,
        "f1": 0.026898,
        "accuracy": 0.037924,
        "main_score": 0.026898,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.028684,
        "recall": 0.047904,
        "f1": 0.032498,
        "accuracy": 0.047904,
        "main_score": 0.032498,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.017305,
        "recall": 0.025283,
        "f1": 0.018811,
        "accuracy": 0.025283,
        "main_score": 0.018811,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.028954,
        "recall": 0.043912,
        "f1": 0.032014,
        "accuracy": 0.043912,
        "main_score": 0.032014,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.019675,
        "recall": 0.037259,
        "f1": 0.023378,
        "accuracy": 0.037259,
        "main_score": 0.023378,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.004263,
        "recall": 0.011976,
        "f1": 0.004887,
        "accuracy": 0.011976,
        "main_score": 0.004887,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.00671,
        "recall": 0.019295,
        "f1": 0.008564,
        "accuracy": 0.019295,
        "main_score": 0.008564,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007362,
        "recall": 0.013972,
        "f1": 0.008358,
        "accuracy": 0.013972,
        "main_score": 0.008358,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.007432,
        "recall": 0.017964,
        "f1": 0.009286,
        "accuracy": 0.017964,
        "main_score": 0.009286,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.010546,
        "recall": 0.021956,
        "f1": 0.012713,
        "accuracy": 0.021956,
        "main_score": 0.012713,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.035096,
        "recall": 0.047239,
        "f1": 0.037053,
        "accuracy": 0.047239,
        "main_score": 0.037053,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.032871,
        "recall": 0.042582,
        "f1": 0.034703,
        "accuracy": 0.042582,
        "main_score": 0.034703,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.025837,
        "recall": 0.02994,
        "f1": 0.026892,
        "accuracy": 0.02994,
        "main_score": 0.026892,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.045154,
        "recall": 0.060546,
        "f1": 0.048605,
        "accuracy": 0.060546,
        "main_score": 0.048605,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.020795,
        "recall": 0.035263,
        "f1": 0.023687,
        "accuracy": 0.035263,
        "main_score": 0.023687,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.035028,
        "recall": 0.043247,
        "f1": 0.036403,
        "accuracy": 0.043247,
        "main_score": 0.036403,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.021049,
        "recall": 0.040585,
        "f1": 0.024666,
        "accuracy": 0.040585,
        "main_score": 0.024666,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.020457,
        "recall": 0.028609,
        "f1": 0.022216,
        "accuracy": 0.028609,
        "main_score": 0.022216,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.005866,
        "recall": 0.015303,
        "f1": 0.007321,
        "accuracy": 0.015303,
        "main_score": 0.007321,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.014529,
        "recall": 0.028609,
        "f1": 0.017006,
        "accuracy": 0.028609,
        "main_score": 0.017006,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.012371,
        "recall": 0.021956,
        "f1": 0.014051,
        "accuracy": 0.021956,
        "main_score": 0.014051,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.009148,
        "recall": 0.018629,
        "f1": 0.011001,
        "accuracy": 0.018629,
        "main_score": 0.011001,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.011283,
        "recall": 0.021956,
        "f1": 0.013291,
        "accuracy": 0.021956,
        "main_score": 0.013291,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.033029,
        "recall": 0.03992,
        "f1": 0.034165,
        "accuracy": 0.03992,
        "main_score": 0.034165,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.012332,
        "recall": 0.025283,
        "f1": 0.01476,
        "accuracy": 0.025283,
        "main_score": 0.01476,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.0053,
        "recall": 0.013307,
        "f1": 0.006544,
        "accuracy": 0.013307,
        "main_score": 0.006544,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.031573,
        "recall": 0.041251,
        "f1": 0.033187,
        "accuracy": 0.041251,
        "main_score": 0.033187,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.03304,
        "recall": 0.047239,
        "f1": 0.035755,
        "accuracy": 0.047239,
        "main_score": 0.035755,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.044838,
        "recall": 0.05988,
        "f1": 0.047396,
        "accuracy": 0.05988,
        "main_score": 0.047396,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.029287,
        "recall": 0.035263,
        "f1": 0.030635,
        "accuracy": 0.035263,
        "main_score": 0.030635,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.019309,
        "recall": 0.037924,
        "f1": 0.022578,
        "accuracy": 0.037924,
        "main_score": 0.022578,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.023878,
        "recall": 0.045243,
        "f1": 0.027879,
        "accuracy": 0.045243,
        "main_score": 0.027879,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.017821,
        "recall": 0.035928,
        "f1": 0.021087,
        "accuracy": 0.035928,
        "main_score": 0.021087,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.020555,
        "recall": 0.034597,
        "f1": 0.023236,
        "accuracy": 0.034597,
        "main_score": 0.023236,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00405,
        "recall": 0.006653,
        "f1": 0.004421,
        "accuracy": 0.006653,
        "main_score": 0.004421,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026264,
        "recall": 0.049235,
        "f1": 0.030929,
        "accuracy": 0.049235,
        "main_score": 0.030929,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.034725,
        "recall": 0.062542,
        "f1": 0.04057,
        "accuracy": 0.062542,
        "main_score": 0.04057,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.022306,
        "recall": 0.037259,
        "f1": 0.025067,
        "accuracy": 0.037259,
        "main_score": 0.025067,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.023068,
        "recall": 0.040585,
        "f1": 0.026412,
        "accuracy": 0.040585,
        "main_score": 0.026412,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006147,
        "recall": 0.013307,
        "f1": 0.00721,
        "accuracy": 0.013307,
        "main_score": 0.00721,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.018219,
        "recall": 0.032601,
        "f1": 0.020987,
        "accuracy": 0.032601,
        "main_score": 0.020987,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.010921,
        "recall": 0.023952,
        "f1": 0.013433,
        "accuracy": 0.023952,
        "main_score": 0.013433,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.023907,
        "recall": 0.044578,
        "f1": 0.027557,
        "accuracy": 0.044578,
        "main_score": 0.027557,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.027491,
        "recall": 0.052562,
        "f1": 0.031988,
        "accuracy": 0.052562,
        "main_score": 0.031988,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.026192,
        "recall": 0.045908,
        "f1": 0.029711,
        "accuracy": 0.045908,
        "main_score": 0.029711,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.022348,
        "recall": 0.035928,
        "f1": 0.025,
        "accuracy": 0.035928,
        "main_score": 0.025,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.016578,
        "recall": 0.035263,
        "f1": 0.01958,
        "accuracy": 0.035263,
        "main_score": 0.01958,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.023167,
        "recall": 0.035928,
        "f1": 0.02551,
        "accuracy": 0.035928,
        "main_score": 0.02551,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.017073,
        "recall": 0.02994,
        "f1": 0.019569,
        "accuracy": 0.02994,
        "main_score": 0.019569,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.008859,
        "recall": 0.018629,
        "f1": 0.010405,
        "accuracy": 0.018629,
        "main_score": 0.010405,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.016823,
        "recall": 0.036593,
        "f1": 0.020487,
        "accuracy": 0.036593,
        "main_score": 0.020487,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007688,
        "recall": 0.012641,
        "f1": 0.008283,
        "accuracy": 0.012641,
        "main_score": 0.008283,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.027333,
        "recall": 0.046574,
        "f1": 0.030824,
        "accuracy": 0.046574,
        "main_score": 0.030824,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.027726,
        "recall": 0.046574,
        "f1": 0.031501,
        "accuracy": 0.046574,
        "main_score": 0.031501,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.020309,
        "recall": 0.045908,
        "f1": 0.025297,
        "accuracy": 0.045908,
        "main_score": 0.025297,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.022117,
        "recall": 0.036593,
        "f1": 0.025102,
        "accuracy": 0.036593,
        "main_score": 0.025102,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002767,
        "recall": 0.005988,
        "f1": 0.003172,
        "accuracy": 0.005988,
        "main_score": 0.003172,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017794,
        "recall": 0.039255,
        "f1": 0.020864,
        "accuracy": 0.039255,
        "main_score": 0.020864,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.017917,
        "recall": 0.035263,
        "f1": 0.020956,
        "accuracy": 0.035263,
        "main_score": 0.020956,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.031356,
        "recall": 0.046574,
        "f1": 0.034515,
        "accuracy": 0.046574,
        "main_score": 0.034515,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.018579,
        "recall": 0.035263,
        "f1": 0.021393,
        "accuracy": 0.035263,
        "main_score": 0.021393,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.005576,
        "recall": 0.011976,
        "f1": 0.006745,
        "accuracy": 0.011976,
        "main_score": 0.006745,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.018881,
        "recall": 0.034597,
        "f1": 0.022154,
        "accuracy": 0.034597,
        "main_score": 0.022154,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.01041,
        "recall": 0.019295,
        "f1": 0.011675,
        "accuracy": 0.019295,
        "main_score": 0.011675,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.018023,
        "recall": 0.037259,
        "f1": 0.020739,
        "accuracy": 0.037259,
        "main_score": 0.020739,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.029596,
        "recall": 0.051231,
        "f1": 0.033856,
        "accuracy": 0.051231,
        "main_score": 0.033856,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.027557,
        "recall": 0.047904,
        "f1": 0.031371,
        "accuracy": 0.047904,
        "main_score": 0.031371,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.023292,
        "recall": 0.036593,
        "f1": 0.025654,
        "accuracy": 0.036593,
        "main_score": 0.025654,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.021786,
        "recall": 0.037259,
        "f1": 0.024847,
        "accuracy": 0.037259,
        "main_score": 0.024847,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.025283,
        "recall": 0.036593,
        "f1": 0.027596,
        "accuracy": 0.036593,
        "main_score": 0.027596,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.021971,
        "recall": 0.033267,
        "f1": 0.023892,
        "accuracy": 0.033267,
        "main_score": 0.023892,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.0075,
        "recall": 0.021956,
        "f1": 0.009047,
        "accuracy": 0.021956,
        "main_score": 0.009047,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009921,
        "recall": 0.025283,
        "f1": 0.012274,
        "accuracy": 0.025283,
        "main_score": 0.012274,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006761,
        "recall": 0.015303,
        "f1": 0.007881,
        "accuracy": 0.015303,
        "main_score": 0.007881,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.031441,
        "recall": 0.052562,
        "f1": 0.035533,
        "accuracy": 0.052562,
        "main_score": 0.035533,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.035175,
        "recall": 0.057884,
        "f1": 0.040369,
        "accuracy": 0.057884,
        "main_score": 0.040369,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.020436,
        "recall": 0.042582,
        "f1": 0.024714,
        "accuracy": 0.042582,
        "main_score": 0.024714,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.025407,
        "recall": 0.043912,
        "f1": 0.029081,
        "accuracy": 0.043912,
        "main_score": 0.029081,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003971,
        "recall": 0.007984,
        "f1": 0.004523,
        "accuracy": 0.007984,
        "main_score": 0.004523,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023941,
        "recall": 0.042582,
        "f1": 0.027227,
        "accuracy": 0.042582,
        "main_score": 0.027227,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.019182,
        "recall": 0.039255,
        "f1": 0.022936,
        "accuracy": 0.039255,
        "main_score": 0.022936,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.028978,
        "recall": 0.045908,
        "f1": 0.032607,
        "accuracy": 0.045908,
        "main_score": 0.032607,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015394,
        "recall": 0.02994,
        "f1": 0.01812,
        "accuracy": 0.02994,
        "main_score": 0.01812,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.00759,
        "recall": 0.015303,
        "f1": 0.008838,
        "accuracy": 0.015303,
        "main_score": 0.008838,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.029141,
        "recall": 0.047904,
        "f1": 0.033322,
        "accuracy": 0.047904,
        "main_score": 0.033322,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.009158,
        "recall": 0.018629,
        "f1": 0.010639,
        "accuracy": 0.018629,
        "main_score": 0.010639,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.024107,
        "recall": 0.044578,
        "f1": 0.027759,
        "accuracy": 0.044578,
        "main_score": 0.027759,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.026573,
        "recall": 0.045243,
        "f1": 0.030671,
        "accuracy": 0.045243,
        "main_score": 0.030671,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.035109,
        "recall": 0.055223,
        "f1": 0.038628,
        "accuracy": 0.055223,
        "main_score": 0.038628,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.025374,
        "recall": 0.03992,
        "f1": 0.028403,
        "accuracy": 0.03992,
        "main_score": 0.028403,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.020465,
        "recall": 0.038589,
        "f1": 0.023757,
        "accuracy": 0.038589,
        "main_score": 0.023757,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.029223,
        "recall": 0.044578,
        "f1": 0.032272,
        "accuracy": 0.044578,
        "main_score": 0.032272,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.014446,
        "recall": 0.030605,
        "f1": 0.01749,
        "accuracy": 0.030605,
        "main_score": 0.01749,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.008143,
        "recall": 0.021291,
        "f1": 0.009765,
        "accuracy": 0.021291,
        "main_score": 0.009765,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.015801,
        "recall": 0.031936,
        "f1": 0.018298,
        "accuracy": 0.031936,
        "main_score": 0.018298,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.008303,
        "recall": 0.018629,
        "f1": 0.009745,
        "accuracy": 0.018629,
        "main_score": 0.009745,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.0335,
        "recall": 0.05855,
        "f1": 0.038307,
        "accuracy": 0.05855,
        "main_score": 0.038307,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.027395,
        "recall": 0.053892,
        "f1": 0.032434,
        "accuracy": 0.053892,
        "main_score": 0.032434,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.01992,
        "recall": 0.040585,
        "f1": 0.024014,
        "accuracy": 0.040585,
        "main_score": 0.024014,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.023392,
        "recall": 0.041251,
        "f1": 0.02744,
        "accuracy": 0.041251,
        "main_score": 0.02744,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.003881,
        "recall": 0.005323,
        "f1": 0.004192,
        "accuracy": 0.005323,
        "main_score": 0.004192,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016302,
        "recall": 0.033932,
        "f1": 0.019357,
        "accuracy": 0.033932,
        "main_score": 0.019357,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.020299,
        "recall": 0.039255,
        "f1": 0.024063,
        "accuracy": 0.039255,
        "main_score": 0.024063,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.029463,
        "recall": 0.0499,
        "f1": 0.033303,
        "accuracy": 0.0499,
        "main_score": 0.033303,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015389,
        "recall": 0.030605,
        "f1": 0.017405,
        "accuracy": 0.030605,
        "main_score": 0.017405,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.005198,
        "recall": 0.013972,
        "f1": 0.006413,
        "accuracy": 0.013972,
        "main_score": 0.006413,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.020111,
        "recall": 0.040585,
        "f1": 0.024154,
        "accuracy": 0.040585,
        "main_score": 0.024154,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.010397,
        "recall": 0.022621,
        "f1": 0.012164,
        "accuracy": 0.022621,
        "main_score": 0.012164,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.019287,
        "recall": 0.037924,
        "f1": 0.022398,
        "accuracy": 0.037924,
        "main_score": 0.022398,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.026201,
        "recall": 0.053227,
        "f1": 0.031363,
        "accuracy": 0.053227,
        "main_score": 0.031363,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.031622,
        "recall": 0.065868,
        "f1": 0.038455,
        "accuracy": 0.065868,
        "main_score": 0.038455,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.021679,
        "recall": 0.043912,
        "f1": 0.025885,
        "accuracy": 0.043912,
        "main_score": 0.025885,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019547,
        "recall": 0.038589,
        "f1": 0.023302,
        "accuracy": 0.038589,
        "main_score": 0.023302,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.026955,
        "recall": 0.052562,
        "f1": 0.032351,
        "accuracy": 0.052562,
        "main_score": 0.032351,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.014955,
        "recall": 0.033267,
        "f1": 0.018411,
        "accuracy": 0.033267,
        "main_score": 0.018411,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.007045,
        "recall": 0.021956,
        "f1": 0.008503,
        "accuracy": 0.021956,
        "main_score": 0.008503,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009252,
        "recall": 0.026613,
        "f1": 0.011769,
        "accuracy": 0.026613,
        "main_score": 0.011769,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.0065,
        "recall": 0.015968,
        "f1": 0.007526,
        "accuracy": 0.015968,
        "main_score": 0.007526,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.024585,
        "recall": 0.043247,
        "f1": 0.028849,
        "accuracy": 0.043247,
        "main_score": 0.028849,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.023946,
        "recall": 0.041251,
        "f1": 0.027467,
        "accuracy": 0.041251,
        "main_score": 0.027467,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.046118,
        "recall": 0.067199,
        "f1": 0.050622,
        "accuracy": 0.067199,
        "main_score": 0.050622,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.075663,
        "recall": 0.106454,
        "f1": 0.082568,
        "accuracy": 0.106454,
        "main_score": 0.082568,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.035836,
        "recall": 0.041916,
        "f1": 0.037179,
        "accuracy": 0.041916,
        "main_score": 0.037179,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.052521,
        "recall": 0.073852,
        "f1": 0.056406,
        "accuracy": 0.073852,
        "main_score": 0.056406,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.031763,
        "recall": 0.057219,
        "f1": 0.036583,
        "accuracy": 0.057219,
        "main_score": 0.036583,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.083052,
        "recall": 0.110446,
        "f1": 0.089582,
        "accuracy": 0.110446,
        "main_score": 0.089582,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.013407,
        "recall": 0.027279,
        "f1": 0.015776,
        "accuracy": 0.027279,
        "main_score": 0.015776,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.029043,
        "recall": 0.041251,
        "f1": 0.031549,
        "accuracy": 0.041251,
        "main_score": 0.031549,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.027316,
        "recall": 0.050566,
        "f1": 0.031924,
        "accuracy": 0.050566,
        "main_score": 0.031924,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.032284,
        "recall": 0.045243,
        "f1": 0.034852,
        "accuracy": 0.045243,
        "main_score": 0.034852,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.021637,
        "recall": 0.035263,
        "f1": 0.023968,
        "accuracy": 0.035263,
        "main_score": 0.023968,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.023982,
        "recall": 0.043247,
        "f1": 0.027773,
        "accuracy": 0.043247,
        "main_score": 0.027773,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.024962,
        "recall": 0.046574,
        "f1": 0.029938,
        "accuracy": 0.046574,
        "main_score": 0.029938,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.026542,
        "recall": 0.044578,
        "f1": 0.030716,
        "accuracy": 0.044578,
        "main_score": 0.030716,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.01196,
        "recall": 0.022621,
        "f1": 0.013737,
        "accuracy": 0.022621,
        "main_score": 0.013737,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.036858,
        "recall": 0.060546,
        "f1": 0.042574,
        "accuracy": 0.060546,
        "main_score": 0.042574,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.056517,
        "recall": 0.07984,
        "f1": 0.06178,
        "accuracy": 0.07984,
        "main_score": 0.06178,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.03371,
        "recall": 0.046574,
        "f1": 0.035542,
        "accuracy": 0.046574,
        "main_score": 0.035542,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.040849,
        "recall": 0.05855,
        "f1": 0.043854,
        "accuracy": 0.05855,
        "main_score": 0.043854,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.046102,
        "recall": 0.063207,
        "f1": 0.048852,
        "accuracy": 0.063207,
        "main_score": 0.048852,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.017323,
        "recall": 0.037924,
        "f1": 0.020641,
        "accuracy": 0.037924,
        "main_score": 0.020641,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.019501,
        "recall": 0.037924,
        "f1": 0.022887,
        "accuracy": 0.037924,
        "main_score": 0.022887,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.012289,
        "recall": 0.027944,
        "f1": 0.014527,
        "accuracy": 0.027944,
        "main_score": 0.014527,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.011914,
        "recall": 0.021956,
        "f1": 0.013107,
        "accuracy": 0.021956,
        "main_score": 0.013107,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.004416,
        "recall": 0.007319,
        "f1": 0.00495,
        "accuracy": 0.007319,
        "main_score": 0.00495,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019717,
        "recall": 0.035928,
        "f1": 0.022296,
        "accuracy": 0.035928,
        "main_score": 0.022296,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.015511,
        "recall": 0.031271,
        "f1": 0.018243,
        "accuracy": 0.031271,
        "main_score": 0.018243,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.018443,
        "recall": 0.033267,
        "f1": 0.020948,
        "accuracy": 0.033267,
        "main_score": 0.020948,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.018071,
        "recall": 0.033932,
        "f1": 0.020933,
        "accuracy": 0.033932,
        "main_score": 0.020933,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.002994,
        "recall": 0.008649,
        "f1": 0.003457,
        "accuracy": 0.008649,
        "main_score": 0.003457,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.015003,
        "recall": 0.027279,
        "f1": 0.017312,
        "accuracy": 0.027279,
        "main_score": 0.017312,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.012045,
        "recall": 0.025283,
        "f1": 0.014215,
        "accuracy": 0.025283,
        "main_score": 0.014215,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.015452,
        "recall": 0.028609,
        "f1": 0.017381,
        "accuracy": 0.028609,
        "main_score": 0.017381,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.022967,
        "recall": 0.039255,
        "f1": 0.026097,
        "accuracy": 0.039255,
        "main_score": 0.026097,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.025708,
        "recall": 0.043247,
        "f1": 0.028457,
        "accuracy": 0.043247,
        "main_score": 0.028457,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.021257,
        "recall": 0.035928,
        "f1": 0.023796,
        "accuracy": 0.035928,
        "main_score": 0.023796,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.012581,
        "recall": 0.027944,
        "f1": 0.014588,
        "accuracy": 0.027944,
        "main_score": 0.014588,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.015256,
        "recall": 0.024617,
        "f1": 0.016608,
        "accuracy": 0.024617,
        "main_score": 0.016608,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.008545,
        "recall": 0.01996,
        "f1": 0.010165,
        "accuracy": 0.01996,
        "main_score": 0.010165,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.007252,
        "recall": 0.017964,
        "f1": 0.008635,
        "accuracy": 0.017964,
        "main_score": 0.008635,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.010912,
        "recall": 0.022621,
        "f1": 0.012389,
        "accuracy": 0.022621,
        "main_score": 0.012389,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.005844,
        "recall": 0.00998,
        "f1": 0.006406,
        "accuracy": 0.00998,
        "main_score": 0.006406,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.019631,
        "recall": 0.041916,
        "f1": 0.024117,
        "accuracy": 0.041916,
        "main_score": 0.024117,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.021069,
        "recall": 0.041251,
        "f1": 0.024796,
        "accuracy": 0.041251,
        "main_score": 0.024796,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.009463,
        "recall": 0.023952,
        "f1": 0.011855,
        "accuracy": 0.023952,
        "main_score": 0.011855,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.03003,
        "recall": 0.051896,
        "f1": 0.03496,
        "accuracy": 0.051896,
        "main_score": 0.03496,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001892,
        "recall": 0.004657,
        "f1": 0.002168,
        "accuracy": 0.004657,
        "main_score": 0.002168,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013848,
        "recall": 0.029275,
        "f1": 0.015926,
        "accuracy": 0.029275,
        "main_score": 0.015926,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.015755,
        "recall": 0.028609,
        "f1": 0.018111,
        "accuracy": 0.028609,
        "main_score": 0.018111,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.024273,
        "recall": 0.041251,
        "f1": 0.027673,
        "accuracy": 0.041251,
        "main_score": 0.027673,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00766,
        "recall": 0.017299,
        "f1": 0.009074,
        "accuracy": 0.017299,
        "main_score": 0.009074,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004742,
        "recall": 0.011311,
        "f1": 0.005737,
        "accuracy": 0.011311,
        "main_score": 0.005737,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.023539,
        "recall": 0.041916,
        "f1": 0.026995,
        "accuracy": 0.041916,
        "main_score": 0.026995,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.004765,
        "recall": 0.012641,
        "f1": 0.005857,
        "accuracy": 0.012641,
        "main_score": 0.005857,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.016923,
        "recall": 0.031271,
        "f1": 0.01899,
        "accuracy": 0.031271,
        "main_score": 0.01899,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.023961,
        "recall": 0.043912,
        "f1": 0.028181,
        "accuracy": 0.043912,
        "main_score": 0.028181,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.027358,
        "recall": 0.049235,
        "f1": 0.031387,
        "accuracy": 0.049235,
        "main_score": 0.031387,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.027545,
        "recall": 0.045908,
        "f1": 0.031228,
        "accuracy": 0.045908,
        "main_score": 0.031228,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.029704,
        "recall": 0.051231,
        "f1": 0.03401,
        "accuracy": 0.051231,
        "main_score": 0.03401,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.012864,
        "recall": 0.025948,
        "f1": 0.014932,
        "accuracy": 0.025948,
        "main_score": 0.014932,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.009181,
        "recall": 0.021956,
        "f1": 0.011675,
        "accuracy": 0.021956,
        "main_score": 0.011675,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.005069,
        "recall": 0.013972,
        "f1": 0.006042,
        "accuracy": 0.013972,
        "main_score": 0.006042,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.007692,
        "recall": 0.018629,
        "f1": 0.009287,
        "accuracy": 0.018629,
        "main_score": 0.009287,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004584,
        "recall": 0.009315,
        "f1": 0.005188,
        "accuracy": 0.009315,
        "main_score": 0.005188,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.014277,
        "recall": 0.025948,
        "f1": 0.016776,
        "accuracy": 0.025948,
        "main_score": 0.016776,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.02113,
        "recall": 0.037259,
        "f1": 0.024307,
        "accuracy": 0.037259,
        "main_score": 0.024307,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.036971,
        "recall": 0.053227,
        "f1": 0.040418,
        "accuracy": 0.053227,
        "main_score": 0.040418,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.054715,
        "recall": 0.079175,
        "f1": 0.05987,
        "accuracy": 0.079175,
        "main_score": 0.05987,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.027651,
        "recall": 0.033932,
        "f1": 0.029165,
        "accuracy": 0.033932,
        "main_score": 0.029165,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.039142,
        "recall": 0.053892,
        "f1": 0.041802,
        "accuracy": 0.053892,
        "main_score": 0.041802,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.02838,
        "recall": 0.045908,
        "f1": 0.031835,
        "accuracy": 0.045908,
        "main_score": 0.031835,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.072039,
        "recall": 0.095143,
        "f1": 0.077182,
        "accuracy": 0.095143,
        "main_score": 0.077182,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0095,
        "recall": 0.020625,
        "f1": 0.011165,
        "accuracy": 0.020625,
        "main_score": 0.011165,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.027515,
        "recall": 0.036593,
        "f1": 0.029763,
        "accuracy": 0.036593,
        "main_score": 0.029763,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.021426,
        "recall": 0.035263,
        "f1": 0.024285,
        "accuracy": 0.035263,
        "main_score": 0.024285,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.031366,
        "recall": 0.044578,
        "f1": 0.033713,
        "accuracy": 0.044578,
        "main_score": 0.033713,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.016862,
        "recall": 0.02994,
        "f1": 0.019397,
        "accuracy": 0.02994,
        "main_score": 0.019397,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.020033,
        "recall": 0.035263,
        "f1": 0.023401,
        "accuracy": 0.035263,
        "main_score": 0.023401,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.018468,
        "recall": 0.02994,
        "f1": 0.02095,
        "accuracy": 0.02994,
        "main_score": 0.02095,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.019934,
        "recall": 0.037259,
        "f1": 0.022655,
        "accuracy": 0.037259,
        "main_score": 0.022655,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.055753,
        "recall": 0.080506,
        "f1": 0.060654,
        "accuracy": 0.080506,
        "main_score": 0.060654,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.010291,
        "recall": 0.020625,
        "f1": 0.012046,
        "accuracy": 0.020625,
        "main_score": 0.012046,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.01308,
        "recall": 0.025283,
        "f1": 0.015653,
        "accuracy": 0.025283,
        "main_score": 0.015653,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.023697,
        "recall": 0.035263,
        "f1": 0.025703,
        "accuracy": 0.035263,
        "main_score": 0.025703,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.03397,
        "recall": 0.044578,
        "f1": 0.035896,
        "accuracy": 0.044578,
        "main_score": 0.035896,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.043646,
        "recall": 0.056554,
        "f1": 0.045839,
        "accuracy": 0.056554,
        "main_score": 0.045839,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.005151,
        "recall": 0.013972,
        "f1": 0.006376,
        "accuracy": 0.013972,
        "main_score": 0.006376,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.014135,
        "recall": 0.021291,
        "f1": 0.015333,
        "accuracy": 0.021291,
        "main_score": 0.015333,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.031224,
        "recall": 0.040585,
        "f1": 0.032896,
        "accuracy": 0.040585,
        "main_score": 0.032896,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.031278,
        "recall": 0.037924,
        "f1": 0.032668,
        "accuracy": 0.037924,
        "main_score": 0.032668,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.023567,
        "recall": 0.030605,
        "f1": 0.025092,
        "accuracy": 0.030605,
        "main_score": 0.025092,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.045016,
        "recall": 0.061211,
        "f1": 0.047931,
        "accuracy": 0.061211,
        "main_score": 0.047931,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.02161,
        "recall": 0.033932,
        "f1": 0.023961,
        "accuracy": 0.033932,
        "main_score": 0.023961,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.033529,
        "recall": 0.041251,
        "f1": 0.03499,
        "accuracy": 0.041251,
        "main_score": 0.03499,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0152,
        "recall": 0.031936,
        "f1": 0.017969,
        "accuracy": 0.031936,
        "main_score": 0.017969,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.023727,
        "recall": 0.031936,
        "f1": 0.025516,
        "accuracy": 0.031936,
        "main_score": 0.025516,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.006779,
        "recall": 0.013972,
        "f1": 0.007833,
        "accuracy": 0.013972,
        "main_score": 0.007833,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.031571,
        "recall": 0.043912,
        "f1": 0.0341,
        "accuracy": 0.043912,
        "main_score": 0.0341,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.014519,
        "recall": 0.024617,
        "f1": 0.016301,
        "accuracy": 0.024617,
        "main_score": 0.016301,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.010494,
        "recall": 0.018629,
        "f1": 0.011671,
        "accuracy": 0.018629,
        "main_score": 0.011671,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.015074,
        "recall": 0.023952,
        "f1": 0.016671,
        "accuracy": 0.023952,
        "main_score": 0.016671,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.011297,
        "recall": 0.018629,
        "f1": 0.012225,
        "accuracy": 0.018629,
        "main_score": 0.012225,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.034339,
        "recall": 0.041251,
        "f1": 0.035771,
        "accuracy": 0.041251,
        "main_score": 0.035771,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.011837,
        "recall": 0.021956,
        "f1": 0.013536,
        "accuracy": 0.021956,
        "main_score": 0.013536,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.007634,
        "recall": 0.014637,
        "f1": 0.008699,
        "accuracy": 0.014637,
        "main_score": 0.008699,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.029797,
        "recall": 0.039255,
        "f1": 0.031444,
        "accuracy": 0.039255,
        "main_score": 0.031444,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.046531,
        "recall": 0.061211,
        "f1": 0.050097,
        "accuracy": 0.061211,
        "main_score": 0.050097,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.031068,
        "recall": 0.038589,
        "f1": 0.032625,
        "accuracy": 0.038589,
        "main_score": 0.032625,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.010016,
        "recall": 0.020625,
        "f1": 0.011637,
        "accuracy": 0.020625,
        "main_score": 0.011637,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.016988,
        "recall": 0.027944,
        "f1": 0.01955,
        "accuracy": 0.027944,
        "main_score": 0.01955,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.034924,
        "recall": 0.052562,
        "f1": 0.038273,
        "accuracy": 0.052562,
        "main_score": 0.038273,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.040481,
        "recall": 0.051896,
        "f1": 0.042698,
        "accuracy": 0.051896,
        "main_score": 0.042698,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.028054,
        "recall": 0.035263,
        "f1": 0.029683,
        "accuracy": 0.035263,
        "main_score": 0.029683,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.058739,
        "recall": 0.080506,
        "f1": 0.062896,
        "accuracy": 0.080506,
        "main_score": 0.062896,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.029966,
        "recall": 0.047239,
        "f1": 0.033406,
        "accuracy": 0.047239,
        "main_score": 0.033406,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.042029,
        "recall": 0.053227,
        "f1": 0.044308,
        "accuracy": 0.053227,
        "main_score": 0.044308,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.032212,
        "recall": 0.051231,
        "f1": 0.035969,
        "accuracy": 0.051231,
        "main_score": 0.035969,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.023834,
        "recall": 0.031936,
        "f1": 0.025657,
        "accuracy": 0.031936,
        "main_score": 0.025657,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.010067,
        "recall": 0.017299,
        "f1": 0.011544,
        "accuracy": 0.017299,
        "main_score": 0.011544,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.041322,
        "recall": 0.060546,
        "f1": 0.045128,
        "accuracy": 0.060546,
        "main_score": 0.045128,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.017224,
        "recall": 0.037259,
        "f1": 0.020603,
        "accuracy": 0.037259,
        "main_score": 0.020603,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00902,
        "recall": 0.018629,
        "f1": 0.010407,
        "accuracy": 0.018629,
        "main_score": 0.010407,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.019712,
        "recall": 0.033932,
        "f1": 0.022307,
        "accuracy": 0.033932,
        "main_score": 0.022307,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.014257,
        "recall": 0.027944,
        "f1": 0.016595,
        "accuracy": 0.027944,
        "main_score": 0.016595,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.044517,
        "recall": 0.055223,
        "f1": 0.046721,
        "accuracy": 0.055223,
        "main_score": 0.046721,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.015149,
        "recall": 0.02994,
        "f1": 0.018198,
        "accuracy": 0.02994,
        "main_score": 0.018198,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.01212,
        "recall": 0.024617,
        "f1": 0.014146,
        "accuracy": 0.024617,
        "main_score": 0.014146,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.037323,
        "recall": 0.047239,
        "f1": 0.039205,
        "accuracy": 0.047239,
        "main_score": 0.039205,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.045263,
        "recall": 0.05988,
        "f1": 0.048341,
        "accuracy": 0.05988,
        "main_score": 0.048341,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.035874,
        "recall": 0.041916,
        "f1": 0.037151,
        "accuracy": 0.041916,
        "main_score": 0.037151,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.005067,
        "recall": 0.009315,
        "f1": 0.00586,
        "accuracy": 0.009315,
        "main_score": 0.00586,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.006326,
        "recall": 0.013307,
        "f1": 0.007469,
        "accuracy": 0.013307,
        "main_score": 0.007469,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.031447,
        "recall": 0.040585,
        "f1": 0.033263,
        "accuracy": 0.040585,
        "main_score": 0.033263,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.041177,
        "recall": 0.057219,
        "f1": 0.04404,
        "accuracy": 0.057219,
        "main_score": 0.04404,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.029264,
        "recall": 0.034597,
        "f1": 0.030618,
        "accuracy": 0.034597,
        "main_score": 0.030618,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.036753,
        "recall": 0.043912,
        "f1": 0.03789,
        "accuracy": 0.043912,
        "main_score": 0.03789,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.015959,
        "recall": 0.027279,
        "f1": 0.018066,
        "accuracy": 0.027279,
        "main_score": 0.018066,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.047333,
        "recall": 0.061876,
        "f1": 0.050191,
        "accuracy": 0.061876,
        "main_score": 0.050191,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004272,
        "recall": 0.007984,
        "f1": 0.004754,
        "accuracy": 0.007984,
        "main_score": 0.004754,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.034177,
        "recall": 0.046574,
        "f1": 0.036901,
        "accuracy": 0.046574,
        "main_score": 0.036901,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.007258,
        "recall": 0.015303,
        "f1": 0.008498,
        "accuracy": 0.015303,
        "main_score": 0.008498,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.024623,
        "recall": 0.032601,
        "f1": 0.02608,
        "accuracy": 0.032601,
        "main_score": 0.02608,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.006101,
        "recall": 0.013307,
        "f1": 0.006979,
        "accuracy": 0.013307,
        "main_score": 0.006979,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00624,
        "recall": 0.011311,
        "f1": 0.00707,
        "accuracy": 0.011311,
        "main_score": 0.00707,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.009305,
        "recall": 0.015303,
        "f1": 0.010304,
        "accuracy": 0.015303,
        "main_score": 0.010304,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.006414,
        "recall": 0.011976,
        "f1": 0.007329,
        "accuracy": 0.011976,
        "main_score": 0.007329,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.04231,
        "recall": 0.055223,
        "f1": 0.044726,
        "accuracy": 0.055223,
        "main_score": 0.044726,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.00577,
        "recall": 0.009315,
        "f1": 0.006105,
        "accuracy": 0.009315,
        "main_score": 0.006105,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006749,
        "recall": 0.011976,
        "f1": 0.007692,
        "accuracy": 0.011976,
        "main_score": 0.007692,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.038767,
        "recall": 0.057219,
        "f1": 0.041695,
        "accuracy": 0.057219,
        "main_score": 0.041695,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.025173,
        "recall": 0.031271,
        "f1": 0.026352,
        "accuracy": 0.031271,
        "main_score": 0.026352,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.030121,
        "recall": 0.037924,
        "f1": 0.031633,
        "accuracy": 0.037924,
        "main_score": 0.031633,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 21.46198081970215,
  "kg_co2_emissions": 0.0007822186735757424
}