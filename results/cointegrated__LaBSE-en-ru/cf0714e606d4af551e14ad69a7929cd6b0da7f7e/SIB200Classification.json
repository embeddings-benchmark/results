{
  "dataset_revision": "a74d7350ea12af010cfb1c21e34f1f81fd2e615b",
  "evaluation_time": 15.080036640167236,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.85",
  "scores": {
    "test": [
      {
        "accuracy": 0.5759803921568627,
        "f1": 0.5679171688097695,
        "f1_weighted": 0.5702790728452761,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.5759803921568627,
        "scores_per_experiment": [
          {
            "accuracy": 0.5882352941176471,
            "f1": 0.5903510309954993,
            "f1_weighted": 0.5860721383388345
          },
          {
            "accuracy": 0.5931372549019608,
            "f1": 0.5868626983044527,
            "f1_weighted": 0.5916693069650689
          },
          {
            "accuracy": 0.5588235294117647,
            "f1": 0.5613493958574431,
            "f1_weighted": 0.5440175956793951
          },
          {
            "accuracy": 0.5735294117647058,
            "f1": 0.5649450212197988,
            "f1_weighted": 0.5688012566888139
          },
          {
            "accuracy": 0.6715686274509803,
            "f1": 0.6620011443059873,
            "f1_weighted": 0.6736660156271681
          },
          {
            "accuracy": 0.5245098039215687,
            "f1": 0.5182608884724214,
            "f1_weighted": 0.5194343965791286
          },
          {
            "accuracy": 0.6176470588235294,
            "f1": 0.598788656109031,
            "f1_weighted": 0.611890890159682
          },
          {
            "accuracy": 0.5098039215686274,
            "f1": 0.5072137927002023,
            "f1_weighted": 0.5053715535068932
          },
          {
            "accuracy": 0.5049019607843137,
            "f1": 0.4746672870761398,
            "f1_weighted": 0.48084954762676224
          },
          {
            "accuracy": 0.6176470588235294,
            "f1": 0.6147317730567201,
            "f1_weighted": 0.6210180272810143
          }
        ]
      }
    ],
    "train": [
      {
        "accuracy": 0.5828815977175463,
        "f1": 0.5746957538418926,
        "f1_weighted": 0.5828071850199906,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.5828815977175463,
        "scores_per_experiment": [
          {
            "accuracy": 0.6077032810271041,
            "f1": 0.5924757569986892,
            "f1_weighted": 0.6117501849675585
          },
          {
            "accuracy": 0.5563480741797432,
            "f1": 0.549009925940073,
            "f1_weighted": 0.5587446616242139
          },
          {
            "accuracy": 0.5805991440798859,
            "f1": 0.5747232279037018,
            "f1_weighted": 0.5768873027360868
          },
          {
            "accuracy": 0.5948644793152639,
            "f1": 0.5869856015112457,
            "f1_weighted": 0.5980857189711497
          },
          {
            "accuracy": 0.6119828815977175,
            "f1": 0.6031225838642993,
            "f1_weighted": 0.6107351862583744
          },
          {
            "accuracy": 0.5606276747503567,
            "f1": 0.5651877089275694,
            "f1_weighted": 0.5538468693344608
          },
          {
            "accuracy": 0.6162624821683309,
            "f1": 0.6057644931344993,
            "f1_weighted": 0.6127808887822873
          },
          {
            "accuracy": 0.543509272467903,
            "f1": 0.534361650563229,
            "f1_weighted": 0.5480384282277836
          },
          {
            "accuracy": 0.5420827389443652,
            "f1": 0.5264525721557006,
            "f1_weighted": 0.5408479612236827
          },
          {
            "accuracy": 0.6148359486447932,
            "f1": 0.6088740174199199,
            "f1_weighted": 0.6163546480743083
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5505050505050505,
        "f1": 0.537688521610112,
        "f1_weighted": 0.5512974035364779,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.5505050505050505,
        "scores_per_experiment": [
          {
            "accuracy": 0.5757575757575758,
            "f1": 0.5554421768707483,
            "f1_weighted": 0.5746031746031746
          },
          {
            "accuracy": 0.5252525252525253,
            "f1": 0.5236265482546948,
            "f1_weighted": 0.5359535797846248
          },
          {
            "accuracy": 0.494949494949495,
            "f1": 0.4917622923499018,
            "f1_weighted": 0.4811272183956809
          },
          {
            "accuracy": 0.5656565656565656,
            "f1": 0.5616458896158144,
            "f1_weighted": 0.5764122273851141
          },
          {
            "accuracy": 0.5858585858585859,
            "f1": 0.5741965517170795,
            "f1_weighted": 0.5918145110499398
          },
          {
            "accuracy": 0.5151515151515151,
            "f1": 0.5218130807416522,
            "f1_weighted": 0.5161961161961162
          },
          {
            "accuracy": 0.5555555555555556,
            "f1": 0.5404848774413992,
            "f1_weighted": 0.5600389216990007
          },
          {
            "accuracy": 0.5858585858585859,
            "f1": 0.570537699560256,
            "f1_weighted": 0.5747515901901866
          },
          {
            "accuracy": 0.494949494949495,
            "f1": 0.4829532487549623,
            "f1_weighted": 0.4986631993812737
          },
          {
            "accuracy": 0.6060606060606061,
            "f1": 0.5544228507946126,
            "f1_weighted": 0.6034134966796684
          }
        ]
      }
    ]
  },
  "task_name": "SIB200Classification"
}