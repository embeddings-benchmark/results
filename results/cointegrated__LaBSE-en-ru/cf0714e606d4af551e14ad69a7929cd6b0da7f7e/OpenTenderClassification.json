{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.219621,
            "f1": 0.208719,
            "f1_weighted": 0.208678,
            "precision": 0.216205,
            "precision_weighted": 0.216126,
            "recall": 0.21964,
            "recall_weighted": 0.219621,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.191081,
            "f1": 0.178228,
            "f1_weighted": 0.178151,
            "precision": 0.193837,
            "precision_weighted": 0.193755,
            "recall": 0.191205,
            "recall_weighted": 0.191081,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.231884,
            "f1": 0.22266,
            "f1_weighted": 0.222665,
            "precision": 0.237725,
            "precision_weighted": 0.237775,
            "recall": 0.23193,
            "recall_weighted": 0.231884,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.218283,
            "f1": 0.212188,
            "f1_weighted": 0.212252,
            "precision": 0.220439,
            "precision_weighted": 0.220522,
            "recall": 0.218241,
            "recall_weighted": 0.218283,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.201115,
            "f1": 0.192581,
            "f1_weighted": 0.192596,
            "precision": 0.208047,
            "precision_weighted": 0.208012,
            "recall": 0.201055,
            "recall_weighted": 0.201115,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.225195,
            "f1": 0.21287,
            "f1_weighted": 0.212804,
            "precision": 0.223552,
            "precision_weighted": 0.223529,
            "recall": 0.225292,
            "recall_weighted": 0.225195,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.222297,
            "f1": 0.212886,
            "f1_weighted": 0.212857,
            "precision": 0.229595,
            "precision_weighted": 0.229476,
            "recall": 0.222255,
            "recall_weighted": 0.222297,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.215385,
            "f1": 0.197391,
            "f1_weighted": 0.197349,
            "precision": 0.211665,
            "precision_weighted": 0.211653,
            "recall": 0.215442,
            "recall_weighted": 0.215385,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.199331,
            "f1": 0.187973,
            "f1_weighted": 0.187931,
            "precision": 0.197836,
            "precision_weighted": 0.197818,
            "recall": 0.199421,
            "recall_weighted": 0.199331,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.202899,
            "f1": 0.18938,
            "f1_weighted": 0.189398,
            "precision": 0.203575,
            "precision_weighted": 0.203568,
            "recall": 0.202841,
            "recall_weighted": 0.202899,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.212709,
        "f1": 0.201488,
        "f1_weighted": 0.201468,
        "precision": 0.214247,
        "precision_weighted": 0.214223,
        "recall": 0.212732,
        "recall_weighted": 0.212709,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.201488,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 60.13737773895264,
  "kg_co2_emissions": null
}