{
  "dataset_revision": "3e0319203c7162b9c9f8015b594441f979c199bc",
  "task_name": "ToxicChatClassification",
  "mteb_version": "1.36.10",
  "scores": {
    "test": [
      {
        "accuracy": 0.818385,
        "f1": 0.697287,
        "f1_weighted": 0.840005,
        "ap": 0.32124,
        "ap_weighted": 0.32124,
        "scores_per_experiment": [
          {
            "accuracy": 0.743127,
            "f1": 0.618662,
            "f1_weighted": 0.78187,
            "ap": 0.23355,
            "ap_weighted": 0.23355
          },
          {
            "accuracy": 0.847079,
            "f1": 0.712744,
            "f1_weighted": 0.859905,
            "ap": 0.322261,
            "ap_weighted": 0.322261
          },
          {
            "accuracy": 0.883162,
            "f1": 0.776558,
            "f1_weighted": 0.892178,
            "ap": 0.430695,
            "ap_weighted": 0.430695
          },
          {
            "accuracy": 0.820447,
            "f1": 0.70766,
            "f1_weighted": 0.843691,
            "ap": 0.338195,
            "ap_weighted": 0.338195
          },
          {
            "accuracy": 0.834192,
            "f1": 0.683627,
            "f1_weighted": 0.84713,
            "ap": 0.27805,
            "ap_weighted": 0.27805
          },
          {
            "accuracy": 0.829038,
            "f1": 0.707122,
            "f1_weighted": 0.848681,
            "ap": 0.327205,
            "ap_weighted": 0.327205
          },
          {
            "accuracy": 0.849656,
            "f1": 0.703669,
            "f1_weighted": 0.859484,
            "ap": 0.303574,
            "ap_weighted": 0.303574
          },
          {
            "accuracy": 0.730241,
            "f1": 0.639493,
            "f1_weighted": 0.774993,
            "ap": 0.290333,
            "ap_weighted": 0.290333
          },
          {
            "accuracy": 0.840206,
            "f1": 0.724683,
            "f1_weighted": 0.858285,
            "ap": 0.354656,
            "ap_weighted": 0.354656
          },
          {
            "accuracy": 0.806701,
            "f1": 0.698649,
            "f1_weighted": 0.83383,
            "ap": 0.333879,
            "ap_weighted": 0.333879
          }
        ],
        "main_score": 0.818385,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 16.100515127182007,
  "kg_co2_emissions": null,
  "mteb_dataset_name": "ToxicChatClassification"
}