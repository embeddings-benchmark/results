{
  "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
  "task_name": "NTREXBitextMining",
  "mteb_version": "1.36.10",
  "scores": {
    "test": [
      {
        "precision": 0.733383,
        "recall": 0.783175,
        "f1": 0.747709,
        "accuracy": 0.783175,
        "main_score": 0.747709,
        "hf_subset": "afr_Latn-eng_Latn",
        "languages": [
          "afr-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.07205,
        "recall": 0.088132,
        "f1": 0.075641,
        "accuracy": 0.088132,
        "main_score": 0.075641,
        "hf_subset": "amh_Ethi-eng_Latn",
        "languages": [
          "amh-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.055009,
        "recall": 0.072609,
        "f1": 0.05833,
        "accuracy": 0.072609,
        "main_score": 0.05833,
        "hf_subset": "arb_Arab-eng_Latn",
        "languages": [
          "arb-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.381713,
        "recall": 0.455684,
        "f1": 0.401518,
        "accuracy": 0.455684,
        "main_score": 0.401518,
        "hf_subset": "aze_Latn-eng_Latn",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.161237,
        "recall": 0.218327,
        "f1": 0.174278,
        "accuracy": 0.218327,
        "main_score": 0.174278,
        "hf_subset": "bak_Cyrl-eng_Latn",
        "languages": [
          "bak-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.235436,
        "recall": 0.312969,
        "f1": 0.253212,
        "accuracy": 0.312969,
        "main_score": 0.253212,
        "hf_subset": "bel_Cyrl-eng_Latn",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.44044,
        "recall": 0.50025,
        "f1": 0.455669,
        "accuracy": 0.50025,
        "main_score": 0.455669,
        "hf_subset": "bem_Latn-eng_Latn",
        "languages": [
          "bem-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.029858,
        "recall": 0.041062,
        "f1": 0.031858,
        "accuracy": 0.041062,
        "main_score": 0.031858,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.165797,
        "recall": 0.196294,
        "f1": 0.173501,
        "accuracy": 0.196294,
        "main_score": 0.173501,
        "hf_subset": "bod_Tibt-eng_Latn",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.581145,
        "recall": 0.653981,
        "f1": 0.602148,
        "accuracy": 0.653981,
        "main_score": 0.602148,
        "hf_subset": "bos_Latn-eng_Latn",
        "languages": [
          "bos-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.289746,
        "recall": 0.361042,
        "f1": 0.306637,
        "accuracy": 0.361042,
        "main_score": 0.306637,
        "hf_subset": "bul_Cyrl-eng_Latn",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.874033,
        "recall": 0.904357,
        "f1": 0.883389,
        "accuracy": 0.904357,
        "main_score": 0.883389,
        "hf_subset": "cat_Latn-eng_Latn",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.621703,
        "recall": 0.685028,
        "f1": 0.640148,
        "accuracy": 0.685028,
        "main_score": 0.640148,
        "hf_subset": "ces_Latn-eng_Latn",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020265,
        "recall": 0.028543,
        "f1": 0.02212,
        "accuracy": 0.028543,
        "main_score": 0.02212,
        "hf_subset": "ckb_Arab-eng_Latn",
        "languages": [
          "ckb-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.415425,
        "recall": 0.483225,
        "f1": 0.432886,
        "accuracy": 0.483225,
        "main_score": 0.432886,
        "hf_subset": "cym_Latn-eng_Latn",
        "languages": [
          "cym-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.727754,
        "recall": 0.783175,
        "f1": 0.743635,
        "accuracy": 0.783175,
        "main_score": 0.743635,
        "hf_subset": "dan_Latn-eng_Latn",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.875175,
        "recall": 0.90636,
        "f1": 0.884681,
        "accuracy": 0.90636,
        "main_score": 0.884681,
        "hf_subset": "deu_Latn-eng_Latn",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01403,
        "recall": 0.025538,
        "f1": 0.015863,
        "accuracy": 0.025538,
        "main_score": 0.015863,
        "hf_subset": "div_Thaa-eng_Latn",
        "languages": [
          "div-Thaa",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009809,
        "recall": 0.02003,
        "f1": 0.011246,
        "accuracy": 0.02003,
        "main_score": 0.011246,
        "hf_subset": "dzo_Tibt-eng_Latn",
        "languages": [
          "dzo-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.155567,
        "recall": 0.196795,
        "f1": 0.16424,
        "accuracy": 0.196795,
        "main_score": 0.16424,
        "hf_subset": "ell_Grek-eng_Latn",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.624646,
        "recall": 0.71357,
        "f1": 0.649725,
        "accuracy": 0.71357,
        "main_score": 0.649725,
        "hf_subset": "eng_Latn-afr_Latn",
        "languages": [
          "eng-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.034171,
        "recall": 0.103155,
        "f1": 0.045054,
        "accuracy": 0.103155,
        "main_score": 0.045054,
        "hf_subset": "eng_Latn-amh_Ethi",
        "languages": [
          "eng-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.077632,
        "recall": 0.131698,
        "f1": 0.087506,
        "accuracy": 0.131698,
        "main_score": 0.087506,
        "hf_subset": "eng_Latn-arb_Arab",
        "languages": [
          "eng-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.285161,
        "recall": 0.398097,
        "f1": 0.311881,
        "accuracy": 0.398097,
        "main_score": 0.311881,
        "hf_subset": "eng_Latn-aze_Latn",
        "languages": [
          "eng-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.13061,
        "recall": 0.20681,
        "f1": 0.145486,
        "accuracy": 0.20681,
        "main_score": 0.145486,
        "hf_subset": "eng_Latn-bak_Cyrl",
        "languages": [
          "eng-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.184679,
        "recall": 0.277917,
        "f1": 0.204404,
        "accuracy": 0.277917,
        "main_score": 0.204404,
        "hf_subset": "eng_Latn-bel_Cyrl",
        "languages": [
          "eng-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.305804,
        "recall": 0.421132,
        "f1": 0.333852,
        "accuracy": 0.421132,
        "main_score": 0.333852,
        "hf_subset": "eng_Latn-bem_Latn",
        "languages": [
          "eng-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.043288,
        "recall": 0.082624,
        "f1": 0.049473,
        "accuracy": 0.082624,
        "main_score": 0.049473,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.098593,
        "recall": 0.198798,
        "f1": 0.117823,
        "accuracy": 0.198798,
        "main_score": 0.117823,
        "hf_subset": "eng_Latn-bod_Tibt",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.490912,
        "recall": 0.593891,
        "f1": 0.519187,
        "accuracy": 0.593891,
        "main_score": 0.519187,
        "hf_subset": "eng_Latn-bos_Latn",
        "languages": [
          "eng-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.260683,
        "recall": 0.359039,
        "f1": 0.282831,
        "accuracy": 0.359039,
        "main_score": 0.282831,
        "hf_subset": "eng_Latn-bul_Cyrl",
        "languages": [
          "eng-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.802946,
        "recall": 0.856284,
        "f1": 0.81929,
        "accuracy": 0.856284,
        "main_score": 0.81929,
        "hf_subset": "eng_Latn-cat_Latn",
        "languages": [
          "eng-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.489298,
        "recall": 0.593891,
        "f1": 0.517556,
        "accuracy": 0.593891,
        "main_score": 0.517556,
        "hf_subset": "eng_Latn-ces_Latn",
        "languages": [
          "eng-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.016442,
        "recall": 0.042063,
        "f1": 0.019733,
        "accuracy": 0.042063,
        "main_score": 0.019733,
        "hf_subset": "eng_Latn-ckb_Arab",
        "languages": [
          "eng-Latn",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.317077,
        "recall": 0.435153,
        "f1": 0.34662,
        "accuracy": 0.435153,
        "main_score": 0.34662,
        "hf_subset": "eng_Latn-cym_Latn",
        "languages": [
          "eng-Latn",
          "cym-Latn"
        ]
      },
      {
        "precision": 0.631529,
        "recall": 0.715573,
        "f1": 0.655061,
        "accuracy": 0.715573,
        "main_score": 0.655061,
        "hf_subset": "eng_Latn-dan_Latn",
        "languages": [
          "eng-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.819421,
        "recall": 0.871307,
        "f1": 0.83542,
        "accuracy": 0.871307,
        "main_score": 0.83542,
        "hf_subset": "eng_Latn-deu_Latn",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.027047,
        "recall": 0.048573,
        "f1": 0.030242,
        "accuracy": 0.048573,
        "main_score": 0.030242,
        "hf_subset": "eng_Latn-div_Thaa",
        "languages": [
          "eng-Latn",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.017213,
        "recall": 0.038558,
        "f1": 0.020242,
        "accuracy": 0.038558,
        "main_score": 0.020242,
        "hf_subset": "eng_Latn-dzo_Tibt",
        "languages": [
          "eng-Latn",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.121589,
        "recall": 0.208813,
        "f1": 0.138482,
        "accuracy": 0.208813,
        "main_score": 0.138482,
        "hf_subset": "eng_Latn-ell_Grek",
        "languages": [
          "eng-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.37776,
        "recall": 0.492238,
        "f1": 0.40775,
        "accuracy": 0.492238,
        "main_score": 0.40775,
        "hf_subset": "eng_Latn-eus_Latn",
        "languages": [
          "eng-Latn",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.285453,
        "recall": 0.403105,
        "f1": 0.315052,
        "accuracy": 0.403105,
        "main_score": 0.315052,
        "hf_subset": "eng_Latn-ewe_Latn",
        "languages": [
          "eng-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.373104,
        "recall": 0.483726,
        "f1": 0.40111,
        "accuracy": 0.483726,
        "main_score": 0.40111,
        "hf_subset": "eng_Latn-fao_Latn",
        "languages": [
          "eng-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.106566,
        "recall": 0.2003,
        "f1": 0.124355,
        "accuracy": 0.2003,
        "main_score": 0.124355,
        "hf_subset": "eng_Latn-fas_Arab",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.186842,
        "recall": 0.295944,
        "f1": 0.211444,
        "accuracy": 0.295944,
        "main_score": 0.211444,
        "hf_subset": "eng_Latn-fij_Latn",
        "languages": [
          "eng-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.610599,
        "recall": 0.698047,
        "f1": 0.635264,
        "accuracy": 0.698047,
        "main_score": 0.635264,
        "hf_subset": "eng_Latn-fil_Latn",
        "languages": [
          "eng-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.345128,
        "recall": 0.459189,
        "f1": 0.373523,
        "accuracy": 0.459189,
        "main_score": 0.373523,
        "hf_subset": "eng_Latn-fin_Latn",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.903063,
        "recall": 0.932399,
        "f1": 0.912485,
        "accuracy": 0.932399,
        "main_score": 0.912485,
        "hf_subset": "eng_Latn-fra_Latn",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.289714,
        "recall": 0.403605,
        "f1": 0.317495,
        "accuracy": 0.403605,
        "main_score": 0.317495,
        "hf_subset": "eng_Latn-fuc_Latn",
        "languages": [
          "eng-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.259686,
        "recall": 0.37306,
        "f1": 0.28711,
        "accuracy": 0.37306,
        "main_score": 0.28711,
        "hf_subset": "eng_Latn-gle_Latn",
        "languages": [
          "eng-Latn",
          "gle-Latn"
        ]
      },
      {
        "precision": 0.816972,
        "recall": 0.868302,
        "f1": 0.832583,
        "accuracy": 0.868302,
        "main_score": 0.832583,
        "hf_subset": "eng_Latn-glg_Latn",
        "languages": [
          "eng-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.025217,
        "recall": 0.054582,
        "f1": 0.029007,
        "accuracy": 0.054582,
        "main_score": 0.029007,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.257948,
        "recall": 0.376064,
        "f1": 0.285381,
        "accuracy": 0.376064,
        "main_score": 0.285381,
        "hf_subset": "eng_Latn-hau_Latn",
        "languages": [
          "eng-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.075963,
        "recall": 0.137707,
        "f1": 0.086296,
        "accuracy": 0.137707,
        "main_score": 0.086296,
        "hf_subset": "eng_Latn-heb_Hebr",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.109029,
        "recall": 0.175764,
        "f1": 0.121046,
        "accuracy": 0.175764,
        "main_score": 0.121046,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.225646,
        "recall": 0.341012,
        "f1": 0.25221,
        "accuracy": 0.341012,
        "main_score": 0.25221,
        "hf_subset": "eng_Latn-hmn_Latn",
        "languages": [
          "eng-Latn",
          "hmn-Latn"
        ]
      },
      {
        "precision": 0.476667,
        "recall": 0.57987,
        "f1": 0.504595,
        "accuracy": 0.57987,
        "main_score": 0.504595,
        "hf_subset": "eng_Latn-hrv_Latn",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.379012,
        "recall": 0.49324,
        "f1": 0.408859,
        "accuracy": 0.49324,
        "main_score": 0.408859,
        "hf_subset": "eng_Latn-hun_Latn",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.050979,
        "recall": 0.11317,
        "f1": 0.061091,
        "accuracy": 0.11317,
        "main_score": 0.061091,
        "hf_subset": "eng_Latn-hye_Armn",
        "languages": [
          "eng-Latn",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.310758,
        "recall": 0.428643,
        "f1": 0.340327,
        "accuracy": 0.428643,
        "main_score": 0.340327,
        "hf_subset": "eng_Latn-ibo_Latn",
        "languages": [
          "eng-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.528245,
        "recall": 0.625438,
        "f1": 0.554494,
        "accuracy": 0.625438,
        "main_score": 0.554494,
        "hf_subset": "eng_Latn-ind_Latn",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.319944,
        "recall": 0.435153,
        "f1": 0.348327,
        "accuracy": 0.435153,
        "main_score": 0.348327,
        "hf_subset": "eng_Latn-isl_Latn",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.889284,
        "recall": 0.920881,
        "f1": 0.899165,
        "accuracy": 0.920881,
        "main_score": 0.899165,
        "hf_subset": "eng_Latn-ita_Latn",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.283428,
        "recall": 0.38007,
        "f1": 0.305207,
        "accuracy": 0.38007,
        "main_score": 0.305207,
        "hf_subset": "eng_Latn-jpn_Jpan",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.031903,
        "recall": 0.072108,
        "f1": 0.037093,
        "accuracy": 0.072108,
        "main_score": 0.037093,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.051699,
        "recall": 0.117677,
        "f1": 0.062956,
        "accuracy": 0.117677,
        "main_score": 0.062956,
        "hf_subset": "eng_Latn-kat_Geor",
        "languages": [
          "eng-Latn",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.113489,
        "recall": 0.188282,
        "f1": 0.128639,
        "accuracy": 0.188282,
        "main_score": 0.128639,
        "hf_subset": "eng_Latn-kaz_Cyrl",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.229024,
        "recall": 0.342514,
        "f1": 0.25512,
        "accuracy": 0.342514,
        "main_score": 0.25512,
        "hf_subset": "eng_Latn-khm_Khmr",
        "languages": [
          "eng-Latn",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.240392,
        "recall": 0.357036,
        "f1": 0.267772,
        "accuracy": 0.357036,
        "main_score": 0.267772,
        "hf_subset": "eng_Latn-kin_Latn",
        "languages": [
          "eng-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.11782,
        "recall": 0.195794,
        "f1": 0.133019,
        "accuracy": 0.195794,
        "main_score": 0.133019,
        "hf_subset": "eng_Latn-kir_Cyrl",
        "languages": [
          "eng-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.274433,
        "recall": 0.387581,
        "f1": 0.301447,
        "accuracy": 0.387581,
        "main_score": 0.301447,
        "hf_subset": "eng_Latn-kmr_Latn",
        "languages": [
          "eng-Latn",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.100063,
        "recall": 0.184777,
        "f1": 0.115923,
        "accuracy": 0.184777,
        "main_score": 0.115923,
        "hf_subset": "eng_Latn-kor_Hang",
        "languages": [
          "eng-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.345795,
        "recall": 0.453681,
        "f1": 0.372433,
        "accuracy": 0.453681,
        "main_score": 0.372433,
        "hf_subset": "eng_Latn-lao_Laoo",
        "languages": [
          "eng-Latn",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.337634,
        "recall": 0.45318,
        "f1": 0.366742,
        "accuracy": 0.45318,
        "main_score": 0.366742,
        "hf_subset": "eng_Latn-lav_Latn",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.340872,
        "recall": 0.454682,
        "f1": 0.369971,
        "accuracy": 0.454682,
        "main_score": 0.369971,
        "hf_subset": "eng_Latn-lit_Latn",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.595041,
        "recall": 0.688533,
        "f1": 0.621144,
        "accuracy": 0.688533,
        "main_score": 0.621144,
        "hf_subset": "eng_Latn-ltz_Latn",
        "languages": [
          "eng-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.028396,
        "recall": 0.057586,
        "f1": 0.032365,
        "accuracy": 0.057586,
        "main_score": 0.032365,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.058282,
        "recall": 0.108663,
        "f1": 0.06641,
        "accuracy": 0.108663,
        "main_score": 0.06641,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.08666,
        "recall": 0.143716,
        "f1": 0.097829,
        "accuracy": 0.143716,
        "main_score": 0.097829,
        "hf_subset": "eng_Latn-mey_Arab",
        "languages": [
          "eng-Latn",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.256155,
        "recall": 0.344016,
        "f1": 0.275032,
        "accuracy": 0.344016,
        "main_score": 0.275032,
        "hf_subset": "eng_Latn-mkd_Cyrl",
        "languages": [
          "eng-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.246768,
        "recall": 0.362043,
        "f1": 0.27388,
        "accuracy": 0.362043,
        "main_score": 0.27388,
        "hf_subset": "eng_Latn-mlg_Latn",
        "languages": [
          "eng-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.526578,
        "recall": 0.623936,
        "f1": 0.552821,
        "accuracy": 0.623936,
        "main_score": 0.552821,
        "hf_subset": "eng_Latn-mlt_Latn",
        "languages": [
          "eng-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.095012,
        "recall": 0.167752,
        "f1": 0.10877,
        "accuracy": 0.167752,
        "main_score": 0.10877,
        "hf_subset": "eng_Latn-mon_Mong",
        "languages": [
          "eng-Latn",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.225971,
        "recall": 0.337006,
        "f1": 0.251703,
        "accuracy": 0.337006,
        "main_score": 0.251703,
        "hf_subset": "eng_Latn-mri_Latn",
        "languages": [
          "eng-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.46409,
        "recall": 0.563846,
        "f1": 0.490065,
        "accuracy": 0.563846,
        "main_score": 0.490065,
        "hf_subset": "eng_Latn-msa_Latn",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.111697,
        "recall": 0.208312,
        "f1": 0.130692,
        "accuracy": 0.208312,
        "main_score": 0.130692,
        "hf_subset": "eng_Latn-mya_Mymr",
        "languages": [
          "eng-Latn",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.149769,
        "recall": 0.249875,
        "f1": 0.169599,
        "accuracy": 0.249875,
        "main_score": 0.169599,
        "hf_subset": "eng_Latn-nde_Latn",
        "languages": [
          "eng-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.08294,
        "recall": 0.164747,
        "f1": 0.096488,
        "accuracy": 0.164747,
        "main_score": 0.096488,
        "hf_subset": "eng_Latn-nep_Deva",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.744471,
        "recall": 0.810716,
        "f1": 0.763946,
        "accuracy": 0.810716,
        "main_score": 0.763946,
        "hf_subset": "eng_Latn-nld_Latn",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.606963,
        "recall": 0.69304,
        "f1": 0.630589,
        "accuracy": 0.69304,
        "main_score": 0.630589,
        "hf_subset": "eng_Latn-nno_Latn",
        "languages": [
          "eng-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.631849,
        "recall": 0.716575,
        "f1": 0.655306,
        "accuracy": 0.716575,
        "main_score": 0.655306,
        "hf_subset": "eng_Latn-nob_Latn",
        "languages": [
          "eng-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.294069,
        "recall": 0.408112,
        "f1": 0.321564,
        "accuracy": 0.408112,
        "main_score": 0.321564,
        "hf_subset": "eng_Latn-nso_Latn",
        "languages": [
          "eng-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.265086,
        "recall": 0.385578,
        "f1": 0.293885,
        "accuracy": 0.385578,
        "main_score": 0.293885,
        "hf_subset": "eng_Latn-nya_Latn",
        "languages": [
          "eng-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.153358,
        "recall": 0.255383,
        "f1": 0.174884,
        "accuracy": 0.255383,
        "main_score": 0.174884,
        "hf_subset": "eng_Latn-orm_Ethi",
        "languages": [
          "eng-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.026395,
        "recall": 0.07311,
        "f1": 0.032357,
        "accuracy": 0.07311,
        "main_score": 0.032357,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.519455,
        "recall": 0.617927,
        "f1": 0.546395,
        "accuracy": 0.617927,
        "main_score": 0.546395,
        "hf_subset": "eng_Latn-pol_Latn",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.865815,
        "recall": 0.903355,
        "f1": 0.877259,
        "accuracy": 0.903355,
        "main_score": 0.877259,
        "hf_subset": "eng_Latn-por_Latn",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.088971,
        "recall": 0.145719,
        "f1": 0.099191,
        "accuracy": 0.145719,
        "main_score": 0.099191,
        "hf_subset": "eng_Latn-prs_Arab",
        "languages": [
          "eng-Latn",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.051687,
        "recall": 0.103155,
        "f1": 0.060586,
        "accuracy": 0.103155,
        "main_score": 0.060586,
        "hf_subset": "eng_Latn-pus_Arab",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.6793,
        "recall": 0.758638,
        "f1": 0.702505,
        "accuracy": 0.758638,
        "main_score": 0.702505,
        "hf_subset": "eng_Latn-ron_Latn",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.297371,
        "recall": 0.404607,
        "f1": 0.322301,
        "accuracy": 0.404607,
        "main_score": 0.322301,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.058361,
        "recall": 0.10015,
        "f1": 0.065629,
        "accuracy": 0.10015,
        "main_score": 0.065629,
        "hf_subset": "eng_Latn-shi_Arab",
        "languages": [
          "eng-Latn",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.029603,
        "recall": 0.065598,
        "f1": 0.034803,
        "accuracy": 0.065598,
        "main_score": 0.034803,
        "hf_subset": "eng_Latn-sin_Sinh",
        "languages": [
          "eng-Latn",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.48651,
        "recall": 0.59339,
        "f1": 0.515431,
        "accuracy": 0.59339,
        "main_score": 0.515431,
        "hf_subset": "eng_Latn-slk_Latn",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.411367,
        "recall": 0.523786,
        "f1": 0.441016,
        "accuracy": 0.523786,
        "main_score": 0.441016,
        "hf_subset": "eng_Latn-slv_Latn",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.262829,
        "recall": 0.372058,
        "f1": 0.288239,
        "accuracy": 0.372058,
        "main_score": 0.288239,
        "hf_subset": "eng_Latn-smo_Latn",
        "languages": [
          "eng-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.17419,
        "recall": 0.284427,
        "f1": 0.197528,
        "accuracy": 0.284427,
        "main_score": 0.197528,
        "hf_subset": "eng_Latn-sna_Latn",
        "languages": [
          "eng-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.052671,
        "recall": 0.104156,
        "f1": 0.060103,
        "accuracy": 0.104156,
        "main_score": 0.060103,
        "hf_subset": "eng_Latn-snd_Arab",
        "languages": [
          "eng-Latn",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.253337,
        "recall": 0.364547,
        "f1": 0.279228,
        "accuracy": 0.364547,
        "main_score": 0.279228,
        "hf_subset": "eng_Latn-som_Latn",
        "languages": [
          "eng-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.904845,
        "recall": 0.932899,
        "f1": 0.913829,
        "accuracy": 0.932899,
        "main_score": 0.913829,
        "hf_subset": "eng_Latn-spa_Latn",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.477317,
        "recall": 0.583375,
        "f1": 0.506051,
        "accuracy": 0.583375,
        "main_score": 0.506051,
        "hf_subset": "eng_Latn-sqi_Latn",
        "languages": [
          "eng-Latn",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.220954,
        "recall": 0.321983,
        "f1": 0.243579,
        "accuracy": 0.321983,
        "main_score": 0.243579,
        "hf_subset": "eng_Latn-srp_Cyrl",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.364989,
        "recall": 0.474712,
        "f1": 0.392333,
        "accuracy": 0.474712,
        "main_score": 0.392333,
        "hf_subset": "eng_Latn-srp_Latn",
        "languages": [
          "eng-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.232792,
        "recall": 0.349524,
        "f1": 0.260678,
        "accuracy": 0.349524,
        "main_score": 0.260678,
        "hf_subset": "eng_Latn-ssw_Latn",
        "languages": [
          "eng-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.268518,
        "recall": 0.381572,
        "f1": 0.295348,
        "accuracy": 0.381572,
        "main_score": 0.295348,
        "hf_subset": "eng_Latn-swa_Latn",
        "languages": [
          "eng-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.647584,
        "recall": 0.729094,
        "f1": 0.670594,
        "accuracy": 0.729094,
        "main_score": 0.670594,
        "hf_subset": "eng_Latn-swe_Latn",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.205867,
        "recall": 0.315473,
        "f1": 0.230711,
        "accuracy": 0.315473,
        "main_score": 0.230711,
        "hf_subset": "eng_Latn-tah_Latn",
        "languages": [
          "eng-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.05285,
        "recall": 0.111167,
        "f1": 0.061635,
        "accuracy": 0.111167,
        "main_score": 0.061635,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.105627,
        "recall": 0.176264,
        "f1": 0.118862,
        "accuracy": 0.176264,
        "main_score": 0.118862,
        "hf_subset": "eng_Latn-tat_Cyrl",
        "languages": [
          "eng-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.034847,
        "recall": 0.080621,
        "f1": 0.041388,
        "accuracy": 0.080621,
        "main_score": 0.041388,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.090156,
        "recall": 0.152228,
        "f1": 0.101504,
        "accuracy": 0.152228,
        "main_score": 0.101504,
        "hf_subset": "eng_Latn-tgk_Cyrl",
        "languages": [
          "eng-Latn",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.250404,
        "recall": 0.352028,
        "f1": 0.273534,
        "accuracy": 0.352028,
        "main_score": 0.273534,
        "hf_subset": "eng_Latn-tha_Thai",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.040114,
        "recall": 0.090135,
        "f1": 0.046968,
        "accuracy": 0.090135,
        "main_score": 0.046968,
        "hf_subset": "eng_Latn-tir_Ethi",
        "languages": [
          "eng-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.197042,
        "recall": 0.302954,
        "f1": 0.220106,
        "accuracy": 0.302954,
        "main_score": 0.220106,
        "hf_subset": "eng_Latn-ton_Latn",
        "languages": [
          "eng-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.258395,
        "recall": 0.374562,
        "f1": 0.285946,
        "accuracy": 0.374562,
        "main_score": 0.285946,
        "hf_subset": "eng_Latn-tsn_Latn",
        "languages": [
          "eng-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.285217,
        "recall": 0.399599,
        "f1": 0.313143,
        "accuracy": 0.399599,
        "main_score": 0.313143,
        "hf_subset": "eng_Latn-tuk_Latn",
        "languages": [
          "eng-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.410494,
        "recall": 0.516775,
        "f1": 0.438391,
        "accuracy": 0.516775,
        "main_score": 0.438391,
        "hf_subset": "eng_Latn-tur_Latn",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.058153,
        "recall": 0.111167,
        "f1": 0.066215,
        "accuracy": 0.111167,
        "main_score": 0.066215,
        "hf_subset": "eng_Latn-uig_Arab",
        "languages": [
          "eng-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.251961,
        "recall": 0.347021,
        "f1": 0.27306,
        "accuracy": 0.347021,
        "main_score": 0.27306,
        "hf_subset": "eng_Latn-ukr_Cyrl",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.06411,
        "recall": 0.12018,
        "f1": 0.072285,
        "accuracy": 0.12018,
        "main_score": 0.072285,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.21891,
        "recall": 0.320481,
        "f1": 0.240825,
        "accuracy": 0.320481,
        "main_score": 0.240825,
        "hf_subset": "eng_Latn-uzb_Latn",
        "languages": [
          "eng-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.274349,
        "recall": 0.395593,
        "f1": 0.303803,
        "accuracy": 0.395593,
        "main_score": 0.303803,
        "hf_subset": "eng_Latn-ven_Latn",
        "languages": [
          "eng-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.327812,
        "recall": 0.446169,
        "f1": 0.357467,
        "accuracy": 0.446169,
        "main_score": 0.357467,
        "hf_subset": "eng_Latn-vie_Latn",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.282705,
        "recall": 0.39359,
        "f1": 0.309973,
        "accuracy": 0.39359,
        "main_score": 0.309973,
        "hf_subset": "eng_Latn-wol_Latn",
        "languages": [
          "eng-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.160279,
        "recall": 0.268903,
        "f1": 0.182614,
        "accuracy": 0.268903,
        "main_score": 0.182614,
        "hf_subset": "eng_Latn-xho_Latn",
        "languages": [
          "eng-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.218473,
        "recall": 0.329995,
        "f1": 0.244086,
        "accuracy": 0.329995,
        "main_score": 0.244086,
        "hf_subset": "eng_Latn-yor_Latn",
        "languages": [
          "eng-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.18657,
        "recall": 0.277416,
        "f1": 0.206785,
        "accuracy": 0.277416,
        "main_score": 0.206785,
        "hf_subset": "eng_Latn-yue_Hant",
        "languages": [
          "eng-Latn",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.223919,
        "recall": 0.32699,
        "f1": 0.247818,
        "accuracy": 0.32699,
        "main_score": 0.247818,
        "hf_subset": "eng_Latn-zho_Hans",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.336413,
        "recall": 0.444667,
        "f1": 0.362839,
        "accuracy": 0.444667,
        "main_score": 0.362839,
        "hf_subset": "eng_Latn-zho_Hant",
        "languages": [
          "eng-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.265019,
        "recall": 0.38658,
        "f1": 0.294208,
        "accuracy": 0.38658,
        "main_score": 0.294208,
        "hf_subset": "eng_Latn-zul_Latn",
        "languages": [
          "eng-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.493232,
        "recall": 0.575864,
        "f1": 0.516006,
        "accuracy": 0.575864,
        "main_score": 0.516006,
        "hf_subset": "eus_Latn-eng_Latn",
        "languages": [
          "eus-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.392913,
        "recall": 0.457687,
        "f1": 0.409904,
        "accuracy": 0.457687,
        "main_score": 0.409904,
        "hf_subset": "ewe_Latn-eng_Latn",
        "languages": [
          "ewe-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.488564,
        "recall": 0.565348,
        "f1": 0.508839,
        "accuracy": 0.565348,
        "main_score": 0.508839,
        "hf_subset": "fao_Latn-eng_Latn",
        "languages": [
          "fao-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.161899,
        "recall": 0.197296,
        "f1": 0.170097,
        "accuracy": 0.197296,
        "main_score": 0.170097,
        "hf_subset": "fas_Arab-eng_Latn",
        "languages": [
          "fas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.300378,
        "recall": 0.36004,
        "f1": 0.31595,
        "accuracy": 0.36004,
        "main_score": 0.31595,
        "hf_subset": "fij_Latn-eng_Latn",
        "languages": [
          "fij-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.696237,
        "recall": 0.745118,
        "f1": 0.710354,
        "accuracy": 0.745118,
        "main_score": 0.710354,
        "hf_subset": "fil_Latn-eng_Latn",
        "languages": [
          "fil-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.446211,
        "recall": 0.524787,
        "f1": 0.467298,
        "accuracy": 0.524787,
        "main_score": 0.467298,
        "hf_subset": "fin_Latn-eng_Latn",
        "languages": [
          "fin-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.946443,
        "recall": 0.959439,
        "f1": 0.950454,
        "accuracy": 0.959439,
        "main_score": 0.950454,
        "hf_subset": "fra_Latn-eng_Latn",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.386618,
        "recall": 0.457186,
        "f1": 0.405471,
        "accuracy": 0.457186,
        "main_score": 0.405471,
        "hf_subset": "fuc_Latn-eng_Latn",
        "languages": [
          "fuc-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.350832,
        "recall": 0.427141,
        "f1": 0.369648,
        "accuracy": 0.427141,
        "main_score": 0.369648,
        "hf_subset": "gle_Latn-eng_Latn",
        "languages": [
          "gle-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.899473,
        "recall": 0.924387,
        "f1": 0.906935,
        "accuracy": 0.924387,
        "main_score": 0.906935,
        "hf_subset": "glg_Latn-eng_Latn",
        "languages": [
          "glg-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01756,
        "recall": 0.031047,
        "f1": 0.019507,
        "accuracy": 0.031047,
        "main_score": 0.019507,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.363899,
        "recall": 0.429144,
        "f1": 0.380925,
        "accuracy": 0.429144,
        "main_score": 0.380925,
        "hf_subset": "hau_Latn-eng_Latn",
        "languages": [
          "hau-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.095705,
        "recall": 0.130696,
        "f1": 0.102563,
        "accuracy": 0.130696,
        "main_score": 0.102563,
        "hf_subset": "heb_Hebr-eng_Latn",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.102737,
        "recall": 0.14021,
        "f1": 0.110285,
        "accuracy": 0.14021,
        "main_score": 0.110285,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.329411,
        "recall": 0.386079,
        "f1": 0.343481,
        "accuracy": 0.386079,
        "main_score": 0.343481,
        "hf_subset": "hmn_Latn-eng_Latn",
        "languages": [
          "hmn-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.574536,
        "recall": 0.645468,
        "f1": 0.594356,
        "accuracy": 0.645468,
        "main_score": 0.594356,
        "hf_subset": "hrv_Latn-eng_Latn",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.44211,
        "recall": 0.529795,
        "f1": 0.465959,
        "accuracy": 0.529795,
        "main_score": 0.465959,
        "hf_subset": "hun_Latn-eng_Latn",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.076234,
        "recall": 0.097646,
        "f1": 0.080836,
        "accuracy": 0.097646,
        "main_score": 0.080836,
        "hf_subset": "hye_Armn-eng_Latn",
        "languages": [
          "hye-Armn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.427061,
        "recall": 0.491738,
        "f1": 0.443859,
        "accuracy": 0.491738,
        "main_score": 0.443859,
        "hf_subset": "ibo_Latn-eng_Latn",
        "languages": [
          "ibo-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.605988,
        "recall": 0.669504,
        "f1": 0.623692,
        "accuracy": 0.669504,
        "main_score": 0.623692,
        "hf_subset": "ind_Latn-eng_Latn",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.412933,
        "recall": 0.489234,
        "f1": 0.432399,
        "accuracy": 0.489234,
        "main_score": 0.432399,
        "hf_subset": "isl_Latn-eng_Latn",
        "languages": [
          "isl-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.926061,
        "recall": 0.945418,
        "f1": 0.93209,
        "accuracy": 0.945418,
        "main_score": 0.93209,
        "hf_subset": "ita_Latn-eng_Latn",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.322004,
        "recall": 0.40661,
        "f1": 0.343214,
        "accuracy": 0.40661,
        "main_score": 0.343214,
        "hf_subset": "jpn_Jpan-eng_Latn",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026166,
        "recall": 0.041062,
        "f1": 0.028764,
        "accuracy": 0.041062,
        "main_score": 0.028764,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.069637,
        "recall": 0.09364,
        "f1": 0.074272,
        "accuracy": 0.09364,
        "main_score": 0.074272,
        "hf_subset": "kat_Geor-eng_Latn",
        "languages": [
          "kat-Geor",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.14464,
        "recall": 0.198798,
        "f1": 0.156636,
        "accuracy": 0.198798,
        "main_score": 0.156636,
        "hf_subset": "kaz_Cyrl-eng_Latn",
        "languages": [
          "kaz-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.295738,
        "recall": 0.34001,
        "f1": 0.307685,
        "accuracy": 0.34001,
        "main_score": 0.307685,
        "hf_subset": "khm_Khmr-eng_Latn",
        "languages": [
          "khm-Khmr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.345288,
        "recall": 0.412118,
        "f1": 0.362195,
        "accuracy": 0.412118,
        "main_score": 0.362195,
        "hf_subset": "kin_Latn-eng_Latn",
        "languages": [
          "kin-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.146414,
        "recall": 0.210315,
        "f1": 0.160329,
        "accuracy": 0.210315,
        "main_score": 0.160329,
        "hf_subset": "kir_Cyrl-eng_Latn",
        "languages": [
          "kir-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.37021,
        "recall": 0.44667,
        "f1": 0.390683,
        "accuracy": 0.44667,
        "main_score": 0.390683,
        "hf_subset": "kmr_Latn-eng_Latn",
        "languages": [
          "kmr-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.172034,
        "recall": 0.211818,
        "f1": 0.180262,
        "accuracy": 0.211818,
        "main_score": 0.180262,
        "hf_subset": "kor_Hang-eng_Latn",
        "languages": [
          "kor-Hang",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.382813,
        "recall": 0.439159,
        "f1": 0.397947,
        "accuracy": 0.439159,
        "main_score": 0.397947,
        "hf_subset": "lao_Laoo-eng_Latn",
        "languages": [
          "lao-Laoo",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.458772,
        "recall": 0.538808,
        "f1": 0.480423,
        "accuracy": 0.538808,
        "main_score": 0.480423,
        "hf_subset": "lav_Latn-eng_Latn",
        "languages": [
          "lav-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.453592,
        "recall": 0.531798,
        "f1": 0.474731,
        "accuracy": 0.531798,
        "main_score": 0.474731,
        "hf_subset": "lit_Latn-eng_Latn",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.716025,
        "recall": 0.769154,
        "f1": 0.730956,
        "accuracy": 0.769154,
        "main_score": 0.730956,
        "hf_subset": "ltz_Latn-eng_Latn",
        "languages": [
          "ltz-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020539,
        "recall": 0.036054,
        "f1": 0.023302,
        "accuracy": 0.036054,
        "main_score": 0.023302,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.060723,
        "recall": 0.081122,
        "f1": 0.064292,
        "accuracy": 0.081122,
        "main_score": 0.064292,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.044027,
        "recall": 0.067101,
        "f1": 0.048395,
        "accuracy": 0.067101,
        "main_score": 0.048395,
        "hf_subset": "mey_Arab-eng_Latn",
        "languages": [
          "mey-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.271476,
        "recall": 0.34001,
        "f1": 0.287447,
        "accuracy": 0.34001,
        "main_score": 0.287447,
        "hf_subset": "mkd_Cyrl-eng_Latn",
        "languages": [
          "mkd-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.356663,
        "recall": 0.427641,
        "f1": 0.375007,
        "accuracy": 0.427641,
        "main_score": 0.375007,
        "hf_subset": "mlg_Latn-eng_Latn",
        "languages": [
          "mlg-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.651553,
        "recall": 0.719579,
        "f1": 0.670563,
        "accuracy": 0.719579,
        "main_score": 0.670563,
        "hf_subset": "mlt_Latn-eng_Latn",
        "languages": [
          "mlt-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.121804,
        "recall": 0.175263,
        "f1": 0.133002,
        "accuracy": 0.175263,
        "main_score": 0.133002,
        "hf_subset": "mon_Mong-eng_Latn",
        "languages": [
          "mon-Mong",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.351366,
        "recall": 0.408112,
        "f1": 0.366051,
        "accuracy": 0.408112,
        "main_score": 0.366051,
        "hf_subset": "mri_Latn-eng_Latn",
        "languages": [
          "mri-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.558512,
        "recall": 0.62644,
        "f1": 0.577093,
        "accuracy": 0.62644,
        "main_score": 0.577093,
        "hf_subset": "msa_Latn-eng_Latn",
        "languages": [
          "msa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.177093,
        "recall": 0.206309,
        "f1": 0.185078,
        "accuracy": 0.206309,
        "main_score": 0.185078,
        "hf_subset": "mya_Mymr-eng_Latn",
        "languages": [
          "mya-Mymr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.256656,
        "recall": 0.297446,
        "f1": 0.267208,
        "accuracy": 0.297446,
        "main_score": 0.267208,
        "hf_subset": "nde_Latn-eng_Latn",
        "languages": [
          "nde-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.121272,
        "recall": 0.160741,
        "f1": 0.129517,
        "accuracy": 0.160741,
        "main_score": 0.129517,
        "hf_subset": "nep_Deva-eng_Latn",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.824779,
        "recall": 0.8668,
        "f1": 0.837462,
        "accuracy": 0.8668,
        "main_score": 0.837462,
        "hf_subset": "nld_Latn-eng_Latn",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.705884,
        "recall": 0.765148,
        "f1": 0.723318,
        "accuracy": 0.765148,
        "main_score": 0.723318,
        "hf_subset": "nno_Latn-eng_Latn",
        "languages": [
          "nno-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.726768,
        "recall": 0.77967,
        "f1": 0.74172,
        "accuracy": 0.77967,
        "main_score": 0.74172,
        "hf_subset": "nob_Latn-eng_Latn",
        "languages": [
          "nob-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.408143,
        "recall": 0.471708,
        "f1": 0.424799,
        "accuracy": 0.471708,
        "main_score": 0.424799,
        "hf_subset": "nso_Latn-eng_Latn",
        "languages": [
          "nso-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.38922,
        "recall": 0.458688,
        "f1": 0.407327,
        "accuracy": 0.458688,
        "main_score": 0.407327,
        "hf_subset": "nya_Latn-eng_Latn",
        "languages": [
          "nya-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.270291,
        "recall": 0.321983,
        "f1": 0.283713,
        "accuracy": 0.321983,
        "main_score": 0.283713,
        "hf_subset": "orm_Ethi-eng_Latn",
        "languages": [
          "orm-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.038814,
        "recall": 0.054081,
        "f1": 0.041837,
        "accuracy": 0.054081,
        "main_score": 0.041837,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.611475,
        "recall": 0.682524,
        "f1": 0.632199,
        "accuracy": 0.682524,
        "main_score": 0.632199,
        "hf_subset": "pol_Latn-eng_Latn",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.926921,
        "recall": 0.94692,
        "f1": 0.9332,
        "accuracy": 0.94692,
        "main_score": 0.9332,
        "hf_subset": "por_Latn-eng_Latn",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0932,
        "recall": 0.121182,
        "f1": 0.098684,
        "accuracy": 0.121182,
        "main_score": 0.098684,
        "hf_subset": "prs_Arab-eng_Latn",
        "languages": [
          "prs-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.056668,
        "recall": 0.077616,
        "f1": 0.06078,
        "accuracy": 0.077616,
        "main_score": 0.06078,
        "hf_subset": "pus_Arab-eng_Latn",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.786971,
        "recall": 0.830746,
        "f1": 0.800165,
        "accuracy": 0.830746,
        "main_score": 0.800165,
        "hf_subset": "ron_Latn-eng_Latn",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.339677,
        "recall": 0.419129,
        "f1": 0.359126,
        "accuracy": 0.419129,
        "main_score": 0.359126,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.036171,
        "recall": 0.050576,
        "f1": 0.038987,
        "accuracy": 0.050576,
        "main_score": 0.038987,
        "hf_subset": "shi_Arab-eng_Latn",
        "languages": [
          "shi-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.033119,
        "recall": 0.050576,
        "f1": 0.035703,
        "accuracy": 0.050576,
        "main_score": 0.035703,
        "hf_subset": "sin_Sinh-eng_Latn",
        "languages": [
          "sin-Sinh",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.597848,
        "recall": 0.667501,
        "f1": 0.617831,
        "accuracy": 0.667501,
        "main_score": 0.617831,
        "hf_subset": "slk_Latn-eng_Latn",
        "languages": [
          "slk-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.523054,
        "recall": 0.595894,
        "f1": 0.542854,
        "accuracy": 0.595894,
        "main_score": 0.542854,
        "hf_subset": "slv_Latn-eng_Latn",
        "languages": [
          "slv-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.38725,
        "recall": 0.448673,
        "f1": 0.403244,
        "accuracy": 0.448673,
        "main_score": 0.403244,
        "hf_subset": "smo_Latn-eng_Latn",
        "languages": [
          "smo-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.290556,
        "recall": 0.350025,
        "f1": 0.305339,
        "accuracy": 0.350025,
        "main_score": 0.305339,
        "hf_subset": "sna_Latn-eng_Latn",
        "languages": [
          "sna-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.055548,
        "recall": 0.077116,
        "f1": 0.059821,
        "accuracy": 0.077116,
        "main_score": 0.059821,
        "hf_subset": "snd_Arab-eng_Latn",
        "languages": [
          "snd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.374055,
        "recall": 0.438157,
        "f1": 0.3906,
        "accuracy": 0.438157,
        "main_score": 0.3906,
        "hf_subset": "som_Latn-eng_Latn",
        "languages": [
          "som-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.937423,
        "recall": 0.95343,
        "f1": 0.94229,
        "accuracy": 0.95343,
        "main_score": 0.94229,
        "hf_subset": "spa_Latn-eng_Latn",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.566066,
        "recall": 0.640961,
        "f1": 0.587348,
        "accuracy": 0.640961,
        "main_score": 0.587348,
        "hf_subset": "sqi_Latn-eng_Latn",
        "languages": [
          "sqi-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.249273,
        "recall": 0.320981,
        "f1": 0.265496,
        "accuracy": 0.320981,
        "main_score": 0.265496,
        "hf_subset": "srp_Cyrl-eng_Latn",
        "languages": [
          "srp-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.479047,
        "recall": 0.562344,
        "f1": 0.501801,
        "accuracy": 0.562344,
        "main_score": 0.501801,
        "hf_subset": "srp_Latn-eng_Latn",
        "languages": [
          "srp-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.347103,
        "recall": 0.406109,
        "f1": 0.362242,
        "accuracy": 0.406109,
        "main_score": 0.362242,
        "hf_subset": "ssw_Latn-eng_Latn",
        "languages": [
          "ssw-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.373662,
        "recall": 0.443665,
        "f1": 0.391354,
        "accuracy": 0.443665,
        "main_score": 0.391354,
        "hf_subset": "swa_Latn-eng_Latn",
        "languages": [
          "swa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.739548,
        "recall": 0.792689,
        "f1": 0.755053,
        "accuracy": 0.792689,
        "main_score": 0.755053,
        "hf_subset": "swe_Latn-eng_Latn",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.316688,
        "recall": 0.377066,
        "f1": 0.332395,
        "accuracy": 0.377066,
        "main_score": 0.332395,
        "hf_subset": "tah_Latn-eng_Latn",
        "languages": [
          "tah-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.056621,
        "recall": 0.082123,
        "f1": 0.06146,
        "accuracy": 0.082123,
        "main_score": 0.06146,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.145793,
        "recall": 0.207311,
        "f1": 0.159141,
        "accuracy": 0.207311,
        "main_score": 0.159141,
        "hf_subset": "tat_Cyrl-eng_Latn",
        "languages": [
          "tat-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.040063,
        "recall": 0.057086,
        "f1": 0.043424,
        "accuracy": 0.057086,
        "main_score": 0.043424,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.11551,
        "recall": 0.159239,
        "f1": 0.124821,
        "accuracy": 0.159239,
        "main_score": 0.124821,
        "hf_subset": "tgk_Cyrl-eng_Latn",
        "languages": [
          "tgk-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.290307,
        "recall": 0.336505,
        "f1": 0.302247,
        "accuracy": 0.336505,
        "main_score": 0.302247,
        "hf_subset": "tha_Thai-eng_Latn",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.055225,
        "recall": 0.077616,
        "f1": 0.059453,
        "accuracy": 0.077616,
        "main_score": 0.059453,
        "hf_subset": "tir_Ethi-eng_Latn",
        "languages": [
          "tir-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.281732,
        "recall": 0.339009,
        "f1": 0.294511,
        "accuracy": 0.339009,
        "main_score": 0.294511,
        "hf_subset": "ton_Latn-eng_Latn",
        "languages": [
          "ton-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.371443,
        "recall": 0.431147,
        "f1": 0.386656,
        "accuracy": 0.431147,
        "main_score": 0.386656,
        "hf_subset": "tsn_Latn-eng_Latn",
        "languages": [
          "tsn-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.365777,
        "recall": 0.444667,
        "f1": 0.385759,
        "accuracy": 0.444667,
        "main_score": 0.385759,
        "hf_subset": "tuk_Latn-eng_Latn",
        "languages": [
          "tuk-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.458567,
        "recall": 0.53981,
        "f1": 0.480618,
        "accuracy": 0.53981,
        "main_score": 0.480618,
        "hf_subset": "tur_Latn-eng_Latn",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.056316,
        "recall": 0.076114,
        "f1": 0.059755,
        "accuracy": 0.076114,
        "main_score": 0.059755,
        "hf_subset": "uig_Arab-eng_Latn",
        "languages": [
          "uig-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.282591,
        "recall": 0.361542,
        "f1": 0.300574,
        "accuracy": 0.361542,
        "main_score": 0.300574,
        "hf_subset": "ukr_Cyrl-eng_Latn",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.07874,
        "recall": 0.097646,
        "f1": 0.082245,
        "accuracy": 0.097646,
        "main_score": 0.082245,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.29376,
        "recall": 0.370556,
        "f1": 0.312871,
        "accuracy": 0.370556,
        "main_score": 0.312871,
        "hf_subset": "uzb_Latn-eng_Latn",
        "languages": [
          "uzb-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.392713,
        "recall": 0.450676,
        "f1": 0.407584,
        "accuracy": 0.450676,
        "main_score": 0.407584,
        "hf_subset": "ven_Latn-eng_Latn",
        "languages": [
          "ven-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.394463,
        "recall": 0.46019,
        "f1": 0.411961,
        "accuracy": 0.46019,
        "main_score": 0.411961,
        "hf_subset": "vie_Latn-eng_Latn",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.382306,
        "recall": 0.445669,
        "f1": 0.399102,
        "accuracy": 0.445669,
        "main_score": 0.399102,
        "hf_subset": "wol_Latn-eng_Latn",
        "languages": [
          "wol-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.292226,
        "recall": 0.342013,
        "f1": 0.30458,
        "accuracy": 0.342013,
        "main_score": 0.30458,
        "hf_subset": "xho_Latn-eng_Latn",
        "languages": [
          "xho-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.320061,
        "recall": 0.382073,
        "f1": 0.336264,
        "accuracy": 0.382073,
        "main_score": 0.336264,
        "hf_subset": "yor_Latn-eng_Latn",
        "languages": [
          "yor-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.212115,
        "recall": 0.302954,
        "f1": 0.23252,
        "accuracy": 0.302954,
        "main_score": 0.23252,
        "hf_subset": "yue_Hant-eng_Latn",
        "languages": [
          "yue-Hant",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.278446,
        "recall": 0.361042,
        "f1": 0.298197,
        "accuracy": 0.361042,
        "main_score": 0.298197,
        "hf_subset": "zho_Hans-eng_Latn",
        "languages": [
          "zho-Hans",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.441323,
        "recall": 0.529294,
        "f1": 0.464042,
        "accuracy": 0.529294,
        "main_score": 0.464042,
        "hf_subset": "zho_Hant-eng_Latn",
        "languages": [
          "zho-Hant",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.395989,
        "recall": 0.450676,
        "f1": 0.41028,
        "accuracy": 0.450676,
        "main_score": 0.41028,
        "hf_subset": "zul_Latn-eng_Latn",
        "languages": [
          "zul-Latn",
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 1512.4562702178955,
  "kg_co2_emissions": null,
  "mteb_dataset_name": "NTREXBitextMining"
}