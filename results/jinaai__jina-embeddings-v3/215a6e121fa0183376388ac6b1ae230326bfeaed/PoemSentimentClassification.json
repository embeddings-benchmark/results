{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 10.622982501983643,
  "kg_co2_emissions": null,
  "mteb_version": "1.18.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.614423076923077,
        "f1": 0.4590187573870935,
        "f1_weighted": 0.662143336788847,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.614423076923077,
        "scores_per_experiment": [
          {
            "accuracy": 0.625,
            "f1": 0.4371959310039805,
            "f1_weighted": 0.6709505664614024
          },
          {
            "accuracy": 0.6153846153846154,
            "f1": 0.46939398501271246,
            "f1_weighted": 0.6482328369309
          },
          {
            "accuracy": 0.5865384615384616,
            "f1": 0.4714238495540296,
            "f1_weighted": 0.6370893405769384
          },
          {
            "accuracy": 0.6153846153846154,
            "f1": 0.45924994762204063,
            "f1_weighted": 0.6673475801382778
          },
          {
            "accuracy": 0.6634615384615384,
            "f1": 0.4680922237661469,
            "f1_weighted": 0.7053543505025672
          },
          {
            "accuracy": 0.5961538461538461,
            "f1": 0.4535140730792905,
            "f1_weighted": 0.6487105237105237
          },
          {
            "accuracy": 0.5576923076923077,
            "f1": 0.41747364953886695,
            "f1_weighted": 0.6236596736596737
          },
          {
            "accuracy": 0.6730769230769231,
            "f1": 0.48393038617886175,
            "f1_weighted": 0.7100116283614759
          },
          {
            "accuracy": 0.5673076923076923,
            "f1": 0.4513420995435775,
            "f1_weighted": 0.6299257686456122
          },
          {
            "accuracy": 0.6442307692307693,
            "f1": 0.47857142857142854,
            "f1_weighted": 0.6801510989010988
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5666666666666667,
        "f1": 0.42300036080127273,
        "f1_weighted": 0.6170595973884636,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5666666666666667,
        "scores_per_experiment": [
          {
            "accuracy": 0.6285714285714286,
            "f1": 0.4810797485517071,
            "f1_weighted": 0.6808074049291847
          },
          {
            "accuracy": 0.5428571428571428,
            "f1": 0.4309380855050247,
            "f1_weighted": 0.5799528757168001
          },
          {
            "accuracy": 0.45714285714285713,
            "f1": 0.37534713736642156,
            "f1_weighted": 0.5143155482628057
          },
          {
            "accuracy": 0.5619047619047619,
            "f1": 0.43506006006006004,
            "f1_weighted": 0.6324753324753325
          },
          {
            "accuracy": 0.5904761904761905,
            "f1": 0.40641955276101616,
            "f1_weighted": 0.6343655904631513
          },
          {
            "accuracy": 0.6285714285714286,
            "f1": 0.4602518484871426,
            "f1_weighted": 0.6669763160519463
          },
          {
            "accuracy": 0.5714285714285714,
            "f1": 0.4466878402903811,
            "f1_weighted": 0.6257799671592774
          },
          {
            "accuracy": 0.5523809523809524,
            "f1": 0.36999546719514254,
            "f1_weighted": 0.5845614574046856
          },
          {
            "accuracy": 0.49523809523809526,
            "f1": 0.34236682334508417,
            "f1_weighted": 0.569086788652006
          },
          {
            "accuracy": 0.638095238095238,
            "f1": 0.4818570444507476,
            "f1_weighted": 0.6822746927694454
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}