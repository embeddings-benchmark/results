{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "evaluation_time": 1669.8070709705353,
  "kg_co2_emissions": null,
  "mteb_version": "1.18.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.11171875,
        "f1": 0.09740276046422339,
        "f1_weighted": 0.10493057406764247,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.11171875,
        "scores_per_experiment": [
          {
            "accuracy": 0.107421875,
            "f1": 0.09473745899837162,
            "f1_weighted": 0.09609382111777107
          },
          {
            "accuracy": 0.10986328125,
            "f1": 0.09680248257977392,
            "f1_weighted": 0.10185522306092659
          },
          {
            "accuracy": 0.09619140625,
            "f1": 0.09145399402795389,
            "f1_weighted": 0.08779607212578028
          },
          {
            "accuracy": 0.103515625,
            "f1": 0.0985856843136613,
            "f1_weighted": 0.09408820573944612
          },
          {
            "accuracy": 0.12646484375,
            "f1": 0.10546427303012272,
            "f1_weighted": 0.1248091762830787
          },
          {
            "accuracy": 0.119140625,
            "f1": 0.09798310415776788,
            "f1_weighted": 0.11285397301182779
          },
          {
            "accuracy": 0.10888671875,
            "f1": 0.09056674500616094,
            "f1_weighted": 0.1098264689034471
          },
          {
            "accuracy": 0.11376953125,
            "f1": 0.10169244895282238,
            "f1_weighted": 0.10431656012196774
          },
          {
            "accuracy": 0.11376953125,
            "f1": 0.09466905250268577,
            "f1_weighted": 0.10914658576635926
          },
          {
            "accuracy": 0.1181640625,
            "f1": 0.10207236107291351,
            "f1_weighted": 0.10851965454582016
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.119873046875,
        "f1": 0.09555012851319404,
        "f1_weighted": 0.11561146767089762,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ],
        "main_score": 0.119873046875,
        "scores_per_experiment": [
          {
            "accuracy": 0.1181640625,
            "f1": 0.08465031721451456,
            "f1_weighted": 0.11239959315236794
          },
          {
            "accuracy": 0.119140625,
            "f1": 0.10057068186966178,
            "f1_weighted": 0.11542811988235524
          },
          {
            "accuracy": 0.115234375,
            "f1": 0.09580121305749807,
            "f1_weighted": 0.10940791331719135
          },
          {
            "accuracy": 0.12353515625,
            "f1": 0.09786892382863598,
            "f1_weighted": 0.11324330565525849
          },
          {
            "accuracy": 0.1240234375,
            "f1": 0.09698916661314783,
            "f1_weighted": 0.12302996730661683
          },
          {
            "accuracy": 0.11669921875,
            "f1": 0.09057386588935139,
            "f1_weighted": 0.11289592845644894
          },
          {
            "accuracy": 0.11572265625,
            "f1": 0.09662595589431519,
            "f1_weighted": 0.11402412816697269
          },
          {
            "accuracy": 0.11376953125,
            "f1": 0.09237709985345423,
            "f1_weighted": 0.1108164840557268
          },
          {
            "accuracy": 0.12158203125,
            "f1": 0.09150548627572357,
            "f1_weighted": 0.11751122697600944
          },
          {
            "accuracy": 0.130859375,
            "f1": 0.10853857463563786,
            "f1_weighted": 0.1273580097400287
          }
        ]
      }
    ]
  },
  "task_name": "GreekLegalCodeClassification"
}