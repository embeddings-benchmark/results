{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQuestions",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 0.995074,
        "recall": 0.996716,
        "f1": 0.995621,
        "accuracy": 0.996716,
        "main_score": 0.995621,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.904397,
        "recall": 0.931493,
        "f1": 0.913088,
        "accuracy": 0.931493,
        "main_score": 0.913088,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.98195,
        "recall": 0.987137,
        "f1": 0.983645,
        "accuracy": 0.987137,
        "main_score": 0.983645,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.975418,
        "recall": 0.983038,
        "f1": 0.977876,
        "accuracy": 0.983038,
        "main_score": 0.977876,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.984954,
        "recall": 0.989583,
        "f1": 0.986497,
        "accuracy": 0.989583,
        "main_score": 0.986497,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.976551,
        "recall": 0.984127,
        "f1": 0.979076,
        "accuracy": 0.984127,
        "main_score": 0.979076,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.983287,
        "recall": 0.98804,
        "f1": 0.984821,
        "accuracy": 0.98804,
        "main_score": 0.984821,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.987616,
        "recall": 0.990712,
        "f1": 0.988648,
        "accuracy": 0.990712,
        "main_score": 0.988648,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.75641,
        "recall": 0.810989,
        "f1": 0.773626,
        "accuracy": 0.810989,
        "main_score": 0.773626,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.968254,
        "recall": 0.978836,
        "f1": 0.971781,
        "accuracy": 0.978836,
        "main_score": 0.971781,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.963567,
        "recall": 0.975358,
        "f1": 0.967409,
        "accuracy": 0.975358,
        "main_score": 0.967409,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.990909,
        "recall": 0.993939,
        "f1": 0.991919,
        "accuracy": 0.993939,
        "main_score": 0.991919,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.987793,
        "recall": 0.991549,
        "f1": 0.988967,
        "accuracy": 0.991549,
        "main_score": 0.988967,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.992528,
        "recall": 0.995019,
        "f1": 0.993358,
        "accuracy": 0.995019,
        "main_score": 0.993358,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.987156,
        "recall": 0.990826,
        "f1": 0.988379,
        "accuracy": 0.990826,
        "main_score": 0.988379,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.96556,
        "recall": 0.97561,
        "f1": 0.968722,
        "accuracy": 0.97561,
        "main_score": 0.968722,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.97978,
        "recall": 0.986135,
        "f1": 0.981802,
        "accuracy": 0.986135,
        "main_score": 0.981802,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.970342,
        "recall": 0.978723,
        "f1": 0.973082,
        "accuracy": 0.978723,
        "main_score": 0.973082,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.941441,
        "recall": 0.959459,
        "f1": 0.947072,
        "accuracy": 0.959459,
        "main_score": 0.947072,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.969894,
        "recall": 0.978585,
        "f1": 0.972688,
        "accuracy": 0.978585,
        "main_score": 0.972688,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.989714,
        "recall": 0.993143,
        "f1": 0.990857,
        "accuracy": 0.993143,
        "main_score": 0.990857,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.992515,
        "recall": 0.99501,
        "f1": 0.993347,
        "accuracy": 0.99501,
        "main_score": 0.993347,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.986783,
        "recall": 0.990793,
        "f1": 0.98812,
        "accuracy": 0.990793,
        "main_score": 0.98812,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.980177,
        "recall": 0.986474,
        "f1": 0.982198,
        "accuracy": 0.986474,
        "main_score": 0.982198,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.993663,
        "recall": 0.995688,
        "f1": 0.994316,
        "accuracy": 0.995688,
        "main_score": 0.994316,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.970803,
        "recall": 0.980292,
        "f1": 0.973966,
        "accuracy": 0.980292,
        "main_score": 0.973966,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.966851,
        "recall": 0.977901,
        "f1": 0.970534,
        "accuracy": 0.977901,
        "main_score": 0.970534,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.970687,
        "recall": 0.978988,
        "f1": 0.973411,
        "accuracy": 0.978988,
        "main_score": 0.973411,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.985623,
        "recall": 0.990415,
        "f1": 0.98722,
        "accuracy": 0.990415,
        "main_score": 0.98722,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.994275,
        "recall": 0.996183,
        "f1": 0.994911,
        "accuracy": 0.996183,
        "main_score": 0.994911,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.981935,
        "recall": 0.987747,
        "f1": 0.98382,
        "accuracy": 0.987747,
        "main_score": 0.98382,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.990536,
        "recall": 0.993691,
        "f1": 0.991588,
        "accuracy": 0.993691,
        "main_score": 0.991588,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.993626,
        "recall": 0.995751,
        "f1": 0.994334,
        "accuracy": 0.995751,
        "main_score": 0.994334,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.994297,
        "recall": 0.996198,
        "f1": 0.99493,
        "accuracy": 0.996198,
        "main_score": 0.99493,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.991313,
        "recall": 0.994208,
        "f1": 0.992278,
        "accuracy": 0.994208,
        "main_score": 0.992278,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.992228,
        "recall": 0.994819,
        "f1": 0.993092,
        "accuracy": 0.994819,
        "main_score": 0.993092,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.995614,
        "recall": 0.997076,
        "f1": 0.996101,
        "accuracy": 0.997076,
        "main_score": 0.996101,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.990635,
        "recall": 0.993757,
        "f1": 0.991675,
        "accuracy": 0.993757,
        "main_score": 0.991675,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.98603,
        "recall": 0.990687,
        "f1": 0.987582,
        "accuracy": 0.990687,
        "main_score": 0.987582,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.982702,
        "recall": 0.98682,
        "f1": 0.984075,
        "accuracy": 0.98682,
        "main_score": 0.984075,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.981221,
        "recall": 0.98748,
        "f1": 0.983307,
        "accuracy": 0.98748,
        "main_score": 0.983307,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.969136,
        "recall": 0.978261,
        "f1": 0.972091,
        "accuracy": 0.978261,
        "main_score": 0.972091,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.988269,
        "recall": 0.991658,
        "f1": 0.989399,
        "accuracy": 0.991658,
        "main_score": 0.989399,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.962132,
        "recall": 0.972504,
        "f1": 0.965509,
        "accuracy": 0.972504,
        "main_score": 0.965509,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.939024,
        "recall": 0.957317,
        "f1": 0.944783,
        "accuracy": 0.957317,
        "main_score": 0.944783,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.975527,
        "recall": 0.9827,
        "f1": 0.977918,
        "accuracy": 0.9827,
        "main_score": 0.977918,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.981657,
        "recall": 0.98654,
        "f1": 0.983241,
        "accuracy": 0.98654,
        "main_score": 0.983241,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.961831,
        "recall": 0.972628,
        "f1": 0.965328,
        "accuracy": 0.972628,
        "main_score": 0.965328,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.92381,
        "recall": 0.947253,
        "f1": 0.931136,
        "accuracy": 0.947253,
        "main_score": 0.931136,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.981914,
        "recall": 0.987345,
        "f1": 0.983659,
        "accuracy": 0.987345,
        "main_score": 0.983659,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.973855,
        "recall": 0.981732,
        "f1": 0.976357,
        "accuracy": 0.981732,
        "main_score": 0.976357,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.933155,
        "recall": 0.953654,
        "f1": 0.939691,
        "accuracy": 0.953654,
        "main_score": 0.939691,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.990819,
        "recall": 0.993644,
        "f1": 0.991702,
        "accuracy": 0.993644,
        "main_score": 0.991702,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.953073,
        "recall": 0.965932,
        "f1": 0.957047,
        "accuracy": 0.965932,
        "main_score": 0.957047,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.955434,
        "recall": 0.968622,
        "f1": 0.959527,
        "accuracy": 0.968622,
        "main_score": 0.959527,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.985099,
        "recall": 0.990066,
        "f1": 0.986755,
        "accuracy": 0.990066,
        "main_score": 0.986755,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.985507,
        "recall": 0.989967,
        "f1": 0.986901,
        "accuracy": 0.989967,
        "main_score": 0.986901,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.992823,
        "recall": 0.995215,
        "f1": 0.99362,
        "accuracy": 0.995215,
        "main_score": 0.99362,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.994902,
        "recall": 0.996601,
        "f1": 0.995468,
        "accuracy": 0.996601,
        "main_score": 0.995468,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.983821,
        "recall": 0.989163,
        "f1": 0.985589,
        "accuracy": 0.989163,
        "main_score": 0.985589,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.969271,
        "recall": 0.977906,
        "f1": 0.972076,
        "accuracy": 0.977906,
        "main_score": 0.972076,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.981651,
        "recall": 0.987768,
        "f1": 0.98369,
        "accuracy": 0.987768,
        "main_score": 0.98369,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.964423,
        "recall": 0.974332,
        "f1": 0.967653,
        "accuracy": 0.974332,
        "main_score": 0.967653,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.97904,
        "recall": 0.985606,
        "f1": 0.981191,
        "accuracy": 0.985606,
        "main_score": 0.981191,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.983289,
        "recall": 0.988091,
        "f1": 0.984825,
        "accuracy": 0.988091,
        "main_score": 0.984825,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.961905,
        "recall": 0.972551,
        "f1": 0.965325,
        "accuracy": 0.972551,
        "main_score": 0.965325,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.966878,
        "recall": 0.976121,
        "f1": 0.969786,
        "accuracy": 0.976121,
        "main_score": 0.969786,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.963675,
        "recall": 0.973397,
        "f1": 0.966788,
        "accuracy": 0.973397,
        "main_score": 0.966788,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.977195,
        "recall": 0.983365,
        "f1": 0.979178,
        "accuracy": 0.983365,
        "main_score": 0.979178,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.965259,
        "recall": 0.9758,
        "f1": 0.968673,
        "accuracy": 0.9758,
        "main_score": 0.968673,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.960884,
        "recall": 0.972789,
        "f1": 0.964853,
        "accuracy": 0.972789,
        "main_score": 0.964853,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.973918,
        "recall": 0.982062,
        "f1": 0.97656,
        "accuracy": 0.982062,
        "main_score": 0.97656,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.974611,
        "recall": 0.982478,
        "f1": 0.977173,
        "accuracy": 0.982478,
        "main_score": 0.977173,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.986885,
        "recall": 0.991017,
        "f1": 0.988202,
        "accuracy": 0.991017,
        "main_score": 0.988202,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.976809,
        "recall": 0.984186,
        "f1": 0.979238,
        "accuracy": 0.984186,
        "main_score": 0.979238,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.984816,
        "recall": 0.989161,
        "f1": 0.986196,
        "accuracy": 0.989161,
        "main_score": 0.986196,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.97309,
        "recall": 0.981458,
        "f1": 0.975831,
        "accuracy": 0.981458,
        "main_score": 0.975831,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.984696,
        "recall": 0.989605,
        "f1": 0.986313,
        "accuracy": 0.989605,
        "main_score": 0.986313,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.98463,
        "recall": 0.988473,
        "f1": 0.985591,
        "accuracy": 0.988473,
        "main_score": 0.985591,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.970671,
        "recall": 0.979602,
        "f1": 0.973594,
        "accuracy": 0.979602,
        "main_score": 0.973594,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.963727,
        "recall": 0.974666,
        "f1": 0.967295,
        "accuracy": 0.974666,
        "main_score": 0.967295,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.97498,
        "recall": 0.982017,
        "f1": 0.977261,
        "accuracy": 0.982017,
        "main_score": 0.977261,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.969349,
        "recall": 0.978213,
        "f1": 0.972223,
        "accuracy": 0.978213,
        "main_score": 0.972223,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.964299,
        "recall": 0.973293,
        "f1": 0.967071,
        "accuracy": 0.973293,
        "main_score": 0.967071,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.965757,
        "recall": 0.975934,
        "f1": 0.969053,
        "accuracy": 0.975934,
        "main_score": 0.969053,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.971917,
        "recall": 0.979824,
        "f1": 0.974428,
        "accuracy": 0.979824,
        "main_score": 0.974428,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.982185,
        "recall": 0.988124,
        "f1": 0.984165,
        "accuracy": 0.988124,
        "main_score": 0.984165,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.951768,
        "recall": 0.967846,
        "f1": 0.957128,
        "accuracy": 0.967846,
        "main_score": 0.957128,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.978006,
        "recall": 0.985337,
        "f1": 0.98045,
        "accuracy": 0.985337,
        "main_score": 0.98045,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.986339,
        "recall": 0.989071,
        "f1": 0.98725,
        "accuracy": 0.989071,
        "main_score": 0.98725,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.990385,
        "recall": 0.99359,
        "f1": 0.991453,
        "accuracy": 0.99359,
        "main_score": 0.991453,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.977365,
        "recall": 0.984498,
        "f1": 0.979731,
        "accuracy": 0.984498,
        "main_score": 0.979731,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.96976,
        "recall": 0.978537,
        "f1": 0.972602,
        "accuracy": 0.978537,
        "main_score": 0.972602,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.97549,
        "recall": 0.982424,
        "f1": 0.977762,
        "accuracy": 0.982424,
        "main_score": 0.977762,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.967956,
        "recall": 0.975595,
        "f1": 0.970363,
        "accuracy": 0.975595,
        "main_score": 0.970363,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.970502,
        "recall": 0.979073,
        "f1": 0.973271,
        "accuracy": 0.979073,
        "main_score": 0.973271,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.974944,
        "recall": 0.982071,
        "f1": 0.977246,
        "accuracy": 0.982071,
        "main_score": 0.977246,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.986612,
        "recall": 0.990991,
        "f1": 0.988051,
        "accuracy": 0.990991,
        "main_score": 0.988051,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.973038,
        "recall": 0.980202,
        "f1": 0.975383,
        "accuracy": 0.980202,
        "main_score": 0.975383,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.97481,
        "recall": 0.982341,
        "f1": 0.977228,
        "accuracy": 0.982341,
        "main_score": 0.977228,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.972789,
        "recall": 0.980848,
        "f1": 0.975458,
        "accuracy": 0.980848,
        "main_score": 0.975458,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.984819,
        "recall": 0.989156,
        "f1": 0.986232,
        "accuracy": 0.989156,
        "main_score": 0.986232,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.964655,
        "recall": 0.975668,
        "f1": 0.968225,
        "accuracy": 0.975668,
        "main_score": 0.968225,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.95877,
        "recall": 0.969547,
        "f1": 0.96204,
        "accuracy": 0.969547,
        "main_score": 0.96204,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.967089,
        "recall": 0.975797,
        "f1": 0.969907,
        "accuracy": 0.975797,
        "main_score": 0.969907,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.983412,
        "recall": 0.988626,
        "f1": 0.985097,
        "accuracy": 0.988626,
        "main_score": 0.985097,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.961996,
        "recall": 0.97158,
        "f1": 0.965065,
        "accuracy": 0.97158,
        "main_score": 0.965065,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.975535,
        "recall": 0.982591,
        "f1": 0.977845,
        "accuracy": 0.982591,
        "main_score": 0.977845,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.972363,
        "recall": 0.979929,
        "f1": 0.97474,
        "accuracy": 0.979929,
        "main_score": 0.97474,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.964321,
        "recall": 0.973333,
        "f1": 0.96718,
        "accuracy": 0.973333,
        "main_score": 0.96718,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.958736,
        "recall": 0.969824,
        "f1": 0.962194,
        "accuracy": 0.969824,
        "main_score": 0.962194,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.972207,
        "recall": 0.97973,
        "f1": 0.974539,
        "accuracy": 0.97973,
        "main_score": 0.974539,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.988501,
        "recall": 0.992334,
        "f1": 0.989779,
        "accuracy": 0.992334,
        "main_score": 0.989779,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.984099,
        "recall": 0.989399,
        "f1": 0.985866,
        "accuracy": 0.989399,
        "main_score": 0.985866,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.973361,
        "recall": 0.981557,
        "f1": 0.976093,
        "accuracy": 0.981557,
        "main_score": 0.976093,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.995122,
        "recall": 0.996748,
        "f1": 0.995664,
        "accuracy": 0.996748,
        "main_score": 0.995664,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.988991,
        "recall": 0.992661,
        "f1": 0.990214,
        "accuracy": 0.992661,
        "main_score": 0.990214,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.961111,
        "recall": 0.974074,
        "f1": 0.965432,
        "accuracy": 0.974074,
        "main_score": 0.965432,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.981796,
        "recall": 0.987864,
        "f1": 0.983819,
        "accuracy": 0.987864,
        "main_score": 0.983819,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.984536,
        "recall": 0.989691,
        "f1": 0.986254,
        "accuracy": 0.989691,
        "main_score": 0.986254,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.995588,
        "recall": 0.997059,
        "f1": 0.996078,
        "accuracy": 0.997059,
        "main_score": 0.996078,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.982911,
        "recall": 0.988608,
        "f1": 0.98481,
        "accuracy": 0.988608,
        "main_score": 0.98481,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.9864,
        "recall": 0.989614,
        "f1": 0.987389,
        "accuracy": 0.989614,
        "main_score": 0.987389,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.97179,
        "recall": 0.981193,
        "f1": 0.974924,
        "accuracy": 0.981193,
        "main_score": 0.974924,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.970259,
        "recall": 0.978413,
        "f1": 0.972885,
        "accuracy": 0.978413,
        "main_score": 0.972885,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.997512,
        "recall": 0.998342,
        "f1": 0.997789,
        "accuracy": 0.998342,
        "main_score": 0.997789,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.993416,
        "recall": 0.995611,
        "f1": 0.994148,
        "accuracy": 0.995611,
        "main_score": 0.994148,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.98656,
        "recall": 0.990624,
        "f1": 0.987889,
        "accuracy": 0.990624,
        "main_score": 0.987889,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.983073,
        "recall": 0.988715,
        "f1": 0.984954,
        "accuracy": 0.988715,
        "main_score": 0.984954,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.992009,
        "recall": 0.994437,
        "f1": 0.992804,
        "accuracy": 0.994437,
        "main_score": 0.992804,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.977338,
        "recall": 0.983821,
        "f1": 0.97944,
        "accuracy": 0.983821,
        "main_score": 0.97944,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.977308,
        "recall": 0.984337,
        "f1": 0.979597,
        "accuracy": 0.984337,
        "main_score": 0.979597,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.984349,
        "recall": 0.989247,
        "f1": 0.985962,
        "accuracy": 0.989247,
        "main_score": 0.985962,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.99404,
        "recall": 0.996026,
        "f1": 0.994702,
        "accuracy": 0.996026,
        "main_score": 0.994702,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 0.994604,
        "recall": 0.996403,
        "f1": 0.995204,
        "accuracy": 0.996403,
        "main_score": 0.995204,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.982743,
        "recall": 0.988092,
        "f1": 0.984481,
        "accuracy": 0.988092,
        "main_score": 0.984481,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.964498,
        "recall": 0.974737,
        "f1": 0.967763,
        "accuracy": 0.974737,
        "main_score": 0.967763,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.933428,
        "recall": 0.952381,
        "f1": 0.939229,
        "accuracy": 0.952381,
        "main_score": 0.939229,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.99294,
        "recall": 0.995043,
        "f1": 0.993616,
        "accuracy": 0.995043,
        "main_score": 0.993616,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.991071,
        "recall": 0.994048,
        "f1": 0.992063,
        "accuracy": 0.994048,
        "main_score": 0.992063,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.987185,
        "recall": 0.991304,
        "f1": 0.988558,
        "accuracy": 0.991304,
        "main_score": 0.988558,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.960273,
        "recall": 0.970469,
        "f1": 0.963376,
        "accuracy": 0.970469,
        "main_score": 0.963376,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.97486,
        "recall": 0.98324,
        "f1": 0.977654,
        "accuracy": 0.98324,
        "main_score": 0.977654,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.973779,
        "recall": 0.981639,
        "f1": 0.976283,
        "accuracy": 0.981639,
        "main_score": 0.976283,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.989296,
        "recall": 0.992382,
        "f1": 0.990299,
        "accuracy": 0.992382,
        "main_score": 0.990299,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.995665,
        "recall": 0.99711,
        "f1": 0.996146,
        "accuracy": 0.99711,
        "main_score": 0.996146,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.994462,
        "recall": 0.996091,
        "f1": 0.994983,
        "accuracy": 0.996091,
        "main_score": 0.994983,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.990269,
        "recall": 0.993513,
        "f1": 0.99135,
        "accuracy": 0.993513,
        "main_score": 0.99135,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.991139,
        "recall": 0.994093,
        "f1": 0.992124,
        "accuracy": 0.994093,
        "main_score": 0.992124,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.994643,
        "recall": 0.996429,
        "f1": 0.995238,
        "accuracy": 0.996429,
        "main_score": 0.995238,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.841329,
        "recall": 0.8742,
        "f1": 0.851142,
        "accuracy": 0.8742,
        "main_score": 0.851142,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.973217,
        "recall": 0.98149,
        "f1": 0.975891,
        "accuracy": 0.98149,
        "main_score": 0.975891,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.98157,
        "recall": 0.986872,
        "f1": 0.983183,
        "accuracy": 0.986872,
        "main_score": 0.983183,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.979613,
        "recall": 0.985149,
        "f1": 0.981324,
        "accuracy": 0.985149,
        "main_score": 0.981324,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.980926,
        "recall": 0.986297,
        "f1": 0.982613,
        "accuracy": 0.986297,
        "main_score": 0.982613,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.983657,
        "recall": 0.988483,
        "f1": 0.985192,
        "accuracy": 0.988483,
        "main_score": 0.985192,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.979405,
        "recall": 0.985363,
        "f1": 0.981278,
        "accuracy": 0.985363,
        "main_score": 0.981278,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.992869,
        "recall": 0.995063,
        "f1": 0.9936,
        "accuracy": 0.995063,
        "main_score": 0.9936,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.957609,
        "recall": 0.968966,
        "f1": 0.961149,
        "accuracy": 0.968966,
        "main_score": 0.961149,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.973837,
        "recall": 0.981606,
        "f1": 0.976333,
        "accuracy": 0.981606,
        "main_score": 0.976333,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.970297,
        "recall": 0.976898,
        "f1": 0.972497,
        "accuracy": 0.976898,
        "main_score": 0.972497,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.984777,
        "recall": 0.989509,
        "f1": 0.9863,
        "accuracy": 0.989509,
        "main_score": 0.9863,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.989111,
        "recall": 0.99274,
        "f1": 0.990321,
        "accuracy": 0.99274,
        "main_score": 0.990321,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.983047,
        "recall": 0.987715,
        "f1": 0.984439,
        "accuracy": 0.987715,
        "main_score": 0.984439,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.987625,
        "recall": 0.991316,
        "f1": 0.988819,
        "accuracy": 0.991316,
        "main_score": 0.988819,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.97095,
        "recall": 0.979619,
        "f1": 0.973681,
        "accuracy": 0.979619,
        "main_score": 0.973681,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.977612,
        "recall": 0.985075,
        "f1": 0.9801,
        "accuracy": 0.985075,
        "main_score": 0.9801,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.98899,
        "recall": 0.992089,
        "f1": 0.9899,
        "accuracy": 0.992089,
        "main_score": 0.9899,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.982288,
        "recall": 0.987699,
        "f1": 0.984069,
        "accuracy": 0.987699,
        "main_score": 0.984069,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 6984.561068058014,
  "kg_co2_emissions": null
}