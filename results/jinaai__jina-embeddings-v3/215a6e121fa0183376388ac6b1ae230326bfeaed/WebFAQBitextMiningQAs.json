{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQAs",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.93865,
        "recall": 0.953988,
        "f1": 0.943388,
        "accuracy": 0.953988,
        "main_score": 0.943388,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.996335,
        "recall": 0.99751,
        "f1": 0.996715,
        "accuracy": 0.99751,
        "main_score": 0.996715,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.995575,
        "recall": 0.99705,
        "f1": 0.996067,
        "accuracy": 0.99705,
        "main_score": 0.996067,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.99238,
        "recall": 0.994792,
        "f1": 0.993152,
        "accuracy": 0.994792,
        "main_score": 0.993152,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.994829,
        "recall": 0.995671,
        "f1": 0.99507,
        "accuracy": 0.995671,
        "main_score": 0.99507,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.98988,
        "recall": 0.99264,
        "f1": 0.9908,
        "accuracy": 0.99264,
        "main_score": 0.9908,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.991228,
        "recall": 0.993808,
        "f1": 0.992002,
        "accuracy": 0.993808,
        "main_score": 0.992002,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.77326,
        "recall": 0.817582,
        "f1": 0.787106,
        "accuracy": 0.817582,
        "main_score": 0.787106,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.979995,
        "recall": 0.986486,
        "f1": 0.982114,
        "accuracy": 0.986486,
        "main_score": 0.982114,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.995286,
        "recall": 0.996633,
        "f1": 0.995735,
        "accuracy": 0.996633,
        "main_score": 0.995735,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.996264,
        "recall": 0.997509,
        "f1": 0.996679,
        "accuracy": 0.997509,
        "main_score": 0.996679,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.989297,
        "recall": 0.992661,
        "f1": 0.990418,
        "accuracy": 0.992661,
        "main_score": 0.990418,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.964826,
        "recall": 0.974932,
        "f1": 0.967977,
        "accuracy": 0.974932,
        "main_score": 0.967977,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.990757,
        "recall": 0.993068,
        "f1": 0.991479,
        "accuracy": 0.993068,
        "main_score": 0.991479,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.981464,
        "recall": 0.98646,
        "f1": 0.983075,
        "accuracy": 0.98646,
        "main_score": 0.983075,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.974662,
        "recall": 0.983108,
        "f1": 0.977477,
        "accuracy": 0.983108,
        "main_score": 0.977477,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.967101,
        "recall": 0.976723,
        "f1": 0.970205,
        "accuracy": 0.976723,
        "main_score": 0.970205,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.998503,
        "recall": 0.999002,
        "f1": 0.998669,
        "accuracy": 0.999002,
        "main_score": 0.998669,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.995198,
        "recall": 0.996733,
        "f1": 0.995693,
        "accuracy": 0.996733,
        "main_score": 0.995693,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.989817,
        "recall": 0.993004,
        "f1": 0.990827,
        "accuracy": 0.993004,
        "main_score": 0.990827,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.998824,
        "recall": 0.999216,
        "f1": 0.998955,
        "accuracy": 0.999216,
        "main_score": 0.998955,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.977372,
        "recall": 0.984672,
        "f1": 0.979805,
        "accuracy": 0.984672,
        "main_score": 0.979805,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.983425,
        "recall": 0.98895,
        "f1": 0.985267,
        "accuracy": 0.98895,
        "main_score": 0.985267,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.985214,
        "recall": 0.989883,
        "f1": 0.98677,
        "accuracy": 0.989883,
        "main_score": 0.98677,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.977103,
        "recall": 0.984026,
        "f1": 0.979233,
        "accuracy": 0.984026,
        "main_score": 0.979233,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.997172,
        "recall": 0.998115,
        "f1": 0.997487,
        "accuracy": 0.998115,
        "main_score": 0.997487,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.995751,
        "recall": 0.997167,
        "f1": 0.996223,
        "accuracy": 0.997167,
        "main_score": 0.996223,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.997409,
        "recall": 0.998273,
        "f1": 0.997697,
        "accuracy": 0.998273,
        "main_score": 0.997697,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.998538,
        "recall": 0.999025,
        "f1": 0.9987,
        "accuracy": 0.999025,
        "main_score": 0.9987,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.998254,
        "recall": 0.998836,
        "f1": 0.998448,
        "accuracy": 0.998836,
        "main_score": 0.998448,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.987644,
        "recall": 0.991763,
        "f1": 0.989017,
        "accuracy": 0.991763,
        "main_score": 0.989017,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.997653,
        "recall": 0.998435,
        "f1": 0.997913,
        "accuracy": 0.998435,
        "main_score": 0.997913,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.981419,
        "recall": 0.986039,
        "f1": 0.982841,
        "accuracy": 0.986039,
        "main_score": 0.982841,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.999218,
        "recall": 0.999479,
        "f1": 0.999305,
        "accuracy": 0.999479,
        "main_score": 0.999305,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.961409,
        "recall": 0.971056,
        "f1": 0.964544,
        "accuracy": 0.971056,
        "main_score": 0.964544,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.955623,
        "recall": 0.969512,
        "f1": 0.960027,
        "accuracy": 0.969512,
        "main_score": 0.960027,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.981646,
        "recall": 0.987342,
        "f1": 0.983544,
        "accuracy": 0.987342,
        "main_score": 0.983544,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.990103,
        "recall": 0.992874,
        "f1": 0.991027,
        "accuracy": 0.992874,
        "main_score": 0.991027,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.962135,
        "recall": 0.972628,
        "f1": 0.965481,
        "accuracy": 0.972628,
        "main_score": 0.965481,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.945421,
        "recall": 0.962637,
        "f1": 0.950916,
        "accuracy": 0.962637,
        "main_score": 0.950916,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.992356,
        "recall": 0.994492,
        "f1": 0.993029,
        "accuracy": 0.994492,
        "main_score": 0.993029,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.982526,
        "recall": 0.988086,
        "f1": 0.984379,
        "accuracy": 0.988086,
        "main_score": 0.984379,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.958705,
        "recall": 0.97148,
        "f1": 0.962864,
        "accuracy": 0.97148,
        "main_score": 0.962864,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.994527,
        "recall": 0.995763,
        "f1": 0.99488,
        "accuracy": 0.995763,
        "main_score": 0.99488,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.961089,
        "recall": 0.971944,
        "f1": 0.964395,
        "accuracy": 0.971944,
        "main_score": 0.964395,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.959527,
        "recall": 0.971351,
        "f1": 0.963165,
        "accuracy": 0.971351,
        "main_score": 0.963165,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.997492,
        "recall": 0.998328,
        "f1": 0.99777,
        "accuracy": 0.998328,
        "main_score": 0.99777,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.995946,
        "recall": 0.997297,
        "f1": 0.996396,
        "accuracy": 0.997297,
        "main_score": 0.996396,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.994658,
        "recall": 0.996311,
        "f1": 0.995196,
        "accuracy": 0.996311,
        "main_score": 0.995196,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.979046,
        "recall": 0.984219,
        "f1": 0.980668,
        "accuracy": 0.984219,
        "main_score": 0.980668,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.986239,
        "recall": 0.990826,
        "f1": 0.987768,
        "accuracy": 0.990826,
        "main_score": 0.987768,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.977803,
        "recall": 0.983237,
        "f1": 0.979501,
        "accuracy": 0.983237,
        "main_score": 0.979501,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.986399,
        "recall": 0.990485,
        "f1": 0.987696,
        "accuracy": 0.990485,
        "main_score": 0.987696,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.982872,
        "recall": 0.987322,
        "f1": 0.984211,
        "accuracy": 0.987322,
        "main_score": 0.984211,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.971567,
        "recall": 0.978166,
        "f1": 0.973513,
        "accuracy": 0.978166,
        "main_score": 0.973513,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.966675,
        "recall": 0.975146,
        "f1": 0.969168,
        "accuracy": 0.975146,
        "main_score": 0.969168,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.974004,
        "recall": 0.979838,
        "f1": 0.97581,
        "accuracy": 0.979838,
        "main_score": 0.97581,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.986906,
        "recall": 0.990159,
        "f1": 0.98791,
        "accuracy": 0.990159,
        "main_score": 0.98791,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.996664,
        "recall": 0.997764,
        "f1": 0.997031,
        "accuracy": 0.997764,
        "main_score": 0.997031,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.97449,
        "recall": 0.982993,
        "f1": 0.977324,
        "accuracy": 0.982993,
        "main_score": 0.977324,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.995901,
        "recall": 0.997232,
        "f1": 0.996336,
        "accuracy": 0.997232,
        "main_score": 0.996336,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.997414,
        "recall": 0.998241,
        "f1": 0.997683,
        "accuracy": 0.998241,
        "main_score": 0.997683,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.993113,
        "recall": 0.995329,
        "f1": 0.993832,
        "accuracy": 0.995329,
        "main_score": 0.993832,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.995391,
        "recall": 0.996908,
        "f1": 0.995892,
        "accuracy": 0.996908,
        "main_score": 0.995892,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.99187,
        "recall": 0.994163,
        "f1": 0.992561,
        "accuracy": 0.994163,
        "main_score": 0.992561,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.995888,
        "recall": 0.997163,
        "f1": 0.996302,
        "accuracy": 0.997163,
        "main_score": 0.996302,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.998181,
        "recall": 0.998787,
        "f1": 0.998383,
        "accuracy": 0.998787,
        "main_score": 0.998383,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.987032,
        "recall": 0.991354,
        "f1": 0.988473,
        "accuracy": 0.991354,
        "main_score": 0.988473,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.990726,
        "recall": 0.993251,
        "f1": 0.991533,
        "accuracy": 0.993251,
        "main_score": 0.991533,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.992636,
        "recall": 0.994756,
        "f1": 0.993315,
        "accuracy": 0.994756,
        "main_score": 0.993315,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.979183,
        "recall": 0.984363,
        "f1": 0.980805,
        "accuracy": 0.984363,
        "main_score": 0.980805,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.988133,
        "recall": 0.991029,
        "f1": 0.989049,
        "accuracy": 0.991029,
        "main_score": 0.989049,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.971558,
        "recall": 0.977845,
        "f1": 0.973354,
        "accuracy": 0.977845,
        "main_score": 0.973354,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.990845,
        "recall": 0.993222,
        "f1": 0.991606,
        "accuracy": 0.993222,
        "main_score": 0.991606,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.983736,
        "recall": 0.987615,
        "f1": 0.984889,
        "accuracy": 0.987615,
        "main_score": 0.984889,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.989311,
        "recall": 0.992874,
        "f1": 0.990499,
        "accuracy": 0.992874,
        "main_score": 0.990499,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.985531,
        "recall": 0.990354,
        "f1": 0.987138,
        "accuracy": 0.990354,
        "main_score": 0.987138,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.991202,
        "recall": 0.994135,
        "f1": 0.99218,
        "accuracy": 0.994135,
        "main_score": 0.99218,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.995902,
        "recall": 0.997268,
        "f1": 0.996357,
        "accuracy": 0.997268,
        "main_score": 0.996357,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.990385,
        "recall": 0.99359,
        "f1": 0.991453,
        "accuracy": 0.99359,
        "main_score": 0.991453,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.991843,
        "recall": 0.994105,
        "f1": 0.992566,
        "accuracy": 0.994105,
        "main_score": 0.992566,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.975888,
        "recall": 0.982114,
        "f1": 0.977941,
        "accuracy": 0.982114,
        "main_score": 0.977941,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.989656,
        "recall": 0.992219,
        "f1": 0.990495,
        "accuracy": 0.992219,
        "main_score": 0.990495,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.973462,
        "recall": 0.978869,
        "f1": 0.975075,
        "accuracy": 0.978869,
        "main_score": 0.975075,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.987941,
        "recall": 0.990807,
        "f1": 0.988843,
        "accuracy": 0.990807,
        "main_score": 0.988843,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.984822,
        "recall": 0.98861,
        "f1": 0.985999,
        "accuracy": 0.98861,
        "main_score": 0.985999,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.987925,
        "recall": 0.991742,
        "f1": 0.989177,
        "accuracy": 0.991742,
        "main_score": 0.989177,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.986616,
        "recall": 0.98946,
        "f1": 0.987514,
        "accuracy": 0.98946,
        "main_score": 0.987514,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.976974,
        "recall": 0.983033,
        "f1": 0.978809,
        "accuracy": 0.983033,
        "main_score": 0.978809,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.988924,
        "recall": 0.991732,
        "f1": 0.989831,
        "accuracy": 0.991732,
        "main_score": 0.989831,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.990586,
        "recall": 0.992902,
        "f1": 0.991305,
        "accuracy": 0.992902,
        "main_score": 0.991305,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.974253,
        "recall": 0.981393,
        "f1": 0.976447,
        "accuracy": 0.981393,
        "main_score": 0.976447,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.963687,
        "recall": 0.971671,
        "f1": 0.965842,
        "accuracy": 0.971671,
        "main_score": 0.965842,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.973044,
        "recall": 0.979255,
        "f1": 0.975029,
        "accuracy": 0.979255,
        "main_score": 0.975029,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.989889,
        "recall": 0.993049,
        "f1": 0.99089,
        "accuracy": 0.993049,
        "main_score": 0.99089,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.968716,
        "recall": 0.975545,
        "f1": 0.970672,
        "accuracy": 0.975545,
        "main_score": 0.970672,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.990557,
        "recall": 0.992788,
        "f1": 0.991258,
        "accuracy": 0.992788,
        "main_score": 0.991258,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.979801,
        "recall": 0.984888,
        "f1": 0.981351,
        "accuracy": 0.984888,
        "main_score": 0.981351,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.970765,
        "recall": 0.976889,
        "f1": 0.972691,
        "accuracy": 0.976889,
        "main_score": 0.972691,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.964461,
        "recall": 0.973073,
        "f1": 0.967069,
        "accuracy": 0.973073,
        "main_score": 0.967069,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.981762,
        "recall": 0.985667,
        "f1": 0.9829,
        "accuracy": 0.985667,
        "main_score": 0.9829,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.998722,
        "recall": 0.999148,
        "f1": 0.998864,
        "accuracy": 0.999148,
        "main_score": 0.998864,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.99735,
        "recall": 0.998233,
        "f1": 0.997644,
        "accuracy": 0.998233,
        "main_score": 0.997644,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.997561,
        "recall": 0.998374,
        "f1": 0.997832,
        "accuracy": 0.998374,
        "main_score": 0.997832,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.996359,
        "recall": 0.997573,
        "f1": 0.996764,
        "accuracy": 0.997573,
        "main_score": 0.996764,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.992268,
        "recall": 0.994845,
        "f1": 0.993127,
        "accuracy": 0.994845,
        "main_score": 0.993127,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.998101,
        "recall": 0.998734,
        "f1": 0.998312,
        "accuracy": 0.998734,
        "main_score": 0.998312,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.997774,
        "recall": 0.998516,
        "f1": 0.998022,
        "accuracy": 0.998516,
        "main_score": 0.998022,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.989516,
        "recall": 0.992866,
        "f1": 0.990597,
        "accuracy": 0.992866,
        "main_score": 0.990597,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.985088,
        "recall": 0.988066,
        "f1": 0.985975,
        "accuracy": 0.988066,
        "main_score": 0.985975,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.997512,
        "recall": 0.998342,
        "f1": 0.997789,
        "accuracy": 0.998342,
        "main_score": 0.997789,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.998903,
        "recall": 0.999268,
        "f1": 0.999025,
        "accuracy": 0.999268,
        "main_score": 0.999025,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.99328,
        "recall": 0.995312,
        "f1": 0.993905,
        "accuracy": 0.995312,
        "main_score": 0.993905,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.998698,
        "recall": 0.999132,
        "f1": 0.998843,
        "accuracy": 0.999132,
        "main_score": 0.998843,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.998411,
        "recall": 0.99894,
        "f1": 0.998587,
        "accuracy": 0.99894,
        "main_score": 0.998587,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.983847,
        "recall": 0.987145,
        "f1": 0.984778,
        "accuracy": 0.987145,
        "main_score": 0.984778,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.998568,
        "recall": 0.999009,
        "f1": 0.998715,
        "accuracy": 0.999009,
        "main_score": 0.998715,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.994922,
        "recall": 0.996416,
        "f1": 0.9954,
        "accuracy": 0.996416,
        "main_score": 0.9954,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.997531,
        "recall": 0.998257,
        "f1": 0.997773,
        "accuracy": 0.998257,
        "main_score": 0.997773,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.993767,
        "recall": 0.995377,
        "f1": 0.994269,
        "accuracy": 0.995377,
        "main_score": 0.994269,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.945578,
        "recall": 0.960317,
        "f1": 0.949887,
        "accuracy": 0.960317,
        "main_score": 0.949887,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.996507,
        "recall": 0.997296,
        "f1": 0.996725,
        "accuracy": 0.997296,
        "main_score": 0.996725,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.995536,
        "recall": 0.997024,
        "f1": 0.996032,
        "accuracy": 0.997024,
        "main_score": 0.996032,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.995347,
        "recall": 0.996796,
        "f1": 0.995805,
        "accuracy": 0.996796,
        "main_score": 0.995805,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.965581,
        "recall": 0.973075,
        "f1": 0.967797,
        "accuracy": 0.973075,
        "main_score": 0.967797,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.99581,
        "recall": 0.997207,
        "f1": 0.996276,
        "accuracy": 0.997207,
        "main_score": 0.996276,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.990652,
        "recall": 0.992778,
        "f1": 0.991282,
        "accuracy": 0.992778,
        "main_score": 0.991282,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.997505,
        "recall": 0.998161,
        "f1": 0.997723,
        "accuracy": 0.998161,
        "main_score": 0.997723,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.995665,
        "recall": 0.99711,
        "f1": 0.996146,
        "accuracy": 0.99711,
        "main_score": 0.996146,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.99785,
        "recall": 0.998436,
        "f1": 0.998045,
        "accuracy": 0.998436,
        "main_score": 0.998045,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.99861,
        "recall": 0.999073,
        "f1": 0.998764,
        "accuracy": 0.999073,
        "main_score": 0.998764,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.998734,
        "recall": 0.999156,
        "f1": 0.998875,
        "accuracy": 0.999156,
        "main_score": 0.998875,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.836496,
        "recall": 0.867804,
        "f1": 0.845913,
        "accuracy": 0.867804,
        "main_score": 0.845913,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.992615,
        "recall": 0.99462,
        "f1": 0.993241,
        "accuracy": 0.99462,
        "main_score": 0.993241,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.985259,
        "recall": 0.988747,
        "f1": 0.986234,
        "accuracy": 0.988747,
        "main_score": 0.986234,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.986876,
        "recall": 0.989662,
        "f1": 0.987663,
        "accuracy": 0.989662,
        "main_score": 0.987663,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.989517,
        "recall": 0.991939,
        "f1": 0.990201,
        "accuracy": 0.991939,
        "main_score": 0.990201,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.986399,
        "recall": 0.990128,
        "f1": 0.987551,
        "accuracy": 0.990128,
        "main_score": 0.987551,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.989208,
        "recall": 0.991774,
        "f1": 0.989939,
        "accuracy": 0.991774,
        "main_score": 0.989939,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.999177,
        "recall": 0.999451,
        "f1": 0.999269,
        "accuracy": 0.999451,
        "main_score": 0.999269,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.96577,
        "recall": 0.973793,
        "f1": 0.968161,
        "accuracy": 0.973793,
        "main_score": 0.968161,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.992052,
        "recall": 0.993991,
        "f1": 0.99264,
        "accuracy": 0.993991,
        "main_score": 0.99264,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.985149,
        "recall": 0.990099,
        "f1": 0.986799,
        "accuracy": 0.990099,
        "main_score": 0.986799,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.993936,
        "recall": 0.99567,
        "f1": 0.99446,
        "accuracy": 0.99567,
        "main_score": 0.99446,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.981818,
        "recall": 0.986486,
        "f1": 0.98321,
        "accuracy": 0.986486,
        "main_score": 0.98321,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.992336,
        "recall": 0.994355,
        "f1": 0.992944,
        "accuracy": 0.994355,
        "main_score": 0.992944,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.984449,
        "recall": 0.988354,
        "f1": 0.985583,
        "accuracy": 0.988354,
        "main_score": 0.985583,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.994403,
        "recall": 0.996269,
        "f1": 0.995025,
        "accuracy": 0.996269,
        "main_score": 0.995025,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.995517,
        "recall": 0.996835,
        "f1": 0.995912,
        "accuracy": 0.996835,
        "main_score": 0.995912,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.995228,
        "recall": 0.996572,
        "f1": 0.995664,
        "accuracy": 0.996572,
        "main_score": 0.995664,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 7854.2025809288025,
  "kg_co2_emissions": null
}