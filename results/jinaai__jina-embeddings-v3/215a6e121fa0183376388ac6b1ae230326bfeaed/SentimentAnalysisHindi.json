{
  "dataset_revision": "1beac1b941da76a9c51e3e5b39d230fde9a80983",
  "evaluation_time": 4.252966642379761,
  "kg_co2_emissions": null,
  "mteb_version": "1.18.2",
  "scores": {
    "train": [
      {
        "accuracy": 0.665625,
        "f1": 0.6571603264331195,
        "f1_weighted": 0.6648379781608289,
        "hf_subset": "default",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.6571603264331195,
        "scores_per_experiment": [
          {
            "accuracy": 0.693359375,
            "f1": 0.6807123657033243,
            "f1_weighted": 0.6959274467893899
          },
          {
            "accuracy": 0.705078125,
            "f1": 0.6940867016056615,
            "f1_weighted": 0.7059751273102746
          },
          {
            "accuracy": 0.66552734375,
            "f1": 0.6559798371727935,
            "f1_weighted": 0.6674279185190207
          },
          {
            "accuracy": 0.59619140625,
            "f1": 0.5985759004806428,
            "f1_weighted": 0.5955584829619305
          },
          {
            "accuracy": 0.71240234375,
            "f1": 0.704747780109261,
            "f1_weighted": 0.7113570983740317
          },
          {
            "accuracy": 0.62646484375,
            "f1": 0.6085770290659828,
            "f1_weighted": 0.6008493966669392
          },
          {
            "accuracy": 0.65185546875,
            "f1": 0.6456472782717441,
            "f1_weighted": 0.6529834199290331
          },
          {
            "accuracy": 0.646484375,
            "f1": 0.6382898277778253,
            "f1_weighted": 0.6533126791661941
          },
          {
            "accuracy": 0.66259765625,
            "f1": 0.6470247056865635,
            "f1_weighted": 0.671748904417969
          },
          {
            "accuracy": 0.6962890625,
            "f1": 0.6979618384573957,
            "f1_weighted": 0.6932393074735056
          }
        ]
      }
    ]
  },
  "task_name": "SentimentAnalysisHindi"
}