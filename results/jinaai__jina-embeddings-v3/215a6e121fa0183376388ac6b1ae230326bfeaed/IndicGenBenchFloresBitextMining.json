{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "evaluation_time": 399.599981546402,
  "kg_co2_emissions": null,
  "mteb_version": "1.18.2",
  "scores": {
    "test": [
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167324,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9934123847167324,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167324,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9934123847167324,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433466,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433466,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167325,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9934123847167325,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9947299077733859,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9947299077733859,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9841897233201581,
        "f1": 0.9794795783926219,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9794795783926219,
        "precision": 0.9773550724637681,
        "recall": 0.9841897233201581
      },
      {
        "accuracy": 0.9664031620553359,
        "f1": 0.9556982872200264,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9556982872200264,
        "precision": 0.950592885375494,
        "recall": 0.9664031620553359
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9881422924901185,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9881422924901185,
        "precision": 0.9866600790513834,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9802371541501976,
        "f1": 0.9736495388669302,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9736495388669302,
        "precision": 0.9703557312252964,
        "recall": 0.9802371541501976
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9963768115942028,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9963768115942028,
        "precision": 0.9960474308300395,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9924242424242423,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9924242424242423,
        "precision": 0.991600790513834,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9920948616600791,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9920948616600791,
        "precision": 0.991106719367589,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167324,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167324,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9980237154150198,
        "f1": 0.997364953886693,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.997364953886693,
        "precision": 0.9970355731225297,
        "recall": 0.9980237154150198
      },
      {
        "accuracy": 0.9950592885375494,
        "f1": 0.9934123847167324,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9934123847167324,
        "precision": 0.9925889328063241,
        "recall": 0.9950592885375494
      },
      {
        "accuracy": 0.9871541501976284,
        "f1": 0.9830368906455862,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.9830368906455862,
        "precision": 0.9810606060606061,
        "recall": 0.9871541501976284
      },
      {
        "accuracy": 0.9723320158102767,
        "f1": 0.9636034255599474,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9636034255599474,
        "precision": 0.9593214756258234,
        "recall": 0.9723320158102767
      },
      {
        "accuracy": 0.9496047430830039,
        "f1": 0.9342885375494071,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9342885375494071,
        "precision": 0.9268774703557312,
        "recall": 0.9496047430830039
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9878787878787879,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9878787878787879,
        "precision": 0.986907114624506,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9856719367588933,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.9856719367588933,
        "precision": 0.9845191040843215,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.9990118577075099,
        "f1": 0.9986824769433464,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986824769433464,
        "precision": 0.9985177865612648,
        "recall": 0.9990118577075099
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.06225296442687747,
        "f1": 0.05195512572959307,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.05195512572959307,
        "precision": 0.04924386532303237,
        "recall": 0.06225296442687747
      },
      {
        "accuracy": 0.12450592885375494,
        "f1": 0.07216681794283067,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.07216681794283067,
        "precision": 0.06265583088909271,
        "recall": 0.12450592885375494
      },
      {
        "accuracy": 0.3438735177865613,
        "f1": 0.28890009519400556,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.28890009519400556,
        "precision": 0.27318244633149635,
        "recall": 0.3438735177865613
      },
      {
        "accuracy": 0.3774703557312253,
        "f1": 0.29422214807590297,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.29422214807590297,
        "precision": 0.2673607902856915,
        "recall": 0.3774703557312253
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9920948616600791,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9920948616600791,
        "precision": 0.991106719367589,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9868247694334651,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.9868247694334651,
        "precision": 0.9851778656126482,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.9179841897233202,
        "f1": 0.8943675889328062,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8943675889328062,
        "precision": 0.8835638998682478,
        "recall": 0.9179841897233202
      },
      {
        "accuracy": 0.8932806324110671,
        "f1": 0.8611330698287221,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8611330698287221,
        "precision": 0.8461791831357048,
        "recall": 0.8932806324110671
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9881422924901185,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9881422924901185,
        "precision": 0.9866600790513834,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9841897233201581,
        "f1": 0.9789196310935442,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9789196310935442,
        "precision": 0.9762845849802372,
        "recall": 0.9841897233201581
      },
      {
        "accuracy": 0.9940711462450593,
        "f1": 0.9920948616600791,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9920948616600791,
        "precision": 0.991106719367589,
        "recall": 0.9940711462450593
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9881422924901185,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.9881422924901185,
        "precision": 0.9866600790513834,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.9970355731225297,
        "f1": 0.9960474308300395,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9960474308300395,
        "precision": 0.9955533596837944,
        "recall": 0.9970355731225297
      },
      {
        "accuracy": 0.9901185770750988,
        "f1": 0.9868247694334651,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9868247694334651,
        "precision": 0.9851778656126482,
        "recall": 0.9901185770750988
      },
      {
        "accuracy": 0.31225296442687744,
        "f1": 0.2711554232516321,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.2711554232516321,
        "precision": 0.2604637337425459,
        "recall": 0.31225296442687744
      },
      {
        "accuracy": 0.33794466403162055,
        "f1": 0.24959619221242893,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.24959619221242893,
        "precision": 0.22386843406664378,
        "recall": 0.33794466403162055
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9947299077733861,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9947299077733861,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.9881422924901185,
        "f1": 0.9841897233201581,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9841897233201581,
        "precision": 0.9822134387351779,
        "recall": 0.9881422924901185
      },
      {
        "accuracy": 0.9960474308300395,
        "f1": 0.9947299077733861,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9947299077733861,
        "precision": 0.9940711462450593,
        "recall": 0.9960474308300395
      },
      {
        "accuracy": 0.991106719367589,
        "f1": 0.9881422924901185,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9881422924901185,
        "precision": 0.9866600790513834,
        "recall": 0.991106719367589
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.01153062208205368,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.01153062208205368,
        "precision": 0.010574271532309954,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.003626383193063275,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.003626383193063275,
        "precision": 0.0021283574700659805,
        "recall": 0.022727272727272728
      }
    ],
    "validation": [
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305584,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9986626546305584,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611167,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9973253092611167,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305584,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986626546305584,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9979939819458375,
        "f1": 0.9973253092611166,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.9973253092611166,
        "precision": 0.9969909729187563,
        "recall": 0.9979939819458375
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9948177866934135,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9948177866934135,
        "precision": 0.994316282179873,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222334,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9946506185222334,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222335,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.9946506185222335,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9933132731527917,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9933132731527917,
        "precision": 0.9924774322968907,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9919759277833501,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9919759277833501,
        "precision": 0.9909729187562688,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.9829488465396189,
        "f1": 0.9772651287194919,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9772651287194919,
        "precision": 0.9744232698094283,
        "recall": 0.9829488465396189
      },
      {
        "accuracy": 0.9699097291875627,
        "f1": 0.9607823470411234,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9607823470411234,
        "precision": 0.9566198595787362,
        "recall": 0.9699097291875627
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9909729187562688,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9909729187562688,
        "precision": 0.9899699097291875,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9759277833500501,
        "f1": 0.9679037111334002,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ],
        "main_score": 0.9679037111334002,
        "precision": 0.9638916750250752,
        "recall": 0.9759277833500501
      },
      {
        "accuracy": 0.9919759277833501,
        "f1": 0.9896355733868271,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9896355733868271,
        "precision": 0.9884653961885657,
        "recall": 0.9919759277833501
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9909729187562688,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ],
        "main_score": 0.9909729187562688,
        "precision": 0.9899699097291875,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.9963223002340353,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9963223002340353,
        "precision": 0.995987963891675,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9919759277833501,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.9919759277833501,
        "precision": 0.9909729187562688,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9989969909729187,
        "f1": 0.9986626546305583,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.9986626546305583,
        "precision": 0.9984954864593781,
        "recall": 0.9989969909729187
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9829488465396189,
        "f1": 0.9772651287194918,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ],
        "main_score": 0.9772651287194918,
        "precision": 0.9744232698094283,
        "recall": 0.9829488465396189
      },
      {
        "accuracy": 0.958876629889669,
        "f1": 0.9466399197592777,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9466399197592777,
        "precision": 0.9409896355733868,
        "recall": 0.958876629889669
      },
      {
        "accuracy": 0.9448345035105316,
        "f1": 0.9281176863925108,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9281176863925108,
        "precision": 0.9202607823470411,
        "recall": 0.9448345035105316
      },
      {
        "accuracy": 0.9949849548645938,
        "f1": 0.9939819458375125,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9939819458375125,
        "precision": 0.993480441323972,
        "recall": 0.9949849548645938
      },
      {
        "accuracy": 0.9879638916750251,
        "f1": 0.984620528251421,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ],
        "main_score": 0.984620528251421,
        "precision": 0.9829488465396189,
        "recall": 0.9879638916750251
      },
      {
        "accuracy": 0.9969909729187563,
        "f1": 0.995987963891675,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ],
        "main_score": 0.995987963891675,
        "precision": 0.9954864593781344,
        "recall": 0.9969909729187563
      },
      {
        "accuracy": 0.995987963891675,
        "f1": 0.9946506185222335,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ],
        "main_score": 0.9946506185222335,
        "precision": 0.9939819458375125,
        "recall": 0.995987963891675
      },
      {
        "accuracy": 0.0732196589769308,
        "f1": 0.06026291249608258,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ],
        "main_score": 0.06026291249608258,
        "precision": 0.05650398384886611,
        "recall": 0.0732196589769308
      },
      {
        "accuracy": 0.13139418254764293,
        "f1": 0.07022316824922582,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ],
        "main_score": 0.07022316824922582,
        "precision": 0.05841478343537769,
        "recall": 0.13139418254764293
      },
      {
        "accuracy": 0.35707121364092276,
        "f1": 0.308822316572886,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ],
        "main_score": 0.308822316572886,
        "precision": 0.2937931503431809,
        "recall": 0.35707121364092276
      },
      {
        "accuracy": 0.4012036108324975,
        "f1": 0.31562020753713477,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ],
        "main_score": 0.31562020753713477,
        "precision": 0.2865049513620226,
        "recall": 0.4012036108324975
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9859578736208626,
        "f1": 0.981444332998997,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ],
        "main_score": 0.981444332998997,
        "precision": 0.9792711467736542,
        "recall": 0.9859578736208626
      },
      {
        "accuracy": 0.905717151454363,
        "f1": 0.8821488274346849,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8821488274346849,
        "precision": 0.8722930696852461,
        "recall": 0.905717151454363
      },
      {
        "accuracy": 0.876629889669007,
        "f1": 0.8416248746238716,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8416248746238716,
        "precision": 0.8260113674356402,
        "recall": 0.876629889669007
      },
      {
        "accuracy": 0.9819458375125376,
        "f1": 0.9765964560347711,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9765964560347711,
        "precision": 0.9739217652958877,
        "recall": 0.9819458375125376
      },
      {
        "accuracy": 0.9729187562688064,
        "f1": 0.9656302240053493,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ],
        "main_score": 0.9656302240053493,
        "precision": 0.9623035773988633,
        "recall": 0.9729187562688064
      },
      {
        "accuracy": 0.9909729187562688,
        "f1": 0.9879638916750251,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9879638916750251,
        "precision": 0.9864593781344032,
        "recall": 0.9909729187562688
      },
      {
        "accuracy": 0.9879638916750251,
        "f1": 0.9839518555667001,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ],
        "main_score": 0.9839518555667001,
        "precision": 0.9819458375125376,
        "recall": 0.9879638916750251
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9939819458375125,
        "f1": 0.9919759277833501,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.9919759277833501,
        "precision": 0.9909729187562688,
        "recall": 0.9939819458375125
      },
      {
        "accuracy": 0.3069207622868606,
        "f1": 0.2679830795358813,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.2679830795358813,
        "precision": 0.2582923446771663,
        "recall": 0.3069207622868606
      },
      {
        "accuracy": 0.34904714142427284,
        "f1": 0.26233805654831893,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.26233805654831893,
        "precision": 0.23685423520959542,
        "recall": 0.34904714142427284
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9909729187562688,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9909729187562688,
        "precision": 0.9899699097291875,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9879638916750251,
        "f1": 0.9839518555667001,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ],
        "main_score": 0.9839518555667001,
        "precision": 0.9819458375125376,
        "recall": 0.9879638916750251
      },
      {
        "accuracy": 0.9929789368104313,
        "f1": 0.9906385824139085,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9906385824139085,
        "precision": 0.9894684052156469,
        "recall": 0.9929789368104313
      },
      {
        "accuracy": 0.9879638916750251,
        "f1": 0.9839518555667001,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ],
        "main_score": 0.9839518555667001,
        "precision": 0.9819458375125376,
        "recall": 0.9879638916750251
      },
      {
        "accuracy": 0.013039117352056168,
        "f1": 0.009495890130126436,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.009495890130126436,
        "precision": 0.0090980559335168,
        "recall": 0.013039117352056168
      },
      {
        "accuracy": 0.020060180541624874,
        "f1": 0.0028915084938133354,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0028915084938133354,
        "precision": 0.0020248878206575094,
        "recall": 0.020060180541624874
      }
    ]
  },
  "task_name": "IndicGenBenchFloresBitextMining"
}