{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 53.65869736671448,
  "kg_co2_emissions": null,
  "mteb_version": "1.18.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.4580078125,
        "f1": 0.394560172326142,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.394560172326142,
        "precision": 0.3728854595223506,
        "recall": 0.4580078125
      },
      {
        "accuracy": 0.9375,
        "f1": 0.9182942708333333,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9182942708333333,
        "precision": 0.9093424479166666,
        "recall": 0.9375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9910481770833333,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9910481770833333,
        "precision": 0.9900716145833334,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.876953125,
        "f1": 0.84306640625,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.84306640625,
        "precision": 0.8279947916666667,
        "recall": 0.876953125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666667,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.9869791666666667,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.7333984375,
        "f1": 0.6783931671626984,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.6783931671626984,
        "precision": 0.6561628069196428,
        "recall": 0.7333984375
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.96630859375,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.96630859375,
        "precision": 0.9622395833333333,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9837239583333333,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.9837239583333333,
        "precision": 0.9820963541666667,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9845377604166667,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.9845377604166667,
        "precision": 0.9827473958333334,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0002188105947871573,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0002188105947871573,
        "precision": 0.00011203853523719059,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9728190104166666,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.9728190104166666,
        "precision": 0.9695638020833334,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.958984375,
        "f1": 0.94580078125,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.94580078125,
        "precision": 0.939453125,
        "recall": 0.958984375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004310793698072789,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0004310793698072789,
        "precision": 0.00023751346383300338,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.833984375,
        "f1": 0.7951683407738095,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.7951683407738095,
        "precision": 0.7777018229166666,
        "recall": 0.833984375
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9851888020833333,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.9851888020833333,
        "precision": 0.9837239583333333,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9895833333333333,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.9895833333333333,
        "precision": 0.98828125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.4609375,
        "f1": 0.39213233677704035,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.39213233677704035,
        "precision": 0.3688175634586768,
        "recall": 0.4609375
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9407552083333333,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.9407552083333333,
        "precision": 0.9342447916666667,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8775390625,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.8775390625,
        "precision": 0.8657552083333333,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.7236328125,
        "f1": 0.6629115513392857,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.6629115513392857,
        "precision": 0.6388439360119048,
        "recall": 0.7236328125
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9925130208333333,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.9925130208333333,
        "precision": 0.99169921875,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.99365234375,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.99365234375,
        "precision": 0.9930013020833333,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00022861502818720078,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.00022861502818720078,
        "precision": 0.00011666601706855138,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.9617513020833333,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.9617513020833333,
        "precision": 0.9573567708333333,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 5.340167697765942e-05,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 5.340167697765942e-05,
        "precision": 2.7006836109807026e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.8623046875,
        "f1": 0.8293154761904762,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.8293154761904762,
        "precision": 0.8148437500000001,
        "recall": 0.8623046875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9912109375,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.9912109375,
        "precision": 0.990234375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.40234375,
        "f1": 0.355470536640319,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.355470536640319,
        "precision": 0.34109143429700983,
        "recall": 0.40234375
      },
      {
        "accuracy": 0.423828125,
        "f1": 0.36797401848152866,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.36797401848152866,
        "precision": 0.3519086725805276,
        "recall": 0.423828125
      },
      {
        "accuracy": 0.4677734375,
        "f1": 0.42143110211558205,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.42143110211558205,
        "precision": 0.40613935304005205,
        "recall": 0.4677734375
      },
      {
        "accuracy": 0.427734375,
        "f1": 0.38013024707101717,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.38013024707101717,
        "precision": 0.3668798282415509,
        "recall": 0.427734375
      },
      {
        "accuracy": 0.4560546875,
        "f1": 0.41819650405214515,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.41819650405214515,
        "precision": 0.4066158800509386,
        "recall": 0.4560546875
      },
      {
        "accuracy": 0.416015625,
        "f1": 0.3627994099117321,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.3627994099117321,
        "precision": 0.3468998020347607,
        "recall": 0.416015625
      },
      {
        "accuracy": 0.44140625,
        "f1": 0.383079985693227,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.383079985693227,
        "precision": 0.36590289704856144,
        "recall": 0.44140625
      },
      {
        "accuracy": 0.396484375,
        "f1": 0.3545290213258963,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.3545290213258963,
        "precision": 0.34239923031968855,
        "recall": 0.396484375
      },
      {
        "accuracy": 0.39453125,
        "f1": 0.3537454063406212,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3537454063406212,
        "precision": 0.3401007139456925,
        "recall": 0.39453125
      },
      {
        "accuracy": 0.4541015625,
        "f1": 0.4074371973614299,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.4074371973614299,
        "precision": 0.39241803788276675,
        "recall": 0.4541015625
      },
      {
        "accuracy": 0.421875,
        "f1": 0.36733490664710644,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.36733490664710644,
        "precision": 0.3499936670289004,
        "recall": 0.421875
      },
      {
        "accuracy": 0.4462890625,
        "f1": 0.38782658968195616,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.38782658968195616,
        "precision": 0.3694436411324629,
        "recall": 0.4462890625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002842382759954264,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002842382759954264,
        "precision": 0.0022039257818752198,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.4423828125,
        "f1": 0.38464543540227136,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.38464543540227136,
        "precision": 0.3667070916222849,
        "recall": 0.4423828125
      },
      {
        "accuracy": 0.3876953125,
        "f1": 0.3385545712518792,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.3385545712518792,
        "precision": 0.32365983313306385,
        "recall": 0.3876953125
      },
      {
        "accuracy": 0.4208984375,
        "f1": 0.3769266414637109,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.3769266414637109,
        "precision": 0.3634388136375588,
        "recall": 0.4208984375
      },
      {
        "accuracy": 0.412109375,
        "f1": 0.3580645254317392,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.3580645254317392,
        "precision": 0.3402547805549674,
        "recall": 0.412109375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014605611969805894,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0014605611969805894,
        "precision": 0.0012689784787735848,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.4794921875,
        "f1": 0.44531888060940794,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.44531888060940794,
        "precision": 0.4327521586381528,
        "recall": 0.4794921875
      },
      {
        "accuracy": 0.384765625,
        "f1": 0.34622778449871666,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.34622778449871666,
        "precision": 0.33366133548218724,
        "recall": 0.384765625
      },
      {
        "accuracy": 0.4384765625,
        "f1": 0.3888812343236743,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.3888812343236743,
        "precision": 0.3743297988903458,
        "recall": 0.4384765625
      },
      {
        "accuracy": 0.39453125,
        "f1": 0.34646076153403754,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.34646076153403754,
        "precision": 0.3325851596942721,
        "recall": 0.39453125
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9217122395833333,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9217122395833333,
        "precision": 0.9138997395833334,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.9560546875,
        "f1": 0.943359375,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.943359375,
        "precision": 0.9373372395833333,
        "recall": 0.9560546875
      },
      {
        "accuracy": 0.5048828125,
        "f1": 0.44878197160912003,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.44878197160912003,
        "precision": 0.4298900383470696,
        "recall": 0.5048828125
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.96337890625,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.96337890625,
        "precision": 0.9593098958333333,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.8731119791666666,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8731119791666666,
        "precision": 0.8614095052083334,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9509114583333333,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9509114583333333,
        "precision": 0.9463704427083333,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9715169270833334,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9715169270833334,
        "precision": 0.9680989583333333,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9494466145833332,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9494466145833332,
        "precision": 0.9444173177083334,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.732421875,
        "f1": 0.6760951450892858,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6760951450892858,
        "precision": 0.6534272693452381,
        "recall": 0.732421875
      },
      {
        "accuracy": 0.97265625,
        "f1": 0.9651692708333333,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9651692708333333,
        "precision": 0.9615885416666667,
        "recall": 0.97265625
      },
      {
        "accuracy": 0.951171875,
        "f1": 0.93701171875,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.93701171875,
        "precision": 0.9303385416666666,
        "recall": 0.951171875
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9547526041666666,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9547526041666666,
        "precision": 0.94970703125,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.000229013902661003,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.000229013902661003,
        "precision": 0.00011754602819055943,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.962890625,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.962890625,
        "precision": 0.95947265625,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.9501953125,
        "f1": 0.9362630208333333,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9362630208333333,
        "precision": 0.9296061197916667,
        "recall": 0.9501953125
      },
      {
        "accuracy": 0.953125,
        "f1": 0.93837890625,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.93837890625,
        "precision": 0.9312337239583333,
        "recall": 0.953125
      },
      {
        "accuracy": 0.90625,
        "f1": 0.8800130208333332,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.8800130208333332,
        "precision": 0.8681640625,
        "recall": 0.90625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0022659908736183407,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0022659908736183407,
        "precision": 0.0017074074180200576,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.8642578125,
        "f1": 0.8354352678571428,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8354352678571428,
        "precision": 0.822998046875,
        "recall": 0.8642578125
      },
      {
        "accuracy": 0.9462890625,
        "f1": 0.9315104166666666,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9315104166666666,
        "precision": 0.9247233072916666,
        "recall": 0.9462890625
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.94921875,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.94921875,
        "precision": 0.9435221354166667,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9537760416666667,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9537760416666667,
        "precision": 0.9484049479166666,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9817708333333334,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.9817708333333334,
        "precision": 0.9794921875,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.466796875,
        "f1": 0.3860205007665945,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.3860205007665945,
        "precision": 0.35806865389384923,
        "recall": 0.466796875
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9430338541666666,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.9430338541666666,
        "precision": 0.9361979166666666,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.9091796875,
        "f1": 0.8828125,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.8828125,
        "precision": 0.8710123697916666,
        "recall": 0.9091796875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.7421875,
        "f1": 0.6795782180059524,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.6795782180059524,
        "precision": 0.6541108630952381,
        "recall": 0.7421875
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.98583984375,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.98583984375,
        "precision": 0.9842122395833333,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9925130208333334,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.9925130208333334,
        "precision": 0.99169921875,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00010842784045345192,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.00010842784045345192,
        "precision": 5.500106239534699e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9657877604166667,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.9657877604166667,
        "precision": 0.9622395833333334,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0010948669413199383,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0010948669413199383,
        "precision": 0.0006258338529924671,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.875,
        "f1": 0.8411318824404761,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.8411318824404761,
        "precision": 0.8258300781250001,
        "recall": 0.875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9951171875,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.9951171875,
        "precision": 0.99462890625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.8896484375,
        "f1": 0.8642438616071428,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8642438616071428,
        "precision": 0.853173828125,
        "recall": 0.8896484375
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8986746651785715,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8986746651785715,
        "precision": 0.890537359775641,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.4912109375,
        "f1": 0.4351272388407462,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.4351272388407462,
        "precision": 0.4151767042636183,
        "recall": 0.4912109375
      },
      {
        "accuracy": 0.892578125,
        "f1": 0.8638671874999999,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8638671874999999,
        "precision": 0.8511067708333333,
        "recall": 0.892578125
      },
      {
        "accuracy": 0.919921875,
        "f1": 0.9009354848710318,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9009354848710318,
        "precision": 0.8931652250744047,
        "recall": 0.919921875
      },
      {
        "accuracy": 0.9287109375,
        "f1": 0.9108561197916667,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9108561197916667,
        "precision": 0.9031668526785714,
        "recall": 0.9287109375
      },
      {
        "accuracy": 0.9287109375,
        "f1": 0.9107445126488095,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9107445126488095,
        "precision": 0.9030529203869048,
        "recall": 0.9287109375
      },
      {
        "accuracy": 0.9140625,
        "f1": 0.8908528645833333,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8908528645833333,
        "precision": 0.880322265625,
        "recall": 0.9140625
      },
      {
        "accuracy": 0.689453125,
        "f1": 0.6392562624007936,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6392562624007936,
        "precision": 0.6192812965029761,
        "recall": 0.689453125
      },
      {
        "accuracy": 0.91796875,
        "f1": 0.8985026041666666,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8985026041666666,
        "precision": 0.8901638454861112,
        "recall": 0.91796875
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.883598400297619,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.883598400297619,
        "precision": 0.8743001302083333,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.9326171875,
        "f1": 0.9169131324404762,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9169131324404762,
        "precision": 0.9102213541666666,
        "recall": 0.9326171875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0008253735672099435,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0008253735672099435,
        "precision": 0.0005776185883258222,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.9267578125,
        "f1": 0.9080264136904763,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9080264136904763,
        "precision": 0.9001790364583334,
        "recall": 0.9267578125
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8704644097222222,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8704644097222222,
        "precision": 0.8599202473958334,
        "recall": 0.8955078125
      },
      {
        "accuracy": 0.8857421875,
        "f1": 0.8603376116071428,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8603376116071428,
        "precision": 0.849267578125,
        "recall": 0.8857421875
      },
      {
        "accuracy": 0.853515625,
        "f1": 0.8248697916666666,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.8248697916666666,
        "precision": 0.8124457465277778,
        "recall": 0.853515625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002030735894076832,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002030735894076832,
        "precision": 0.0014283689499497445,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.8203125,
        "f1": 0.7841471354166666,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.7841471354166666,
        "precision": 0.7683430989583333,
        "recall": 0.8203125
      },
      {
        "accuracy": 0.8818359375,
        "f1": 0.8590874565972222,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8590874565972222,
        "precision": 0.8493663969494047,
        "recall": 0.8818359375
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.8897321428571427,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8897321428571427,
        "precision": 0.8809895833333333,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.9111328125,
        "f1": 0.890966796875,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.890966796875,
        "precision": 0.8824032738095238,
        "recall": 0.9111328125
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9845377604166667,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.9845377604166667,
        "precision": 0.9827473958333333,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.4541015625,
        "f1": 0.3828818812863505,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.3828818812863505,
        "precision": 0.3589814794038427,
        "recall": 0.4541015625
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.933984375,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.933984375,
        "precision": 0.9266764322916666,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9169921875,
        "f1": 0.8954938616071428,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.8954938616071428,
        "precision": 0.8861490885416667,
        "recall": 0.9169921875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.72265625,
        "f1": 0.660439918154762,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.660439918154762,
        "precision": 0.634814453125,
        "recall": 0.72265625
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333333,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.9964192708333333,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0011595092640252702,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.0011595092640252702,
        "precision": 0.0007681155804760715,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9874674479166667,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.9874674479166667,
        "precision": 0.9861653645833333,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.9615885416666667,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.9615885416666667,
        "precision": 0.9571940104166666,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0007708116814637046,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.0007708116814637046,
        "precision": 0.0004399853632932574,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.8662109375,
        "f1": 0.8338541666666666,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.8338541666666666,
        "precision": 0.8191569010416666,
        "recall": 0.8662109375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333334,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.9886067708333334,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333334,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.9973958333333334,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9830729166666667,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9830729166666667,
        "precision": 0.98095703125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.486328125,
        "f1": 0.4144564997017892,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.4144564997017892,
        "precision": 0.3907689410741168,
        "recall": 0.486328125
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9537760416666667,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9537760416666667,
        "precision": 0.9485677083333334,
        "recall": 0.96484375
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.8793294270833334,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8793294270833334,
        "precision": 0.86787109375,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.7314453125,
        "f1": 0.6704876612103174,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6704876612103174,
        "precision": 0.6452880859375,
        "recall": 0.7314453125
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00022307137323841541,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00022307137323841541,
        "precision": 0.00011376598982480723,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9712565104166666,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.9712565104166666,
        "precision": 0.9683430989583333,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0007305947780468259,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0007305947780468259,
        "precision": 0.0004226785150873536,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.880859375,
        "f1": 0.84990234375,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.84990234375,
        "precision": 0.8360351562499999,
        "recall": 0.880859375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9925130208333333,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9925130208333333,
        "precision": 0.99169921875,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.416015625,
        "f1": 0.34699436385586435,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.34699436385586435,
        "precision": 0.32359890407986114,
        "recall": 0.416015625
      },
      {
        "accuracy": 0.947265625,
        "f1": 0.9308268229166666,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.9308268229166666,
        "precision": 0.9228515625,
        "recall": 0.947265625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8775716145833332,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.8775716145833332,
        "precision": 0.8659505208333333,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.7001953125,
        "f1": 0.6376232328869047,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.6376232328869047,
        "precision": 0.6127697172619049,
        "recall": 0.7001953125
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9939778645833333,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.9939778645833333,
        "precision": 0.9934895833333334,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0002454664808484865,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.0002454664808484865,
        "precision": 0.00012501173157038667,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9661458333333333,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.9661458333333333,
        "precision": 0.9625651041666666,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.000761092472320092,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.000761092472320092,
        "precision": 0.0004758329730731225,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.8486328125,
        "f1": 0.8139834449404761,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.8139834449404761,
        "precision": 0.7992513020833334,
        "recall": 0.8486328125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.9964192708333334,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.9964192708333334,
        "precision": 0.99609375,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.736328125,
        "f1": 0.6953587176384562,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.6953587176384562,
        "precision": 0.6795648484002976,
        "recall": 0.736328125
      },
      {
        "accuracy": 0.763671875,
        "f1": 0.7209383525545634,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.7209383525545634,
        "precision": 0.703909441380719,
        "recall": 0.763671875
      },
      {
        "accuracy": 0.4013671875,
        "f1": 0.3525924176192731,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.3525924176192731,
        "precision": 0.33381630174331156,
        "recall": 0.4013671875
      },
      {
        "accuracy": 0.7509765625,
        "f1": 0.7126589556277056,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.7126589556277056,
        "precision": 0.6974821085917919,
        "recall": 0.7509765625
      },
      {
        "accuracy": 0.77734375,
        "f1": 0.7416737546202956,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.7416737546202956,
        "precision": 0.7273961865526607,
        "recall": 0.77734375
      },
      {
        "accuracy": 0.7001953125,
        "f1": 0.6544239831349207,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.6544239831349207,
        "precision": 0.636444030145202,
        "recall": 0.7001953125
      },
      {
        "accuracy": 0.7607421875,
        "f1": 0.7190476190476189,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.7190476190476189,
        "precision": 0.7021071913819876,
        "recall": 0.7607421875
      },
      {
        "accuracy": 0.7666015625,
        "f1": 0.7308705959610564,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.7308705959610564,
        "precision": 0.7176741715315934,
        "recall": 0.7666015625
      },
      {
        "accuracy": 0.73828125,
        "f1": 0.6979583643353174,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.6979583643353174,
        "precision": 0.6821256868131869,
        "recall": 0.73828125
      },
      {
        "accuracy": 0.779296875,
        "f1": 0.7411179315476191,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.7411179315476191,
        "precision": 0.7258998325892857,
        "recall": 0.779296875
      },
      {
        "accuracy": 0.7431640625,
        "f1": 0.704111532456259,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.704111532456259,
        "precision": 0.6893491714719742,
        "recall": 0.7431640625
      },
      {
        "accuracy": 0.7548828125,
        "f1": 0.7190375434027778,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.7190375434027778,
        "precision": 0.7047278730384199,
        "recall": 0.7548828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0009544773423793593,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0009544773423793593,
        "precision": 0.0006459142258774612,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.759765625,
        "f1": 0.7237667261506875,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.7237667261506875,
        "precision": 0.7100454092776513,
        "recall": 0.759765625
      },
      {
        "accuracy": 0.7333984375,
        "f1": 0.690548806662088,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.690548806662088,
        "precision": 0.6738785700168398,
        "recall": 0.7333984375
      },
      {
        "accuracy": 0.748046875,
        "f1": 0.7096788194444444,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.7096788194444444,
        "precision": 0.6936424649760471,
        "recall": 0.748046875
      },
      {
        "accuracy": 0.69921875,
        "f1": 0.650815605006207,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.650815605006207,
        "precision": 0.6312116603179994,
        "recall": 0.69921875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0027294365429131055,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0027294365429131055,
        "precision": 0.002093193060538665,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.68359375,
        "f1": 0.6486707899305555,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.6486707899305555,
        "precision": 0.6339766597334957,
        "recall": 0.68359375
      },
      {
        "accuracy": 0.734375,
        "f1": 0.6936238078327922,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.6936238078327922,
        "precision": 0.6772336929563492,
        "recall": 0.734375
      },
      {
        "accuracy": 0.7578125,
        "f1": 0.7188301688545828,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.7188301688545828,
        "precision": 0.7036822606646825,
        "recall": 0.7578125
      },
      {
        "accuracy": 0.826171875,
        "f1": 0.7982933407738095,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.7982933407738095,
        "precision": 0.7873835157783554,
        "recall": 0.826171875
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9728190104166667,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9728190104166667,
        "precision": 0.9695638020833333,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9912109375,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9912109375,
        "precision": 0.990234375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.486328125,
        "f1": 0.41895921461351154,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.41895921461351154,
        "precision": 0.3957514228279031,
        "recall": 0.486328125
      },
      {
        "accuracy": 0.96875,
        "f1": 0.958984375,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.958984375,
        "precision": 0.9542643229166666,
        "recall": 0.96875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8885416666666668,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8885416666666668,
        "precision": 0.8780110677083333,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333334,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9886067708333334,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.7451171875,
        "f1": 0.6864606584821429,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6864606584821429,
        "precision": 0.662069847470238,
        "recall": 0.7451171875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9871419270833333,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9871419270833333,
        "precision": 0.9856770833333334,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9884440104166666,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9884440104166666,
        "precision": 0.9871419270833333,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002815385919992997,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002815385919992997,
        "precision": 0.0025498865614658026,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9938151041666666,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9938151041666666,
        "precision": 0.9931640625,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9814453125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.974609375,
        "f1": 0.9661458333333333,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9661458333333333,
        "precision": 0.9619140625,
        "recall": 0.974609375
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9494466145833333,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.9494466145833333,
        "precision": 0.9439290364583333,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0013451853455934612,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0013451853455934612,
        "precision": 0.0009225443047132121,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.876953125,
        "f1": 0.8472005208333333,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8472005208333333,
        "precision": 0.833935546875,
        "recall": 0.876953125
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9737955729166667,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9737955729166667,
        "precision": 0.9710286458333333,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9889322916666666,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9889322916666666,
        "precision": 0.98779296875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9830729166666667,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.9830729166666667,
        "precision": 0.98095703125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.453125,
        "f1": 0.3843040142696223,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.3843040142696223,
        "precision": 0.3609851501465914,
        "recall": 0.453125
      },
      {
        "accuracy": 0.9404296875,
        "f1": 0.9225260416666666,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.9225260416666666,
        "precision": 0.9138997395833333,
        "recall": 0.9404296875
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8665690104166667,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.8665690104166667,
        "precision": 0.8534342447916666,
        "recall": 0.8955078125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.7109375,
        "f1": 0.6487490699404762,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.6487490699404762,
        "precision": 0.6241156684027778,
        "recall": 0.7109375
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9791666666666666,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.9791666666666666,
        "precision": 0.9765625,
        "recall": 0.984375
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00018063694078875435,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.00018063694078875435,
        "precision": 9.208008986265126e-05,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9899088541666667,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.9899088541666667,
        "precision": 0.98876953125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.984375,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.984375,
        "precision": 0.982421875,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.95400390625,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.95400390625,
        "precision": 0.9488118489583333,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00021980536413787453,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.00021980536413787453,
        "precision": 0.00011577798915378292,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8066592261904761,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.8066592261904761,
        "precision": 0.7900716145833333,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.9886067708333334,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.9886067708333334,
        "precision": 0.9873046875,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9814453125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333334,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9934895833333334,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.4853515625,
        "f1": 0.41446671004776475,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.41446671004776475,
        "precision": 0.38938418081484494,
        "recall": 0.4853515625
      },
      {
        "accuracy": 0.95703125,
        "f1": 0.9436848958333333,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9436848958333333,
        "precision": 0.9371744791666666,
        "recall": 0.95703125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.90576171875,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.90576171875,
        "precision": 0.8955403645833333,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.7255859375,
        "f1": 0.6650762648809523,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6650762648809523,
        "precision": 0.6393252418154762,
        "recall": 0.7255859375
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.98583984375,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.98583984375,
        "precision": 0.9842122395833334,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9913736979166667,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9913736979166667,
        "precision": 0.9905598958333334,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0003854083199786325,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0003854083199786325,
        "precision": 0.00020550498870566922,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.984375,
        "f1": 0.9794921875,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9794921875,
        "precision": 0.9772135416666667,
        "recall": 0.984375
      },
      {
        "accuracy": 0.9765625,
        "f1": 0.9695638020833334,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.9695638020833334,
        "precision": 0.9661458333333333,
        "recall": 0.9765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00032900361934202484,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00032900361934202484,
        "precision": 0.00017384423550628362,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.8671875,
        "f1": 0.8367513020833334,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8367513020833334,
        "precision": 0.823486328125,
        "recall": 0.8671875
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9900716145833334,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9900716145833334,
        "precision": 0.9890950520833333,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0002951856909761635,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.0002951856909761635,
        "precision": 0.00016101470087387027,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00018195574836199838,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.00018195574836199838,
        "precision": 9.986068002257336e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0002462340065648446,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0002462340065648446,
        "precision": 0.00014055674241263027,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 7.637334519436792e-05,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 7.637334519436792e-05,
        "precision": 3.958196468386686e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.7890172253706015e-05,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 2.7890172253706015e-05,
        "precision": 1.4083206119267247e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00019739250532481363,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.00019739250532481363,
        "precision": 0.0001095480558516939,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00024949165239726025,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.00024949165239726025,
        "precision": 0.00014219179258241757,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00033190359477124184,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.00033190359477124184,
        "precision": 0.00018310546875,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.870635910224439e-06,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 4.870635910224439e-06,
        "precision": 2.44140625e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0016276041666666665,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.0016276041666666665,
        "precision": 0.00146484375,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0022291690368126077,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0022291690368126077,
        "precision": 0.0021088025755486143,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 7.937952628183095e-05,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 7.937952628183095e-05,
        "precision": 4.0994964407858105e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004913425744514107,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0004913425744514107,
        "precision": 0.0003270538984824699,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006545799365942029,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0006545799365942029,
        "precision": 0.0004900535957350272,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.937624007936508e-06,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 1.937624007936508e-06,
        "precision": 9.6977408142999e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.4112654320987654e-06,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 2.4112654320987654e-06,
        "precision": 1.2071229913473423e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 8.215525793650794e-05,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 8.215525793650794e-05,
        "precision": 4.179668332189654e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.06141946161477411,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.06141946161477411,
        "precision": 0.05286064846611722,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.8471209912536443e-06,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 2.8471209912536443e-06,
        "precision": 1.4256386861313868e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00018004804904916513,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.00018004804904916513,
        "precision": 9.890345625798213e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00014952877362430634,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.00014952877362430634,
        "precision": 8.01459417123082e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.48046875,
        "f1": 0.4098381924065518,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.4098381924065518,
        "precision": 0.38533886536385387,
        "recall": 0.48046875
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9537760416666667,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9537760416666667,
        "precision": 0.9484049479166667,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.8921223958333333,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8921223958333333,
        "precision": 0.8809407552083334,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.7373046875,
        "f1": 0.6770740327380952,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6770740327380952,
        "precision": 0.653173828125,
        "recall": 0.7373046875
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666666,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9869791666666666,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00014435760434236046,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00014435760434236046,
        "precision": 7.360689065804042e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9845377604166667,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.9845377604166667,
        "precision": 0.9827473958333334,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9651692708333334,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.9651692708333334,
        "precision": 0.9611002604166666,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0009159126946683423,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0009159126946683423,
        "precision": 0.000559384286450466,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.873046875,
        "f1": 0.8402994791666667,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8402994791666667,
        "precision": 0.8258789062499999,
        "recall": 0.873046875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9913736979166666,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9913736979166666,
        "precision": 0.9905598958333333,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.4267578125,
        "f1": 0.3595835447104978,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.3595835447104978,
        "precision": 0.3364754652452837,
        "recall": 0.4267578125
      },
      {
        "accuracy": 0.9384765625,
        "f1": 0.9215494791666666,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.9215494791666666,
        "precision": 0.9139322916666667,
        "recall": 0.9384765625
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.8896484375,
        "f1": 0.8616396949404762,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.8616396949404762,
        "precision": 0.8498860677083333,
        "recall": 0.8896484375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.703125,
        "f1": 0.643567863343254,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.643567863343254,
        "precision": 0.6202349950396825,
        "recall": 0.703125
      },
      {
        "accuracy": 0.9814453125,
        "f1": 0.9755859375,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.9755859375,
        "precision": 0.9728190104166666,
        "recall": 0.9814453125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9876302083333333,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.9876302083333333,
        "precision": 0.986328125,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0006836029091505957,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.0006836029091505957,
        "precision": 0.0004252400542542851,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9638671875,
        "f1": 0.9537760416666667,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.9537760416666667,
        "precision": 0.94921875,
        "recall": 0.9638671875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0006669813630432793,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0006669813630432793,
        "precision": 0.00039086364262867724,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.8486328125,
        "f1": 0.8119140624999999,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.8119140624999999,
        "precision": 0.7961588541666667,
        "recall": 0.8486328125
      },
      {
        "accuracy": 0.9921875,
        "f1": 0.9899088541666667,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.9899088541666667,
        "precision": 0.98876953125,
        "recall": 0.9921875
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9949544270833333,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.9949544270833333,
        "precision": 0.9944661458333333,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.97216796875,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.97216796875,
        "precision": 0.9690755208333333,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.4609375,
        "f1": 0.39485462804913635,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.39485462804913635,
        "precision": 0.3723499224841998,
        "recall": 0.4609375
      },
      {
        "accuracy": 0.9501953125,
        "f1": 0.93544921875,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.93544921875,
        "precision": 0.9286295572916666,
        "recall": 0.9501953125
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8472842261904763,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.8472842261904763,
        "precision": 0.8340983072916666,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.7265625,
        "f1": 0.6647786458333333,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.6647786458333333,
        "precision": 0.6397135416666667,
        "recall": 0.7265625
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9676106770833333,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.9676106770833333,
        "precision": 0.9637044270833333,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9876302083333334,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.9876302083333334,
        "precision": 0.986328125,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9850260416666666,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.9850260416666666,
        "precision": 0.9835611979166666,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0010426706885606342,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.0010426706885606342,
        "precision": 0.0006970213774146234,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.98828125,
        "f1": 0.9851888020833333,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.9851888020833333,
        "precision": 0.9837239583333333,
        "recall": 0.98828125
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9869791666666667,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.9869791666666667,
        "precision": 0.9853515625,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9609375,
        "f1": 0.9492838541666666,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.9492838541666666,
        "precision": 0.9439290364583334,
        "recall": 0.9609375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001118535595521268,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.001118535595521268,
        "precision": 0.0006400595473797815,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.8525390625,
        "f1": 0.8178873697916667,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.8178873697916667,
        "precision": 0.8027111235119047,
        "recall": 0.8525390625
      },
      {
        "accuracy": 0.986328125,
        "f1": 0.9820963541666667,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.9820963541666667,
        "precision": 0.97998046875,
        "recall": 0.986328125
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.98046875,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.98046875,
        "precision": 0.97802734375,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9923502604166666,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.9923502604166666,
        "precision": 0.9915364583333333,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9567057291666666,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.9567057291666666,
        "precision": 0.9520182291666667,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9679361979166667,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.9679361979166667,
        "precision": 0.9641927083333334,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.4501953125,
        "f1": 0.39047841073346584,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.39047841073346584,
        "precision": 0.37025295532375607,
        "recall": 0.4501953125
      },
      {
        "accuracy": 0.9033203125,
        "f1": 0.87626953125,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.87626953125,
        "precision": 0.8641276041666667,
        "recall": 0.9033203125
      },
      {
        "accuracy": 0.966796875,
        "f1": 0.9562174479166666,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9562174479166666,
        "precision": 0.951171875,
        "recall": 0.966796875
      },
      {
        "accuracy": 0.83984375,
        "f1": 0.8010416666666667,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.8010416666666667,
        "precision": 0.7840494791666666,
        "recall": 0.83984375
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9590494791666666,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.9590494791666666,
        "precision": 0.9545084635416667,
        "recall": 0.96875
      },
      {
        "accuracy": 0.9794921875,
        "f1": 0.9737955729166667,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9737955729166667,
        "precision": 0.9710286458333334,
        "recall": 0.9794921875
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9655598958333333,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.9655598958333333,
        "precision": 0.961669921875,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.6708984375,
        "f1": 0.6113699776785715,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6113699776785715,
        "precision": 0.5881533668154761,
        "recall": 0.6708984375
      },
      {
        "accuracy": 0.955078125,
        "f1": 0.9410807291666666,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9410807291666666,
        "precision": 0.9342447916666666,
        "recall": 0.955078125
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.962890625,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.962890625,
        "precision": 0.9593424479166667,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9689778645833333,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9689778645833333,
        "precision": 0.9659016927083333,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0014370902896472283,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0014370902896472283,
        "precision": 0.000883886145580303,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9715169270833333,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9715169270833333,
        "precision": 0.9680989583333333,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.9541015625,
        "f1": 0.9402669270833333,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.9402669270833333,
        "precision": 0.9334309895833334,
        "recall": 0.9541015625
      },
      {
        "accuracy": 0.9453125,
        "f1": 0.92822265625,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.92822265625,
        "precision": 0.9200846354166667,
        "recall": 0.9453125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.001891480053047004,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001891480053047004,
        "precision": 0.0011647761731023566,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.80859375,
        "f1": 0.7675316220238095,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.7675316220238095,
        "precision": 0.7506673177083334,
        "recall": 0.80859375
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9462890625,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.9462890625,
        "precision": 0.94091796875,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9595377604166666,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.9595377604166666,
        "precision": 0.9551595052083333,
        "recall": 0.96875
      },
      {
        "accuracy": 0.96875,
        "f1": 0.9592633928571428,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9592633928571428,
        "precision": 0.9547526041666666,
        "recall": 0.96875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013078360306985112,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0013078360306985112,
        "precision": 0.0011615691036049648,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012669766693005448,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.0012669766693005448,
        "precision": 0.0011396656062480262,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007754097732843137,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0007754097732843137,
        "precision": 0.0005545356669611307,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002104577312829649,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.002104577312829649,
        "precision": 0.0020327214508897434,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001982302554648721,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.001982302554648721,
        "precision": 0.0019678396772044573,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0022617862228012887,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0022617862228012887,
        "precision": 0.002130904758648536,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001991436179699927,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.001991436179699927,
        "precision": 0.001972463590008237,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009792827298050139,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0009792827298050139,
        "precision": 0.0009779245118549512,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011137964628297361,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.0011137964628297361,
        "precision": 0.001049842460675606,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019581202046035804,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0019581202046035804,
        "precision": 0.0019556290064102564,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002283014917498065,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.002283014917498065,
        "precision": 0.0021417843088164263,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010425278029131083,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.0010425278029131083,
        "precision": 0.0010104248417834925,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001223813196656051,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.001223813196656051,
        "precision": 0.0011176289445203919,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0830078125,
        "f1": 0.054024903048340546,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.054024903048340546,
        "precision": 0.045280663347069594,
        "recall": 0.0830078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019601004464285714,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.0019601004464285714,
        "precision": 0.0019566252240143366,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009785595603271984,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.0009785595603271984,
        "precision": 0.000977562052200614,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009788023222477064,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.0009788023222477064,
        "precision": 0.000977683696900115,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010878278533324552,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.0010878278533324552,
        "precision": 0.0010341526232373547,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001955822686464088,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.001955822686464088,
        "precision": 0.0019544757088520055,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0012237837638012618,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0012237837638012618,
        "precision": 0.0011176141813360415,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.001953125,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.001953125,
        "precision": 0.001953125,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001034262127334517,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.001034262127334517,
        "precision": 0.0010060493182172078,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.8486328125,
        "f1": 0.8124697730654762,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.8124697730654762,
        "precision": 0.7967540922619047,
        "recall": 0.8486328125
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8468749999999999,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8468749999999999,
        "precision": 0.8335123697916667,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.5107421875,
        "f1": 0.45496031746031745,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.45496031746031745,
        "precision": 0.43355848524305557,
        "recall": 0.5107421875
      },
      {
        "accuracy": 0.87109375,
        "f1": 0.8447451636904761,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8447451636904761,
        "precision": 0.8336588541666666,
        "recall": 0.87109375
      },
      {
        "accuracy": 0.8798828125,
        "f1": 0.8508975074404761,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8508975074404761,
        "precision": 0.8382975260416667,
        "recall": 0.8798828125
      },
      {
        "accuracy": 0.822265625,
        "f1": 0.7889508928571429,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7889508928571429,
        "precision": 0.7744140625,
        "recall": 0.822265625
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8501953124999999,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.8501953124999999,
        "precision": 0.8375651041666667,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8682454427083333,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8682454427083333,
        "precision": 0.8563732328869047,
        "recall": 0.8955078125
      },
      {
        "accuracy": 0.8662109375,
        "f1": 0.8374240451388888,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.8374240451388888,
        "precision": 0.8251329210069445,
        "recall": 0.8662109375
      },
      {
        "accuracy": 0.68359375,
        "f1": 0.627001953125,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.627001953125,
        "precision": 0.6044689360119047,
        "recall": 0.68359375
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8681849888392856,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8681849888392856,
        "precision": 0.8573172433035714,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.861328125,
        "f1": 0.8285884796626983,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.8285884796626983,
        "precision": 0.8143310546875,
        "recall": 0.861328125
      },
      {
        "accuracy": 0.88671875,
        "f1": 0.8598818824404761,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8598818824404761,
        "precision": 0.8477701822916667,
        "recall": 0.88671875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0015567368045455402,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0015567368045455402,
        "precision": 0.0012829536999458874,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.8935546875,
        "f1": 0.8688639322916667,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8688639322916667,
        "precision": 0.8578869047619047,
        "recall": 0.8935546875
      },
      {
        "accuracy": 0.85546875,
        "f1": 0.8202799479166667,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.8202799479166667,
        "precision": 0.80478515625,
        "recall": 0.85546875
      },
      {
        "accuracy": 0.861328125,
        "f1": 0.8273763020833333,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.8273763020833333,
        "precision": 0.8127278645833333,
        "recall": 0.861328125
      },
      {
        "accuracy": 0.822265625,
        "f1": 0.783394562251984,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.783394562251984,
        "precision": 0.7668143136160714,
        "recall": 0.822265625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0023869248220121384,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0023869248220121384,
        "precision": 0.0020084514031760317,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.8037923177083333,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.8037923177083333,
        "precision": 0.7885393415178572,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.8662109375,
        "f1": 0.8376162574404762,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.8376162574404762,
        "precision": 0.8252604166666667,
        "recall": 0.8662109375
      },
      {
        "accuracy": 0.8828125,
        "f1": 0.8556718129960317,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8556718129960317,
        "precision": 0.8441487630208333,
        "recall": 0.8828125
      },
      {
        "accuracy": 0.98046875,
        "f1": 0.9743489583333333,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.9743489583333333,
        "precision": 0.971435546875,
        "recall": 0.98046875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.4228515625,
        "f1": 0.3548133615516428,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.3548133615516428,
        "precision": 0.3315825315092893,
        "recall": 0.4228515625
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.9239908854166666,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.9239908854166666,
        "precision": 0.9158528645833333,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8448567708333333,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.8448567708333333,
        "precision": 0.8301920572916666,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666667,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.9947916666666667,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.7041015625,
        "f1": 0.6395577566964286,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.6395577566964286,
        "precision": 0.6135184151785714,
        "recall": 0.7041015625
      },
      {
        "accuracy": 0.9755859375,
        "f1": 0.9677734375,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.9677734375,
        "precision": 0.9640299479166666,
        "recall": 0.9755859375
      },
      {
        "accuracy": 0.990234375,
        "f1": 0.9873046875,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.9873046875,
        "precision": 0.98583984375,
        "recall": 0.990234375
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00018992935078314543,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.00018992935078314543,
        "precision": 9.693016232868293e-05,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.9912109375,
        "f1": 0.98828125,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.98828125,
        "precision": 0.98681640625,
        "recall": 0.9912109375
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333334,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.9856770833333334,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.9853515625,
        "f1": 0.9806315104166666,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.9806315104166666,
        "precision": 0.9783528645833333,
        "recall": 0.9853515625
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9519856770833333,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.9519856770833333,
        "precision": 0.9468098958333333,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 5.8694166118637e-05,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 5.8694166118637e-05,
        "precision": 2.9714209401709403e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.828125,
        "f1": 0.7896724640376984,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.7896724640376984,
        "precision": 0.7735851469494047,
        "recall": 0.828125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666667,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.9908854166666667,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333334,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.9856770833333334,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.46875,
        "f1": 0.4027700904079581,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.4027700904079581,
        "precision": 0.38065868814288323,
        "recall": 0.46875
      },
      {
        "accuracy": 0.9501953125,
        "f1": 0.93505859375,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.93505859375,
        "precision": 0.9278971354166666,
        "recall": 0.9501953125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.89453125,
        "f1": 0.8653645833333333,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.8653645833333333,
        "precision": 0.8524576822916667,
        "recall": 0.89453125
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9921875,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.9921875,
        "precision": 0.9912109375,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.724609375,
        "f1": 0.6620489211309524,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.6620489211309524,
        "precision": 0.6364095052083334,
        "recall": 0.724609375
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9814453125,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9977213541666666,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.9977213541666666,
        "precision": 0.99755859375,
        "recall": 0.998046875
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0001887743296502329,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.0001887743296502329,
        "precision": 9.628719656378818e-05,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9951171875,
        "f1": 0.9934895833333333,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.9934895833333333,
        "precision": 0.99267578125,
        "recall": 0.9951171875
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9833984375,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.9833984375,
        "precision": 0.9816080729166666,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9544921875,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.9544921875,
        "precision": 0.9496256510416666,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0007616048928003746,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0007616048928003746,
        "precision": 0.0004486572179329669,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.857421875,
        "f1": 0.8224283854166666,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.8224283854166666,
        "precision": 0.8071126302083333,
        "recall": 0.857421875
      },
      {
        "accuracy": 0.994140625,
        "f1": 0.9925130208333333,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.9925130208333333,
        "precision": 0.99169921875,
        "recall": 0.994140625
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666667,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.9986979166666667,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.4375,
        "f1": 0.36922660672660673,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.36922660672660673,
        "precision": 0.3463959118024702,
        "recall": 0.4375
      },
      {
        "accuracy": 0.9619140625,
        "f1": 0.9501953125,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.9501953125,
        "precision": 0.9444986979166667,
        "recall": 0.9619140625
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.908203125,
        "f1": 0.8815104166666666,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.8815104166666666,
        "precision": 0.869140625,
        "recall": 0.908203125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.998046875,
        "f1": 0.9973958333333333,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9973958333333333,
        "precision": 0.9970703125,
        "recall": 0.998046875
      },
      {
        "accuracy": 1.0,
        "f1": 1.0,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 1.0,
        "precision": 1.0,
        "recall": 1.0
      },
      {
        "accuracy": 0.7939453125,
        "f1": 0.7427083333333333,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.7427083333333333,
        "precision": 0.7206705729166667,
        "recall": 0.7939453125
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9990234375,
        "f1": 0.9986979166666666,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.9986979166666666,
        "precision": 0.99853515625,
        "recall": 0.9990234375
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9947916666666666,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.9947916666666666,
        "precision": 0.994140625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0006279458733388956,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0006279458733388956,
        "precision": 0.0003967246585280287,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      },
      {
        "accuracy": 0.9931640625,
        "f1": 0.9908854166666666,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.9908854166666666,
        "precision": 0.98974609375,
        "recall": 0.9931640625
      },
      {
        "accuracy": 0.9736328125,
        "f1": 0.9656575520833334,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.9656575520833334,
        "precision": 0.9617513020833333,
        "recall": 0.9736328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0007273016045081413,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0007273016045081413,
        "precision": 0.0004237180185160368,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.86328125,
        "f1": 0.8284830729166666,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.8284830729166666,
        "precision": 0.8128580729166667,
        "recall": 0.86328125
      },
      {
        "accuracy": 0.99609375,
        "f1": 0.9951171875,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.9951171875,
        "precision": 0.99462890625,
        "recall": 0.99609375
      },
      {
        "accuracy": 0.9970703125,
        "f1": 0.99609375,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.99609375,
        "precision": 0.99560546875,
        "recall": 0.9970703125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}