{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.583906,
        "f1": 0.565391,
        "f1_weighted": 0.599993,
        "ap": 0.74327,
        "ap_weighted": 0.74327,
        "scores_per_experiment": [
          {
            "accuracy": 0.56867,
            "f1": 0.548282,
            "f1_weighted": 0.586174,
            "ap": 0.731534,
            "ap_weighted": 0.731534
          },
          {
            "accuracy": 0.545064,
            "f1": 0.531951,
            "f1_weighted": 0.562885,
            "ap": 0.72836,
            "ap_weighted": 0.72836
          },
          {
            "accuracy": 0.67382,
            "f1": 0.644418,
            "f1_weighted": 0.684791,
            "ap": 0.778148,
            "ap_weighted": 0.778148
          },
          {
            "accuracy": 0.549356,
            "f1": 0.538953,
            "f1_weighted": 0.566299,
            "ap": 0.735084,
            "ap_weighted": 0.735084
          },
          {
            "accuracy": 0.592275,
            "f1": 0.574204,
            "f1_weighted": 0.608839,
            "ap": 0.747436,
            "ap_weighted": 0.747436
          },
          {
            "accuracy": 0.594421,
            "f1": 0.586373,
            "f1_weighted": 0.609154,
            "ap": 0.767231,
            "ap_weighted": 0.767231
          },
          {
            "accuracy": 0.633047,
            "f1": 0.605568,
            "f1_weighted": 0.646675,
            "ap": 0.75803,
            "ap_weighted": 0.75803
          },
          {
            "accuracy": 0.51073,
            "f1": 0.495872,
            "f1_weighted": 0.530045,
            "ap": 0.708204,
            "ap_weighted": 0.708204
          },
          {
            "accuracy": 0.56867,
            "f1": 0.546515,
            "f1_weighted": 0.586092,
            "ap": 0.729511,
            "ap_weighted": 0.729511
          },
          {
            "accuracy": 0.603004,
            "f1": 0.581771,
            "f1_weighted": 0.61898,
            "ap": 0.749165,
            "ap_weighted": 0.749165
          }
        ],
        "main_score": 0.583906,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.607388,
        "f1": 0.584437,
        "f1_weighted": 0.62081,
        "ap": 0.749905,
        "ap_weighted": 0.749905,
        "scores_per_experiment": [
          {
            "accuracy": 0.589936,
            "f1": 0.576726,
            "f1_weighted": 0.606028,
            "ap": 0.751777,
            "ap_weighted": 0.751777
          },
          {
            "accuracy": 0.501071,
            "f1": 0.49241,
            "f1_weighted": 0.518391,
            "ap": 0.709851,
            "ap_weighted": 0.709851
          },
          {
            "accuracy": 0.654176,
            "f1": 0.631226,
            "f1_weighted": 0.667276,
            "ap": 0.774044,
            "ap_weighted": 0.774044
          },
          {
            "accuracy": 0.589936,
            "f1": 0.580372,
            "f1_weighted": 0.605196,
            "ap": 0.758843,
            "ap_weighted": 0.758843
          },
          {
            "accuracy": 0.61242,
            "f1": 0.589653,
            "f1_weighted": 0.627529,
            "ap": 0.75063,
            "ap_weighted": 0.75063
          },
          {
            "accuracy": 0.664882,
            "f1": 0.63153,
            "f1_weighted": 0.674971,
            "ap": 0.766911,
            "ap_weighted": 0.766911
          },
          {
            "accuracy": 0.594218,
            "f1": 0.577273,
            "f1_weighted": 0.610439,
            "ap": 0.748302,
            "ap_weighted": 0.748302
          },
          {
            "accuracy": 0.635974,
            "f1": 0.583327,
            "f1_weighted": 0.641366,
            "ap": 0.735601,
            "ap_weighted": 0.735601
          },
          {
            "accuracy": 0.571734,
            "f1": 0.559766,
            "f1_weighted": 0.58821,
            "ap": 0.743275,
            "ap_weighted": 0.743275
          },
          {
            "accuracy": 0.659529,
            "f1": 0.622084,
            "f1_weighted": 0.668699,
            "ap": 0.759818,
            "ap_weighted": 0.759818
          }
        ],
        "main_score": 0.607388,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 37.15504169464111,
  "kg_co2_emissions": null
}