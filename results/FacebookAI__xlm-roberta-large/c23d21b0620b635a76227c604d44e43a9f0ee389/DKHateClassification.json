{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "2.3.9",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.531915,
            "f1": 0.45586,
            "f1_weighted": 0.608589,
            "precision": 0.533056,
            "precision_weighted": 0.814952,
            "recall": 0.575754,
            "recall_weighted": 0.531915,
            "ap": 0.892534,
            "ap_weighted": 0.892534
          },
          {
            "accuracy": 0.559271,
            "f1": 0.465173,
            "f1_weighted": 0.633594,
            "precision": 0.526387,
            "precision_weighted": 0.806461,
            "recall": 0.560002,
            "recall_weighted": 0.559271,
            "ap": 0.888831,
            "ap_weighted": 0.888831
          },
          {
            "accuracy": 0.699088,
            "f1": 0.55773,
            "f1_weighted": 0.745448,
            "precision": 0.565993,
            "precision_weighted": 0.828989,
            "recall": 0.629404,
            "recall_weighted": 0.699088,
            "ap": 0.904933,
            "ap_weighted": 0.904933
          },
          {
            "accuracy": 0.610942,
            "f1": 0.49622,
            "f1_weighted": 0.676707,
            "precision": 0.53599,
            "precision_weighted": 0.812307,
            "recall": 0.579057,
            "recall_weighted": 0.610942,
            "ap": 0.893193,
            "ap_weighted": 0.893193
          },
          {
            "accuracy": 0.68693,
            "f1": 0.530267,
            "f1_weighted": 0.733929,
            "precision": 0.542053,
            "precision_weighted": 0.81111,
            "recall": 0.580623,
            "recall_weighted": 0.68693,
            "ap": 0.893474,
            "ap_weighted": 0.893474
          },
          {
            "accuracy": 0.577508,
            "f1": 0.473903,
            "f1_weighted": 0.649179,
            "precision": 0.526663,
            "precision_weighted": 0.805745,
            "recall": 0.559959,
            "recall_weighted": 0.577508,
            "ap": 0.888806,
            "ap_weighted": 0.888806
          },
          {
            "accuracy": 0.534954,
            "f1": 0.439111,
            "f1_weighted": 0.61318,
            "precision": 0.506467,
            "precision_weighted": 0.787919,
            "recall": 0.514736,
            "recall_weighted": 0.534954,
            "ap": 0.878617,
            "ap_weighted": 0.878617
          },
          {
            "accuracy": 0.556231,
            "f1": 0.441725,
            "f1_weighted": 0.631544,
            "precision": 0.497993,
            "precision_weighted": 0.780047,
            "recall": 0.495512,
            "recall_weighted": 0.556231,
            "ap": 0.874403,
            "ap_weighted": 0.874403
          },
          {
            "accuracy": 0.638298,
            "f1": 0.536812,
            "f1_weighted": 0.699585,
            "precision": 0.571144,
            "precision_weighted": 0.843061,
            "recall": 0.657436,
            "recall_weighted": 0.638298,
            "ap": 0.912003,
            "ap_weighted": 0.912003
          },
          {
            "accuracy": 0.62614,
            "f1": 0.476257,
            "f1_weighted": 0.686604,
            "precision": 0.507056,
            "precision_weighted": 0.787186,
            "recall": 0.514524,
            "recall_weighted": 0.62614,
            "ap": 0.878566,
            "ap_weighted": 0.878566
          }
        ],
        "accuracy": 0.602128,
        "f1": 0.487306,
        "f1_weighted": 0.667836,
        "precision": 0.53128,
        "precision_weighted": 0.807778,
        "recall": 0.566701,
        "recall_weighted": 0.602128,
        "ap": 0.890536,
        "ap_weighted": 0.890536,
        "main_score": 0.602128,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 45.287312746047974,
  "kg_co2_emissions": null
}