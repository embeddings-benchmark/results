{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.629185,
        "f1": 0.605816,
        "f1_weighted": 0.643011,
        "ap": 0.762963,
        "ap_weighted": 0.762963,
        "scores_per_experiment": [
          {
            "accuracy": 0.607296,
            "f1": 0.584567,
            "f1_weighted": 0.622935,
            "ap": 0.749636,
            "ap_weighted": 0.749636
          },
          {
            "accuracy": 0.611588,
            "f1": 0.578259,
            "f1_weighted": 0.625072,
            "ap": 0.740485,
            "ap_weighted": 0.740485
          },
          {
            "accuracy": 0.654506,
            "f1": 0.62182,
            "f1_weighted": 0.66572,
            "ap": 0.763752,
            "ap_weighted": 0.763752
          },
          {
            "accuracy": 0.618026,
            "f1": 0.608684,
            "f1_weighted": 0.632557,
            "ap": 0.779198,
            "ap_weighted": 0.779198
          },
          {
            "accuracy": 0.609442,
            "f1": 0.594999,
            "f1_weighted": 0.625198,
            "ap": 0.763127,
            "ap_weighted": 0.763127
          },
          {
            "accuracy": 0.645923,
            "f1": 0.62847,
            "f1_weighted": 0.660265,
            "ap": 0.779775,
            "ap_weighted": 0.779775
          },
          {
            "accuracy": 0.641631,
            "f1": 0.61088,
            "f1_weighted": 0.654072,
            "ap": 0.758959,
            "ap_weighted": 0.758959
          },
          {
            "accuracy": 0.598712,
            "f1": 0.575487,
            "f1_weighted": 0.614694,
            "ap": 0.744328,
            "ap_weighted": 0.744328
          },
          {
            "accuracy": 0.643777,
            "f1": 0.608435,
            "f1_weighted": 0.654884,
            "ap": 0.755297,
            "ap_weighted": 0.755297
          },
          {
            "accuracy": 0.660944,
            "f1": 0.646563,
            "f1_weighted": 0.674713,
            "ap": 0.795076,
            "ap_weighted": 0.795076
          }
        ],
        "main_score": 0.629185,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.602998,
        "f1": 0.58119,
        "f1_weighted": 0.617856,
        "ap": 0.748982,
        "ap_weighted": 0.748982,
        "scores_per_experiment": [
          {
            "accuracy": 0.589936,
            "f1": 0.563708,
            "f1_weighted": 0.605626,
            "ap": 0.734513,
            "ap_weighted": 0.734513
          },
          {
            "accuracy": 0.61242,
            "f1": 0.572934,
            "f1_weighted": 0.62382,
            "ap": 0.733852,
            "ap_weighted": 0.733852
          },
          {
            "accuracy": 0.642398,
            "f1": 0.619313,
            "f1_weighted": 0.656049,
            "ap": 0.767095,
            "ap_weighted": 0.767095
          },
          {
            "accuracy": 0.62848,
            "f1": 0.618235,
            "f1_weighted": 0.642741,
            "ap": 0.781743,
            "ap_weighted": 0.781743
          },
          {
            "accuracy": 0.563169,
            "f1": 0.547835,
            "f1_weighted": 0.580465,
            "ap": 0.733204,
            "ap_weighted": 0.733204
          },
          {
            "accuracy": 0.594218,
            "f1": 0.584197,
            "f1_weighted": 0.609492,
            "ap": 0.760503,
            "ap_weighted": 0.760503
          },
          {
            "accuracy": 0.607066,
            "f1": 0.578032,
            "f1_weighted": 0.621406,
            "ap": 0.740625,
            "ap_weighted": 0.740625
          },
          {
            "accuracy": 0.571734,
            "f1": 0.548472,
            "f1_weighted": 0.588633,
            "ap": 0.728115,
            "ap_weighted": 0.728115
          },
          {
            "accuracy": 0.588865,
            "f1": 0.559799,
            "f1_weighted": 0.604125,
            "ap": 0.731108,
            "ap_weighted": 0.731108
          },
          {
            "accuracy": 0.631692,
            "f1": 0.619377,
            "f1_weighted": 0.646205,
            "ap": 0.779057,
            "ap_weighted": 0.779057
          }
        ],
        "main_score": 0.602998,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 24.232409715652466,
  "kg_co2_emissions": null
}