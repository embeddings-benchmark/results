{
  "dataset_revision": "fc69d1c153a8ccdcf1eef52f4e2a27f88782f543",
  "task_name": "PAC",
  "mteb_version": "1.38.54",
  "scores": {
    "test": [
      {
        "accuracy": 0.661801,
        "f1": 0.641531,
        "f1_weighted": 0.668468,
        "ap": 0.769702,
        "ap_weighted": 0.769702,
        "scores_per_experiment": [
          {
            "accuracy": 0.661164,
            "f1": 0.654906,
            "f1_weighted": 0.671231,
            "ap": 0.788269,
            "ap_weighted": 0.788269
          },
          {
            "accuracy": 0.706342,
            "f1": 0.688656,
            "f1_weighted": 0.714724,
            "ap": 0.790142,
            "ap_weighted": 0.790142
          },
          {
            "accuracy": 0.712134,
            "f1": 0.6916,
            "f1_weighted": 0.719555,
            "ap": 0.788561,
            "ap_weighted": 0.788561
          },
          {
            "accuracy": 0.607588,
            "f1": 0.514193,
            "f1_weighted": 0.58902,
            "ap": 0.683389,
            "ap_weighted": 0.683389
          },
          {
            "accuracy": 0.677672,
            "f1": 0.674287,
            "f1_weighted": 0.685951,
            "ap": 0.813393,
            "ap_weighted": 0.813393
          },
          {
            "accuracy": 0.599189,
            "f1": 0.590918,
            "f1_weighted": 0.611352,
            "ap": 0.740875,
            "ap_weighted": 0.740875
          },
          {
            "accuracy": 0.647263,
            "f1": 0.639923,
            "f1_weighted": 0.657983,
            "ap": 0.775027,
            "ap_weighted": 0.775027
          },
          {
            "accuracy": 0.675355,
            "f1": 0.661023,
            "f1_weighted": 0.685508,
            "ap": 0.777025,
            "ap_weighted": 0.777025
          },
          {
            "accuracy": 0.635969,
            "f1": 0.628796,
            "f1_weighted": 0.646923,
            "ap": 0.767753,
            "ap_weighted": 0.767753
          },
          {
            "accuracy": 0.695337,
            "f1": 0.671008,
            "f1_weighted": 0.702437,
            "ap": 0.772587,
            "ap_weighted": 0.772587
          }
        ],
        "main_score": 0.661801,
        "hf_subset": "default",
        "languages": [
          "pol-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 96.39520692825317,
  "kg_co2_emissions": null
}