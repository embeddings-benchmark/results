{
  "dataset_revision": "23a20c659d868740ef9c54854de631fe19cd5c17",
  "task_name": "CSFDSKMovieReviewSentimentClassification",
  "mteb_version": "1.38.54",
  "scores": {
    "test": [
      {
        "accuracy": 0.374268,
        "f1": 0.357493,
        "f1_weighted": 0.359928,
        "scores_per_experiment": [
          {
            "accuracy": 0.39502,
            "f1": 0.376106,
            "f1_weighted": 0.378949
          },
          {
            "accuracy": 0.378906,
            "f1": 0.356621,
            "f1_weighted": 0.360023
          },
          {
            "accuracy": 0.393555,
            "f1": 0.369625,
            "f1_weighted": 0.372461
          },
          {
            "accuracy": 0.375,
            "f1": 0.366483,
            "f1_weighted": 0.367845
          },
          {
            "accuracy": 0.351562,
            "f1": 0.334109,
            "f1_weighted": 0.336065
          },
          {
            "accuracy": 0.352539,
            "f1": 0.326956,
            "f1_weighted": 0.329653
          },
          {
            "accuracy": 0.372559,
            "f1": 0.359996,
            "f1_weighted": 0.362961
          },
          {
            "accuracy": 0.375977,
            "f1": 0.372315,
            "f1_weighted": 0.373918
          },
          {
            "accuracy": 0.38623,
            "f1": 0.364044,
            "f1_weighted": 0.366979
          },
          {
            "accuracy": 0.361328,
            "f1": 0.348677,
            "f1_weighted": 0.350426
          }
        ],
        "main_score": 0.374268,
        "hf_subset": "default",
        "languages": [
          "slk-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 91.51709175109863,
  "kg_co2_emissions": null
}