{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.38.54",
  "scores": {
    "validation": [
      {
        "accuracy": 0.387402,
        "f1": 0.326938,
        "f1_weighted": 0.37993,
        "scores_per_experiment": [
          {
            "accuracy": 0.388184,
            "f1": 0.324867,
            "f1_weighted": 0.385302
          },
          {
            "accuracy": 0.364746,
            "f1": 0.315066,
            "f1_weighted": 0.359718
          },
          {
            "accuracy": 0.39502,
            "f1": 0.326901,
            "f1_weighted": 0.38336
          },
          {
            "accuracy": 0.368652,
            "f1": 0.316697,
            "f1_weighted": 0.358108
          },
          {
            "accuracy": 0.395996,
            "f1": 0.321772,
            "f1_weighted": 0.387029
          },
          {
            "accuracy": 0.389648,
            "f1": 0.32851,
            "f1_weighted": 0.381319
          },
          {
            "accuracy": 0.401855,
            "f1": 0.340538,
            "f1_weighted": 0.395285
          },
          {
            "accuracy": 0.392578,
            "f1": 0.33676,
            "f1_weighted": 0.386114
          },
          {
            "accuracy": 0.384766,
            "f1": 0.328076,
            "f1_weighted": 0.376025
          },
          {
            "accuracy": 0.392578,
            "f1": 0.330195,
            "f1_weighted": 0.387038
          }
        ],
        "main_score": 0.387402,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.383936,
        "f1": 0.354582,
        "f1_weighted": 0.376437,
        "scores_per_experiment": [
          {
            "accuracy": 0.379395,
            "f1": 0.35639,
            "f1_weighted": 0.375668
          },
          {
            "accuracy": 0.393066,
            "f1": 0.372014,
            "f1_weighted": 0.388189
          },
          {
            "accuracy": 0.384766,
            "f1": 0.349805,
            "f1_weighted": 0.371654
          },
          {
            "accuracy": 0.379395,
            "f1": 0.346515,
            "f1_weighted": 0.368156
          },
          {
            "accuracy": 0.386719,
            "f1": 0.361216,
            "f1_weighted": 0.37655
          },
          {
            "accuracy": 0.378418,
            "f1": 0.344829,
            "f1_weighted": 0.369043
          },
          {
            "accuracy": 0.380371,
            "f1": 0.348412,
            "f1_weighted": 0.374554
          },
          {
            "accuracy": 0.38916,
            "f1": 0.358271,
            "f1_weighted": 0.382435
          },
          {
            "accuracy": 0.375977,
            "f1": 0.339044,
            "f1_weighted": 0.371698
          },
          {
            "accuracy": 0.39209,
            "f1": 0.369322,
            "f1_weighted": 0.386427
          }
        ],
        "main_score": 0.383936,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 12627.893227815628,
  "kg_co2_emissions": null
}