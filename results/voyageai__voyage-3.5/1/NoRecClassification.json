{
  "dataset_revision": "5b740b7c42c73d586420812a35745fc37118862f",
  "task_name": "NoRecClassification",
  "mteb_version": "2.1.11",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.564941,
            "f1": 0.536215,
            "f1_weighted": 0.577257,
            "precision": 0.556588,
            "precision_weighted": 0.622518,
            "recall": 0.564782,
            "recall_weighted": 0.564941,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.515625,
            "f1": 0.468075,
            "f1_weighted": 0.519354,
            "precision": 0.470192,
            "precision_weighted": 0.526437,
            "recall": 0.470498,
            "recall_weighted": 0.515625,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.523438,
            "f1": 0.499591,
            "f1_weighted": 0.539905,
            "precision": 0.529387,
            "precision_weighted": 0.604534,
            "recall": 0.540755,
            "recall_weighted": 0.523438,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.529785,
            "f1": 0.497094,
            "f1_weighted": 0.5347,
            "precision": 0.493852,
            "precision_weighted": 0.543528,
            "recall": 0.506889,
            "recall_weighted": 0.529785,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.538574,
            "f1": 0.500673,
            "f1_weighted": 0.541838,
            "precision": 0.505575,
            "precision_weighted": 0.560265,
            "recall": 0.517661,
            "recall_weighted": 0.538574,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.533691,
            "f1": 0.51485,
            "f1_weighted": 0.545169,
            "precision": 0.521758,
            "precision_weighted": 0.585511,
            "recall": 0.542348,
            "recall_weighted": 0.533691,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.518555,
            "f1": 0.49612,
            "f1_weighted": 0.534907,
            "precision": 0.52653,
            "precision_weighted": 0.595402,
            "recall": 0.530408,
            "recall_weighted": 0.518555,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.549805,
            "f1": 0.49843,
            "f1_weighted": 0.553415,
            "precision": 0.497658,
            "precision_weighted": 0.558256,
            "recall": 0.500356,
            "recall_weighted": 0.549805,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.485352,
            "f1": 0.475414,
            "f1_weighted": 0.4906,
            "precision": 0.473135,
            "precision_weighted": 0.515854,
            "recall": 0.50796,
            "recall_weighted": 0.485352,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.541992,
            "f1": 0.516118,
            "f1_weighted": 0.539105,
            "precision": 0.533406,
            "precision_weighted": 0.587992,
            "recall": 0.539828,
            "recall_weighted": 0.541992,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.530176,
        "f1": 0.500258,
        "f1_weighted": 0.537625,
        "precision": 0.510808,
        "precision_weighted": 0.57003,
        "recall": 0.522148,
        "recall_weighted": 0.530176,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.530176,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 106.01515793800354,
  "kg_co2_emissions": null
}