{
  "dataset_revision": "3d96e36e10a88d5b7a3f617cf8362d997504494b",
  "task_name": "KorSarcasmClassification",
  "mteb_version": "1.38.54",
  "scores": {
    "train": [
      {
        "accuracy": 0.572559,
        "f1": 0.567957,
        "f1_weighted": 0.567961,
        "ap": 0.542228,
        "ap_weighted": 0.542228,
        "scores_per_experiment": [
          {
            "accuracy": 0.608398,
            "f1": 0.599811,
            "f1_weighted": 0.599926,
            "ap": 0.569599,
            "ap_weighted": 0.569599
          },
          {
            "accuracy": 0.600098,
            "f1": 0.599869,
            "f1_weighted": 0.599887,
            "ap": 0.559563,
            "ap_weighted": 0.559563
          },
          {
            "accuracy": 0.50293,
            "f1": 0.49824,
            "f1_weighted": 0.498334,
            "ap": 0.500404,
            "ap_weighted": 0.500404
          },
          {
            "accuracy": 0.569824,
            "f1": 0.568367,
            "f1_weighted": 0.568416,
            "ap": 0.539377,
            "ap_weighted": 0.539377
          },
          {
            "accuracy": 0.572266,
            "f1": 0.570742,
            "f1_weighted": 0.570792,
            "ap": 0.541007,
            "ap_weighted": 0.541007
          },
          {
            "accuracy": 0.578125,
            "f1": 0.576949,
            "f1_weighted": 0.576992,
            "ap": 0.544839,
            "ap_weighted": 0.544839
          },
          {
            "accuracy": 0.616699,
            "f1": 0.615444,
            "f1_weighted": 0.615401,
            "ap": 0.569678,
            "ap_weighted": 0.569678
          },
          {
            "accuracy": 0.615723,
            "f1": 0.595399,
            "f1_weighted": 0.595222,
            "ap": 0.566428,
            "ap_weighted": 0.566428
          },
          {
            "accuracy": 0.513672,
            "f1": 0.5069,
            "f1_weighted": 0.506787,
            "ap": 0.506131,
            "ap_weighted": 0.506131
          },
          {
            "accuracy": 0.547852,
            "f1": 0.547845,
            "f1_weighted": 0.547848,
            "ap": 0.525254,
            "ap_weighted": 0.525254
          }
        ],
        "main_score": 0.572559,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ]
      }
    ]
  },
  "evaluation_time": 115.47490000724792,
  "kg_co2_emissions": null
}