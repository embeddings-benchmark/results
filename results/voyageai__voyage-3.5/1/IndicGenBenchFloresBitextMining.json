{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.38.54",
  "scores": {
    "validation": [
      {
        "precision": 0.950435,
        "recall": 0.965898,
        "f1": 0.955433,
        "accuracy": 0.965898,
        "main_score": 0.955433,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.870445,
        "recall": 0.910732,
        "f1": 0.883283,
        "accuracy": 0.910732,
        "main_score": 0.883283,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.916249,
        "recall": 0.940822,
        "f1": 0.924024,
        "accuracy": 0.940822,
        "main_score": 0.924024,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.792695,
        "recall": 0.852558,
        "f1": 0.811067,
        "accuracy": 0.852558,
        "main_score": 0.811067,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.972919,
        "recall": 0.981946,
        "f1": 0.975928,
        "accuracy": 0.981946,
        "main_score": 0.975928,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.91207,
        "recall": 0.938816,
        "f1": 0.920395,
        "accuracy": 0.938816,
        "main_score": 0.920395,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.85886,
        "recall": 0.900702,
        "f1": 0.871983,
        "accuracy": 0.900702,
        "main_score": 0.871983,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.725937,
        "recall": 0.797392,
        "f1": 0.746925,
        "accuracy": 0.797392,
        "main_score": 0.746925,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.845045,
        "recall": 0.88666,
        "f1": 0.857957,
        "accuracy": 0.88666,
        "main_score": 0.857957,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.734386,
        "recall": 0.807422,
        "f1": 0.756522,
        "accuracy": 0.807422,
        "main_score": 0.756522,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.920679,
        "recall": 0.944835,
        "f1": 0.928318,
        "accuracy": 0.944835,
        "main_score": 0.928318,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.830257,
        "recall": 0.878636,
        "f1": 0.844968,
        "accuracy": 0.878636,
        "main_score": 0.844968,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.803519,
        "recall": 0.854564,
        "f1": 0.818545,
        "accuracy": 0.854564,
        "main_score": 0.818545,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.676522,
        "recall": 0.759278,
        "f1": 0.700337,
        "accuracy": 0.759278,
        "main_score": 0.700337,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.889679,
        "recall": 0.920762,
        "f1": 0.899448,
        "accuracy": 0.920762,
        "main_score": 0.899448,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.734656,
        "recall": 0.804413,
        "f1": 0.754951,
        "accuracy": 0.804413,
        "main_score": 0.754951,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.963056,
        "recall": 0.974925,
        "f1": 0.966901,
        "accuracy": 0.974925,
        "main_score": 0.966901,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.895436,
        "recall": 0.927783,
        "f1": 0.905617,
        "accuracy": 0.927783,
        "main_score": 0.905617,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.862939,
        "recall": 0.898696,
        "f1": 0.873759,
        "accuracy": 0.898696,
        "main_score": 0.873759,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.701748,
        "recall": 0.780341,
        "f1": 0.724791,
        "accuracy": 0.780341,
        "main_score": 0.724791,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.903377,
        "recall": 0.931795,
        "f1": 0.912156,
        "accuracy": 0.931795,
        "main_score": 0.912156,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.801581,
        "recall": 0.85657,
        "f1": 0.817971,
        "accuracy": 0.85657,
        "main_score": 0.817971,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.942828,
        "recall": 0.960883,
        "f1": 0.948679,
        "accuracy": 0.960883,
        "main_score": 0.948679,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.873872,
        "recall": 0.912738,
        "f1": 0.886225,
        "accuracy": 0.912738,
        "main_score": 0.886225,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.880568,
        "recall": 0.913741,
        "f1": 0.890622,
        "accuracy": 0.913741,
        "main_score": 0.890622,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.781822,
        "recall": 0.842528,
        "f1": 0.79985,
        "accuracy": 0.842528,
        "main_score": 0.79985,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.914888,
        "recall": 0.939819,
        "f1": 0.922651,
        "accuracy": 0.939819,
        "main_score": 0.922651,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.789268,
        "recall": 0.849549,
        "f1": 0.807441,
        "accuracy": 0.849549,
        "main_score": 0.807441,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.826173,
        "recall": 0.872618,
        "f1": 0.840374,
        "accuracy": 0.872618,
        "main_score": 0.840374,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.728053,
        "recall": 0.798395,
        "f1": 0.747977,
        "accuracy": 0.798395,
        "main_score": 0.747977,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.743131,
        "recall": 0.801404,
        "f1": 0.759816,
        "accuracy": 0.801404,
        "main_score": 0.759816,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.573642,
        "recall": 0.668004,
        "f1": 0.599314,
        "accuracy": 0.668004,
        "main_score": 0.599314,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.946506,
        "recall": 0.962889,
        "f1": 0.951856,
        "accuracy": 0.962889,
        "main_score": 0.951856,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.862454,
        "recall": 0.900702,
        "f1": 0.874242,
        "accuracy": 0.900702,
        "main_score": 0.874242,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.911797,
        "recall": 0.934804,
        "f1": 0.918689,
        "accuracy": 0.934804,
        "main_score": 0.918689,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.818489,
        "recall": 0.870612,
        "f1": 0.834236,
        "accuracy": 0.870612,
        "main_score": 0.834236,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.020061,
        "recall": 0.031093,
        "f1": 0.021484,
        "accuracy": 0.031093,
        "main_score": 0.021484,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015019,
        "recall": 0.038114,
        "f1": 0.018414,
        "accuracy": 0.038114,
        "main_score": 0.018414,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.268021,
        "recall": 0.307924,
        "f1": 0.278133,
        "accuracy": 0.307924,
        "main_score": 0.278133,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.172898,
        "recall": 0.274824,
        "f1": 0.195031,
        "accuracy": 0.274824,
        "main_score": 0.195031,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.896055,
        "recall": 0.927783,
        "f1": 0.906219,
        "accuracy": 0.927783,
        "main_score": 0.906219,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.801507,
        "recall": 0.855567,
        "f1": 0.817441,
        "accuracy": 0.855567,
        "main_score": 0.817441,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.718925,
        "recall": 0.778335,
        "f1": 0.736164,
        "accuracy": 0.778335,
        "main_score": 0.736164,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.576146,
        "recall": 0.677031,
        "f1": 0.604075,
        "accuracy": 0.677031,
        "main_score": 0.604075,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.8834,
        "recall": 0.915747,
        "f1": 0.893332,
        "accuracy": 0.915747,
        "main_score": 0.893332,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.766593,
        "recall": 0.831494,
        "f1": 0.786046,
        "accuracy": 0.831494,
        "main_score": 0.786046,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.891298,
        "recall": 0.921765,
        "f1": 0.900702,
        "accuracy": 0.921765,
        "main_score": 0.900702,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.760782,
        "recall": 0.830491,
        "f1": 0.781865,
        "accuracy": 0.830491,
        "main_score": 0.781865,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.928653,
        "recall": 0.94985,
        "f1": 0.935272,
        "accuracy": 0.94985,
        "main_score": 0.935272,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.820429,
        "recall": 0.871615,
        "f1": 0.836233,
        "accuracy": 0.871615,
        "main_score": 0.836233,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.2701,
        "recall": 0.307924,
        "f1": 0.278771,
        "accuracy": 0.307924,
        "main_score": 0.278771,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.175669,
        "recall": 0.280843,
        "f1": 0.198115,
        "accuracy": 0.280843,
        "main_score": 0.198115,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.911601,
        "recall": 0.93681,
        "f1": 0.919392,
        "accuracy": 0.93681,
        "main_score": 0.919392,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.788516,
        "recall": 0.848546,
        "f1": 0.806491,
        "accuracy": 0.848546,
        "main_score": 0.806491,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.927031,
        "recall": 0.948847,
        "f1": 0.933701,
        "accuracy": 0.948847,
        "main_score": 0.933701,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.815563,
        "recall": 0.869609,
        "f1": 0.832029,
        "accuracy": 0.869609,
        "main_score": 0.832029,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.006854,
        "recall": 0.008024,
        "f1": 0.007188,
        "accuracy": 0.008024,
        "main_score": 0.007188,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005709,
        "recall": 0.015045,
        "f1": 0.006661,
        "accuracy": 0.015045,
        "main_score": 0.006661,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.953722,
        "recall": 0.968379,
        "f1": 0.958498,
        "accuracy": 0.968379,
        "main_score": 0.958498,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.870002,
        "recall": 0.906126,
        "f1": 0.88105,
        "accuracy": 0.906126,
        "main_score": 0.88105,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.919121,
        "recall": 0.9417,
        "f1": 0.925955,
        "accuracy": 0.9417,
        "main_score": 0.925955,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.812582,
        "recall": 0.865613,
        "f1": 0.828247,
        "accuracy": 0.865613,
        "main_score": 0.828247,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.976943,
        "recall": 0.98419,
        "f1": 0.979249,
        "accuracy": 0.98419,
        "main_score": 0.979249,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.916584,
        "recall": 0.942688,
        "f1": 0.924967,
        "accuracy": 0.942688,
        "main_score": 0.924967,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.887822,
        "recall": 0.91996,
        "f1": 0.897777,
        "accuracy": 0.91996,
        "main_score": 0.897777,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.726508,
        "recall": 0.802372,
        "f1": 0.749184,
        "accuracy": 0.802372,
        "main_score": 0.749184,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.880517,
        "recall": 0.916008,
        "f1": 0.891653,
        "accuracy": 0.916008,
        "main_score": 0.891653,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.73018,
        "recall": 0.804348,
        "f1": 0.751998,
        "accuracy": 0.804348,
        "main_score": 0.751998,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.926581,
        "recall": 0.948617,
        "f1": 0.933597,
        "accuracy": 0.948617,
        "main_score": 0.933597,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.83111,
        "recall": 0.881423,
        "f1": 0.846542,
        "accuracy": 0.881423,
        "main_score": 0.846542,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.830067,
        "recall": 0.876482,
        "f1": 0.84401,
        "accuracy": 0.876482,
        "main_score": 0.84401,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.687411,
        "recall": 0.770751,
        "f1": 0.711728,
        "accuracy": 0.770751,
        "main_score": 0.711728,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.912961,
        "recall": 0.937747,
        "f1": 0.920455,
        "accuracy": 0.937747,
        "main_score": 0.920455,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.762744,
        "recall": 0.825099,
        "f1": 0.780948,
        "accuracy": 0.825099,
        "main_score": 0.780948,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.97332,
        "recall": 0.982213,
        "f1": 0.976285,
        "accuracy": 0.982213,
        "main_score": 0.976285,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.895751,
        "recall": 0.927866,
        "f1": 0.905962,
        "accuracy": 0.927866,
        "main_score": 0.905962,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.84632,
        "recall": 0.889328,
        "f1": 0.859371,
        "accuracy": 0.889328,
        "main_score": 0.859371,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.730896,
        "recall": 0.806324,
        "f1": 0.753506,
        "accuracy": 0.806324,
        "main_score": 0.753506,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.922134,
        "recall": 0.943676,
        "f1": 0.928491,
        "accuracy": 0.943676,
        "main_score": 0.928491,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.818881,
        "recall": 0.869565,
        "f1": 0.834354,
        "accuracy": 0.869565,
        "main_score": 0.834354,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.958827,
        "recall": 0.971344,
        "f1": 0.962945,
        "accuracy": 0.971344,
        "main_score": 0.962945,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.874539,
        "recall": 0.911067,
        "f1": 0.88579,
        "accuracy": 0.911067,
        "main_score": 0.88579,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.865464,
        "recall": 0.90415,
        "f1": 0.877518,
        "accuracy": 0.90415,
        "main_score": 0.877518,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.75276,
        "recall": 0.824111,
        "f1": 0.774325,
        "accuracy": 0.824111,
        "main_score": 0.774325,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.92206,
        "recall": 0.944664,
        "f1": 0.929073,
        "accuracy": 0.944664,
        "main_score": 0.929073,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.817812,
        "recall": 0.869565,
        "f1": 0.833435,
        "accuracy": 0.869565,
        "main_score": 0.833435,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.863679,
        "recall": 0.900198,
        "f1": 0.874555,
        "accuracy": 0.900198,
        "main_score": 0.874555,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.740893,
        "recall": 0.813241,
        "f1": 0.762451,
        "accuracy": 0.813241,
        "main_score": 0.762451,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.76362,
        "recall": 0.817194,
        "f1": 0.778848,
        "accuracy": 0.817194,
        "main_score": 0.778848,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.603082,
        "recall": 0.698617,
        "f1": 0.629594,
        "accuracy": 0.698617,
        "main_score": 0.629594,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.939394,
        "recall": 0.956522,
        "f1": 0.944796,
        "accuracy": 0.956522,
        "main_score": 0.944796,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.8528,
        "recall": 0.896245,
        "f1": 0.866568,
        "accuracy": 0.896245,
        "main_score": 0.866568,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.939921,
        "recall": 0.95751,
        "f1": 0.945323,
        "accuracy": 0.95751,
        "main_score": 0.945323,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.824061,
        "recall": 0.875494,
        "f1": 0.839921,
        "accuracy": 0.875494,
        "main_score": 0.839921,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.032832,
        "recall": 0.037549,
        "f1": 0.033996,
        "accuracy": 0.037549,
        "main_score": 0.033996,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01742,
        "recall": 0.037549,
        "f1": 0.020179,
        "accuracy": 0.037549,
        "main_score": 0.020179,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.201281,
        "recall": 0.238142,
        "f1": 0.210112,
        "accuracy": 0.238142,
        "main_score": 0.210112,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.16645,
        "recall": 0.248024,
        "f1": 0.183251,
        "accuracy": 0.248024,
        "main_score": 0.183251,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.903821,
        "recall": 0.93083,
        "f1": 0.912187,
        "accuracy": 0.93083,
        "main_score": 0.912187,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.817523,
        "recall": 0.870553,
        "f1": 0.833583,
        "accuracy": 0.870553,
        "main_score": 0.833583,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.732214,
        "recall": 0.789526,
        "f1": 0.748257,
        "accuracy": 0.789526,
        "main_score": 0.748257,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.622393,
        "recall": 0.718379,
        "f1": 0.649863,
        "accuracy": 0.718379,
        "main_score": 0.649863,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.899605,
        "recall": 0.926877,
        "f1": 0.90774,
        "accuracy": 0.926877,
        "main_score": 0.90774,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.781686,
        "recall": 0.844862,
        "f1": 0.800791,
        "accuracy": 0.844862,
        "main_score": 0.800791,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.909371,
        "recall": 0.934783,
        "f1": 0.91718,
        "accuracy": 0.934783,
        "main_score": 0.91718,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.809033,
        "recall": 0.863636,
        "f1": 0.825878,
        "accuracy": 0.863636,
        "main_score": 0.825878,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.917523,
        "recall": 0.940711,
        "f1": 0.924492,
        "accuracy": 0.940711,
        "main_score": 0.924492,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.830649,
        "recall": 0.878458,
        "f1": 0.845026,
        "accuracy": 0.878458,
        "main_score": 0.845026,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.261784,
        "recall": 0.3083,
        "f1": 0.27257,
        "accuracy": 0.3083,
        "main_score": 0.27257,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.184612,
        "recall": 0.283597,
        "f1": 0.205138,
        "accuracy": 0.283597,
        "main_score": 0.205138,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.915036,
        "recall": 0.938735,
        "f1": 0.922167,
        "accuracy": 0.938735,
        "main_score": 0.922167,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.803508,
        "recall": 0.860672,
        "f1": 0.820817,
        "accuracy": 0.860672,
        "main_score": 0.820817,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.926466,
        "recall": 0.947628,
        "f1": 0.93299,
        "accuracy": 0.947628,
        "main_score": 0.93299,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.835293,
        "recall": 0.884387,
        "f1": 0.850659,
        "accuracy": 0.884387,
        "main_score": 0.850659,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.008427,
        "recall": 0.01087,
        "f1": 0.008618,
        "accuracy": 0.01087,
        "main_score": 0.008618,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005534,
        "recall": 0.017787,
        "f1": 0.006779,
        "accuracy": 0.017787,
        "main_score": 0.006779,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 1075.3912992477417,
  "kg_co2_emissions": null
}