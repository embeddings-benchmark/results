{
  "dataset_revision": "87b7a0d1c402dbb481db649569c556d9aa27ac05",
  "task_name": "TweetTopicSingleClassification",
  "mteb_version": "1.38.48",
  "scores": {
    "test_2021": [
      {
        "accuracy": 0.773479,
        "f1": 0.608165,
        "f1_weighted": 0.78909,
        "scores_per_experiment": [
          {
            "accuracy": 0.782634,
            "f1": 0.600321,
            "f1_weighted": 0.794115
          },
          {
            "accuracy": 0.789132,
            "f1": 0.629247,
            "f1_weighted": 0.804684
          },
          {
            "accuracy": 0.731837,
            "f1": 0.580778,
            "f1_weighted": 0.760831
          },
          {
            "accuracy": 0.773184,
            "f1": 0.628362,
            "f1_weighted": 0.788849
          },
          {
            "accuracy": 0.790313,
            "f1": 0.640546,
            "f1_weighted": 0.80545
          },
          {
            "accuracy": 0.804489,
            "f1": 0.664332,
            "f1_weighted": 0.812866
          },
          {
            "accuracy": 0.744241,
            "f1": 0.534734,
            "f1_weighted": 0.754535
          },
          {
            "accuracy": 0.779681,
            "f1": 0.618255,
            "f1_weighted": 0.802186
          },
          {
            "accuracy": 0.756054,
            "f1": 0.58351,
            "f1_weighted": 0.771332
          },
          {
            "accuracy": 0.783225,
            "f1": 0.601564,
            "f1_weighted": 0.796055
          }
        ],
        "main_score": 0.773479,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 49.94997549057007,
  "kg_co2_emissions": null
}