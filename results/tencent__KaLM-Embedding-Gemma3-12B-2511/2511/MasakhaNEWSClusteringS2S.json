{
  "dataset_revision": "8ccc72e69e65f40c70e117d8b3c08306bb788b60",
  "task_name": "MasakhaNEWSClusteringS2S",
  "mteb_version": "1.38.48",
  "scores": {
    "test": [
      {
        "v_measure": 0.709134,
        "v_measure_std": 0.374763,
        "v_measures": [
          1.0,
          0.007039,
          0.641154,
          0.897476,
          1.0
        ],
        "main_score": 0.709134,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ]
      },
      {
        "v_measure": 0.67582,
        "v_measure_std": 0.29137,
        "v_measures": [
          0.162935,
          0.823038,
          0.548167,
          0.952321,
          0.89264
        ],
        "main_score": 0.67582,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "v_measure": 0.741573,
        "v_measure_std": 0.341986,
        "v_measures": [
          1.0,
          0.079929,
          0.852366,
          1.0,
          0.775569
        ],
        "main_score": 0.741573,
        "hf_subset": "fra",
        "languages": [
          "fra-Latn"
        ]
      },
      {
        "v_measure": 0.586637,
        "v_measure_std": 0.343368,
        "v_measures": [
          0.089392,
          0.356682,
          0.557462,
          0.929648,
          1.0
        ],
        "main_score": 0.586637,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ]
      },
      {
        "v_measure": 0.68863,
        "v_measure_std": 0.196946,
        "v_measures": [
          0.574609,
          0.428169,
          0.804316,
          1.0,
          0.636056
        ],
        "main_score": 0.68863,
        "hf_subset": "ibo",
        "languages": [
          "ibo-Latn"
        ]
      },
      {
        "v_measure": 0.826759,
        "v_measure_std": 0.219527,
        "v_measures": [
          0.655969,
          0.477825,
          1.0,
          1.0,
          1.0
        ],
        "main_score": 0.826759,
        "hf_subset": "lin",
        "languages": [
          "lin-Latn"
        ]
      },
      {
        "v_measure": 0.534993,
        "v_measure_std": 0.385577,
        "v_measures": [
          0.119132,
          0.224204,
          1.0,
          1.0,
          0.331631
        ],
        "main_score": 0.534993,
        "hf_subset": "lug",
        "languages": [
          "lug-Latn"
        ]
      },
      {
        "v_measure": 0.517576,
        "v_measure_std": 0.31742,
        "v_measures": [
          0.543897,
          0.031275,
          1.0,
          0.635992,
          0.376719
        ],
        "main_score": 0.517576,
        "hf_subset": "orm",
        "languages": [
          "orm-Ethi"
        ]
      },
      {
        "v_measure": 0.861283,
        "v_measure_std": 0.182608,
        "v_measures": [
          1.0,
          0.759059,
          0.547354,
          1.0,
          1.0
        ],
        "main_score": 0.861283,
        "hf_subset": "pcm",
        "languages": [
          "pcm-Latn"
        ]
      },
      {
        "v_measure": 0.662662,
        "v_measure_std": 0.353453,
        "v_measures": [
          0.444381,
          0.084282,
          1.0,
          0.784648,
          1.0
        ],
        "main_score": 0.662662,
        "hf_subset": "run",
        "languages": [
          "run-Latn"
        ]
      },
      {
        "v_measure": 0.647098,
        "v_measure_std": 0.322182,
        "v_measures": [
          1.0,
          0.425923,
          0.632351,
          0.177215,
          1.0
        ],
        "main_score": 0.647098,
        "hf_subset": "sna",
        "languages": [
          "sna-Latn"
        ]
      },
      {
        "v_measure": 0.490097,
        "v_measure_std": 0.305168,
        "v_measures": [
          0.490243,
          1.0,
          0.069361,
          0.334468,
          0.556416
        ],
        "main_score": 0.490097,
        "hf_subset": "som",
        "languages": [
          "som-Latn"
        ]
      },
      {
        "v_measure": 0.4462,
        "v_measure_std": 0.342231,
        "v_measures": [
          0.516137,
          0.074859,
          0.027334,
          0.869501,
          0.74317
        ],
        "main_score": 0.4462,
        "hf_subset": "swa",
        "languages": [
          "swa-Latn"
        ]
      },
      {
        "v_measure": 0.66213,
        "v_measure_std": 0.346627,
        "v_measures": [
          0.521913,
          1.0,
          0.070807,
          1.0,
          0.71793
        ],
        "main_score": 0.66213,
        "hf_subset": "tir",
        "languages": [
          "tir-Ethi"
        ]
      },
      {
        "v_measure": 0.440377,
        "v_measure_std": 0.300058,
        "v_measures": [
          0.293297,
          0.171152,
          0.241025,
          0.496412,
          1.0
        ],
        "main_score": 0.440377,
        "hf_subset": "xho",
        "languages": [
          "xho-Latn"
        ]
      },
      {
        "v_measure": 0.707135,
        "v_measure_std": 0.227998,
        "v_measures": [
          1.0,
          0.671444,
          0.305848,
          0.80616,
          0.752224
        ],
        "main_score": 0.707135,
        "hf_subset": "yor",
        "languages": [
          "yor-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 226.2137050628662,
  "kg_co2_emissions": null
}