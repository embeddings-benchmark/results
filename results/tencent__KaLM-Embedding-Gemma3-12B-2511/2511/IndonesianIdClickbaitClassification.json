{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.38.48",
  "scores": {
    "train": [
      {
        "accuracy": 0.619482,
        "f1": 0.613259,
        "f1_weighted": 0.619,
        "ap": 0.501475,
        "ap_weighted": 0.501475,
        "scores_per_experiment": [
          {
            "accuracy": 0.692383,
            "f1": 0.673379,
            "f1_weighted": 0.686074,
            "ap": 0.551372,
            "ap_weighted": 0.551372
          },
          {
            "accuracy": 0.512695,
            "f1": 0.509851,
            "f1_weighted": 0.503835,
            "ap": 0.439716,
            "ap_weighted": 0.439716
          },
          {
            "accuracy": 0.619629,
            "f1": 0.612748,
            "f1_weighted": 0.621066,
            "ap": 0.491458,
            "ap_weighted": 0.491458
          },
          {
            "accuracy": 0.655762,
            "f1": 0.647092,
            "f1_weighted": 0.656005,
            "ap": 0.520132,
            "ap_weighted": 0.520132
          },
          {
            "accuracy": 0.651855,
            "f1": 0.649175,
            "f1_weighted": 0.654116,
            "ap": 0.522278,
            "ap_weighted": 0.522278
          },
          {
            "accuracy": 0.463379,
            "f1": 0.462222,
            "f1_weighted": 0.466241,
            "ap": 0.404957,
            "ap_weighted": 0.404957
          },
          {
            "accuracy": 0.697266,
            "f1": 0.688994,
            "f1_weighted": 0.697167,
            "ap": 0.559738,
            "ap_weighted": 0.559738
          },
          {
            "accuracy": 0.641113,
            "f1": 0.638769,
            "f1_weighted": 0.643458,
            "ap": 0.513728,
            "ap_weighted": 0.513728
          },
          {
            "accuracy": 0.590332,
            "f1": 0.589811,
            "f1_weighted": 0.592167,
            "ap": 0.478632,
            "ap_weighted": 0.478632
          },
          {
            "accuracy": 0.67041,
            "f1": 0.660553,
            "f1_weighted": 0.669874,
            "ap": 0.532735,
            "ap_weighted": 0.532735
          }
        ],
        "main_score": 0.613259,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 27.66240382194519,
  "kg_co2_emissions": null
}