{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.989468,
        "recall": 0.992979,
        "f1": 0.990639,
        "accuracy": 0.992979,
        "main_score": 0.990639,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.96991,
        "recall": 0.97994,
        "f1": 0.973253,
        "accuracy": 0.97994,
        "main_score": 0.973253,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.982447,
        "recall": 0.987964,
        "f1": 0.984286,
        "accuracy": 0.987964,
        "main_score": 0.984286,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.977432,
        "recall": 0.984955,
        "f1": 0.97994,
        "accuracy": 0.984955,
        "main_score": 0.97994,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.992812,
        "recall": 0.994985,
        "f1": 0.99348,
        "accuracy": 0.994985,
        "main_score": 0.99348,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.989803,
        "recall": 0.992979,
        "f1": 0.990806,
        "accuracy": 0.992979,
        "main_score": 0.990806,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.976429,
        "recall": 0.983952,
        "f1": 0.978937,
        "accuracy": 0.983952,
        "main_score": 0.978937,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.98345,
        "recall": 0.988967,
        "f1": 0.985289,
        "accuracy": 0.988967,
        "main_score": 0.985289,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.984955,
        "recall": 0.98997,
        "f1": 0.986627,
        "accuracy": 0.98997,
        "main_score": 0.986627,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.978937,
        "recall": 0.985958,
        "f1": 0.981277,
        "accuracy": 0.985958,
        "main_score": 0.981277,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.993982,
        "recall": 0.995988,
        "f1": 0.994651,
        "accuracy": 0.995988,
        "main_score": 0.994651,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.983785,
        "recall": 0.988967,
        "f1": 0.985456,
        "accuracy": 0.988967,
        "main_score": 0.985456,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.984955,
        "recall": 0.98997,
        "f1": 0.986627,
        "accuracy": 0.98997,
        "main_score": 0.986627,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.974758,
        "recall": 0.982949,
        "f1": 0.977432,
        "accuracy": 0.982949,
        "main_score": 0.977432,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.970578,
        "recall": 0.97994,
        "f1": 0.973587,
        "accuracy": 0.97994,
        "main_score": 0.973587,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.966901,
        "recall": 0.977934,
        "f1": 0.970578,
        "accuracy": 0.977934,
        "main_score": 0.970578,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.98345,
        "recall": 0.988967,
        "f1": 0.985289,
        "accuracy": 0.988967,
        "main_score": 0.985289,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.972919,
        "recall": 0.981946,
        "f1": 0.975928,
        "accuracy": 0.981946,
        "main_score": 0.975928,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.880033,
        "recall": 0.913741,
        "f1": 0.890488,
        "accuracy": 0.913741,
        "main_score": 0.890488,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.872116,
        "recall": 0.910732,
        "f1": 0.884286,
        "accuracy": 0.910732,
        "main_score": 0.884286,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.909813,
        "recall": 0.937813,
        "f1": 0.918823,
        "accuracy": 0.937813,
        "main_score": 0.918823,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.891591,
        "recall": 0.924774,
        "f1": 0.902273,
        "accuracy": 0.924774,
        "main_score": 0.902273,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.982447,
        "recall": 0.987964,
        "f1": 0.984286,
        "accuracy": 0.987964,
        "main_score": 0.984286,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.970913,
        "recall": 0.97994,
        "f1": 0.973922,
        "accuracy": 0.97994,
        "main_score": 0.973922,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.960047,
        "recall": 0.972919,
        "f1": 0.964226,
        "accuracy": 0.972919,
        "main_score": 0.964226,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.965731,
        "recall": 0.976931,
        "f1": 0.969408,
        "accuracy": 0.976931,
        "main_score": 0.969408,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.964644,
        "recall": 0.975928,
        "f1": 0.968305,
        "accuracy": 0.975928,
        "main_score": 0.968305,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.965396,
        "recall": 0.976931,
        "f1": 0.969241,
        "accuracy": 0.976931,
        "main_score": 0.969241,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.956035,
        "recall": 0.96991,
        "f1": 0.960548,
        "accuracy": 0.96991,
        "main_score": 0.960548,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.92561,
        "recall": 0.94985,
        "f1": 0.933634,
        "accuracy": 0.94985,
        "main_score": 0.933634,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.848078,
        "recall": 0.892678,
        "f1": 0.862053,
        "accuracy": 0.892678,
        "main_score": 0.862053,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.854062,
        "recall": 0.89669,
        "f1": 0.867569,
        "accuracy": 0.89669,
        "main_score": 0.867569,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.967904,
        "recall": 0.977934,
        "f1": 0.971247,
        "accuracy": 0.977934,
        "main_score": 0.971247,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.972083,
        "recall": 0.97994,
        "f1": 0.97459,
        "accuracy": 0.97994,
        "main_score": 0.97459,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.930625,
        "recall": 0.952859,
        "f1": 0.937813,
        "accuracy": 0.952859,
        "main_score": 0.937813,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.92678,
        "recall": 0.94985,
        "f1": 0.934303,
        "accuracy": 0.94985,
        "main_score": 0.934303,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.034258,
        "recall": 0.048144,
        "f1": 0.036943,
        "accuracy": 0.048144,
        "main_score": 0.036943,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025456,
        "recall": 0.074223,
        "f1": 0.031736,
        "accuracy": 0.074223,
        "main_score": 0.031736,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.102278,
        "recall": 0.132397,
        "f1": 0.108841,
        "accuracy": 0.132397,
        "main_score": 0.108841,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.143342,
        "recall": 0.235707,
        "f1": 0.163565,
        "accuracy": 0.235707,
        "main_score": 0.163565,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.922601,
        "recall": 0.946841,
        "f1": 0.930458,
        "accuracy": 0.946841,
        "main_score": 0.930458,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.916082,
        "recall": 0.942828,
        "f1": 0.924774,
        "accuracy": 0.942828,
        "main_score": 0.924774,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.657282,
        "recall": 0.7332,
        "f1": 0.679109,
        "accuracy": 0.7332,
        "main_score": 0.679109,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.694868,
        "recall": 0.774323,
        "f1": 0.718895,
        "accuracy": 0.774323,
        "main_score": 0.718895,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.888332,
        "recall": 0.921765,
        "f1": 0.89883,
        "accuracy": 0.921765,
        "main_score": 0.89883,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.899532,
        "recall": 0.930792,
        "f1": 0.909729,
        "accuracy": 0.930792,
        "main_score": 0.909729,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.900234,
        "recall": 0.930792,
        "f1": 0.909896,
        "accuracy": 0.930792,
        "main_score": 0.909896,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.872367,
        "recall": 0.910732,
        "f1": 0.884888,
        "accuracy": 0.910732,
        "main_score": 0.884888,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.922601,
        "recall": 0.947844,
        "f1": 0.93096,
        "accuracy": 0.947844,
        "main_score": 0.93096,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.922016,
        "recall": 0.945838,
        "f1": 0.929522,
        "accuracy": 0.945838,
        "main_score": 0.929522,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.093767,
        "recall": 0.115346,
        "f1": 0.098889,
        "accuracy": 0.115346,
        "main_score": 0.098889,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.123779,
        "recall": 0.21665,
        "f1": 0.142429,
        "accuracy": 0.21665,
        "main_score": 0.142429,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.914577,
        "recall": 0.941825,
        "f1": 0.923437,
        "accuracy": 0.941825,
        "main_score": 0.923437,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.924975,
        "recall": 0.948847,
        "f1": 0.932798,
        "accuracy": 0.948847,
        "main_score": 0.932798,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.934637,
        "recall": 0.955868,
        "f1": 0.941658,
        "accuracy": 0.955868,
        "main_score": 0.941658,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.926112,
        "recall": 0.94985,
        "f1": 0.933801,
        "accuracy": 0.94985,
        "main_score": 0.933801,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.004013,
        "recall": 0.005015,
        "f1": 0.004014,
        "accuracy": 0.005015,
        "main_score": 0.004014,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000955,
        "recall": 0.014042,
        "f1": 0.001663,
        "accuracy": 0.014042,
        "main_score": 0.001663,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.984025,
        "recall": 0.98913,
        "f1": 0.985672,
        "accuracy": 0.98913,
        "main_score": 0.985672,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.976614,
        "recall": 0.98419,
        "f1": 0.979084,
        "accuracy": 0.98419,
        "main_score": 0.979084,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.98666,
        "recall": 0.991107,
        "f1": 0.988142,
        "accuracy": 0.991107,
        "main_score": 0.988142,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.986989,
        "recall": 0.991107,
        "f1": 0.988307,
        "accuracy": 0.991107,
        "main_score": 0.988307,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.997036,
        "recall": 0.998024,
        "f1": 0.997365,
        "accuracy": 0.998024,
        "main_score": 0.997365,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.995553,
        "recall": 0.997036,
        "f1": 0.996047,
        "accuracy": 0.997036,
        "main_score": 0.996047,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.979578,
        "recall": 0.986166,
        "f1": 0.981719,
        "accuracy": 0.986166,
        "main_score": 0.981719,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.976614,
        "recall": 0.98419,
        "f1": 0.979084,
        "accuracy": 0.98419,
        "main_score": 0.979084,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.992589,
        "recall": 0.995059,
        "f1": 0.993412,
        "accuracy": 0.995059,
        "main_score": 0.993412,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.985507,
        "recall": 0.990119,
        "f1": 0.986989,
        "accuracy": 0.990119,
        "main_score": 0.986989,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.995553,
        "recall": 0.997036,
        "f1": 0.996047,
        "accuracy": 0.997036,
        "main_score": 0.996047,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.985178,
        "recall": 0.990119,
        "f1": 0.986825,
        "accuracy": 0.990119,
        "main_score": 0.986825,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.982955,
        "recall": 0.988142,
        "f1": 0.984585,
        "accuracy": 0.988142,
        "main_score": 0.984585,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.989954,
        "recall": 0.993083,
        "f1": 0.990942,
        "accuracy": 0.993083,
        "main_score": 0.990942,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.982543,
        "recall": 0.988142,
        "f1": 0.984354,
        "accuracy": 0.988142,
        "main_score": 0.984354,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.981061,
        "recall": 0.987154,
        "f1": 0.983037,
        "accuracy": 0.987154,
        "main_score": 0.983037,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.98419,
        "recall": 0.98913,
        "f1": 0.985837,
        "accuracy": 0.98913,
        "main_score": 0.985837,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.981061,
        "recall": 0.987154,
        "f1": 0.983037,
        "accuracy": 0.987154,
        "main_score": 0.983037,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.891798,
        "recall": 0.924901,
        "f1": 0.902292,
        "accuracy": 0.924901,
        "main_score": 0.902292,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.910738,
        "recall": 0.939723,
        "f1": 0.92029,
        "accuracy": 0.939723,
        "main_score": 0.92029,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.902833,
        "recall": 0.93083,
        "f1": 0.911693,
        "accuracy": 0.93083,
        "main_score": 0.911693,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.909338,
        "recall": 0.936759,
        "f1": 0.91805,
        "accuracy": 0.936759,
        "main_score": 0.91805,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.98419,
        "recall": 0.98913,
        "f1": 0.985837,
        "accuracy": 0.98913,
        "main_score": 0.985837,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.980567,
        "recall": 0.986166,
        "f1": 0.982378,
        "accuracy": 0.986166,
        "main_score": 0.982378,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.962204,
        "recall": 0.974308,
        "f1": 0.96614,
        "accuracy": 0.974308,
        "main_score": 0.96614,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.969697,
        "recall": 0.979249,
        "f1": 0.972826,
        "accuracy": 0.979249,
        "main_score": 0.972826,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.970685,
        "recall": 0.980237,
        "f1": 0.973814,
        "accuracy": 0.980237,
        "main_score": 0.973814,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.976285,
        "recall": 0.98419,
        "f1": 0.97892,
        "accuracy": 0.98419,
        "main_score": 0.97892,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.952404,
        "recall": 0.967391,
        "f1": 0.957181,
        "accuracy": 0.967391,
        "main_score": 0.957181,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.943709,
        "recall": 0.961462,
        "f1": 0.94944,
        "accuracy": 0.961462,
        "main_score": 0.94944,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.889163,
        "recall": 0.922925,
        "f1": 0.900033,
        "accuracy": 0.922925,
        "main_score": 0.900033,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.902009,
        "recall": 0.929842,
        "f1": 0.910705,
        "accuracy": 0.929842,
        "main_score": 0.910705,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.968709,
        "recall": 0.978261,
        "f1": 0.971838,
        "accuracy": 0.978261,
        "main_score": 0.971838,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.954545,
        "recall": 0.967391,
        "f1": 0.958663,
        "accuracy": 0.967391,
        "main_score": 0.958663,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.941947,
        "recall": 0.959486,
        "f1": 0.94753,
        "accuracy": 0.959486,
        "main_score": 0.94753,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.950593,
        "recall": 0.966403,
        "f1": 0.955698,
        "accuracy": 0.966403,
        "main_score": 0.955698,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.02835,
        "recall": 0.039526,
        "f1": 0.029863,
        "accuracy": 0.039526,
        "main_score": 0.029863,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027322,
        "recall": 0.071146,
        "f1": 0.033407,
        "accuracy": 0.071146,
        "main_score": 0.033407,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.096017,
        "recall": 0.113636,
        "f1": 0.099819,
        "accuracy": 0.113636,
        "main_score": 0.099819,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.144597,
        "recall": 0.231225,
        "f1": 0.163352,
        "accuracy": 0.231225,
        "main_score": 0.163352,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.919713,
        "recall": 0.944664,
        "f1": 0.927767,
        "accuracy": 0.944664,
        "main_score": 0.927767,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.926005,
        "recall": 0.948617,
        "f1": 0.933202,
        "accuracy": 0.948617,
        "main_score": 0.933202,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.690083,
        "recall": 0.76087,
        "f1": 0.709658,
        "accuracy": 0.76087,
        "main_score": 0.709658,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.731143,
        "recall": 0.805336,
        "f1": 0.753623,
        "accuracy": 0.805336,
        "main_score": 0.753623,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.907279,
        "recall": 0.936759,
        "f1": 0.916831,
        "accuracy": 0.936759,
        "main_score": 0.916831,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.901268,
        "recall": 0.931818,
        "f1": 0.911133,
        "accuracy": 0.931818,
        "main_score": 0.911133,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.904397,
        "recall": 0.932806,
        "f1": 0.913241,
        "accuracy": 0.932806,
        "main_score": 0.913241,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.927207,
        "recall": 0.949605,
        "f1": 0.934453,
        "accuracy": 0.949605,
        "main_score": 0.934453,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.926054,
        "recall": 0.947628,
        "f1": 0.932924,
        "accuracy": 0.947628,
        "main_score": 0.932924,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.926219,
        "recall": 0.948617,
        "f1": 0.933267,
        "accuracy": 0.948617,
        "main_score": 0.933267,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.073003,
        "recall": 0.091897,
        "f1": 0.077245,
        "accuracy": 0.091897,
        "main_score": 0.077245,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.105077,
        "recall": 0.190711,
        "f1": 0.121889,
        "accuracy": 0.190711,
        "main_score": 0.121889,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.929792,
        "recall": 0.950593,
        "f1": 0.936166,
        "accuracy": 0.950593,
        "main_score": 0.936166,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.953096,
        "recall": 0.967391,
        "f1": 0.957675,
        "accuracy": 0.967391,
        "main_score": 0.957675,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.933877,
        "recall": 0.954545,
        "f1": 0.940448,
        "accuracy": 0.954545,
        "main_score": 0.940448,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.950428,
        "recall": 0.966403,
        "f1": 0.955698,
        "accuracy": 0.966403,
        "main_score": 0.955698,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.006918,
        "recall": 0.007905,
        "f1": 0.006919,
        "accuracy": 0.007905,
        "main_score": 0.006919,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003186,
        "recall": 0.021739,
        "f1": 0.00449,
        "accuracy": 0.021739,
        "main_score": 0.00449,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 242.9391987323761,
  "kg_co2_emissions": 0.019554393666425175
}