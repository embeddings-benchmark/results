{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.333447,
        "f1": 0.27428,
        "f1_weighted": 0.34907,
        "scores_per_experiment": [
          {
            "accuracy": 0.33252,
            "f1": 0.273845,
            "f1_weighted": 0.350182
          },
          {
            "accuracy": 0.329102,
            "f1": 0.275167,
            "f1_weighted": 0.34442
          },
          {
            "accuracy": 0.319824,
            "f1": 0.261746,
            "f1_weighted": 0.332875
          },
          {
            "accuracy": 0.325195,
            "f1": 0.270164,
            "f1_weighted": 0.338374
          },
          {
            "accuracy": 0.325195,
            "f1": 0.268741,
            "f1_weighted": 0.341878
          },
          {
            "accuracy": 0.331543,
            "f1": 0.269461,
            "f1_weighted": 0.350628
          },
          {
            "accuracy": 0.345703,
            "f1": 0.281856,
            "f1_weighted": 0.364415
          },
          {
            "accuracy": 0.335938,
            "f1": 0.284498,
            "f1_weighted": 0.350978
          },
          {
            "accuracy": 0.355957,
            "f1": 0.28357,
            "f1_weighted": 0.3679
          },
          {
            "accuracy": 0.333496,
            "f1": 0.273749,
            "f1_weighted": 0.34905
          }
        ],
        "main_score": 0.333447,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.330127,
        "f1": 0.295785,
        "f1_weighted": 0.341748,
        "scores_per_experiment": [
          {
            "accuracy": 0.328613,
            "f1": 0.294611,
            "f1_weighted": 0.340848
          },
          {
            "accuracy": 0.347168,
            "f1": 0.307761,
            "f1_weighted": 0.359414
          },
          {
            "accuracy": 0.327148,
            "f1": 0.297674,
            "f1_weighted": 0.336388
          },
          {
            "accuracy": 0.327637,
            "f1": 0.289404,
            "f1_weighted": 0.339156
          },
          {
            "accuracy": 0.32666,
            "f1": 0.297451,
            "f1_weighted": 0.339997
          },
          {
            "accuracy": 0.325195,
            "f1": 0.308025,
            "f1_weighted": 0.335984
          },
          {
            "accuracy": 0.328125,
            "f1": 0.287286,
            "f1_weighted": 0.339025
          },
          {
            "accuracy": 0.332031,
            "f1": 0.293554,
            "f1_weighted": 0.340888
          },
          {
            "accuracy": 0.32373,
            "f1": 0.287998,
            "f1_weighted": 0.337105
          },
          {
            "accuracy": 0.334961,
            "f1": 0.294086,
            "f1_weighted": 0.348678
          }
        ],
        "main_score": 0.330127,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 1440.1515052318573,
  "kg_co2_emissions": 0.06182466238518565
}