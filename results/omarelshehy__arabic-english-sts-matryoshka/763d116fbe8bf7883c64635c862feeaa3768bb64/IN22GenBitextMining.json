{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.966634,
        "recall": 0.976562,
        "f1": 0.969889,
        "accuracy": 0.976562,
        "main_score": 0.969889,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.187692,
        "recall": 0.261719,
        "f1": 0.204012,
        "accuracy": 0.261719,
        "main_score": 0.204012,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.768896,
        "recall": 0.830078,
        "f1": 0.787826,
        "accuracy": 0.830078,
        "main_score": 0.787826,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.944824,
        "recall": 0.961914,
        "f1": 0.950358,
        "accuracy": 0.961914,
        "main_score": 0.950358,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.71154,
        "recall": 0.780273,
        "f1": 0.731971,
        "accuracy": 0.780273,
        "main_score": 0.731971,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.942383,
        "recall": 0.960938,
        "f1": 0.948405,
        "accuracy": 0.960938,
        "main_score": 0.948405,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.943441,
        "recall": 0.960938,
        "f1": 0.948958,
        "accuracy": 0.960938,
        "main_score": 0.948958,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.95109,
        "recall": 0.96582,
        "f1": 0.955794,
        "accuracy": 0.96582,
        "main_score": 0.955794,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.414184,
        "recall": 0.518555,
        "f1": 0.442128,
        "accuracy": 0.518555,
        "main_score": 0.442128,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.868164,
        "recall": 0.90625,
        "f1": 0.880013,
        "accuracy": 0.90625,
        "main_score": 0.880013,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.939616,
        "recall": 0.958984,
        "f1": 0.945964,
        "accuracy": 0.958984,
        "main_score": 0.945964,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.947217,
        "recall": 0.962891,
        "f1": 0.952051,
        "accuracy": 0.962891,
        "main_score": 0.952051,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000761,
        "recall": 0.007812,
        "f1": 0.001273,
        "accuracy": 0.007812,
        "main_score": 0.001273,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.94751,
        "recall": 0.962891,
        "f1": 0.952376,
        "accuracy": 0.962891,
        "main_score": 0.952376,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.951335,
        "recall": 0.966797,
        "f1": 0.95638,
        "accuracy": 0.966797,
        "main_score": 0.95638,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.897298,
        "recall": 0.928711,
        "f1": 0.907552,
        "accuracy": 0.928711,
        "main_score": 0.907552,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.904785,
        "recall": 0.932617,
        "f1": 0.913737,
        "accuracy": 0.932617,
        "main_score": 0.913737,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000648,
        "recall": 0.009766,
        "f1": 0.001101,
        "accuracy": 0.009766,
        "main_score": 0.001101,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.614221,
        "recall": 0.695312,
        "f1": 0.637387,
        "accuracy": 0.695312,
        "main_score": 0.637387,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.927165,
        "recall": 0.948242,
        "f1": 0.933659,
        "accuracy": 0.948242,
        "main_score": 0.933659,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.941732,
        "recall": 0.959961,
        "f1": 0.947754,
        "accuracy": 0.959961,
        "main_score": 0.947754,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.947266,
        "recall": 0.963867,
        "f1": 0.952637,
        "accuracy": 0.963867,
        "main_score": 0.952637,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.972982,
        "recall": 0.981445,
        "f1": 0.975749,
        "accuracy": 0.981445,
        "main_score": 0.975749,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.184942,
        "recall": 0.272461,
        "f1": 0.204345,
        "accuracy": 0.272461,
        "main_score": 0.204345,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.800537,
        "recall": 0.858398,
        "f1": 0.818638,
        "accuracy": 0.858398,
        "main_score": 0.818638,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.74974,
        "recall": 0.813477,
        "f1": 0.768913,
        "accuracy": 0.813477,
        "main_score": 0.768913,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.98763,
        "recall": 0.991211,
        "f1": 0.98877,
        "accuracy": 0.991211,
        "main_score": 0.98877,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.985677,
        "recall": 0.990234,
        "f1": 0.987142,
        "accuracy": 0.990234,
        "main_score": 0.987142,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.394466,
        "recall": 0.506836,
        "f1": 0.423547,
        "accuracy": 0.506836,
        "main_score": 0.423547,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.917318,
        "recall": 0.943359,
        "f1": 0.925944,
        "accuracy": 0.943359,
        "main_score": 0.925944,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.984375,
        "recall": 0.989258,
        "f1": 0.986003,
        "accuracy": 0.989258,
        "main_score": 0.986003,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000243,
        "recall": 0.004883,
        "f1": 0.000451,
        "accuracy": 0.004883,
        "main_score": 0.000451,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.946777,
        "recall": 0.963867,
        "f1": 0.952311,
        "accuracy": 0.963867,
        "main_score": 0.952311,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.907959,
        "recall": 0.936523,
        "f1": 0.91722,
        "accuracy": 0.936523,
        "main_score": 0.91722,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000543,
        "recall": 0.010742,
        "f1": 0.000986,
        "accuracy": 0.010742,
        "main_score": 0.000986,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.632189,
        "recall": 0.713867,
        "f1": 0.655486,
        "accuracy": 0.713867,
        "main_score": 0.655486,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.97998,
        "recall": 0.986328,
        "f1": 0.982096,
        "accuracy": 0.986328,
        "main_score": 0.982096,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.976562,
        "recall": 0.984375,
        "f1": 0.979167,
        "accuracy": 0.984375,
        "main_score": 0.979167,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.122128,
        "recall": 0.151367,
        "f1": 0.127958,
        "accuracy": 0.151367,
        "main_score": 0.127958,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.102615,
        "recall": 0.125977,
        "f1": 0.107061,
        "accuracy": 0.125977,
        "main_score": 0.107061,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.201038,
        "recall": 0.232422,
        "f1": 0.207787,
        "accuracy": 0.232422,
        "main_score": 0.207787,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.103957,
        "recall": 0.125977,
        "f1": 0.108546,
        "accuracy": 0.125977,
        "main_score": 0.108546,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.192028,
        "recall": 0.21875,
        "f1": 0.19698,
        "accuracy": 0.21875,
        "main_score": 0.19698,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.105257,
        "recall": 0.132812,
        "f1": 0.110273,
        "accuracy": 0.132812,
        "main_score": 0.110273,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.123984,
        "recall": 0.142578,
        "f1": 0.127859,
        "accuracy": 0.142578,
        "main_score": 0.127859,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.087522,
        "recall": 0.107422,
        "f1": 0.091743,
        "accuracy": 0.107422,
        "main_score": 0.091743,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.176499,
        "recall": 0.214844,
        "f1": 0.184837,
        "accuracy": 0.214844,
        "main_score": 0.184837,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.1499,
        "recall": 0.176758,
        "f1": 0.15561,
        "accuracy": 0.176758,
        "main_score": 0.15561,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.120955,
        "recall": 0.143555,
        "f1": 0.125858,
        "accuracy": 0.143555,
        "main_score": 0.125858,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.101873,
        "recall": 0.124023,
        "f1": 0.105979,
        "accuracy": 0.124023,
        "main_score": 0.105979,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001396,
        "recall": 0.004883,
        "f1": 0.001639,
        "accuracy": 0.004883,
        "main_score": 0.001639,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.106816,
        "recall": 0.124023,
        "f1": 0.11033,
        "accuracy": 0.124023,
        "main_score": 0.11033,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.095892,
        "recall": 0.128906,
        "f1": 0.102187,
        "accuracy": 0.128906,
        "main_score": 0.102187,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.117895,
        "recall": 0.146484,
        "f1": 0.12337,
        "accuracy": 0.146484,
        "main_score": 0.12337,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.114914,
        "recall": 0.146484,
        "f1": 0.12121,
        "accuracy": 0.146484,
        "main_score": 0.12121,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002918,
        "recall": 0.009766,
        "f1": 0.003419,
        "accuracy": 0.009766,
        "main_score": 0.003419,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.203281,
        "recall": 0.224609,
        "f1": 0.209137,
        "accuracy": 0.224609,
        "main_score": 0.209137,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.112238,
        "recall": 0.130859,
        "f1": 0.116011,
        "accuracy": 0.130859,
        "main_score": 0.116011,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.121684,
        "recall": 0.143555,
        "f1": 0.125768,
        "accuracy": 0.143555,
        "main_score": 0.125768,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.110658,
        "recall": 0.133789,
        "f1": 0.115228,
        "accuracy": 0.133789,
        "main_score": 0.115228,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.71832,
        "recall": 0.786133,
        "f1": 0.737893,
        "accuracy": 0.786133,
        "main_score": 0.737893,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.76901,
        "recall": 0.823242,
        "f1": 0.784459,
        "accuracy": 0.823242,
        "main_score": 0.784459,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.286693,
        "recall": 0.359375,
        "f1": 0.303421,
        "accuracy": 0.359375,
        "main_score": 0.303421,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.785256,
        "recall": 0.837891,
        "f1": 0.800312,
        "accuracy": 0.837891,
        "main_score": 0.800312,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.718685,
        "recall": 0.786133,
        "f1": 0.739225,
        "accuracy": 0.786133,
        "main_score": 0.739225,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.762882,
        "recall": 0.826172,
        "f1": 0.782053,
        "accuracy": 0.826172,
        "main_score": 0.782053,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.811133,
        "recall": 0.864258,
        "f1": 0.827246,
        "accuracy": 0.864258,
        "main_score": 0.827246,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.778659,
        "recall": 0.833008,
        "f1": 0.794373,
        "accuracy": 0.833008,
        "main_score": 0.794373,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.472433,
        "recall": 0.55957,
        "f1": 0.495692,
        "accuracy": 0.55957,
        "main_score": 0.495692,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.841732,
        "recall": 0.884766,
        "f1": 0.854427,
        "accuracy": 0.884766,
        "main_score": 0.854427,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.758333,
        "recall": 0.820312,
        "f1": 0.7766,
        "accuracy": 0.820312,
        "main_score": 0.7766,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.797275,
        "recall": 0.84668,
        "f1": 0.812014,
        "accuracy": 0.84668,
        "main_score": 0.812014,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000556,
        "recall": 0.004883,
        "f1": 0.000957,
        "accuracy": 0.004883,
        "main_score": 0.000957,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.808968,
        "recall": 0.859375,
        "f1": 0.823828,
        "accuracy": 0.859375,
        "main_score": 0.823828,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.750049,
        "recall": 0.808594,
        "f1": 0.767296,
        "accuracy": 0.808594,
        "main_score": 0.767296,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.739144,
        "recall": 0.801758,
        "f1": 0.757375,
        "accuracy": 0.801758,
        "main_score": 0.757375,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.73422,
        "recall": 0.798828,
        "f1": 0.753119,
        "accuracy": 0.798828,
        "main_score": 0.753119,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000586,
        "recall": 0.008789,
        "f1": 0.001035,
        "accuracy": 0.008789,
        "main_score": 0.001035,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.695939,
        "recall": 0.759766,
        "f1": 0.714624,
        "accuracy": 0.759766,
        "main_score": 0.714624,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.765918,
        "recall": 0.824219,
        "f1": 0.783105,
        "accuracy": 0.824219,
        "main_score": 0.783105,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.784066,
        "recall": 0.838867,
        "f1": 0.800246,
        "accuracy": 0.838867,
        "main_score": 0.800246,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.789626,
        "recall": 0.84375,
        "f1": 0.805729,
        "accuracy": 0.84375,
        "main_score": 0.805729,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.945475,
        "recall": 0.962891,
        "f1": 0.951172,
        "accuracy": 0.962891,
        "main_score": 0.951172,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.208553,
        "recall": 0.298828,
        "f1": 0.229356,
        "accuracy": 0.298828,
        "main_score": 0.229356,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.827637,
        "recall": 0.87793,
        "f1": 0.843392,
        "accuracy": 0.87793,
        "main_score": 0.843392,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.755143,
        "recall": 0.819336,
        "f1": 0.774628,
        "accuracy": 0.819336,
        "main_score": 0.774628,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.997396,
        "recall": 0.998047,
        "f1": 0.997559,
        "accuracy": 0.998047,
        "main_score": 0.997559,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.417794,
        "recall": 0.52832,
        "f1": 0.44636,
        "accuracy": 0.52832,
        "main_score": 0.44636,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.921224,
        "recall": 0.946289,
        "f1": 0.929362,
        "accuracy": 0.946289,
        "main_score": 0.929362,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.993164,
        "f1": 0.991211,
        "accuracy": 0.993164,
        "main_score": 0.991211,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001203,
        "recall": 0.006836,
        "f1": 0.001408,
        "accuracy": 0.006836,
        "main_score": 0.001408,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.979818,
        "recall": 0.986328,
        "f1": 0.981934,
        "accuracy": 0.986328,
        "main_score": 0.981934,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.942871,
        "recall": 0.960938,
        "f1": 0.94873,
        "accuracy": 0.960938,
        "main_score": 0.94873,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.912842,
        "recall": 0.939453,
        "f1": 0.921452,
        "accuracy": 0.939453,
        "main_score": 0.921452,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000596,
        "recall": 0.009766,
        "f1": 0.001069,
        "accuracy": 0.009766,
        "main_score": 0.001069,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.643799,
        "recall": 0.723633,
        "f1": 0.666835,
        "accuracy": 0.723633,
        "main_score": 0.666835,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.993164,
        "f1": 0.991211,
        "accuracy": 0.993164,
        "main_score": 0.991211,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.98584,
        "recall": 0.990234,
        "f1": 0.987305,
        "accuracy": 0.990234,
        "main_score": 0.987305,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.684637,
        "recall": 0.756836,
        "f1": 0.705349,
        "accuracy": 0.756836,
        "main_score": 0.705349,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.693752,
        "recall": 0.761719,
        "f1": 0.713115,
        "accuracy": 0.761719,
        "main_score": 0.713115,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.278217,
        "recall": 0.354492,
        "f1": 0.295703,
        "accuracy": 0.354492,
        "main_score": 0.295703,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.710042,
        "recall": 0.780273,
        "f1": 0.731297,
        "accuracy": 0.780273,
        "main_score": 0.731297,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.704162,
        "recall": 0.768555,
        "f1": 0.721946,
        "accuracy": 0.768555,
        "main_score": 0.721946,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.709138,
        "recall": 0.777344,
        "f1": 0.728943,
        "accuracy": 0.777344,
        "main_score": 0.728943,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.720906,
        "recall": 0.78418,
        "f1": 0.739439,
        "accuracy": 0.78418,
        "main_score": 0.739439,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.694458,
        "recall": 0.765625,
        "f1": 0.714893,
        "accuracy": 0.765625,
        "main_score": 0.714893,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.416846,
        "recall": 0.509766,
        "f1": 0.442256,
        "accuracy": 0.509766,
        "main_score": 0.442256,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.74123,
        "recall": 0.799805,
        "f1": 0.758402,
        "accuracy": 0.799805,
        "main_score": 0.758402,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.679965,
        "recall": 0.750977,
        "f1": 0.700109,
        "accuracy": 0.750977,
        "main_score": 0.700109,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.736726,
        "recall": 0.803711,
        "f1": 0.756417,
        "accuracy": 0.803711,
        "main_score": 0.756417,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000406,
        "recall": 0.003906,
        "f1": 0.000645,
        "accuracy": 0.003906,
        "main_score": 0.000645,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.736544,
        "recall": 0.795898,
        "f1": 0.753811,
        "accuracy": 0.795898,
        "main_score": 0.753811,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.676808,
        "recall": 0.75293,
        "f1": 0.698606,
        "accuracy": 0.75293,
        "main_score": 0.698606,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.682115,
        "recall": 0.751953,
        "f1": 0.701882,
        "accuracy": 0.751953,
        "main_score": 0.701882,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.663639,
        "recall": 0.745117,
        "f1": 0.687985,
        "accuracy": 0.745117,
        "main_score": 0.687985,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000568,
        "recall": 0.009766,
        "f1": 0.001029,
        "accuracy": 0.009766,
        "main_score": 0.001029,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.628041,
        "recall": 0.698242,
        "f1": 0.648171,
        "accuracy": 0.698242,
        "main_score": 0.648171,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.681214,
        "recall": 0.748047,
        "f1": 0.699619,
        "accuracy": 0.748047,
        "main_score": 0.699619,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.700378,
        "recall": 0.768555,
        "f1": 0.719976,
        "accuracy": 0.768555,
        "main_score": 0.719976,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.714651,
        "recall": 0.776367,
        "f1": 0.732276,
        "accuracy": 0.776367,
        "main_score": 0.732276,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.943034,
        "recall": 0.960938,
        "f1": 0.948893,
        "accuracy": 0.960938,
        "main_score": 0.948893,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.973633,
        "recall": 0.982422,
        "f1": 0.976562,
        "accuracy": 0.982422,
        "main_score": 0.976562,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.185763,
        "recall": 0.272461,
        "f1": 0.20535,
        "accuracy": 0.272461,
        "main_score": 0.20535,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.793701,
        "recall": 0.852539,
        "f1": 0.812077,
        "accuracy": 0.852539,
        "main_score": 0.812077,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.984212,
        "recall": 0.989258,
        "f1": 0.98584,
        "accuracy": 0.989258,
        "main_score": 0.98584,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.749065,
        "recall": 0.81543,
        "f1": 0.769222,
        "accuracy": 0.81543,
        "main_score": 0.769222,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.971029,
        "recall": 0.980469,
        "f1": 0.974121,
        "accuracy": 0.980469,
        "main_score": 0.974121,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.976562,
        "recall": 0.984375,
        "f1": 0.979167,
        "accuracy": 0.984375,
        "main_score": 0.979167,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.413349,
        "recall": 0.518555,
        "f1": 0.440357,
        "accuracy": 0.518555,
        "main_score": 0.440357,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.914551,
        "recall": 0.939453,
        "f1": 0.922493,
        "accuracy": 0.939453,
        "main_score": 0.922493,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.977051,
        "recall": 0.984375,
        "f1": 0.979492,
        "accuracy": 0.984375,
        "main_score": 0.979492,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.975423,
        "recall": 0.983398,
        "f1": 0.978027,
        "accuracy": 0.983398,
        "main_score": 0.978027,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00043,
        "recall": 0.005859,
        "f1": 0.000744,
        "accuracy": 0.005859,
        "main_score": 0.000744,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.976562,
        "recall": 0.983398,
        "f1": 0.978841,
        "accuracy": 0.983398,
        "main_score": 0.978841,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.9375,
        "recall": 0.957031,
        "f1": 0.943848,
        "accuracy": 0.957031,
        "main_score": 0.943848,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.908447,
        "recall": 0.935547,
        "f1": 0.917057,
        "accuracy": 0.935547,
        "main_score": 0.917057,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000842,
        "recall": 0.010742,
        "f1": 0.001326,
        "accuracy": 0.010742,
        "main_score": 0.001326,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.639724,
        "recall": 0.71875,
        "f1": 0.662537,
        "accuracy": 0.71875,
        "main_score": 0.662537,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.965332,
        "recall": 0.976562,
        "f1": 0.969076,
        "accuracy": 0.976562,
        "main_score": 0.969076,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.980143,
        "recall": 0.986328,
        "f1": 0.982096,
        "accuracy": 0.986328,
        "main_score": 0.982096,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.971029,
        "recall": 0.980469,
        "f1": 0.974121,
        "accuracy": 0.980469,
        "main_score": 0.974121,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.941813,
        "recall": 0.959961,
        "f1": 0.947656,
        "accuracy": 0.959961,
        "main_score": 0.947656,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.980957,
        "recall": 0.987305,
        "f1": 0.983073,
        "accuracy": 0.987305,
        "main_score": 0.983073,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.2141,
        "recall": 0.305664,
        "f1": 0.234019,
        "accuracy": 0.305664,
        "main_score": 0.234019,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.832275,
        "recall": 0.882812,
        "f1": 0.848177,
        "accuracy": 0.882812,
        "main_score": 0.848177,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.766146,
        "recall": 0.828125,
        "f1": 0.784998,
        "accuracy": 0.828125,
        "main_score": 0.784998,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.971354,
        "recall": 0.980469,
        "f1": 0.974284,
        "accuracy": 0.980469,
        "main_score": 0.974284,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.41311,
        "recall": 0.523438,
        "f1": 0.442483,
        "accuracy": 0.523438,
        "main_score": 0.442483,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.930013,
        "recall": 0.952148,
        "f1": 0.937337,
        "accuracy": 0.952148,
        "main_score": 0.937337,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.98291,
        "recall": 0.988281,
        "f1": 0.984701,
        "accuracy": 0.988281,
        "main_score": 0.984701,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000253,
        "recall": 0.005859,
        "f1": 0.00048,
        "accuracy": 0.005859,
        "main_score": 0.00048,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.977539,
        "recall": 0.984375,
        "f1": 0.979818,
        "accuracy": 0.984375,
        "main_score": 0.979818,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.942708,
        "recall": 0.960938,
        "f1": 0.94873,
        "accuracy": 0.960938,
        "main_score": 0.94873,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.920199,
        "recall": 0.943359,
        "f1": 0.927474,
        "accuracy": 0.943359,
        "main_score": 0.927474,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000686,
        "recall": 0.008789,
        "f1": 0.001149,
        "accuracy": 0.008789,
        "main_score": 0.001149,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.683622,
        "recall": 0.754883,
        "f1": 0.703898,
        "accuracy": 0.754883,
        "main_score": 0.703898,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.984375,
        "recall": 0.989258,
        "f1": 0.986003,
        "accuracy": 0.989258,
        "main_score": 0.986003,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.975423,
        "recall": 0.983398,
        "f1": 0.978027,
        "accuracy": 0.983398,
        "main_score": 0.978027,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.981283,
        "recall": 0.987305,
        "f1": 0.983236,
        "accuracy": 0.987305,
        "main_score": 0.983236,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.95166,
        "recall": 0.966797,
        "f1": 0.956543,
        "accuracy": 0.966797,
        "main_score": 0.956543,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.972168,
        "recall": 0.981445,
        "f1": 0.97526,
        "accuracy": 0.981445,
        "main_score": 0.97526,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.155573,
        "recall": 0.235352,
        "f1": 0.172309,
        "accuracy": 0.235352,
        "main_score": 0.172309,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.787174,
        "recall": 0.847656,
        "f1": 0.805794,
        "accuracy": 0.847656,
        "main_score": 0.805794,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.744792,
        "recall": 0.8125,
        "f1": 0.765499,
        "accuracy": 0.8125,
        "main_score": 0.765499,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.982747,
        "recall": 0.988281,
        "f1": 0.984538,
        "accuracy": 0.988281,
        "main_score": 0.984538,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.362423,
        "recall": 0.472656,
        "f1": 0.390599,
        "accuracy": 0.472656,
        "main_score": 0.390599,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.90446,
        "recall": 0.93457,
        "f1": 0.914225,
        "accuracy": 0.93457,
        "main_score": 0.914225,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.974609,
        "recall": 0.982422,
        "f1": 0.977214,
        "accuracy": 0.982422,
        "main_score": 0.977214,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.976888,
        "recall": 0.984375,
        "f1": 0.979329,
        "accuracy": 0.984375,
        "main_score": 0.979329,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000513,
        "recall": 0.005859,
        "f1": 0.000844,
        "accuracy": 0.005859,
        "main_score": 0.000844,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.978027,
        "recall": 0.985352,
        "f1": 0.980469,
        "accuracy": 0.985352,
        "main_score": 0.980469,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.96224,
        "recall": 0.974609,
        "f1": 0.966309,
        "accuracy": 0.974609,
        "main_score": 0.966309,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.931803,
        "recall": 0.952148,
        "f1": 0.938477,
        "accuracy": 0.952148,
        "main_score": 0.938477,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.925651,
        "recall": 0.946289,
        "f1": 0.932292,
        "accuracy": 0.946289,
        "main_score": 0.932292,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000514,
        "recall": 0.008789,
        "f1": 0.000929,
        "accuracy": 0.008789,
        "main_score": 0.000929,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.610348,
        "recall": 0.69043,
        "f1": 0.633085,
        "accuracy": 0.69043,
        "main_score": 0.633085,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.97168,
        "recall": 0.980469,
        "f1": 0.974609,
        "accuracy": 0.980469,
        "main_score": 0.974609,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.980957,
        "recall": 0.987305,
        "f1": 0.983073,
        "accuracy": 0.987305,
        "main_score": 0.983073,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.973958,
        "recall": 0.982422,
        "f1": 0.976725,
        "accuracy": 0.982422,
        "main_score": 0.976725,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.341376,
        "recall": 0.408203,
        "f1": 0.357027,
        "accuracy": 0.408203,
        "main_score": 0.357027,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.336338,
        "recall": 0.399414,
        "f1": 0.350625,
        "accuracy": 0.399414,
        "main_score": 0.350625,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.233305,
        "recall": 0.289062,
        "f1": 0.245789,
        "accuracy": 0.289062,
        "main_score": 0.245789,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.414407,
        "recall": 0.476562,
        "f1": 0.428488,
        "accuracy": 0.476562,
        "main_score": 0.428488,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.345287,
        "recall": 0.397461,
        "f1": 0.356621,
        "accuracy": 0.397461,
        "main_score": 0.356621,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.374852,
        "recall": 0.4375,
        "f1": 0.38986,
        "accuracy": 0.4375,
        "main_score": 0.38986,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.335364,
        "recall": 0.392578,
        "f1": 0.348404,
        "accuracy": 0.392578,
        "main_score": 0.348404,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.334811,
        "recall": 0.387695,
        "f1": 0.347751,
        "accuracy": 0.387695,
        "main_score": 0.347751,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.313593,
        "recall": 0.373047,
        "f1": 0.327391,
        "accuracy": 0.373047,
        "main_score": 0.327391,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.387809,
        "recall": 0.448242,
        "f1": 0.402449,
        "accuracy": 0.448242,
        "main_score": 0.402449,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.348381,
        "recall": 0.410156,
        "f1": 0.362227,
        "accuracy": 0.410156,
        "main_score": 0.362227,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.331735,
        "recall": 0.381836,
        "f1": 0.343466,
        "accuracy": 0.381836,
        "main_score": 0.343466,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001804,
        "recall": 0.007812,
        "f1": 0.002325,
        "accuracy": 0.007812,
        "main_score": 0.002325,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.344509,
        "recall": 0.390625,
        "f1": 0.355244,
        "accuracy": 0.390625,
        "main_score": 0.355244,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.305144,
        "recall": 0.368164,
        "f1": 0.320025,
        "accuracy": 0.368164,
        "main_score": 0.320025,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.356016,
        "recall": 0.413086,
        "f1": 0.369035,
        "accuracy": 0.413086,
        "main_score": 0.369035,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.311005,
        "recall": 0.373047,
        "f1": 0.325664,
        "accuracy": 0.373047,
        "main_score": 0.325664,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00237,
        "recall": 0.008789,
        "f1": 0.002703,
        "accuracy": 0.008789,
        "main_score": 0.002703,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.370989,
        "recall": 0.433594,
        "f1": 0.386387,
        "accuracy": 0.433594,
        "main_score": 0.386387,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.331034,
        "recall": 0.393555,
        "f1": 0.346207,
        "accuracy": 0.393555,
        "main_score": 0.346207,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.345437,
        "recall": 0.399414,
        "f1": 0.357383,
        "accuracy": 0.399414,
        "main_score": 0.357383,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.400386,
        "recall": 0.456055,
        "f1": 0.413274,
        "accuracy": 0.456055,
        "main_score": 0.413274,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.861572,
        "recall": 0.900391,
        "f1": 0.873763,
        "accuracy": 0.900391,
        "main_score": 0.873763,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.898682,
        "recall": 0.929688,
        "f1": 0.908594,
        "accuracy": 0.929688,
        "main_score": 0.908594,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.216461,
        "recall": 0.296875,
        "f1": 0.234357,
        "accuracy": 0.296875,
        "main_score": 0.234357,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.840983,
        "recall": 0.889648,
        "f1": 0.856576,
        "accuracy": 0.889648,
        "main_score": 0.856576,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.904215,
        "recall": 0.933594,
        "f1": 0.913639,
        "accuracy": 0.933594,
        "main_score": 0.913639,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.773063,
        "recall": 0.831055,
        "f1": 0.79069,
        "accuracy": 0.831055,
        "main_score": 0.79069,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.899251,
        "recall": 0.930664,
        "f1": 0.909505,
        "accuracy": 0.930664,
        "main_score": 0.909505,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.93278,
        "recall": 0.954102,
        "f1": 0.939779,
        "accuracy": 0.954102,
        "main_score": 0.939779,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.899577,
        "recall": 0.929688,
        "f1": 0.909342,
        "accuracy": 0.929688,
        "main_score": 0.909342,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.443792,
        "recall": 0.546875,
        "f1": 0.47195,
        "accuracy": 0.546875,
        "main_score": 0.47195,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.897054,
        "recall": 0.928711,
        "f1": 0.907292,
        "accuracy": 0.928711,
        "main_score": 0.907292,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.913249,
        "recall": 0.94043,
        "f1": 0.922038,
        "accuracy": 0.94043,
        "main_score": 0.922038,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000234,
        "recall": 0.00293,
        "f1": 0.000401,
        "accuracy": 0.00293,
        "main_score": 0.000401,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.929281,
        "recall": 0.950195,
        "f1": 0.9361,
        "accuracy": 0.950195,
        "main_score": 0.9361,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.890251,
        "recall": 0.922852,
        "f1": 0.900618,
        "accuracy": 0.922852,
        "main_score": 0.900618,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.83776,
        "recall": 0.879883,
        "f1": 0.851042,
        "accuracy": 0.879883,
        "main_score": 0.851042,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.84139,
        "recall": 0.886719,
        "f1": 0.855859,
        "accuracy": 0.886719,
        "main_score": 0.855859,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001422,
        "recall": 0.008789,
        "f1": 0.001775,
        "accuracy": 0.008789,
        "main_score": 0.001775,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.678592,
        "recall": 0.75293,
        "f1": 0.700731,
        "accuracy": 0.75293,
        "main_score": 0.700731,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.879639,
        "recall": 0.914062,
        "f1": 0.890137,
        "accuracy": 0.914062,
        "main_score": 0.890137,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.911865,
        "recall": 0.938477,
        "f1": 0.920475,
        "accuracy": 0.938477,
        "main_score": 0.920475,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.90096,
        "recall": 0.932617,
        "f1": 0.911361,
        "accuracy": 0.932617,
        "main_score": 0.911361,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.941081,
        "recall": 0.959961,
        "f1": 0.947266,
        "accuracy": 0.959961,
        "main_score": 0.947266,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.978516,
        "recall": 0.985352,
        "f1": 0.980794,
        "accuracy": 0.985352,
        "main_score": 0.980794,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.211141,
        "recall": 0.297852,
        "f1": 0.230777,
        "accuracy": 0.297852,
        "main_score": 0.230777,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.78611,
        "recall": 0.84668,
        "f1": 0.805029,
        "accuracy": 0.84668,
        "main_score": 0.805029,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.739355,
        "recall": 0.807617,
        "f1": 0.759993,
        "accuracy": 0.807617,
        "main_score": 0.759993,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.975098,
        "recall": 0.983398,
        "f1": 0.977865,
        "accuracy": 0.983398,
        "main_score": 0.977865,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.406903,
        "recall": 0.521484,
        "f1": 0.436675,
        "accuracy": 0.521484,
        "main_score": 0.436675,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.911784,
        "recall": 0.938477,
        "f1": 0.920378,
        "accuracy": 0.938477,
        "main_score": 0.920378,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.976888,
        "recall": 0.984375,
        "f1": 0.979329,
        "accuracy": 0.984375,
        "main_score": 0.979329,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000102,
        "recall": 0.003906,
        "f1": 0.000196,
        "accuracy": 0.003906,
        "main_score": 0.000196,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.977214,
        "recall": 0.984375,
        "f1": 0.979492,
        "accuracy": 0.984375,
        "main_score": 0.979492,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.962728,
        "recall": 0.974609,
        "f1": 0.966634,
        "accuracy": 0.974609,
        "main_score": 0.966634,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.933268,
        "recall": 0.955078,
        "f1": 0.94043,
        "accuracy": 0.955078,
        "main_score": 0.94043,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.916423,
        "recall": 0.941406,
        "f1": 0.924498,
        "accuracy": 0.941406,
        "main_score": 0.924498,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000789,
        "recall": 0.010742,
        "f1": 0.001356,
        "accuracy": 0.010742,
        "main_score": 0.001356,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.632613,
        "recall": 0.712891,
        "f1": 0.655496,
        "accuracy": 0.712891,
        "main_score": 0.655496,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.972982,
        "recall": 0.981445,
        "f1": 0.975749,
        "accuracy": 0.981445,
        "main_score": 0.975749,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.976562,
        "recall": 0.984375,
        "f1": 0.979167,
        "accuracy": 0.984375,
        "main_score": 0.979167,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.947428,
        "recall": 0.963867,
        "f1": 0.952799,
        "accuracy": 0.963867,
        "main_score": 0.952799,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.987142,
        "recall": 0.991211,
        "f1": 0.988444,
        "accuracy": 0.991211,
        "main_score": 0.988444,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.189777,
        "recall": 0.274414,
        "f1": 0.208622,
        "accuracy": 0.274414,
        "main_score": 0.208622,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.819824,
        "recall": 0.869141,
        "f1": 0.835221,
        "accuracy": 0.869141,
        "main_score": 0.835221,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.991536,
        "recall": 0.994141,
        "f1": 0.99235,
        "accuracy": 0.994141,
        "main_score": 0.99235,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.797396,
        "recall": 0.852539,
        "f1": 0.813983,
        "accuracy": 0.852539,
        "main_score": 0.813983,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.395831,
        "recall": 0.509766,
        "f1": 0.425691,
        "accuracy": 0.509766,
        "main_score": 0.425691,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.927572,
        "recall": 0.950195,
        "f1": 0.934896,
        "accuracy": 0.950195,
        "main_score": 0.934896,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.972982,
        "recall": 0.981445,
        "f1": 0.975749,
        "accuracy": 0.981445,
        "main_score": 0.975749,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000314,
        "recall": 0.006836,
        "f1": 0.000593,
        "accuracy": 0.006836,
        "main_score": 0.000593,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.96932,
        "recall": 0.978516,
        "f1": 0.972233,
        "accuracy": 0.978516,
        "main_score": 0.972233,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.931478,
        "recall": 0.951172,
        "f1": 0.937826,
        "accuracy": 0.951172,
        "main_score": 0.937826,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.92277,
        "recall": 0.947266,
        "f1": 0.930729,
        "accuracy": 0.947266,
        "main_score": 0.930729,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00058,
        "recall": 0.006836,
        "f1": 0.000967,
        "accuracy": 0.006836,
        "main_score": 0.000967,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.659094,
        "recall": 0.735352,
        "f1": 0.68096,
        "accuracy": 0.735352,
        "main_score": 0.68096,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.972982,
        "recall": 0.981445,
        "f1": 0.975749,
        "accuracy": 0.981445,
        "main_score": 0.975749,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.97876,
        "recall": 0.985352,
        "f1": 0.980859,
        "accuracy": 0.985352,
        "main_score": 0.980859,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000978,
        "recall": 0.001953,
        "f1": 0.000979,
        "accuracy": 0.001953,
        "main_score": 0.000979,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.001117,
        "recall": 0.00293,
        "f1": 0.001223,
        "accuracy": 0.00293,
        "main_score": 0.001223,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001088,
        "recall": 0.00293,
        "f1": 0.001177,
        "accuracy": 0.00293,
        "main_score": 0.001177,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.000118,
        "recall": 0.003906,
        "f1": 0.000214,
        "accuracy": 0.003906,
        "main_score": 0.000214,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000164,
        "recall": 0.001953,
        "f1": 0.000281,
        "accuracy": 0.001953,
        "main_score": 0.000281,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 9.9e-05,
        "recall": 0.001953,
        "f1": 0.00018,
        "accuracy": 0.001953,
        "main_score": 0.00018,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.000979,
        "recall": 0.001953,
        "f1": 0.000981,
        "accuracy": 0.001953,
        "main_score": 0.000981,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000197,
        "recall": 0.001953,
        "f1": 0.000328,
        "accuracy": 0.001953,
        "main_score": 0.000328,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001222,
        "recall": 0.00293,
        "f1": 0.001369,
        "accuracy": 0.00293,
        "main_score": 0.001369,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001075,
        "recall": 0.00293,
        "f1": 0.001156,
        "accuracy": 0.00293,
        "main_score": 0.001156,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.000587,
        "recall": 0.00293,
        "f1": 0.000831,
        "accuracy": 0.00293,
        "main_score": 0.000831,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.001469,
        "recall": 0.003906,
        "f1": 0.001635,
        "accuracy": 0.003906,
        "main_score": 0.001635,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001953,
        "f1": 9e-06,
        "accuracy": 0.001953,
        "main_score": 9e-06,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000328,
        "recall": 0.001953,
        "f1": 0.000493,
        "accuracy": 0.001953,
        "main_score": 0.000493,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.001173,
        "recall": 0.00293,
        "f1": 0.001304,
        "accuracy": 0.00293,
        "main_score": 0.001304,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.000164,
        "recall": 0.001953,
        "f1": 0.000282,
        "accuracy": 0.001953,
        "main_score": 0.000282,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000355,
        "recall": 0.00293,
        "f1": 0.00059,
        "accuracy": 0.00293,
        "main_score": 0.00059,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.047755,
        "recall": 0.083008,
        "f1": 0.056424,
        "accuracy": 0.083008,
        "main_score": 0.056424,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 9.9e-05,
        "recall": 0.001953,
        "f1": 0.00018,
        "accuracy": 0.001953,
        "main_score": 0.00018,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000977,
        "f1": 3e-06,
        "accuracy": 0.000977,
        "main_score": 3e-06,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001173,
        "recall": 0.00293,
        "f1": 0.001304,
        "accuracy": 0.00293,
        "main_score": 0.001304,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000109,
        "recall": 0.001953,
        "f1": 0.000197,
        "accuracy": 0.001953,
        "main_score": 0.000197,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.964437,
        "recall": 0.974609,
        "f1": 0.967676,
        "accuracy": 0.974609,
        "main_score": 0.967676,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.192482,
        "recall": 0.288086,
        "f1": 0.214104,
        "accuracy": 0.288086,
        "main_score": 0.214104,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.824219,
        "recall": 0.875977,
        "f1": 0.840625,
        "accuracy": 0.875977,
        "main_score": 0.840625,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.776546,
        "recall": 0.833984,
        "f1": 0.794452,
        "accuracy": 0.833984,
        "main_score": 0.794452,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.985677,
        "recall": 0.990234,
        "f1": 0.987142,
        "accuracy": 0.990234,
        "main_score": 0.987142,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.985677,
        "recall": 0.990234,
        "f1": 0.987142,
        "accuracy": 0.990234,
        "main_score": 0.987142,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.398722,
        "recall": 0.512695,
        "f1": 0.429047,
        "accuracy": 0.512695,
        "main_score": 0.429047,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.934082,
        "recall": 0.954102,
        "f1": 0.940592,
        "accuracy": 0.954102,
        "main_score": 0.940592,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.976074,
        "recall": 0.983398,
        "f1": 0.978516,
        "accuracy": 0.983398,
        "main_score": 0.978516,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000194,
        "recall": 0.004883,
        "f1": 0.000367,
        "accuracy": 0.004883,
        "main_score": 0.000367,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.937012,
        "recall": 0.956055,
        "f1": 0.943197,
        "accuracy": 0.956055,
        "main_score": 0.943197,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.940918,
        "recall": 0.958984,
        "f1": 0.946777,
        "accuracy": 0.958984,
        "main_score": 0.946777,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000828,
        "recall": 0.010742,
        "f1": 0.001301,
        "accuracy": 0.010742,
        "main_score": 0.001301,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.665845,
        "recall": 0.740234,
        "f1": 0.68748,
        "accuracy": 0.740234,
        "main_score": 0.68748,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.973307,
        "recall": 0.981445,
        "f1": 0.975911,
        "accuracy": 0.981445,
        "main_score": 0.975911,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.9611,
        "recall": 0.973633,
        "f1": 0.965169,
        "accuracy": 0.973633,
        "main_score": 0.965169,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.158759,
        "recall": 0.239258,
        "f1": 0.175778,
        "accuracy": 0.239258,
        "main_score": 0.175778,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.786084,
        "recall": 0.845703,
        "f1": 0.804297,
        "accuracy": 0.845703,
        "main_score": 0.804297,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.733919,
        "recall": 0.798828,
        "f1": 0.753144,
        "accuracy": 0.798828,
        "main_score": 0.753144,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.974121,
        "recall": 0.981445,
        "f1": 0.976562,
        "accuracy": 0.981445,
        "main_score": 0.976562,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.975098,
        "recall": 0.983398,
        "f1": 0.977865,
        "accuracy": 0.983398,
        "main_score": 0.977865,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.972656,
        "recall": 0.981445,
        "f1": 0.975586,
        "accuracy": 0.981445,
        "main_score": 0.975586,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.371739,
        "recall": 0.485352,
        "f1": 0.401428,
        "accuracy": 0.485352,
        "main_score": 0.401428,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.899658,
        "recall": 0.929688,
        "f1": 0.909245,
        "accuracy": 0.929688,
        "main_score": 0.909245,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.964193,
        "recall": 0.975586,
        "f1": 0.967936,
        "accuracy": 0.975586,
        "main_score": 0.967936,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.978353,
        "recall": 0.985352,
        "f1": 0.980632,
        "accuracy": 0.985352,
        "main_score": 0.980632,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.0002,
        "recall": 0.004883,
        "f1": 0.000377,
        "accuracy": 0.004883,
        "main_score": 0.000377,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.976888,
        "recall": 0.984375,
        "f1": 0.979329,
        "accuracy": 0.984375,
        "main_score": 0.979329,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.937256,
        "recall": 0.957031,
        "f1": 0.94375,
        "accuracy": 0.957031,
        "main_score": 0.94375,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.912272,
        "recall": 0.938477,
        "f1": 0.92054,
        "accuracy": 0.938477,
        "main_score": 0.92054,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000786,
        "recall": 0.011719,
        "f1": 0.001356,
        "accuracy": 0.011719,
        "main_score": 0.001356,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.581679,
        "recall": 0.668945,
        "f1": 0.606216,
        "accuracy": 0.668945,
        "main_score": 0.606216,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.955892,
        "recall": 0.969727,
        "f1": 0.960449,
        "accuracy": 0.969727,
        "main_score": 0.960449,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.974121,
        "recall": 0.982422,
        "f1": 0.976888,
        "accuracy": 0.982422,
        "main_score": 0.976888,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.971029,
        "recall": 0.980469,
        "f1": 0.974121,
        "accuracy": 0.980469,
        "main_score": 0.974121,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.890137,
        "recall": 0.924805,
        "f1": 0.90153,
        "accuracy": 0.924805,
        "main_score": 0.90153,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.951335,
        "recall": 0.966797,
        "f1": 0.95638,
        "accuracy": 0.966797,
        "main_score": 0.95638,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.211804,
        "recall": 0.298828,
        "f1": 0.231492,
        "accuracy": 0.298828,
        "main_score": 0.231492,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.775228,
        "recall": 0.836914,
        "f1": 0.794531,
        "accuracy": 0.836914,
        "main_score": 0.794531,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.935905,
        "recall": 0.956055,
        "f1": 0.942383,
        "accuracy": 0.956055,
        "main_score": 0.942383,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.727979,
        "recall": 0.792969,
        "f1": 0.747447,
        "accuracy": 0.792969,
        "main_score": 0.747447,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.938314,
        "recall": 0.957031,
        "f1": 0.944336,
        "accuracy": 0.957031,
        "main_score": 0.944336,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.945068,
        "recall": 0.960938,
        "f1": 0.949935,
        "accuracy": 0.960938,
        "main_score": 0.949935,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.927409,
        "recall": 0.950195,
        "f1": 0.934896,
        "accuracy": 0.950195,
        "main_score": 0.934896,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.415389,
        "recall": 0.517578,
        "f1": 0.442241,
        "accuracy": 0.517578,
        "main_score": 0.442241,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.86263,
        "recall": 0.904297,
        "f1": 0.875977,
        "accuracy": 0.904297,
        "main_score": 0.875977,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.933431,
        "recall": 0.954102,
        "f1": 0.940267,
        "accuracy": 0.954102,
        "main_score": 0.940267,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.936035,
        "recall": 0.955078,
        "f1": 0.942025,
        "accuracy": 0.955078,
        "main_score": 0.942025,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000365,
        "recall": 0.006836,
        "f1": 0.000682,
        "accuracy": 0.006836,
        "main_score": 0.000682,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.94222,
        "recall": 0.959961,
        "f1": 0.948079,
        "accuracy": 0.959961,
        "main_score": 0.948079,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.931641,
        "recall": 0.953125,
        "f1": 0.938639,
        "accuracy": 0.953125,
        "main_score": 0.938639,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.879476,
        "recall": 0.913086,
        "f1": 0.890365,
        "accuracy": 0.913086,
        "main_score": 0.890365,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000221,
        "recall": 0.006836,
        "f1": 0.000423,
        "accuracy": 0.006836,
        "main_score": 0.000423,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.630583,
        "recall": 0.707031,
        "f1": 0.652519,
        "accuracy": 0.707031,
        "main_score": 0.652519,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.933268,
        "recall": 0.954102,
        "f1": 0.940104,
        "accuracy": 0.954102,
        "main_score": 0.940104,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.941406,
        "recall": 0.958984,
        "f1": 0.947103,
        "accuracy": 0.958984,
        "main_score": 0.947103,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.950684,
        "recall": 0.96582,
        "f1": 0.955566,
        "accuracy": 0.96582,
        "main_score": 0.955566,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.880078,
        "recall": 0.915039,
        "f1": 0.891081,
        "accuracy": 0.915039,
        "main_score": 0.891081,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.885579,
        "recall": 0.919922,
        "f1": 0.896452,
        "accuracy": 0.919922,
        "main_score": 0.896452,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.195547,
        "recall": 0.282227,
        "f1": 0.215179,
        "accuracy": 0.282227,
        "main_score": 0.215179,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.760352,
        "recall": 0.822266,
        "f1": 0.779232,
        "accuracy": 0.822266,
        "main_score": 0.779232,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.880192,
        "recall": 0.915039,
        "f1": 0.890853,
        "accuracy": 0.915039,
        "main_score": 0.890853,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.708545,
        "recall": 0.77832,
        "f1": 0.729297,
        "accuracy": 0.77832,
        "main_score": 0.729297,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.882438,
        "recall": 0.916992,
        "f1": 0.893294,
        "accuracy": 0.916992,
        "main_score": 0.893294,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.894971,
        "recall": 0.925781,
        "f1": 0.904688,
        "accuracy": 0.925781,
        "main_score": 0.904688,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.892415,
        "recall": 0.923828,
        "f1": 0.902311,
        "accuracy": 0.923828,
        "main_score": 0.902311,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.362854,
        "recall": 0.46875,
        "f1": 0.390336,
        "accuracy": 0.46875,
        "main_score": 0.390336,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.832496,
        "recall": 0.880859,
        "f1": 0.847542,
        "accuracy": 0.880859,
        "main_score": 0.847542,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.876383,
        "recall": 0.912109,
        "f1": 0.887402,
        "accuracy": 0.912109,
        "main_score": 0.887402,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.907389,
        "recall": 0.932617,
        "f1": 0.915318,
        "accuracy": 0.932617,
        "main_score": 0.915318,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000401,
        "recall": 0.005859,
        "f1": 0.000729,
        "accuracy": 0.005859,
        "main_score": 0.000729,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.92277,
        "recall": 0.946289,
        "f1": 0.930404,
        "accuracy": 0.946289,
        "main_score": 0.930404,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.884766,
        "recall": 0.917969,
        "f1": 0.89515,
        "accuracy": 0.917969,
        "main_score": 0.89515,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.857503,
        "recall": 0.897461,
        "f1": 0.870182,
        "accuracy": 0.897461,
        "main_score": 0.870182,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.000783,
        "recall": 0.008789,
        "f1": 0.001214,
        "accuracy": 0.008789,
        "main_score": 0.001214,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.58232,
        "recall": 0.666992,
        "f1": 0.606345,
        "accuracy": 0.666992,
        "main_score": 0.606345,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.876686,
        "recall": 0.911133,
        "f1": 0.887516,
        "accuracy": 0.911133,
        "main_score": 0.887516,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.898275,
        "recall": 0.927734,
        "f1": 0.907389,
        "accuracy": 0.927734,
        "main_score": 0.907389,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.877881,
        "recall": 0.912109,
        "f1": 0.888379,
        "accuracy": 0.912109,
        "main_score": 0.888379,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001954,
        "recall": 0.00293,
        "f1": 0.001955,
        "accuracy": 0.00293,
        "main_score": 0.001955,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.002117,
        "recall": 0.003906,
        "f1": 0.002234,
        "accuracy": 0.003906,
        "main_score": 0.002234,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001139,
        "recall": 0.001953,
        "f1": 0.001256,
        "accuracy": 0.001953,
        "main_score": 0.001256,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.001116,
        "recall": 0.001953,
        "f1": 0.001221,
        "accuracy": 0.001953,
        "main_score": 0.001221,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001466,
        "recall": 0.00293,
        "f1": 0.00163,
        "accuracy": 0.00293,
        "main_score": 0.00163,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002094,
        "recall": 0.003906,
        "f1": 0.0022,
        "accuracy": 0.003906,
        "main_score": 0.0022,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.001953,
        "recall": 0.001953,
        "f1": 0.001953,
        "accuracy": 0.001953,
        "main_score": 0.001953,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.001954,
        "recall": 0.00293,
        "f1": 0.001955,
        "accuracy": 0.00293,
        "main_score": 0.001955,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.002931,
        "recall": 0.003906,
        "f1": 0.002932,
        "accuracy": 0.003906,
        "main_score": 0.002932,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001117,
        "recall": 0.00293,
        "f1": 0.001223,
        "accuracy": 0.00293,
        "main_score": 0.001223,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.001119,
        "recall": 0.00293,
        "f1": 0.001227,
        "accuracy": 0.00293,
        "main_score": 0.001227,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.001958,
        "recall": 0.003906,
        "f1": 0.001962,
        "accuracy": 0.003906,
        "main_score": 0.001962,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000982,
        "recall": 0.00293,
        "f1": 0.000988,
        "accuracy": 0.00293,
        "main_score": 0.000988,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.051387,
        "recall": 0.080078,
        "f1": 0.057783,
        "accuracy": 0.080078,
        "main_score": 0.057783,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.001959,
        "recall": 0.00293,
        "f1": 0.001965,
        "accuracy": 0.00293,
        "main_score": 0.001965,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.002198,
        "recall": 0.003906,
        "f1": 0.002346,
        "accuracy": 0.003906,
        "main_score": 0.002346,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.001466,
        "recall": 0.00293,
        "f1": 0.00163,
        "accuracy": 0.00293,
        "main_score": 0.00163,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001133,
        "recall": 0.003906,
        "f1": 0.001255,
        "accuracy": 0.003906,
        "main_score": 0.001255,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002117,
        "recall": 0.003906,
        "f1": 0.002234,
        "accuracy": 0.003906,
        "main_score": 0.002234,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.000982,
        "recall": 0.00293,
        "f1": 0.000988,
        "accuracy": 0.00293,
        "main_score": 0.000988,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.002931,
        "recall": 0.003906,
        "f1": 0.002932,
        "accuracy": 0.003906,
        "main_score": 0.002932,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.00114,
        "recall": 0.00293,
        "f1": 0.001258,
        "accuracy": 0.00293,
        "main_score": 0.001258,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.553225,
        "recall": 0.630859,
        "f1": 0.572943,
        "accuracy": 0.630859,
        "main_score": 0.572943,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.553568,
        "recall": 0.632812,
        "f1": 0.574267,
        "accuracy": 0.632812,
        "main_score": 0.574267,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.307099,
        "recall": 0.37793,
        "f1": 0.32413,
        "accuracy": 0.37793,
        "main_score": 0.32413,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.656801,
        "recall": 0.722656,
        "f1": 0.674876,
        "accuracy": 0.722656,
        "main_score": 0.674876,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.565757,
        "recall": 0.640625,
        "f1": 0.585408,
        "accuracy": 0.640625,
        "main_score": 0.585408,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.602315,
        "recall": 0.666992,
        "f1": 0.62076,
        "accuracy": 0.666992,
        "main_score": 0.62076,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.574478,
        "recall": 0.646484,
        "f1": 0.593645,
        "accuracy": 0.646484,
        "main_score": 0.593645,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.605569,
        "recall": 0.673828,
        "f1": 0.624347,
        "accuracy": 0.673828,
        "main_score": 0.624347,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.553601,
        "recall": 0.628906,
        "f1": 0.573487,
        "accuracy": 0.628906,
        "main_score": 0.573487,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.420603,
        "recall": 0.506836,
        "f1": 0.44343,
        "accuracy": 0.506836,
        "main_score": 0.44343,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.642663,
        "recall": 0.712891,
        "f1": 0.66223,
        "accuracy": 0.712891,
        "main_score": 0.66223,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.561294,
        "recall": 0.635742,
        "f1": 0.580115,
        "accuracy": 0.635742,
        "main_score": 0.580115,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.564164,
        "recall": 0.636719,
        "f1": 0.583475,
        "accuracy": 0.636719,
        "main_score": 0.583475,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000903,
        "recall": 0.005859,
        "f1": 0.001363,
        "accuracy": 0.005859,
        "main_score": 0.001363,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.60127,
        "recall": 0.669922,
        "f1": 0.619764,
        "accuracy": 0.669922,
        "main_score": 0.619764,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.540094,
        "recall": 0.625977,
        "f1": 0.562728,
        "accuracy": 0.625977,
        "main_score": 0.562728,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.559627,
        "recall": 0.631836,
        "f1": 0.578949,
        "accuracy": 0.631836,
        "main_score": 0.578949,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.551912,
        "recall": 0.630859,
        "f1": 0.572893,
        "accuracy": 0.630859,
        "main_score": 0.572893,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000923,
        "recall": 0.007812,
        "f1": 0.001448,
        "accuracy": 0.007812,
        "main_score": 0.001448,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.543735,
        "recall": 0.620117,
        "f1": 0.563911,
        "accuracy": 0.620117,
        "main_score": 0.563911,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.573585,
        "recall": 0.645508,
        "f1": 0.592637,
        "accuracy": 0.645508,
        "main_score": 0.592637,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.579423,
        "recall": 0.649414,
        "f1": 0.597722,
        "accuracy": 0.649414,
        "main_score": 0.597722,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.933105,
        "recall": 0.954102,
        "f1": 0.939941,
        "accuracy": 0.954102,
        "main_score": 0.939941,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.968913,
        "recall": 0.978516,
        "f1": 0.972005,
        "accuracy": 0.978516,
        "main_score": 0.972005,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.199949,
        "recall": 0.287109,
        "f1": 0.219699,
        "accuracy": 0.287109,
        "main_score": 0.219699,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.79248,
        "recall": 0.849609,
        "f1": 0.809928,
        "accuracy": 0.849609,
        "main_score": 0.809928,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.731803,
        "recall": 0.799805,
        "f1": 0.752772,
        "accuracy": 0.799805,
        "main_score": 0.752772,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.965332,
        "recall": 0.976562,
        "f1": 0.969076,
        "accuracy": 0.976562,
        "main_score": 0.969076,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.978841,
        "recall": 0.985352,
        "f1": 0.980957,
        "accuracy": 0.985352,
        "main_score": 0.980957,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.402077,
        "recall": 0.512695,
        "f1": 0.431688,
        "accuracy": 0.512695,
        "main_score": 0.431688,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.886719,
        "recall": 0.919922,
        "f1": 0.897233,
        "accuracy": 0.919922,
        "main_score": 0.897233,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.97998,
        "recall": 0.986328,
        "f1": 0.982096,
        "accuracy": 0.986328,
        "main_score": 0.982096,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.974284,
        "recall": 0.982422,
        "f1": 0.976888,
        "accuracy": 0.982422,
        "main_score": 0.976888,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000213,
        "recall": 0.005859,
        "f1": 0.000406,
        "accuracy": 0.005859,
        "main_score": 0.000406,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.969727,
        "recall": 0.979492,
        "f1": 0.972982,
        "accuracy": 0.979492,
        "main_score": 0.972982,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.958659,
        "recall": 0.97168,
        "f1": 0.962891,
        "accuracy": 0.97168,
        "main_score": 0.962891,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.937663,
        "recall": 0.957031,
        "f1": 0.94401,
        "accuracy": 0.957031,
        "main_score": 0.94401,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.896973,
        "recall": 0.926758,
        "f1": 0.90638,
        "accuracy": 0.926758,
        "main_score": 0.90638,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000346,
        "recall": 0.007812,
        "f1": 0.000632,
        "accuracy": 0.007812,
        "main_score": 0.000632,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.619401,
        "recall": 0.703125,
        "f1": 0.643104,
        "accuracy": 0.703125,
        "main_score": 0.643104,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.975098,
        "recall": 0.983398,
        "f1": 0.977865,
        "accuracy": 0.983398,
        "main_score": 0.977865,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.973958,
        "recall": 0.982422,
        "f1": 0.976725,
        "accuracy": 0.982422,
        "main_score": 0.976725,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.941406,
        "recall": 0.959961,
        "f1": 0.947428,
        "accuracy": 0.959961,
        "main_score": 0.947428,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.975098,
        "recall": 0.983398,
        "f1": 0.977865,
        "accuracy": 0.983398,
        "main_score": 0.977865,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.216053,
        "recall": 0.304688,
        "f1": 0.235438,
        "accuracy": 0.304688,
        "main_score": 0.235438,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.80127,
        "recall": 0.856445,
        "f1": 0.818457,
        "accuracy": 0.856445,
        "main_score": 0.818457,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.729818,
        "recall": 0.802734,
        "f1": 0.751986,
        "accuracy": 0.802734,
        "main_score": 0.751986,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.972168,
        "recall": 0.981445,
        "f1": 0.97526,
        "accuracy": 0.981445,
        "main_score": 0.97526,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.976562,
        "recall": 0.984375,
        "f1": 0.979167,
        "accuracy": 0.984375,
        "main_score": 0.979167,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.416269,
        "recall": 0.524414,
        "f1": 0.443939,
        "accuracy": 0.524414,
        "main_score": 0.443939,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.911947,
        "recall": 0.939453,
        "f1": 0.920703,
        "accuracy": 0.939453,
        "main_score": 0.920703,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.97998,
        "recall": 0.986328,
        "f1": 0.982096,
        "accuracy": 0.986328,
        "main_score": 0.982096,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.977051,
        "recall": 0.984375,
        "f1": 0.979492,
        "accuracy": 0.984375,
        "main_score": 0.979492,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001492,
        "recall": 0.006836,
        "f1": 0.001825,
        "accuracy": 0.006836,
        "main_score": 0.001825,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.980143,
        "recall": 0.986328,
        "f1": 0.982096,
        "accuracy": 0.986328,
        "main_score": 0.982096,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.966146,
        "recall": 0.976562,
        "f1": 0.969564,
        "accuracy": 0.976562,
        "main_score": 0.969564,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.934733,
        "recall": 0.955078,
        "f1": 0.941406,
        "accuracy": 0.955078,
        "main_score": 0.941406,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.918132,
        "recall": 0.942383,
        "f1": 0.925735,
        "accuracy": 0.942383,
        "main_score": 0.925735,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000591,
        "recall": 0.008789,
        "f1": 0.000996,
        "accuracy": 0.008789,
        "main_score": 0.000996,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.638821,
        "recall": 0.71875,
        "f1": 0.661489,
        "accuracy": 0.71875,
        "main_score": 0.661489,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.972656,
        "recall": 0.981445,
        "f1": 0.975586,
        "accuracy": 0.981445,
        "main_score": 0.975586,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.975098,
        "recall": 0.983398,
        "f1": 0.977865,
        "accuracy": 0.983398,
        "main_score": 0.977865,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.951986,
        "recall": 0.967773,
        "f1": 0.957194,
        "accuracy": 0.967773,
        "main_score": 0.957194,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.985677,
        "recall": 0.990234,
        "f1": 0.987142,
        "accuracy": 0.990234,
        "main_score": 0.987142,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.208737,
        "recall": 0.293945,
        "f1": 0.226965,
        "accuracy": 0.293945,
        "main_score": 0.226965,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.824951,
        "recall": 0.875,
        "f1": 0.840885,
        "accuracy": 0.875,
        "main_score": 0.840885,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.770566,
        "recall": 0.833008,
        "f1": 0.789925,
        "accuracy": 0.833008,
        "main_score": 0.789925,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.981283,
        "recall": 0.987305,
        "f1": 0.983236,
        "accuracy": 0.987305,
        "main_score": 0.983236,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.469506,
        "recall": 0.577148,
        "f1": 0.499147,
        "accuracy": 0.577148,
        "main_score": 0.499147,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.932617,
        "recall": 0.954102,
        "f1": 0.939616,
        "accuracy": 0.954102,
        "main_score": 0.939616,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.98291,
        "recall": 0.988281,
        "f1": 0.984701,
        "accuracy": 0.988281,
        "main_score": 0.984701,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001108,
        "recall": 0.004883,
        "f1": 0.001227,
        "accuracy": 0.004883,
        "main_score": 0.001227,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.973958,
        "recall": 0.982422,
        "f1": 0.976725,
        "accuracy": 0.982422,
        "main_score": 0.976725,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.948568,
        "recall": 0.964844,
        "f1": 0.953939,
        "accuracy": 0.964844,
        "main_score": 0.953939,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.915885,
        "recall": 0.941406,
        "f1": 0.924154,
        "accuracy": 0.941406,
        "main_score": 0.924154,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000792,
        "recall": 0.009766,
        "f1": 0.001232,
        "accuracy": 0.009766,
        "main_score": 0.001232,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.641783,
        "recall": 0.717773,
        "f1": 0.663008,
        "accuracy": 0.717773,
        "main_score": 0.663008,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.981934,
        "recall": 0.987305,
        "f1": 0.983724,
        "accuracy": 0.987305,
        "main_score": 0.983724,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.975911,
        "recall": 0.983398,
        "f1": 0.978353,
        "accuracy": 0.983398,
        "main_score": 0.978353,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 90.82293200492859,
  "kg_co2_emissions": 0.004563603922223039
}