{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.559326,
        "f1": 0.551287,
        "f1_weighted": 0.557138,
        "ap": 0.454094,
        "ap_weighted": 0.454094,
        "scores_per_experiment": [
          {
            "accuracy": 0.561523,
            "f1": 0.560063,
            "f1_weighted": 0.564147,
            "ap": 0.456893,
            "ap_weighted": 0.456893
          },
          {
            "accuracy": 0.543457,
            "f1": 0.543196,
            "f1_weighted": 0.541434,
            "ap": 0.453165,
            "ap_weighted": 0.453165
          },
          {
            "accuracy": 0.553711,
            "f1": 0.52494,
            "f1_weighted": 0.543778,
            "ap": 0.434256,
            "ap_weighted": 0.434256
          },
          {
            "accuracy": 0.571777,
            "f1": 0.556592,
            "f1_weighted": 0.569814,
            "ap": 0.451453,
            "ap_weighted": 0.451453
          },
          {
            "accuracy": 0.580078,
            "f1": 0.579642,
            "f1_weighted": 0.577459,
            "ap": 0.47795,
            "ap_weighted": 0.47795
          },
          {
            "accuracy": 0.55127,
            "f1": 0.527319,
            "f1_weighted": 0.544464,
            "ap": 0.434737,
            "ap_weighted": 0.434737
          },
          {
            "accuracy": 0.590332,
            "f1": 0.590261,
            "f1_weighted": 0.58939,
            "ap": 0.483313,
            "ap_weighted": 0.483313
          },
          {
            "accuracy": 0.56543,
            "f1": 0.564766,
            "f1_weighted": 0.562026,
            "ap": 0.468688,
            "ap_weighted": 0.468688
          },
          {
            "accuracy": 0.506348,
            "f1": 0.505819,
            "f1_weighted": 0.508424,
            "ap": 0.426678,
            "ap_weighted": 0.426678
          },
          {
            "accuracy": 0.569336,
            "f1": 0.560274,
            "f1_weighted": 0.570446,
            "ap": 0.453805,
            "ap_weighted": 0.453805
          }
        ],
        "main_score": 0.551287,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 8.281558752059937,
  "kg_co2_emissions": 0.0002800861422426869
}