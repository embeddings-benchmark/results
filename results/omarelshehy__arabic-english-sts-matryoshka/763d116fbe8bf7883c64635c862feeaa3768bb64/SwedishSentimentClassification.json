{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.953027,
        "f1": 0.952998,
        "f1_weighted": 0.952999,
        "ap": 0.929321,
        "ap_weighted": 0.929321,
        "scores_per_experiment": [
          {
            "accuracy": 0.958984,
            "f1": 0.958973,
            "f1_weighted": 0.958975,
            "ap": 0.934775,
            "ap_weighted": 0.934775
          },
          {
            "accuracy": 0.937988,
            "f1": 0.937937,
            "f1_weighted": 0.937932,
            "ap": 0.924187,
            "ap_weighted": 0.924187
          },
          {
            "accuracy": 0.963379,
            "f1": 0.963378,
            "f1_weighted": 0.963379,
            "ap": 0.945988,
            "ap_weighted": 0.945988
          },
          {
            "accuracy": 0.94873,
            "f1": 0.948726,
            "f1_weighted": 0.948725,
            "ap": 0.931054,
            "ap_weighted": 0.931054
          },
          {
            "accuracy": 0.960449,
            "f1": 0.960445,
            "f1_weighted": 0.960446,
            "ap": 0.939396,
            "ap_weighted": 0.939396
          },
          {
            "accuracy": 0.961914,
            "f1": 0.961913,
            "f1_weighted": 0.961913,
            "ap": 0.947496,
            "ap_weighted": 0.947496
          },
          {
            "accuracy": 0.938965,
            "f1": 0.938864,
            "f1_weighted": 0.938872,
            "ap": 0.899002,
            "ap_weighted": 0.899002
          },
          {
            "accuracy": 0.949219,
            "f1": 0.949159,
            "f1_weighted": 0.949164,
            "ap": 0.914797,
            "ap_weighted": 0.914797
          },
          {
            "accuracy": 0.963379,
            "f1": 0.963376,
            "f1_weighted": 0.963377,
            "ap": 0.944331,
            "ap_weighted": 0.944331
          },
          {
            "accuracy": 0.947266,
            "f1": 0.947204,
            "f1_weighted": 0.947209,
            "ap": 0.912182,
            "ap_weighted": 0.912182
          }
        ],
        "main_score": 0.953027,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.951123,
        "f1": 0.951099,
        "f1_weighted": 0.951099,
        "ap": 0.929232,
        "ap_weighted": 0.929232,
        "scores_per_experiment": [
          {
            "accuracy": 0.961914,
            "f1": 0.961912,
            "f1_weighted": 0.961912,
            "ap": 0.941991,
            "ap_weighted": 0.941991
          },
          {
            "accuracy": 0.94043,
            "f1": 0.940382,
            "f1_weighted": 0.940379,
            "ap": 0.926923,
            "ap_weighted": 0.926923
          },
          {
            "accuracy": 0.958496,
            "f1": 0.958494,
            "f1_weighted": 0.958493,
            "ap": 0.943599,
            "ap_weighted": 0.943599
          },
          {
            "accuracy": 0.94873,
            "f1": 0.948715,
            "f1_weighted": 0.948714,
            "ap": 0.933892,
            "ap_weighted": 0.933892
          },
          {
            "accuracy": 0.953613,
            "f1": 0.953613,
            "f1_weighted": 0.953613,
            "ap": 0.933755,
            "ap_weighted": 0.933755
          },
          {
            "accuracy": 0.95752,
            "f1": 0.957514,
            "f1_weighted": 0.957513,
            "ap": 0.943915,
            "ap_weighted": 0.943915
          },
          {
            "accuracy": 0.932129,
            "f1": 0.932043,
            "f1_weighted": 0.932047,
            "ap": 0.89124,
            "ap_weighted": 0.89124
          },
          {
            "accuracy": 0.952637,
            "f1": 0.95262,
            "f1_weighted": 0.952621,
            "ap": 0.924596,
            "ap_weighted": 0.924596
          },
          {
            "accuracy": 0.962891,
            "f1": 0.962891,
            "f1_weighted": 0.962891,
            "ap": 0.946693,
            "ap_weighted": 0.946693
          },
          {
            "accuracy": 0.942871,
            "f1": 0.942802,
            "f1_weighted": 0.942806,
            "ap": 0.90572,
            "ap_weighted": 0.90572
          }
        ],
        "main_score": 0.951123,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 23.340869903564453,
  "kg_co2_emissions": 0.0011908374779184868
}