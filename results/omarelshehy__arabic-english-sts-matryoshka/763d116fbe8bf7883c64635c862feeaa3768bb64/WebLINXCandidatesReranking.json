{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.113841,
        "mrr": 0.096263,
        "nAUC_map_max": -0.109525,
        "nAUC_map_std": -0.017651,
        "nAUC_map_diff1": 0.292393,
        "nAUC_mrr_max": -0.112404,
        "nAUC_mrr_std": -0.023657,
        "nAUC_mrr_diff1": 0.300707,
        "main_score": 0.096263,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.104139,
        "mrr": 0.086366,
        "nAUC_map_max": -0.009497,
        "nAUC_map_std": 0.0173,
        "nAUC_map_diff1": 0.084768,
        "nAUC_mrr_max": 0.008546,
        "nAUC_mrr_std": 0.006107,
        "nAUC_mrr_diff1": 0.102954,
        "main_score": 0.086366,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.089123,
        "mrr": 0.073444,
        "nAUC_map_max": -0.189382,
        "nAUC_map_std": 0.190158,
        "nAUC_map_diff1": 0.116944,
        "nAUC_mrr_max": -0.175198,
        "nAUC_mrr_std": 0.168613,
        "nAUC_mrr_diff1": 0.112826,
        "main_score": 0.073444,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.111306,
        "mrr": 0.093716,
        "nAUC_map_max": -0.133074,
        "nAUC_map_std": 0.044514,
        "nAUC_map_diff1": 0.092955,
        "nAUC_mrr_max": -0.13328,
        "nAUC_mrr_std": 0.036372,
        "nAUC_mrr_diff1": 0.091613,
        "main_score": 0.093716,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.096052,
        "mrr": 0.078102,
        "nAUC_map_max": -0.131216,
        "nAUC_map_std": 0.107066,
        "nAUC_map_diff1": 0.073719,
        "nAUC_mrr_max": -0.123836,
        "nAUC_mrr_std": 0.086469,
        "nAUC_mrr_diff1": 0.076347,
        "main_score": 0.078102,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.07909,
        "mrr": 0.060849,
        "nAUC_map_max": -0.095121,
        "nAUC_map_std": 0.015095,
        "nAUC_map_diff1": 0.108038,
        "nAUC_mrr_max": -0.088769,
        "nAUC_mrr_std": 0.002665,
        "nAUC_mrr_diff1": 0.109768,
        "main_score": 0.060849,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 5377.005950212479,
  "kg_co2_emissions": 0.503400308958242
}