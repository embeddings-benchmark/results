{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.559008,
        "f1": 0.558023,
        "f1_weighted": 0.557211,
        "scores_per_experiment": [
          {
            "accuracy": 0.587467,
            "f1": 0.585313,
            "f1_weighted": 0.58349
          },
          {
            "accuracy": 0.587467,
            "f1": 0.585085,
            "f1_weighted": 0.586802
          },
          {
            "accuracy": 0.618799,
            "f1": 0.619061,
            "f1_weighted": 0.615745
          },
          {
            "accuracy": 0.483029,
            "f1": 0.479901,
            "f1_weighted": 0.476929
          },
          {
            "accuracy": 0.616188,
            "f1": 0.614551,
            "f1_weighted": 0.616863
          },
          {
            "accuracy": 0.527415,
            "f1": 0.527568,
            "f1_weighted": 0.526555
          },
          {
            "accuracy": 0.509138,
            "f1": 0.508585,
            "f1_weighted": 0.50927
          },
          {
            "accuracy": 0.503916,
            "f1": 0.504113,
            "f1_weighted": 0.501543
          },
          {
            "accuracy": 0.571802,
            "f1": 0.57149,
            "f1_weighted": 0.569811
          },
          {
            "accuracy": 0.584856,
            "f1": 0.584561,
            "f1_weighted": 0.585105
          }
        ],
        "main_score": 0.559008,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.53125,
        "f1": 0.534553,
        "f1_weighted": 0.52773,
        "scores_per_experiment": [
          {
            "accuracy": 0.552083,
            "f1": 0.546336,
            "f1_weighted": 0.536762
          },
          {
            "accuracy": 0.645833,
            "f1": 0.644946,
            "f1_weighted": 0.638891
          },
          {
            "accuracy": 0.541667,
            "f1": 0.55062,
            "f1_weighted": 0.534915
          },
          {
            "accuracy": 0.510417,
            "f1": 0.513931,
            "f1_weighted": 0.510369
          },
          {
            "accuracy": 0.458333,
            "f1": 0.463294,
            "f1_weighted": 0.458705
          },
          {
            "accuracy": 0.604167,
            "f1": 0.607003,
            "f1_weighted": 0.601881
          },
          {
            "accuracy": 0.416667,
            "f1": 0.416615,
            "f1_weighted": 0.422787
          },
          {
            "accuracy": 0.5,
            "f1": 0.508547,
            "f1_weighted": 0.493113
          },
          {
            "accuracy": 0.572917,
            "f1": 0.579208,
            "f1_weighted": 0.575443
          },
          {
            "accuracy": 0.510417,
            "f1": 0.515033,
            "f1_weighted": 0.504432
          }
        ],
        "main_score": 0.53125,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 13.867350339889526,
  "kg_co2_emissions": 0.00043179838506333197
}