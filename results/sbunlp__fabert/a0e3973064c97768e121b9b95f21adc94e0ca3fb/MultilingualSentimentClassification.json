{
  "dataset_revision": "2b9b4d10fc589af67794141fe8cbd3739de1eb33",
  "task_name": "MultilingualSentimentClassification",
  "mteb_version": "1.25.8",
  "scores": {
    "test": [
      {
        "accuracy": 0.586443,
        "f1": 0.559921,
        "f1_weighted": 0.559921,
        "ap": 0.556054,
        "ap_weighted": 0.556054,
        "scores_per_experiment": [
          {
            "accuracy": 0.576429,
            "f1": 0.513418,
            "f1_weighted": 0.513418,
            "ap": 0.559055,
            "ap_weighted": 0.559055
          },
          {
            "accuracy": 0.618714,
            "f1": 0.615977,
            "f1_weighted": 0.615977,
            "ap": 0.571414,
            "ap_weighted": 0.571414
          },
          {
            "accuracy": 0.485714,
            "f1": 0.450925,
            "f1_weighted": 0.450925,
            "ap": 0.492993,
            "ap_weighted": 0.492993
          },
          {
            "accuracy": 0.654429,
            "f1": 0.653476,
            "f1_weighted": 0.653476,
            "ap": 0.603856,
            "ap_weighted": 0.603856
          },
          {
            "accuracy": 0.593143,
            "f1": 0.572449,
            "f1_weighted": 0.572449,
            "ap": 0.552596,
            "ap_weighted": 0.552596
          },
          {
            "accuracy": 0.557714,
            "f1": 0.549871,
            "f1_weighted": 0.549871,
            "ap": 0.531492,
            "ap_weighted": 0.531492
          },
          {
            "accuracy": 0.571286,
            "f1": 0.529107,
            "f1_weighted": 0.529107,
            "ap": 0.548302,
            "ap_weighted": 0.548302
          },
          {
            "accuracy": 0.694714,
            "f1": 0.690561,
            "f1_weighted": 0.690561,
            "ap": 0.628138,
            "ap_weighted": 0.628138
          },
          {
            "accuracy": 0.634286,
            "f1": 0.633216,
            "f1_weighted": 0.633216,
            "ap": 0.583418,
            "ap_weighted": 0.583418
          },
          {
            "accuracy": 0.478,
            "f1": 0.390211,
            "f1_weighted": 0.390211,
            "ap": 0.489275,
            "ap_weighted": 0.489275
          }
        ],
        "main_score": 0.586443,
        "hf_subset": "fas",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 5.378393173217773,
  "kg_co2_emissions": null
}