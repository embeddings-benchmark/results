{
  "dataset_revision": "92ba517dfd22f6334111ad84154d16a2890f5b1d",
  "task_name": "PersianFoodSentimentClassification",
  "mteb_version": "1.25.8",
  "scores": {
    "validation": [
      {
        "accuracy": 0.717285,
        "f1": 0.712661,
        "f1_weighted": 0.712661,
        "ap": 0.670428,
        "ap_weighted": 0.670428,
        "scores_per_experiment": [
          {
            "accuracy": 0.679199,
            "f1": 0.666009,
            "f1_weighted": 0.666009,
            "ap": 0.642895,
            "ap_weighted": 0.642895
          },
          {
            "accuracy": 0.725586,
            "f1": 0.721299,
            "f1_weighted": 0.721299,
            "ap": 0.680469,
            "ap_weighted": 0.680469
          },
          {
            "accuracy": 0.748047,
            "f1": 0.745997,
            "f1_weighted": 0.745997,
            "ap": 0.699028,
            "ap_weighted": 0.699028
          },
          {
            "accuracy": 0.716309,
            "f1": 0.707107,
            "f1_weighted": 0.707107,
            "ap": 0.680639,
            "ap_weighted": 0.680639
          },
          {
            "accuracy": 0.740234,
            "f1": 0.735214,
            "f1_weighted": 0.735214,
            "ap": 0.699764,
            "ap_weighted": 0.699764
          },
          {
            "accuracy": 0.70752,
            "f1": 0.707453,
            "f1_weighted": 0.707453,
            "ap": 0.648169,
            "ap_weighted": 0.648169
          },
          {
            "accuracy": 0.660645,
            "f1": 0.655301,
            "f1_weighted": 0.655301,
            "ap": 0.614686,
            "ap_weighted": 0.614686
          },
          {
            "accuracy": 0.685547,
            "f1": 0.679816,
            "f1_weighted": 0.679816,
            "ap": 0.639779,
            "ap_weighted": 0.639779
          },
          {
            "accuracy": 0.755371,
            "f1": 0.755195,
            "f1_weighted": 0.755195,
            "ap": 0.696601,
            "ap_weighted": 0.696601
          },
          {
            "accuracy": 0.754395,
            "f1": 0.753225,
            "f1_weighted": 0.753225,
            "ap": 0.702248,
            "ap_weighted": 0.702248
          }
        ],
        "main_score": 0.717285,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.702979,
        "f1": 0.697539,
        "f1_weighted": 0.697539,
        "ap": 0.656203,
        "ap_weighted": 0.656203,
        "scores_per_experiment": [
          {
            "accuracy": 0.660156,
            "f1": 0.643554,
            "f1_weighted": 0.643554,
            "ap": 0.625208,
            "ap_weighted": 0.625208
          },
          {
            "accuracy": 0.710938,
            "f1": 0.706844,
            "f1_weighted": 0.706844,
            "ap": 0.663733,
            "ap_weighted": 0.663733
          },
          {
            "accuracy": 0.72998,
            "f1": 0.727248,
            "f1_weighted": 0.727248,
            "ap": 0.68112,
            "ap_weighted": 0.68112
          },
          {
            "accuracy": 0.699707,
            "f1": 0.690832,
            "f1_weighted": 0.690832,
            "ap": 0.660179,
            "ap_weighted": 0.660179
          },
          {
            "accuracy": 0.729492,
            "f1": 0.723957,
            "f1_weighted": 0.723957,
            "ap": 0.688221,
            "ap_weighted": 0.688221
          },
          {
            "accuracy": 0.705078,
            "f1": 0.705068,
            "f1_weighted": 0.705068,
            "ap": 0.645095,
            "ap_weighted": 0.645095
          },
          {
            "accuracy": 0.635254,
            "f1": 0.628457,
            "f1_weighted": 0.628457,
            "ap": 0.592704,
            "ap_weighted": 0.592704
          },
          {
            "accuracy": 0.661621,
            "f1": 0.653739,
            "f1_weighted": 0.653739,
            "ap": 0.618221,
            "ap_weighted": 0.618221
          },
          {
            "accuracy": 0.750977,
            "f1": 0.750851,
            "f1_weighted": 0.750851,
            "ap": 0.69144,
            "ap_weighted": 0.69144
          },
          {
            "accuracy": 0.746582,
            "f1": 0.744845,
            "f1_weighted": 0.744845,
            "ap": 0.696112,
            "ap_weighted": 0.696112
          }
        ],
        "main_score": 0.702979,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 22.225833892822266,
  "kg_co2_emissions": null
}