{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.876077,
        "recall": 0.900702,
        "f1": 0.882851,
        "accuracy": 0.900702,
        "main_score": 0.882851,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.918623,
        "recall": 0.942828,
        "f1": 0.926112,
        "accuracy": 0.942828,
        "main_score": 0.926112,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.364664,
        "recall": 0.407222,
        "f1": 0.373309,
        "accuracy": 0.407222,
        "main_score": 0.373309,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.545277,
        "recall": 0.613842,
        "f1": 0.563629,
        "accuracy": 0.613842,
        "main_score": 0.563629,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.949298,
        "recall": 0.962889,
        "f1": 0.953212,
        "accuracy": 0.962889,
        "main_score": 0.953212,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.968104,
        "recall": 0.977934,
        "f1": 0.971247,
        "accuracy": 0.977934,
        "main_score": 0.971247,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.546128,
        "recall": 0.585757,
        "f1": 0.55521,
        "accuracy": 0.585757,
        "main_score": 0.55521,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.697812,
        "recall": 0.760281,
        "f1": 0.714821,
        "accuracy": 0.760281,
        "main_score": 0.714821,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.234982,
        "recall": 0.264794,
        "f1": 0.240554,
        "accuracy": 0.264794,
        "main_score": 0.240554,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.444901,
        "recall": 0.528586,
        "f1": 0.466939,
        "accuracy": 0.528586,
        "main_score": 0.466939,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.71719,
        "recall": 0.755266,
        "f1": 0.726103,
        "accuracy": 0.755266,
        "main_score": 0.726103,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.774822,
        "recall": 0.832497,
        "f1": 0.792014,
        "accuracy": 0.832497,
        "main_score": 0.792014,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.406191,
        "recall": 0.449348,
        "f1": 0.415669,
        "accuracy": 0.449348,
        "main_score": 0.415669,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.607338,
        "recall": 0.68004,
        "f1": 0.626666,
        "accuracy": 0.68004,
        "main_score": 0.626666,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.377513,
        "recall": 0.412237,
        "f1": 0.385054,
        "accuracy": 0.412237,
        "main_score": 0.385054,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.564355,
        "recall": 0.64995,
        "f1": 0.587043,
        "accuracy": 0.64995,
        "main_score": 0.587043,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.864471,
        "recall": 0.888666,
        "f1": 0.870897,
        "accuracy": 0.888666,
        "main_score": 0.870897,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.900117,
        "recall": 0.930792,
        "f1": 0.909796,
        "accuracy": 0.930792,
        "main_score": 0.909796,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.485912,
        "recall": 0.529589,
        "f1": 0.495842,
        "accuracy": 0.529589,
        "main_score": 0.495842,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.665702,
        "recall": 0.734203,
        "f1": 0.684319,
        "accuracy": 0.734203,
        "main_score": 0.684319,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.806156,
        "recall": 0.835507,
        "f1": 0.813474,
        "accuracy": 0.835507,
        "main_score": 0.813474,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.844067,
        "recall": 0.879639,
        "f1": 0.854121,
        "accuracy": 0.879639,
        "main_score": 0.854121,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.85049,
        "recall": 0.878636,
        "f1": 0.857737,
        "accuracy": 0.878636,
        "main_score": 0.857737,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.882355,
        "recall": 0.913741,
        "f1": 0.891909,
        "accuracy": 0.913741,
        "main_score": 0.891909,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.137564,
        "recall": 0.157472,
        "f1": 0.140792,
        "accuracy": 0.157472,
        "main_score": 0.140792,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.28544,
        "recall": 0.372116,
        "f1": 0.30706,
        "accuracy": 0.372116,
        "main_score": 0.30706,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.183851,
        "recall": 0.202608,
        "f1": 0.187607,
        "accuracy": 0.202608,
        "main_score": 0.187607,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.428898,
        "recall": 0.520562,
        "f1": 0.452531,
        "accuracy": 0.520562,
        "main_score": 0.452531,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.403546,
        "recall": 0.44333,
        "f1": 0.412635,
        "accuracy": 0.44333,
        "main_score": 0.412635,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.520533,
        "recall": 0.609829,
        "f1": 0.545454,
        "accuracy": 0.609829,
        "main_score": 0.545454,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.719159,
        "recall": 0.75326,
        "f1": 0.727378,
        "accuracy": 0.75326,
        "main_score": 0.727378,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.827733,
        "recall": 0.872618,
        "f1": 0.840794,
        "accuracy": 0.872618,
        "main_score": 0.840794,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.908438,
        "recall": 0.925777,
        "f1": 0.912882,
        "accuracy": 0.925777,
        "main_score": 0.912882,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.920261,
        "recall": 0.942828,
        "f1": 0.927248,
        "accuracy": 0.942828,
        "main_score": 0.927248,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.82009,
        "recall": 0.84654,
        "f1": 0.826808,
        "accuracy": 0.84654,
        "main_score": 0.826808,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.876107,
        "recall": 0.910732,
        "f1": 0.887012,
        "accuracy": 0.910732,
        "main_score": 0.887012,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.056101,
        "recall": 0.071214,
        "f1": 0.058232,
        "accuracy": 0.071214,
        "main_score": 0.058232,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.140414,
        "recall": 0.208626,
        "f1": 0.154767,
        "accuracy": 0.208626,
        "main_score": 0.154767,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.177519,
        "recall": 0.202608,
        "f1": 0.182325,
        "accuracy": 0.202608,
        "main_score": 0.182325,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.294317,
        "recall": 0.365095,
        "f1": 0.313269,
        "accuracy": 0.365095,
        "main_score": 0.313269,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.813182,
        "recall": 0.839519,
        "f1": 0.819579,
        "accuracy": 0.839519,
        "main_score": 0.819579,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.876237,
        "recall": 0.909729,
        "f1": 0.886014,
        "accuracy": 0.909729,
        "main_score": 0.886014,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.501488,
        "recall": 0.537613,
        "f1": 0.509493,
        "accuracy": 0.537613,
        "main_score": 0.509493,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.620018,
        "recall": 0.696088,
        "f1": 0.639819,
        "accuracy": 0.696088,
        "main_score": 0.639819,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.821441,
        "recall": 0.847543,
        "f1": 0.828213,
        "accuracy": 0.847543,
        "main_score": 0.828213,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.873069,
        "recall": 0.90672,
        "f1": 0.882893,
        "accuracy": 0.90672,
        "main_score": 0.882893,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.805582,
        "recall": 0.834504,
        "f1": 0.812677,
        "accuracy": 0.834504,
        "main_score": 0.812677,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.855383,
        "recall": 0.895687,
        "f1": 0.867388,
        "accuracy": 0.895687,
        "main_score": 0.867388,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.824128,
        "recall": 0.849549,
        "f1": 0.830059,
        "accuracy": 0.849549,
        "main_score": 0.830059,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.880291,
        "recall": 0.912738,
        "f1": 0.890162,
        "accuracy": 0.912738,
        "main_score": 0.890162,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.251518,
        "recall": 0.277834,
        "f1": 0.25647,
        "accuracy": 0.277834,
        "main_score": 0.25647,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.417355,
        "recall": 0.498495,
        "f1": 0.438239,
        "accuracy": 0.498495,
        "main_score": 0.438239,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.849678,
        "recall": 0.874624,
        "f1": 0.855923,
        "accuracy": 0.874624,
        "main_score": 0.855923,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.870144,
        "recall": 0.907723,
        "f1": 0.881564,
        "accuracy": 0.907723,
        "main_score": 0.881564,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.86499,
        "recall": 0.887663,
        "f1": 0.870817,
        "accuracy": 0.887663,
        "main_score": 0.870817,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.901872,
        "recall": 0.930792,
        "f1": 0.910665,
        "accuracy": 0.930792,
        "main_score": 0.910665,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.00502,
        "recall": 0.007021,
        "f1": 0.005026,
        "accuracy": 0.007021,
        "main_score": 0.005026,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002275,
        "recall": 0.021063,
        "f1": 0.003814,
        "accuracy": 0.021063,
        "main_score": 0.003814,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.887395,
        "recall": 0.90415,
        "f1": 0.891775,
        "accuracy": 0.90415,
        "main_score": 0.891775,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.944664,
        "recall": 0.962451,
        "f1": 0.950428,
        "accuracy": 0.962451,
        "main_score": 0.950428,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.271126,
        "recall": 0.290514,
        "f1": 0.275137,
        "accuracy": 0.290514,
        "main_score": 0.275137,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.554925,
        "recall": 0.651186,
        "f1": 0.581368,
        "accuracy": 0.651186,
        "main_score": 0.581368,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.960319,
        "recall": 0.967391,
        "f1": 0.962069,
        "accuracy": 0.967391,
        "main_score": 0.962069,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.974473,
        "recall": 0.982213,
        "f1": 0.976943,
        "accuracy": 0.982213,
        "main_score": 0.976943,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.55154,
        "recall": 0.587945,
        "f1": 0.559743,
        "accuracy": 0.587945,
        "main_score": 0.559743,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.706287,
        "recall": 0.772727,
        "f1": 0.72456,
        "accuracy": 0.772727,
        "main_score": 0.72456,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.190794,
        "recall": 0.214427,
        "f1": 0.195214,
        "accuracy": 0.214427,
        "main_score": 0.195214,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.451751,
        "recall": 0.54249,
        "f1": 0.475465,
        "accuracy": 0.54249,
        "main_score": 0.475465,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.686142,
        "recall": 0.704545,
        "f1": 0.690519,
        "accuracy": 0.704545,
        "main_score": 0.690519,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.820438,
        "recall": 0.870553,
        "f1": 0.835394,
        "accuracy": 0.870553,
        "main_score": 0.835394,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.397162,
        "recall": 0.433794,
        "f1": 0.405307,
        "accuracy": 0.433794,
        "main_score": 0.405307,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.623456,
        "recall": 0.69664,
        "f1": 0.642695,
        "accuracy": 0.69664,
        "main_score": 0.642695,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.376332,
        "recall": 0.408103,
        "f1": 0.38301,
        "accuracy": 0.408103,
        "main_score": 0.38301,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.575222,
        "recall": 0.66502,
        "f1": 0.599714,
        "accuracy": 0.66502,
        "main_score": 0.599714,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.886175,
        "recall": 0.908103,
        "f1": 0.891925,
        "accuracy": 0.908103,
        "main_score": 0.891925,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.928277,
        "recall": 0.948617,
        "f1": 0.934289,
        "accuracy": 0.948617,
        "main_score": 0.934289,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.374142,
        "recall": 0.398221,
        "f1": 0.379094,
        "accuracy": 0.398221,
        "main_score": 0.379094,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.670193,
        "recall": 0.749012,
        "f1": 0.692286,
        "accuracy": 0.749012,
        "main_score": 0.692286,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.713299,
        "recall": 0.726285,
        "f1": 0.715954,
        "accuracy": 0.726285,
        "main_score": 0.715954,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.855155,
        "recall": 0.895257,
        "f1": 0.867256,
        "accuracy": 0.895257,
        "main_score": 0.867256,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.811456,
        "recall": 0.829051,
        "f1": 0.815845,
        "accuracy": 0.829051,
        "main_score": 0.815845,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.89861,
        "recall": 0.927866,
        "f1": 0.907677,
        "accuracy": 0.927866,
        "main_score": 0.907677,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.086509,
        "recall": 0.09585,
        "f1": 0.0882,
        "accuracy": 0.09585,
        "main_score": 0.0882,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.264677,
        "recall": 0.36166,
        "f1": 0.287932,
        "accuracy": 0.36166,
        "main_score": 0.287932,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.143806,
        "recall": 0.158103,
        "f1": 0.14621,
        "accuracy": 0.158103,
        "main_score": 0.14621,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.430559,
        "recall": 0.525692,
        "f1": 0.454975,
        "accuracy": 0.525692,
        "main_score": 0.454975,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.332029,
        "recall": 0.348814,
        "f1": 0.335499,
        "accuracy": 0.348814,
        "main_score": 0.335499,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.562818,
        "recall": 0.651186,
        "f1": 0.58632,
        "accuracy": 0.651186,
        "main_score": 0.58632,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.644357,
        "recall": 0.661067,
        "f1": 0.648278,
        "accuracy": 0.661067,
        "main_score": 0.648278,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.854194,
        "recall": 0.895257,
        "f1": 0.866685,
        "accuracy": 0.895257,
        "main_score": 0.866685,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.849232,
        "recall": 0.858696,
        "f1": 0.851192,
        "accuracy": 0.858696,
        "main_score": 0.851192,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.943923,
        "recall": 0.960474,
        "f1": 0.949177,
        "accuracy": 0.960474,
        "main_score": 0.949177,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.783495,
        "recall": 0.794466,
        "f1": 0.785701,
        "accuracy": 0.794466,
        "main_score": 0.785701,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.918725,
        "recall": 0.942688,
        "f1": 0.92612,
        "accuracy": 0.942688,
        "main_score": 0.92612,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.055803,
        "recall": 0.068182,
        "f1": 0.05814,
        "accuracy": 0.068182,
        "main_score": 0.05814,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.138782,
        "recall": 0.211462,
        "f1": 0.153751,
        "accuracy": 0.211462,
        "main_score": 0.153751,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.066374,
        "recall": 0.074111,
        "f1": 0.067287,
        "accuracy": 0.074111,
        "main_score": 0.067287,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.27559,
        "recall": 0.353755,
        "f1": 0.294141,
        "accuracy": 0.353755,
        "main_score": 0.294141,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.763733,
        "recall": 0.774704,
        "f1": 0.765946,
        "accuracy": 0.774704,
        "main_score": 0.765946,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.898172,
        "recall": 0.928854,
        "f1": 0.907792,
        "accuracy": 0.928854,
        "main_score": 0.907792,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.406542,
        "recall": 0.420949,
        "f1": 0.409656,
        "accuracy": 0.420949,
        "main_score": 0.409656,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.643817,
        "recall": 0.713439,
        "f1": 0.662932,
        "accuracy": 0.713439,
        "main_score": 0.662932,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.737696,
        "recall": 0.746047,
        "f1": 0.738871,
        "accuracy": 0.746047,
        "main_score": 0.738871,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.899292,
        "recall": 0.93083,
        "f1": 0.909321,
        "accuracy": 0.93083,
        "main_score": 0.909321,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.733645,
        "recall": 0.743083,
        "f1": 0.735303,
        "accuracy": 0.743083,
        "main_score": 0.735303,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.885985,
        "recall": 0.91996,
        "f1": 0.896443,
        "accuracy": 0.91996,
        "main_score": 0.896443,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.713081,
        "recall": 0.721344,
        "f1": 0.714197,
        "accuracy": 0.721344,
        "main_score": 0.714197,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.902421,
        "recall": 0.932806,
        "f1": 0.912121,
        "accuracy": 0.932806,
        "main_score": 0.912121,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.201818,
        "recall": 0.212451,
        "f1": 0.203661,
        "accuracy": 0.212451,
        "main_score": 0.203661,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.423293,
        "recall": 0.505929,
        "f1": 0.443341,
        "accuracy": 0.505929,
        "main_score": 0.443341,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.786319,
        "recall": 0.798419,
        "f1": 0.788833,
        "accuracy": 0.798419,
        "main_score": 0.788833,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.903162,
        "recall": 0.931818,
        "f1": 0.911975,
        "accuracy": 0.931818,
        "main_score": 0.911975,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.807711,
        "recall": 0.818182,
        "f1": 0.809989,
        "accuracy": 0.818182,
        "main_score": 0.809989,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.90336,
        "recall": 0.931818,
        "f1": 0.912352,
        "accuracy": 0.931818,
        "main_score": 0.912352,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.003954,
        "recall": 0.005929,
        "f1": 0.004284,
        "accuracy": 0.005929,
        "main_score": 0.004284,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002991,
        "recall": 0.021739,
        "f1": 0.004493,
        "accuracy": 0.021739,
        "main_score": 0.004493,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 3192.028078317642,
  "kg_co2_emissions": 0.29367100812185143
}