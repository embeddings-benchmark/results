{
  "dataset_revision": "6268b37d6f975f2a134791ba2f250a91d0bdfb4f",
  "task_name": "WikipediaRerankingMultilingual",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "map": 0.896951,
        "mrr": 0.896951,
        "nAUC_map_max": 0.358302,
        "nAUC_map_std": 0.311978,
        "nAUC_map_diff1": 0.776658,
        "nAUC_mrr_max": 0.358302,
        "nAUC_mrr_std": 0.311978,
        "nAUC_mrr_diff1": 0.776658,
        "main_score": 0.896951,
        "hf_subset": "bg",
        "languages": [
          "bul-Cyrl"
        ]
      },
      {
        "map": 0.811234,
        "mrr": 0.811234,
        "nAUC_map_max": 0.472246,
        "nAUC_map_std": 0.12897,
        "nAUC_map_diff1": 0.681911,
        "nAUC_mrr_max": 0.472246,
        "nAUC_mrr_std": 0.12897,
        "nAUC_mrr_diff1": 0.681911,
        "main_score": 0.811234,
        "hf_subset": "bn",
        "languages": [
          "ben-Beng"
        ]
      },
      {
        "map": 0.920143,
        "mrr": 0.920143,
        "nAUC_map_max": 0.368645,
        "nAUC_map_std": 0.247495,
        "nAUC_map_diff1": 0.816929,
        "nAUC_mrr_max": 0.368645,
        "nAUC_mrr_std": 0.247495,
        "nAUC_mrr_diff1": 0.816929,
        "main_score": 0.920143,
        "hf_subset": "cs",
        "languages": [
          "ces-Latn"
        ]
      },
      {
        "map": 0.930805,
        "mrr": 0.931249,
        "nAUC_map_max": 0.418194,
        "nAUC_map_std": 0.343919,
        "nAUC_map_diff1": 0.848183,
        "nAUC_mrr_max": 0.432012,
        "nAUC_mrr_std": 0.349622,
        "nAUC_mrr_diff1": 0.84665,
        "main_score": 0.930805,
        "hf_subset": "da",
        "languages": [
          "dan-Latn"
        ]
      },
      {
        "map": 0.920453,
        "mrr": 0.920453,
        "nAUC_map_max": 0.453259,
        "nAUC_map_std": 0.336877,
        "nAUC_map_diff1": 0.825546,
        "nAUC_mrr_max": 0.453259,
        "nAUC_mrr_std": 0.336877,
        "nAUC_mrr_diff1": 0.825546,
        "main_score": 0.920453,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      },
      {
        "map": 0.942928,
        "mrr": 0.942928,
        "nAUC_map_max": 0.398172,
        "nAUC_map_std": 0.402136,
        "nAUC_map_diff1": 0.850981,
        "nAUC_mrr_max": 0.398172,
        "nAUC_mrr_std": 0.402136,
        "nAUC_mrr_diff1": 0.850981,
        "main_score": 0.942928,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      },
      {
        "map": 0.884572,
        "mrr": 0.884572,
        "nAUC_map_max": 0.463027,
        "nAUC_map_std": 0.392243,
        "nAUC_map_diff1": 0.800938,
        "nAUC_mrr_max": 0.463027,
        "nAUC_mrr_std": 0.392243,
        "nAUC_mrr_diff1": 0.800938,
        "main_score": 0.884572,
        "hf_subset": "fa",
        "languages": [
          "fas-Arab"
        ]
      },
      {
        "map": 0.914984,
        "mrr": 0.914984,
        "nAUC_map_max": 0.329871,
        "nAUC_map_std": 0.150696,
        "nAUC_map_diff1": 0.782931,
        "nAUC_mrr_max": 0.329871,
        "nAUC_mrr_std": 0.150696,
        "nAUC_mrr_diff1": 0.782931,
        "main_score": 0.914984,
        "hf_subset": "fi",
        "languages": [
          "fin-Latn"
        ]
      },
      {
        "map": 0.834259,
        "mrr": 0.834944,
        "nAUC_map_max": 0.495141,
        "nAUC_map_std": 0.274094,
        "nAUC_map_diff1": 0.755301,
        "nAUC_mrr_max": 0.497702,
        "nAUC_mrr_std": 0.280056,
        "nAUC_mrr_diff1": 0.753306,
        "main_score": 0.834259,
        "hf_subset": "hi",
        "languages": [
          "hin-Deva"
        ]
      },
      {
        "map": 0.92841,
        "mrr": 0.92841,
        "nAUC_map_max": 0.435246,
        "nAUC_map_std": 0.321337,
        "nAUC_map_diff1": 0.853961,
        "nAUC_mrr_max": 0.435246,
        "nAUC_mrr_std": 0.321337,
        "nAUC_mrr_diff1": 0.853961,
        "main_score": 0.92841,
        "hf_subset": "it",
        "languages": [
          "ita-Latn"
        ]
      },
      {
        "map": 0.924425,
        "mrr": 0.924758,
        "nAUC_map_max": 0.189771,
        "nAUC_map_std": 0.233026,
        "nAUC_map_diff1": 0.740042,
        "nAUC_mrr_max": 0.191288,
        "nAUC_mrr_std": 0.241789,
        "nAUC_mrr_diff1": 0.738433,
        "main_score": 0.924425,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      },
      {
        "map": 0.916449,
        "mrr": 0.916449,
        "nAUC_map_max": 0.294881,
        "nAUC_map_std": 0.307256,
        "nAUC_map_diff1": 0.799411,
        "nAUC_mrr_max": 0.294881,
        "nAUC_mrr_std": 0.307256,
        "nAUC_mrr_diff1": 0.799411,
        "main_score": 0.916449,
        "hf_subset": "pt",
        "languages": [
          "por-Latn"
        ]
      },
      {
        "map": 0.920763,
        "mrr": 0.921096,
        "nAUC_map_max": 0.272465,
        "nAUC_map_std": 0.140197,
        "nAUC_map_diff1": 0.751684,
        "nAUC_mrr_max": 0.269731,
        "nAUC_mrr_std": 0.145702,
        "nAUC_mrr_diff1": 0.750186,
        "main_score": 0.920763,
        "hf_subset": "ro",
        "languages": [
          "ron-Latn"
        ]
      },
      {
        "map": 0.910826,
        "mrr": 0.91116,
        "nAUC_map_max": 0.291584,
        "nAUC_map_std": 0.060059,
        "nAUC_map_diff1": 0.803989,
        "nAUC_mrr_max": 0.299306,
        "nAUC_mrr_std": 0.067001,
        "nAUC_mrr_diff1": 0.802823,
        "main_score": 0.910826,
        "hf_subset": "sr",
        "languages": [
          "srp-Cyrl"
        ]
      },
      {
        "map": 0.904789,
        "mrr": 0.904789,
        "nAUC_map_max": 0.358364,
        "nAUC_map_std": 0.290332,
        "nAUC_map_diff1": 0.806751,
        "nAUC_mrr_max": 0.358364,
        "nAUC_mrr_std": 0.290332,
        "nAUC_mrr_diff1": 0.806751,
        "main_score": 0.904789,
        "hf_subset": "no",
        "languages": [
          "nor-Latn"
        ]
      },
      {
        "map": 0.935422,
        "mrr": 0.935422,
        "nAUC_map_max": 0.233553,
        "nAUC_map_std": 0.170817,
        "nAUC_map_diff1": 0.833772,
        "nAUC_mrr_max": 0.233553,
        "nAUC_mrr_std": 0.170817,
        "nAUC_mrr_diff1": 0.833772,
        "main_score": 0.935422,
        "hf_subset": "sv",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 3778.4207892417908,
  "kg_co2_emissions": 0.33096389381834446
}