{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.102051,
        "f1": 0.073335,
        "f1_weighted": 0.09104,
        "scores_per_experiment": [
          {
            "accuracy": 0.089844,
            "f1": 0.070188,
            "f1_weighted": 0.078884
          },
          {
            "accuracy": 0.087891,
            "f1": 0.063712,
            "f1_weighted": 0.079373
          },
          {
            "accuracy": 0.102051,
            "f1": 0.074018,
            "f1_weighted": 0.083517
          },
          {
            "accuracy": 0.100098,
            "f1": 0.072966,
            "f1_weighted": 0.096098
          },
          {
            "accuracy": 0.100098,
            "f1": 0.07287,
            "f1_weighted": 0.094318
          },
          {
            "accuracy": 0.102051,
            "f1": 0.071613,
            "f1_weighted": 0.0965
          },
          {
            "accuracy": 0.112305,
            "f1": 0.082044,
            "f1_weighted": 0.094918
          },
          {
            "accuracy": 0.113281,
            "f1": 0.079763,
            "f1_weighted": 0.096836
          },
          {
            "accuracy": 0.116699,
            "f1": 0.077438,
            "f1_weighted": 0.107603
          },
          {
            "accuracy": 0.096191,
            "f1": 0.068736,
            "f1_weighted": 0.082354
          }
        ],
        "main_score": 0.102051,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.101221,
        "f1": 0.072363,
        "f1_weighted": 0.088303,
        "scores_per_experiment": [
          {
            "accuracy": 0.087402,
            "f1": 0.066421,
            "f1_weighted": 0.072637
          },
          {
            "accuracy": 0.089355,
            "f1": 0.068008,
            "f1_weighted": 0.074695
          },
          {
            "accuracy": 0.106934,
            "f1": 0.078093,
            "f1_weighted": 0.092064
          },
          {
            "accuracy": 0.108887,
            "f1": 0.081519,
            "f1_weighted": 0.098304
          },
          {
            "accuracy": 0.095703,
            "f1": 0.07104,
            "f1_weighted": 0.086818
          },
          {
            "accuracy": 0.084473,
            "f1": 0.053647,
            "f1_weighted": 0.076386
          },
          {
            "accuracy": 0.108398,
            "f1": 0.071296,
            "f1_weighted": 0.083234
          },
          {
            "accuracy": 0.107422,
            "f1": 0.076654,
            "f1_weighted": 0.098386
          },
          {
            "accuracy": 0.123047,
            "f1": 0.087835,
            "f1_weighted": 0.116414
          },
          {
            "accuracy": 0.100586,
            "f1": 0.069118,
            "f1_weighted": 0.084095
          }
        ],
        "main_score": 0.101221,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 27572.723649263382,
  "kg_co2_emissions": 2.46378659217948
}