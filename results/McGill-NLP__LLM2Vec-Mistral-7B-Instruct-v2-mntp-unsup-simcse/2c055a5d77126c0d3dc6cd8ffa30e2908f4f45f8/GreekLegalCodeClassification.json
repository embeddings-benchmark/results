{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.24502,
        "f1": 0.201105,
        "f1_weighted": 0.261263,
        "scores_per_experiment": [
          {
            "accuracy": 0.234375,
            "f1": 0.191579,
            "f1_weighted": 0.253836
          },
          {
            "accuracy": 0.234863,
            "f1": 0.19301,
            "f1_weighted": 0.246849
          },
          {
            "accuracy": 0.244141,
            "f1": 0.197593,
            "f1_weighted": 0.263873
          },
          {
            "accuracy": 0.220215,
            "f1": 0.17919,
            "f1_weighted": 0.2366
          },
          {
            "accuracy": 0.255371,
            "f1": 0.218052,
            "f1_weighted": 0.273248
          },
          {
            "accuracy": 0.241699,
            "f1": 0.195906,
            "f1_weighted": 0.258074
          },
          {
            "accuracy": 0.255371,
            "f1": 0.197417,
            "f1_weighted": 0.277052
          },
          {
            "accuracy": 0.25,
            "f1": 0.212904,
            "f1_weighted": 0.258855
          },
          {
            "accuracy": 0.245605,
            "f1": 0.201116,
            "f1_weighted": 0.262478
          },
          {
            "accuracy": 0.268555,
            "f1": 0.224284,
            "f1_weighted": 0.281762
          }
        ],
        "main_score": 0.24502,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.240918,
        "f1": 0.207703,
        "f1_weighted": 0.253833,
        "scores_per_experiment": [
          {
            "accuracy": 0.230957,
            "f1": 0.196087,
            "f1_weighted": 0.244004
          },
          {
            "accuracy": 0.234375,
            "f1": 0.204252,
            "f1_weighted": 0.24742
          },
          {
            "accuracy": 0.24707,
            "f1": 0.215166,
            "f1_weighted": 0.257675
          },
          {
            "accuracy": 0.238281,
            "f1": 0.204415,
            "f1_weighted": 0.251368
          },
          {
            "accuracy": 0.250488,
            "f1": 0.213366,
            "f1_weighted": 0.263073
          },
          {
            "accuracy": 0.227051,
            "f1": 0.196072,
            "f1_weighted": 0.240046
          },
          {
            "accuracy": 0.241699,
            "f1": 0.208811,
            "f1_weighted": 0.256597
          },
          {
            "accuracy": 0.23584,
            "f1": 0.21017,
            "f1_weighted": 0.247937
          },
          {
            "accuracy": 0.234863,
            "f1": 0.200167,
            "f1_weighted": 0.248379
          },
          {
            "accuracy": 0.268555,
            "f1": 0.228519,
            "f1_weighted": 0.281825
          }
        ],
        "main_score": 0.240918,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 12608.025142669678,
  "kg_co2_emissions": 0.42041161427626095
}