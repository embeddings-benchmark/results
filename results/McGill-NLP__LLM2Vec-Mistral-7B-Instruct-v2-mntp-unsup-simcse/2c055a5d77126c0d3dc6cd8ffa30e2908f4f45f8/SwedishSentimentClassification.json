{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.811768,
        "f1": 0.811505,
        "f1_weighted": 0.811509,
        "ap": 0.754343,
        "ap_weighted": 0.754343,
        "scores_per_experiment": [
          {
            "accuracy": 0.805176,
            "f1": 0.804111,
            "f1_weighted": 0.804153,
            "ap": 0.734968,
            "ap_weighted": 0.734968
          },
          {
            "accuracy": 0.833496,
            "f1": 0.833475,
            "f1_weighted": 0.833481,
            "ap": 0.77695,
            "ap_weighted": 0.77695
          },
          {
            "accuracy": 0.806152,
            "f1": 0.805093,
            "f1_weighted": 0.805051,
            "ap": 0.764808,
            "ap_weighted": 0.764808
          },
          {
            "accuracy": 0.749023,
            "f1": 0.748989,
            "f1_weighted": 0.74898,
            "ap": 0.689522,
            "ap_weighted": 0.689522
          },
          {
            "accuracy": 0.819824,
            "f1": 0.819797,
            "f1_weighted": 0.819804,
            "ap": 0.761185,
            "ap_weighted": 0.761185
          },
          {
            "accuracy": 0.841309,
            "f1": 0.841262,
            "f1_weighted": 0.841254,
            "ap": 0.792812,
            "ap_weighted": 0.792812
          },
          {
            "accuracy": 0.807129,
            "f1": 0.807009,
            "f1_weighted": 0.807023,
            "ap": 0.744796,
            "ap_weighted": 0.744796
          },
          {
            "accuracy": 0.858398,
            "f1": 0.858379,
            "f1_weighted": 0.858384,
            "ap": 0.806128,
            "ap_weighted": 0.806128
          },
          {
            "accuracy": 0.79541,
            "f1": 0.795384,
            "f1_weighted": 0.795391,
            "ap": 0.734484,
            "ap_weighted": 0.734484
          },
          {
            "accuracy": 0.801758,
            "f1": 0.801552,
            "f1_weighted": 0.80157,
            "ap": 0.737777,
            "ap_weighted": 0.737777
          }
        ],
        "main_score": 0.811768,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.804834,
        "f1": 0.804524,
        "f1_weighted": 0.804525,
        "ap": 0.747043,
        "ap_weighted": 0.747043,
        "scores_per_experiment": [
          {
            "accuracy": 0.791504,
            "f1": 0.790175,
            "f1_weighted": 0.790207,
            "ap": 0.719861,
            "ap_weighted": 0.719861
          },
          {
            "accuracy": 0.823242,
            "f1": 0.823229,
            "f1_weighted": 0.823232,
            "ap": 0.765258,
            "ap_weighted": 0.765258
          },
          {
            "accuracy": 0.806152,
            "f1": 0.805036,
            "f1_weighted": 0.805007,
            "ap": 0.764722,
            "ap_weighted": 0.764722
          },
          {
            "accuracy": 0.746582,
            "f1": 0.74649,
            "f1_weighted": 0.746481,
            "ap": 0.687522,
            "ap_weighted": 0.687522
          },
          {
            "accuracy": 0.81543,
            "f1": 0.81543,
            "f1_weighted": 0.815429,
            "ap": 0.758387,
            "ap_weighted": 0.758387
          },
          {
            "accuracy": 0.821289,
            "f1": 0.821155,
            "f1_weighted": 0.821146,
            "ap": 0.770898,
            "ap_weighted": 0.770898
          },
          {
            "accuracy": 0.799316,
            "f1": 0.799264,
            "f1_weighted": 0.799271,
            "ap": 0.737391,
            "ap_weighted": 0.737391
          },
          {
            "accuracy": 0.852051,
            "f1": 0.852049,
            "f1_weighted": 0.852048,
            "ap": 0.801807,
            "ap_weighted": 0.801807
          },
          {
            "accuracy": 0.79834,
            "f1": 0.798267,
            "f1_weighted": 0.798274,
            "ap": 0.735844,
            "ap_weighted": 0.735844
          },
          {
            "accuracy": 0.794434,
            "f1": 0.794143,
            "f1_weighted": 0.794158,
            "ap": 0.728736,
            "ap_weighted": 0.728736
          }
        ],
        "main_score": 0.804834,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 57.42942929267883,
  "kg_co2_emissions": 0.0039296196819258375
}