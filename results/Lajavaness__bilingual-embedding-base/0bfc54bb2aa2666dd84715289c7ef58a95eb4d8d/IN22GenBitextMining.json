{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.274608,
        "recall": 0.358398,
        "f1": 0.294985,
        "accuracy": 0.358398,
        "main_score": 0.294985,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.938232,
        "recall": 0.956055,
        "f1": 0.943913,
        "accuracy": 0.956055,
        "main_score": 0.943913,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.877686,
        "recall": 0.911133,
        "f1": 0.888216,
        "accuracy": 0.911133,
        "main_score": 0.888216,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.809001,
        "recall": 0.864258,
        "f1": 0.826563,
        "accuracy": 0.864258,
        "main_score": 0.826563,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.978516,
        "recall": 0.985352,
        "f1": 0.980794,
        "accuracy": 0.985352,
        "main_score": 0.980794,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005499,
        "recall": 0.018555,
        "f1": 0.007385,
        "accuracy": 0.018555,
        "main_score": 0.007385,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.978027,
        "recall": 0.985352,
        "f1": 0.980469,
        "accuracy": 0.985352,
        "main_score": 0.980469,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.949382,
        "recall": 0.96582,
        "f1": 0.954753,
        "accuracy": 0.96582,
        "main_score": 0.954753,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005131,
        "recall": 0.017578,
        "f1": 0.006774,
        "accuracy": 0.017578,
        "main_score": 0.006774,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.760368,
        "recall": 0.822266,
        "f1": 0.779297,
        "accuracy": 0.822266,
        "main_score": 0.779297,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.99056,
        "recall": 0.993164,
        "f1": 0.991374,
        "accuracy": 0.993164,
        "main_score": 0.991374,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.306547,
        "recall": 0.394531,
        "f1": 0.327521,
        "accuracy": 0.394531,
        "main_score": 0.327521,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.930176,
        "recall": 0.951172,
        "f1": 0.937012,
        "accuracy": 0.951172,
        "main_score": 0.937012,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.900879,
        "recall": 0.927734,
        "f1": 0.90931,
        "accuracy": 0.927734,
        "main_score": 0.90931,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.800732,
        "recall": 0.857422,
        "f1": 0.818392,
        "accuracy": 0.857422,
        "main_score": 0.818392,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.008391,
        "recall": 0.021484,
        "f1": 0.010097,
        "accuracy": 0.021484,
        "main_score": 0.010097,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.982422,
        "recall": 0.988281,
        "f1": 0.984375,
        "accuracy": 0.988281,
        "main_score": 0.984375,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.964844,
        "recall": 0.976562,
        "f1": 0.96875,
        "accuracy": 0.976562,
        "main_score": 0.96875,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.003241,
        "recall": 0.015625,
        "f1": 0.004643,
        "accuracy": 0.015625,
        "main_score": 0.004643,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.787419,
        "recall": 0.848633,
        "f1": 0.806348,
        "accuracy": 0.848633,
        "main_score": 0.806348,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.997559,
        "recall": 0.998047,
        "f1": 0.997721,
        "accuracy": 0.998047,
        "main_score": 0.997721,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.273605,
        "recall": 0.321289,
        "f1": 0.282984,
        "accuracy": 0.321289,
        "main_score": 0.282984,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.296915,
        "recall": 0.350586,
        "f1": 0.308019,
        "accuracy": 0.350586,
        "main_score": 0.308019,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.351323,
        "recall": 0.399414,
        "f1": 0.362445,
        "accuracy": 0.399414,
        "main_score": 0.362445,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.263004,
        "recall": 0.299805,
        "f1": 0.271644,
        "accuracy": 0.299805,
        "main_score": 0.271644,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.312211,
        "recall": 0.350586,
        "f1": 0.32075,
        "accuracy": 0.350586,
        "main_score": 0.32075,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.26497,
        "recall": 0.316406,
        "f1": 0.27671,
        "accuracy": 0.316406,
        "main_score": 0.27671,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.333769,
        "recall": 0.388672,
        "f1": 0.346023,
        "accuracy": 0.388672,
        "main_score": 0.346023,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.24458,
        "recall": 0.293945,
        "f1": 0.254652,
        "accuracy": 0.293945,
        "main_score": 0.254652,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.264004,
        "recall": 0.319336,
        "f1": 0.275423,
        "accuracy": 0.319336,
        "main_score": 0.275423,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.328402,
        "recall": 0.386719,
        "f1": 0.341929,
        "accuracy": 0.386719,
        "main_score": 0.341929,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.277394,
        "recall": 0.321289,
        "f1": 0.287588,
        "accuracy": 0.321289,
        "main_score": 0.287588,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.300584,
        "recall": 0.352539,
        "f1": 0.312229,
        "accuracy": 0.352539,
        "main_score": 0.312229,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.011177,
        "recall": 0.024414,
        "f1": 0.013142,
        "accuracy": 0.024414,
        "main_score": 0.013142,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.327533,
        "recall": 0.37207,
        "f1": 0.337232,
        "accuracy": 0.37207,
        "main_score": 0.337232,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.27142,
        "recall": 0.325195,
        "f1": 0.282951,
        "accuracy": 0.325195,
        "main_score": 0.282951,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.257611,
        "recall": 0.30957,
        "f1": 0.269424,
        "accuracy": 0.30957,
        "main_score": 0.269424,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.301089,
        "recall": 0.368164,
        "f1": 0.316636,
        "accuracy": 0.368164,
        "main_score": 0.316636,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00699,
        "recall": 0.023438,
        "f1": 0.009313,
        "accuracy": 0.023438,
        "main_score": 0.009313,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.346504,
        "recall": 0.396484,
        "f1": 0.357974,
        "accuracy": 0.396484,
        "main_score": 0.357974,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.270893,
        "recall": 0.31543,
        "f1": 0.281543,
        "accuracy": 0.31543,
        "main_score": 0.281543,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.282322,
        "recall": 0.334961,
        "f1": 0.29376,
        "accuracy": 0.334961,
        "main_score": 0.29376,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.290005,
        "recall": 0.331055,
        "f1": 0.298859,
        "accuracy": 0.331055,
        "main_score": 0.298859,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.913363,
        "recall": 0.9375,
        "f1": 0.920768,
        "accuracy": 0.9375,
        "main_score": 0.920768,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.932731,
        "recall": 0.951172,
        "f1": 0.938379,
        "accuracy": 0.951172,
        "main_score": 0.938379,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.372052,
        "recall": 0.448242,
        "f1": 0.389997,
        "accuracy": 0.448242,
        "main_score": 0.389997,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.94515,
        "recall": 0.960938,
        "f1": 0.95,
        "accuracy": 0.960938,
        "main_score": 0.95,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.850993,
        "recall": 0.888672,
        "f1": 0.862421,
        "accuracy": 0.888672,
        "main_score": 0.862421,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.950439,
        "recall": 0.963867,
        "f1": 0.954622,
        "accuracy": 0.963867,
        "main_score": 0.954622,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.975911,
        "recall": 0.983398,
        "f1": 0.978353,
        "accuracy": 0.983398,
        "main_score": 0.978353,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.930046,
        "recall": 0.948242,
        "f1": 0.935454,
        "accuracy": 0.948242,
        "main_score": 0.935454,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.756494,
        "recall": 0.816406,
        "f1": 0.77474,
        "accuracy": 0.816406,
        "main_score": 0.77474,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.968343,
        "recall": 0.977539,
        "f1": 0.971257,
        "accuracy": 0.977539,
        "main_score": 0.971257,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.932699,
        "recall": 0.951172,
        "f1": 0.938509,
        "accuracy": 0.951172,
        "main_score": 0.938509,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.948893,
        "recall": 0.963867,
        "f1": 0.953776,
        "accuracy": 0.963867,
        "main_score": 0.953776,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003949,
        "recall": 0.013672,
        "f1": 0.005103,
        "accuracy": 0.013672,
        "main_score": 0.005103,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.970866,
        "recall": 0.979492,
        "f1": 0.973633,
        "accuracy": 0.979492,
        "main_score": 0.973633,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.942139,
        "recall": 0.958984,
        "f1": 0.947331,
        "accuracy": 0.958984,
        "main_score": 0.947331,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.905029,
        "recall": 0.931641,
        "f1": 0.913477,
        "accuracy": 0.931641,
        "main_score": 0.913477,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.876937,
        "recall": 0.910156,
        "f1": 0.887272,
        "accuracy": 0.910156,
        "main_score": 0.887272,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005694,
        "recall": 0.016602,
        "f1": 0.007001,
        "accuracy": 0.016602,
        "main_score": 0.007001,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.826367,
        "recall": 0.871094,
        "f1": 0.840137,
        "accuracy": 0.871094,
        "main_score": 0.840137,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.94165,
        "recall": 0.957031,
        "f1": 0.946322,
        "accuracy": 0.957031,
        "main_score": 0.946322,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.926628,
        "recall": 0.947266,
        "f1": 0.932943,
        "accuracy": 0.947266,
        "main_score": 0.932943,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.954582,
        "recall": 0.96582,
        "f1": 0.957899,
        "accuracy": 0.96582,
        "main_score": 0.957899,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.974365,
        "recall": 0.982422,
        "f1": 0.976953,
        "accuracy": 0.982422,
        "main_score": 0.976953,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.254058,
        "recall": 0.345703,
        "f1": 0.275009,
        "accuracy": 0.345703,
        "main_score": 0.275009,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.930013,
        "recall": 0.951172,
        "f1": 0.936654,
        "accuracy": 0.951172,
        "main_score": 0.936654,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.873291,
        "recall": 0.911133,
        "f1": 0.88524,
        "accuracy": 0.911133,
        "main_score": 0.88524,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.771061,
        "recall": 0.834961,
        "f1": 0.790416,
        "accuracy": 0.834961,
        "main_score": 0.790416,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.98584,
        "recall": 0.990234,
        "f1": 0.987305,
        "accuracy": 0.990234,
        "main_score": 0.987305,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003016,
        "recall": 0.012695,
        "f1": 0.003639,
        "accuracy": 0.012695,
        "main_score": 0.003639,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.942057,
        "recall": 0.960938,
        "f1": 0.948242,
        "accuracy": 0.960938,
        "main_score": 0.948242,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001453,
        "recall": 0.010742,
        "f1": 0.002244,
        "accuracy": 0.010742,
        "main_score": 0.002244,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.786793,
        "recall": 0.84375,
        "f1": 0.803975,
        "accuracy": 0.84375,
        "main_score": 0.803975,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.996094,
        "recall": 0.99707,
        "f1": 0.996419,
        "accuracy": 0.99707,
        "main_score": 0.996419,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.882659,
        "recall": 0.914062,
        "f1": 0.891976,
        "accuracy": 0.914062,
        "main_score": 0.891976,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.913167,
        "recall": 0.938477,
        "f1": 0.921289,
        "accuracy": 0.938477,
        "main_score": 0.921289,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.366202,
        "recall": 0.446289,
        "f1": 0.386169,
        "accuracy": 0.446289,
        "main_score": 0.386169,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.858994,
        "recall": 0.895508,
        "f1": 0.870181,
        "accuracy": 0.895508,
        "main_score": 0.870181,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.879209,
        "recall": 0.912109,
        "f1": 0.888967,
        "accuracy": 0.912109,
        "main_score": 0.888967,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.912663,
        "recall": 0.9375,
        "f1": 0.920364,
        "accuracy": 0.9375,
        "main_score": 0.920364,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.932617,
        "recall": 0.951172,
        "f1": 0.938235,
        "accuracy": 0.951172,
        "main_score": 0.938235,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.900367,
        "recall": 0.924805,
        "f1": 0.907345,
        "accuracy": 0.924805,
        "main_score": 0.907345,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.721088,
        "recall": 0.78418,
        "f1": 0.739881,
        "accuracy": 0.78418,
        "main_score": 0.739881,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.911702,
        "recall": 0.936523,
        "f1": 0.919257,
        "accuracy": 0.936523,
        "main_score": 0.919257,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.90083,
        "recall": 0.928711,
        "f1": 0.909375,
        "accuracy": 0.928711,
        "main_score": 0.909375,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.935872,
        "recall": 0.954102,
        "f1": 0.941476,
        "accuracy": 0.954102,
        "main_score": 0.941476,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.008358,
        "recall": 0.022461,
        "f1": 0.009775,
        "accuracy": 0.022461,
        "main_score": 0.009775,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.925618,
        "recall": 0.947266,
        "f1": 0.932227,
        "accuracy": 0.947266,
        "main_score": 0.932227,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.902295,
        "recall": 0.930664,
        "f1": 0.911151,
        "accuracy": 0.930664,
        "main_score": 0.911151,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.857008,
        "recall": 0.889648,
        "f1": 0.866457,
        "accuracy": 0.889648,
        "main_score": 0.866457,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.854036,
        "recall": 0.891602,
        "f1": 0.865123,
        "accuracy": 0.891602,
        "main_score": 0.865123,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005792,
        "recall": 0.024414,
        "f1": 0.007816,
        "accuracy": 0.024414,
        "main_score": 0.007816,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.771883,
        "recall": 0.822266,
        "f1": 0.78715,
        "accuracy": 0.822266,
        "main_score": 0.78715,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.889039,
        "recall": 0.916016,
        "f1": 0.896975,
        "accuracy": 0.916016,
        "main_score": 0.896975,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.890397,
        "recall": 0.919922,
        "f1": 0.899364,
        "accuracy": 0.919922,
        "main_score": 0.899364,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.898479,
        "recall": 0.925781,
        "f1": 0.906624,
        "accuracy": 0.925781,
        "main_score": 0.906624,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.291835,
        "recall": 0.376953,
        "f1": 0.312703,
        "accuracy": 0.376953,
        "main_score": 0.312703,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.937988,
        "recall": 0.957031,
        "f1": 0.944173,
        "accuracy": 0.957031,
        "main_score": 0.944173,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.90918,
        "recall": 0.936523,
        "f1": 0.918085,
        "accuracy": 0.936523,
        "main_score": 0.918085,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.836507,
        "recall": 0.883789,
        "f1": 0.85127,
        "accuracy": 0.883789,
        "main_score": 0.85127,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.993164,
        "f1": 0.991211,
        "accuracy": 0.993164,
        "main_score": 0.991211,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.009381,
        "recall": 0.021484,
        "f1": 0.011101,
        "accuracy": 0.021484,
        "main_score": 0.011101,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.944824,
        "recall": 0.961914,
        "f1": 0.950358,
        "accuracy": 0.961914,
        "main_score": 0.950358,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002868,
        "recall": 0.014648,
        "f1": 0.004055,
        "accuracy": 0.014648,
        "main_score": 0.004055,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.785352,
        "recall": 0.841797,
        "f1": 0.802637,
        "accuracy": 0.841797,
        "main_score": 0.802637,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.991699,
        "recall": 0.994141,
        "f1": 0.992513,
        "accuracy": 0.994141,
        "main_score": 0.992513,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.346524,
        "recall": 0.43457,
        "f1": 0.36749,
        "accuracy": 0.43457,
        "main_score": 0.36749,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.950684,
        "recall": 0.966797,
        "f1": 0.956055,
        "accuracy": 0.966797,
        "main_score": 0.956055,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.9021,
        "recall": 0.932617,
        "f1": 0.911849,
        "accuracy": 0.932617,
        "main_score": 0.911849,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.804095,
        "recall": 0.857422,
        "f1": 0.820199,
        "accuracy": 0.857422,
        "main_score": 0.820199,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003103,
        "recall": 0.013672,
        "f1": 0.004225,
        "accuracy": 0.013672,
        "main_score": 0.004225,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.994466,
        "recall": 0.996094,
        "f1": 0.994954,
        "accuracy": 0.996094,
        "main_score": 0.994954,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.980957,
        "recall": 0.987305,
        "f1": 0.983073,
        "accuracy": 0.987305,
        "main_score": 0.983073,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.951986,
        "recall": 0.967773,
        "f1": 0.957194,
        "accuracy": 0.967773,
        "main_score": 0.957194,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001163,
        "recall": 0.009766,
        "f1": 0.001952,
        "accuracy": 0.009766,
        "main_score": 0.001952,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.841715,
        "recall": 0.885742,
        "f1": 0.855353,
        "accuracy": 0.885742,
        "main_score": 0.855353,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.985677,
        "recall": 0.990234,
        "f1": 0.987142,
        "accuracy": 0.990234,
        "main_score": 0.987142,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.261612,
        "recall": 0.357422,
        "f1": 0.28444,
        "accuracy": 0.357422,
        "main_score": 0.28444,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.930176,
        "recall": 0.952148,
        "f1": 0.937337,
        "accuracy": 0.952148,
        "main_score": 0.937337,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.894645,
        "recall": 0.924805,
        "f1": 0.904036,
        "accuracy": 0.924805,
        "main_score": 0.904036,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.821615,
        "recall": 0.870117,
        "f1": 0.836509,
        "accuracy": 0.870117,
        "main_score": 0.836509,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004246,
        "recall": 0.016602,
        "f1": 0.005637,
        "accuracy": 0.016602,
        "main_score": 0.005637,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.975098,
        "recall": 0.983398,
        "f1": 0.977865,
        "accuracy": 0.983398,
        "main_score": 0.977865,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.964193,
        "recall": 0.975586,
        "f1": 0.967936,
        "accuracy": 0.975586,
        "main_score": 0.967936,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.004076,
        "recall": 0.016602,
        "f1": 0.005391,
        "accuracy": 0.016602,
        "main_score": 0.005391,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.78221,
        "recall": 0.841797,
        "f1": 0.800293,
        "accuracy": 0.841797,
        "main_score": 0.800293,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.996094,
        "recall": 0.99707,
        "f1": 0.996419,
        "accuracy": 0.99707,
        "main_score": 0.996419,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.841757,
        "recall": 0.883789,
        "f1": 0.854397,
        "accuracy": 0.883789,
        "main_score": 0.854397,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.837809,
        "recall": 0.880859,
        "f1": 0.851256,
        "accuracy": 0.880859,
        "main_score": 0.851256,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.293003,
        "recall": 0.365234,
        "f1": 0.310614,
        "accuracy": 0.365234,
        "main_score": 0.310614,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.773772,
        "recall": 0.829102,
        "f1": 0.790381,
        "accuracy": 0.829102,
        "main_score": 0.790381,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.817716,
        "recall": 0.864258,
        "f1": 0.831552,
        "accuracy": 0.864258,
        "main_score": 0.831552,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.722396,
        "recall": 0.787109,
        "f1": 0.741671,
        "accuracy": 0.787109,
        "main_score": 0.741671,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.864502,
        "recall": 0.901367,
        "f1": 0.876042,
        "accuracy": 0.901367,
        "main_score": 0.876042,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.843335,
        "recall": 0.884766,
        "f1": 0.856044,
        "accuracy": 0.884766,
        "main_score": 0.856044,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.857829,
        "recall": 0.897461,
        "f1": 0.870103,
        "accuracy": 0.897461,
        "main_score": 0.870103,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.873454,
        "recall": 0.90918,
        "f1": 0.884993,
        "accuracy": 0.90918,
        "main_score": 0.884993,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.833473,
        "recall": 0.876953,
        "f1": 0.846812,
        "accuracy": 0.876953,
        "main_score": 0.846812,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.844678,
        "recall": 0.889648,
        "f1": 0.858757,
        "accuracy": 0.889648,
        "main_score": 0.858757,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004554,
        "recall": 0.017578,
        "f1": 0.006007,
        "accuracy": 0.017578,
        "main_score": 0.006007,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.87557,
        "recall": 0.912109,
        "f1": 0.887109,
        "accuracy": 0.912109,
        "main_score": 0.887109,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.850781,
        "recall": 0.890625,
        "f1": 0.863053,
        "accuracy": 0.890625,
        "main_score": 0.863053,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.818636,
        "recall": 0.864258,
        "f1": 0.832668,
        "accuracy": 0.864258,
        "main_score": 0.832668,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.7643,
        "recall": 0.823242,
        "f1": 0.782243,
        "accuracy": 0.823242,
        "main_score": 0.782243,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.003305,
        "recall": 0.016602,
        "f1": 0.004282,
        "accuracy": 0.016602,
        "main_score": 0.004282,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.674919,
        "recall": 0.740234,
        "f1": 0.694224,
        "accuracy": 0.740234,
        "main_score": 0.694224,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.816056,
        "recall": 0.861328,
        "f1": 0.82963,
        "accuracy": 0.861328,
        "main_score": 0.82963,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.836995,
        "recall": 0.878906,
        "f1": 0.849549,
        "accuracy": 0.878906,
        "main_score": 0.849549,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.92041,
        "recall": 0.943359,
        "f1": 0.927376,
        "accuracy": 0.943359,
        "main_score": 0.927376,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.987142,
        "recall": 0.991211,
        "f1": 0.988444,
        "accuracy": 0.991211,
        "main_score": 0.988444,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.334963,
        "recall": 0.416016,
        "f1": 0.35462,
        "accuracy": 0.416016,
        "main_score": 0.35462,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.965332,
        "recall": 0.976562,
        "f1": 0.969076,
        "accuracy": 0.976562,
        "main_score": 0.969076,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.912874,
        "recall": 0.938477,
        "f1": 0.920964,
        "accuracy": 0.938477,
        "main_score": 0.920964,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.842936,
        "recall": 0.888672,
        "f1": 0.857552,
        "accuracy": 0.888672,
        "main_score": 0.857552,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.987793,
        "recall": 0.991211,
        "f1": 0.988932,
        "accuracy": 0.991211,
        "main_score": 0.988932,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005389,
        "recall": 0.019531,
        "f1": 0.006851,
        "accuracy": 0.019531,
        "main_score": 0.006851,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.970378,
        "recall": 0.979492,
        "f1": 0.973307,
        "accuracy": 0.979492,
        "main_score": 0.973307,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.974121,
        "recall": 0.982422,
        "f1": 0.976888,
        "accuracy": 0.982422,
        "main_score": 0.976888,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006074,
        "recall": 0.020508,
        "f1": 0.007756,
        "accuracy": 0.020508,
        "main_score": 0.007756,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.824219,
        "recall": 0.87207,
        "f1": 0.838918,
        "accuracy": 0.87207,
        "main_score": 0.838918,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.991699,
        "recall": 0.994141,
        "f1": 0.992513,
        "accuracy": 0.994141,
        "main_score": 0.992513,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.973389,
        "recall": 0.981445,
        "f1": 0.975977,
        "accuracy": 0.981445,
        "main_score": 0.975977,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.295647,
        "recall": 0.385742,
        "f1": 0.317392,
        "accuracy": 0.385742,
        "main_score": 0.317392,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.925618,
        "recall": 0.948242,
        "f1": 0.932943,
        "accuracy": 0.948242,
        "main_score": 0.932943,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.89738,
        "recall": 0.928711,
        "f1": 0.907454,
        "accuracy": 0.928711,
        "main_score": 0.907454,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.810547,
        "recall": 0.864258,
        "f1": 0.827604,
        "accuracy": 0.864258,
        "main_score": 0.827604,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.993164,
        "f1": 0.991211,
        "accuracy": 0.993164,
        "main_score": 0.991211,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005661,
        "recall": 0.019531,
        "f1": 0.007311,
        "accuracy": 0.019531,
        "main_score": 0.007311,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.98877,
        "recall": 0.992188,
        "f1": 0.989909,
        "accuracy": 0.992188,
        "main_score": 0.989909,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.975586,
        "recall": 0.983398,
        "f1": 0.97819,
        "accuracy": 0.983398,
        "main_score": 0.97819,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.945638,
        "recall": 0.962891,
        "f1": 0.951335,
        "accuracy": 0.962891,
        "main_score": 0.951335,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002556,
        "recall": 0.015625,
        "f1": 0.003685,
        "accuracy": 0.015625,
        "main_score": 0.003685,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.783919,
        "recall": 0.842773,
        "f1": 0.802037,
        "accuracy": 0.842773,
        "main_score": 0.802037,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.98877,
        "recall": 0.992188,
        "f1": 0.989909,
        "accuracy": 0.992188,
        "main_score": 0.989909,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.981445,
        "recall": 0.987305,
        "f1": 0.983398,
        "accuracy": 0.987305,
        "main_score": 0.983398,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.327901,
        "recall": 0.415039,
        "f1": 0.348558,
        "accuracy": 0.415039,
        "main_score": 0.348558,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.944499,
        "recall": 0.961914,
        "f1": 0.950195,
        "accuracy": 0.961914,
        "main_score": 0.950195,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.993164,
        "recall": 0.995117,
        "f1": 0.993815,
        "accuracy": 0.995117,
        "main_score": 0.993815,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.914665,
        "recall": 0.94043,
        "f1": 0.922917,
        "accuracy": 0.94043,
        "main_score": 0.922917,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.802653,
        "recall": 0.859375,
        "f1": 0.820494,
        "accuracy": 0.859375,
        "main_score": 0.820494,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.993652,
        "recall": 0.995117,
        "f1": 0.994141,
        "accuracy": 0.995117,
        "main_score": 0.994141,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.005518,
        "recall": 0.019531,
        "f1": 0.007037,
        "accuracy": 0.019531,
        "main_score": 0.007037,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.977214,
        "recall": 0.984375,
        "f1": 0.979492,
        "accuracy": 0.984375,
        "main_score": 0.979492,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.958984,
        "recall": 0.972656,
        "f1": 0.963542,
        "accuracy": 0.972656,
        "main_score": 0.963542,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.002186,
        "recall": 0.014648,
        "f1": 0.003585,
        "accuracy": 0.014648,
        "main_score": 0.003585,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.819906,
        "recall": 0.870117,
        "f1": 0.835482,
        "accuracy": 0.870117,
        "main_score": 0.835482,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.98877,
        "recall": 0.992188,
        "f1": 0.989909,
        "accuracy": 0.992188,
        "main_score": 0.989909,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.991536,
        "recall": 0.994141,
        "f1": 0.99235,
        "accuracy": 0.994141,
        "main_score": 0.99235,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001838,
        "recall": 0.006836,
        "f1": 0.002338,
        "accuracy": 0.006836,
        "main_score": 0.002338,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.004093,
        "recall": 0.009766,
        "f1": 0.004979,
        "accuracy": 0.009766,
        "main_score": 0.004979,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.002871,
        "recall": 0.008789,
        "f1": 0.00341,
        "accuracy": 0.008789,
        "main_score": 0.00341,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.004094,
        "recall": 0.006836,
        "f1": 0.004235,
        "accuracy": 0.006836,
        "main_score": 0.004235,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.0015,
        "recall": 0.005859,
        "f1": 0.001698,
        "accuracy": 0.005859,
        "main_score": 0.001698,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002872,
        "recall": 0.006836,
        "f1": 0.003366,
        "accuracy": 0.006836,
        "main_score": 0.003366,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.001734,
        "recall": 0.006836,
        "f1": 0.002069,
        "accuracy": 0.006836,
        "main_score": 0.002069,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.00158,
        "recall": 0.005859,
        "f1": 0.001945,
        "accuracy": 0.005859,
        "main_score": 0.001945,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001388,
        "recall": 0.003906,
        "f1": 0.001624,
        "accuracy": 0.003906,
        "main_score": 0.001624,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001591,
        "recall": 0.005859,
        "f1": 0.001868,
        "accuracy": 0.005859,
        "main_score": 0.001868,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.001066,
        "recall": 0.004883,
        "f1": 0.001148,
        "accuracy": 0.004883,
        "main_score": 0.001148,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.003175,
        "recall": 0.008789,
        "f1": 0.00379,
        "accuracy": 0.008789,
        "main_score": 0.00379,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.003714,
        "recall": 0.008789,
        "f1": 0.004497,
        "accuracy": 0.008789,
        "main_score": 0.004497,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003179,
        "recall": 0.009766,
        "f1": 0.003702,
        "accuracy": 0.009766,
        "main_score": 0.003702,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.001481,
        "recall": 0.005859,
        "f1": 0.001857,
        "accuracy": 0.005859,
        "main_score": 0.001857,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.002129,
        "recall": 0.007812,
        "f1": 0.0027,
        "accuracy": 0.007812,
        "main_score": 0.0027,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.004165,
        "recall": 0.010742,
        "f1": 0.004789,
        "accuracy": 0.010742,
        "main_score": 0.004789,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.066008,
        "recall": 0.099609,
        "f1": 0.074548,
        "accuracy": 0.099609,
        "main_score": 0.074548,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.001561,
        "recall": 0.005859,
        "f1": 0.001947,
        "accuracy": 0.005859,
        "main_score": 0.001947,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.002639,
        "recall": 0.006836,
        "f1": 0.002963,
        "accuracy": 0.006836,
        "main_score": 0.002963,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.002011,
        "recall": 0.005859,
        "f1": 0.00239,
        "accuracy": 0.005859,
        "main_score": 0.00239,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002541,
        "recall": 0.006836,
        "f1": 0.003193,
        "accuracy": 0.006836,
        "main_score": 0.003193,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.339126,
        "recall": 0.428711,
        "f1": 0.360849,
        "accuracy": 0.428711,
        "main_score": 0.360849,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.957357,
        "recall": 0.970703,
        "f1": 0.961751,
        "accuracy": 0.970703,
        "main_score": 0.961751,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.916536,
        "recall": 0.941406,
        "f1": 0.924479,
        "accuracy": 0.941406,
        "main_score": 0.924479,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.83667,
        "recall": 0.884766,
        "f1": 0.851953,
        "accuracy": 0.884766,
        "main_score": 0.851953,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.990723,
        "recall": 0.993164,
        "f1": 0.991536,
        "accuracy": 0.993164,
        "main_score": 0.991536,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004011,
        "recall": 0.019531,
        "f1": 0.005706,
        "accuracy": 0.019531,
        "main_score": 0.005706,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.978353,
        "recall": 0.985352,
        "f1": 0.980632,
        "accuracy": 0.985352,
        "main_score": 0.980632,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.973958,
        "recall": 0.982422,
        "f1": 0.976725,
        "accuracy": 0.982422,
        "main_score": 0.976725,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005598,
        "recall": 0.017578,
        "f1": 0.00651,
        "accuracy": 0.017578,
        "main_score": 0.00651,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.830729,
        "recall": 0.878906,
        "f1": 0.845638,
        "accuracy": 0.878906,
        "main_score": 0.845638,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.270094,
        "recall": 0.359375,
        "f1": 0.291373,
        "accuracy": 0.359375,
        "main_score": 0.291373,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.934001,
        "recall": 0.954102,
        "f1": 0.940495,
        "accuracy": 0.954102,
        "main_score": 0.940495,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.887939,
        "recall": 0.920898,
        "f1": 0.89834,
        "accuracy": 0.920898,
        "main_score": 0.89834,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.816081,
        "recall": 0.870117,
        "f1": 0.833138,
        "accuracy": 0.870117,
        "main_score": 0.833138,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.98877,
        "recall": 0.992188,
        "f1": 0.989909,
        "accuracy": 0.992188,
        "main_score": 0.989909,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.007279,
        "recall": 0.020508,
        "f1": 0.009115,
        "accuracy": 0.020508,
        "main_score": 0.009115,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.979492,
        "recall": 0.986328,
        "f1": 0.981771,
        "accuracy": 0.986328,
        "main_score": 0.981771,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.95459,
        "recall": 0.969727,
        "f1": 0.959635,
        "accuracy": 0.969727,
        "main_score": 0.959635,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00343,
        "recall": 0.016602,
        "f1": 0.004814,
        "accuracy": 0.016602,
        "main_score": 0.004814,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.79012,
        "recall": 0.848633,
        "f1": 0.808138,
        "accuracy": 0.848633,
        "main_score": 0.808138,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.993164,
        "f1": 0.991211,
        "accuracy": 0.993164,
        "main_score": 0.991211,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.969238,
        "recall": 0.979492,
        "f1": 0.972656,
        "accuracy": 0.979492,
        "main_score": 0.972656,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.98584,
        "recall": 0.990234,
        "f1": 0.987305,
        "accuracy": 0.990234,
        "main_score": 0.987305,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.298475,
        "recall": 0.384766,
        "f1": 0.319932,
        "accuracy": 0.384766,
        "main_score": 0.319932,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.911458,
        "recall": 0.9375,
        "f1": 0.919922,
        "accuracy": 0.9375,
        "main_score": 0.919922,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.980957,
        "recall": 0.987305,
        "f1": 0.983073,
        "accuracy": 0.987305,
        "main_score": 0.983073,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.859196,
        "recall": 0.896484,
        "f1": 0.870638,
        "accuracy": 0.896484,
        "main_score": 0.870638,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.983887,
        "recall": 0.989258,
        "f1": 0.985677,
        "accuracy": 0.989258,
        "main_score": 0.985677,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.788281,
        "recall": 0.845703,
        "f1": 0.80612,
        "accuracy": 0.845703,
        "main_score": 0.80612,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.977051,
        "recall": 0.984375,
        "f1": 0.979492,
        "accuracy": 0.984375,
        "main_score": 0.979492,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.977376,
        "recall": 0.984375,
        "f1": 0.979655,
        "accuracy": 0.984375,
        "main_score": 0.979655,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.008838,
        "recall": 0.022461,
        "f1": 0.01117,
        "accuracy": 0.022461,
        "main_score": 0.01117,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.985352,
        "recall": 0.990234,
        "f1": 0.986979,
        "accuracy": 0.990234,
        "main_score": 0.986979,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.980957,
        "recall": 0.987305,
        "f1": 0.983073,
        "accuracy": 0.987305,
        "main_score": 0.983073,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.930501,
        "recall": 0.953125,
        "f1": 0.937988,
        "accuracy": 0.953125,
        "main_score": 0.937988,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.003829,
        "recall": 0.020508,
        "f1": 0.005625,
        "accuracy": 0.020508,
        "main_score": 0.005625,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.776758,
        "recall": 0.834961,
        "f1": 0.794322,
        "accuracy": 0.834961,
        "main_score": 0.794322,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.971517,
        "recall": 0.980469,
        "f1": 0.974447,
        "accuracy": 0.980469,
        "main_score": 0.974447,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.973633,
        "recall": 0.982422,
        "f1": 0.976562,
        "accuracy": 0.982422,
        "main_score": 0.976562,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.953206,
        "recall": 0.96582,
        "f1": 0.957096,
        "accuracy": 0.96582,
        "main_score": 0.957096,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.959961,
        "recall": 0.972656,
        "f1": 0.96403,
        "accuracy": 0.972656,
        "main_score": 0.96403,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.324731,
        "recall": 0.402344,
        "f1": 0.343742,
        "accuracy": 0.402344,
        "main_score": 0.343742,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.878174,
        "recall": 0.912109,
        "f1": 0.888867,
        "accuracy": 0.912109,
        "main_score": 0.888867,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.946347,
        "recall": 0.961914,
        "f1": 0.951156,
        "accuracy": 0.961914,
        "main_score": 0.951156,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.847087,
        "recall": 0.889648,
        "f1": 0.860547,
        "accuracy": 0.889648,
        "main_score": 0.860547,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.954915,
        "recall": 0.96875,
        "f1": 0.959277,
        "accuracy": 0.96875,
        "main_score": 0.959277,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.967855,
        "recall": 0.977539,
        "f1": 0.970931,
        "accuracy": 0.977539,
        "main_score": 0.970931,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.970378,
        "recall": 0.979492,
        "f1": 0.973307,
        "accuracy": 0.979492,
        "main_score": 0.973307,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.76097,
        "recall": 0.822266,
        "f1": 0.779362,
        "accuracy": 0.822266,
        "main_score": 0.779362,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.972249,
        "recall": 0.979492,
        "f1": 0.974512,
        "accuracy": 0.979492,
        "main_score": 0.974512,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.960286,
        "recall": 0.97168,
        "f1": 0.963867,
        "accuracy": 0.97168,
        "main_score": 0.963867,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.970296,
        "recall": 0.979492,
        "f1": 0.97321,
        "accuracy": 0.979492,
        "main_score": 0.97321,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00418,
        "recall": 0.016602,
        "f1": 0.005581,
        "accuracy": 0.016602,
        "main_score": 0.005581,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.970378,
        "recall": 0.979492,
        "f1": 0.973307,
        "accuracy": 0.979492,
        "main_score": 0.973307,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.970378,
        "recall": 0.979492,
        "f1": 0.973307,
        "accuracy": 0.979492,
        "main_score": 0.973307,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.927083,
        "recall": 0.950195,
        "f1": 0.934733,
        "accuracy": 0.950195,
        "main_score": 0.934733,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.00362,
        "recall": 0.018555,
        "f1": 0.005168,
        "accuracy": 0.018555,
        "main_score": 0.005168,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.749984,
        "recall": 0.810547,
        "f1": 0.768215,
        "accuracy": 0.810547,
        "main_score": 0.768215,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.948405,
        "recall": 0.962891,
        "f1": 0.95293,
        "accuracy": 0.962891,
        "main_score": 0.95293,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.9611,
        "recall": 0.973633,
        "f1": 0.965169,
        "accuracy": 0.973633,
        "main_score": 0.965169,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.951009,
        "recall": 0.96582,
        "f1": 0.955683,
        "accuracy": 0.96582,
        "main_score": 0.955683,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.003822,
        "recall": 0.006836,
        "f1": 0.004217,
        "accuracy": 0.006836,
        "main_score": 0.004217,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.003184,
        "recall": 0.006836,
        "f1": 0.003665,
        "accuracy": 0.006836,
        "main_score": 0.003665,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001201,
        "recall": 0.005859,
        "f1": 0.001395,
        "accuracy": 0.005859,
        "main_score": 0.001395,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.004039,
        "recall": 0.005859,
        "f1": 0.004154,
        "accuracy": 0.005859,
        "main_score": 0.004154,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002996,
        "recall": 0.005859,
        "f1": 0.003055,
        "accuracy": 0.005859,
        "main_score": 0.003055,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004144,
        "recall": 0.010742,
        "f1": 0.00468,
        "accuracy": 0.010742,
        "main_score": 0.00468,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.003303,
        "recall": 0.007812,
        "f1": 0.003512,
        "accuracy": 0.007812,
        "main_score": 0.003512,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.00253,
        "recall": 0.005859,
        "f1": 0.002846,
        "accuracy": 0.005859,
        "main_score": 0.002846,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.002934,
        "recall": 0.004883,
        "f1": 0.002939,
        "accuracy": 0.004883,
        "main_score": 0.002939,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001615,
        "recall": 0.009766,
        "f1": 0.002041,
        "accuracy": 0.009766,
        "main_score": 0.002041,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.000982,
        "recall": 0.00293,
        "f1": 0.000988,
        "accuracy": 0.00293,
        "main_score": 0.000988,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.003191,
        "recall": 0.006836,
        "f1": 0.003353,
        "accuracy": 0.006836,
        "main_score": 0.003353,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.004247,
        "recall": 0.007812,
        "f1": 0.004475,
        "accuracy": 0.007812,
        "main_score": 0.004475,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.044021,
        "recall": 0.083984,
        "f1": 0.053133,
        "accuracy": 0.083984,
        "main_score": 0.053133,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.002909,
        "recall": 0.006836,
        "f1": 0.003348,
        "accuracy": 0.006836,
        "main_score": 0.003348,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.003769,
        "recall": 0.006836,
        "f1": 0.004188,
        "accuracy": 0.006836,
        "main_score": 0.004188,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.003517,
        "recall": 0.006836,
        "f1": 0.003767,
        "accuracy": 0.006836,
        "main_score": 0.003767,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.00476,
        "recall": 0.008789,
        "f1": 0.005176,
        "accuracy": 0.008789,
        "main_score": 0.005176,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001548,
        "recall": 0.003906,
        "f1": 0.001859,
        "accuracy": 0.003906,
        "main_score": 0.001859,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.003432,
        "recall": 0.007812,
        "f1": 0.003788,
        "accuracy": 0.007812,
        "main_score": 0.003788,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.002974,
        "recall": 0.006836,
        "f1": 0.003017,
        "accuracy": 0.006836,
        "main_score": 0.003017,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004152,
        "recall": 0.006836,
        "f1": 0.004625,
        "accuracy": 0.006836,
        "main_score": 0.004625,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.78979,
        "recall": 0.833984,
        "f1": 0.802234,
        "accuracy": 0.833984,
        "main_score": 0.802234,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.824154,
        "recall": 0.867188,
        "f1": 0.836965,
        "accuracy": 0.867188,
        "main_score": 0.836965,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.378479,
        "recall": 0.447266,
        "f1": 0.395757,
        "accuracy": 0.447266,
        "main_score": 0.395757,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.828971,
        "recall": 0.869141,
        "f1": 0.841197,
        "accuracy": 0.869141,
        "main_score": 0.841197,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.808573,
        "recall": 0.853516,
        "f1": 0.821043,
        "accuracy": 0.853516,
        "main_score": 0.821043,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.763356,
        "recall": 0.811523,
        "f1": 0.777357,
        "accuracy": 0.811523,
        "main_score": 0.777357,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.80539,
        "recall": 0.849609,
        "f1": 0.817984,
        "accuracy": 0.849609,
        "main_score": 0.817984,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.861995,
        "recall": 0.898438,
        "f1": 0.872707,
        "accuracy": 0.898438,
        "main_score": 0.872707,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.80353,
        "recall": 0.844727,
        "f1": 0.814962,
        "accuracy": 0.844727,
        "main_score": 0.814962,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.659131,
        "recall": 0.728516,
        "f1": 0.679381,
        "accuracy": 0.728516,
        "main_score": 0.679381,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.834049,
        "recall": 0.875,
        "f1": 0.845824,
        "accuracy": 0.875,
        "main_score": 0.845824,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.802623,
        "recall": 0.850586,
        "f1": 0.816634,
        "accuracy": 0.850586,
        "main_score": 0.816634,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.844807,
        "recall": 0.879883,
        "f1": 0.854746,
        "accuracy": 0.879883,
        "main_score": 0.854746,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005787,
        "recall": 0.016602,
        "f1": 0.007216,
        "accuracy": 0.016602,
        "main_score": 0.007216,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.837169,
        "recall": 0.87793,
        "f1": 0.849045,
        "accuracy": 0.87793,
        "main_score": 0.849045,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.800684,
        "recall": 0.850586,
        "f1": 0.815462,
        "accuracy": 0.850586,
        "main_score": 0.815462,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.791059,
        "recall": 0.831055,
        "f1": 0.802178,
        "accuracy": 0.831055,
        "main_score": 0.802178,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.76631,
        "recall": 0.822266,
        "f1": 0.782981,
        "accuracy": 0.822266,
        "main_score": 0.782981,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.0042,
        "recall": 0.020508,
        "f1": 0.006171,
        "accuracy": 0.020508,
        "main_score": 0.006171,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.778044,
        "recall": 0.825195,
        "f1": 0.791103,
        "accuracy": 0.825195,
        "main_score": 0.791103,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.802466,
        "recall": 0.851562,
        "f1": 0.817391,
        "accuracy": 0.851562,
        "main_score": 0.817391,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.823595,
        "recall": 0.866211,
        "f1": 0.836151,
        "accuracy": 0.866211,
        "main_score": 0.836151,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.976562,
        "recall": 0.984375,
        "f1": 0.979167,
        "accuracy": 0.984375,
        "main_score": 0.979167,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.990072,
        "recall": 0.993164,
        "f1": 0.991048,
        "accuracy": 0.993164,
        "main_score": 0.991048,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.275266,
        "recall": 0.363281,
        "f1": 0.297277,
        "accuracy": 0.363281,
        "main_score": 0.297277,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.91984,
        "recall": 0.944336,
        "f1": 0.927637,
        "accuracy": 0.944336,
        "main_score": 0.927637,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.880078,
        "recall": 0.914062,
        "f1": 0.890755,
        "accuracy": 0.914062,
        "main_score": 0.890755,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.987305,
        "recall": 0.991211,
        "f1": 0.988607,
        "accuracy": 0.991211,
        "main_score": 0.988607,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.776204,
        "recall": 0.837891,
        "f1": 0.795006,
        "accuracy": 0.837891,
        "main_score": 0.795006,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.993164,
        "f1": 0.991211,
        "accuracy": 0.993164,
        "main_score": 0.991211,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.988281,
        "recall": 0.992188,
        "f1": 0.989583,
        "accuracy": 0.992188,
        "main_score": 0.989583,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.008183,
        "recall": 0.018555,
        "f1": 0.009398,
        "accuracy": 0.018555,
        "main_score": 0.009398,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.989746,
        "recall": 0.993164,
        "f1": 0.990885,
        "accuracy": 0.993164,
        "main_score": 0.990885,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.972982,
        "recall": 0.981445,
        "f1": 0.975749,
        "accuracy": 0.981445,
        "main_score": 0.975749,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.947754,
        "recall": 0.963867,
        "f1": 0.952962,
        "accuracy": 0.963867,
        "main_score": 0.952962,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00362,
        "recall": 0.018555,
        "f1": 0.005248,
        "accuracy": 0.018555,
        "main_score": 0.005248,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.770671,
        "recall": 0.830078,
        "f1": 0.788546,
        "accuracy": 0.830078,
        "main_score": 0.788546,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.993652,
        "recall": 0.995117,
        "f1": 0.994141,
        "accuracy": 0.995117,
        "main_score": 0.994141,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.975911,
        "recall": 0.983398,
        "f1": 0.978353,
        "accuracy": 0.983398,
        "main_score": 0.978353,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.297071,
        "recall": 0.394531,
        "f1": 0.321245,
        "accuracy": 0.394531,
        "main_score": 0.321245,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.922363,
        "recall": 0.946289,
        "f1": 0.930176,
        "accuracy": 0.946289,
        "main_score": 0.930176,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.898763,
        "recall": 0.929688,
        "f1": 0.908691,
        "accuracy": 0.929688,
        "main_score": 0.908691,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.812988,
        "recall": 0.866211,
        "f1": 0.82985,
        "accuracy": 0.866211,
        "main_score": 0.82985,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.987793,
        "recall": 0.991211,
        "f1": 0.988932,
        "accuracy": 0.991211,
        "main_score": 0.988932,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.007836,
        "recall": 0.019531,
        "f1": 0.00935,
        "accuracy": 0.019531,
        "main_score": 0.00935,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.970703,
        "recall": 0.980469,
        "f1": 0.973958,
        "accuracy": 0.980469,
        "main_score": 0.973958,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.949707,
        "recall": 0.96582,
        "f1": 0.954915,
        "accuracy": 0.96582,
        "main_score": 0.954915,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.003422,
        "recall": 0.017578,
        "f1": 0.004951,
        "accuracy": 0.017578,
        "main_score": 0.004951,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.781608,
        "recall": 0.842773,
        "f1": 0.800195,
        "accuracy": 0.842773,
        "main_score": 0.800195,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.990234,
        "recall": 0.992188,
        "f1": 0.990885,
        "accuracy": 0.992188,
        "main_score": 0.990885,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.991211,
        "recall": 0.994141,
        "f1": 0.992188,
        "accuracy": 0.994141,
        "main_score": 0.992188,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.2949,
        "recall": 0.386719,
        "f1": 0.317314,
        "accuracy": 0.386719,
        "main_score": 0.317314,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.945475,
        "recall": 0.962891,
        "f1": 0.951172,
        "accuracy": 0.962891,
        "main_score": 0.951172,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.903076,
        "recall": 0.931641,
        "f1": 0.912012,
        "accuracy": 0.931641,
        "main_score": 0.912012,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.99707,
        "recall": 0.998047,
        "f1": 0.997396,
        "accuracy": 0.998047,
        "main_score": 0.997396,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.88724,
        "recall": 0.920898,
        "f1": 0.898112,
        "accuracy": 0.920898,
        "main_score": 0.898112,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.992676,
        "recall": 0.995117,
        "f1": 0.99349,
        "accuracy": 0.995117,
        "main_score": 0.99349,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.998535,
        "recall": 0.999023,
        "f1": 0.998698,
        "accuracy": 0.999023,
        "main_score": 0.998698,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005385,
        "recall": 0.016602,
        "f1": 0.006316,
        "accuracy": 0.016602,
        "main_score": 0.006316,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.994141,
        "recall": 0.996094,
        "f1": 0.994792,
        "accuracy": 0.996094,
        "main_score": 0.994792,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.995605,
        "recall": 0.99707,
        "f1": 0.996094,
        "accuracy": 0.99707,
        "main_score": 0.996094,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.986816,
        "recall": 0.991211,
        "f1": 0.988281,
        "accuracy": 0.991211,
        "main_score": 0.988281,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.956868,
        "recall": 0.970703,
        "f1": 0.961426,
        "accuracy": 0.970703,
        "main_score": 0.961426,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.001548,
        "recall": 0.013672,
        "f1": 0.002642,
        "accuracy": 0.013672,
        "main_score": 0.002642,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.813623,
        "recall": 0.867188,
        "f1": 0.830227,
        "accuracy": 0.867188,
        "main_score": 0.830227,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.994629,
        "recall": 0.996094,
        "f1": 0.995117,
        "accuracy": 0.996094,
        "main_score": 0.995117,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 90.07716083526611,
  "kg_co2_emissions": 0.0029833924587374535
}