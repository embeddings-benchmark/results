{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.328223,
        "f1": 0.271444,
        "f1_weighted": 0.321318,
        "scores_per_experiment": [
          {
            "accuracy": 0.321289,
            "f1": 0.257774,
            "f1_weighted": 0.322589
          },
          {
            "accuracy": 0.320312,
            "f1": 0.265953,
            "f1_weighted": 0.315194
          },
          {
            "accuracy": 0.321289,
            "f1": 0.267975,
            "f1_weighted": 0.307536
          },
          {
            "accuracy": 0.314453,
            "f1": 0.255457,
            "f1_weighted": 0.30391
          },
          {
            "accuracy": 0.328125,
            "f1": 0.263402,
            "f1_weighted": 0.31714
          },
          {
            "accuracy": 0.330566,
            "f1": 0.271632,
            "f1_weighted": 0.326391
          },
          {
            "accuracy": 0.350586,
            "f1": 0.280493,
            "f1_weighted": 0.345574
          },
          {
            "accuracy": 0.31543,
            "f1": 0.281576,
            "f1_weighted": 0.305864
          },
          {
            "accuracy": 0.336426,
            "f1": 0.284527,
            "f1_weighted": 0.332963
          },
          {
            "accuracy": 0.34375,
            "f1": 0.285655,
            "f1_weighted": 0.336017
          }
        ],
        "main_score": 0.328223,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.323975,
        "f1": 0.284371,
        "f1_weighted": 0.318655,
        "scores_per_experiment": [
          {
            "accuracy": 0.325684,
            "f1": 0.285367,
            "f1_weighted": 0.328651
          },
          {
            "accuracy": 0.335449,
            "f1": 0.292523,
            "f1_weighted": 0.331451
          },
          {
            "accuracy": 0.31543,
            "f1": 0.276716,
            "f1_weighted": 0.306133
          },
          {
            "accuracy": 0.315918,
            "f1": 0.270983,
            "f1_weighted": 0.30377
          },
          {
            "accuracy": 0.30957,
            "f1": 0.273848,
            "f1_weighted": 0.301183
          },
          {
            "accuracy": 0.317871,
            "f1": 0.286782,
            "f1_weighted": 0.311688
          },
          {
            "accuracy": 0.343262,
            "f1": 0.293287,
            "f1_weighted": 0.348904
          },
          {
            "accuracy": 0.326172,
            "f1": 0.291791,
            "f1_weighted": 0.321362
          },
          {
            "accuracy": 0.324219,
            "f1": 0.285107,
            "f1_weighted": 0.321911
          },
          {
            "accuracy": 0.326172,
            "f1": 0.287307,
            "f1_weighted": 0.311494
          }
        ],
        "main_score": 0.323975,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 362.1887216567993,
  "kg_co2_emissions": 0.01704044829763243
}