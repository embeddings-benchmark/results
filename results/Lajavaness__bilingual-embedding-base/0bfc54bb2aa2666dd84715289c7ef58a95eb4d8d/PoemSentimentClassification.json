{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "task_name": "PoemSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.498095,
        "f1": 0.382429,
        "f1_weighted": 0.545126,
        "scores_per_experiment": [
          {
            "accuracy": 0.504762,
            "f1": 0.386237,
            "f1_weighted": 0.559386
          },
          {
            "accuracy": 0.533333,
            "f1": 0.4169,
            "f1_weighted": 0.568088
          },
          {
            "accuracy": 0.466667,
            "f1": 0.377266,
            "f1_weighted": 0.518027
          },
          {
            "accuracy": 0.514286,
            "f1": 0.391451,
            "f1_weighted": 0.568509
          },
          {
            "accuracy": 0.542857,
            "f1": 0.381812,
            "f1_weighted": 0.591386
          },
          {
            "accuracy": 0.466667,
            "f1": 0.360159,
            "f1_weighted": 0.506492
          },
          {
            "accuracy": 0.52381,
            "f1": 0.405833,
            "f1_weighted": 0.587301
          },
          {
            "accuracy": 0.438095,
            "f1": 0.320981,
            "f1_weighted": 0.494005
          },
          {
            "accuracy": 0.419048,
            "f1": 0.336185,
            "f1_weighted": 0.468103
          },
          {
            "accuracy": 0.571429,
            "f1": 0.447464,
            "f1_weighted": 0.589963
          }
        ],
        "main_score": 0.498095,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.507692,
        "f1": 0.396346,
        "f1_weighted": 0.550403,
        "scores_per_experiment": [
          {
            "accuracy": 0.519231,
            "f1": 0.409124,
            "f1_weighted": 0.550062
          },
          {
            "accuracy": 0.576923,
            "f1": 0.446404,
            "f1_weighted": 0.601485
          },
          {
            "accuracy": 0.557692,
            "f1": 0.458378,
            "f1_weighted": 0.601232
          },
          {
            "accuracy": 0.586538,
            "f1": 0.450938,
            "f1_weighted": 0.633945
          },
          {
            "accuracy": 0.557692,
            "f1": 0.423482,
            "f1_weighted": 0.613012
          },
          {
            "accuracy": 0.432692,
            "f1": 0.355678,
            "f1_weighted": 0.473183
          },
          {
            "accuracy": 0.480769,
            "f1": 0.386311,
            "f1_weighted": 0.529304
          },
          {
            "accuracy": 0.461538,
            "f1": 0.328561,
            "f1_weighted": 0.517481
          },
          {
            "accuracy": 0.403846,
            "f1": 0.314698,
            "f1_weighted": 0.43923
          },
          {
            "accuracy": 0.5,
            "f1": 0.389891,
            "f1_weighted": 0.545097
          }
        ],
        "main_score": 0.507692,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 46.88751244544983,
  "kg_co2_emissions": 0.0013176661237663302
}