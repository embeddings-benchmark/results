{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 494.25193905830383,
  "kg_co2_emissions": 0.044510744116622314,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.8046875,
        "f1": 0.7676945233585859,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.7676945233585859,
        "precision": 0.7541445777529763,
        "recall": 0.8046875
      },
      {
        "accuracy": 0.490234375,
        "f1": 0.4409426727786103,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.4409426727786103,
        "precision": 0.4254324776785714,
        "recall": 0.490234375
      },
      {
        "accuracy": 0.6171875,
        "f1": 0.5766814809539419,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.5766814809539419,
        "precision": 0.5621918402777777,
        "recall": 0.6171875
      },
      {
        "accuracy": 0.4951171875,
        "f1": 0.4385846926139495,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.4385846926139495,
        "precision": 0.42277179131957787,
        "recall": 0.4951171875
      },
      {
        "accuracy": 0.5810546875,
        "f1": 0.54732796771371,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.54732796771371,
        "precision": 0.535516042440056,
        "recall": 0.5810546875
      },
      {
        "accuracy": 0.6005859375,
        "f1": 0.5493635650373931,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.5493635650373931,
        "precision": 0.5300104345715558,
        "recall": 0.6005859375
      },
      {
        "accuracy": 0.6962890625,
        "f1": 0.6532227375489095,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.6532227375489095,
        "precision": 0.63806219659247,
        "recall": 0.6962890625
      },
      {
        "accuracy": 0.5341796875,
        "f1": 0.4758547604739011,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.4758547604739011,
        "precision": 0.45478838286024637,
        "recall": 0.5341796875
      },
      {
        "accuracy": 0.4248046875,
        "f1": 0.3730636090255231,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.3730636090255231,
        "precision": 0.35698341164597813,
        "recall": 0.4248046875
      },
      {
        "accuracy": 0.6845703125,
        "f1": 0.6375530908978174,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.6375530908978174,
        "precision": 0.6204991197868036,
        "recall": 0.6845703125
      },
      {
        "accuracy": 0.46875,
        "f1": 0.4139855424523393,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.4139855424523393,
        "precision": 0.3959625014685151,
        "recall": 0.46875
      },
      {
        "accuracy": 0.6474609375,
        "f1": 0.609695299446533,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.609695299446533,
        "precision": 0.5965882072571526,
        "recall": 0.6474609375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011193849468668141,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.011193849468668141,
        "precision": 0.00960556167465347,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.712890625,
        "f1": 0.6710087980595792,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.6710087980595792,
        "precision": 0.6564153303179825,
        "recall": 0.712890625
      },
      {
        "accuracy": 0.3779296875,
        "f1": 0.312219041607526,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.312219041607526,
        "precision": 0.2904112800719246,
        "recall": 0.3779296875
      },
      {
        "accuracy": 0.46484375,
        "f1": 0.4074621190815291,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.4074621190815291,
        "precision": 0.3874361288667929,
        "recall": 0.46484375
      },
      {
        "accuracy": 0.6435546875,
        "f1": 0.5972522345276252,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.5972522345276252,
        "precision": 0.5799239417989418,
        "recall": 0.6435546875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.009330762541734327,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.009330762541734327,
        "precision": 0.007768823498111914,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.5634765625,
        "f1": 0.514200458829365,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.514200458829365,
        "precision": 0.49739676779949366,
        "recall": 0.5634765625
      },
      {
        "accuracy": 0.3203125,
        "f1": 0.27383601270577007,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.27383601270577007,
        "precision": 0.2584502663518059,
        "recall": 0.3203125
      },
      {
        "accuracy": 0.486328125,
        "f1": 0.4334595471802503,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.4334595471802503,
        "precision": 0.41471417979033165,
        "recall": 0.486328125
      },
      {
        "accuracy": 0.529296875,
        "f1": 0.485816285338057,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.485816285338057,
        "precision": 0.4725035728203554,
        "recall": 0.529296875
      },
      {
        "accuracy": 0.8408203125,
        "f1": 0.8051958133012821,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.8051958133012821,
        "precision": 0.7903645833333334,
        "recall": 0.8408203125
      },
      {
        "accuracy": 0.5478515625,
        "f1": 0.5019000341021825,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.5019000341021825,
        "precision": 0.48549149418290044,
        "recall": 0.5478515625
      },
      {
        "accuracy": 0.75390625,
        "f1": 0.7088646298363095,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.7088646298363095,
        "precision": 0.6913899739583333,
        "recall": 0.75390625
      },
      {
        "accuracy": 0.6650390625,
        "f1": 0.6102587173199405,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.6102587173199405,
        "precision": 0.5923299505941106,
        "recall": 0.6650390625
      },
      {
        "accuracy": 0.69921875,
        "f1": 0.6613661024305555,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.6613661024305555,
        "precision": 0.6459104507688491,
        "recall": 0.69921875
      },
      {
        "accuracy": 0.6513671875,
        "f1": 0.5995132688492064,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.5995132688492064,
        "precision": 0.5799576400162338,
        "recall": 0.6513671875
      },
      {
        "accuracy": 0.8359375,
        "f1": 0.8078576352415967,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.8078576352415967,
        "precision": 0.7971576397235577,
        "recall": 0.8359375
      },
      {
        "accuracy": 0.580078125,
        "f1": 0.521295650421627,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.521295650421627,
        "precision": 0.49914318266369045,
        "recall": 0.580078125
      },
      {
        "accuracy": 0.4892578125,
        "f1": 0.4474986406822344,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.4474986406822344,
        "precision": 0.4327238272794913,
        "recall": 0.4892578125
      },
      {
        "accuracy": 0.7900390625,
        "f1": 0.7599803137400793,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.7599803137400793,
        "precision": 0.7484560768008033,
        "recall": 0.7900390625
      },
      {
        "accuracy": 0.548828125,
        "f1": 0.4930195662957212,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.4930195662957212,
        "precision": 0.47292269091585504,
        "recall": 0.548828125
      },
      {
        "accuracy": 0.74609375,
        "f1": 0.7098005022321429,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.7098005022321429,
        "precision": 0.6963891143578643,
        "recall": 0.74609375
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.00759812922784342,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.00759812922784342,
        "precision": 0.005898912150694991,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.814453125,
        "f1": 0.7800533234126984,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.7800533234126984,
        "precision": 0.7667019314236111,
        "recall": 0.814453125
      },
      {
        "accuracy": 0.390625,
        "f1": 0.3231893395005031,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.3231893395005031,
        "precision": 0.30112796545902015,
        "recall": 0.390625
      },
      {
        "accuracy": 0.55859375,
        "f1": 0.5009496181285014,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.5009496181285014,
        "precision": 0.4804476298983135,
        "recall": 0.55859375
      },
      {
        "accuracy": 0.7490234375,
        "f1": 0.7102183948863636,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.7102183948863636,
        "precision": 0.6946714743589744,
        "recall": 0.7490234375
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.00797882228977442,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.00797882228977442,
        "precision": 0.006223817928070333,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.6904296875,
        "f1": 0.6490443638392857,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.6490443638392857,
        "precision": 0.6334891183035715,
        "recall": 0.6904296875
      },
      {
        "accuracy": 0.408203125,
        "f1": 0.35367445145277177,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.35367445145277177,
        "precision": 0.33441527276976496,
        "recall": 0.408203125
      },
      {
        "accuracy": 0.5712890625,
        "f1": 0.5149332039870872,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.5149332039870872,
        "precision": 0.4945089673239087,
        "recall": 0.5712890625
      },
      {
        "accuracy": 0.6669921875,
        "f1": 0.6193543110535298,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.6193543110535298,
        "precision": 0.6031859393804295,
        "recall": 0.6669921875
      },
      {
        "accuracy": 0.498046875,
        "f1": 0.45591028573206305,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.45591028573206305,
        "precision": 0.4428769703498786,
        "recall": 0.498046875
      },
      {
        "accuracy": 0.5185546875,
        "f1": 0.4828423431936033,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.4828423431936033,
        "precision": 0.47091090292110993,
        "recall": 0.5185546875
      },
      {
        "accuracy": 0.5615234375,
        "f1": 0.5307050913496226,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.5307050913496226,
        "precision": 0.5212233060291425,
        "recall": 0.5615234375
      },
      {
        "accuracy": 0.4111328125,
        "f1": 0.37670915743774974,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.37670915743774974,
        "precision": 0.36614968448409535,
        "recall": 0.4111328125
      },
      {
        "accuracy": 0.544921875,
        "f1": 0.51822775748557,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.51822775748557,
        "precision": 0.5090928277451715,
        "recall": 0.544921875
      },
      {
        "accuracy": 0.5146484375,
        "f1": 0.4636887466757354,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.4636887466757354,
        "precision": 0.446951330686446,
        "recall": 0.5146484375
      },
      {
        "accuracy": 0.529296875,
        "f1": 0.4932421101180564,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.4932421101180564,
        "precision": 0.48190010267360756,
        "recall": 0.529296875
      },
      {
        "accuracy": 0.4306640625,
        "f1": 0.36834471792799517,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.36834471792799517,
        "precision": 0.34730398995535716,
        "recall": 0.4306640625
      },
      {
        "accuracy": 0.4482421875,
        "f1": 0.4159697778350122,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.4159697778350122,
        "precision": 0.4065863488579293,
        "recall": 0.4482421875
      },
      {
        "accuracy": 0.5107421875,
        "f1": 0.47626971859406586,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.47626971859406586,
        "precision": 0.4651186581701259,
        "recall": 0.5107421875
      },
      {
        "accuracy": 0.4873046875,
        "f1": 0.44182899619911337,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.44182899619911337,
        "precision": 0.4265980887304417,
        "recall": 0.4873046875
      },
      {
        "accuracy": 0.51171875,
        "f1": 0.4740629793766282,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.4740629793766282,
        "precision": 0.4620154923356574,
        "recall": 0.51171875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009917773454078602,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009917773454078602,
        "precision": 0.00887975944276588,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.546875,
        "f1": 0.5091060646339224,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.5091060646339224,
        "precision": 0.49642628817433504,
        "recall": 0.546875
      },
      {
        "accuracy": 0.244140625,
        "f1": 0.19652017632974664,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.19652017632974664,
        "precision": 0.18233401255862192,
        "recall": 0.244140625
      },
      {
        "accuracy": 0.4833984375,
        "f1": 0.439701350443538,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.439701350443538,
        "precision": 0.42546673241612354,
        "recall": 0.4833984375
      },
      {
        "accuracy": 0.5126953125,
        "f1": 0.47584664489577644,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.47584664489577644,
        "precision": 0.462989200671588,
        "recall": 0.5126953125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.006878785381277418,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006878785381277418,
        "precision": 0.005563698996316184,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.5771484375,
        "f1": 0.5471261377511377,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5471261377511377,
        "precision": 0.5381983995691516,
        "recall": 0.5771484375
      },
      {
        "accuracy": 0.4345703125,
        "f1": 0.39035141945129825,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.39035141945129825,
        "precision": 0.37689642714056776,
        "recall": 0.4345703125
      },
      {
        "accuracy": 0.5078125,
        "f1": 0.46812928724806807,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.46812928724806807,
        "precision": 0.45473463525349833,
        "recall": 0.5078125
      },
      {
        "accuracy": 0.478515625,
        "f1": 0.4417230436600825,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.4417230436600825,
        "precision": 0.43157344859156654,
        "recall": 0.478515625
      },
      {
        "accuracy": 0.70703125,
        "f1": 0.6688681950644841,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6688681950644841,
        "precision": 0.6550744888630319,
        "recall": 0.70703125
      },
      {
        "accuracy": 0.763671875,
        "f1": 0.7275239490327381,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7275239490327381,
        "precision": 0.7142383170215202,
        "recall": 0.763671875
      },
      {
        "accuracy": 0.6044921875,
        "f1": 0.5700943939957612,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5700943939957612,
        "precision": 0.5591668991815477,
        "recall": 0.6044921875
      },
      {
        "accuracy": 0.751953125,
        "f1": 0.7127582772872144,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7127582772872144,
        "precision": 0.699174994926948,
        "recall": 0.751953125
      },
      {
        "accuracy": 0.7861328125,
        "f1": 0.75654052436279,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.75654052436279,
        "precision": 0.7450532459077381,
        "recall": 0.7861328125
      },
      {
        "accuracy": 0.7412109375,
        "f1": 0.6945715525793651,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6945715525793651,
        "precision": 0.6761711351799242,
        "recall": 0.7412109375
      },
      {
        "accuracy": 0.919921875,
        "f1": 0.9029699900793651,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9029699900793651,
        "precision": 0.8963134765625,
        "recall": 0.919921875
      },
      {
        "accuracy": 0.5654296875,
        "f1": 0.5024872046356421,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5024872046356421,
        "precision": 0.4783633277529762,
        "recall": 0.5654296875
      },
      {
        "accuracy": 0.6640625,
        "f1": 0.6208651103670635,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6208651103670635,
        "precision": 0.6056183345734127,
        "recall": 0.6640625
      },
      {
        "accuracy": 0.8984375,
        "f1": 0.8779227120535714,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8779227120535714,
        "precision": 0.8705550905257937,
        "recall": 0.8984375
      },
      {
        "accuracy": 0.607421875,
        "f1": 0.5570107464150433,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5570107464150433,
        "precision": 0.5380209037923882,
        "recall": 0.607421875
      },
      {
        "accuracy": 0.7978515625,
        "f1": 0.7687244233630952,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7687244233630952,
        "precision": 0.7576861669146826,
        "recall": 0.7978515625
      },
      {
        "accuracy": 0.0205078125,
        "f1": 0.010574027954785804,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.010574027954785804,
        "precision": 0.00901692038924769,
        "recall": 0.0205078125
      },
      {
        "accuracy": 0.8779296875,
        "f1": 0.8520887586805556,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8520887586805556,
        "precision": 0.8414725167410715,
        "recall": 0.8779296875
      },
      {
        "accuracy": 0.2861328125,
        "f1": 0.22537662532779718,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.22537662532779718,
        "precision": 0.20620734788215256,
        "recall": 0.2861328125
      },
      {
        "accuracy": 0.7158203125,
        "f1": 0.66945447130994,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.66945447130994,
        "precision": 0.652170984397547,
        "recall": 0.7158203125
      },
      {
        "accuracy": 0.7861328125,
        "f1": 0.7502380033543867,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.7502380033543867,
        "precision": 0.7363438197544643,
        "recall": 0.7861328125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.004277367974596404,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004277367974596404,
        "precision": 0.0033926524860680794,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.8388671875,
        "f1": 0.8107445126488095,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8107445126488095,
        "precision": 0.7996023995535715,
        "recall": 0.8388671875
      },
      {
        "accuracy": 0.46484375,
        "f1": 0.42746001828033076,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.42746001828033076,
        "precision": 0.41402206029647437,
        "recall": 0.46484375
      },
      {
        "accuracy": 0.6259765625,
        "f1": 0.5799471416170634,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5799471416170634,
        "precision": 0.5627054586038961,
        "recall": 0.6259765625
      },
      {
        "accuracy": 0.78515625,
        "f1": 0.753102791847909,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.753102791847909,
        "precision": 0.7426671129320698,
        "recall": 0.78515625
      },
      {
        "accuracy": 0.615234375,
        "f1": 0.55260312509803,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.55260312509803,
        "precision": 0.529245933103355,
        "recall": 0.615234375
      },
      {
        "accuracy": 0.7548828125,
        "f1": 0.7022608196924602,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.7022608196924602,
        "precision": 0.6808876643105158,
        "recall": 0.7548828125
      },
      {
        "accuracy": 0.5205078125,
        "f1": 0.45628954920947107,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.45628954920947107,
        "precision": 0.43408823164682536,
        "recall": 0.5205078125
      },
      {
        "accuracy": 0.86328125,
        "f1": 0.8300641741071428,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.8300641741071428,
        "precision": 0.8157389322916666,
        "recall": 0.86328125
      },
      {
        "accuracy": 0.6982421875,
        "f1": 0.6417352585565477,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.6417352585565477,
        "precision": 0.6203666938530221,
        "recall": 0.6982421875
      },
      {
        "accuracy": 0.51171875,
        "f1": 0.45381216582456096,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.45381216582456096,
        "precision": 0.4349312918526786,
        "recall": 0.51171875
      },
      {
        "accuracy": 0.962890625,
        "f1": 0.9519856770833334,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9519856770833334,
        "precision": 0.9469401041666666,
        "recall": 0.962890625
      },
      {
        "accuracy": 0.33203125,
        "f1": 0.28169565352182535,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.28169565352182535,
        "precision": 0.2653675642933455,
        "recall": 0.33203125
      },
      {
        "accuracy": 0.669921875,
        "f1": 0.6110777839781746,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.6110777839781746,
        "precision": 0.5891803987219888,
        "recall": 0.669921875
      },
      {
        "accuracy": 0.8603515625,
        "f1": 0.8301416790674603,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.8301416790674603,
        "precision": 0.8170428936298078,
        "recall": 0.8603515625
      },
      {
        "accuracy": 0.4892578125,
        "f1": 0.4293689546130953,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.4293689546130953,
        "precision": 0.4078783304369242,
        "recall": 0.4892578125
      },
      {
        "accuracy": 0.7431640625,
        "f1": 0.6973657473169192,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.6973657473169192,
        "precision": 0.6790484716021825,
        "recall": 0.7431640625
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.006319769123793298,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.006319769123793298,
        "precision": 0.005408895829966602,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.8232421875,
        "f1": 0.77967044890873,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.77967044890873,
        "precision": 0.7609049479166666,
        "recall": 0.8232421875
      },
      {
        "accuracy": 0.14453125,
        "f1": 0.10448681556049948,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.10448681556049948,
        "precision": 0.09380239037221459,
        "recall": 0.14453125
      },
      {
        "accuracy": 0.5625,
        "f1": 0.5020821065168491,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.5020821065168491,
        "precision": 0.48159425616701,
        "recall": 0.5625
      },
      {
        "accuracy": 0.7978515625,
        "f1": 0.7529668898809523,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.7529668898809523,
        "precision": 0.7339463975694445,
        "recall": 0.7978515625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0019684215833769402,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0019684215833769402,
        "precision": 0.0015255397412950503,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.7841796875,
        "f1": 0.7423162286931817,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.7423162286931817,
        "precision": 0.725684016504329,
        "recall": 0.7841796875
      },
      {
        "accuracy": 0.3525390625,
        "f1": 0.3029432874269991,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.3029432874269991,
        "precision": 0.2861639933417277,
        "recall": 0.3525390625
      },
      {
        "accuracy": 0.4599609375,
        "f1": 0.40538786278880784,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.40538786278880784,
        "precision": 0.3865794348338294,
        "recall": 0.4599609375
      },
      {
        "accuracy": 0.923828125,
        "f1": 0.9042317708333334,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9042317708333334,
        "precision": 0.8958658854166666,
        "recall": 0.923828125
      },
      {
        "accuracy": 0.6318359375,
        "f1": 0.5868989277096031,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5868989277096031,
        "precision": 0.571418220766129,
        "recall": 0.6318359375
      },
      {
        "accuracy": 0.693359375,
        "f1": 0.6584856305803571,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6584856305803571,
        "precision": 0.6464312597125097,
        "recall": 0.693359375
      },
      {
        "accuracy": 0.5927734375,
        "f1": 0.5503828961836774,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5503828961836774,
        "precision": 0.5349929592862364,
        "recall": 0.5927734375
      },
      {
        "accuracy": 0.76953125,
        "f1": 0.7366094680059523,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7366094680059523,
        "precision": 0.7240490141369048,
        "recall": 0.76953125
      },
      {
        "accuracy": 0.595703125,
        "f1": 0.5486379735949896,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5486379735949896,
        "precision": 0.533153985000973,
        "recall": 0.595703125
      },
      {
        "accuracy": 0.685546875,
        "f1": 0.634330822172619,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.634330822172619,
        "precision": 0.6142616877480158,
        "recall": 0.685546875
      },
      {
        "accuracy": 0.765625,
        "f1": 0.7348006584674384,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7348006584674384,
        "precision": 0.7239190171807359,
        "recall": 0.765625
      },
      {
        "accuracy": 0.56640625,
        "f1": 0.5047728259154041,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5047728259154041,
        "precision": 0.4810605003720238,
        "recall": 0.56640625
      },
      {
        "accuracy": 0.578125,
        "f1": 0.5391409524491864,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5391409524491864,
        "precision": 0.5249225654987374,
        "recall": 0.578125
      },
      {
        "accuracy": 0.7529296875,
        "f1": 0.7242575024801587,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7242575024801587,
        "precision": 0.7138846017263986,
        "recall": 0.7529296875
      },
      {
        "accuracy": 0.5830078125,
        "f1": 0.5402031505974944,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5402031505974944,
        "precision": 0.5238794720362103,
        "recall": 0.5830078125
      },
      {
        "accuracy": 0.83203125,
        "f1": 0.8023189484126985,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8023189484126985,
        "precision": 0.7912082248263889,
        "recall": 0.83203125
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.01443508928491432,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.01443508928491432,
        "precision": 0.01234368882551627,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.7822265625,
        "f1": 0.7489404584131147,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7489404584131147,
        "precision": 0.7369873046875,
        "recall": 0.7822265625
      },
      {
        "accuracy": 0.2626953125,
        "f1": 0.20933194301358363,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.20933194301358363,
        "precision": 0.1922642614738203,
        "recall": 0.2626953125
      },
      {
        "accuracy": 0.5869140625,
        "f1": 0.5370052644136398,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5370052644136398,
        "precision": 0.5198084839067632,
        "recall": 0.5869140625
      },
      {
        "accuracy": 0.7158203125,
        "f1": 0.6801942274305556,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.6801942274305556,
        "precision": 0.6661154012386205,
        "recall": 0.7158203125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007801232786883116,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007801232786883116,
        "precision": 0.006254291499072104,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.7265625,
        "f1": 0.6919619605654762,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6919619605654762,
        "precision": 0.6788171192956349,
        "recall": 0.7265625
      },
      {
        "accuracy": 0.4501953125,
        "f1": 0.4042413820759832,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.4042413820759832,
        "precision": 0.3892538949765513,
        "recall": 0.4501953125
      },
      {
        "accuracy": 0.62109375,
        "f1": 0.5747125270562771,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5747125270562771,
        "precision": 0.5572409361471862,
        "recall": 0.62109375
      },
      {
        "accuracy": 0.6318359375,
        "f1": 0.5962219923538521,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.5962219923538521,
        "precision": 0.5843926938265183,
        "recall": 0.6318359375
      },
      {
        "accuracy": 0.4970703125,
        "f1": 0.4575362977758135,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.4575362977758135,
        "precision": 0.4439847207913614,
        "recall": 0.4970703125
      },
      {
        "accuracy": 0.525390625,
        "f1": 0.48911991550635586,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.48911991550635586,
        "precision": 0.4775012276454142,
        "recall": 0.525390625
      },
      {
        "accuracy": 0.404296875,
        "f1": 0.3701647053769641,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.3701647053769641,
        "precision": 0.36107040528585715,
        "recall": 0.404296875
      },
      {
        "accuracy": 0.5419921875,
        "f1": 0.5038970198638166,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.5038970198638166,
        "precision": 0.4929402264836147,
        "recall": 0.5419921875
      },
      {
        "accuracy": 0.3583984375,
        "f1": 0.31997157970425916,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.31997157970425916,
        "precision": 0.3092370770557226,
        "recall": 0.3583984375
      },
      {
        "accuracy": 0.4931640625,
        "f1": 0.46042146540059814,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.46042146540059814,
        "precision": 0.44927411435470355,
        "recall": 0.4931640625
      },
      {
        "accuracy": 0.541015625,
        "f1": 0.5108228392626544,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.5108228392626544,
        "precision": 0.5015910657513953,
        "recall": 0.541015625
      },
      {
        "accuracy": 0.607421875,
        "f1": 0.5501365496482684,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.5501365496482684,
        "precision": 0.5278103298611111,
        "recall": 0.607421875
      },
      {
        "accuracy": 0.3916015625,
        "f1": 0.3526833124234845,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.3526833124234845,
        "precision": 0.341122845036745,
        "recall": 0.3916015625
      },
      {
        "accuracy": 0.53125,
        "f1": 0.5017557608981091,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.5017557608981091,
        "precision": 0.49301698764748614,
        "recall": 0.53125
      },
      {
        "accuracy": 0.4970703125,
        "f1": 0.45393903459821433,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.45393903459821433,
        "precision": 0.43813402213850283,
        "recall": 0.4970703125
      },
      {
        "accuracy": 0.552734375,
        "f1": 0.5169639196801261,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.5169639196801261,
        "precision": 0.5057915262459151,
        "recall": 0.552734375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.012036471934753707,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.012036471934753707,
        "precision": 0.010416805468184392,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.5546875,
        "f1": 0.514987095333775,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.514987095333775,
        "precision": 0.5033176393657268,
        "recall": 0.5546875
      },
      {
        "accuracy": 0.404296875,
        "f1": 0.3428021143353175,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.3428021143353175,
        "precision": 0.3219099124616702,
        "recall": 0.404296875
      },
      {
        "accuracy": 0.5537109375,
        "f1": 0.5024015064568108,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.5024015064568108,
        "precision": 0.4859923215483518,
        "recall": 0.5537109375
      },
      {
        "accuracy": 0.5263671875,
        "f1": 0.482178365093238,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.482178365093238,
        "precision": 0.46708860811764086,
        "recall": 0.5263671875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008530399638622434,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.008530399638622434,
        "precision": 0.007005339080582448,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.5205078125,
        "f1": 0.48693625494245213,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.48693625494245213,
        "precision": 0.4767000951363026,
        "recall": 0.5205078125
      },
      {
        "accuracy": 0.3798828125,
        "f1": 0.33577104669992996,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.33577104669992996,
        "precision": 0.32072547813514607,
        "recall": 0.3798828125
      },
      {
        "accuracy": 0.6015625,
        "f1": 0.5512959533955628,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.5512959533955628,
        "precision": 0.5323319096268315,
        "recall": 0.6015625
      },
      {
        "accuracy": 0.4482421875,
        "f1": 0.41036255486339657,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.41036255486339657,
        "precision": 0.39945312409599315,
        "recall": 0.4482421875
      },
      {
        "accuracy": 0.7841796875,
        "f1": 0.7436895461309524,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7436895461309524,
        "precision": 0.7273135230654761,
        "recall": 0.7841796875
      },
      {
        "accuracy": 0.87890625,
        "f1": 0.852930533008658,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.852930533008658,
        "precision": 0.8421223958333334,
        "recall": 0.87890625
      },
      {
        "accuracy": 0.607421875,
        "f1": 0.5698986939709596,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5698986939709596,
        "precision": 0.5558570498511906,
        "recall": 0.607421875
      },
      {
        "accuracy": 0.9345703125,
        "f1": 0.9172200520833333,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.9172200520833333,
        "precision": 0.9092610677083334,
        "recall": 0.9345703125
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8887044270833334,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8887044270833334,
        "precision": 0.8790961371527778,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.818359375,
        "f1": 0.7860319368131867,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7860319368131867,
        "precision": 0.772324469150641,
        "recall": 0.818359375
      },
      {
        "accuracy": 0.7568359375,
        "f1": 0.7140322730654762,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7140322730654762,
        "precision": 0.6968029203869048,
        "recall": 0.7568359375
      },
      {
        "accuracy": 0.5947265625,
        "f1": 0.5287535652281746,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5287535652281746,
        "precision": 0.5025185236855159,
        "recall": 0.5947265625
      },
      {
        "accuracy": 0.6708984375,
        "f1": 0.6283187624007937,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6283187624007937,
        "precision": 0.6121795169890872,
        "recall": 0.6708984375
      },
      {
        "accuracy": 0.9599609375,
        "f1": 0.9482421875,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9482421875,
        "precision": 0.94287109375,
        "recall": 0.9599609375
      },
      {
        "accuracy": 0.619140625,
        "f1": 0.5626395720547834,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5626395720547834,
        "precision": 0.5405069986979166,
        "recall": 0.619140625
      },
      {
        "accuracy": 0.8837890625,
        "f1": 0.8601329985119047,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8601329985119047,
        "precision": 0.8501402243589743,
        "recall": 0.8837890625
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.011839603346550858,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.011839603346550858,
        "precision": 0.009702335197704401,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.9501953125,
        "f1": 0.9363606770833333,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9363606770833333,
        "precision": 0.9298502604166667,
        "recall": 0.9501953125
      },
      {
        "accuracy": 0.3544921875,
        "f1": 0.28824770415705614,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.28824770415705614,
        "precision": 0.26511718397704725,
        "recall": 0.3544921875
      },
      {
        "accuracy": 0.7236328125,
        "f1": 0.671692863343254,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.671692863343254,
        "precision": 0.6524832589285714,
        "recall": 0.7236328125
      },
      {
        "accuracy": 0.8740234375,
        "f1": 0.8441879734848485,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.8441879734848485,
        "precision": 0.830859375,
        "recall": 0.8740234375
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006563534387951785,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.006563534387951785,
        "precision": 0.005591698243019104,
        "recall": 0.015625
      },
      {
        "accuracy": 0.8623046875,
        "f1": 0.8331054687499999,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.8331054687499999,
        "precision": 0.8205078125,
        "recall": 0.8623046875
      },
      {
        "accuracy": 0.4677734375,
        "f1": 0.42639431423611107,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.42639431423611107,
        "precision": 0.41163755492497267,
        "recall": 0.4677734375
      },
      {
        "accuracy": 0.6396484375,
        "f1": 0.5886881510416666,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5886881510416666,
        "precision": 0.568910375648657,
        "recall": 0.6396484375
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8801292782738095,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8801292782738095,
        "precision": 0.8691731770833333,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.3720703125,
        "f1": 0.3272469488507838,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.3272469488507838,
        "precision": 0.3140045325021196,
        "recall": 0.3720703125
      },
      {
        "accuracy": 0.369140625,
        "f1": 0.33135308243673145,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.33135308243673145,
        "precision": 0.3212559779620221,
        "recall": 0.369140625
      },
      {
        "accuracy": 0.2529296875,
        "f1": 0.2145651435153388,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.2145651435153388,
        "precision": 0.2045021298853245,
        "recall": 0.2529296875
      },
      {
        "accuracy": 0.2939453125,
        "f1": 0.2539498636101018,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.2539498636101018,
        "precision": 0.2435517584229267,
        "recall": 0.2939453125
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.14498220982271545,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.14498220982271545,
        "precision": 0.13845685812492495,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.2998046875,
        "f1": 0.26119118931799323,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.26119118931799323,
        "precision": 0.24978752310260638,
        "recall": 0.2998046875
      },
      {
        "accuracy": 0.509765625,
        "f1": 0.4499156033824003,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.4499156033824003,
        "precision": 0.42956028432231147,
        "recall": 0.509765625
      },
      {
        "accuracy": 0.296875,
        "f1": 0.2635602478590954,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.2635602478590954,
        "precision": 0.2527305085801558,
        "recall": 0.296875
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.13966845849170068,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.13966845849170068,
        "precision": 0.13005751748793742,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.3203125,
        "f1": 0.28241604315823066,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.28241604315823066,
        "precision": 0.2718795731108017,
        "recall": 0.3203125
      },
      {
        "accuracy": 0.412109375,
        "f1": 0.35024407775384336,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.35024407775384336,
        "precision": 0.32972276475694445,
        "recall": 0.412109375
      },
      {
        "accuracy": 0.3759765625,
        "f1": 0.334606170985811,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.334606170985811,
        "precision": 0.3236411321311866,
        "recall": 0.3759765625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.015813421775592827,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.015813421775592827,
        "precision": 0.013623495607813797,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.3544921875,
        "f1": 0.3131872487905004,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.3131872487905004,
        "precision": 0.3025427482682559,
        "recall": 0.3544921875
      },
      {
        "accuracy": 0.3330078125,
        "f1": 0.2686205667162698,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.2686205667162698,
        "precision": 0.24788376228805917,
        "recall": 0.3330078125
      },
      {
        "accuracy": 0.302734375,
        "f1": 0.25178277277197075,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.25178277277197075,
        "precision": 0.23710274472854898,
        "recall": 0.302734375
      },
      {
        "accuracy": 0.42578125,
        "f1": 0.3771679919124019,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.3771679919124019,
        "precision": 0.3605525104308832,
        "recall": 0.42578125
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.00752357620100126,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.00752357620100126,
        "precision": 0.005927501860119047,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.25390625,
        "f1": 0.2174355234609141,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.2174355234609141,
        "precision": 0.20724396946118023,
        "recall": 0.25390625
      },
      {
        "accuracy": 0.3251953125,
        "f1": 0.26606430849851903,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.26606430849851903,
        "precision": 0.24706123094051935,
        "recall": 0.3251953125
      },
      {
        "accuracy": 0.578125,
        "f1": 0.5211062917117605,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.5211062917117605,
        "precision": 0.5002108134920635,
        "recall": 0.578125
      },
      {
        "accuracy": 0.224609375,
        "f1": 0.18625814977686078,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.18625814977686078,
        "precision": 0.17752461140313142,
        "recall": 0.224609375
      },
      {
        "accuracy": 0.501953125,
        "f1": 0.4593821948079362,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.4593821948079362,
        "precision": 0.44482287666235815,
        "recall": 0.501953125
      },
      {
        "accuracy": 0.5263671875,
        "f1": 0.49137510845274524,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.49137510845274524,
        "precision": 0.47969438534043735,
        "recall": 0.5263671875
      },
      {
        "accuracy": 0.4931640625,
        "f1": 0.46021254678481244,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.46021254678481244,
        "precision": 0.44874336275703464,
        "recall": 0.4931640625
      },
      {
        "accuracy": 0.646484375,
        "f1": 0.6133271896296494,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.6133271896296494,
        "precision": 0.6017692234430416,
        "recall": 0.646484375
      },
      {
        "accuracy": 0.6025390625,
        "f1": 0.5580129419191919,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.5580129419191919,
        "precision": 0.542797735142234,
        "recall": 0.6025390625
      },
      {
        "accuracy": 0.5732421875,
        "f1": 0.5403529575892857,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.5403529575892857,
        "precision": 0.5275883133793291,
        "recall": 0.5732421875
      },
      {
        "accuracy": 0.5595703125,
        "f1": 0.5068577093479437,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.5068577093479437,
        "precision": 0.48679547991071426,
        "recall": 0.5595703125
      },
      {
        "accuracy": 0.62890625,
        "f1": 0.5950979218971322,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.5950979218971322,
        "precision": 0.5833101953736306,
        "recall": 0.62890625
      },
      {
        "accuracy": 0.41015625,
        "f1": 0.3527894035218254,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.3527894035218254,
        "precision": 0.3321893601190476,
        "recall": 0.41015625
      },
      {
        "accuracy": 0.5908203125,
        "f1": 0.5565411238352747,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.5565411238352747,
        "precision": 0.5448384602864583,
        "recall": 0.5908203125
      },
      {
        "accuracy": 0.5087890625,
        "f1": 0.46759024024906015,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.46759024024906015,
        "precision": 0.45203295510912694,
        "recall": 0.5087890625
      },
      {
        "accuracy": 0.546875,
        "f1": 0.5081060423114288,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.5081060423114288,
        "precision": 0.49457266761954255,
        "recall": 0.546875
      },
      {
        "accuracy": 0.015625,
        "f1": 0.008380016031170922,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.008380016031170922,
        "precision": 0.0074173500254168,
        "recall": 0.015625
      },
      {
        "accuracy": 0.5830078125,
        "f1": 0.5513280537120151,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.5513280537120151,
        "precision": 0.5399477425435318,
        "recall": 0.5830078125
      },
      {
        "accuracy": 0.216796875,
        "f1": 0.16276695580894798,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.16276695580894798,
        "precision": 0.14699743344762875,
        "recall": 0.216796875
      },
      {
        "accuracy": 0.55078125,
        "f1": 0.5060103620787453,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.5060103620787453,
        "precision": 0.4903715587797619,
        "recall": 0.55078125
      },
      {
        "accuracy": 0.556640625,
        "f1": 0.5138546833936255,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.5138546833936255,
        "precision": 0.4983925227333431,
        "recall": 0.556640625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.007018230339396258,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.007018230339396258,
        "precision": 0.005984687276534234,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.6396484375,
        "f1": 0.5999762318121693,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.5999762318121693,
        "precision": 0.5868057304096891,
        "recall": 0.6396484375
      },
      {
        "accuracy": 0.40625,
        "f1": 0.36983939480148115,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.36983939480148115,
        "precision": 0.3576944986979167,
        "recall": 0.40625
      },
      {
        "accuracy": 0.5009765625,
        "f1": 0.4543480282738095,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.4543480282738095,
        "precision": 0.43709542410714286,
        "recall": 0.5009765625
      },
      {
        "accuracy": 0.7861328125,
        "f1": 0.7548905846757409,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.7548905846757409,
        "precision": 0.7435601128472222,
        "recall": 0.7861328125
      },
      {
        "accuracy": 0.775390625,
        "f1": 0.7399302700109649,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7399302700109649,
        "precision": 0.7256820436507937,
        "recall": 0.775390625
      },
      {
        "accuracy": 0.81640625,
        "f1": 0.7852236793154762,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7852236793154762,
        "precision": 0.7735816592261905,
        "recall": 0.81640625
      },
      {
        "accuracy": 0.57421875,
        "f1": 0.5293513108368348,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5293513108368348,
        "precision": 0.5131295340401786,
        "recall": 0.57421875
      },
      {
        "accuracy": 0.9013671875,
        "f1": 0.8784705528846153,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8784705528846153,
        "precision": 0.868359375,
        "recall": 0.9013671875
      },
      {
        "accuracy": 0.77734375,
        "f1": 0.7354920912306808,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7354920912306808,
        "precision": 0.719360041161799,
        "recall": 0.77734375
      },
      {
        "accuracy": 0.79296875,
        "f1": 0.760152445211039,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.760152445211039,
        "precision": 0.746875,
        "recall": 0.79296875
      },
      {
        "accuracy": 0.7294921875,
        "f1": 0.6832869008161977,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6832869008161977,
        "precision": 0.6653034455969888,
        "recall": 0.7294921875
      },
      {
        "accuracy": 0.953125,
        "f1": 0.941015625,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.941015625,
        "precision": 0.9357367621527778,
        "recall": 0.953125
      },
      {
        "accuracy": 0.583984375,
        "f1": 0.5237859353433403,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5237859353433403,
        "precision": 0.5003392359593533,
        "recall": 0.583984375
      },
      {
        "accuracy": 0.6318359375,
        "f1": 0.5827466207837302,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5827466207837302,
        "precision": 0.5650276815084586,
        "recall": 0.6318359375
      },
      {
        "accuracy": 0.578125,
        "f1": 0.5217280440913253,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5217280440913253,
        "precision": 0.5005092075892856,
        "recall": 0.578125
      },
      {
        "accuracy": 0.8427734375,
        "f1": 0.8135494171626985,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8135494171626985,
        "precision": 0.8020612444196429,
        "recall": 0.8427734375
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.009130573749069209,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009130573749069209,
        "precision": 0.007816605052933178,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.9287109375,
        "f1": 0.9099934895833333,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9099934895833333,
        "precision": 0.9017740885416666,
        "recall": 0.9287109375
      },
      {
        "accuracy": 0.3486328125,
        "f1": 0.2830132378472222,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.2830132378472222,
        "precision": 0.26215443356556634,
        "recall": 0.3486328125
      },
      {
        "accuracy": 0.6474609375,
        "f1": 0.593000597492785,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.593000597492785,
        "precision": 0.5724454121182636,
        "recall": 0.6474609375
      },
      {
        "accuracy": 0.8251953125,
        "f1": 0.7951985677083333,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.7951985677083333,
        "precision": 0.7836076412736569,
        "recall": 0.8251953125
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.009568321735060972,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.009568321735060972,
        "precision": 0.008354229753424806,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.7900390625,
        "f1": 0.7549393911210318,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.7549393911210318,
        "precision": 0.7411632719494048,
        "recall": 0.7900390625
      },
      {
        "accuracy": 0.3896484375,
        "f1": 0.3398221324002574,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.3398221324002574,
        "precision": 0.3229310050843254,
        "recall": 0.3896484375
      },
      {
        "accuracy": 0.5927734375,
        "f1": 0.5382370721726191,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5382370721726191,
        "precision": 0.5170751129482946,
        "recall": 0.5927734375
      },
      {
        "accuracy": 0.787109375,
        "f1": 0.7525217295725108,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7525217295725108,
        "precision": 0.7392543563398917,
        "recall": 0.787109375
      },
      {
        "accuracy": 0.421875,
        "f1": 0.3798071472966499,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.3798071472966499,
        "precision": 0.3662805699633106,
        "recall": 0.421875
      },
      {
        "accuracy": 0.439453125,
        "f1": 0.3978321012544802,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.3978321012544802,
        "precision": 0.38473702460434683,
        "recall": 0.439453125
      },
      {
        "accuracy": 0.4208984375,
        "f1": 0.3844035827836379,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.3844035827836379,
        "precision": 0.37467611234765325,
        "recall": 0.4208984375
      },
      {
        "accuracy": 0.470703125,
        "f1": 0.43920928412224003,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.43920928412224003,
        "precision": 0.4297327699427309,
        "recall": 0.470703125
      },
      {
        "accuracy": 0.3671875,
        "f1": 0.3253803076782198,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.3253803076782198,
        "precision": 0.31443378111739184,
        "recall": 0.3671875
      },
      {
        "accuracy": 0.462890625,
        "f1": 0.4334384780686692,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.4334384780686692,
        "precision": 0.42377003817433506,
        "recall": 0.462890625
      },
      {
        "accuracy": 0.4990234375,
        "f1": 0.4430954533519295,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.4430954533519295,
        "precision": 0.4243799603174603,
        "recall": 0.4990234375
      },
      {
        "accuracy": 0.4619140625,
        "f1": 0.4326844800420169,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.4326844800420169,
        "precision": 0.4229293609702264,
        "recall": 0.4619140625
      },
      {
        "accuracy": 0.5498046875,
        "f1": 0.49838157719017095,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.49838157719017095,
        "precision": 0.47884767413576007,
        "recall": 0.5498046875
      },
      {
        "accuracy": 0.3828125,
        "f1": 0.35083772141958924,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.35083772141958924,
        "precision": 0.3410366007297016,
        "recall": 0.3828125
      },
      {
        "accuracy": 0.4306640625,
        "f1": 0.3980777700957775,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.3980777700957775,
        "precision": 0.3888216269136679,
        "recall": 0.4306640625
      },
      {
        "accuracy": 0.4326171875,
        "f1": 0.399041263640873,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.399041263640873,
        "precision": 0.3877776473426007,
        "recall": 0.4326171875
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.011939751437009748,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.011939751437009748,
        "precision": 0.010154836488699746,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.4453125,
        "f1": 0.40372037768083496,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.40372037768083496,
        "precision": 0.3907345837046141,
        "recall": 0.4453125
      },
      {
        "accuracy": 0.2294921875,
        "f1": 0.18140818057810243,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.18140818057810243,
        "precision": 0.16585332166386854,
        "recall": 0.2294921875
      },
      {
        "accuracy": 0.4609375,
        "f1": 0.4244232397918921,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.4244232397918921,
        "precision": 0.4131923038150132,
        "recall": 0.4609375
      },
      {
        "accuracy": 0.5107421875,
        "f1": 0.4621363079737103,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.4621363079737103,
        "precision": 0.44583210876803503,
        "recall": 0.5107421875
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.0050762388121648235,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.0050762388121648235,
        "precision": 0.004010932320123351,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.4599609375,
        "f1": 0.43151157505554416,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.43151157505554416,
        "precision": 0.42347796531164245,
        "recall": 0.4599609375
      },
      {
        "accuracy": 0.486328125,
        "f1": 0.44251994750041623,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.44251994750041623,
        "precision": 0.427418929811508,
        "recall": 0.486328125
      },
      {
        "accuracy": 0.5859375,
        "f1": 0.5437415018090569,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.5437415018090569,
        "precision": 0.5283239939856151,
        "recall": 0.5859375
      },
      {
        "accuracy": 0.4208984375,
        "f1": 0.38896239936279,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.38896239936279,
        "precision": 0.37923148481535973,
        "recall": 0.4208984375
      },
      {
        "accuracy": 0.69921875,
        "f1": 0.6569230718644781,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6569230718644781,
        "precision": 0.6408578725961538,
        "recall": 0.69921875
      },
      {
        "accuracy": 0.7431640625,
        "f1": 0.7069576907467532,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7069576907467532,
        "precision": 0.6946906283820347,
        "recall": 0.7431640625
      },
      {
        "accuracy": 0.5498046875,
        "f1": 0.5049493121523971,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5049493121523971,
        "precision": 0.48832276799806096,
        "recall": 0.5498046875
      },
      {
        "accuracy": 0.779296875,
        "f1": 0.7396493949142157,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7396493949142157,
        "precision": 0.7245269663604624,
        "recall": 0.779296875
      },
      {
        "accuracy": 0.6552734375,
        "f1": 0.6124480445769508,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6124480445769508,
        "precision": 0.5992269584798882,
        "recall": 0.6552734375
      },
      {
        "accuracy": 0.8193359375,
        "f1": 0.7863792782738095,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7863792782738095,
        "precision": 0.7727224766522989,
        "recall": 0.8193359375
      },
      {
        "accuracy": 0.728515625,
        "f1": 0.6828187708558803,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6828187708558803,
        "precision": 0.6640636625744047,
        "recall": 0.728515625
      },
      {
        "accuracy": 0.83203125,
        "f1": 0.8027285621279762,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8027285621279762,
        "precision": 0.7917495921149611,
        "recall": 0.83203125
      },
      {
        "accuracy": 0.6162109375,
        "f1": 0.5545720176091269,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5545720176091269,
        "precision": 0.5307489304315476,
        "recall": 0.6162109375
      },
      {
        "accuracy": 0.5185546875,
        "f1": 0.47024395865683233,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.47024395865683233,
        "precision": 0.45309847216585497,
        "recall": 0.5185546875
      },
      {
        "accuracy": 0.8115234375,
        "f1": 0.7842708768341411,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7842708768341411,
        "precision": 0.7743385013806658,
        "recall": 0.8115234375
      },
      {
        "accuracy": 0.54296875,
        "f1": 0.4930548716882586,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.4930548716882586,
        "precision": 0.473854652834145,
        "recall": 0.54296875
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.012169704609427132,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.012169704609427132,
        "precision": 0.010114856027704178,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.84765625,
        "f1": 0.8160714285714286,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8160714285714286,
        "precision": 0.8034722222222221,
        "recall": 0.84765625
      },
      {
        "accuracy": 0.3134765625,
        "f1": 0.24951794082653456,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.24951794082653456,
        "precision": 0.22853306361607142,
        "recall": 0.3134765625
      },
      {
        "accuracy": 0.5419921875,
        "f1": 0.482323972143308,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.482323972143308,
        "precision": 0.46145515991835895,
        "recall": 0.5419921875
      },
      {
        "accuracy": 0.796875,
        "f1": 0.765708183131207,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.765708183131207,
        "precision": 0.7540021623883929,
        "recall": 0.796875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.007932833100511603,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007932833100511603,
        "precision": 0.0065844056717413325,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.7197265625,
        "f1": 0.6769711036677972,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6769711036677972,
        "precision": 0.6609877373060966,
        "recall": 0.7197265625
      },
      {
        "accuracy": 0.390625,
        "f1": 0.3372333341571623,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.3372333341571623,
        "precision": 0.31811851415807685,
        "recall": 0.390625
      },
      {
        "accuracy": 0.5966796875,
        "f1": 0.5394128928796897,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5394128928796897,
        "precision": 0.5178831070188492,
        "recall": 0.5966796875
      },
      {
        "accuracy": 0.666015625,
        "f1": 0.6269094919157594,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6269094919157594,
        "precision": 0.6135743244385823,
        "recall": 0.666015625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001963671714176772,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.001963671714176772,
        "precision": 0.0016478652174806425,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004908545372200264,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0004908545372200264,
        "precision": 0.0003268091743623571,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0006120677437641724,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0006120677437641724,
        "precision": 0.0003609130982580564,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0012644384247788793,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0012644384247788793,
        "precision": 0.0011437621974524448,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.405326354679803e-06,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 2.405326354679803e-06,
        "precision": 1.2041461159062885e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000488501267299646,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.000488501267299646,
        "precision": 0.0002816896674543596,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002783046042853164,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.002783046042853164,
        "precision": 0.0022867555206318507,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006529967467467467,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0006529967467467467,
        "precision": 0.0004892597695390781,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0033048988939822195,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0033048988939822195,
        "precision": 0.0028484284046810574,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002424088384689029,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.002424088384689029,
        "precision": 0.002238135960203047,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006869510040627313,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0006869510040627313,
        "precision": 0.0005064684935290404,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003903014257829015,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.003903014257829015,
        "precision": 0.0031704442503891453,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014014012377963738,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0014014012377963738,
        "precision": 0.0012380031193220532,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00042892044512888466,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.00042892044512888466,
        "precision": 0.0002634994368148546,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014895916716696684,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0014895916716696684,
        "precision": 0.0012851317557479845,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001452770967055097,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.001452770967055097,
        "precision": 0.0012431257860231139,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019727746212121213,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0019727746212121213,
        "precision": 0.0019630015871412478,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.007223082511764447,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.007223082511764447,
        "precision": 0.006035234705698394,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001183279193993376,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.001183279193993376,
        "precision": 0.0010907933155568845,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0022983170688817296,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.0022983170688817296,
        "precision": 0.0021498084864198575,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001881607351226053,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.001881607351226053,
        "precision": 0.0016092979928258636,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0006908178609917521,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.0006908178609917521,
        "precision": 0.00043445436990143237,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.76953125,
        "f1": 0.7324743846106151,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7324743846106151,
        "precision": 0.7179363104238672,
        "recall": 0.76953125
      },
      {
        "accuracy": 0.8271484375,
        "f1": 0.7957287016369048,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7957287016369048,
        "precision": 0.7834077380952381,
        "recall": 0.8271484375
      },
      {
        "accuracy": 0.5712890625,
        "f1": 0.5325154508417951,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.5325154508417951,
        "precision": 0.5186877778796724,
        "recall": 0.5712890625
      },
      {
        "accuracy": 0.8798828125,
        "f1": 0.8511579241071429,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8511579241071429,
        "precision": 0.8392740885416667,
        "recall": 0.8798828125
      },
      {
        "accuracy": 0.7197265625,
        "f1": 0.6732685391865079,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6732685391865079,
        "precision": 0.6572163920064311,
        "recall": 0.7197265625
      },
      {
        "accuracy": 0.787109375,
        "f1": 0.7560919810632587,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7560919810632587,
        "precision": 0.7439287898516413,
        "recall": 0.787109375
      },
      {
        "accuracy": 0.7275390625,
        "f1": 0.6785737537202381,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6785737537202381,
        "precision": 0.6595741877480159,
        "recall": 0.7275390625
      },
      {
        "accuracy": 0.927734375,
        "f1": 0.9102267795138888,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9102267795138888,
        "precision": 0.9030936104910714,
        "recall": 0.927734375
      },
      {
        "accuracy": 0.6201171875,
        "f1": 0.5572065521284272,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5572065521284272,
        "precision": 0.5331891741071428,
        "recall": 0.6201171875
      },
      {
        "accuracy": 0.583984375,
        "f1": 0.5362141927083333,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5362141927083333,
        "precision": 0.5186114512543377,
        "recall": 0.583984375
      },
      {
        "accuracy": 0.9072265625,
        "f1": 0.8878333417884199,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8878333417884199,
        "precision": 0.8803641183035714,
        "recall": 0.9072265625
      },
      {
        "accuracy": 0.56640625,
        "f1": 0.5138384510454823,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5138384510454823,
        "precision": 0.49407079303075396,
        "recall": 0.56640625
      },
      {
        "accuracy": 0.8720703125,
        "f1": 0.8462100074404761,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8462100074404761,
        "precision": 0.8359231968118688,
        "recall": 0.8720703125
      },
      {
        "accuracy": 0.02734375,
        "f1": 0.014106493687564326,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.014106493687564326,
        "precision": 0.01186241198196826,
        "recall": 0.02734375
      },
      {
        "accuracy": 0.3720703125,
        "f1": 0.30041835876796813,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.30041835876796813,
        "precision": 0.27611533160849566,
        "recall": 0.3720703125
      },
      {
        "accuracy": 0.6201171875,
        "f1": 0.5637867232593795,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5637867232593795,
        "precision": 0.5438230994152047,
        "recall": 0.6201171875
      },
      {
        "accuracy": 0.8427734375,
        "f1": 0.8133192274305555,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.8133192274305555,
        "precision": 0.8010428292410714,
        "recall": 0.8427734375
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.007820839093539714,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007820839093539714,
        "precision": 0.006564488269832389,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.767578125,
        "f1": 0.7328325320512821,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.7328325320512821,
        "precision": 0.7198265438988096,
        "recall": 0.767578125
      },
      {
        "accuracy": 0.400390625,
        "f1": 0.34750423187923185,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.34750423187923185,
        "precision": 0.33012849617830087,
        "recall": 0.400390625
      },
      {
        "accuracy": 0.6298828125,
        "f1": 0.5775863405257936,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5775863405257936,
        "precision": 0.5565387059771826,
        "recall": 0.6298828125
      },
      {
        "accuracy": 0.7333984375,
        "f1": 0.6983354915483821,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6983354915483821,
        "precision": 0.6850555756156629,
        "recall": 0.7333984375
      },
      {
        "accuracy": 0.12890625,
        "f1": 0.10029234488665177,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.10029234488665177,
        "precision": 0.09377892797194085,
        "recall": 0.12890625
      },
      {
        "accuracy": 0.1162109375,
        "f1": 0.08868768705427134,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.08868768705427134,
        "precision": 0.08214336739885338,
        "recall": 0.1162109375
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.043404215226833937,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.043404215226833937,
        "precision": 0.039318331922852875,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.045826493269025076,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.045826493269025076,
        "precision": 0.04132055150138409,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.02104273733308232,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.02104273733308232,
        "precision": 0.018867747022137126,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.0595703125,
        "f1": 0.042590798605800895,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.042590798605800895,
        "precision": 0.039232238432429636,
        "recall": 0.0595703125
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.14715380662876065,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.14715380662876065,
        "precision": 0.13628114163619648,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.06680264986761356,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.06680264986761356,
        "precision": 0.06286867644229574,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.2158203125,
        "f1": 0.17170615323515964,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.17170615323515964,
        "precision": 0.1606267414111491,
        "recall": 0.2158203125
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.028017857556415542,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.028017857556415542,
        "precision": 0.025586669143213496,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07292739767251677,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.07292739767251677,
        "precision": 0.06866607939402214,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.059302676655083,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.059302676655083,
        "precision": 0.05372329345999737,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.05064696480236352,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.05064696480236352,
        "precision": 0.04705922289771241,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.0073442173783970655,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.0073442173783970655,
        "precision": 0.00629708921925173,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.07266805796574115,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.07266805796574115,
        "precision": 0.06765504077411696,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.07757617602826901,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.07757617602826901,
        "precision": 0.0692013113679876,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.1083984375,
        "f1": 0.07784946781210039,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.07784946781210039,
        "precision": 0.07152227116934334,
        "recall": 0.1083984375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.0096618530842677,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0096618530842677,
        "precision": 0.008053322507440702,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0673828125,
        "f1": 0.04555277475316721,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.04555277475316721,
        "precision": 0.04187046992547896,
        "recall": 0.0673828125
      },
      {
        "accuracy": 0.078125,
        "f1": 0.055295249795447615,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.055295249795447615,
        "precision": 0.05042549211486249,
        "recall": 0.078125
      },
      {
        "accuracy": 0.146484375,
        "f1": 0.1103995123954187,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.1103995123954187,
        "precision": 0.10183488718150621,
        "recall": 0.146484375
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.037407585622156236,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.037407585622156236,
        "precision": 0.03466938520186315,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.4208984375,
        "f1": 0.37718065525939704,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.37718065525939704,
        "precision": 0.3638106455985205,
        "recall": 0.4208984375
      },
      {
        "accuracy": 0.43359375,
        "f1": 0.3963717207088168,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.3963717207088168,
        "precision": 0.3845146181681405,
        "recall": 0.43359375
      },
      {
        "accuracy": 0.4296875,
        "f1": 0.39938681652548835,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.39938681652548835,
        "precision": 0.3901067916719142,
        "recall": 0.4296875
      },
      {
        "accuracy": 0.5625,
        "f1": 0.527905775080938,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.527905775080938,
        "precision": 0.5181286699034662,
        "recall": 0.5625
      },
      {
        "accuracy": 0.3408203125,
        "f1": 0.3000068121225896,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.3000068121225896,
        "precision": 0.28964643382666955,
        "recall": 0.3408203125
      },
      {
        "accuracy": 0.4912109375,
        "f1": 0.46469716372725633,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.46469716372725633,
        "precision": 0.4559122626438937,
        "recall": 0.4912109375
      },
      {
        "accuracy": 0.583984375,
        "f1": 0.5401614401597565,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.5401614401597565,
        "precision": 0.5266971534707633,
        "recall": 0.583984375
      },
      {
        "accuracy": 0.5546875,
        "f1": 0.515972415738983,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.515972415738983,
        "precision": 0.5060221185391726,
        "recall": 0.5546875
      },
      {
        "accuracy": 0.4287109375,
        "f1": 0.3762388571714744,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.3762388571714744,
        "precision": 0.35793798053075393,
        "recall": 0.4287109375
      },
      {
        "accuracy": 0.431640625,
        "f1": 0.39381552365309835,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.39381552365309835,
        "precision": 0.3835977750172165,
        "recall": 0.431640625
      },
      {
        "accuracy": 0.4990234375,
        "f1": 0.46505734520523545,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.46505734520523545,
        "precision": 0.45544543026360973,
        "recall": 0.4990234375
      },
      {
        "accuracy": 0.4599609375,
        "f1": 0.42214698558889585,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.42214698558889585,
        "precision": 0.4089678378453654,
        "recall": 0.4599609375
      },
      {
        "accuracy": 0.4462890625,
        "f1": 0.4090303768116839,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.4090303768116839,
        "precision": 0.3979228107885022,
        "recall": 0.4462890625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.008792109668703007,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.008792109668703007,
        "precision": 0.007413373740180505,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.4892578125,
        "f1": 0.4404790714226031,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.4404790714226031,
        "precision": 0.42644866090666544,
        "recall": 0.4892578125
      },
      {
        "accuracy": 0.2880859375,
        "f1": 0.2376604858145704,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.2376604858145704,
        "precision": 0.2209137975739538,
        "recall": 0.2880859375
      },
      {
        "accuracy": 0.4619140625,
        "f1": 0.4189872481270239,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.4189872481270239,
        "precision": 0.4042221162218952,
        "recall": 0.4619140625
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.010690935736745299,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.010690935736745299,
        "precision": 0.008519940226377047,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.517578125,
        "f1": 0.4830380505294338,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.4830380505294338,
        "precision": 0.4724791159911442,
        "recall": 0.517578125
      },
      {
        "accuracy": 0.427734375,
        "f1": 0.39342470418106756,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.39342470418106756,
        "precision": 0.38229416932084354,
        "recall": 0.427734375
      },
      {
        "accuracy": 0.5107421875,
        "f1": 0.4731574920077182,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.4731574920077182,
        "precision": 0.46014432791345705,
        "recall": 0.5107421875
      },
      {
        "accuracy": 0.4814453125,
        "f1": 0.44319005001369666,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.44319005001369666,
        "precision": 0.4309132214587459,
        "recall": 0.4814453125
      },
      {
        "accuracy": 0.64453125,
        "f1": 0.5999190090838358,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5999190090838358,
        "precision": 0.5840514853955439,
        "recall": 0.64453125
      },
      {
        "accuracy": 0.703125,
        "f1": 0.6670945645066739,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6670945645066739,
        "precision": 0.654879039274145,
        "recall": 0.703125
      },
      {
        "accuracy": 0.5234375,
        "f1": 0.48464742993551585,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.48464742993551585,
        "precision": 0.47226694435652067,
        "recall": 0.5234375
      },
      {
        "accuracy": 0.7197265625,
        "f1": 0.6765758167613636,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.6765758167613636,
        "precision": 0.661697950072548,
        "recall": 0.7197265625
      },
      {
        "accuracy": 0.630859375,
        "f1": 0.5925007215245259,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5925007215245259,
        "precision": 0.5796362823645539,
        "recall": 0.630859375
      },
      {
        "accuracy": 0.6787109375,
        "f1": 0.6406345188464567,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6406345188464567,
        "precision": 0.6266549892526454,
        "recall": 0.6787109375
      },
      {
        "accuracy": 0.623046875,
        "f1": 0.5699611206935425,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.5699611206935425,
        "precision": 0.5514385272930195,
        "recall": 0.623046875
      },
      {
        "accuracy": 0.7919921875,
        "f1": 0.7602953433476756,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7602953433476756,
        "precision": 0.749234870617281,
        "recall": 0.7919921875
      },
      {
        "accuracy": 0.6064453125,
        "f1": 0.5439043053300865,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5439043053300865,
        "precision": 0.5204450334821429,
        "recall": 0.6064453125
      },
      {
        "accuracy": 0.5087890625,
        "f1": 0.46531614273313493,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.46531614273313493,
        "precision": 0.4510249787105256,
        "recall": 0.5087890625
      },
      {
        "accuracy": 0.7314453125,
        "f1": 0.701522113411762,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.701522113411762,
        "precision": 0.6905591560132576,
        "recall": 0.7314453125
      },
      {
        "accuracy": 0.5712890625,
        "f1": 0.5235296549175226,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5235296549175226,
        "precision": 0.5063698793068909,
        "recall": 0.5712890625
      },
      {
        "accuracy": 0.767578125,
        "f1": 0.7314298819669912,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7314298819669912,
        "precision": 0.7177711123511905,
        "recall": 0.767578125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.0124106332245901,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0124106332245901,
        "precision": 0.010628806715685692,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.78515625,
        "f1": 0.7535722036210317,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7535722036210317,
        "precision": 0.7423084077380953,
        "recall": 0.78515625
      },
      {
        "accuracy": 0.2744140625,
        "f1": 0.22061179015259347,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.22061179015259347,
        "precision": 0.20231140929383115,
        "recall": 0.2744140625
      },
      {
        "accuracy": 0.5439453125,
        "f1": 0.48997898206394297,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.48997898206394297,
        "precision": 0.4719878049467893,
        "recall": 0.5439453125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.007584294553339983,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.007584294553339983,
        "precision": 0.006314586292613636,
        "recall": 0.015625
      },
      {
        "accuracy": 0.658203125,
        "f1": 0.622119563379329,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.622119563379329,
        "precision": 0.6093530402612435,
        "recall": 0.658203125
      },
      {
        "accuracy": 0.421875,
        "f1": 0.3728874261589106,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.3728874261589106,
        "precision": 0.35576128370630095,
        "recall": 0.421875
      },
      {
        "accuracy": 0.5986328125,
        "f1": 0.5453934754253422,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5453934754253422,
        "precision": 0.5267152552308803,
        "recall": 0.5986328125
      },
      {
        "accuracy": 0.6533203125,
        "f1": 0.6167267587555674,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.6167267587555674,
        "precision": 0.6052616035309847,
        "recall": 0.6533203125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0023683991549703605,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.0023683991549703605,
        "precision": 0.002181238709831861,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.003908327792553191,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.003908327792553191,
        "precision": 0.003907290002662407,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004708250614234635,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.004708250614234635,
        "precision": 0.004374901806464618,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003412599623096217,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.003412599623096217,
        "precision": 0.0032085059748994172,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0015223742775913498,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0015223742775913498,
        "precision": 0.0013316264005602241,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0024521057252489013,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.0024521057252489013,
        "precision": 0.0022336568791246087,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004676675464413907,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.004676675464413907,
        "precision": 0.00437314523777218,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.003265358193654427,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.003265358193654427,
        "precision": 0.003130088190365669,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005660445103895239,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.005660445103895239,
        "precision": 0.0051254474762111235,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0027036229461052576,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.0027036229461052576,
        "precision": 0.0024100070755043784,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0022785810351126957,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0022785810351126957,
        "precision": 0.0021393702475419065,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0030607195387450906,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.0030607195387450906,
        "precision": 0.002719563070027486,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003389986520887434,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.003389986520887434,
        "precision": 0.003185273890706589,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.007616946251590261,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.007616946251590261,
        "precision": 0.006333102788755362,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.00594216452415096,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.00594216452415096,
        "precision": 0.005901734049110574,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.009279473657306435,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.009279473657306435,
        "precision": 0.009115649449599708,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.002060638745868294,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.002060638745868294,
        "precision": 0.0020097430303336024,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.005113520060043668,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.005113520060043668,
        "precision": 0.004672647518828961,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016488724396008403,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0016488724396008403,
        "precision": 0.0014755236828581577,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004897727732117085,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.004897727732117085,
        "precision": 0.004326967143288474,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0036509793311263897,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.0036509793311263897,
        "precision": 0.00334876851366329,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0031109645562770565,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.0031109645562770565,
        "precision": 0.0027036865855597962,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.6298828125,
        "f1": 0.5906994047619047,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5906994047619047,
        "precision": 0.5760291466346155,
        "recall": 0.6298828125
      },
      {
        "accuracy": 0.6923828125,
        "f1": 0.6580995718691032,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.6580995718691032,
        "precision": 0.6457140668767507,
        "recall": 0.6923828125
      },
      {
        "accuracy": 0.625,
        "f1": 0.59257568061279,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.59257568061279,
        "precision": 0.581425896171148,
        "recall": 0.625
      },
      {
        "accuracy": 0.8564453125,
        "f1": 0.8295417906746031,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8295417906746031,
        "precision": 0.8187573033520299,
        "recall": 0.8564453125
      },
      {
        "accuracy": 0.6865234375,
        "f1": 0.6504209750126171,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.6504209750126171,
        "precision": 0.6385597475349362,
        "recall": 0.6865234375
      },
      {
        "accuracy": 0.7294921875,
        "f1": 0.697343010721917,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.697343010721917,
        "precision": 0.6849971064814815,
        "recall": 0.7294921875
      },
      {
        "accuracy": 0.6845703125,
        "f1": 0.6326871867167919,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6326871867167919,
        "precision": 0.6108899115735054,
        "recall": 0.6845703125
      },
      {
        "accuracy": 0.833984375,
        "f1": 0.8083556905334248,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8083556905334248,
        "precision": 0.7993683345734126,
        "recall": 0.833984375
      },
      {
        "accuracy": 0.513671875,
        "f1": 0.45247860863095235,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.45247860863095235,
        "precision": 0.43001210301143483,
        "recall": 0.513671875
      },
      {
        "accuracy": 0.646484375,
        "f1": 0.6083746637859689,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.6083746637859689,
        "precision": 0.5944667271205357,
        "recall": 0.646484375
      },
      {
        "accuracy": 0.7939453125,
        "f1": 0.7628203483097785,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.7628203483097785,
        "precision": 0.7518257634834783,
        "recall": 0.7939453125
      },
      {
        "accuracy": 0.58203125,
        "f1": 0.5337353175583475,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5337353175583475,
        "precision": 0.5149416176271645,
        "recall": 0.58203125
      },
      {
        "accuracy": 0.7255859375,
        "f1": 0.6895922464037698,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.6895922464037698,
        "precision": 0.6768599762753237,
        "recall": 0.7255859375
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01284084034938527,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.01284084034938527,
        "precision": 0.010879748490578278,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.7919921875,
        "f1": 0.7558422046703297,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.7558422046703297,
        "precision": 0.7428141032144939,
        "recall": 0.7919921875
      },
      {
        "accuracy": 0.275390625,
        "f1": 0.21551712718704907,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.21551712718704907,
        "precision": 0.19697135090329992,
        "recall": 0.275390625
      },
      {
        "accuracy": 0.6474609375,
        "f1": 0.5990606398809524,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5990606398809524,
        "precision": 0.5812460172092162,
        "recall": 0.6474609375
      },
      {
        "accuracy": 0.7119140625,
        "f1": 0.6742147474711109,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.6742147474711109,
        "precision": 0.6597772507440476,
        "recall": 0.7119140625
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.012983943422971954,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.012983943422971954,
        "precision": 0.011281084434068243,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.4580078125,
        "f1": 0.41290213150564714,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.41290213150564714,
        "precision": 0.39883586194621345,
        "recall": 0.4580078125
      },
      {
        "accuracy": 0.6044921875,
        "f1": 0.5543836805555555,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5543836805555555,
        "precision": 0.5353572068829796,
        "recall": 0.6044921875
      },
      {
        "accuracy": 0.7421875,
        "f1": 0.7071395668826242,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7071395668826242,
        "precision": 0.6957170162736569,
        "recall": 0.7421875
      },
      {
        "accuracy": 0.25390625,
        "f1": 0.2194591769442012,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.2194591769442012,
        "precision": 0.20941434388372118,
        "recall": 0.25390625
      },
      {
        "accuracy": 0.265625,
        "f1": 0.23413118586685866,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.23413118586685866,
        "precision": 0.22562413373873114,
        "recall": 0.265625
      },
      {
        "accuracy": 0.330078125,
        "f1": 0.30197347565938615,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.30197347565938615,
        "precision": 0.2936531277852721,
        "recall": 0.330078125
      },
      {
        "accuracy": 0.314453125,
        "f1": 0.28932992838760424,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.28932992838760424,
        "precision": 0.2811704466943027,
        "recall": 0.314453125
      },
      {
        "accuracy": 0.1865234375,
        "f1": 0.14623221647239756,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.14623221647239756,
        "precision": 0.1380446394103152,
        "recall": 0.1865234375
      },
      {
        "accuracy": 0.31640625,
        "f1": 0.29293422652493745,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.29293422652493745,
        "precision": 0.2848538536849945,
        "recall": 0.31640625
      },
      {
        "accuracy": 0.3056640625,
        "f1": 0.26938752884532435,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.26938752884532435,
        "precision": 0.2576215023228089,
        "recall": 0.3056640625
      },
      {
        "accuracy": 0.3037109375,
        "f1": 0.2794886997767857,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.2794886997767857,
        "precision": 0.2719029673244441,
        "recall": 0.3037109375
      },
      {
        "accuracy": 0.33984375,
        "f1": 0.2934197776067055,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.2934197776067055,
        "precision": 0.27972794164328907,
        "recall": 0.33984375
      },
      {
        "accuracy": 0.2998046875,
        "f1": 0.2685809407141056,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.2685809407141056,
        "precision": 0.25984668135832595,
        "recall": 0.2998046875
      },
      {
        "accuracy": 0.2353515625,
        "f1": 0.20796774283196068,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.20796774283196068,
        "precision": 0.19989368677112818,
        "recall": 0.2353515625
      },
      {
        "accuracy": 0.400390625,
        "f1": 0.3569744811651279,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.3569744811651279,
        "precision": 0.3448321006792686,
        "recall": 0.400390625
      },
      {
        "accuracy": 0.2607421875,
        "f1": 0.22690329819083188,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.22690329819083188,
        "precision": 0.21847732327710662,
        "recall": 0.2607421875
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.009630306560942804,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.009630306560942804,
        "precision": 0.008238582420810643,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.2529296875,
        "f1": 0.2224357737508096,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.2224357737508096,
        "precision": 0.213528633181243,
        "recall": 0.2529296875
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.08906017485119046,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.08906017485119046,
        "precision": 0.08136492584991763,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.3681640625,
        "f1": 0.3411050481607122,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.3411050481607122,
        "precision": 0.33268228547653916,
        "recall": 0.3681640625
      },
      {
        "accuracy": 0.2939453125,
        "f1": 0.2570000895521359,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.2570000895521359,
        "precision": 0.24631156187864944,
        "recall": 0.2939453125
      },
      {
        "accuracy": 0.013671875,
        "f1": 0.005427255036630036,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.005427255036630036,
        "precision": 0.004226455797572526,
        "recall": 0.013671875
      },
      {
        "accuracy": 0.30859375,
        "f1": 0.2795765992317573,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.2795765992317573,
        "precision": 0.2719235433200652,
        "recall": 0.30859375
      },
      {
        "accuracy": 0.4248046875,
        "f1": 0.4024845216765447,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.4024845216765447,
        "precision": 0.3955413681732041,
        "recall": 0.4248046875
      },
      {
        "accuracy": 0.3193359375,
        "f1": 0.28968247269913994,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.28968247269913994,
        "precision": 0.2809110272052757,
        "recall": 0.3193359375
      },
      {
        "accuracy": 0.4150390625,
        "f1": 0.3725827806329899,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.3725827806329899,
        "precision": 0.3596095660976032,
        "recall": 0.4150390625
      },
      {
        "accuracy": 0.4296875,
        "f1": 0.3956437135027374,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.3956437135027374,
        "precision": 0.3851221739338121,
        "recall": 0.4296875
      },
      {
        "accuracy": 0.4169921875,
        "f1": 0.386754125865454,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.386754125865454,
        "precision": 0.3773331852864252,
        "recall": 0.4169921875
      },
      {
        "accuracy": 0.4501953125,
        "f1": 0.4138323923940892,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.4138323923940892,
        "precision": 0.4029468893768353,
        "recall": 0.4501953125
      },
      {
        "accuracy": 0.2744140625,
        "f1": 0.23812069525602628,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.23812069525602628,
        "precision": 0.22827790403759007,
        "recall": 0.2744140625
      },
      {
        "accuracy": 0.44140625,
        "f1": 0.41187519741288126,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.41187519741288126,
        "precision": 0.4031438332908921,
        "recall": 0.44140625
      },
      {
        "accuracy": 0.5537109375,
        "f1": 0.5005318879881997,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.5005318879881997,
        "precision": 0.48260129898313486,
        "recall": 0.5537109375
      },
      {
        "accuracy": 0.447265625,
        "f1": 0.4185505207596991,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.4185505207596991,
        "precision": 0.40955583674070123,
        "recall": 0.447265625
      },
      {
        "accuracy": 0.638671875,
        "f1": 0.5837913876488096,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.5837913876488096,
        "precision": 0.5631867291779401,
        "recall": 0.638671875
      },
      {
        "accuracy": 0.353515625,
        "f1": 0.318685884518404,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.318685884518404,
        "precision": 0.30839748313730136,
        "recall": 0.353515625
      },
      {
        "accuracy": 0.412109375,
        "f1": 0.3749318539216081,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.3749318539216081,
        "precision": 0.364445504709751,
        "recall": 0.412109375
      },
      {
        "accuracy": 0.5322265625,
        "f1": 0.49589107452876985,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.49589107452876985,
        "precision": 0.4834678152793388,
        "recall": 0.5322265625
      },
      {
        "accuracy": 0.4189453125,
        "f1": 0.38306858731432125,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.38306858731432125,
        "precision": 0.3728304986796317,
        "recall": 0.4189453125
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.011987833573549964,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.011987833573549964,
        "precision": 0.010546878500372198,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.4384765625,
        "f1": 0.39903086013087763,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.39903086013087763,
        "precision": 0.38859660931984,
        "recall": 0.4384765625
      },
      {
        "accuracy": 0.2802734375,
        "f1": 0.22882145252750719,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.22882145252750719,
        "precision": 0.21261632789953103,
        "recall": 0.2802734375
      },
      {
        "accuracy": 0.478515625,
        "f1": 0.43630597956483597,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.43630597956483597,
        "precision": 0.423545246061323,
        "recall": 0.478515625
      },
      {
        "accuracy": 0.46875,
        "f1": 0.4346646219448954,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.4346646219448954,
        "precision": 0.4233875983867565,
        "recall": 0.46875
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009251907559906881,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.009251907559906881,
        "precision": 0.008049878737130818,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.421875,
        "f1": 0.390892650681006,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.390892650681006,
        "precision": 0.3820241950613044,
        "recall": 0.421875
      },
      {
        "accuracy": 0.47265625,
        "f1": 0.4378142826140873,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.4378142826140873,
        "precision": 0.42573173800770303,
        "recall": 0.47265625
      },
      {
        "accuracy": 0.3994140625,
        "f1": 0.3652701875665905,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.3652701875665905,
        "precision": 0.3565283960444525,
        "recall": 0.3994140625
      },
      {
        "accuracy": 0.6513671875,
        "f1": 0.6084597368777056,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.6084597368777056,
        "precision": 0.5929640753127081,
        "recall": 0.6513671875
      },
      {
        "accuracy": 0.7421875,
        "f1": 0.7053424873737374,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.7053424873737374,
        "precision": 0.6909265854779412,
        "recall": 0.7421875
      },
      {
        "accuracy": 0.568359375,
        "f1": 0.5302325422356442,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.5302325422356442,
        "precision": 0.5166033415911345,
        "recall": 0.568359375
      },
      {
        "accuracy": 0.8671875,
        "f1": 0.8393275669642857,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.8393275669642857,
        "precision": 0.8287109374999999,
        "recall": 0.8671875
      },
      {
        "accuracy": 0.888671875,
        "f1": 0.8649135044642857,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.8649135044642857,
        "precision": 0.8551457990679825,
        "recall": 0.888671875
      },
      {
        "accuracy": 0.7041015625,
        "f1": 0.6716652199074075,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.6716652199074075,
        "precision": 0.659537081969297,
        "recall": 0.7041015625
      },
      {
        "accuracy": 0.6767578125,
        "f1": 0.628608630952381,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.628608630952381,
        "precision": 0.6088990599244506,
        "recall": 0.6767578125
      },
      {
        "accuracy": 0.9091796875,
        "f1": 0.8889997209821429,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.8889997209821429,
        "precision": 0.8808361235119048,
        "recall": 0.9091796875
      },
      {
        "accuracy": 0.482421875,
        "f1": 0.4234584263392857,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.4234584263392857,
        "precision": 0.4003131200396825,
        "recall": 0.482421875
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.8090680803571428,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.8090680803571428,
        "precision": 0.7952311197916667,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.8203125,
        "f1": 0.7920447716346153,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.7920447716346153,
        "precision": 0.7796875,
        "recall": 0.8203125
      },
      {
        "accuracy": 0.564453125,
        "f1": 0.5197069477831197,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.5197069477831197,
        "precision": 0.501986839657738,
        "recall": 0.564453125
      },
      {
        "accuracy": 0.724609375,
        "f1": 0.6874176062652625,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.6874176062652625,
        "precision": 0.6728785464638157,
        "recall": 0.724609375
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.010505446102051933,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.010505446102051933,
        "precision": 0.008901149167964771,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.7998046875,
        "f1": 0.7632332673836579,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.7632332673836579,
        "precision": 0.7483328683035715,
        "recall": 0.7998046875
      },
      {
        "accuracy": 0.224609375,
        "f1": 0.1711743063793845,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.1711743063793845,
        "precision": 0.15496658464977628,
        "recall": 0.224609375
      },
      {
        "accuracy": 0.64453125,
        "f1": 0.5930687313988096,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.5930687313988096,
        "precision": 0.5737474682512808,
        "recall": 0.64453125
      },
      {
        "accuracy": 0.7431640625,
        "f1": 0.6975857204861111,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.6975857204861111,
        "precision": 0.6787256634424603,
        "recall": 0.7431640625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.008221649880411014,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.008221649880411014,
        "precision": 0.006891758948686798,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.8232421875,
        "f1": 0.7936508641098484,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.7936508641098484,
        "precision": 0.781552269345238,
        "recall": 0.8232421875
      },
      {
        "accuracy": 0.4501953125,
        "f1": 0.4100683523290945,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.4100683523290945,
        "precision": 0.39657252826326633,
        "recall": 0.4501953125
      },
      {
        "accuracy": 0.5625,
        "f1": 0.515146864853896,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.515146864853896,
        "precision": 0.49710978041056164,
        "recall": 0.5625
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}