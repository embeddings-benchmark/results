{
  "dataset_revision": "1beac1b941da76a9c51e3e5b39d230fde9a80983",
  "evaluation_time": 11.65048098564148,
  "kg_co2_emissions": 0.000387452443533203,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.395361328125,
        "f1": 0.3756159074846676,
        "f1_weighted": 0.41029116069567495,
        "hf_subset": "default",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.3756159074846676,
        "scores_per_experiment": [
          {
            "accuracy": 0.46630859375,
            "f1": 0.420340724073061,
            "f1_weighted": 0.47687547962629073
          },
          {
            "accuracy": 0.3828125,
            "f1": 0.37393002974182316,
            "f1_weighted": 0.39845814052316486
          },
          {
            "accuracy": 0.36572265625,
            "f1": 0.354238567923393,
            "f1_weighted": 0.38114097291322
          },
          {
            "accuracy": 0.39453125,
            "f1": 0.3865620678638572,
            "f1_weighted": 0.4103449887722839
          },
          {
            "accuracy": 0.37158203125,
            "f1": 0.35063072133667966,
            "f1_weighted": 0.37713460320938585
          },
          {
            "accuracy": 0.390625,
            "f1": 0.3873320553542359,
            "f1_weighted": 0.41574596012699316
          },
          {
            "accuracy": 0.38720703125,
            "f1": 0.37203666009265796,
            "f1_weighted": 0.40577781249329814
          },
          {
            "accuracy": 0.4365234375,
            "f1": 0.4108475248430614,
            "f1_weighted": 0.45563550679196313
          },
          {
            "accuracy": 0.30859375,
            "f1": 0.3099963975347968,
            "f1_weighted": 0.3298076798405599
          },
          {
            "accuracy": 0.44970703125,
            "f1": 0.3902443260831105,
            "f1_weighted": 0.45199046265958953
          }
        ]
      }
    ]
  },
  "task_name": "SentimentAnalysisHindi"
}