{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 13.878223896026611,
  "kg_co2_emissions": 0.0004027102397802119,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.4471153846153846,
        "f1": 0.33073411928222807,
        "f1_weighted": 0.5156421393899981,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.4471153846153846,
        "scores_per_experiment": [
          {
            "accuracy": 0.4230769230769231,
            "f1": 0.28535353535353536,
            "f1_weighted": 0.5069606319606319
          },
          {
            "accuracy": 0.5384615384615384,
            "f1": 0.3998018673175159,
            "f1_weighted": 0.5966479006833321
          },
          {
            "accuracy": 0.5673076923076923,
            "f1": 0.4224021592442645,
            "f1_weighted": 0.6327468078480224
          },
          {
            "accuracy": 0.4230769230769231,
            "f1": 0.34547430830039527,
            "f1_weighted": 0.5015878686530861
          },
          {
            "accuracy": 0.4807692307692308,
            "f1": 0.31333746898263026,
            "f1_weighted": 0.5588590379843481
          },
          {
            "accuracy": 0.41346153846153844,
            "f1": 0.3095841440789176,
            "f1_weighted": 0.48143668178511384
          },
          {
            "accuracy": 0.4230769230769231,
            "f1": 0.35357142857142854,
            "f1_weighted": 0.4872252747252747
          },
          {
            "accuracy": 0.38461538461538464,
            "f1": 0.2893750155190823,
            "f1_weighted": 0.4626744583601535
          },
          {
            "accuracy": 0.4230769230769231,
            "f1": 0.29521246745083957,
            "f1_weighted": 0.4684554819002494
          },
          {
            "accuracy": 0.3942307692307692,
            "f1": 0.2932287980036711,
            "f1_weighted": 0.4598272499997692
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.46380952380952384,
        "f1": 0.32340289661992944,
        "f1_weighted": 0.5236623451540766,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.46380952380952384,
        "scores_per_experiment": [
          {
            "accuracy": 0.44761904761904764,
            "f1": 0.2921195652173913,
            "f1_weighted": 0.5154761904761904
          },
          {
            "accuracy": 0.4857142857142857,
            "f1": 0.32550447264406074,
            "f1_weighted": 0.5451082251082251
          },
          {
            "accuracy": 0.4857142857142857,
            "f1": 0.3426724137931034,
            "f1_weighted": 0.5364532019704433
          },
          {
            "accuracy": 0.44761904761904764,
            "f1": 0.33176199455269223,
            "f1_weighted": 0.5076052796983029
          },
          {
            "accuracy": 0.4857142857142857,
            "f1": 0.3193548387096774,
            "f1_weighted": 0.5473835125448029
          },
          {
            "accuracy": 0.42857142857142855,
            "f1": 0.32141145458902465,
            "f1_weighted": 0.48294820444353154
          },
          {
            "accuracy": 0.49523809523809526,
            "f1": 0.3592049328121504,
            "f1_weighted": 0.5602426922520104
          },
          {
            "accuracy": 0.42857142857142855,
            "f1": 0.2950947270800212,
            "f1_weighted": 0.4911304161304162
          },
          {
            "accuracy": 0.45714285714285713,
            "f1": 0.32077526132404177,
            "f1_weighted": 0.5138626182180189
          },
          {
            "accuracy": 0.47619047619047616,
            "f1": 0.3261293054771316,
            "f1_weighted": 0.5364131106988249
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}