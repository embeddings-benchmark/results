{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 38.140382289886475,
  "kg_co2_emissions": 0.0018067586301622057,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.08203125,
        "f1": 0.06087920326201576,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.06087920326201576,
        "precision": 0.054195671407585466,
        "recall": 0.08203125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0021021792763157897,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.0021021792763157897,
        "precision": 0.0020309166073968704,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00039542383292383293,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.00039542383292383293,
        "precision": 0.0002465459513546798,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.2270524515393387e-06,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 2.2270524515393387e-06,
        "precision": 1.1147973744292237e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00034128011880697425,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.00034128011880697425,
        "precision": 0.00019457077477141863,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004752271153026428,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0004752271153026428,
        "precision": 0.000253859089800693,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004579844708898579,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.0004579844708898579,
        "precision": 0.0002782436239542926,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0035556028813964607,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0035556028813964607,
        "precision": 0.0030922013099747474,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011984349087893866,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.0011984349087893866,
        "precision": 0.0011010681304551122,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.000523843954533716,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.000523843954533716,
        "precision": 0.00029343372867051873,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0027094959615236334,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.0027094959615236334,
        "precision": 0.0018274965725913533,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0021059811639588272,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0021059811639588272,
        "precision": 0.00203168825886612,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0038884449131060175,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0038884449131060175,
        "precision": 0.0026382004624766575,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0010130977420499405,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0010130977420499405,
        "precision": 0.000611402244197568,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0033228625855261213,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0033228625855261213,
        "precision": 0.002769060319242801,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0006131357143422445,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0006131357143422445,
        "precision": 0.00034143357049851186,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0007293832597569302,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.0007293832597569302,
        "precision": 0.00042400434930922734,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.953125e-06,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 1.953125e-06,
        "precision": 9.7754004004004e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007171166501825927,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0007171166501825927,
        "precision": 0.0005223712270341208,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0002025446271454476,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.0002025446271454476,
        "precision": 0.00010621116031563792,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.001803269761748172,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.001803269761748172,
        "precision": 0.0011837825802669551,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9242610837438422e-06,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 1.9242610837438422e-06,
        "precision": 9.630793885601578e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.05232931402364996,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.05232931402364996,
        "precision": 0.04692476259116035,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001626596452847356,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.001626596452847356,
        "precision": 0.0010930424726073346,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001636730919003115,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.001636730919003115,
        "precision": 0.0014694285504694836,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.0093878600823047e-06,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 2.0093878600823047e-06,
        "precision": 1.0057286302780638e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 7.907388663967611e-06,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 7.907388663967611e-06,
        "precision": 3.969766260162602e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0014915364626125888,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.0014915364626125888,
        "precision": 0.0012543490484106623,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0006877253605769231,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.0006877253605769231,
        "precision": 0.0004001061893203883,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0006396443548808528,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.0006396443548808528,
        "precision": 0.0004027834406789031,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004208282743601603,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.0004208282743601603,
        "precision": 0.00023528194275565365,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010033160949627295,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.0010033160949627295,
        "precision": 0.00099000663871155,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00047407200727513224,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.00047407200727513224,
        "precision": 0.0002613159693694156,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0009218957094248417,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.0009218957094248417,
        "precision": 0.0006378305938852814,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0033579835155961605,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0033579835155961605,
        "precision": 0.0028788402226882994,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0017945442354642233,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.0017945442354642233,
        "precision": 0.0014677698896352644,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012468330509037746,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.0012468330509037746,
        "precision": 0.0011180174263210262,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0012209031994530454,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.0012209031994530454,
        "precision": 0.001105818887287329,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003466260302197802,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.0003466260302197802,
        "precision": 0.0001972816700896191,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009784698486328125,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0009784698486328125,
        "precision": 0.0009775171065493646,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0003889556623931624,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.0003889556623931624,
        "precision": 0.00020857952556022408,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.8306159420289855e-05,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 2.8306159420289855e-05,
        "precision": 1.4361213235294117e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 9.812179134580124e-05,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 9.812179134580124e-05,
        "precision": 5.0559371816097816e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9280602171767027e-06,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 1.9280602171767027e-06,
        "precision": 9.649827075098814e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000257344845356144,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.000257344845356144,
        "precision": 0.00014255117935024476,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00040213628708398304,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00040213628708398304,
        "precision": 0.00021347205209991678,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.134765625,
        "f1": 0.11231297807584573,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.11231297807584573,
        "precision": 0.10653271528372056,
        "recall": 0.134765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009809221540178572,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0009809221540178572,
        "precision": 0.0009787472035794184,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.12267879689754688,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.12267879689754688,
        "precision": 0.11673219795045212,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.010118053391611826,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.010118053391611826,
        "precision": 0.008138960843227967,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.14011097902865752,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.14011097902865752,
        "precision": 0.13389811175429733,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00254983153117016,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.00254983153117016,
        "precision": 0.0020953844239695115,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.04296875,
        "f1": 0.03665434377174389,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.03665434377174389,
        "precision": 0.03563469594022049,
        "recall": 0.04296875
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.036263892602629785,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.036263892602629785,
        "precision": 0.03226515824972629,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04118809005993812,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.04118809005993812,
        "precision": 0.037215288204700214,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.027944415283267354,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.027944415283267354,
        "precision": 0.024834505514621096,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003995611673759191,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003995611673759191,
        "precision": 0.0032145999924135314,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0517578125,
        "f1": 0.035853794642857144,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.035853794642857144,
        "precision": 0.03172819200779727,
        "recall": 0.0517578125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.00535878493238256,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.00535878493238256,
        "precision": 0.0044386306772097334,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.047283831080240535,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.047283831080240535,
        "precision": 0.0453524582430208,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.028877322760393485,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.028877322760393485,
        "precision": 0.02530092113832348,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001195866101667318,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.001195866101667318,
        "precision": 0.0007742581792840376,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.13800476475910034,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.13800476475910034,
        "precision": 0.13212713922114927,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002647593845434985,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.002647593845434985,
        "precision": 0.002386622117960556,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0927734375,
        "f1": 0.07334446652940269,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.07334446652940269,
        "precision": 0.06799648329667012,
        "recall": 0.0927734375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.007875504032258064,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.007875504032258064,
        "precision": 0.007845052083333333,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0005848019622093024,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0005848019622093024,
        "precision": 0.0003216281000740732,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0007633463541666667,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0007633463541666667,
        "precision": 0.00047473555024846816,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.14124902951798868,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.14124902951798868,
        "precision": 0.1341250118861362,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0030955729166666666,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0030955729166666666,
        "precision": 0.003020030913097319,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.2138671875,
        "f1": 0.18428143923213475,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.18428143923213475,
        "precision": 0.1751654173677573,
        "recall": 0.2138671875
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.009160140321559082,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.009160140321559082,
        "precision": 0.007436170359347443,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.384765625,
        "f1": 0.3397404299259768,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.3397404299259768,
        "precision": 0.3251767465390512,
        "recall": 0.384765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0033259249281609197,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0033259249281609197,
        "precision": 0.0031766424261527376,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0654296875,
        "f1": 0.053078015641019674,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.053078015641019674,
        "precision": 0.04987562094764467,
        "recall": 0.0654296875
      },
      {
        "accuracy": 0.21875,
        "f1": 0.17114698731136424,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.17114698731136424,
        "precision": 0.1567260843731432,
        "recall": 0.21875
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.05064023667539293,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.05064023667539293,
        "precision": 0.046741514126395614,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.080078125,
        "f1": 0.060539706147744794,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.060539706147744794,
        "precision": 0.05525955243542058,
        "recall": 0.080078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013498079544858686,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0013498079544858686,
        "precision": 0.0011830178285256409,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.12993543132215007,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.12993543132215007,
        "precision": 0.12009140847159966,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0010986632919787766,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0010986632919787766,
        "precision": 0.0006482435817813413,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.0252384824082813,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0252384824082813,
        "precision": 0.02331598122073201,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.032359411756464285,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.032359411756464285,
        "precision": 0.027839567939244664,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0013041948198198197,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0013041948198198197,
        "precision": 0.0011729318858225107,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.2841796875,
        "f1": 0.25058924907557717,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.25058924907557717,
        "precision": 0.24006529494810744,
        "recall": 0.2841796875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005093825017146776,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.005093825017146776,
        "precision": 0.004362580778596404,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.103515625,
        "f1": 0.08886681996542398,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.08886681996542398,
        "precision": 0.08435666263577313,
        "recall": 0.103515625
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.021066036679431698,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.021066036679431698,
        "precision": 0.020381227935821936,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0001775568181818182,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.0001775568181818182,
        "precision": 9.765625e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.01589485818001443,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.01589485818001443,
        "precision": 0.01478460728205973,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.03399221787094171,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.03399221787094171,
        "precision": 0.031072351681978236,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.012338472934143727,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.012338472934143727,
        "precision": 0.010287143052189147,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0012529983471240673,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.0012529983471240673,
        "precision": 0.0007052749252256168,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.021521995618675308,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.021521995618675308,
        "precision": 0.01892386575665376,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.001508892608467718,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.001508892608467718,
        "precision": 0.0009752364723968032,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.017402571669725204,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.017402571669725204,
        "precision": 0.015426955856643356,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011088551475204017,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.0011088551475204017,
        "precision": 0.0010446638864607615,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.012805074803846697,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.012805074803846697,
        "precision": 0.010892110583219618,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003502439345991561,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.0003502439345991561,
        "precision": 0.00020783253205128207,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 7.705760750643771e-05,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 7.705760750643771e-05,
        "precision": 3.924532016533994e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0022742790904471543,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.0022742790904471543,
        "precision": 0.0018544844845530236,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011905534681492342,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.0011905534681492342,
        "precision": 0.0008397762281141965,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.017538958798724424,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.017538958798724424,
        "precision": 0.014315530666060495,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0010608195873688458,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.0010608195873688458,
        "precision": 0.0007192769774652148,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00043762800819252437,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.00043762800819252437,
        "precision": 0.00026796234631147543,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.03125,
        "f1": 0.020039641852059323,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.020039641852059323,
        "precision": 0.0183074750879615,
        "recall": 0.03125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004613808636025433,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.004613808636025433,
        "precision": 0.004026382688492063,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.025390625,
        "f1": 0.0093334246339823,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.0093334246339823,
        "precision": 0.007852543087562986,
        "recall": 0.025390625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006076388888888888,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.006076388888888888,
        "precision": 0.004996004971590909,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00030849010723806665,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.00030849010723806665,
        "precision": 0.00016213392832391987,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.00031070506253868944,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.00031070506253868944,
        "precision": 0.00016368698177454254,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.16015625,
        "f1": 0.13657879803012712,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.13657879803012712,
        "precision": 0.12966306675310388,
        "recall": 0.16015625
      },
      {
        "accuracy": 0.177734375,
        "f1": 0.1469283419148424,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.1469283419148424,
        "precision": 0.13964528845500537,
        "recall": 0.177734375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0001953125,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0001953125,
        "precision": 0.00010850694444444444,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0263671875,
        "f1": 0.01396289194825542,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.01396289194825542,
        "precision": 0.011976023566288104,
        "recall": 0.0263671875
      },
      {
        "accuracy": 0.294921875,
        "f1": 0.25397304518398267,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.25397304518398267,
        "precision": 0.24088967259180108,
        "recall": 0.294921875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002895036811641682,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.002895036811641682,
        "precision": 0.0025961029812069892,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.02720550933441558,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.02720550933441558,
        "precision": 0.026300880670155992,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.09806646054491872,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.09806646054491872,
        "precision": 0.0889290505501443,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.05515810415712759,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.05515810415712759,
        "precision": 0.05031902234050671,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.279296875,
        "f1": 0.22273375496031744,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.22273375496031744,
        "precision": 0.20250350140056023,
        "recall": 0.279296875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0011121899936138266,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0011121899936138266,
        "precision": 0.0007367390711031229,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1142578125,
        "f1": 0.08561394038879618,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.08561394038879618,
        "precision": 0.07744137205663515,
        "recall": 0.1142578125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0029731607368326117,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0029731607368326117,
        "precision": 0.0025438803066872816,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.05962295015269528,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.05962295015269528,
        "precision": 0.055743299627102325,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.05108017395300031,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.05108017395300031,
        "precision": 0.04638207794763803,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0006014762465741028,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0006014762465741028,
        "precision": 0.0003509577250056322,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.228515625,
        "f1": 0.19763320238227214,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.19763320238227214,
        "precision": 0.18921630905192413,
        "recall": 0.228515625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003434562115650093,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.003434562115650093,
        "precision": 0.002947938993873526,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0888671875,
        "f1": 0.07160325896712424,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.07160325896712424,
        "precision": 0.06651511946989225,
        "recall": 0.0888671875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00392578125,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.00392578125,
        "precision": 0.003916114267676768,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007506848190064428,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.0007506848190064428,
        "precision": 0.0005406737391467467,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00027160693133858896,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.00027160693133858896,
        "precision": 0.0001534061884166828,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001691021182672764,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.001691021182672764,
        "precision": 0.0014975381501339162,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009785514256619144,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.0009785514256619144,
        "precision": 0.0009775579765545362,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.5201612903225806e-06,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 2.5201612903225806e-06,
        "precision": 1.2617086563307494e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019551179846938774,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.0019551179846938774,
        "precision": 0.0019541225102145047,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000978505907960199,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.000978505907960199,
        "precision": 0.000977535171812749,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.166015625,
        "f1": 0.13591044372294372,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.13591044372294372,
        "precision": 0.12538407230790044,
        "recall": 0.166015625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0019730976227943452,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.0019730976227943452,
        "precision": 0.001963194019104462,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.822162426614481e-06,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 3.822162426614481e-06,
        "precision": 1.914828431372549e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.06836480034722223,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.06836480034722223,
        "precision": 0.06235515690651261,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00018033904752654754,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.00018033904752654754,
        "precision": 9.904934914407989e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.0494437591374269,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.0494437591374269,
        "precision": 0.04340682133220047,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 6.240015974440894e-06,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 6.240015974440894e-06,
        "precision": 3.1300080128205127e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.006000726162721283,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.006000726162721283,
        "precision": 0.005615724108469166,
        "recall": 0.015625
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.030229364291572365,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.030229364291572365,
        "precision": 0.026978769978106134,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0005348392899917056,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.0005348392899917056,
        "precision": 0.00030412682582964246,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.032104405042845896,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.032104405042845896,
        "precision": 0.028034928271535933,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009790473918575063,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.0009790473918575063,
        "precision": 0.0009778065286624204,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.000597961562300888,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.000597961562300888,
        "precision": 0.0003377365348943542,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.0834488590836247,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.0834488590836247,
        "precision": 0.0778198098907611,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.937624007936508e-06,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 1.937624007936508e-06,
        "precision": 9.6977408142999e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00022810270999795132,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.00022810270999795132,
        "precision": 0.00011965036366452072,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001226246101708761,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.001226246101708761,
        "precision": 0.0011100813747033965,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.13173508812535717,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.13173508812535717,
        "precision": 0.1247520392760107,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.306640625,
        "f1": 0.2644696871538577,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2644696871538577,
        "precision": 0.2526348671162306,
        "recall": 0.306640625
      },
      {
        "accuracy": 0.0,
        "f1": 0.0,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0,
        "precision": 0.0,
        "recall": 0.0
      },
      {
        "accuracy": 0.2470703125,
        "f1": 0.214855988153194,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.214855988153194,
        "precision": 0.2052140247086536,
        "recall": 0.2470703125
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.011670863565244327,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.011670863565244327,
        "precision": 0.010166281907288448,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00161251617080944,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.00161251617080944,
        "precision": 0.0010085494970005838,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.03230116394931935,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.03230116394931935,
        "precision": 0.03080320586198622,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.3251953125,
        "f1": 0.27294351156655844,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.27294351156655844,
        "precision": 0.25554119274822396,
        "recall": 0.3251953125
      },
      {
        "accuracy": 0.0576171875,
        "f1": 0.044305799348647645,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.044305799348647645,
        "precision": 0.0408350140298482,
        "recall": 0.0576171875
      },
      {
        "accuracy": 0.1435546875,
        "f1": 0.11634385730717725,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.11634385730717725,
        "precision": 0.10748168796264498,
        "recall": 0.1435546875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0031152251664130523,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0031152251664130523,
        "precision": 0.0024497905179092236,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.24609375,
        "f1": 0.2020119095314408,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.2020119095314408,
        "precision": 0.18715534767909356,
        "recall": 0.24609375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0012054557587942312,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0012054557587942312,
        "precision": 0.0007704239528294899,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.01856037729074142,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.01856037729074142,
        "precision": 0.017236384664259856,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.0771484375,
        "f1": 0.055243849456531734,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.055243849456531734,
        "precision": 0.05035810304005205,
        "recall": 0.0771484375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00019750949100112486,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00019750949100112486,
        "precision": 0.00010960667698948949,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.27734375,
        "f1": 0.24199395721803174,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.24199395721803174,
        "precision": 0.2329252881150296,
        "recall": 0.27734375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002041225143903715,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.002041225143903715,
        "precision": 0.001720587505268106,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0908203125,
        "f1": 0.07346596923752854,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.07346596923752854,
        "precision": 0.06948025702263988,
        "recall": 0.0908203125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.01146556712962963,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.01146556712962963,
        "precision": 0.011268028846153846,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010566663500506585,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.0010566663500506585,
        "precision": 0.0010182430326656526,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016824057228295118,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.0016824057228295118,
        "precision": 0.0014218191244502467,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0002696538139485387,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.0002696538139485387,
        "precision": 0.00014905090374188424,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.95508008008008e-06,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 1.95508008008008e-06,
        "precision": 9.785195390781562e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.6251680107526884e-06,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 2.6251680107526884e-06,
        "precision": 1.314350605652759e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.959002006018054e-06,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 1.959002006018054e-06,
        "precision": 9.80484437751004e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.162109375,
        "f1": 0.12437065972222222,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.12437065972222222,
        "precision": 0.11107531605706975,
        "recall": 0.162109375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.922367125984252e-06,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 1.922367125984252e-06,
        "precision": 9.621305418719211e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1183568329718005e-06,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 2.1183568329718005e-06,
        "precision": 1.060328447339848e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.739305750350631e-06,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 2.739305750350631e-06,
        "precision": 1.3715765449438202e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.06941738816738816,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.06941738816738816,
        "precision": 0.05941185008567822,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000246476898923445,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.000246476898923445,
        "precision": 0.00014067846449957228,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.064453125,
        "f1": 0.039443352725539324,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.039443352725539324,
        "precision": 0.0338287986241888,
        "recall": 0.064453125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 4.137976694915254e-06,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 4.137976694915254e-06,
        "precision": 2.0733811040339702e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.01953125,
        "f1": 0.009456910957992618,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.009456910957992618,
        "precision": 0.008895834452736541,
        "recall": 0.01953125
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.00885898063913006,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.00885898063913006,
        "precision": 0.0069520637087472,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0020214036327317574,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.0020214036327317574,
        "precision": 0.0016948641237695369,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0419921875,
        "f1": 0.025140855715074063,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.025140855715074063,
        "precision": 0.022002693727954145,
        "recall": 0.0419921875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.774325284090909e-06,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 2.774325284090909e-06,
        "precision": 1.3891358463726885e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00037421819689414227,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.00037421819689414227,
        "precision": 0.0002200964725378788,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.111328125,
        "f1": 0.08149694272741147,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.08149694272741147,
        "precision": 0.07197932447066963,
        "recall": 0.111328125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.918590373280943e-06,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 1.918590373280943e-06,
        "precision": 9.602384464110128e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.759572072072072e-05,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 1.759572072072072e-05,
        "precision": 8.877840909090909e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00035636926270027217,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.00035636926270027217,
        "precision": 0.000188138151584407,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.05000775049603175,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.05000775049603175,
        "precision": 0.04714355468749999,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.03481729261572349,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.03481729261572349,
        "precision": 0.03219125171200676,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 8.138020833333333e-05,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 8.138020833333333e-05,
        "precision": 4.245923913043478e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.03522242259168922,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.03522242259168922,
        "precision": 0.03359884768397535,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006884968880083254,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.006884968880083254,
        "precision": 0.006272289857356719,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0546875,
        "f1": 0.04700219192406692,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.04700219192406692,
        "precision": 0.04545741146896223,
        "recall": 0.0546875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.00202439044426919,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.00202439044426919,
        "precision": 0.001501608706623745,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0009168521121635499,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0009168521121635499,
        "precision": 0.0006386669346253365,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.03528182814080181,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.03528182814080181,
        "precision": 0.03346080910754799,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0008630475427350427,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.0008630475427350427,
        "precision": 0.0006052068366858238,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0003905896278429173,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0003905896278429173,
        "precision": 0.00021215650185829927,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002054847622398957,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.002054847622398957,
        "precision": 0.0016906266572784085,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0010000729730636035,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.0010000729730636035,
        "precision": 0.0006814131494237993,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.072265625,
        "f1": 0.06205532548819966,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.06205532548819966,
        "precision": 0.05933123659308135,
        "recall": 0.072265625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.000443046812768355,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.000443046812768355,
        "precision": 0.0002552172558543621,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00010477892065188351,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.00010477892065188351,
        "precision": 5.524591378726287e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.04547799009763584,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.04547799009763584,
        "precision": 0.04350641848205715,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.004985759584481175,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.004985759584481175,
        "precision": 0.004633246527777778,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.043007244130291,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.043007244130291,
        "precision": 0.03987318492077063,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.13671875,
        "f1": 0.12009176345122285,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.12009176345122285,
        "precision": 0.11654838000607551,
        "recall": 0.13671875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0017067456473652842,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.0017067456473652842,
        "precision": 0.0015050843584065885,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 4.99485856544956e-05,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 4.99485856544956e-05,
        "precision": 2.5571127073459715e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.044921875,
        "f1": 0.02831339845280014,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.02831339845280014,
        "precision": 0.02482696717366744,
        "recall": 0.044921875
      },
      {
        "accuracy": 0.1748046875,
        "f1": 0.13058993776767214,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.13058993776767214,
        "precision": 0.11806569257310295,
        "recall": 0.1748046875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00032859178459119495,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.00032859178459119495,
        "precision": 0.0001968503937007874,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.08984375,
        "f1": 0.06449907856671837,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.06449907856671837,
        "precision": 0.05744942449044011,
        "recall": 0.08984375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0020142467309397162,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0020142467309397162,
        "precision": 0.0016046288456578741,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.3017578125,
        "f1": 0.23956021543050493,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.23956021543050493,
        "precision": 0.21888479128038527,
        "recall": 0.3017578125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00031827255603706934,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.00031827255603706934,
        "precision": 0.00018253122909545484,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000898352949134199,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.000898352949134199,
        "precision": 0.0006221064814814814,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002002492289941339,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.002002492289941339,
        "precision": 0.0016116305618183947,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.162109375,
        "f1": 0.1293609764801171,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.1293609764801171,
        "precision": 0.11999175184053884,
        "recall": 0.162109375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.005835919916785122,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.005835919916785122,
        "precision": 0.005490438851321778,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.263671875,
        "f1": 0.20778614831349207,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.20778614831349207,
        "precision": 0.18872810132575757,
        "recall": 0.263671875
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0026334302403026428,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.0026334302403026428,
        "precision": 0.002012295510886459,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004299308471018418,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0004299308471018418,
        "precision": 0.0002639507173883164,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1171875,
        "f1": 0.08744558198895522,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.08744558198895522,
        "precision": 0.07985733405603336,
        "recall": 0.1171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00032800256776789496,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00032800256776789496,
        "precision": 0.0001965549459287532,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.091796875,
        "f1": 0.06266596284791404,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.06266596284791404,
        "precision": 0.05680719690881135,
        "recall": 0.091796875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00015373537168695707,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.00015373537168695707,
        "precision": 7.993030394524959e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0009748642295459851,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0009748642295459851,
        "precision": 0.000618849105819909,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 6.103515625e-05,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 6.103515625e-05,
        "precision": 3.150201612903226e-05,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.953125e-06,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 1.953125e-06,
        "precision": 9.7754004004004e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00024637276785714285,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.00024637276785714285,
        "precision": 0.0001406262769695979,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.004349054856661223,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.004349054856661223,
        "precision": 0.003160720131073654,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.003257151741293532,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.003257151741293532,
        "precision": 0.002930660171812749,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 7.768334847567131e-05,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 7.768334847567131e-05,
        "precision": 4.034576215505913e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0019551078680203047,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.0019551078680203047,
        "precision": 0.0019541174415650406,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.083984375,
        "f1": 0.06170141336413951,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.06170141336413951,
        "precision": 0.05571095300099206,
        "recall": 0.083984375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.005210314190331305,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.005210314190331305,
        "precision": 0.004883803934010152,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.0828925124737395,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.0828925124737395,
        "precision": 0.07561746115212913,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0014742337740384615,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.0014742337740384615,
        "precision": 0.0013068010265700483,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.6976864640883977e-06,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 2.6976864640883977e-06,
        "precision": 1.3507088520055326e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.982144805761676e-05,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 6.982144805761676e-05,
        "precision": 3.6114953942603655e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.022823410399222487,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.022823410399222487,
        "precision": 0.020028479549963923,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.844734251968504e-06,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 3.844734251968504e-06,
        "precision": 1.9261587771203157e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006444671477961931,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.006444671477961931,
        "precision": 0.006189042116026755,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.08062467316029248,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.08062467316029248,
        "precision": 0.07703153233288806,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0003559995103113709,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.0003559995103113709,
        "precision": 0.0002021977805838072,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.011239510995370369,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.011239510995370369,
        "precision": 0.009384786977685867,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002263433283025568,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.002263433283025568,
        "precision": 0.0018288401878841498,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0004090523475745438,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.0004090523475745438,
        "precision": 0.00022974221257225568,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.16052820777198862,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.16052820777198862,
        "precision": 0.15101496268488457,
        "recall": 0.189453125
      },
      {
        "accuracy": 0.001953125,
        "f1": 4.268716449386503e-05,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 4.268716449386503e-05,
        "precision": 2.1777477732529017e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.001987450131028637,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.001987450131028637,
        "precision": 0.0016561698188456335,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0007477217502951342,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0007477217502951342,
        "precision": 0.0004628202099029247,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.020096093716842796,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.020096093716842796,
        "precision": 0.017446832766652674,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.0732421875,
        "f1": 0.047199532275973545,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.047199532275973545,
        "precision": 0.0421631940640099,
        "recall": 0.0732421875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.0001953125,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0001953125,
        "precision": 0.00010850694444444444,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.2021484375,
        "f1": 0.14918176658411034,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.14918176658411034,
        "precision": 0.1325497690243784,
        "recall": 0.2021484375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0015338866496886082,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0015338866496886082,
        "precision": 0.0009158186875028903,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.09620928142527407,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.09620928142527407,
        "precision": 0.08718011947776999,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0007516688209839806,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0007516688209839806,
        "precision": 0.00043376262922932335,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008283319100033738,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0008283319100033738,
        "precision": 0.0004984242904589372,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1689453125,
        "f1": 0.13332092711975524,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.13332092711975524,
        "precision": 0.12335731759559884,
        "recall": 0.1689453125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0015907043451850436,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.0015907043451850436,
        "precision": 0.0009422907324079077,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.002758182778560584,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002758182778560584,
        "precision": 0.0023862429175949464,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.1640625,
        "f1": 0.11813641353795307,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.11813641353795307,
        "precision": 0.10587936848387257,
        "recall": 0.1640625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.000805063973555224,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.000805063973555224,
        "precision": 0.0004900052150688463,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0021291507231989103,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0021291507231989103,
        "precision": 0.002043483548648996,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1044921875,
        "f1": 0.07936792009036403,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.07936792009036403,
        "precision": 0.07292915701247321,
        "recall": 0.1044921875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00025994124964203894,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.00025994124964203894,
        "precision": 0.0001439681491557681,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.043267524321387696,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.043267524321387696,
        "precision": 0.037270123744213145,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00029306712092066464,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.00029306712092066464,
        "precision": 0.00015883723948981302,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.001802470441523795,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.001802470441523795,
        "precision": 0.0014584280846590327,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00040537176215628895,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.00040537176215628895,
        "precision": 0.0002515544337760516,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9909531090723753e-06,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 1.9909531090723753e-06,
        "precision": 9.964923469387756e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002327857720758206,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.002327857720758206,
        "precision": 0.0019782999343665314,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006716689204208654,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.0006716689204208654,
        "precision": 0.0004079151252596054,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.4944125159642403e-06,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 2.4944125159642403e-06,
        "precision": 1.2488011508951408e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.276369463869464e-06,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 2.276369463869464e-06,
        "precision": 1.1395128354725787e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9649144869215293e-06,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 1.9649144869215293e-06,
        "precision": 9.834466263846928e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0712890625,
        "f1": 0.05174110739119883,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 0.05174110739119883,
        "precision": 0.04641146796908516,
        "recall": 0.0712890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0001523937749130693,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0001523937749130693,
        "precision": 8.245809188741722e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0537109375,
        "f1": 0.03874737479358646,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.03874737479358646,
        "precision": 0.034800337117770405,
        "recall": 0.0537109375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.953694331983806e-06,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 3.953694331983806e-06,
        "precision": 1.9808569979716024e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.9124316098683678e-05,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 1.9124316098683678e-05,
        "precision": 9.636704215301494e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02755519550676136,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.02755519550676136,
        "precision": 0.024799399734433902,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.8856943862832683e-05,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 1.8856943862832683e-05,
        "precision": 9.474285001174537e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.2904848937854957e-05,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 2.2904848937854957e-05,
        "precision": 1.1561183347147396e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.007510447283532978,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.007510447283532978,
        "precision": 0.00720717826971854,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.026124453018345817,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.026124453018345817,
        "precision": 0.02227491014176225,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0009654321075579651,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.0009654321075579651,
        "precision": 0.0006140908235272467,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1025390625,
        "f1": 0.08115748355263158,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.08115748355263158,
        "precision": 0.07396150399080087,
        "recall": 0.1025390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.35316265060241e-06,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 2.35316265060241e-06,
        "precision": 1.1780006031363087e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00035408840126158826,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.00035408840126158826,
        "precision": 0.00020970171993499458,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.02437454544388138,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.02437454544388138,
        "precision": 0.021128884417427225,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.922367125984252e-06,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 1.922367125984252e-06,
        "precision": 9.621305418719211e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.000660945942177833,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.000660945942177833,
        "precision": 0.000414393159897073,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014883555375307515,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.0014883555375307515,
        "precision": 0.0013139549803102791,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.021584634055979653,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.021584634055979653,
        "precision": 0.02053928029624147,
        "recall": 0.03125
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.09288117062021613,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.09288117062021613,
        "precision": 0.08313944798576789,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.5837155963302754e-06,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 3.5837155963302754e-06,
        "precision": 1.7951516544117647e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.087890625,
        "f1": 0.061554799790329684,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.061554799790329684,
        "precision": 0.05544125335385101,
        "recall": 0.087890625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0033904635012919895,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0033904635012919895,
        "precision": 0.0026764510856155934,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.23828125,
        "f1": 0.1761545854319292,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.1761545854319292,
        "precision": 0.15701423047183616,
        "recall": 0.23828125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0039962004211031195,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0039962004211031195,
        "precision": 0.0036457945880683075,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0014834449404761904,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0014834449404761904,
        "precision": 0.001280690704042457,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.2939453125,
        "f1": 0.23990856862207602,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.23990856862207602,
        "precision": 0.22287920317274637,
        "recall": 0.2939453125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002523934961844409,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.002523934961844409,
        "precision": 0.0022676778586556813,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1416015625,
        "f1": 0.1164977058531746,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.1164977058531746,
        "precision": 0.10859801277281746,
        "recall": 0.1416015625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.009802418058617108,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.009802418058617108,
        "precision": 0.008338489496343396,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.006937541303588099,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.006937541303588099,
        "precision": 0.0062388738721274005,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0009382248171468675,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0009382248171468675,
        "precision": 0.0005771837205811888,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1005859375,
        "f1": 0.07579208520362249,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.07579208520362249,
        "precision": 0.07003318675681958,
        "recall": 0.1005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0003279531185139062,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0003279531185139062,
        "precision": 0.00019653015897755613,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.06640625,
        "f1": 0.042432918686645046,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.042432918686645046,
        "precision": 0.0380816658099373,
        "recall": 0.06640625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0007317264635211883,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.0007317264635211883,
        "precision": 0.0005302529322506562,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002313524823862403,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.002313524823862403,
        "precision": 0.0018090035912682301,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 1.0873488833718178e-05,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 1.0873488833718178e-05,
        "precision": 5.455783421401801e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006696241751981684,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.0006696241751981684,
        "precision": 0.0004976403554918336,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001493182121266003,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.001493182121266003,
        "precision": 0.0013164256314839875,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0014918624196639705,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.0014918624196639705,
        "precision": 0.0013156614627998233,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.001953125,
        "f1": 5.9310079507566044e-05,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 5.9310079507566044e-05,
        "precision": 3.0478833844688954e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.402367773677737e-06,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 2.402367773677737e-06,
        "precision": 1.2026631773399015e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 6.925975177304964e-06,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 6.925975177304964e-06,
        "precision": 3.4753113879003557e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.080078125,
        "f1": 0.05471999246413309,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.05471999246413309,
        "precision": 0.04797621639116173,
        "recall": 0.080078125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00015829248366013073,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.00015829248366013073,
        "precision": 8.250165629237026e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.052105641754079245,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.052105641754079245,
        "precision": 0.0483073621257215,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 5.2787162162162165e-06,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 5.2787162162162165e-06,
        "precision": 2.646510840108401e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0003185137445263321,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.0003185137445263321,
        "precision": 0.000169144206363435,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0322265625,
        "f1": 0.021317610378426652,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.021317610378426652,
        "precision": 0.018682958209325397,
        "recall": 0.0322265625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 0.00048828125,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.00048828125,
        "precision": 0.0003255208333333333,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0966796875,
        "f1": 0.0664624739416915,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.0664624739416915,
        "precision": 0.058422394426980016,
        "recall": 0.0966796875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0001168526455808454,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.0001168526455808454,
        "precision": 6.201761349346077e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.00675340051864063,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.00675340051864063,
        "precision": 0.006073715612279281,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0006345833562121506,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.0006345833562121506,
        "precision": 0.0004009646748320746,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.008034069399710889,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.008034069399710889,
        "precision": 0.007361225285009406,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.444461827284105e-06,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 2.444461827284105e-06,
        "precision": 1.2237625313283207e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0003032456633530852,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.0003032456633530852,
        "precision": 0.00015899369644774058,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.02759181293849366,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.02759181293849366,
        "precision": 0.024006287782687437,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9204768928220257e-06,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 1.9204768928220257e-06,
        "precision": 9.61183562992126e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0005554991883116883,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.0005554991883116883,
        "precision": 0.00033397706496848226,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.095285261489699e-06,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 3.095285261489699e-06,
        "precision": 1.5500992063492063e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.01704566039970026,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.01704566039970026,
        "precision": 0.015900210782489134,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.01385247237676003,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.01385247237676003,
        "precision": 0.013216750956807,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.8365451752548527e-05,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 2.8365451752548527e-05,
        "precision": 1.4351910425101214e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.015625,
        "f1": 0.012468114567723941,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.012468114567723941,
        "precision": 0.011956989504754045,
        "recall": 0.015625
      },
      {
        "accuracy": 0.072265625,
        "f1": 0.04737011562940067,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.04737011562940067,
        "precision": 0.041666568930272825,
        "recall": 0.072265625
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.010069466987981465,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.010069466987981465,
        "precision": 0.009326206570397273,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.03125,
        "f1": 0.01855349220467194,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.01855349220467194,
        "precision": 0.016208852332145588,
        "recall": 0.03125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.008941359747023809,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.008941359747023809,
        "precision": 0.00857379559232757,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.001953125,
        "f1": 4.4631791966919765e-05,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 4.4631791966919765e-05,
        "precision": 2.2788874969067064e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1376953125,
        "f1": 0.11029560829197144,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.11029560829197144,
        "precision": 0.10210756925792357,
        "recall": 0.1376953125
      },
      {
        "accuracy": 0.001953125,
        "f1": 2.7246518578484282e-05,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 2.7246518578484282e-05,
        "precision": 1.3783372930971572e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.068359375,
        "f1": 0.04674789186507936,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.04674789186507936,
        "precision": 0.0403399904132326,
        "recall": 0.068359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 7.865801656920078e-05,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 7.865801656920078e-05,
        "precision": 4.007183304482054e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.006395252871772243,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.006395252871772243,
        "precision": 0.006153687645792251,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006806974331076724,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.0006806974331076724,
        "precision": 0.0005032411115407277,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0634765625,
        "f1": 0.04370074178782818,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.04370074178782818,
        "precision": 0.03844467995597467,
        "recall": 0.0634765625
      },
      {
        "accuracy": 0.017578125,
        "f1": 0.011562596564884606,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.011562596564884606,
        "precision": 0.010431997318158031,
        "recall": 0.017578125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00018571370385886513,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.00018571370385886513,
        "precision": 9.585005397709794e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.1943359375,
        "f1": 0.16571590979549963,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.16571590979549963,
        "precision": 0.15530943830950977,
        "recall": 0.1943359375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010140894725114927,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.0010140894725114927,
        "precision": 0.000995655836298592,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.2600806451612903e-05,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 1.2600806451612903e-05,
        "precision": 6.3413149350649355e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.989890947150445e-05,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 6.989890947150445e-05,
        "precision": 3.615378443043884e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.0217790645781961,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.0217790645781961,
        "precision": 0.018720914262943075,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0478515625,
        "f1": 0.03362675385730515,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.03362675385730515,
        "precision": 0.03155679759995939,
        "recall": 0.0478515625
      },
      {
        "accuracy": 0.001953125,
        "f1": 8.355376546591791e-06,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 8.355376546591791e-06,
        "precision": 4.186662345135584e-06,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.05859375,
        "f1": 0.04032274080933833,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.04032274080933833,
        "precision": 0.03623186980120574,
        "recall": 0.05859375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0011264993686868686,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0011264993686868686,
        "precision": 0.001056281887755102,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0986328125,
        "f1": 0.0677319754840828,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.0677319754840828,
        "precision": 0.05930308639295249,
        "recall": 0.0986328125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0005960233019299945,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0005960233019299945,
        "precision": 0.00033897133714711695,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0005301339285714286,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.0005301339285714286,
        "precision": 0.0003192608173076923,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.1298828125,
        "f1": 0.09632942184305375,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.09632942184305375,
        "precision": 0.08668117770900974,
        "recall": 0.1298828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002483792648780313,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.002483792648780313,
        "precision": 0.0022482897348087916,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.1015625,
        "f1": 0.07613420108537296,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.07613420108537296,
        "precision": 0.06943306231815825,
        "recall": 0.1015625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.007091170228337236,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.007091170228337236,
        "precision": 0.006282552083333333,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.1181640625,
        "f1": 0.08437347971039377,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.08437347971039377,
        "precision": 0.07633943243680265,
        "recall": 0.1181640625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003948184593040462,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.003948184593040462,
        "precision": 0.0036184905575908826,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0008390016690797941,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.0008390016690797941,
        "precision": 0.000533533738727727,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.000394432261208577,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.000394432261208577,
        "precision": 0.0002460479736328125,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.041015625,
        "f1": 0.02493373703162306,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.02493373703162306,
        "precision": 0.02259296440255064,
        "recall": 0.041015625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.00019771191646191647,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.00019771191646191647,
        "precision": 0.0001097081283312833,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0013687269465577552,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.0013687269465577552,
        "precision": 0.0008353743103312581,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006535139767932489,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.0006535139767932489,
        "precision": 0.0004895189717997466,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.03238813735692e-06,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 2.03238813735692e-06,
        "precision": 1.0172526041666667e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00204461608270202,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.00204461608270202,
        "precision": 0.00200098619941718,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0009785554846938776,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.0009785554846938776,
        "precision": 0.0009775600102145045,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.559796854521625e-06,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 2.559796854521625e-06,
        "precision": 1.2815780839895013e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.0956276824034335e-06,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 2.0956276824034335e-06,
        "precision": 1.048939312567132e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.0135309278350516e-06,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 2.0135309278350516e-06,
        "precision": 1.0078044375644994e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0380859375,
        "f1": 0.023269593895028234,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.023269593895028234,
        "precision": 0.020175194414407974,
        "recall": 0.0380859375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.211919592298981e-06,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 2.211919592298981e-06,
        "precision": 1.1072137188208617e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.023324789077166792,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.023324789077166792,
        "precision": 0.02047661215995799,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.2825630252100842e-06,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 3.2825630252100842e-06,
        "precision": 1.6440446127946127e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.715361577474642e-05,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 6.715361577474642e-05,
        "precision": 3.4700369910895395e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.021484375,
        "f1": 0.01367594739491275,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.01367594739491275,
        "precision": 0.012174017902327933,
        "recall": 0.021484375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 3.322742377720146e-05,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 3.322742377720146e-05,
        "precision": 1.674910128682409e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.09375,
        "f1": 0.06586998613365799,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.06586998613365799,
        "precision": 0.057666438379329006,
        "recall": 0.09375
      },
      {
        "accuracy": 0.001953125,
        "f1": 9.512891433747412e-05,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 9.512891433747412e-05,
        "precision": 4.9890761017410234e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.007947948483609217,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.007947948483609217,
        "precision": 0.007589462550037054,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.0302734375,
        "f1": 0.016899561124908608,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.016899561124908608,
        "precision": 0.014647333750575017,
        "recall": 0.0302734375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002127037976068052,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.002127037976068052,
        "precision": 0.001795959559177922,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.2790256709451573e-06,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 2.2790256709451573e-06,
        "precision": 1.1408440420560747e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0005041603150406504,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0005041603150406504,
        "precision": 0.00033352544398907103,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.014712238871490467,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.014712238871490467,
        "precision": 0.013240917611034797,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 1.9110812133072406e-06,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 1.9110812133072406e-06,
        "precision": 9.564764936336925e-07,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00047826749659709623,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.00047826749659709623,
        "precision": 0.0002888900465992081,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002576385468105119,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.002576385468105119,
        "precision": 0.0023271808516507767,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.1650390625,
        "f1": 0.14051528783488076,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.14051528783488076,
        "precision": 0.13347481511544013,
        "recall": 0.1650390625
      },
      {
        "accuracy": 0.236328125,
        "f1": 0.2112152956635378,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.2112152956635378,
        "precision": 0.20357561383928574,
        "recall": 0.236328125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0011591117730815348,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.0011591117730815348,
        "precision": 0.0010731166004603505,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.21875,
        "f1": 0.19417190136794626,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.19417190136794626,
        "precision": 0.18679426211541011,
        "recall": 0.21875
      },
      {
        "accuracy": 0.0224609375,
        "f1": 0.0159042604197828,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.0159042604197828,
        "precision": 0.014596598090300469,
        "recall": 0.0224609375
      },
      {
        "accuracy": 0.29296875,
        "f1": 0.25883755364691163,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.25883755364691163,
        "precision": 0.2471355557305907,
        "recall": 0.29296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0004872806010170907,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.0004872806010170907,
        "precision": 0.00026946346629407557,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.028452225693601486,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.028452225693601486,
        "precision": 0.02731193911524694,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.115234375,
        "f1": 0.07812807594542275,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.07812807594542275,
        "precision": 0.06907282306452228,
        "recall": 0.115234375
      },
      {
        "accuracy": 0.060546875,
        "f1": 0.042227868844547996,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.042227868844547996,
        "precision": 0.03800869438294353,
        "recall": 0.060546875
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.056822407420468145,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.056822407420468145,
        "precision": 0.05249352671175727,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.001870414046121593,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001870414046121593,
        "precision": 0.0012685738357843136,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0751953125,
        "f1": 0.050951074282301306,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.050951074282301306,
        "precision": 0.04562788103304832,
        "recall": 0.0751953125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002030211469833835,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.002030211469833835,
        "precision": 0.0015040759734291443,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0556640625,
        "f1": 0.04586011462039422,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.04586011462039422,
        "precision": 0.04368714677526595,
        "recall": 0.0556640625
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.03208881542204158,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.03208881542204158,
        "precision": 0.02897075269736659,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006816537587906164,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0006816537587906164,
        "precision": 0.0005037967924315115,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001689976336567732,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.001689976336567732,
        "precision": 0.0014965889206274552,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0810546875,
        "f1": 0.06523462492792802,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.06523462492792802,
        "precision": 0.061004705536490275,
        "recall": 0.0810546875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.009495219248971856,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.009495219248971856,
        "precision": 0.009305635835156457,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00027122536925954595,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.00027122536925954595,
        "precision": 0.00014357793898809522,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0001463917220113852,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.0001463917220113852,
        "precision": 7.704437756147541e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.033203125,
        "f1": 0.024734561436589475,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.024734561436589475,
        "precision": 0.02300226546785234,
        "recall": 0.033203125
      },
      {
        "accuracy": 0.03515625,
        "f1": 0.02729995870892656,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.02729995870892656,
        "precision": 0.02589795865417504,
        "recall": 0.03515625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.001047989143150241,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.001047989143150241,
        "precision": 0.001013482749925284,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.01209247815693128,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.01209247815693128,
        "precision": 0.011242185676353874,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.0234375,
        "f1": 0.011277378527525932,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.011277378527525932,
        "precision": 0.008938028842085046,
        "recall": 0.0234375
      },
      {
        "accuracy": 0.0283203125,
        "f1": 0.020020557309420192,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.020020557309420192,
        "precision": 0.018929344198616943,
        "recall": 0.0283203125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.00186942474186769,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.00186942474186769,
        "precision": 0.0012164755817099565,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0185546875,
        "f1": 0.016194661458333332,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.016194661458333332,
        "precision": 0.015438988095238096,
        "recall": 0.0185546875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00030305758717494085,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.00030305758717494085,
        "precision": 0.00016946104795361646,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.056640625,
        "f1": 0.0393594713497879,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.0393594713497879,
        "precision": 0.035359659930290874,
        "recall": 0.056640625
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006677350427350427,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.0006677350427350427,
        "precision": 0.0004966998922413793,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002570163690234328,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.002570163690234328,
        "precision": 0.001961735187339615,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00034466840024103006,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.00034466840024103006,
        "precision": 0.00019663755088195387,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0024694428269496204,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.0024694428269496204,
        "precision": 0.002243078989383287,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0439453125,
        "f1": 0.0313284464745882,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.0313284464745882,
        "precision": 0.029062021292465923,
        "recall": 0.0439453125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006953418703007519,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.0006953418703007519,
        "precision": 0.000419921875,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001832734217294903,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.001832734217294903,
        "precision": 0.001572936314347367,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.029296875,
        "f1": 0.02248574495888949,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.02248574495888949,
        "precision": 0.021273886057009535,
        "recall": 0.029296875
      },
      {
        "accuracy": 0.076171875,
        "f1": 0.05736943872959081,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.05736943872959081,
        "precision": 0.05387953603681321,
        "recall": 0.076171875
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.010366630179085894,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.010366630179085894,
        "precision": 0.010112851135779671,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006367207050800802,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.0006367207050800802,
        "precision": 0.0003846280731105067,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0004673438910516813,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.0004673438910516813,
        "precision": 0.00027159112943699244,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0166015625,
        "f1": 0.010994203501146835,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.010994203501146835,
        "precision": 0.010203299694152835,
        "recall": 0.0166015625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0034347480195354558,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.0034347480195354558,
        "precision": 0.0030283361915650407,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.4848918575063615e-06,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 2.4848918575063615e-06,
        "precision": 1.244028662420382e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.006140351859148875,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.006140351859148875,
        "precision": 0.0060231159011044175,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.1123046875,
        "f1": 0.07774892359505604,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.07774892359505604,
        "precision": 0.06844447192347583,
        "recall": 0.1123046875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.008380940755208333,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.008380940755208333,
        "precision": 0.008179729250847237,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.123046875,
        "f1": 0.09521174355158729,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.09521174355158729,
        "precision": 0.08567682222036542,
        "recall": 0.123046875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0009928468755333675,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.0009928468755333675,
        "precision": 0.0009847562664581254,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0009765625,
        "f1": 3.6851415094339623e-06,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 3.6851415094339623e-06,
        "precision": 1.846053875236295e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.1904296875,
        "f1": 0.1588834993131868,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.1588834993131868,
        "precision": 0.147900390625,
        "recall": 0.1904296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.0422177636298424e-05,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 6.0422177636298424e-05,
        "precision": 3.108373814480685e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.03387804903429903,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.03387804903429903,
        "precision": 0.031182528409090908,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 6.711769759450172e-06,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 6.711769759450172e-06,
        "precision": 3.367456896551724e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.005551252477391638,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.005551252477391638,
        "precision": 0.0050225369828255225,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.1552734375,
        "f1": 0.13339188453655618,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.13339188453655618,
        "precision": 0.1273748024252231,
        "recall": 0.1552734375
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0006925827516920473,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.0006925827516920473,
        "precision": 0.0005094519641560564,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0361328125,
        "f1": 0.022602919626973902,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.022602919626973902,
        "precision": 0.01982412788211549,
        "recall": 0.0361328125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004359458017658809,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.004359458017658809,
        "precision": 0.0038348279516133375,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0014866866333142935,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.0014866866333142935,
        "precision": 0.0012584371104878917,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.001953125,
        "f1": 3.752282089691976e-05,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 3.752282089691976e-05,
        "precision": 1.9091256204658265e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.000359909188034188,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.000359909188034188,
        "precision": 0.00021270054590534742,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.00390625,
        "f1": 6.773450584555979e-05,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 6.773450584555979e-05,
        "precision": 3.428864706433344e-05,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.03742819393382353,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.03742819393382353,
        "precision": 0.034633251872947454,
        "recall": 0.0458984375
      },
      {
        "accuracy": 0.052734375,
        "f1": 0.04046293452491555,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.04046293452491555,
        "precision": 0.0378506156557547,
        "recall": 0.052734375
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.794170243204578e-06,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 2.794170243204578e-06,
        "precision": 1.399086676217765e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.037109375,
        "f1": 0.029201521859484315,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.029201521859484315,
        "precision": 0.027236012582239944,
        "recall": 0.037109375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.005253977840170096,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.005253977840170096,
        "precision": 0.0045953743579876995,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.048828125,
        "f1": 0.041561509605530934,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.041561509605530934,
        "precision": 0.04021740932070059,
        "recall": 0.048828125
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0010099331076724694,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.0010099331076724694,
        "precision": 0.0009934791014460345,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.1234862444104865,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.1234862444104865,
        "precision": 0.11717828058584683,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0001329860223689991,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.0001329860223689991,
        "precision": 7.057968451052296e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0390625,
        "f1": 0.029439836090686275,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.029439836090686275,
        "precision": 0.027520486924870968,
        "recall": 0.0390625
      },
      {
        "accuracy": 0.001953125,
        "f1": 6.965188419117647e-05,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 6.965188419117647e-05,
        "precision": 3.57347055460263e-05,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0010890961858261235,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0010890961858261235,
        "precision": 0.0010338272781392041,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.00037614016748925284,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.00037614016748925284,
        "precision": 0.00022088593451369528,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00011604042080011023,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.00011604042080011023,
        "precision": 6.027817730357054e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0498046875,
        "f1": 0.04212948047998488,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.04212948047998488,
        "precision": 0.040760096219618146,
        "recall": 0.0498046875
      },
      {
        "accuracy": 0.0029296875,
        "f1": 7.076173050996099e-05,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 7.076173050996099e-05,
        "precision": 3.597136132606999e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0006529583742230945,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0006529583742230945,
        "precision": 0.0004892405451866405,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.046875,
        "f1": 0.038121021221705007,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.038121021221705007,
        "precision": 0.03642833435457516,
        "recall": 0.046875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.007870926816239316,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.007870926816239316,
        "precision": 0.007537158611847868,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0458984375,
        "f1": 0.036134736761083745,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.036134736761083745,
        "precision": 0.03307856153660886,
        "recall": 0.0458984375
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}