{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 9.443621397018433,
  "kg_co2_emissions": 0.000337082240314049,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.632958984375,
        "ap": 0.11299763453524037,
        "ap_weighted": 0.11299763453524037,
        "f1": 0.4877361957011659,
        "f1_weighted": 0.7144060764076728,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.632958984375,
        "scores_per_experiment": [
          {
            "accuracy": 0.7099609375,
            "ap": 0.12565119525045215,
            "ap_weighted": 0.12565119525045215,
            "f1": 0.5342139722943324,
            "f1_weighted": 0.7750627544998736
          },
          {
            "accuracy": 0.70068359375,
            "ap": 0.11856026095703164,
            "ap_weighted": 0.11856026095703164,
            "f1": 0.5243335815056672,
            "f1_weighted": 0.768140655370326
          },
          {
            "accuracy": 0.73583984375,
            "ap": 0.12460168828264759,
            "ap_weighted": 0.12460168828264759,
            "f1": 0.5446784815328505,
            "f1_weighted": 0.7930297916024555
          },
          {
            "accuracy": 0.65185546875,
            "ap": 0.1285423275320073,
            "ap_weighted": 0.1285423275320073,
            "f1": 0.5096126366199359,
            "f1_weighted": 0.7319396017987487
          },
          {
            "accuracy": 0.61572265625,
            "ap": 0.1067663831088326,
            "ap_weighted": 0.1067663831088326,
            "f1": 0.47619525812830776,
            "f1_weighted": 0.7037688005708786
          },
          {
            "accuracy": 0.59716796875,
            "ap": 0.08864169034090909,
            "ap_weighted": 0.08864169034090909,
            "f1": 0.4493875511921952,
            "f1_weighted": 0.6895133192126055
          },
          {
            "accuracy": 0.7060546875,
            "ap": 0.12114321921541249,
            "ap_weighted": 0.12114321921541249,
            "f1": 0.5288478000342407,
            "f1_weighted": 0.7720840054410631
          },
          {
            "accuracy": 0.53955078125,
            "ap": 0.1059982563018197,
            "ap_weighted": 0.1059982563018197,
            "f1": 0.43844614777576857,
            "f1_weighted": 0.6390265713771207
          },
          {
            "accuracy": 0.50439453125,
            "ap": 0.09970954677437903,
            "ap_weighted": 0.09970954677437903,
            "f1": 0.415417124707845,
            "f1_weighted": 0.6074034186736463
          },
          {
            "accuracy": 0.568359375,
            "ap": 0.11036177758891214,
            "ap_weighted": 0.11036177758891214,
            "f1": 0.45622940322051636,
            "f1_weighted": 0.6640918455300108
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}