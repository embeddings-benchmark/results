{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 18.639316082000732,
  "kg_co2_emissions": 0.0008085043361029824,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.5638232916184935,
        "cosine_spearman": 0.5643285398210998,
        "euclidean_pearson": 0.5675328999091268,
        "euclidean_spearman": 0.5643285398210998,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.5643285398210998,
        "manhattan_pearson": 0.5643191360622091,
        "manhattan_spearman": 0.5618972186842096,
        "pearson": 0.5638232916184935,
        "spearman": 0.5643285398210998
      },
      {
        "cosine_pearson": 0.09038774243673688,
        "cosine_spearman": 0.090260750747396,
        "euclidean_pearson": 0.10421893055877655,
        "euclidean_spearman": 0.09016229855218691,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.090260750747396,
        "manhattan_pearson": 0.10620870544221063,
        "manhattan_spearman": 0.09115251339929771,
        "pearson": 0.09038774243673688,
        "spearman": 0.090260750747396
      },
      {
        "cosine_pearson": 0.13673972424488404,
        "cosine_spearman": 0.165771288776183,
        "euclidean_pearson": 0.16117310925926343,
        "euclidean_spearman": 0.165771288776183,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.165771288776183,
        "manhattan_pearson": 0.1634777315254433,
        "manhattan_spearman": 0.16654948376063522,
        "pearson": 0.13673972424488404,
        "spearman": 0.165771288776183
      },
      {
        "cosine_pearson": 0.2695758936134516,
        "cosine_spearman": 0.26597893732066036,
        "euclidean_pearson": 0.2798144907112557,
        "euclidean_spearman": 0.26597893732066036,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.26597893732066036,
        "manhattan_pearson": 0.28127010441136363,
        "manhattan_spearman": 0.2656870300630609,
        "pearson": 0.2695758936134516,
        "spearman": 0.26597893732066036
      },
      {
        "cosine_pearson": 0.15085519839634084,
        "cosine_spearman": 0.13615255715522442,
        "euclidean_pearson": 0.18196178876485714,
        "euclidean_spearman": 0.13615255715522442,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.13615255715522442,
        "manhattan_pearson": 0.1852736354725266,
        "manhattan_spearman": 0.13895113783038435,
        "pearson": 0.15085519839634084,
        "spearman": 0.13615255715522442
      },
      {
        "cosine_pearson": 0.6627484477414328,
        "cosine_spearman": 0.7010770616304981,
        "euclidean_pearson": 0.7010730773830833,
        "euclidean_spearman": 0.7010770616304981,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7010770616304981,
        "manhattan_pearson": 0.7007891185736668,
        "manhattan_spearman": 0.7006835045111552,
        "pearson": 0.6627484477414328,
        "spearman": 0.7010770616304981
      },
      {
        "cosine_pearson": 0.2871058502319756,
        "cosine_spearman": 0.26572516704460686,
        "euclidean_pearson": 0.3035978859105975,
        "euclidean_spearman": 0.26572516704460686,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.26572516704460686,
        "manhattan_pearson": 0.30041390050546796,
        "manhattan_spearman": 0.2594634759133362,
        "pearson": 0.2871058502319756,
        "spearman": 0.26572516704460686
      },
      {
        "cosine_pearson": 0.34632216869223126,
        "cosine_spearman": 0.37176573657092954,
        "euclidean_pearson": 0.38379749041497313,
        "euclidean_spearman": 0.37176573657092954,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.37176573657092954,
        "manhattan_pearson": 0.3854508766765683,
        "manhattan_spearman": 0.3738293888011254,
        "pearson": 0.34632216869223126,
        "spearman": 0.37176573657092954
      },
      {
        "cosine_pearson": 0.48949460360819785,
        "cosine_spearman": 0.5027677536678697,
        "euclidean_pearson": 0.5123946218686758,
        "euclidean_spearman": 0.5027677536678697,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.5027677536678697,
        "manhattan_pearson": 0.5124020915419868,
        "manhattan_spearman": 0.5025854936178126,
        "pearson": 0.48949460360819785,
        "spearman": 0.5027677536678697
      },
      {
        "cosine_pearson": 0.4186917074282517,
        "cosine_spearman": 0.37968475273555,
        "euclidean_pearson": 0.4248953457188903,
        "euclidean_spearman": 0.37968475273555,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.37968475273555,
        "manhattan_pearson": 0.4197572995315755,
        "manhattan_spearman": 0.3720032058536724,
        "pearson": 0.4186917074282517,
        "spearman": 0.37968475273555
      },
      {
        "cosine_pearson": 0.42817299187258223,
        "cosine_spearman": 0.41793050184784825,
        "euclidean_pearson": 0.45496384063470324,
        "euclidean_spearman": 0.41793050184784825,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.41793050184784825,
        "manhattan_pearson": 0.45525698732622816,
        "manhattan_spearman": 0.4164190352215328,
        "pearson": 0.42817299187258223,
        "spearman": 0.41793050184784825
      },
      {
        "cosine_pearson": 0.260283633254586,
        "cosine_spearman": 0.319651829140711,
        "euclidean_pearson": 0.32672299096067925,
        "euclidean_spearman": 0.3203061741348398,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.319651829140711,
        "manhattan_pearson": 0.32639656432880887,
        "manhattan_spearman": 0.319130949226871,
        "pearson": 0.260283633254586,
        "spearman": 0.319651829140711
      }
    ]
  },
  "task_name": "SemRel24STS"
}