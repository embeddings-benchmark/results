{
  "dataset_revision": "d48254fbdb51af1ae7f20831aab0bccf0b70a19c",
  "evaluation_time": 5.129334211349487,
  "kg_co2_emissions": 0.00021048438396849934,
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.04878048780487805,
        "f1": 0.035847863590366694,
        "hf_subset": "en-ha",
        "languages": [
          "eng-Latn",
          "hau-Latn"
        ],
        "main_score": 0.035847863590366694,
        "precision": 0.033891116769648524,
        "recall": 0.04878048780487805
      },
      {
        "accuracy": 0.08048780487804878,
        "f1": 0.06345624154927426,
        "hf_subset": "en-ig",
        "languages": [
          "eng-Latn",
          "ibo-Latn"
        ],
        "main_score": 0.06345624154927426,
        "precision": 0.05949856684674317,
        "recall": 0.08048780487804878
      },
      {
        "accuracy": 0.697560975609756,
        "f1": 0.6503901383169676,
        "hf_subset": "en-pcm",
        "languages": [
          "eng-Latn",
          "pcm-Latn"
        ],
        "main_score": 0.6503901383169676,
        "precision": 0.6347969239432654,
        "recall": 0.697560975609756
      },
      {
        "accuracy": 0.05853658536585366,
        "f1": 0.044246965947920346,
        "hf_subset": "en-yo",
        "languages": [
          "eng-Latn",
          "yor-Latn"
        ],
        "main_score": 0.044246965947920346,
        "precision": 0.04194124064999244,
        "recall": 0.05853658536585366
      }
    ]
  },
  "task_name": "NollySentiBitextMining"
}