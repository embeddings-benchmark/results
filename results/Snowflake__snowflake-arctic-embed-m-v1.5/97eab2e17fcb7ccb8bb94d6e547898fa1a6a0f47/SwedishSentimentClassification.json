{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.731592,
        "f1": 0.729068,
        "f1_weighted": 0.729135,
        "ap": 0.663912,
        "ap_weighted": 0.663912,
        "scores_per_experiment": [
          {
            "accuracy": 0.701172,
            "f1": 0.690633,
            "f1_weighted": 0.6908,
            "ap": 0.631161,
            "ap_weighted": 0.631161
          },
          {
            "accuracy": 0.699707,
            "f1": 0.695905,
            "f1_weighted": 0.696005,
            "ap": 0.633628,
            "ap_weighted": 0.633628
          },
          {
            "accuracy": 0.753906,
            "f1": 0.749812,
            "f1_weighted": 0.749905,
            "ap": 0.679387,
            "ap_weighted": 0.679387
          },
          {
            "accuracy": 0.72998,
            "f1": 0.728301,
            "f1_weighted": 0.728364,
            "ap": 0.661939,
            "ap_weighted": 0.661939
          },
          {
            "accuracy": 0.74707,
            "f1": 0.746907,
            "f1_weighted": 0.746926,
            "ap": 0.683018,
            "ap_weighted": 0.683018
          },
          {
            "accuracy": 0.722168,
            "f1": 0.721666,
            "f1_weighted": 0.7217,
            "ap": 0.657923,
            "ap_weighted": 0.657923
          },
          {
            "accuracy": 0.743652,
            "f1": 0.741895,
            "f1_weighted": 0.741957,
            "ap": 0.674009,
            "ap_weighted": 0.674009
          },
          {
            "accuracy": 0.747559,
            "f1": 0.745702,
            "f1_weighted": 0.745765,
            "ap": 0.677336,
            "ap_weighted": 0.677336
          },
          {
            "accuracy": 0.731445,
            "f1": 0.731131,
            "f1_weighted": 0.731158,
            "ap": 0.667229,
            "ap_weighted": 0.667229
          },
          {
            "accuracy": 0.739258,
            "f1": 0.738731,
            "f1_weighted": 0.738765,
            "ap": 0.673487,
            "ap_weighted": 0.673487
          }
        ],
        "main_score": 0.731592,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.729736,
        "f1": 0.727261,
        "f1_weighted": 0.727304,
        "ap": 0.661838,
        "ap_weighted": 0.661838,
        "scores_per_experiment": [
          {
            "accuracy": 0.709473,
            "f1": 0.697527,
            "f1_weighted": 0.697644,
            "ap": 0.636786,
            "ap_weighted": 0.636786
          },
          {
            "accuracy": 0.709473,
            "f1": 0.705729,
            "f1_weighted": 0.705794,
            "ap": 0.641319,
            "ap_weighted": 0.641319
          },
          {
            "accuracy": 0.757324,
            "f1": 0.754197,
            "f1_weighted": 0.754251,
            "ap": 0.683446,
            "ap_weighted": 0.683446
          },
          {
            "accuracy": 0.727051,
            "f1": 0.725751,
            "f1_weighted": 0.725788,
            "ap": 0.659685,
            "ap_weighted": 0.659685
          },
          {
            "accuracy": 0.736328,
            "f1": 0.736145,
            "f1_weighted": 0.736158,
            "ap": 0.672142,
            "ap_weighted": 0.672142
          },
          {
            "accuracy": 0.72998,
            "f1": 0.729241,
            "f1_weighted": 0.729269,
            "ap": 0.663754,
            "ap_weighted": 0.663754
          },
          {
            "accuracy": 0.726074,
            "f1": 0.724617,
            "f1_weighted": 0.724656,
            "ap": 0.658495,
            "ap_weighted": 0.658495
          },
          {
            "accuracy": 0.746582,
            "f1": 0.745006,
            "f1_weighted": 0.745045,
            "ap": 0.676655,
            "ap_weighted": 0.676655
          },
          {
            "accuracy": 0.729004,
            "f1": 0.7286,
            "f1_weighted": 0.728621,
            "ap": 0.664091,
            "ap_weighted": 0.664091
          },
          {
            "accuracy": 0.726074,
            "f1": 0.725798,
            "f1_weighted": 0.725815,
            "ap": 0.662012,
            "ap_weighted": 0.662012
          }
        ],
        "main_score": 0.729736,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 18.025052547454834,
  "kg_co2_emissions": 0.0007391647228669941
}