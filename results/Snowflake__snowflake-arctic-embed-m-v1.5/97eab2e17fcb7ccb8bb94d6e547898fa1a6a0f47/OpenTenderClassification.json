{
  "dataset_revision": "9af5657575a669dc18c7f897a67287ff7d1a0c65",
  "task_name": "OpenTenderClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.279376,
            "f1": 0.260782,
            "f1_weighted": 0.260879,
            "precision": 0.275448,
            "precision_weighted": 0.27557,
            "recall": 0.279319,
            "recall_weighted": 0.279376,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.256633,
            "f1": 0.244667,
            "f1_weighted": 0.244619,
            "precision": 0.256587,
            "precision_weighted": 0.256569,
            "recall": 0.256703,
            "recall_weighted": 0.256633,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.299889,
            "f1": 0.284817,
            "f1_weighted": 0.284839,
            "precision": 0.305807,
            "precision_weighted": 0.305833,
            "recall": 0.299875,
            "recall_weighted": 0.299889,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.298105,
            "f1": 0.284733,
            "f1_weighted": 0.284782,
            "precision": 0.296181,
            "precision_weighted": 0.296127,
            "recall": 0.298035,
            "recall_weighted": 0.298105,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.251728,
            "f1": 0.23401,
            "f1_weighted": 0.23409,
            "precision": 0.251528,
            "precision_weighted": 0.251538,
            "recall": 0.25157,
            "recall_weighted": 0.251728,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.284058,
            "f1": 0.26444,
            "f1_weighted": 0.264396,
            "precision": 0.278221,
            "precision_weighted": 0.278201,
            "recall": 0.284109,
            "recall_weighted": 0.284058,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.267113,
            "f1": 0.254788,
            "f1_weighted": 0.254818,
            "precision": 0.268121,
            "precision_weighted": 0.268054,
            "recall": 0.267014,
            "recall_weighted": 0.267113,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.269342,
            "f1": 0.256758,
            "f1_weighted": 0.256687,
            "precision": 0.278913,
            "precision_weighted": 0.278823,
            "recall": 0.269402,
            "recall_weighted": 0.269342,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.255741,
            "f1": 0.239248,
            "f1_weighted": 0.239237,
            "precision": 0.253329,
            "precision_weighted": 0.253303,
            "recall": 0.255778,
            "recall_weighted": 0.255741,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.257079,
            "f1": 0.237597,
            "f1_weighted": 0.237596,
            "precision": 0.269302,
            "precision_weighted": 0.269256,
            "recall": 0.257003,
            "recall_weighted": 0.257079,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.271906,
        "f1": 0.256184,
        "f1_weighted": 0.256194,
        "precision": 0.273344,
        "precision_weighted": 0.273327,
        "recall": 0.271881,
        "recall_weighted": 0.271906,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.256184,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 84.98166251182556,
  "kg_co2_emissions": null
}