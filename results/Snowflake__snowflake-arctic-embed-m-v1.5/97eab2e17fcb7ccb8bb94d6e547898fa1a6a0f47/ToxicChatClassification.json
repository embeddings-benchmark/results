{
  "dataset_revision": "3e0319203c7162b9c9f8015b594441f979c199bc",
  "task_name": "ToxicChatClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.817698,
        "f1": 0.684026,
        "f1_weighted": 0.837513,
        "ap": 0.295548,
        "ap_weighted": 0.295548,
        "scores_per_experiment": [
          {
            "accuracy": 0.785223,
            "f1": 0.642154,
            "f1_weighted": 0.81166,
            "ap": 0.241357,
            "ap_weighted": 0.241357
          },
          {
            "accuracy": 0.878007,
            "f1": 0.725194,
            "f1_weighted": 0.878711,
            "ap": 0.330009,
            "ap_weighted": 0.330009
          },
          {
            "accuracy": 0.843643,
            "f1": 0.710113,
            "f1_weighted": 0.857503,
            "ap": 0.319812,
            "ap_weighted": 0.319812
          },
          {
            "accuracy": 0.808419,
            "f1": 0.681378,
            "f1_weighted": 0.832099,
            "ap": 0.293706,
            "ap_weighted": 0.293706
          },
          {
            "accuracy": 0.732818,
            "f1": 0.593772,
            "f1_weighted": 0.771816,
            "ap": 0.201865,
            "ap_weighted": 0.201865
          },
          {
            "accuracy": 0.830756,
            "f1": 0.684169,
            "f1_weighted": 0.845359,
            "ap": 0.281098,
            "ap_weighted": 0.281098
          },
          {
            "accuracy": 0.879725,
            "f1": 0.740919,
            "f1_weighted": 0.882983,
            "ap": 0.356712,
            "ap_weighted": 0.356712
          },
          {
            "accuracy": 0.793814,
            "f1": 0.681108,
            "f1_weighted": 0.823131,
            "ap": 0.308486,
            "ap_weighted": 0.308486
          },
          {
            "accuracy": 0.786082,
            "f1": 0.657618,
            "f1_weighted": 0.81473,
            "ap": 0.267741,
            "ap_weighted": 0.267741
          },
          {
            "accuracy": 0.838488,
            "f1": 0.723835,
            "f1_weighted": 0.857138,
            "ap": 0.35469,
            "ap_weighted": 0.35469
          }
        ],
        "main_score": 0.817698,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 11.585155963897705,
  "kg_co2_emissions": 0.0003752063704014841
}