{
  "dataset_revision": "bd27d0058bea2ad52470d9072a3b5da6b97c1ac3",
  "task_name": "VaccinChatNLClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.18547,
            "f1": 0.225763,
            "f1_weighted": 0.156763,
            "precision": 0.268793,
            "precision_weighted": 0.355759,
            "recall": 0.379928,
            "recall_weighted": 0.18547,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.220513,
            "f1": 0.259876,
            "f1_weighted": 0.198426,
            "precision": 0.332167,
            "precision_weighted": 0.435977,
            "recall": 0.397128,
            "recall_weighted": 0.220513,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.232479,
            "f1": 0.27606,
            "f1_weighted": 0.213832,
            "precision": 0.336112,
            "precision_weighted": 0.407025,
            "recall": 0.399671,
            "recall_weighted": 0.232479,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.204274,
            "f1": 0.236836,
            "f1_weighted": 0.192589,
            "precision": 0.285041,
            "precision_weighted": 0.434373,
            "recall": 0.361984,
            "recall_weighted": 0.204274,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.21453,
            "f1": 0.244112,
            "f1_weighted": 0.17512,
            "precision": 0.283112,
            "precision_weighted": 0.353366,
            "recall": 0.38662,
            "recall_weighted": 0.21453,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.218803,
            "f1": 0.251436,
            "f1_weighted": 0.19035,
            "precision": 0.299342,
            "precision_weighted": 0.361671,
            "recall": 0.402992,
            "recall_weighted": 0.218803,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.225641,
            "f1": 0.240528,
            "f1_weighted": 0.184847,
            "precision": 0.28212,
            "precision_weighted": 0.322606,
            "recall": 0.392698,
            "recall_weighted": 0.225641,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.197436,
            "f1": 0.228939,
            "f1_weighted": 0.16518,
            "precision": 0.266953,
            "precision_weighted": 0.294029,
            "recall": 0.376187,
            "recall_weighted": 0.197436,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.223932,
            "f1": 0.254632,
            "f1_weighted": 0.193473,
            "precision": 0.305416,
            "precision_weighted": 0.362917,
            "recall": 0.399695,
            "recall_weighted": 0.223932,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.215385,
            "f1": 0.264213,
            "f1_weighted": 0.195208,
            "precision": 0.333743,
            "precision_weighted": 0.404167,
            "recall": 0.391961,
            "recall_weighted": 0.215385,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.213846,
        "f1": 0.24824,
        "f1_weighted": 0.186579,
        "precision": 0.29928,
        "precision_weighted": 0.373189,
        "recall": 0.388886,
        "recall_weighted": 0.213846,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.24824,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 45.094520568847656,
  "kg_co2_emissions": null
}