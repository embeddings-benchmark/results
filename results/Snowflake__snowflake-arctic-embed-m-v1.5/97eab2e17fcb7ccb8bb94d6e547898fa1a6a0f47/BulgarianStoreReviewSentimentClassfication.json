{
  "dataset_revision": "701984d6c6efea0e14a1c7850ef70e464c5577c0",
  "task_name": "BulgarianStoreReviewSentimentClassfication",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.274725,
        "f1": 0.20047,
        "f1_weighted": 0.325025,
        "scores_per_experiment": [
          {
            "accuracy": 0.263736,
            "f1": 0.20629,
            "f1_weighted": 0.317161
          },
          {
            "accuracy": 0.307692,
            "f1": 0.24181,
            "f1_weighted": 0.360381
          },
          {
            "accuracy": 0.252747,
            "f1": 0.181853,
            "f1_weighted": 0.319738
          },
          {
            "accuracy": 0.357143,
            "f1": 0.246342,
            "f1_weighted": 0.419986
          },
          {
            "accuracy": 0.32967,
            "f1": 0.195315,
            "f1_weighted": 0.385882
          },
          {
            "accuracy": 0.335165,
            "f1": 0.242735,
            "f1_weighted": 0.37374
          },
          {
            "accuracy": 0.203297,
            "f1": 0.179802,
            "f1_weighted": 0.224615
          },
          {
            "accuracy": 0.214286,
            "f1": 0.155449,
            "f1_weighted": 0.258602
          },
          {
            "accuracy": 0.186813,
            "f1": 0.144162,
            "f1_weighted": 0.242827
          },
          {
            "accuracy": 0.296703,
            "f1": 0.210942,
            "f1_weighted": 0.347314
          }
        ],
        "main_score": 0.274725,
        "hf_subset": "default",
        "languages": [
          "bul-Cyrl"
        ]
      }
    ]
  },
  "evaluation_time": 9.33214020729065,
  "kg_co2_emissions": 0.0003299083764993676
}