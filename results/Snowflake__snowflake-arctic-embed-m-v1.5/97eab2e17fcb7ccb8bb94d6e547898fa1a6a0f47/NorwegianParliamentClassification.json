{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.54,
        "f1": 0.535829,
        "f1_weighted": 0.535829,
        "ap": 0.52217,
        "ap_weighted": 0.52217,
        "scores_per_experiment": [
          {
            "accuracy": 0.5525,
            "f1": 0.552306,
            "f1_weighted": 0.552306,
            "ap": 0.528896,
            "ap_weighted": 0.528896
          },
          {
            "accuracy": 0.4875,
            "f1": 0.478575,
            "f1_weighted": 0.478575,
            "ap": 0.493962,
            "ap_weighted": 0.493962
          },
          {
            "accuracy": 0.556667,
            "f1": 0.546693,
            "f1_weighted": 0.546693,
            "ap": 0.53081,
            "ap_weighted": 0.53081
          },
          {
            "accuracy": 0.543333,
            "f1": 0.543008,
            "f1_weighted": 0.543008,
            "ap": 0.52365,
            "ap_weighted": 0.52365
          },
          {
            "accuracy": 0.573333,
            "f1": 0.572991,
            "f1_weighted": 0.572991,
            "ap": 0.541756,
            "ap_weighted": 0.541756
          },
          {
            "accuracy": 0.524167,
            "f1": 0.518947,
            "f1_weighted": 0.518947,
            "ap": 0.512567,
            "ap_weighted": 0.512567
          },
          {
            "accuracy": 0.509167,
            "f1": 0.504775,
            "f1_weighted": 0.504775,
            "ap": 0.504654,
            "ap_weighted": 0.504654
          },
          {
            "accuracy": 0.5175,
            "f1": 0.50843,
            "f1_weighted": 0.50843,
            "ap": 0.508991,
            "ap_weighted": 0.508991
          },
          {
            "accuracy": 0.581667,
            "f1": 0.579405,
            "f1_weighted": 0.579405,
            "ap": 0.54665,
            "ap_weighted": 0.54665
          },
          {
            "accuracy": 0.554167,
            "f1": 0.553158,
            "f1_weighted": 0.553158,
            "ap": 0.529763,
            "ap_weighted": 0.529763
          }
        ],
        "main_score": 0.54,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5515,
        "f1": 0.547732,
        "f1_weighted": 0.547732,
        "ap": 0.529645,
        "ap_weighted": 0.529645,
        "scores_per_experiment": [
          {
            "accuracy": 0.558333,
            "f1": 0.558234,
            "f1_weighted": 0.558234,
            "ap": 0.53247,
            "ap_weighted": 0.53247
          },
          {
            "accuracy": 0.494167,
            "f1": 0.48343,
            "f1_weighted": 0.48343,
            "ap": 0.497131,
            "ap_weighted": 0.497131
          },
          {
            "accuracy": 0.568333,
            "f1": 0.55794,
            "f1_weighted": 0.55794,
            "ap": 0.53774,
            "ap_weighted": 0.53774
          },
          {
            "accuracy": 0.5675,
            "f1": 0.5675,
            "f1_weighted": 0.5675,
            "ap": 0.538314,
            "ap_weighted": 0.538314
          },
          {
            "accuracy": 0.58,
            "f1": 0.579943,
            "f1_weighted": 0.579943,
            "ap": 0.546553,
            "ap_weighted": 0.546553
          },
          {
            "accuracy": 0.534167,
            "f1": 0.53296,
            "f1_weighted": 0.53296,
            "ap": 0.518143,
            "ap_weighted": 0.518143
          },
          {
            "accuracy": 0.5475,
            "f1": 0.544142,
            "f1_weighted": 0.544142,
            "ap": 0.525676,
            "ap_weighted": 0.525676
          },
          {
            "accuracy": 0.489167,
            "f1": 0.479803,
            "f1_weighted": 0.479803,
            "ap": 0.494676,
            "ap_weighted": 0.494676
          },
          {
            "accuracy": 0.633333,
            "f1": 0.632475,
            "f1_weighted": 0.632475,
            "ap": 0.582877,
            "ap_weighted": 0.582877
          },
          {
            "accuracy": 0.5425,
            "f1": 0.540893,
            "f1_weighted": 0.540893,
            "ap": 0.522865,
            "ap_weighted": 0.522865
          }
        ],
        "main_score": 0.5515,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 30.37331771850586,
  "kg_co2_emissions": 0.001198558456790509
}