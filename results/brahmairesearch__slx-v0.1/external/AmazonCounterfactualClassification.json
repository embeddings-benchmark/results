{
    "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
    "task_name": "AmazonCounterfactualClassification",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "en-ext",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6559220389805098,
                "ap": 0.1681423101691947,
                "ap_weighted": 0.1681423101691947,
                "f1": 0.5371729938392706,
                "f1_weighted": 0.7220850142432689,
                "main_score": 0.6559220389805098
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6364179104477612,
                "ap": 0.26921335760715964,
                "ap_weighted": 0.26921335760715964,
                "f1": 0.5764569779029121,
                "f1_weighted": 0.6727976461433454,
                "main_score": 0.6364179104477612
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.5781584582441114,
                "ap": 0.7396447293747234,
                "ap_weighted": 0.7396447293747234,
                "f1": 0.5608677257778776,
                "f1_weighted": 0.5941839602591139,
                "main_score": 0.5781584582441114
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.6089935760171306,
                "ap": 0.13241905671485688,
                "ap_weighted": 0.13241905671485688,
                "f1": 0.48847713021626776,
                "f1_weighted": 0.6843256893578159,
                "main_score": 0.6089935760171306
            }
        ],
        "validation": [
            {
                "hf_subset": "en-ext",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6346846846846848,
                "ap": 0.15500820900257253,
                "ap_weighted": 0.15500820900257253,
                "f1": 0.5182923849325543,
                "f1_weighted": 0.7067890974680999,
                "main_score": 0.6346846846846848
            },
            {
                "hf_subset": "en",
                "languages": [
                    "eng-Latn"
                ],
                "accuracy": 0.6146268656716418,
                "ap": 0.22787749709369065,
                "ap_weighted": 0.22787749709369065,
                "f1": 0.5439887901518377,
                "f1_weighted": 0.6603261824563178,
                "main_score": 0.6146268656716418
            },
            {
                "hf_subset": "de",
                "languages": [
                    "deu-Latn"
                ],
                "accuracy": 0.5798283261802576,
                "ap": 0.7353358224916597,
                "ap_weighted": 0.7353358224916597,
                "f1": 0.5563777177215615,
                "f1_weighted": 0.595970573764842,
                "main_score": 0.5798283261802576
            },
            {
                "hf_subset": "ja",
                "languages": [
                    "jpn-Jpan"
                ],
                "accuracy": 0.5937768240343347,
                "ap": 0.11144115013790348,
                "ap_weighted": 0.11144115013790348,
                "f1": 0.4623809480101249,
                "f1_weighted": 0.6741908331890756,
                "main_score": 0.5937768240343347
            }
        ]
    }
}