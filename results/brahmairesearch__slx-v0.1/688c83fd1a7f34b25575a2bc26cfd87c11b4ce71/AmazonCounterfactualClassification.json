{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.29.10",
  "scores": {
    "validation": [
      {
        "accuracy": 0.579828,
        "f1": 0.556378,
        "f1_weighted": 0.595971,
        "ap": 0.735336,
        "ap_weighted": 0.735336,
        "scores_per_experiment": [
          {
            "accuracy": 0.635193,
            "f1": 0.605423,
            "f1_weighted": 0.648218,
            "ap": 0.756576,
            "ap_weighted": 0.756576
          },
          {
            "accuracy": 0.540773,
            "f1": 0.530171,
            "f1_weighted": 0.558038,
            "ap": 0.729926,
            "ap_weighted": 0.729926
          },
          {
            "accuracy": 0.577253,
            "f1": 0.544477,
            "f1_weighted": 0.592724,
            "ap": 0.723597,
            "ap_weighted": 0.723597
          },
          {
            "accuracy": 0.577253,
            "f1": 0.567206,
            "f1_weighted": 0.593243,
            "ap": 0.752067,
            "ap_weighted": 0.752067
          },
          {
            "accuracy": 0.564378,
            "f1": 0.543787,
            "f1_weighted": 0.582056,
            "ap": 0.729026,
            "ap_weighted": 0.729026
          },
          {
            "accuracy": 0.603004,
            "f1": 0.579125,
            "f1_weighted": 0.618709,
            "ap": 0.745884,
            "ap_weighted": 0.745884
          },
          {
            "accuracy": 0.553648,
            "f1": 0.521948,
            "f1_weighted": 0.570555,
            "ap": 0.71296,
            "ap_weighted": 0.71296
          },
          {
            "accuracy": 0.564378,
            "f1": 0.541078,
            "f1_weighted": 0.581908,
            "ap": 0.72604,
            "ap_weighted": 0.72604
          },
          {
            "accuracy": 0.532189,
            "f1": 0.505635,
            "f1_weighted": 0.550875,
            "ap": 0.706974,
            "ap_weighted": 0.706974
          },
          {
            "accuracy": 0.650215,
            "f1": 0.624927,
            "f1_weighted": 0.663381,
            "ap": 0.770311,
            "ap_weighted": 0.770311
          }
        ],
        "main_score": 0.579828,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.578158,
        "f1": 0.560868,
        "f1_weighted": 0.594184,
        "ap": 0.739645,
        "ap_weighted": 0.739645,
        "scores_per_experiment": [
          {
            "accuracy": 0.623126,
            "f1": 0.595522,
            "f1_weighted": 0.636929,
            "ap": 0.750743,
            "ap_weighted": 0.750743
          },
          {
            "accuracy": 0.553533,
            "f1": 0.545391,
            "f1_weighted": 0.569232,
            "ap": 0.739839,
            "ap_weighted": 0.739839
          },
          {
            "accuracy": 0.602784,
            "f1": 0.580992,
            "f1_weighted": 0.618437,
            "ap": 0.746522,
            "ap_weighted": 0.746522
          },
          {
            "accuracy": 0.54818,
            "f1": 0.539805,
            "f1_weighted": 0.564132,
            "ap": 0.736232,
            "ap_weighted": 0.736232
          },
          {
            "accuracy": 0.555675,
            "f1": 0.538337,
            "f1_weighted": 0.573395,
            "ap": 0.726493,
            "ap_weighted": 0.726493
          },
          {
            "accuracy": 0.622056,
            "f1": 0.603317,
            "f1_weighted": 0.637102,
            "ap": 0.761665,
            "ap_weighted": 0.761665
          },
          {
            "accuracy": 0.543897,
            "f1": 0.526304,
            "f1_weighted": 0.562077,
            "ap": 0.719984,
            "ap_weighted": 0.719984
          },
          {
            "accuracy": 0.56424,
            "f1": 0.551235,
            "f1_weighted": 0.581171,
            "ap": 0.737268,
            "ap_weighted": 0.737268
          },
          {
            "accuracy": 0.539615,
            "f1": 0.526749,
            "f1_weighted": 0.557326,
            "ap": 0.723876,
            "ap_weighted": 0.723876
          },
          {
            "accuracy": 0.62848,
            "f1": 0.601027,
            "f1_weighted": 0.642038,
            "ap": 0.753825,
            "ap_weighted": 0.753825
          }
        ],
        "main_score": 0.578158,
        "hf_subset": "de",
        "languages": [
          "deu-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 38.32903718948364,
  "kg_co2_emissions": null
}