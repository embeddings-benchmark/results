{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.543945,
        "f1": 0.538833,
        "f1_weighted": 0.5434,
        "ap": 0.446024,
        "ap_weighted": 0.446024,
        "scores_per_experiment": [
          {
            "accuracy": 0.580566,
            "f1": 0.572635,
            "f1_weighted": 0.582016,
            "ap": 0.462108,
            "ap_weighted": 0.462108
          },
          {
            "accuracy": 0.526855,
            "f1": 0.526562,
            "f1_weighted": 0.524662,
            "ap": 0.443251,
            "ap_weighted": 0.443251
          },
          {
            "accuracy": 0.497559,
            "f1": 0.496988,
            "f1_weighted": 0.494257,
            "ap": 0.427666,
            "ap_weighted": 0.427666
          },
          {
            "accuracy": 0.574219,
            "f1": 0.572162,
            "f1_weighted": 0.576942,
            "ap": 0.464187,
            "ap_weighted": 0.464187
          },
          {
            "accuracy": 0.561523,
            "f1": 0.547543,
            "f1_weighted": 0.560358,
            "ap": 0.445665,
            "ap_weighted": 0.445665
          },
          {
            "accuracy": 0.474609,
            "f1": 0.473404,
            "f1_weighted": 0.469343,
            "ap": 0.417105,
            "ap_weighted": 0.417105
          },
          {
            "accuracy": 0.547363,
            "f1": 0.54411,
            "f1_weighted": 0.550315,
            "ap": 0.445425,
            "ap_weighted": 0.445425
          },
          {
            "accuracy": 0.554688,
            "f1": 0.554616,
            "f1_weighted": 0.553705,
            "ap": 0.459174,
            "ap_weighted": 0.459174
          },
          {
            "accuracy": 0.570312,
            "f1": 0.564022,
            "f1_weighted": 0.57246,
            "ap": 0.456696,
            "ap_weighted": 0.456696
          },
          {
            "accuracy": 0.551758,
            "f1": 0.536294,
            "f1_weighted": 0.549938,
            "ap": 0.438958,
            "ap_weighted": 0.438958
          }
        ],
        "main_score": 0.538833,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.412323951721191,
  "kg_co2_emissions": 0.00020570996730555376
}