{
  "dataset_revision": "59d12749a3c91a186063c7d729ec392fda94681c",
  "task_name": "DKHateClassification",
  "mteb_version": "2.3.3",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.613982,
            "f1": 0.53721,
            "f1_weighted": 0.678722,
            "precision": 0.59039,
            "precision_weighted": 0.867878,
            "recall": 0.706301,
            "recall_weighted": 0.613982,
            "ap": 0.204362,
            "ap_weighted": 0.204362
          },
          {
            "accuracy": 0.653495,
            "f1": 0.557879,
            "f1_weighted": 0.71224,
            "precision": 0.589042,
            "precision_weighted": 0.858874,
            "recall": 0.697493,
            "recall_weighted": 0.653495,
            "ap": 0.204018,
            "ap_weighted": 0.204018
          },
          {
            "accuracy": 0.680851,
            "f1": 0.510729,
            "f1_weighted": 0.727328,
            "precision": 0.524468,
            "precision_weighted": 0.798416,
            "recall": 0.545774,
            "recall_weighted": 0.680851,
            "ap": 0.137408,
            "ap_weighted": 0.137408
          },
          {
            "accuracy": 0.56231,
            "f1": 0.473694,
            "f1_weighted": 0.635829,
            "precision": 0.536245,
            "precision_weighted": 0.816163,
            "recall": 0.582656,
            "recall_weighted": 0.56231,
            "ap": 0.148266,
            "ap_weighted": 0.148266
          },
          {
            "accuracy": 0.641337,
            "f1": 0.535578,
            "f1_weighted": 0.701964,
            "precision": 0.5677,
            "precision_weighted": 0.839169,
            "recall": 0.648713,
            "recall_weighted": 0.641337,
            "ap": 0.178282,
            "ap_weighted": 0.178282
          },
          {
            "accuracy": 0.571429,
            "f1": 0.466333,
            "f1_weighted": 0.644132,
            "precision": 0.520468,
            "precision_weighted": 0.800186,
            "recall": 0.546028,
            "recall_weighted": 0.571429,
            "ap": 0.136537,
            "ap_weighted": 0.136537
          },
          {
            "accuracy": 0.589666,
            "f1": 0.502057,
            "f1_weighted": 0.658864,
            "precision": 0.55702,
            "precision_weighted": 0.835067,
            "recall": 0.629658,
            "recall_weighted": 0.589666,
            "ap": 0.166993,
            "ap_weighted": 0.166993
          },
          {
            "accuracy": 0.671733,
            "f1": 0.571697,
            "f1_weighted": 0.727098,
            "precision": 0.595155,
            "precision_weighted": 0.861558,
            "recall": 0.70791,
            "recall_weighted": 0.671733,
            "ap": 0.212093,
            "ap_weighted": 0.212093
          },
          {
            "accuracy": 0.714286,
            "f1": 0.559559,
            "f1_weighted": 0.755546,
            "precision": 0.563035,
            "precision_weighted": 0.824286,
            "recall": 0.617166,
            "recall_weighted": 0.714286,
            "ap": 0.168734,
            "ap_weighted": 0.168734
          },
          {
            "accuracy": 0.62614,
            "f1": 0.498457,
            "f1_weighted": 0.688443,
            "precision": 0.531243,
            "precision_weighted": 0.807003,
            "recall": 0.566819,
            "recall_weighted": 0.62614,
            "ap": 0.143798,
            "ap_weighted": 0.143798
          }
        ],
        "accuracy": 0.632523,
        "f1": 0.521319,
        "f1_weighted": 0.693017,
        "precision": 0.557477,
        "precision_weighted": 0.83086,
        "recall": 0.624852,
        "recall_weighted": 0.632523,
        "ap": 0.170049,
        "ap_weighted": 0.170049,
        "main_score": 0.632523,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 40.68353462219238,
  "kg_co2_emissions": null
}