{
  "dataset_revision": "3047317d2586abb183293f92b1b7d66d1c9ec81a",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "2.3.3",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.543333,
            "f1": 0.543252,
            "f1_weighted": 0.543252,
            "precision": 0.543364,
            "precision_weighted": 0.543364,
            "recall": 0.543333,
            "recall_weighted": 0.543333,
            "ap": 0.523496,
            "ap_weighted": 0.523496
          },
          {
            "accuracy": 0.48,
            "f1": 0.478325,
            "f1_weighted": 0.478325,
            "precision": 0.47974,
            "precision_weighted": 0.47974,
            "recall": 0.48,
            "recall_weighted": 0.48,
            "ap": 0.490359,
            "ap_weighted": 0.490359
          },
          {
            "accuracy": 0.565,
            "f1": 0.56391,
            "f1_weighted": 0.56391,
            "precision": 0.565657,
            "precision_weighted": 0.565657,
            "recall": 0.565,
            "recall_weighted": 0.565,
            "ap": 0.536341,
            "ap_weighted": 0.536341
          },
          {
            "accuracy": 0.515833,
            "f1": 0.512649,
            "f1_weighted": 0.512649,
            "precision": 0.516258,
            "precision_weighted": 0.516258,
            "recall": 0.515833,
            "recall_weighted": 0.515833,
            "ap": 0.508132,
            "ap_weighted": 0.508132
          },
          {
            "accuracy": 0.603333,
            "f1": 0.602847,
            "f1_weighted": 0.602847,
            "precision": 0.603842,
            "precision_weighted": 0.603842,
            "recall": 0.603333,
            "recall_weighted": 0.603333,
            "ap": 0.563148,
            "ap_weighted": 0.563148
          },
          {
            "accuracy": 0.486667,
            "f1": 0.486575,
            "f1_weighted": 0.486575,
            "precision": 0.486657,
            "precision_weighted": 0.486657,
            "recall": 0.486667,
            "recall_weighted": 0.486667,
            "ap": 0.493516,
            "ap_weighted": 0.493516
          },
          {
            "accuracy": 0.508333,
            "f1": 0.504013,
            "f1_weighted": 0.504013,
            "precision": 0.508634,
            "precision_weighted": 0.508634,
            "recall": 0.508333,
            "recall_weighted": 0.508333,
            "ap": 0.504252,
            "ap_weighted": 0.504252
          },
          {
            "accuracy": 0.5725,
            "f1": 0.56945,
            "f1_weighted": 0.56945,
            "precision": 0.574614,
            "precision_weighted": 0.574614,
            "recall": 0.5725,
            "recall_weighted": 0.5725,
            "ap": 0.540749,
            "ap_weighted": 0.540749
          },
          {
            "accuracy": 0.5475,
            "f1": 0.544524,
            "f1_weighted": 0.544524,
            "precision": 0.548775,
            "precision_weighted": 0.548775,
            "recall": 0.5475,
            "recall_weighted": 0.5475,
            "ap": 0.525692,
            "ap_weighted": 0.525692
          },
          {
            "accuracy": 0.57,
            "f1": 0.550162,
            "f1_weighted": 0.550162,
            "precision": 0.584993,
            "precision_weighted": 0.584993,
            "recall": 0.57,
            "recall_weighted": 0.57,
            "ap": 0.543448,
            "ap_weighted": 0.543448
          }
        ],
        "accuracy": 0.53925,
        "f1": 0.535571,
        "f1_weighted": 0.535571,
        "precision": 0.541253,
        "precision_weighted": 0.541253,
        "recall": 0.53925,
        "recall_weighted": 0.53925,
        "ap": 0.522913,
        "ap_weighted": 0.522913,
        "main_score": 0.53925,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.540833,
            "f1": 0.540825,
            "f1_weighted": 0.540825,
            "precision": 0.540836,
            "precision_weighted": 0.540836,
            "recall": 0.540833,
            "recall_weighted": 0.540833,
            "ap": 0.522098,
            "ap_weighted": 0.522098
          },
          {
            "accuracy": 0.4475,
            "f1": 0.446337,
            "f1_weighted": 0.446337,
            "precision": 0.447055,
            "precision_weighted": 0.447055,
            "recall": 0.4475,
            "recall_weighted": 0.4475,
            "ap": 0.476275,
            "ap_weighted": 0.476275
          },
          {
            "accuracy": 0.57,
            "f1": 0.569191,
            "f1_weighted": 0.569191,
            "precision": 0.57053,
            "precision_weighted": 0.57053,
            "recall": 0.57,
            "recall_weighted": 0.57,
            "ap": 0.539509,
            "ap_weighted": 0.539509
          },
          {
            "accuracy": 0.556667,
            "f1": 0.554587,
            "f1_weighted": 0.554587,
            "precision": 0.557745,
            "precision_weighted": 0.557745,
            "recall": 0.556667,
            "recall_weighted": 0.556667,
            "ap": 0.531158,
            "ap_weighted": 0.531158
          },
          {
            "accuracy": 0.609167,
            "f1": 0.606378,
            "f1_weighted": 0.606378,
            "precision": 0.61235,
            "precision_weighted": 0.61235,
            "recall": 0.609167,
            "recall_weighted": 0.609167,
            "ap": 0.568913,
            "ap_weighted": 0.568913
          },
          {
            "accuracy": 0.4525,
            "f1": 0.452223,
            "f1_weighted": 0.452223,
            "precision": 0.452404,
            "precision_weighted": 0.452404,
            "recall": 0.4525,
            "recall_weighted": 0.4525,
            "ap": 0.478613,
            "ap_weighted": 0.478613
          },
          {
            "accuracy": 0.511667,
            "f1": 0.509487,
            "f1_weighted": 0.509487,
            "precision": 0.511878,
            "precision_weighted": 0.511878,
            "recall": 0.511667,
            "recall_weighted": 0.511667,
            "ap": 0.50599,
            "ap_weighted": 0.50599
          },
          {
            "accuracy": 0.560833,
            "f1": 0.558064,
            "f1_weighted": 0.558064,
            "precision": 0.562398,
            "precision_weighted": 0.562398,
            "recall": 0.560833,
            "recall_weighted": 0.560833,
            "ap": 0.533612,
            "ap_weighted": 0.533612
          },
          {
            "accuracy": 0.53,
            "f1": 0.526304,
            "f1_weighted": 0.526304,
            "precision": 0.530966,
            "precision_weighted": 0.530966,
            "recall": 0.53,
            "recall_weighted": 0.53,
            "ap": 0.515765,
            "ap_weighted": 0.515765
          },
          {
            "accuracy": 0.558333,
            "f1": 0.539285,
            "f1_weighted": 0.539285,
            "precision": 0.569892,
            "precision_weighted": 0.569892,
            "recall": 0.558333,
            "recall_weighted": 0.558333,
            "ap": 0.534902,
            "ap_weighted": 0.534902
          }
        ],
        "accuracy": 0.53375,
        "f1": 0.530268,
        "f1_weighted": 0.530268,
        "precision": 0.535605,
        "precision_weighted": 0.535605,
        "recall": 0.53375,
        "recall_weighted": 0.53375,
        "ap": 0.520683,
        "ap_weighted": 0.520683,
        "main_score": 0.53375,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 92.5095489025116,
  "kg_co2_emissions": null
}