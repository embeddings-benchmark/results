{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "2.3.11",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.642578,
            "f1": 0.524266,
            "f1_weighted": 0.614898,
            "precision": 0.543149,
            "precision_weighted": 0.657434,
            "recall": 0.585953,
            "recall_weighted": 0.642578,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.655762,
            "f1": 0.530545,
            "f1_weighted": 0.632851,
            "precision": 0.560269,
            "precision_weighted": 0.679633,
            "recall": 0.588062,
            "recall_weighted": 0.655762,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.658203,
            "f1": 0.522735,
            "f1_weighted": 0.63889,
            "precision": 0.544722,
            "precision_weighted": 0.682069,
            "recall": 0.576233,
            "recall_weighted": 0.658203,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.64502,
            "f1": 0.516919,
            "f1_weighted": 0.613891,
            "precision": 0.552711,
            "precision_weighted": 0.678287,
            "recall": 0.576626,
            "recall_weighted": 0.64502,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.644531,
            "f1": 0.511798,
            "f1_weighted": 0.617026,
            "precision": 0.540172,
            "precision_weighted": 0.668557,
            "recall": 0.569992,
            "recall_weighted": 0.644531,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.649414,
            "f1": 0.530521,
            "f1_weighted": 0.625941,
            "precision": 0.560178,
            "precision_weighted": 0.686847,
            "recall": 0.586291,
            "recall_weighted": 0.649414,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.646484,
            "f1": 0.520289,
            "f1_weighted": 0.623635,
            "precision": 0.550117,
            "precision_weighted": 0.673566,
            "recall": 0.574741,
            "recall_weighted": 0.646484,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.656738,
            "f1": 0.541644,
            "f1_weighted": 0.636509,
            "precision": 0.564994,
            "precision_weighted": 0.680008,
            "recall": 0.593147,
            "recall_weighted": 0.656738,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.656738,
            "f1": 0.526536,
            "f1_weighted": 0.630193,
            "precision": 0.541682,
            "precision_weighted": 0.665178,
            "recall": 0.585439,
            "recall_weighted": 0.656738,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.652832,
            "f1": 0.533661,
            "f1_weighted": 0.630203,
            "precision": 0.57201,
            "precision_weighted": 0.70005,
            "recall": 0.588534,
            "recall_weighted": 0.652832,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.65083,
        "f1": 0.525891,
        "f1_weighted": 0.626404,
        "precision": 0.553,
        "precision_weighted": 0.677163,
        "recall": 0.582502,
        "recall_weighted": 0.65083,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.65083,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.658203,
            "f1": 0.533099,
            "f1_weighted": 0.635601,
            "precision": 0.548503,
            "precision_weighted": 0.686033,
            "recall": 0.592985,
            "recall_weighted": 0.658203,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.65625,
            "f1": 0.533057,
            "f1_weighted": 0.63115,
            "precision": 0.543147,
            "precision_weighted": 0.660416,
            "recall": 0.594233,
            "recall_weighted": 0.65625,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.650391,
            "f1": 0.513932,
            "f1_weighted": 0.623933,
            "precision": 0.52363,
            "precision_weighted": 0.659741,
            "recall": 0.580946,
            "recall_weighted": 0.650391,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.638672,
            "f1": 0.517774,
            "f1_weighted": 0.606073,
            "precision": 0.540027,
            "precision_weighted": 0.663256,
            "recall": 0.584132,
            "recall_weighted": 0.638672,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.631348,
            "f1": 0.51184,
            "f1_weighted": 0.600421,
            "precision": 0.527743,
            "precision_weighted": 0.650156,
            "recall": 0.579622,
            "recall_weighted": 0.631348,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.64502,
            "f1": 0.523979,
            "f1_weighted": 0.618808,
            "precision": 0.533721,
            "precision_weighted": 0.656249,
            "recall": 0.590856,
            "recall_weighted": 0.64502,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.647949,
            "f1": 0.516596,
            "f1_weighted": 0.625384,
            "precision": 0.537681,
            "precision_weighted": 0.676989,
            "recall": 0.582991,
            "recall_weighted": 0.647949,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.647461,
            "f1": 0.517232,
            "f1_weighted": 0.62131,
            "precision": 0.526126,
            "precision_weighted": 0.653052,
            "recall": 0.577295,
            "recall_weighted": 0.647461,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.655273,
            "f1": 0.52136,
            "f1_weighted": 0.633007,
            "precision": 0.534336,
            "precision_weighted": 0.673687,
            "recall": 0.584052,
            "recall_weighted": 0.655273,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.652344,
            "f1": 0.529958,
            "f1_weighted": 0.628217,
            "precision": 0.545013,
            "precision_weighted": 0.662304,
            "recall": 0.589257,
            "recall_weighted": 0.652344,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.648291,
        "f1": 0.521883,
        "f1_weighted": 0.62239,
        "precision": 0.535993,
        "precision_weighted": 0.664188,
        "recall": 0.585637,
        "recall_weighted": 0.648291,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.648291,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 6568.148213148117,
  "kg_co2_emissions": null
}