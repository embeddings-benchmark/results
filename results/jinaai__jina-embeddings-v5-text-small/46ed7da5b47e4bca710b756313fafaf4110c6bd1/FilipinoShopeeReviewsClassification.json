{
  "dataset_revision": "d096f402fdc76886458c0cfb5dedc829bea2b935",
  "task_name": "FilipinoShopeeReviewsClassification",
  "mteb_version": "2.3.11",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.428711,
            "f1": 0.396873,
            "f1_weighted": 0.396827,
            "precision": 0.396259,
            "precision_weighted": 0.396227,
            "recall": 0.428784,
            "recall_weighted": 0.428711,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.416504,
            "f1": 0.361093,
            "f1_weighted": 0.361033,
            "precision": 0.372412,
            "precision_weighted": 0.372382,
            "recall": 0.416591,
            "recall_weighted": 0.416504,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.416504,
            "f1": 0.381367,
            "f1_weighted": 0.381386,
            "precision": 0.389406,
            "precision_weighted": 0.389397,
            "recall": 0.416491,
            "recall_weighted": 0.416504,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.42041,
            "f1": 0.380039,
            "f1_weighted": 0.379982,
            "precision": 0.387725,
            "precision_weighted": 0.387721,
            "recall": 0.420488,
            "recall_weighted": 0.42041,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.388184,
            "f1": 0.354898,
            "f1_weighted": 0.354887,
            "precision": 0.356752,
            "precision_weighted": 0.356749,
            "recall": 0.388184,
            "recall_weighted": 0.388184,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.42627,
            "f1": 0.378277,
            "f1_weighted": 0.378184,
            "precision": 0.389387,
            "precision_weighted": 0.389374,
            "recall": 0.426445,
            "recall_weighted": 0.42627,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.412598,
            "f1": 0.365984,
            "f1_weighted": 0.365959,
            "precision": 0.371705,
            "precision_weighted": 0.371673,
            "recall": 0.412645,
            "recall_weighted": 0.412598,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.430664,
            "f1": 0.390922,
            "f1_weighted": 0.390855,
            "precision": 0.390125,
            "precision_weighted": 0.390097,
            "recall": 0.43076,
            "recall_weighted": 0.430664,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.43457,
            "f1": 0.407028,
            "f1_weighted": 0.406963,
            "precision": 0.40955,
            "precision_weighted": 0.40954,
            "recall": 0.434702,
            "recall_weighted": 0.43457,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.387695,
            "f1": 0.370188,
            "f1_weighted": 0.37018,
            "precision": 0.363649,
            "precision_weighted": 0.363646,
            "recall": 0.387698,
            "recall_weighted": 0.387695,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.416211,
        "f1": 0.378667,
        "f1_weighted": 0.378626,
        "precision": 0.382697,
        "precision_weighted": 0.38268,
        "recall": 0.416279,
        "recall_weighted": 0.416211,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.416211,
        "hf_subset": "default",
        "languages": [
          "fil-Latn"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.436035,
            "f1": 0.400031,
            "f1_weighted": 0.400008,
            "precision": 0.399536,
            "precision_weighted": 0.39953,
            "recall": 0.436093,
            "recall_weighted": 0.436035,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.419922,
            "f1": 0.368226,
            "f1_weighted": 0.368201,
            "precision": 0.38444,
            "precision_weighted": 0.384443,
            "recall": 0.41998,
            "recall_weighted": 0.419922,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.424805,
            "f1": 0.385593,
            "f1_weighted": 0.385611,
            "precision": 0.394489,
            "precision_weighted": 0.394485,
            "recall": 0.424802,
            "recall_weighted": 0.424805,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.421875,
            "f1": 0.385158,
            "f1_weighted": 0.385109,
            "precision": 0.390006,
            "precision_weighted": 0.390004,
            "recall": 0.421945,
            "recall_weighted": 0.421875,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.404297,
            "f1": 0.371966,
            "f1_weighted": 0.371949,
            "precision": 0.373734,
            "precision_weighted": 0.373715,
            "recall": 0.404296,
            "recall_weighted": 0.404297,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.435059,
            "f1": 0.388966,
            "f1_weighted": 0.388882,
            "precision": 0.403746,
            "precision_weighted": 0.403744,
            "recall": 0.435223,
            "recall_weighted": 0.435059,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.412109,
            "f1": 0.364161,
            "f1_weighted": 0.364132,
            "precision": 0.370416,
            "precision_weighted": 0.370384,
            "recall": 0.412166,
            "recall_weighted": 0.412109,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.432617,
            "f1": 0.392031,
            "f1_weighted": 0.391969,
            "precision": 0.393101,
            "precision_weighted": 0.393084,
            "recall": 0.432716,
            "recall_weighted": 0.432617,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.4375,
            "f1": 0.412943,
            "f1_weighted": 0.4129,
            "precision": 0.419096,
            "precision_weighted": 0.419099,
            "recall": 0.437606,
            "recall_weighted": 0.4375,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.397461,
            "f1": 0.381312,
            "f1_weighted": 0.381305,
            "precision": 0.374537,
            "precision_weighted": 0.374539,
            "recall": 0.397468,
            "recall_weighted": 0.397461,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.422168,
        "f1": 0.385039,
        "f1_weighted": 0.385007,
        "precision": 0.39031,
        "precision_weighted": 0.390303,
        "recall": 0.42223,
        "recall_weighted": 0.422168,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.422168,
        "hf_subset": "default",
        "languages": [
          "fil-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 44.484715938568115,
  "kg_co2_emissions": null
}