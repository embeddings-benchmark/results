{
  "dataset_revision": "c0ba03d058e3e1b2f3fd20518875a4563dd12db4",
  "task_name": "CEDRClassification",
  "mteb_version": "2.3.11",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.647715,
            "lrap": 0.914878,
            "f1": 0.664039,
            "hamming": 0.654623
          },
          {
            "accuracy": 0.673751,
            "lrap": 0.904623,
            "f1": 0.670874,
            "hamming": 0.679862
          },
          {
            "accuracy": 0.682784,
            "lrap": 0.913974,
            "f1": 0.680888,
            "hamming": 0.688895
          },
          {
            "accuracy": 0.566419,
            "lrap": 0.909192,
            "f1": 0.656471,
            "hamming": 0.581031
          },
          {
            "accuracy": 0.721041,
            "lrap": 0.912859,
            "f1": 0.700696,
            "hamming": 0.727418
          },
          {
            "accuracy": 0.664187,
            "lrap": 0.916312,
            "f1": 0.670536,
            "hamming": 0.67136
          },
          {
            "accuracy": 0.593518,
            "lrap": 0.916366,
            "f1": 0.643951,
            "hamming": 0.600956
          },
          {
            "accuracy": 0.670563,
            "lrap": 0.907811,
            "f1": 0.664695,
            "hamming": 0.675611
          },
          {
            "accuracy": 0.629649,
            "lrap": 0.916419,
            "f1": 0.657319,
            "hamming": 0.640011
          },
          {
            "accuracy": 0.650903,
            "lrap": 0.915383,
            "f1": 0.663844,
            "hamming": 0.658254
          }
        ],
        "accuracy": 0.650053,
        "lrap": 0.912782,
        "f1": 0.667331,
        "hamming": 0.657802,
        "main_score": 0.650053,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ]
      }
    ]
  },
  "evaluation_time": 67.93614864349365,
  "kg_co2_emissions": null
}