{
  "dataset_revision": "f7393532774c66312378d30b197610b43d751972",
  "task_name": "NorwegianParliamentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.557333,
        "f1": 0.553822,
        "f1_weighted": 0.553822,
        "ap": 0.532656,
        "ap_weighted": 0.532656,
        "scores_per_experiment": [
          {
            "accuracy": 0.585833,
            "f1": 0.585831,
            "f1_weighted": 0.585831,
            "ap": 0.550321,
            "ap_weighted": 0.550321
          },
          {
            "accuracy": 0.523333,
            "f1": 0.521097,
            "f1_weighted": 0.521097,
            "ap": 0.512297,
            "ap_weighted": 0.512297
          },
          {
            "accuracy": 0.546667,
            "f1": 0.545206,
            "f1_weighted": 0.545206,
            "ap": 0.525289,
            "ap_weighted": 0.525289
          },
          {
            "accuracy": 0.593333,
            "f1": 0.592446,
            "f1_weighted": 0.592446,
            "ap": 0.556275,
            "ap_weighted": 0.556275
          },
          {
            "accuracy": 0.573333,
            "f1": 0.567446,
            "f1_weighted": 0.567446,
            "ap": 0.543681,
            "ap_weighted": 0.543681
          },
          {
            "accuracy": 0.525833,
            "f1": 0.506247,
            "f1_weighted": 0.506247,
            "ap": 0.513394,
            "ap_weighted": 0.513394
          },
          {
            "accuracy": 0.544167,
            "f1": 0.543936,
            "f1_weighted": 0.543936,
            "ap": 0.524126,
            "ap_weighted": 0.524126
          },
          {
            "accuracy": 0.549167,
            "f1": 0.548414,
            "f1_weighted": 0.548414,
            "ap": 0.527216,
            "ap_weighted": 0.527216
          },
          {
            "accuracy": 0.579167,
            "f1": 0.575266,
            "f1_weighted": 0.575266,
            "ap": 0.544843,
            "ap_weighted": 0.544843
          },
          {
            "accuracy": 0.5525,
            "f1": 0.552336,
            "f1_weighted": 0.552336,
            "ap": 0.529116,
            "ap_weighted": 0.529116
          }
        ],
        "main_score": 0.557333,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.56125,
        "f1": 0.55864,
        "f1_weighted": 0.55864,
        "ap": 0.535504,
        "ap_weighted": 0.535504,
        "scores_per_experiment": [
          {
            "accuracy": 0.575833,
            "f1": 0.575677,
            "f1_weighted": 0.575677,
            "ap": 0.543897,
            "ap_weighted": 0.543897
          },
          {
            "accuracy": 0.540833,
            "f1": 0.538935,
            "f1_weighted": 0.538935,
            "ap": 0.52233,
            "ap_weighted": 0.52233
          },
          {
            "accuracy": 0.556667,
            "f1": 0.554688,
            "f1_weighted": 0.554688,
            "ap": 0.531167,
            "ap_weighted": 0.531167
          },
          {
            "accuracy": 0.614167,
            "f1": 0.613716,
            "f1_weighted": 0.613716,
            "ap": 0.571073,
            "ap_weighted": 0.571073
          },
          {
            "accuracy": 0.5875,
            "f1": 0.580129,
            "f1_weighted": 0.580129,
            "ap": 0.554167,
            "ap_weighted": 0.554167
          },
          {
            "accuracy": 0.546667,
            "f1": 0.534241,
            "f1_weighted": 0.534241,
            "ap": 0.524975,
            "ap_weighted": 0.524975
          },
          {
            "accuracy": 0.546667,
            "f1": 0.546621,
            "f1_weighted": 0.546621,
            "ap": 0.525556,
            "ap_weighted": 0.525556
          },
          {
            "accuracy": 0.509167,
            "f1": 0.509044,
            "f1_weighted": 0.509044,
            "ap": 0.50467,
            "ap_weighted": 0.50467
          },
          {
            "accuracy": 0.594167,
            "f1": 0.59282,
            "f1_weighted": 0.59282,
            "ap": 0.555036,
            "ap_weighted": 0.555036
          },
          {
            "accuracy": 0.540833,
            "f1": 0.540527,
            "f1_weighted": 0.540527,
            "ap": 0.522175,
            "ap_weighted": 0.522175
          }
        ],
        "main_score": 0.56125,
        "hf_subset": "default",
        "languages": [
          "nob-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 20.27630090713501,
  "kg_co2_emissions": 0.0009034040884464444
}