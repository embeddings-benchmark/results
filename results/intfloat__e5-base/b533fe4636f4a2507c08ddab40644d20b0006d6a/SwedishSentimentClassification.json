{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.723828,
        "f1": 0.722385,
        "f1_weighted": 0.72243,
        "ap": 0.659158,
        "ap_weighted": 0.659158,
        "scores_per_experiment": [
          {
            "accuracy": 0.722168,
            "f1": 0.716199,
            "f1_weighted": 0.71632,
            "ap": 0.65043,
            "ap_weighted": 0.65043
          },
          {
            "accuracy": 0.728027,
            "f1": 0.727106,
            "f1_weighted": 0.727152,
            "ap": 0.661897,
            "ap_weighted": 0.661897
          },
          {
            "accuracy": 0.713379,
            "f1": 0.713107,
            "f1_weighted": 0.713133,
            "ap": 0.650962,
            "ap_weighted": 0.650962
          },
          {
            "accuracy": 0.712402,
            "f1": 0.711782,
            "f1_weighted": 0.711821,
            "ap": 0.648824,
            "ap_weighted": 0.648824
          },
          {
            "accuracy": 0.751465,
            "f1": 0.751094,
            "f1_weighted": 0.751066,
            "ap": 0.695858,
            "ap_weighted": 0.695858
          },
          {
            "accuracy": 0.682617,
            "f1": 0.681947,
            "f1_weighted": 0.68199,
            "ap": 0.623203,
            "ap_weighted": 0.623203
          },
          {
            "accuracy": 0.740234,
            "f1": 0.739118,
            "f1_weighted": 0.739168,
            "ap": 0.672426,
            "ap_weighted": 0.672426
          },
          {
            "accuracy": 0.74707,
            "f1": 0.74384,
            "f1_weighted": 0.743924,
            "ap": 0.674528,
            "ap_weighted": 0.674528
          },
          {
            "accuracy": 0.722168,
            "f1": 0.720955,
            "f1_weighted": 0.721009,
            "ap": 0.655975,
            "ap_weighted": 0.655975
          },
          {
            "accuracy": 0.71875,
            "f1": 0.718705,
            "f1_weighted": 0.718715,
            "ap": 0.657473,
            "ap_weighted": 0.657473
          }
        ],
        "main_score": 0.723828,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.72334,
        "f1": 0.721908,
        "f1_weighted": 0.721936,
        "ap": 0.658093,
        "ap_weighted": 0.658093,
        "scores_per_experiment": [
          {
            "accuracy": 0.730469,
            "f1": 0.724639,
            "f1_weighted": 0.724717,
            "ap": 0.657094,
            "ap_weighted": 0.657094
          },
          {
            "accuracy": 0.744629,
            "f1": 0.743612,
            "f1_weighted": 0.743643,
            "ap": 0.676314,
            "ap_weighted": 0.676314
          },
          {
            "accuracy": 0.701172,
            "f1": 0.700898,
            "f1_weighted": 0.700915,
            "ap": 0.639668,
            "ap_weighted": 0.639668
          },
          {
            "accuracy": 0.727051,
            "f1": 0.726534,
            "f1_weighted": 0.726558,
            "ap": 0.661848,
            "ap_weighted": 0.661848
          },
          {
            "accuracy": 0.72168,
            "f1": 0.721117,
            "f1_weighted": 0.721092,
            "ap": 0.665908,
            "ap_weighted": 0.665908
          },
          {
            "accuracy": 0.695312,
            "f1": 0.694774,
            "f1_weighted": 0.694799,
            "ap": 0.63375,
            "ap_weighted": 0.63375
          },
          {
            "accuracy": 0.743652,
            "f1": 0.742534,
            "f1_weighted": 0.742567,
            "ap": 0.675124,
            "ap_weighted": 0.675124
          },
          {
            "accuracy": 0.73291,
            "f1": 0.729468,
            "f1_weighted": 0.729528,
            "ap": 0.661486,
            "ap_weighted": 0.661486
          },
          {
            "accuracy": 0.721191,
            "f1": 0.720182,
            "f1_weighted": 0.720215,
            "ap": 0.655139,
            "ap_weighted": 0.655139
          },
          {
            "accuracy": 0.715332,
            "f1": 0.715327,
            "f1_weighted": 0.715329,
            "ap": 0.6546,
            "ap_weighted": 0.6546
          }
        ],
        "main_score": 0.72334,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 18.147395849227905,
  "kg_co2_emissions": 0.0006813997461303647
}