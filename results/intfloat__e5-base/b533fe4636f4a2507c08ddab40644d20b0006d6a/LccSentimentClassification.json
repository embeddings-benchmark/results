{
  "dataset_revision": "de7ba3406ee55ea2cc52a0a41408fa6aede6d3c6",
  "task_name": "LccSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.374667,
        "f1": 0.349595,
        "f1_weighted": 0.388129,
        "scores_per_experiment": [
          {
            "accuracy": 0.366667,
            "f1": 0.340739,
            "f1_weighted": 0.38686
          },
          {
            "accuracy": 0.353333,
            "f1": 0.344463,
            "f1_weighted": 0.367823
          },
          {
            "accuracy": 0.353333,
            "f1": 0.3363,
            "f1_weighted": 0.36566
          },
          {
            "accuracy": 0.366667,
            "f1": 0.343219,
            "f1_weighted": 0.381377
          },
          {
            "accuracy": 0.32,
            "f1": 0.295834,
            "f1_weighted": 0.338038
          },
          {
            "accuracy": 0.453333,
            "f1": 0.392774,
            "f1_weighted": 0.465338
          },
          {
            "accuracy": 0.42,
            "f1": 0.405404,
            "f1_weighted": 0.438746
          },
          {
            "accuracy": 0.44,
            "f1": 0.391655,
            "f1_weighted": 0.453944
          },
          {
            "accuracy": 0.353333,
            "f1": 0.332607,
            "f1_weighted": 0.365435
          },
          {
            "accuracy": 0.32,
            "f1": 0.312954,
            "f1_weighted": 0.318072
          }
        ],
        "main_score": 0.374667,
        "hf_subset": "default",
        "languages": [
          "dan-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 6.615284442901611,
  "kg_co2_emissions": 0.0002023221572333686
}