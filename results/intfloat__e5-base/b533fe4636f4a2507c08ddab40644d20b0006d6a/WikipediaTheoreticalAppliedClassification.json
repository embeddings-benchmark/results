{
  "dataset_revision": "7896906653d31d7102a143d7f55d67cd688e3147",
  "task_name": "WikipediaTheoreticalAppliedClassification",
  "mteb_version": "1.26.4",
  "scores": {
    "test": [
      {
        "accuracy": 0.638355,
        "f1": 0.635901,
        "f1_weighted": 0.636836,
        "ap": 0.561394,
        "ap_weighted": 0.561394,
        "scores_per_experiment": [
          {
            "accuracy": 0.656812,
            "f1": 0.656143,
            "f1_weighted": 0.655269,
            "ap": 0.575721,
            "ap_weighted": 0.575721
          },
          {
            "accuracy": 0.643959,
            "f1": 0.643402,
            "f1_weighted": 0.644214,
            "ap": 0.565159,
            "ap_weighted": 0.565159
          },
          {
            "accuracy": 0.660754,
            "f1": 0.660107,
            "f1_weighted": 0.660961,
            "ap": 0.579118,
            "ap_weighted": 0.579118
          },
          {
            "accuracy": 0.619966,
            "f1": 0.618121,
            "f1_weighted": 0.61965,
            "ap": 0.546,
            "ap_weighted": 0.546
          },
          {
            "accuracy": 0.605313,
            "f1": 0.604989,
            "f1_weighted": 0.604338,
            "ap": 0.536747,
            "ap_weighted": 0.536747
          },
          {
            "accuracy": 0.653899,
            "f1": 0.653564,
            "f1_weighted": 0.654184,
            "ap": 0.573296,
            "ap_weighted": 0.573296
          },
          {
            "accuracy": 0.664096,
            "f1": 0.663883,
            "f1_weighted": 0.663395,
            "ap": 0.581585,
            "ap_weighted": 0.581585
          },
          {
            "accuracy": 0.604884,
            "f1": 0.603982,
            "f1_weighted": 0.605071,
            "ap": 0.534987,
            "ap_weighted": 0.534987
          },
          {
            "accuracy": 0.628449,
            "f1": 0.624895,
            "f1_weighted": 0.626997,
            "ap": 0.55252,
            "ap_weighted": 0.55252
          },
          {
            "accuracy": 0.645416,
            "f1": 0.629919,
            "f1_weighted": 0.63428,
            "ap": 0.56881,
            "ap_weighted": 0.56881
          }
        ],
        "main_score": 0.638355,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 113.2717547416687,
  "kg_co2_emissions": null
}