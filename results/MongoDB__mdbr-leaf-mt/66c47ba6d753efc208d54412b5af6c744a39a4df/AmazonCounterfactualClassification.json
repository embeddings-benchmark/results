{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "task_name": "AmazonCounterfactualClassification",
  "mteb_version": "1.38.39",
  "scores": {
    "test": [
      {
        "accuracy": 0.705522,
        "f1": 0.648289,
        "f1_weighted": 0.734072,
        "ap": 0.337611,
        "ap_weighted": 0.337611,
        "scores_per_experiment": [
          {
            "accuracy": 0.704478,
            "f1": 0.645127,
            "f1_weighted": 0.733503,
            "ap": 0.330089,
            "ap_weighted": 0.330089
          },
          {
            "accuracy": 0.667164,
            "f1": 0.616751,
            "f1_weighted": 0.701395,
            "ap": 0.311594,
            "ap_weighted": 0.311594
          },
          {
            "accuracy": 0.667164,
            "f1": 0.612826,
            "f1_weighted": 0.701153,
            "ap": 0.303813,
            "ap_weighted": 0.303813
          },
          {
            "accuracy": 0.708955,
            "f1": 0.644659,
            "f1_weighted": 0.736704,
            "ap": 0.324964,
            "ap_weighted": 0.324964
          },
          {
            "accuracy": 0.7,
            "f1": 0.640277,
            "f1_weighted": 0.729534,
            "ap": 0.324866,
            "ap_weighted": 0.324866
          },
          {
            "accuracy": 0.744776,
            "f1": 0.683399,
            "f1_weighted": 0.768287,
            "ap": 0.368775,
            "ap_weighted": 0.368775
          },
          {
            "accuracy": 0.801493,
            "f1": 0.729867,
            "f1_weighted": 0.814572,
            "ap": 0.414874,
            "ap_weighted": 0.414874
          },
          {
            "accuracy": 0.716418,
            "f1": 0.660457,
            "f1_weighted": 0.744398,
            "ap": 0.34953,
            "ap_weighted": 0.34953
          },
          {
            "accuracy": 0.655224,
            "f1": 0.618058,
            "f1_weighted": 0.690611,
            "ap": 0.329802,
            "ap_weighted": 0.329802
          },
          {
            "accuracy": 0.689552,
            "f1": 0.631463,
            "f1_weighted": 0.720562,
            "ap": 0.317799,
            "ap_weighted": 0.317799
          }
        ],
        "main_score": 0.705522,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 2.0711417198181152,
  "kg_co2_emissions": null
}