{
  "dataset_revision": "3d96e36e10a88d5b7a3f617cf8362d997504494b",
  "task_name": "KorSarcasmClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.529883,
        "f1": 0.524806,
        "f1_weighted": 0.52485,
        "ap": 0.515941,
        "ap_weighted": 0.515941,
        "scores_per_experiment": [
          {
            "accuracy": 0.586914,
            "f1": 0.585243,
            "f1_weighted": 0.585294,
            "ap": 0.551045,
            "ap_weighted": 0.551045
          },
          {
            "accuracy": 0.508301,
            "f1": 0.507412,
            "f1_weighted": 0.507453,
            "ap": 0.503207,
            "ap_weighted": 0.503207
          },
          {
            "accuracy": 0.583496,
            "f1": 0.57662,
            "f1_weighted": 0.576514,
            "ap": 0.546488,
            "ap_weighted": 0.546488
          },
          {
            "accuracy": 0.511719,
            "f1": 0.511148,
            "f1_weighted": 0.511115,
            "ap": 0.505047,
            "ap_weighted": 0.505047
          },
          {
            "accuracy": 0.509766,
            "f1": 0.483957,
            "f1_weighted": 0.484183,
            "ap": 0.503846,
            "ap_weighted": 0.503846
          },
          {
            "accuracy": 0.522949,
            "f1": 0.522605,
            "f1_weighted": 0.52263,
            "ap": 0.511027,
            "ap_weighted": 0.511027
          },
          {
            "accuracy": 0.556641,
            "f1": 0.551838,
            "f1_weighted": 0.551929,
            "ap": 0.531259,
            "ap_weighted": 0.531259
          },
          {
            "accuracy": 0.498535,
            "f1": 0.491011,
            "f1_weighted": 0.491132,
            "ap": 0.498177,
            "ap_weighted": 0.498177
          },
          {
            "accuracy": 0.491211,
            "f1": 0.490774,
            "f1_weighted": 0.490745,
            "ap": 0.49473,
            "ap_weighted": 0.49473
          },
          {
            "accuracy": 0.529297,
            "f1": 0.527451,
            "f1_weighted": 0.527509,
            "ap": 0.514584,
            "ap_weighted": 0.514584
          }
        ],
        "main_score": 0.529883,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ]
      }
    ]
  },
  "evaluation_time": 8.249390125274658,
  "kg_co2_emissions": 0.00025035777177823273
}