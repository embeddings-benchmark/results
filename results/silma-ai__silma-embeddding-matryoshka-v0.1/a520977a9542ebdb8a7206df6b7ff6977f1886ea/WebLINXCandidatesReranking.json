{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.109359,
        "mrr": 0.092697,
        "nAUC_map_max": -0.038637,
        "nAUC_map_std": -0.077187,
        "nAUC_map_diff1": 0.171968,
        "nAUC_mrr_max": -0.045783,
        "nAUC_mrr_std": -0.08709,
        "nAUC_mrr_diff1": 0.173674,
        "main_score": 0.092697,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.090665,
        "mrr": 0.072918,
        "nAUC_map_max": -0.148264,
        "nAUC_map_std": 0.001368,
        "nAUC_map_diff1": 0.046211,
        "nAUC_mrr_max": -0.153819,
        "nAUC_mrr_std": -0.009101,
        "nAUC_mrr_diff1": 0.050639,
        "main_score": 0.072918,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.084781,
        "mrr": 0.068443,
        "nAUC_map_max": -0.065657,
        "nAUC_map_std": 0.052021,
        "nAUC_map_diff1": 0.060169,
        "nAUC_mrr_max": -0.050743,
        "nAUC_mrr_std": 0.038332,
        "nAUC_mrr_diff1": 0.078341,
        "main_score": 0.068443,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.088553,
        "mrr": 0.068515,
        "nAUC_map_max": -0.156984,
        "nAUC_map_std": -0.010717,
        "nAUC_map_diff1": 0.145813,
        "nAUC_mrr_max": -0.158483,
        "nAUC_mrr_std": -0.013867,
        "nAUC_mrr_diff1": 0.144785,
        "main_score": 0.068515,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.093517,
        "mrr": 0.075513,
        "nAUC_map_max": -0.176369,
        "nAUC_map_std": 0.039894,
        "nAUC_map_diff1": 0.086666,
        "nAUC_mrr_max": -0.176519,
        "nAUC_mrr_std": 0.036666,
        "nAUC_mrr_diff1": 0.090944,
        "main_score": 0.075513,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.077901,
        "mrr": 0.061217,
        "nAUC_map_max": -0.08894,
        "nAUC_map_std": 0.053314,
        "nAUC_map_diff1": 0.085075,
        "nAUC_mrr_max": -0.095759,
        "nAUC_mrr_std": 0.044249,
        "nAUC_mrr_diff1": 0.087939,
        "main_score": 0.061217,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 2657.221962928772,
  "kg_co2_emissions": 0.23399609313025108
}