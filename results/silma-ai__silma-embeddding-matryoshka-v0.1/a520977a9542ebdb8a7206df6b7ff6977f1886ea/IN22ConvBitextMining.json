{
  "dataset_revision": "16f46f059d56eac7c65c3c9581a45e40199eb140",
  "task_name": "IN22ConvBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.039753,
        "recall": 0.066534,
        "f1": 0.045413,
        "accuracy": 0.066534,
        "main_score": 0.045413,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.027136,
        "recall": 0.04857,
        "f1": 0.031101,
        "accuracy": 0.04857,
        "main_score": 0.031101,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.027339,
        "recall": 0.040585,
        "f1": 0.030733,
        "accuracy": 0.040585,
        "main_score": 0.030733,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000795,
        "recall": 0.008649,
        "f1": 0.001316,
        "accuracy": 0.008649,
        "main_score": 0.001316,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023469,
        "recall": 0.051231,
        "f1": 0.028522,
        "accuracy": 0.051231,
        "main_score": 0.028522,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.027078,
        "recall": 0.052562,
        "f1": 0.032247,
        "accuracy": 0.052562,
        "main_score": 0.032247,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.033304,
        "recall": 0.050566,
        "f1": 0.036946,
        "accuracy": 0.050566,
        "main_score": 0.036946,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.014584,
        "recall": 0.027944,
        "f1": 0.017056,
        "accuracy": 0.027944,
        "main_score": 0.017056,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.002536,
        "recall": 0.016633,
        "f1": 0.003844,
        "accuracy": 0.016633,
        "main_score": 0.003844,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.029025,
        "recall": 0.04857,
        "f1": 0.033095,
        "accuracy": 0.04857,
        "main_score": 0.033095,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.012033,
        "recall": 0.021956,
        "f1": 0.013319,
        "accuracy": 0.021956,
        "main_score": 0.013319,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.023206,
        "recall": 0.041916,
        "f1": 0.026872,
        "accuracy": 0.041916,
        "main_score": 0.026872,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.034615,
        "recall": 0.053227,
        "f1": 0.038187,
        "accuracy": 0.053227,
        "main_score": 0.038187,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.035934,
        "recall": 0.061211,
        "f1": 0.041026,
        "accuracy": 0.061211,
        "main_score": 0.041026,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.038964,
        "recall": 0.063872,
        "f1": 0.044073,
        "accuracy": 0.063872,
        "main_score": 0.044073,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.027291,
        "recall": 0.043912,
        "f1": 0.030581,
        "accuracy": 0.043912,
        "main_score": 0.030581,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.025832,
        "recall": 0.047904,
        "f1": 0.030015,
        "accuracy": 0.047904,
        "main_score": 0.030015,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.030186,
        "recall": 0.046574,
        "f1": 0.033842,
        "accuracy": 0.046574,
        "main_score": 0.033842,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.018585,
        "recall": 0.033932,
        "f1": 0.021689,
        "accuracy": 0.033932,
        "main_score": 0.021689,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.006571,
        "recall": 0.017964,
        "f1": 0.007809,
        "accuracy": 0.017964,
        "main_score": 0.007809,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009187,
        "recall": 0.024617,
        "f1": 0.011946,
        "accuracy": 0.024617,
        "main_score": 0.011946,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003319,
        "recall": 0.017299,
        "f1": 0.004848,
        "accuracy": 0.017299,
        "main_score": 0.004848,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.036635,
        "recall": 0.067199,
        "f1": 0.043163,
        "accuracy": 0.067199,
        "main_score": 0.043163,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.019612,
        "recall": 0.041251,
        "f1": 0.023464,
        "accuracy": 0.041251,
        "main_score": 0.023464,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.026797,
        "recall": 0.044578,
        "f1": 0.030336,
        "accuracy": 0.044578,
        "main_score": 0.030336,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000739,
        "recall": 0.006653,
        "f1": 0.001177,
        "accuracy": 0.006653,
        "main_score": 0.001177,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024523,
        "recall": 0.045243,
        "f1": 0.028261,
        "accuracy": 0.045243,
        "main_score": 0.028261,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.021781,
        "recall": 0.041251,
        "f1": 0.025885,
        "accuracy": 0.041251,
        "main_score": 0.025885,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.031337,
        "recall": 0.047239,
        "f1": 0.035171,
        "accuracy": 0.047239,
        "main_score": 0.035171,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.014824,
        "recall": 0.024617,
        "f1": 0.016707,
        "accuracy": 0.024617,
        "main_score": 0.016707,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.003117,
        "recall": 0.018629,
        "f1": 0.004728,
        "accuracy": 0.018629,
        "main_score": 0.004728,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.027588,
        "recall": 0.047904,
        "f1": 0.031822,
        "accuracy": 0.047904,
        "main_score": 0.031822,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.013189,
        "recall": 0.023952,
        "f1": 0.014787,
        "accuracy": 0.023952,
        "main_score": 0.014787,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.025564,
        "recall": 0.042582,
        "f1": 0.029,
        "accuracy": 0.042582,
        "main_score": 0.029,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.029536,
        "recall": 0.04857,
        "f1": 0.033613,
        "accuracy": 0.04857,
        "main_score": 0.033613,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.040614,
        "recall": 0.061876,
        "f1": 0.045371,
        "accuracy": 0.061876,
        "main_score": 0.045371,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.033032,
        "recall": 0.053227,
        "f1": 0.037033,
        "accuracy": 0.053227,
        "main_score": 0.037033,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.020191,
        "recall": 0.033932,
        "f1": 0.022391,
        "accuracy": 0.033932,
        "main_score": 0.022391,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019273,
        "recall": 0.035263,
        "f1": 0.022129,
        "accuracy": 0.035263,
        "main_score": 0.022129,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.023829,
        "recall": 0.043247,
        "f1": 0.028088,
        "accuracy": 0.043247,
        "main_score": 0.028088,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.018137,
        "recall": 0.037259,
        "f1": 0.021649,
        "accuracy": 0.037259,
        "main_score": 0.021649,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.005191,
        "recall": 0.016633,
        "f1": 0.006946,
        "accuracy": 0.016633,
        "main_score": 0.006946,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.013359,
        "recall": 0.025948,
        "f1": 0.015233,
        "accuracy": 0.025948,
        "main_score": 0.015233,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002677,
        "recall": 0.015303,
        "f1": 0.003987,
        "accuracy": 0.015303,
        "main_score": 0.003987,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.036255,
        "recall": 0.057219,
        "f1": 0.040537,
        "accuracy": 0.057219,
        "main_score": 0.040537,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.026642,
        "recall": 0.044578,
        "f1": 0.02993,
        "accuracy": 0.044578,
        "main_score": 0.02993,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.045052,
        "recall": 0.063872,
        "f1": 0.049063,
        "accuracy": 0.063872,
        "main_score": 0.049063,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.014988,
        "recall": 0.023287,
        "f1": 0.016288,
        "accuracy": 0.023287,
        "main_score": 0.016288,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.048649,
        "recall": 0.070526,
        "f1": 0.053255,
        "accuracy": 0.070526,
        "main_score": 0.053255,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.035121,
        "recall": 0.057884,
        "f1": 0.040026,
        "accuracy": 0.057884,
        "main_score": 0.040026,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.05479,
        "recall": 0.072522,
        "f1": 0.059045,
        "accuracy": 0.072522,
        "main_score": 0.059045,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.012549,
        "recall": 0.022621,
        "f1": 0.014828,
        "accuracy": 0.022621,
        "main_score": 0.014828,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.020957,
        "recall": 0.037924,
        "f1": 0.023942,
        "accuracy": 0.037924,
        "main_score": 0.023942,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.019769,
        "recall": 0.034597,
        "f1": 0.022563,
        "accuracy": 0.034597,
        "main_score": 0.022563,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.036565,
        "recall": 0.052562,
        "f1": 0.03958,
        "accuracy": 0.052562,
        "main_score": 0.03958,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.019162,
        "recall": 0.037259,
        "f1": 0.022231,
        "accuracy": 0.037259,
        "main_score": 0.022231,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.027736,
        "recall": 0.047239,
        "f1": 0.032008,
        "accuracy": 0.047239,
        "main_score": 0.032008,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.02823,
        "recall": 0.050566,
        "f1": 0.032838,
        "accuracy": 0.050566,
        "main_score": 0.032838,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.03248,
        "recall": 0.052562,
        "f1": 0.03609,
        "accuracy": 0.052562,
        "main_score": 0.03609,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.049708,
        "recall": 0.064538,
        "f1": 0.052409,
        "accuracy": 0.064538,
        "main_score": 0.052409,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.022233,
        "recall": 0.041251,
        "f1": 0.025988,
        "accuracy": 0.041251,
        "main_score": 0.025988,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.020665,
        "recall": 0.036593,
        "f1": 0.023786,
        "accuracy": 0.036593,
        "main_score": 0.023786,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.041047,
        "recall": 0.057219,
        "f1": 0.044353,
        "accuracy": 0.057219,
        "main_score": 0.044353,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.027501,
        "recall": 0.043247,
        "f1": 0.030305,
        "accuracy": 0.043247,
        "main_score": 0.030305,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.040399,
        "recall": 0.057219,
        "f1": 0.044343,
        "accuracy": 0.057219,
        "main_score": 0.044343,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.022961,
        "recall": 0.038589,
        "f1": 0.025271,
        "accuracy": 0.038589,
        "main_score": 0.025271,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.028121,
        "recall": 0.051896,
        "f1": 0.033166,
        "accuracy": 0.051896,
        "main_score": 0.033166,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.027754,
        "recall": 0.046574,
        "f1": 0.031544,
        "accuracy": 0.046574,
        "main_score": 0.031544,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.041875,
        "recall": 0.062542,
        "f1": 0.046209,
        "accuracy": 0.062542,
        "main_score": 0.046209,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.020089,
        "recall": 0.028609,
        "f1": 0.021149,
        "accuracy": 0.028609,
        "main_score": 0.021149,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.046188,
        "recall": 0.066534,
        "f1": 0.050066,
        "accuracy": 0.066534,
        "main_score": 0.050066,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.035596,
        "recall": 0.05988,
        "f1": 0.0407,
        "accuracy": 0.05988,
        "main_score": 0.0407,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.085336,
        "recall": 0.119095,
        "f1": 0.093317,
        "accuracy": 0.119095,
        "main_score": 0.093317,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.008758,
        "recall": 0.017299,
        "f1": 0.010253,
        "accuracy": 0.017299,
        "main_score": 0.010253,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.025343,
        "recall": 0.045243,
        "f1": 0.028112,
        "accuracy": 0.045243,
        "main_score": 0.028112,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.032009,
        "recall": 0.064538,
        "f1": 0.038357,
        "accuracy": 0.064538,
        "main_score": 0.038357,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.028485,
        "recall": 0.038589,
        "f1": 0.030005,
        "accuracy": 0.038589,
        "main_score": 0.030005,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.020509,
        "recall": 0.036593,
        "f1": 0.023419,
        "accuracy": 0.036593,
        "main_score": 0.023419,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.024107,
        "recall": 0.039255,
        "f1": 0.027557,
        "accuracy": 0.039255,
        "main_score": 0.027557,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.032193,
        "recall": 0.05988,
        "f1": 0.03808,
        "accuracy": 0.05988,
        "main_score": 0.03808,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.029058,
        "recall": 0.04857,
        "f1": 0.033224,
        "accuracy": 0.04857,
        "main_score": 0.033224,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.065952,
        "recall": 0.090486,
        "f1": 0.070392,
        "accuracy": 0.090486,
        "main_score": 0.070392,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.012809,
        "recall": 0.026613,
        "f1": 0.015165,
        "accuracy": 0.026613,
        "main_score": 0.015165,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.034052,
        "recall": 0.056554,
        "f1": 0.038966,
        "accuracy": 0.056554,
        "main_score": 0.038966,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.056256,
        "recall": 0.087159,
        "f1": 0.062619,
        "accuracy": 0.087159,
        "main_score": 0.062619,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.027503,
        "recall": 0.036593,
        "f1": 0.029066,
        "accuracy": 0.036593,
        "main_score": 0.029066,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.034544,
        "recall": 0.047239,
        "f1": 0.036692,
        "accuracy": 0.047239,
        "main_score": 0.036692,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.028249,
        "recall": 0.047239,
        "f1": 0.030779,
        "accuracy": 0.047239,
        "main_score": 0.030779,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001702,
        "recall": 0.008649,
        "f1": 0.002334,
        "accuracy": 0.008649,
        "main_score": 0.002334,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.000519,
        "recall": 0.006653,
        "f1": 0.000923,
        "accuracy": 0.006653,
        "main_score": 0.000923,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.01302,
        "recall": 0.038589,
        "f1": 0.017198,
        "accuracy": 0.038589,
        "main_score": 0.017198,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.013255,
        "recall": 0.040585,
        "f1": 0.017161,
        "accuracy": 0.040585,
        "main_score": 0.017161,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.015632,
        "recall": 0.043912,
        "f1": 0.020042,
        "accuracy": 0.043912,
        "main_score": 0.020042,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.004119,
        "recall": 0.023952,
        "f1": 0.00658,
        "accuracy": 0.023952,
        "main_score": 0.00658,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.011488,
        "recall": 0.040585,
        "f1": 0.015806,
        "accuracy": 0.040585,
        "main_score": 0.015806,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00195,
        "recall": 0.00998,
        "f1": 0.002742,
        "accuracy": 0.00998,
        "main_score": 0.002742,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.025653,
        "recall": 0.051896,
        "f1": 0.030743,
        "accuracy": 0.051896,
        "main_score": 0.030743,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.000891,
        "recall": 0.005988,
        "f1": 0.001393,
        "accuracy": 0.005988,
        "main_score": 0.001393,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.011911,
        "recall": 0.041916,
        "f1": 0.015759,
        "accuracy": 0.041916,
        "main_score": 0.015759,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001407,
        "recall": 0.009315,
        "f1": 0.001976,
        "accuracy": 0.009315,
        "main_score": 0.001976,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.002204,
        "recall": 0.011976,
        "f1": 0.00316,
        "accuracy": 0.011976,
        "main_score": 0.00316,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.001114,
        "recall": 0.007984,
        "f1": 0.001491,
        "accuracy": 0.007984,
        "main_score": 0.001491,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.001771,
        "recall": 0.005988,
        "f1": 0.002091,
        "accuracy": 0.005988,
        "main_score": 0.002091,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.017198,
        "recall": 0.044578,
        "f1": 0.021739,
        "accuracy": 0.044578,
        "main_score": 0.021739,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001009,
        "recall": 0.008649,
        "f1": 0.001609,
        "accuracy": 0.008649,
        "main_score": 0.001609,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000482,
        "recall": 0.007319,
        "f1": 0.000871,
        "accuracy": 0.007319,
        "main_score": 0.000871,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.010334,
        "recall": 0.038589,
        "f1": 0.013902,
        "accuracy": 0.038589,
        "main_score": 0.013902,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.010915,
        "recall": 0.035928,
        "f1": 0.014632,
        "accuracy": 0.035928,
        "main_score": 0.014632,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.015262,
        "recall": 0.046574,
        "f1": 0.020376,
        "accuracy": 0.046574,
        "main_score": 0.020376,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.038914,
        "recall": 0.061876,
        "f1": 0.04338,
        "accuracy": 0.061876,
        "main_score": 0.04338,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.024104,
        "recall": 0.042582,
        "f1": 0.027412,
        "accuracy": 0.042582,
        "main_score": 0.027412,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.025853,
        "recall": 0.043912,
        "f1": 0.02924,
        "accuracy": 0.043912,
        "main_score": 0.02924,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.047459,
        "recall": 0.06853,
        "f1": 0.051749,
        "accuracy": 0.06853,
        "main_score": 0.051749,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.048789,
        "recall": 0.064538,
        "f1": 0.05199,
        "accuracy": 0.064538,
        "main_score": 0.05199,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.023288,
        "recall": 0.033932,
        "f1": 0.02491,
        "accuracy": 0.033932,
        "main_score": 0.02491,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.043851,
        "recall": 0.067864,
        "f1": 0.049006,
        "accuracy": 0.067864,
        "main_score": 0.049006,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.057656,
        "recall": 0.06986,
        "f1": 0.060302,
        "accuracy": 0.06986,
        "main_score": 0.060302,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.032475,
        "recall": 0.051231,
        "f1": 0.036108,
        "accuracy": 0.051231,
        "main_score": 0.036108,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.020003,
        "recall": 0.037924,
        "f1": 0.02306,
        "accuracy": 0.037924,
        "main_score": 0.02306,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.01575,
        "recall": 0.026613,
        "f1": 0.017804,
        "accuracy": 0.026613,
        "main_score": 0.017804,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.048232,
        "recall": 0.066534,
        "f1": 0.05237,
        "accuracy": 0.066534,
        "main_score": 0.05237,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.035423,
        "recall": 0.059215,
        "f1": 0.040175,
        "accuracy": 0.059215,
        "main_score": 0.040175,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.028524,
        "recall": 0.04857,
        "f1": 0.031949,
        "accuracy": 0.04857,
        "main_score": 0.031949,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.02633,
        "recall": 0.045908,
        "f1": 0.030146,
        "accuracy": 0.045908,
        "main_score": 0.030146,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.02316,
        "recall": 0.03992,
        "f1": 0.026244,
        "accuracy": 0.03992,
        "main_score": 0.026244,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.054402,
        "recall": 0.067199,
        "f1": 0.056958,
        "accuracy": 0.067199,
        "main_score": 0.056958,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.023483,
        "recall": 0.041251,
        "f1": 0.026478,
        "accuracy": 0.041251,
        "main_score": 0.026478,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.017619,
        "recall": 0.032601,
        "f1": 0.019873,
        "accuracy": 0.032601,
        "main_score": 0.019873,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.043755,
        "recall": 0.057219,
        "f1": 0.046757,
        "accuracy": 0.057219,
        "main_score": 0.046757,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.044746,
        "recall": 0.066534,
        "f1": 0.049012,
        "accuracy": 0.066534,
        "main_score": 0.049012,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.061105,
        "recall": 0.081171,
        "f1": 0.065359,
        "accuracy": 0.081171,
        "main_score": 0.065359,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.027907,
        "recall": 0.041251,
        "f1": 0.029624,
        "accuracy": 0.041251,
        "main_score": 0.029624,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.027768,
        "recall": 0.04857,
        "f1": 0.03154,
        "accuracy": 0.04857,
        "main_score": 0.03154,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.025815,
        "recall": 0.0499,
        "f1": 0.029891,
        "accuracy": 0.0499,
        "main_score": 0.029891,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.030653,
        "recall": 0.0499,
        "f1": 0.034244,
        "accuracy": 0.0499,
        "main_score": 0.034244,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.034127,
        "recall": 0.050566,
        "f1": 0.037321,
        "accuracy": 0.050566,
        "main_score": 0.037321,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.011838,
        "recall": 0.017964,
        "f1": 0.012417,
        "accuracy": 0.017964,
        "main_score": 0.012417,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.049297,
        "recall": 0.069195,
        "f1": 0.053285,
        "accuracy": 0.069195,
        "main_score": 0.053285,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.046338,
        "recall": 0.067864,
        "f1": 0.05135,
        "accuracy": 0.067864,
        "main_score": 0.05135,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.018973,
        "recall": 0.031271,
        "f1": 0.021565,
        "accuracy": 0.031271,
        "main_score": 0.021565,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.011507,
        "recall": 0.023287,
        "f1": 0.013275,
        "accuracy": 0.023287,
        "main_score": 0.013275,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.021052,
        "recall": 0.037924,
        "f1": 0.02422,
        "accuracy": 0.037924,
        "main_score": 0.02422,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.024351,
        "recall": 0.032601,
        "f1": 0.026044,
        "accuracy": 0.032601,
        "main_score": 0.026044,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.044434,
        "recall": 0.069195,
        "f1": 0.0499,
        "accuracy": 0.069195,
        "main_score": 0.0499,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.02056,
        "recall": 0.037259,
        "f1": 0.024059,
        "accuracy": 0.037259,
        "main_score": 0.024059,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.027556,
        "recall": 0.04857,
        "f1": 0.031603,
        "accuracy": 0.04857,
        "main_score": 0.031603,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.026999,
        "recall": 0.043912,
        "f1": 0.030001,
        "accuracy": 0.043912,
        "main_score": 0.030001,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.033606,
        "recall": 0.049235,
        "f1": 0.036172,
        "accuracy": 0.049235,
        "main_score": 0.036172,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.020211,
        "recall": 0.038589,
        "f1": 0.023685,
        "accuracy": 0.038589,
        "main_score": 0.023685,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.022829,
        "recall": 0.039255,
        "f1": 0.026643,
        "accuracy": 0.039255,
        "main_score": 0.026643,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.033772,
        "recall": 0.053227,
        "f1": 0.037512,
        "accuracy": 0.053227,
        "main_score": 0.037512,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.023051,
        "recall": 0.031271,
        "f1": 0.024748,
        "accuracy": 0.031271,
        "main_score": 0.024748,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.034579,
        "recall": 0.046574,
        "f1": 0.036952,
        "accuracy": 0.046574,
        "main_score": 0.036952,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.016125,
        "recall": 0.026613,
        "f1": 0.017503,
        "accuracy": 0.026613,
        "main_score": 0.017503,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.030052,
        "recall": 0.055223,
        "f1": 0.035292,
        "accuracy": 0.055223,
        "main_score": 0.035292,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.025736,
        "recall": 0.043912,
        "f1": 0.029785,
        "accuracy": 0.043912,
        "main_score": 0.029785,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.050254,
        "recall": 0.071856,
        "f1": 0.054892,
        "accuracy": 0.071856,
        "main_score": 0.054892,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.087018,
        "recall": 0.121091,
        "f1": 0.095082,
        "accuracy": 0.121091,
        "main_score": 0.095082,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.018577,
        "recall": 0.028609,
        "f1": 0.020041,
        "accuracy": 0.028609,
        "main_score": 0.020041,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.054171,
        "recall": 0.072522,
        "f1": 0.058013,
        "accuracy": 0.072522,
        "main_score": 0.058013,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.0432,
        "recall": 0.069195,
        "f1": 0.04899,
        "accuracy": 0.069195,
        "main_score": 0.04899,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.012825,
        "recall": 0.026613,
        "f1": 0.015163,
        "accuracy": 0.026613,
        "main_score": 0.015163,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.022741,
        "recall": 0.043912,
        "f1": 0.02579,
        "accuracy": 0.043912,
        "main_score": 0.02579,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.037874,
        "recall": 0.066534,
        "f1": 0.044204,
        "accuracy": 0.066534,
        "main_score": 0.044204,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.030569,
        "recall": 0.044578,
        "f1": 0.033245,
        "accuracy": 0.044578,
        "main_score": 0.033245,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.024362,
        "recall": 0.040585,
        "f1": 0.027405,
        "accuracy": 0.040585,
        "main_score": 0.027405,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.028123,
        "recall": 0.047239,
        "f1": 0.032671,
        "accuracy": 0.047239,
        "main_score": 0.032671,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.02785,
        "recall": 0.053892,
        "f1": 0.033473,
        "accuracy": 0.053892,
        "main_score": 0.033473,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.027936,
        "recall": 0.046574,
        "f1": 0.031735,
        "accuracy": 0.046574,
        "main_score": 0.031735,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.065537,
        "recall": 0.091151,
        "f1": 0.070672,
        "accuracy": 0.091151,
        "main_score": 0.070672,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.016052,
        "recall": 0.029275,
        "f1": 0.018643,
        "accuracy": 0.029275,
        "main_score": 0.018643,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.02821,
        "recall": 0.047904,
        "f1": 0.032742,
        "accuracy": 0.047904,
        "main_score": 0.032742,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.071985,
        "recall": 0.09847,
        "f1": 0.077823,
        "accuracy": 0.09847,
        "main_score": 0.077823,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.029425,
        "recall": 0.043912,
        "f1": 0.03221,
        "accuracy": 0.043912,
        "main_score": 0.03221,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.03813,
        "recall": 0.050566,
        "f1": 0.04061,
        "accuracy": 0.050566,
        "main_score": 0.04061,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.027971,
        "recall": 0.049235,
        "f1": 0.030689,
        "accuracy": 0.049235,
        "main_score": 0.030689,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.01727,
        "recall": 0.035928,
        "f1": 0.020302,
        "accuracy": 0.035928,
        "main_score": 0.020302,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.0163,
        "recall": 0.032601,
        "f1": 0.019264,
        "accuracy": 0.032601,
        "main_score": 0.019264,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.010776,
        "recall": 0.029275,
        "f1": 0.013467,
        "accuracy": 0.029275,
        "main_score": 0.013467,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.008712,
        "recall": 0.017299,
        "f1": 0.009795,
        "accuracy": 0.017299,
        "main_score": 0.009795,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00036,
        "recall": 0.005323,
        "f1": 0.000648,
        "accuracy": 0.005323,
        "main_score": 0.000648,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031623,
        "recall": 0.057219,
        "f1": 0.036793,
        "accuracy": 0.057219,
        "main_score": 0.036793,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.021148,
        "recall": 0.035928,
        "f1": 0.024248,
        "accuracy": 0.035928,
        "main_score": 0.024248,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.01129,
        "recall": 0.023287,
        "f1": 0.013635,
        "accuracy": 0.023287,
        "main_score": 0.013635,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00261,
        "recall": 0.010645,
        "f1": 0.003406,
        "accuracy": 0.010645,
        "main_score": 0.003406,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.010045,
        "recall": 0.01996,
        "f1": 0.011838,
        "accuracy": 0.01996,
        "main_score": 0.011838,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.021196,
        "recall": 0.03992,
        "f1": 0.02442,
        "accuracy": 0.03992,
        "main_score": 0.02442,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.022085,
        "recall": 0.042582,
        "f1": 0.025864,
        "accuracy": 0.042582,
        "main_score": 0.025864,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.018981,
        "recall": 0.03992,
        "f1": 0.022065,
        "accuracy": 0.03992,
        "main_score": 0.022065,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.017563,
        "recall": 0.033932,
        "f1": 0.020375,
        "accuracy": 0.033932,
        "main_score": 0.020375,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.016281,
        "recall": 0.031271,
        "f1": 0.018775,
        "accuracy": 0.031271,
        "main_score": 0.018775,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.005575,
        "recall": 0.015303,
        "f1": 0.006777,
        "accuracy": 0.015303,
        "main_score": 0.006777,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019503,
        "recall": 0.034597,
        "f1": 0.022279,
        "accuracy": 0.034597,
        "main_score": 0.022279,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.007857,
        "recall": 0.017964,
        "f1": 0.009415,
        "accuracy": 0.017964,
        "main_score": 0.009415,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.011321,
        "recall": 0.023287,
        "f1": 0.013408,
        "accuracy": 0.023287,
        "main_score": 0.013408,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.012112,
        "recall": 0.031936,
        "f1": 0.015231,
        "accuracy": 0.031936,
        "main_score": 0.015231,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.028653,
        "recall": 0.050566,
        "f1": 0.033369,
        "accuracy": 0.050566,
        "main_score": 0.033369,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001016,
        "recall": 0.006653,
        "f1": 0.001309,
        "accuracy": 0.006653,
        "main_score": 0.001309,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.006839,
        "recall": 0.013972,
        "f1": 0.007934,
        "accuracy": 0.013972,
        "main_score": 0.007934,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.007855,
        "recall": 0.016633,
        "f1": 0.009647,
        "accuracy": 0.016633,
        "main_score": 0.009647,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.025939,
        "recall": 0.037259,
        "f1": 0.027997,
        "accuracy": 0.037259,
        "main_score": 0.027997,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.033653,
        "recall": 0.045243,
        "f1": 0.036078,
        "accuracy": 0.045243,
        "main_score": 0.036078,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.021873,
        "recall": 0.033267,
        "f1": 0.0238,
        "accuracy": 0.033267,
        "main_score": 0.0238,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030919,
        "recall": 0.041916,
        "f1": 0.032956,
        "accuracy": 0.041916,
        "main_score": 0.032956,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.016011,
        "recall": 0.027944,
        "f1": 0.018027,
        "accuracy": 0.027944,
        "main_score": 0.018027,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.028884,
        "recall": 0.038589,
        "f1": 0.030987,
        "accuracy": 0.038589,
        "main_score": 0.030987,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001141,
        "recall": 0.005988,
        "f1": 0.001758,
        "accuracy": 0.005988,
        "main_score": 0.001758,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.007709,
        "recall": 0.018629,
        "f1": 0.009017,
        "accuracy": 0.018629,
        "main_score": 0.009017,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.019706,
        "recall": 0.028609,
        "f1": 0.021335,
        "accuracy": 0.028609,
        "main_score": 0.021335,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.007704,
        "recall": 0.018629,
        "f1": 0.009543,
        "accuracy": 0.018629,
        "main_score": 0.009543,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.006035,
        "recall": 0.013972,
        "f1": 0.007471,
        "accuracy": 0.013972,
        "main_score": 0.007471,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.009718,
        "recall": 0.021956,
        "f1": 0.011725,
        "accuracy": 0.021956,
        "main_score": 0.011725,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.008652,
        "recall": 0.018629,
        "f1": 0.010288,
        "accuracy": 0.018629,
        "main_score": 0.010288,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.036425,
        "recall": 0.047904,
        "f1": 0.038457,
        "accuracy": 0.047904,
        "main_score": 0.038457,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.004414,
        "recall": 0.015968,
        "f1": 0.006026,
        "accuracy": 0.015968,
        "main_score": 0.006026,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.003563,
        "recall": 0.013307,
        "f1": 0.00478,
        "accuracy": 0.013307,
        "main_score": 0.00478,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.023748,
        "recall": 0.036593,
        "f1": 0.025854,
        "accuracy": 0.036593,
        "main_score": 0.025854,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.018971,
        "recall": 0.025948,
        "f1": 0.020388,
        "accuracy": 0.025948,
        "main_score": 0.020388,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.027434,
        "recall": 0.034597,
        "f1": 0.028561,
        "accuracy": 0.034597,
        "main_score": 0.028561,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.079628,
        "recall": 0.111111,
        "f1": 0.086368,
        "accuracy": 0.111111,
        "main_score": 0.086368,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.027888,
        "recall": 0.040585,
        "f1": 0.030653,
        "accuracy": 0.040585,
        "main_score": 0.030653,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.028861,
        "recall": 0.043247,
        "f1": 0.031588,
        "accuracy": 0.043247,
        "main_score": 0.031588,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.015996,
        "recall": 0.023287,
        "f1": 0.017506,
        "accuracy": 0.023287,
        "main_score": 0.017506,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.038594,
        "recall": 0.056554,
        "f1": 0.04171,
        "accuracy": 0.056554,
        "main_score": 0.04171,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001445,
        "recall": 0.007319,
        "f1": 0.001855,
        "accuracy": 0.007319,
        "main_score": 0.001855,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018962,
        "recall": 0.027944,
        "f1": 0.020184,
        "accuracy": 0.027944,
        "main_score": 0.020184,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.025816,
        "recall": 0.03992,
        "f1": 0.028287,
        "accuracy": 0.03992,
        "main_score": 0.028287,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.039148,
        "recall": 0.05988,
        "f1": 0.043367,
        "accuracy": 0.05988,
        "main_score": 0.043367,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.012507,
        "recall": 0.020625,
        "f1": 0.013877,
        "accuracy": 0.020625,
        "main_score": 0.013877,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.003578,
        "recall": 0.013307,
        "f1": 0.00452,
        "accuracy": 0.013307,
        "main_score": 0.00452,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.005607,
        "recall": 0.011311,
        "f1": 0.006411,
        "accuracy": 0.011311,
        "main_score": 0.006411,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.023583,
        "recall": 0.031936,
        "f1": 0.025209,
        "accuracy": 0.031936,
        "main_score": 0.025209,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.02109,
        "recall": 0.02994,
        "f1": 0.023032,
        "accuracy": 0.02994,
        "main_score": 0.023032,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.035657,
        "recall": 0.053892,
        "f1": 0.03946,
        "accuracy": 0.053892,
        "main_score": 0.03946,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.028267,
        "recall": 0.043247,
        "f1": 0.031103,
        "accuracy": 0.043247,
        "main_score": 0.031103,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.02345,
        "recall": 0.03992,
        "f1": 0.025767,
        "accuracy": 0.03992,
        "main_score": 0.025767,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019147,
        "recall": 0.026613,
        "f1": 0.020426,
        "accuracy": 0.026613,
        "main_score": 0.020426,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.026472,
        "recall": 0.042582,
        "f1": 0.029711,
        "accuracy": 0.042582,
        "main_score": 0.029711,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.025051,
        "recall": 0.041916,
        "f1": 0.028406,
        "accuracy": 0.041916,
        "main_score": 0.028406,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.00763,
        "recall": 0.015303,
        "f1": 0.008689,
        "accuracy": 0.015303,
        "main_score": 0.008689,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.011392,
        "recall": 0.021956,
        "f1": 0.012881,
        "accuracy": 0.021956,
        "main_score": 0.012881,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003775,
        "recall": 0.014637,
        "f1": 0.004884,
        "accuracy": 0.014637,
        "main_score": 0.004884,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.008968,
        "recall": 0.021291,
        "f1": 0.010704,
        "accuracy": 0.021291,
        "main_score": 0.010704,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.010377,
        "recall": 0.01996,
        "f1": 0.01186,
        "accuracy": 0.01996,
        "main_score": 0.01186,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.033454,
        "recall": 0.04857,
        "f1": 0.036089,
        "accuracy": 0.04857,
        "main_score": 0.036089,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.029995,
        "recall": 0.039255,
        "f1": 0.031276,
        "accuracy": 0.039255,
        "main_score": 0.031276,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.016928,
        "recall": 0.025283,
        "f1": 0.018049,
        "accuracy": 0.025283,
        "main_score": 0.018049,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.042884,
        "recall": 0.05988,
        "f1": 0.046509,
        "accuracy": 0.05988,
        "main_score": 0.046509,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.022494,
        "recall": 0.035263,
        "f1": 0.025076,
        "accuracy": 0.035263,
        "main_score": 0.025076,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.035214,
        "recall": 0.047239,
        "f1": 0.037348,
        "accuracy": 0.047239,
        "main_score": 0.037348,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.024268,
        "recall": 0.047239,
        "f1": 0.028038,
        "accuracy": 0.047239,
        "main_score": 0.028038,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.015533,
        "recall": 0.025948,
        "f1": 0.017157,
        "accuracy": 0.025948,
        "main_score": 0.017157,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.005577,
        "recall": 0.016633,
        "f1": 0.007368,
        "accuracy": 0.016633,
        "main_score": 0.007368,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.012075,
        "recall": 0.026613,
        "f1": 0.014381,
        "accuracy": 0.026613,
        "main_score": 0.014381,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.008686,
        "recall": 0.019295,
        "f1": 0.010255,
        "accuracy": 0.019295,
        "main_score": 0.010255,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.009245,
        "recall": 0.021956,
        "f1": 0.011412,
        "accuracy": 0.021956,
        "main_score": 0.011412,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.016059,
        "recall": 0.029275,
        "f1": 0.018552,
        "accuracy": 0.029275,
        "main_score": 0.018552,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.03394,
        "recall": 0.042582,
        "f1": 0.035306,
        "accuracy": 0.042582,
        "main_score": 0.035306,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.01456,
        "recall": 0.031271,
        "f1": 0.017506,
        "accuracy": 0.031271,
        "main_score": 0.017506,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.004911,
        "recall": 0.013972,
        "f1": 0.006299,
        "accuracy": 0.013972,
        "main_score": 0.006299,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.029681,
        "recall": 0.041916,
        "f1": 0.031498,
        "accuracy": 0.041916,
        "main_score": 0.031498,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.034962,
        "recall": 0.0499,
        "f1": 0.037975,
        "accuracy": 0.0499,
        "main_score": 0.037975,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.047217,
        "recall": 0.064538,
        "f1": 0.050201,
        "accuracy": 0.064538,
        "main_score": 0.050201,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.020035,
        "recall": 0.027279,
        "f1": 0.021446,
        "accuracy": 0.027279,
        "main_score": 0.021446,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.021819,
        "recall": 0.041251,
        "f1": 0.025382,
        "accuracy": 0.041251,
        "main_score": 0.025382,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.024553,
        "recall": 0.045243,
        "f1": 0.028762,
        "accuracy": 0.045243,
        "main_score": 0.028762,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.015663,
        "recall": 0.034597,
        "f1": 0.019024,
        "accuracy": 0.034597,
        "main_score": 0.019024,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.019645,
        "recall": 0.031271,
        "f1": 0.02188,
        "accuracy": 0.031271,
        "main_score": 0.02188,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000988,
        "recall": 0.005988,
        "f1": 0.001493,
        "accuracy": 0.005988,
        "main_score": 0.001493,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.03001,
        "recall": 0.053227,
        "f1": 0.034755,
        "accuracy": 0.053227,
        "main_score": 0.034755,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.040131,
        "recall": 0.067199,
        "f1": 0.04646,
        "accuracy": 0.067199,
        "main_score": 0.04646,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.024823,
        "recall": 0.040585,
        "f1": 0.027946,
        "accuracy": 0.040585,
        "main_score": 0.027946,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.024768,
        "recall": 0.043912,
        "f1": 0.028628,
        "accuracy": 0.043912,
        "main_score": 0.028628,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.003166,
        "recall": 0.00998,
        "f1": 0.004238,
        "accuracy": 0.00998,
        "main_score": 0.004238,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.020584,
        "recall": 0.038589,
        "f1": 0.024084,
        "accuracy": 0.038589,
        "main_score": 0.024084,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.013204,
        "recall": 0.024617,
        "f1": 0.015053,
        "accuracy": 0.024617,
        "main_score": 0.015053,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.021837,
        "recall": 0.042582,
        "f1": 0.025214,
        "accuracy": 0.042582,
        "main_score": 0.025214,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.029364,
        "recall": 0.053227,
        "f1": 0.033945,
        "accuracy": 0.053227,
        "main_score": 0.033945,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.025248,
        "recall": 0.043247,
        "f1": 0.028501,
        "accuracy": 0.043247,
        "main_score": 0.028501,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.015792,
        "recall": 0.027279,
        "f1": 0.017635,
        "accuracy": 0.027279,
        "main_score": 0.017635,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.018132,
        "recall": 0.036593,
        "f1": 0.021308,
        "accuracy": 0.036593,
        "main_score": 0.021308,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.016419,
        "recall": 0.027279,
        "f1": 0.018513,
        "accuracy": 0.027279,
        "main_score": 0.018513,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.014835,
        "recall": 0.028609,
        "f1": 0.017383,
        "accuracy": 0.028609,
        "main_score": 0.017383,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.009848,
        "recall": 0.021956,
        "f1": 0.012054,
        "accuracy": 0.021956,
        "main_score": 0.012054,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.01782,
        "recall": 0.032601,
        "f1": 0.021022,
        "accuracy": 0.032601,
        "main_score": 0.021022,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002532,
        "recall": 0.010645,
        "f1": 0.003269,
        "accuracy": 0.010645,
        "main_score": 0.003269,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.036151,
        "recall": 0.057219,
        "f1": 0.040285,
        "accuracy": 0.057219,
        "main_score": 0.040285,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.029733,
        "recall": 0.053892,
        "f1": 0.034909,
        "accuracy": 0.053892,
        "main_score": 0.034909,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.024936,
        "recall": 0.049235,
        "f1": 0.029871,
        "accuracy": 0.049235,
        "main_score": 0.029871,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.02537,
        "recall": 0.040585,
        "f1": 0.028745,
        "accuracy": 0.040585,
        "main_score": 0.028745,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000562,
        "recall": 0.006653,
        "f1": 0.000965,
        "accuracy": 0.006653,
        "main_score": 0.000965,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022827,
        "recall": 0.045243,
        "f1": 0.026198,
        "accuracy": 0.045243,
        "main_score": 0.026198,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.022448,
        "recall": 0.043247,
        "f1": 0.026552,
        "accuracy": 0.043247,
        "main_score": 0.026552,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.030836,
        "recall": 0.0499,
        "f1": 0.034914,
        "accuracy": 0.0499,
        "main_score": 0.034914,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.017089,
        "recall": 0.036593,
        "f1": 0.020129,
        "accuracy": 0.036593,
        "main_score": 0.020129,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.003268,
        "recall": 0.017964,
        "f1": 0.004879,
        "accuracy": 0.017964,
        "main_score": 0.004879,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.021844,
        "recall": 0.040585,
        "f1": 0.02582,
        "accuracy": 0.040585,
        "main_score": 0.02582,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.0124,
        "recall": 0.024617,
        "f1": 0.014189,
        "accuracy": 0.024617,
        "main_score": 0.014189,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.024325,
        "recall": 0.043912,
        "f1": 0.027206,
        "accuracy": 0.043912,
        "main_score": 0.027206,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.029573,
        "recall": 0.049235,
        "f1": 0.03403,
        "accuracy": 0.049235,
        "main_score": 0.03403,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.032246,
        "recall": 0.055888,
        "f1": 0.036897,
        "accuracy": 0.055888,
        "main_score": 0.036897,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.01718,
        "recall": 0.032601,
        "f1": 0.019702,
        "accuracy": 0.032601,
        "main_score": 0.019702,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.026919,
        "recall": 0.041251,
        "f1": 0.029929,
        "accuracy": 0.041251,
        "main_score": 0.029929,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.022557,
        "recall": 0.042582,
        "f1": 0.026598,
        "accuracy": 0.042582,
        "main_score": 0.026598,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.017847,
        "recall": 0.029275,
        "f1": 0.02017,
        "accuracy": 0.029275,
        "main_score": 0.02017,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.007233,
        "recall": 0.020625,
        "f1": 0.008679,
        "accuracy": 0.020625,
        "main_score": 0.008679,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.012239,
        "recall": 0.027279,
        "f1": 0.014773,
        "accuracy": 0.027279,
        "main_score": 0.014773,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002709,
        "recall": 0.014637,
        "f1": 0.003726,
        "accuracy": 0.014637,
        "main_score": 0.003726,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.033751,
        "recall": 0.053892,
        "f1": 0.037462,
        "accuracy": 0.053892,
        "main_score": 0.037462,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.03824,
        "recall": 0.05855,
        "f1": 0.042732,
        "accuracy": 0.05855,
        "main_score": 0.042732,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.024314,
        "recall": 0.045243,
        "f1": 0.028575,
        "accuracy": 0.045243,
        "main_score": 0.028575,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.030253,
        "recall": 0.050566,
        "f1": 0.034808,
        "accuracy": 0.050566,
        "main_score": 0.034808,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001483,
        "recall": 0.008649,
        "f1": 0.001935,
        "accuracy": 0.008649,
        "main_score": 0.001935,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.02663,
        "recall": 0.047904,
        "f1": 0.030555,
        "accuracy": 0.047904,
        "main_score": 0.030555,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.024821,
        "recall": 0.047904,
        "f1": 0.0294,
        "accuracy": 0.047904,
        "main_score": 0.0294,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.029435,
        "recall": 0.042582,
        "f1": 0.032162,
        "accuracy": 0.042582,
        "main_score": 0.032162,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015558,
        "recall": 0.026613,
        "f1": 0.017831,
        "accuracy": 0.026613,
        "main_score": 0.017831,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.005279,
        "recall": 0.016633,
        "f1": 0.006679,
        "accuracy": 0.016633,
        "main_score": 0.006679,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.033896,
        "recall": 0.054558,
        "f1": 0.038224,
        "accuracy": 0.054558,
        "main_score": 0.038224,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.009064,
        "recall": 0.015303,
        "f1": 0.009884,
        "accuracy": 0.015303,
        "main_score": 0.009884,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.026499,
        "recall": 0.043247,
        "f1": 0.029771,
        "accuracy": 0.043247,
        "main_score": 0.029771,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.036209,
        "recall": 0.055223,
        "f1": 0.040167,
        "accuracy": 0.055223,
        "main_score": 0.040167,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.033746,
        "recall": 0.054558,
        "f1": 0.037692,
        "accuracy": 0.054558,
        "main_score": 0.037692,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.01974,
        "recall": 0.037259,
        "f1": 0.022651,
        "accuracy": 0.037259,
        "main_score": 0.022651,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.01991,
        "recall": 0.041251,
        "f1": 0.023848,
        "accuracy": 0.041251,
        "main_score": 0.023848,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.030471,
        "recall": 0.04857,
        "f1": 0.034133,
        "accuracy": 0.04857,
        "main_score": 0.034133,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.01961,
        "recall": 0.038589,
        "f1": 0.023153,
        "accuracy": 0.038589,
        "main_score": 0.023153,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.011855,
        "recall": 0.025283,
        "f1": 0.013433,
        "accuracy": 0.025283,
        "main_score": 0.013433,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.017383,
        "recall": 0.034597,
        "f1": 0.020165,
        "accuracy": 0.034597,
        "main_score": 0.020165,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003274,
        "recall": 0.017299,
        "f1": 0.00451,
        "accuracy": 0.017299,
        "main_score": 0.00451,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.037944,
        "recall": 0.067199,
        "f1": 0.043712,
        "accuracy": 0.067199,
        "main_score": 0.043712,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.03621,
        "recall": 0.067199,
        "f1": 0.042219,
        "accuracy": 0.067199,
        "main_score": 0.042219,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.027189,
        "recall": 0.049235,
        "f1": 0.031625,
        "accuracy": 0.049235,
        "main_score": 0.031625,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.026579,
        "recall": 0.049235,
        "f1": 0.031332,
        "accuracy": 0.049235,
        "main_score": 0.031332,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001542,
        "recall": 0.009315,
        "f1": 0.002079,
        "accuracy": 0.009315,
        "main_score": 0.002079,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022055,
        "recall": 0.043247,
        "f1": 0.025754,
        "accuracy": 0.043247,
        "main_score": 0.025754,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.027187,
        "recall": 0.051231,
        "f1": 0.032053,
        "accuracy": 0.051231,
        "main_score": 0.032053,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.02845,
        "recall": 0.050566,
        "f1": 0.032801,
        "accuracy": 0.050566,
        "main_score": 0.032801,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.013567,
        "recall": 0.030605,
        "f1": 0.016319,
        "accuracy": 0.030605,
        "main_score": 0.016319,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004156,
        "recall": 0.021956,
        "f1": 0.006225,
        "accuracy": 0.021956,
        "main_score": 0.006225,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.02747,
        "recall": 0.049235,
        "f1": 0.031739,
        "accuracy": 0.049235,
        "main_score": 0.031739,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.011817,
        "recall": 0.022621,
        "f1": 0.013563,
        "accuracy": 0.022621,
        "main_score": 0.013563,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.024397,
        "recall": 0.043912,
        "f1": 0.028378,
        "accuracy": 0.043912,
        "main_score": 0.028378,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.030294,
        "recall": 0.057884,
        "f1": 0.035816,
        "accuracy": 0.057884,
        "main_score": 0.035816,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.037448,
        "recall": 0.070526,
        "f1": 0.044432,
        "accuracy": 0.070526,
        "main_score": 0.044432,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.022234,
        "recall": 0.045243,
        "f1": 0.025979,
        "accuracy": 0.045243,
        "main_score": 0.025979,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.028066,
        "recall": 0.045908,
        "f1": 0.031401,
        "accuracy": 0.045908,
        "main_score": 0.031401,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.029919,
        "recall": 0.055223,
        "f1": 0.035278,
        "accuracy": 0.055223,
        "main_score": 0.035278,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.018405,
        "recall": 0.038589,
        "f1": 0.021914,
        "accuracy": 0.038589,
        "main_score": 0.021914,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.009462,
        "recall": 0.025948,
        "f1": 0.011778,
        "accuracy": 0.025948,
        "main_score": 0.011778,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.010666,
        "recall": 0.028609,
        "f1": 0.013593,
        "accuracy": 0.028609,
        "main_score": 0.013593,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003061,
        "recall": 0.015968,
        "f1": 0.004547,
        "accuracy": 0.015968,
        "main_score": 0.004547,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.024282,
        "recall": 0.046574,
        "f1": 0.029639,
        "accuracy": 0.046574,
        "main_score": 0.029639,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.018608,
        "recall": 0.037259,
        "f1": 0.022576,
        "accuracy": 0.037259,
        "main_score": 0.022576,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.046915,
        "recall": 0.069195,
        "f1": 0.051677,
        "accuracy": 0.069195,
        "main_score": 0.051677,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.068536,
        "recall": 0.09847,
        "f1": 0.075367,
        "accuracy": 0.09847,
        "main_score": 0.075367,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.021138,
        "recall": 0.029275,
        "f1": 0.022333,
        "accuracy": 0.029275,
        "main_score": 0.022333,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.053048,
        "recall": 0.076514,
        "f1": 0.057727,
        "accuracy": 0.076514,
        "main_score": 0.057727,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.035394,
        "recall": 0.063207,
        "f1": 0.040974,
        "accuracy": 0.063207,
        "main_score": 0.040974,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.071792,
        "recall": 0.100466,
        "f1": 0.078466,
        "accuracy": 0.100466,
        "main_score": 0.078466,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.007733,
        "recall": 0.020625,
        "f1": 0.009854,
        "accuracy": 0.020625,
        "main_score": 0.009854,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.021772,
        "recall": 0.040585,
        "f1": 0.024987,
        "accuracy": 0.040585,
        "main_score": 0.024987,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.023505,
        "recall": 0.0499,
        "f1": 0.028704,
        "accuracy": 0.0499,
        "main_score": 0.028704,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.029586,
        "recall": 0.041251,
        "f1": 0.03165,
        "accuracy": 0.041251,
        "main_score": 0.03165,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.019307,
        "recall": 0.039255,
        "f1": 0.022914,
        "accuracy": 0.039255,
        "main_score": 0.022914,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.022325,
        "recall": 0.042582,
        "f1": 0.026598,
        "accuracy": 0.042582,
        "main_score": 0.026598,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.023943,
        "recall": 0.047904,
        "f1": 0.028877,
        "accuracy": 0.047904,
        "main_score": 0.028877,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.023033,
        "recall": 0.041916,
        "f1": 0.02645,
        "accuracy": 0.041916,
        "main_score": 0.02645,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.011979,
        "recall": 0.026613,
        "f1": 0.014384,
        "accuracy": 0.026613,
        "main_score": 0.014384,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.026289,
        "recall": 0.052562,
        "f1": 0.031668,
        "accuracy": 0.052562,
        "main_score": 0.031668,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.055473,
        "recall": 0.083167,
        "f1": 0.06086,
        "accuracy": 0.083167,
        "main_score": 0.06086,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.0309,
        "recall": 0.043912,
        "f1": 0.033523,
        "accuracy": 0.043912,
        "main_score": 0.033523,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.042999,
        "recall": 0.059215,
        "f1": 0.045487,
        "accuracy": 0.059215,
        "main_score": 0.045487,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.026043,
        "recall": 0.040585,
        "f1": 0.028082,
        "accuracy": 0.040585,
        "main_score": 0.028082,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.022328,
        "recall": 0.043247,
        "f1": 0.025396,
        "accuracy": 0.043247,
        "main_score": 0.025396,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.017528,
        "recall": 0.034597,
        "f1": 0.020856,
        "accuracy": 0.034597,
        "main_score": 0.020856,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.017499,
        "recall": 0.02994,
        "f1": 0.0197,
        "accuracy": 0.02994,
        "main_score": 0.0197,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.010338,
        "recall": 0.021291,
        "f1": 0.012007,
        "accuracy": 0.021291,
        "main_score": 0.012007,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000352,
        "recall": 0.005323,
        "f1": 0.000578,
        "accuracy": 0.005323,
        "main_score": 0.000578,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020696,
        "recall": 0.036593,
        "f1": 0.023238,
        "accuracy": 0.036593,
        "main_score": 0.023238,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.017396,
        "recall": 0.034597,
        "f1": 0.020538,
        "accuracy": 0.034597,
        "main_score": 0.020538,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.017731,
        "recall": 0.031936,
        "f1": 0.020345,
        "accuracy": 0.031936,
        "main_score": 0.020345,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.017919,
        "recall": 0.032601,
        "f1": 0.020777,
        "accuracy": 0.032601,
        "main_score": 0.020777,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.002337,
        "recall": 0.011311,
        "f1": 0.00307,
        "accuracy": 0.011311,
        "main_score": 0.00307,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.017154,
        "recall": 0.029275,
        "f1": 0.019379,
        "accuracy": 0.029275,
        "main_score": 0.019379,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.016211,
        "recall": 0.030605,
        "f1": 0.018268,
        "accuracy": 0.030605,
        "main_score": 0.018268,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.01733,
        "recall": 0.033932,
        "f1": 0.019947,
        "accuracy": 0.033932,
        "main_score": 0.019947,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.023419,
        "recall": 0.039255,
        "f1": 0.026331,
        "accuracy": 0.039255,
        "main_score": 0.026331,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.020919,
        "recall": 0.03992,
        "f1": 0.024359,
        "accuracy": 0.03992,
        "main_score": 0.024359,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.026155,
        "recall": 0.043912,
        "f1": 0.029167,
        "accuracy": 0.043912,
        "main_score": 0.029167,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.008665,
        "recall": 0.020625,
        "f1": 0.010328,
        "accuracy": 0.020625,
        "main_score": 0.010328,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.011221,
        "recall": 0.023287,
        "f1": 0.012864,
        "accuracy": 0.023287,
        "main_score": 0.012864,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.012668,
        "recall": 0.024617,
        "f1": 0.014191,
        "accuracy": 0.024617,
        "main_score": 0.014191,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.00774,
        "recall": 0.01996,
        "f1": 0.009517,
        "accuracy": 0.01996,
        "main_score": 0.009517,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.012621,
        "recall": 0.028609,
        "f1": 0.015077,
        "accuracy": 0.028609,
        "main_score": 0.015077,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001716,
        "recall": 0.007984,
        "f1": 0.002546,
        "accuracy": 0.007984,
        "main_score": 0.002546,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.029219,
        "recall": 0.04857,
        "f1": 0.033114,
        "accuracy": 0.04857,
        "main_score": 0.033114,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.020444,
        "recall": 0.040585,
        "f1": 0.024231,
        "accuracy": 0.040585,
        "main_score": 0.024231,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.013866,
        "recall": 0.030605,
        "f1": 0.017061,
        "accuracy": 0.030605,
        "main_score": 0.017061,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.033211,
        "recall": 0.053892,
        "f1": 0.037667,
        "accuracy": 0.053892,
        "main_score": 0.037667,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000846,
        "recall": 0.006653,
        "f1": 0.001297,
        "accuracy": 0.006653,
        "main_score": 0.001297,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017077,
        "recall": 0.031936,
        "f1": 0.019231,
        "accuracy": 0.031936,
        "main_score": 0.019231,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.019985,
        "recall": 0.037924,
        "f1": 0.023548,
        "accuracy": 0.037924,
        "main_score": 0.023548,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.026115,
        "recall": 0.043247,
        "f1": 0.029747,
        "accuracy": 0.043247,
        "main_score": 0.029747,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.008847,
        "recall": 0.017299,
        "f1": 0.010269,
        "accuracy": 0.017299,
        "main_score": 0.010269,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.005115,
        "recall": 0.020625,
        "f1": 0.006987,
        "accuracy": 0.020625,
        "main_score": 0.006987,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.025887,
        "recall": 0.046574,
        "f1": 0.029835,
        "accuracy": 0.046574,
        "main_score": 0.029835,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.004225,
        "recall": 0.010645,
        "f1": 0.004972,
        "accuracy": 0.010645,
        "main_score": 0.004972,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.015621,
        "recall": 0.033267,
        "f1": 0.018368,
        "accuracy": 0.033267,
        "main_score": 0.018368,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.023146,
        "recall": 0.040585,
        "f1": 0.027137,
        "accuracy": 0.040585,
        "main_score": 0.027137,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.024533,
        "recall": 0.044578,
        "f1": 0.02854,
        "accuracy": 0.044578,
        "main_score": 0.02854,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.026121,
        "recall": 0.044578,
        "f1": 0.029769,
        "accuracy": 0.044578,
        "main_score": 0.029769,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.020949,
        "recall": 0.036593,
        "f1": 0.023732,
        "accuracy": 0.036593,
        "main_score": 0.023732,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.013931,
        "recall": 0.027944,
        "f1": 0.016361,
        "accuracy": 0.027944,
        "main_score": 0.016361,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.011913,
        "recall": 0.023952,
        "f1": 0.01423,
        "accuracy": 0.023952,
        "main_score": 0.01423,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.005132,
        "recall": 0.012641,
        "f1": 0.006146,
        "accuracy": 0.012641,
        "main_score": 0.006146,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.008243,
        "recall": 0.020625,
        "f1": 0.010075,
        "accuracy": 0.020625,
        "main_score": 0.010075,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.00199,
        "recall": 0.012641,
        "f1": 0.002917,
        "accuracy": 0.012641,
        "main_score": 0.002917,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.020053,
        "recall": 0.031936,
        "f1": 0.022564,
        "accuracy": 0.031936,
        "main_score": 0.022564,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.020304,
        "recall": 0.035928,
        "f1": 0.023455,
        "accuracy": 0.035928,
        "main_score": 0.023455,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.046177,
        "recall": 0.061876,
        "f1": 0.049439,
        "accuracy": 0.061876,
        "main_score": 0.049439,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.059122,
        "recall": 0.083167,
        "f1": 0.064339,
        "accuracy": 0.083167,
        "main_score": 0.064339,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.017873,
        "recall": 0.025948,
        "f1": 0.018829,
        "accuracy": 0.025948,
        "main_score": 0.018829,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.040842,
        "recall": 0.053892,
        "f1": 0.04327,
        "accuracy": 0.053892,
        "main_score": 0.04327,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.031449,
        "recall": 0.051896,
        "f1": 0.035931,
        "accuracy": 0.051896,
        "main_score": 0.035931,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.070092,
        "recall": 0.094478,
        "f1": 0.075305,
        "accuracy": 0.094478,
        "main_score": 0.075305,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.014458,
        "recall": 0.026613,
        "f1": 0.016355,
        "accuracy": 0.026613,
        "main_score": 0.016355,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.021501,
        "recall": 0.037924,
        "f1": 0.024173,
        "accuracy": 0.037924,
        "main_score": 0.024173,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.022407,
        "recall": 0.039255,
        "f1": 0.025881,
        "accuracy": 0.039255,
        "main_score": 0.025881,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.028871,
        "recall": 0.041251,
        "f1": 0.031125,
        "accuracy": 0.041251,
        "main_score": 0.031125,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.015966,
        "recall": 0.029275,
        "f1": 0.018375,
        "accuracy": 0.029275,
        "main_score": 0.018375,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.019038,
        "recall": 0.031271,
        "f1": 0.022162,
        "accuracy": 0.031271,
        "main_score": 0.022162,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.019974,
        "recall": 0.034597,
        "f1": 0.022952,
        "accuracy": 0.034597,
        "main_score": 0.022952,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.016363,
        "recall": 0.034597,
        "f1": 0.019217,
        "accuracy": 0.034597,
        "main_score": 0.019217,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.04878,
        "recall": 0.071191,
        "f1": 0.052622,
        "accuracy": 0.071191,
        "main_score": 0.052622,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.011638,
        "recall": 0.022621,
        "f1": 0.013696,
        "accuracy": 0.022621,
        "main_score": 0.013696,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.015045,
        "recall": 0.026613,
        "f1": 0.017143,
        "accuracy": 0.026613,
        "main_score": 0.017143,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.022614,
        "recall": 0.035928,
        "f1": 0.025206,
        "accuracy": 0.035928,
        "main_score": 0.025206,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.032889,
        "recall": 0.042582,
        "f1": 0.034676,
        "accuracy": 0.042582,
        "main_score": 0.034676,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.021098,
        "recall": 0.035928,
        "f1": 0.023385,
        "accuracy": 0.035928,
        "main_score": 0.023385,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.006942,
        "recall": 0.015303,
        "f1": 0.007987,
        "accuracy": 0.015303,
        "main_score": 0.007987,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.009991,
        "recall": 0.017299,
        "f1": 0.011122,
        "accuracy": 0.017299,
        "main_score": 0.011122,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.026488,
        "recall": 0.037924,
        "f1": 0.028524,
        "accuracy": 0.037924,
        "main_score": 0.028524,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.027802,
        "recall": 0.037924,
        "f1": 0.029559,
        "accuracy": 0.037924,
        "main_score": 0.029559,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.016878,
        "recall": 0.023952,
        "f1": 0.017629,
        "accuracy": 0.023952,
        "main_score": 0.017629,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.043217,
        "recall": 0.060546,
        "f1": 0.045979,
        "accuracy": 0.060546,
        "main_score": 0.045979,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.019922,
        "recall": 0.031271,
        "f1": 0.022135,
        "accuracy": 0.031271,
        "main_score": 0.022135,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.032,
        "recall": 0.040585,
        "f1": 0.033912,
        "accuracy": 0.040585,
        "main_score": 0.033912,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.01477,
        "recall": 0.033932,
        "f1": 0.017922,
        "accuracy": 0.033932,
        "main_score": 0.017922,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.016883,
        "recall": 0.027944,
        "f1": 0.01871,
        "accuracy": 0.027944,
        "main_score": 0.01871,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.005853,
        "recall": 0.011976,
        "f1": 0.006733,
        "accuracy": 0.011976,
        "main_score": 0.006733,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.034859,
        "recall": 0.049235,
        "f1": 0.03744,
        "accuracy": 0.049235,
        "main_score": 0.03744,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.009167,
        "recall": 0.020625,
        "f1": 0.010741,
        "accuracy": 0.020625,
        "main_score": 0.010741,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.008399,
        "recall": 0.020625,
        "f1": 0.009929,
        "accuracy": 0.020625,
        "main_score": 0.009929,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.010203,
        "recall": 0.01996,
        "f1": 0.012106,
        "accuracy": 0.01996,
        "main_score": 0.012106,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.006947,
        "recall": 0.017964,
        "f1": 0.008642,
        "accuracy": 0.017964,
        "main_score": 0.008642,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.031065,
        "recall": 0.03992,
        "f1": 0.032671,
        "accuracy": 0.03992,
        "main_score": 0.032671,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.009258,
        "recall": 0.021291,
        "f1": 0.010889,
        "accuracy": 0.021291,
        "main_score": 0.010889,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005168,
        "recall": 0.016633,
        "f1": 0.006778,
        "accuracy": 0.016633,
        "main_score": 0.006778,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.025329,
        "recall": 0.034597,
        "f1": 0.02686,
        "accuracy": 0.034597,
        "main_score": 0.02686,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.041994,
        "recall": 0.05988,
        "f1": 0.045943,
        "accuracy": 0.05988,
        "main_score": 0.045943,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.021139,
        "recall": 0.02994,
        "f1": 0.022712,
        "accuracy": 0.02994,
        "main_score": 0.022712,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.013129,
        "recall": 0.025948,
        "f1": 0.014694,
        "accuracy": 0.025948,
        "main_score": 0.014694,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.015845,
        "recall": 0.025948,
        "f1": 0.017726,
        "accuracy": 0.025948,
        "main_score": 0.017726,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.0409,
        "recall": 0.05855,
        "f1": 0.043971,
        "accuracy": 0.05855,
        "main_score": 0.043971,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.03651,
        "recall": 0.04857,
        "f1": 0.0387,
        "accuracy": 0.04857,
        "main_score": 0.0387,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.021314,
        "recall": 0.031936,
        "f1": 0.022592,
        "accuracy": 0.031936,
        "main_score": 0.022592,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.065746,
        "recall": 0.085828,
        "f1": 0.070051,
        "accuracy": 0.085828,
        "main_score": 0.070051,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.03081,
        "recall": 0.0499,
        "f1": 0.035002,
        "accuracy": 0.0499,
        "main_score": 0.035002,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.042019,
        "recall": 0.050566,
        "f1": 0.043701,
        "accuracy": 0.050566,
        "main_score": 0.043701,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.026333,
        "recall": 0.047904,
        "f1": 0.031048,
        "accuracy": 0.047904,
        "main_score": 0.031048,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.020618,
        "recall": 0.036593,
        "f1": 0.023157,
        "accuracy": 0.036593,
        "main_score": 0.023157,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.011683,
        "recall": 0.021956,
        "f1": 0.013723,
        "accuracy": 0.021956,
        "main_score": 0.013723,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.041778,
        "recall": 0.063872,
        "f1": 0.046027,
        "accuracy": 0.063872,
        "main_score": 0.046027,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.015966,
        "recall": 0.033267,
        "f1": 0.018934,
        "accuracy": 0.033267,
        "main_score": 0.018934,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.013795,
        "recall": 0.026613,
        "f1": 0.015326,
        "accuracy": 0.026613,
        "main_score": 0.015326,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.019469,
        "recall": 0.030605,
        "f1": 0.021417,
        "accuracy": 0.030605,
        "main_score": 0.021417,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.012616,
        "recall": 0.023287,
        "f1": 0.0144,
        "accuracy": 0.023287,
        "main_score": 0.0144,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.041913,
        "recall": 0.051231,
        "f1": 0.043626,
        "accuracy": 0.051231,
        "main_score": 0.043626,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.012075,
        "recall": 0.029275,
        "f1": 0.015139,
        "accuracy": 0.029275,
        "main_score": 0.015139,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.010997,
        "recall": 0.018629,
        "f1": 0.012434,
        "accuracy": 0.018629,
        "main_score": 0.012434,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.036063,
        "recall": 0.047239,
        "f1": 0.03828,
        "accuracy": 0.047239,
        "main_score": 0.03828,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.046712,
        "recall": 0.067199,
        "f1": 0.050949,
        "accuracy": 0.067199,
        "main_score": 0.050949,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.023059,
        "recall": 0.032601,
        "f1": 0.024446,
        "accuracy": 0.032601,
        "main_score": 0.024446,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.007155,
        "recall": 0.015303,
        "f1": 0.008696,
        "accuracy": 0.015303,
        "main_score": 0.008696,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.004555,
        "recall": 0.013307,
        "f1": 0.005884,
        "accuracy": 0.013307,
        "main_score": 0.005884,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.033016,
        "recall": 0.047239,
        "f1": 0.036014,
        "accuracy": 0.047239,
        "main_score": 0.036014,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.037284,
        "recall": 0.05855,
        "f1": 0.04155,
        "accuracy": 0.05855,
        "main_score": 0.04155,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.030011,
        "recall": 0.047239,
        "f1": 0.032973,
        "accuracy": 0.047239,
        "main_score": 0.032973,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.036559,
        "recall": 0.051896,
        "f1": 0.039695,
        "accuracy": 0.051896,
        "main_score": 0.039695,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.018939,
        "recall": 0.037924,
        "f1": 0.022528,
        "accuracy": 0.037924,
        "main_score": 0.022528,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.037193,
        "recall": 0.05855,
        "f1": 0.04122,
        "accuracy": 0.05855,
        "main_score": 0.04122,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.005454,
        "recall": 0.009315,
        "f1": 0.006172,
        "accuracy": 0.009315,
        "main_score": 0.006172,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.078523,
        "recall": 0.11976,
        "f1": 0.088359,
        "accuracy": 0.11976,
        "main_score": 0.088359,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.009074,
        "recall": 0.020625,
        "f1": 0.010982,
        "accuracy": 0.020625,
        "main_score": 0.010982,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.024404,
        "recall": 0.036593,
        "f1": 0.026611,
        "accuracy": 0.036593,
        "main_score": 0.026611,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.005682,
        "recall": 0.015303,
        "f1": 0.007303,
        "accuracy": 0.015303,
        "main_score": 0.007303,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00549,
        "recall": 0.013307,
        "f1": 0.006537,
        "accuracy": 0.013307,
        "main_score": 0.006537,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.008472,
        "recall": 0.020625,
        "f1": 0.010225,
        "accuracy": 0.020625,
        "main_score": 0.010225,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.007739,
        "recall": 0.017964,
        "f1": 0.009542,
        "accuracy": 0.017964,
        "main_score": 0.009542,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.03626,
        "recall": 0.051231,
        "f1": 0.039072,
        "accuracy": 0.051231,
        "main_score": 0.039072,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.004982,
        "recall": 0.015303,
        "f1": 0.00622,
        "accuracy": 0.015303,
        "main_score": 0.00622,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.009289,
        "recall": 0.020625,
        "f1": 0.01099,
        "accuracy": 0.020625,
        "main_score": 0.01099,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.030792,
        "recall": 0.047904,
        "f1": 0.034068,
        "accuracy": 0.047904,
        "main_score": 0.034068,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.024048,
        "recall": 0.038589,
        "f1": 0.027036,
        "accuracy": 0.038589,
        "main_score": 0.027036,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.030381,
        "recall": 0.045243,
        "f1": 0.033417,
        "accuracy": 0.045243,
        "main_score": 0.033417,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 19.99764633178711,
  "kg_co2_emissions": 0.0007454237720644413
}