{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "task_name": "IndonesianIdClickbaitClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.533838,
        "f1": 0.529187,
        "f1_weighted": 0.533116,
        "ap": 0.441527,
        "ap_weighted": 0.441527,
        "scores_per_experiment": [
          {
            "accuracy": 0.594238,
            "f1": 0.58815,
            "f1_weighted": 0.596219,
            "ap": 0.47322,
            "ap_weighted": 0.47322
          },
          {
            "accuracy": 0.495117,
            "f1": 0.494884,
            "f1_weighted": 0.496633,
            "ap": 0.421775,
            "ap_weighted": 0.421775
          },
          {
            "accuracy": 0.504395,
            "f1": 0.503186,
            "f1_weighted": 0.507134,
            "ap": 0.424248,
            "ap_weighted": 0.424248
          },
          {
            "accuracy": 0.515137,
            "f1": 0.515123,
            "f1_weighted": 0.515542,
            "ap": 0.43383,
            "ap_weighted": 0.43383
          },
          {
            "accuracy": 0.53418,
            "f1": 0.531865,
            "f1_weighted": 0.526561,
            "ap": 0.451812,
            "ap_weighted": 0.451812
          },
          {
            "accuracy": 0.521973,
            "f1": 0.512123,
            "f1_weighted": 0.523293,
            "ap": 0.425661,
            "ap_weighted": 0.425661
          },
          {
            "accuracy": 0.526855,
            "f1": 0.525086,
            "f1_weighted": 0.520416,
            "ap": 0.446562,
            "ap_weighted": 0.446562
          },
          {
            "accuracy": 0.591797,
            "f1": 0.587031,
            "f1_weighted": 0.59418,
            "ap": 0.472807,
            "ap_weighted": 0.472807
          },
          {
            "accuracy": 0.574707,
            "f1": 0.554614,
            "f1_weighted": 0.569857,
            "ap": 0.450793,
            "ap_weighted": 0.450793
          },
          {
            "accuracy": 0.47998,
            "f1": 0.479811,
            "f1_weighted": 0.481325,
            "ap": 0.414564,
            "ap_weighted": 0.414564
          }
        ],
        "main_score": 0.529187,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.62890887260437,
  "kg_co2_emissions": 0.00023583745978084398
}