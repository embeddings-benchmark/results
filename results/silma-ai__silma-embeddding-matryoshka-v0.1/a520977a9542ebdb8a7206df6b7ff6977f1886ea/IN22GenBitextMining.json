{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.125807,
        "recall": 0.166992,
        "f1": 0.137358,
        "accuracy": 0.166992,
        "main_score": 0.137358,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.087642,
        "recall": 0.137695,
        "f1": 0.100023,
        "accuracy": 0.137695,
        "main_score": 0.100023,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.061103,
        "recall": 0.105469,
        "f1": 0.071954,
        "accuracy": 0.105469,
        "main_score": 0.071954,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000743,
        "recall": 0.003906,
        "f1": 0.001062,
        "accuracy": 0.003906,
        "main_score": 0.001062,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.046491,
        "recall": 0.084961,
        "f1": 0.054842,
        "accuracy": 0.084961,
        "main_score": 0.054842,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.083964,
        "recall": 0.124023,
        "f1": 0.09397,
        "accuracy": 0.124023,
        "main_score": 0.09397,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.070806,
        "recall": 0.120117,
        "f1": 0.082362,
        "accuracy": 0.120117,
        "main_score": 0.082362,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.085229,
        "recall": 0.120117,
        "f1": 0.09406,
        "accuracy": 0.120117,
        "main_score": 0.09406,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.005031,
        "recall": 0.018555,
        "f1": 0.005934,
        "accuracy": 0.018555,
        "main_score": 0.005934,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.106244,
        "recall": 0.154297,
        "f1": 0.118945,
        "accuracy": 0.154297,
        "main_score": 0.118945,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.0248,
        "recall": 0.045898,
        "f1": 0.028825,
        "accuracy": 0.045898,
        "main_score": 0.028825,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.084928,
        "recall": 0.123047,
        "f1": 0.092943,
        "accuracy": 0.123047,
        "main_score": 0.092943,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.123899,
        "recall": 0.168945,
        "f1": 0.135226,
        "accuracy": 0.168945,
        "main_score": 0.135226,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.106218,
        "recall": 0.15918,
        "f1": 0.119929,
        "accuracy": 0.15918,
        "main_score": 0.119929,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.125565,
        "recall": 0.170898,
        "f1": 0.137498,
        "accuracy": 0.170898,
        "main_score": 0.137498,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.026667,
        "recall": 0.056641,
        "f1": 0.031905,
        "accuracy": 0.056641,
        "main_score": 0.031905,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.038725,
        "recall": 0.060547,
        "f1": 0.04237,
        "accuracy": 0.060547,
        "main_score": 0.04237,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.075539,
        "recall": 0.117188,
        "f1": 0.085318,
        "accuracy": 0.117188,
        "main_score": 0.085318,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.057215,
        "recall": 0.100586,
        "f1": 0.067739,
        "accuracy": 0.100586,
        "main_score": 0.067739,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.024665,
        "recall": 0.049805,
        "f1": 0.029636,
        "accuracy": 0.049805,
        "main_score": 0.029636,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.033742,
        "recall": 0.057617,
        "f1": 0.037693,
        "accuracy": 0.057617,
        "main_score": 0.037693,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002622,
        "recall": 0.005859,
        "f1": 0.002918,
        "accuracy": 0.005859,
        "main_score": 0.002918,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.12536,
        "recall": 0.166016,
        "f1": 0.135989,
        "accuracy": 0.166016,
        "main_score": 0.135989,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.056025,
        "recall": 0.098633,
        "f1": 0.065507,
        "accuracy": 0.098633,
        "main_score": 0.065507,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.04482,
        "recall": 0.081055,
        "f1": 0.053988,
        "accuracy": 0.081055,
        "main_score": 0.053988,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.001953,
        "f1": 2.1e-05,
        "accuracy": 0.001953,
        "main_score": 2.1e-05,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.039628,
        "recall": 0.071289,
        "f1": 0.045601,
        "accuracy": 0.071289,
        "main_score": 0.045601,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.065136,
        "recall": 0.110352,
        "f1": 0.075147,
        "accuracy": 0.110352,
        "main_score": 0.075147,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.057307,
        "recall": 0.091797,
        "f1": 0.065257,
        "accuracy": 0.091797,
        "main_score": 0.065257,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.07605,
        "recall": 0.103516,
        "f1": 0.082462,
        "accuracy": 0.103516,
        "main_score": 0.082462,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.003303,
        "recall": 0.015625,
        "f1": 0.004144,
        "accuracy": 0.015625,
        "main_score": 0.004144,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.100782,
        "recall": 0.138672,
        "f1": 0.1104,
        "accuracy": 0.138672,
        "main_score": 0.1104,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.030848,
        "recall": 0.050781,
        "f1": 0.034716,
        "accuracy": 0.050781,
        "main_score": 0.034716,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.068776,
        "recall": 0.100586,
        "f1": 0.075983,
        "accuracy": 0.100586,
        "main_score": 0.075983,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.098548,
        "recall": 0.135742,
        "f1": 0.108018,
        "accuracy": 0.135742,
        "main_score": 0.108018,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.114779,
        "recall": 0.15332,
        "f1": 0.125786,
        "accuracy": 0.15332,
        "main_score": 0.125786,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.088959,
        "recall": 0.121094,
        "f1": 0.09714,
        "accuracy": 0.121094,
        "main_score": 0.09714,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.02411,
        "recall": 0.053711,
        "f1": 0.029606,
        "accuracy": 0.053711,
        "main_score": 0.029606,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.037398,
        "recall": 0.054688,
        "f1": 0.041106,
        "accuracy": 0.054688,
        "main_score": 0.041106,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.133927,
        "recall": 0.196289,
        "f1": 0.149814,
        "accuracy": 0.196289,
        "main_score": 0.149814,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.040415,
        "recall": 0.069336,
        "f1": 0.046959,
        "accuracy": 0.069336,
        "main_score": 0.046959,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.033298,
        "recall": 0.05957,
        "f1": 0.039179,
        "accuracy": 0.05957,
        "main_score": 0.039179,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.035282,
        "recall": 0.056641,
        "f1": 0.040107,
        "accuracy": 0.056641,
        "main_score": 0.040107,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001977,
        "recall": 0.004883,
        "f1": 0.002,
        "accuracy": 0.004883,
        "main_score": 0.002,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.122448,
        "recall": 0.168945,
        "f1": 0.133898,
        "accuracy": 0.168945,
        "main_score": 0.133898,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.07519,
        "recall": 0.115234,
        "f1": 0.084969,
        "accuracy": 0.115234,
        "main_score": 0.084969,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.302653,
        "recall": 0.341797,
        "f1": 0.313088,
        "accuracy": 0.341797,
        "main_score": 0.313088,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.11034,
        "recall": 0.136719,
        "f1": 0.116425,
        "accuracy": 0.136719,
        "main_score": 0.116425,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.294382,
        "recall": 0.334961,
        "f1": 0.30498,
        "accuracy": 0.334961,
        "main_score": 0.30498,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.101548,
        "recall": 0.158203,
        "f1": 0.114295,
        "accuracy": 0.158203,
        "main_score": 0.114295,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.313951,
        "recall": 0.345703,
        "f1": 0.322626,
        "accuracy": 0.345703,
        "main_score": 0.322626,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.075501,
        "recall": 0.108398,
        "f1": 0.082667,
        "accuracy": 0.108398,
        "main_score": 0.082667,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.143555,
        "recall": 0.183594,
        "f1": 0.150678,
        "accuracy": 0.183594,
        "main_score": 0.150678,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.073291,
        "recall": 0.112305,
        "f1": 0.082762,
        "accuracy": 0.112305,
        "main_score": 0.082762,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.17461,
        "recall": 0.21582,
        "f1": 0.185546,
        "accuracy": 0.21582,
        "main_score": 0.185546,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.072007,
        "recall": 0.099609,
        "f1": 0.07848,
        "accuracy": 0.099609,
        "main_score": 0.07848,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.080842,
        "recall": 0.125977,
        "f1": 0.092127,
        "accuracy": 0.125977,
        "main_score": 0.092127,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.076922,
        "recall": 0.119141,
        "f1": 0.087059,
        "accuracy": 0.119141,
        "main_score": 0.087059,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.108727,
        "recall": 0.149414,
        "f1": 0.119552,
        "accuracy": 0.149414,
        "main_score": 0.119552,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.274328,
        "recall": 0.308594,
        "f1": 0.282576,
        "accuracy": 0.308594,
        "main_score": 0.282576,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.027782,
        "recall": 0.046875,
        "f1": 0.031574,
        "accuracy": 0.046875,
        "main_score": 0.031574,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.037223,
        "recall": 0.073242,
        "f1": 0.044863,
        "accuracy": 0.073242,
        "main_score": 0.044863,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.321126,
        "recall": 0.349609,
        "f1": 0.328875,
        "accuracy": 0.349609,
        "main_score": 0.328875,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.183005,
        "recall": 0.232422,
        "f1": 0.195678,
        "accuracy": 0.232422,
        "main_score": 0.195678,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.222592,
        "recall": 0.269531,
        "f1": 0.234277,
        "accuracy": 0.269531,
        "main_score": 0.234277,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.117073,
        "recall": 0.141602,
        "f1": 0.122032,
        "accuracy": 0.141602,
        "main_score": 0.122032,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.078507,
        "recall": 0.109375,
        "f1": 0.085458,
        "accuracy": 0.109375,
        "main_score": 0.085458,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.053651,
        "recall": 0.076172,
        "f1": 0.059114,
        "accuracy": 0.076172,
        "main_score": 0.059114,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.294955,
        "recall": 0.326172,
        "f1": 0.302803,
        "accuracy": 0.326172,
        "main_score": 0.302803,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.11119,
        "recall": 0.133789,
        "f1": 0.116617,
        "accuracy": 0.133789,
        "main_score": 0.116617,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.255058,
        "recall": 0.283203,
        "f1": 0.262015,
        "accuracy": 0.283203,
        "main_score": 0.262015,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.054321,
        "recall": 0.09668,
        "f1": 0.062187,
        "accuracy": 0.09668,
        "main_score": 0.062187,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.344222,
        "recall": 0.383789,
        "f1": 0.355125,
        "accuracy": 0.383789,
        "main_score": 0.355125,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.036397,
        "recall": 0.054688,
        "f1": 0.039203,
        "accuracy": 0.054688,
        "main_score": 0.039203,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.145039,
        "recall": 0.176758,
        "f1": 0.151358,
        "accuracy": 0.176758,
        "main_score": 0.151358,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.087229,
        "recall": 0.125,
        "f1": 0.096206,
        "accuracy": 0.125,
        "main_score": 0.096206,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.144295,
        "recall": 0.179688,
        "f1": 0.153,
        "accuracy": 0.179688,
        "main_score": 0.153,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.041961,
        "recall": 0.06543,
        "f1": 0.046376,
        "accuracy": 0.06543,
        "main_score": 0.046376,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.06721,
        "recall": 0.095703,
        "f1": 0.073745,
        "accuracy": 0.095703,
        "main_score": 0.073745,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.07454,
        "recall": 0.110352,
        "f1": 0.082957,
        "accuracy": 0.110352,
        "main_score": 0.082957,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.063296,
        "recall": 0.097656,
        "f1": 0.071339,
        "accuracy": 0.097656,
        "main_score": 0.071339,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.293059,
        "recall": 0.330078,
        "f1": 0.30153,
        "accuracy": 0.330078,
        "main_score": 0.30153,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.021025,
        "recall": 0.036133,
        "f1": 0.023485,
        "accuracy": 0.036133,
        "main_score": 0.023485,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.068932,
        "recall": 0.102539,
        "f1": 0.076717,
        "accuracy": 0.102539,
        "main_score": 0.076717,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.34346,
        "recall": 0.386719,
        "f1": 0.354874,
        "accuracy": 0.386719,
        "main_score": 0.354874,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.17147,
        "recall": 0.212891,
        "f1": 0.18157,
        "accuracy": 0.212891,
        "main_score": 0.18157,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.206484,
        "recall": 0.248047,
        "f1": 0.217017,
        "accuracy": 0.248047,
        "main_score": 0.217017,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.113429,
        "recall": 0.137695,
        "f1": 0.118639,
        "accuracy": 0.137695,
        "main_score": 0.118639,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.003796,
        "recall": 0.015625,
        "f1": 0.005069,
        "accuracy": 0.015625,
        "main_score": 0.005069,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.002963,
        "recall": 0.014648,
        "f1": 0.00419,
        "accuracy": 0.014648,
        "main_score": 0.00419,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.125673,
        "recall": 0.216797,
        "f1": 0.146211,
        "accuracy": 0.216797,
        "main_score": 0.146211,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.134682,
        "recall": 0.217773,
        "f1": 0.153125,
        "accuracy": 0.217773,
        "main_score": 0.153125,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.12718,
        "recall": 0.201172,
        "f1": 0.144906,
        "accuracy": 0.201172,
        "main_score": 0.144906,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.009632,
        "recall": 0.043945,
        "f1": 0.013868,
        "accuracy": 0.043945,
        "main_score": 0.013868,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.117538,
        "recall": 0.213867,
        "f1": 0.139042,
        "accuracy": 0.213867,
        "main_score": 0.139042,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003317,
        "recall": 0.013672,
        "f1": 0.004852,
        "accuracy": 0.013672,
        "main_score": 0.004852,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.160584,
        "recall": 0.216797,
        "f1": 0.174544,
        "accuracy": 0.216797,
        "main_score": 0.174544,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.000861,
        "recall": 0.010742,
        "f1": 0.00152,
        "accuracy": 0.010742,
        "main_score": 0.00152,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.075924,
        "recall": 0.144531,
        "f1": 0.091841,
        "accuracy": 0.144531,
        "main_score": 0.091841,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001771,
        "recall": 0.008789,
        "f1": 0.002618,
        "accuracy": 0.008789,
        "main_score": 0.002618,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001484,
        "recall": 0.011719,
        "f1": 0.002373,
        "accuracy": 0.011719,
        "main_score": 0.002373,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.004448,
        "recall": 0.020508,
        "f1": 0.005978,
        "accuracy": 0.020508,
        "main_score": 0.005978,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.001216,
        "recall": 0.012695,
        "f1": 0.002107,
        "accuracy": 0.012695,
        "main_score": 0.002107,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.13143,
        "recall": 0.214844,
        "f1": 0.149788,
        "accuracy": 0.214844,
        "main_score": 0.149788,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.004021,
        "recall": 0.012695,
        "f1": 0.005148,
        "accuracy": 0.012695,
        "main_score": 0.005148,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.00121,
        "recall": 0.014648,
        "f1": 0.002097,
        "accuracy": 0.014648,
        "main_score": 0.002097,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.130881,
        "recall": 0.206055,
        "f1": 0.147753,
        "accuracy": 0.206055,
        "main_score": 0.147753,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.087768,
        "recall": 0.162109,
        "f1": 0.103828,
        "accuracy": 0.162109,
        "main_score": 0.103828,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.109211,
        "recall": 0.18457,
        "f1": 0.126451,
        "accuracy": 0.18457,
        "main_score": 0.126451,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.199862,
        "recall": 0.259766,
        "f1": 0.214704,
        "accuracy": 0.259766,
        "main_score": 0.214704,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.06535,
        "recall": 0.104492,
        "f1": 0.073431,
        "accuracy": 0.104492,
        "main_score": 0.073431,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.056543,
        "recall": 0.087891,
        "f1": 0.06346,
        "accuracy": 0.087891,
        "main_score": 0.06346,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.307846,
        "recall": 0.354492,
        "f1": 0.320279,
        "accuracy": 0.354492,
        "main_score": 0.320279,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.278394,
        "recall": 0.313477,
        "f1": 0.287255,
        "accuracy": 0.313477,
        "main_score": 0.287255,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.107274,
        "recall": 0.133789,
        "f1": 0.113397,
        "accuracy": 0.133789,
        "main_score": 0.113397,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.102038,
        "recall": 0.165039,
        "f1": 0.115607,
        "accuracy": 0.165039,
        "main_score": 0.115607,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.278651,
        "recall": 0.3125,
        "f1": 0.286837,
        "accuracy": 0.3125,
        "main_score": 0.286837,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.102292,
        "recall": 0.145508,
        "f1": 0.113437,
        "accuracy": 0.145508,
        "main_score": 0.113437,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.138683,
        "recall": 0.175781,
        "f1": 0.146062,
        "accuracy": 0.175781,
        "main_score": 0.146062,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.050143,
        "recall": 0.083984,
        "f1": 0.057516,
        "accuracy": 0.083984,
        "main_score": 0.057516,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.176294,
        "recall": 0.227539,
        "f1": 0.189391,
        "accuracy": 0.227539,
        "main_score": 0.189391,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.089178,
        "recall": 0.121094,
        "f1": 0.096888,
        "accuracy": 0.121094,
        "main_score": 0.096888,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.066087,
        "recall": 0.103516,
        "f1": 0.074355,
        "accuracy": 0.103516,
        "main_score": 0.074355,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.06176,
        "recall": 0.099609,
        "f1": 0.070493,
        "accuracy": 0.099609,
        "main_score": 0.070493,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.081167,
        "recall": 0.116211,
        "f1": 0.088571,
        "accuracy": 0.116211,
        "main_score": 0.088571,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.265881,
        "recall": 0.295898,
        "f1": 0.273019,
        "accuracy": 0.295898,
        "main_score": 0.273019,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.039289,
        "recall": 0.066406,
        "f1": 0.044996,
        "accuracy": 0.066406,
        "main_score": 0.044996,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.042444,
        "recall": 0.077148,
        "f1": 0.049134,
        "accuracy": 0.077148,
        "main_score": 0.049134,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.289945,
        "recall": 0.327148,
        "f1": 0.299208,
        "accuracy": 0.327148,
        "main_score": 0.299208,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.209291,
        "recall": 0.260742,
        "f1": 0.222897,
        "accuracy": 0.260742,
        "main_score": 0.222897,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.255866,
        "recall": 0.299805,
        "f1": 0.267942,
        "accuracy": 0.299805,
        "main_score": 0.267942,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.121287,
        "recall": 0.150391,
        "f1": 0.127188,
        "accuracy": 0.150391,
        "main_score": 0.127188,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.094112,
        "recall": 0.131836,
        "f1": 0.10313,
        "accuracy": 0.131836,
        "main_score": 0.10313,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.064605,
        "recall": 0.107422,
        "f1": 0.075001,
        "accuracy": 0.107422,
        "main_score": 0.075001,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.096564,
        "recall": 0.138672,
        "f1": 0.106273,
        "accuracy": 0.138672,
        "main_score": 0.106273,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.07658,
        "recall": 0.107422,
        "f1": 0.082981,
        "accuracy": 0.107422,
        "main_score": 0.082981,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.018561,
        "recall": 0.022461,
        "f1": 0.019023,
        "accuracy": 0.022461,
        "main_score": 0.019023,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.095656,
        "recall": 0.137695,
        "f1": 0.105644,
        "accuracy": 0.137695,
        "main_score": 0.105644,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.081831,
        "recall": 0.114258,
        "f1": 0.08916,
        "accuracy": 0.114258,
        "main_score": 0.08916,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.102905,
        "recall": 0.147461,
        "f1": 0.11443,
        "accuracy": 0.147461,
        "main_score": 0.11443,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.024444,
        "recall": 0.036133,
        "f1": 0.025506,
        "accuracy": 0.036133,
        "main_score": 0.025506,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.083311,
        "recall": 0.123047,
        "f1": 0.092316,
        "accuracy": 0.123047,
        "main_score": 0.092316,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.066989,
        "recall": 0.09375,
        "f1": 0.07252,
        "accuracy": 0.09375,
        "main_score": 0.07252,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.097407,
        "recall": 0.136719,
        "f1": 0.106585,
        "accuracy": 0.136719,
        "main_score": 0.106585,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.069862,
        "recall": 0.109375,
        "f1": 0.079134,
        "accuracy": 0.109375,
        "main_score": 0.079134,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.071311,
        "recall": 0.111328,
        "f1": 0.079988,
        "accuracy": 0.111328,
        "main_score": 0.079988,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.091956,
        "recall": 0.138672,
        "f1": 0.102802,
        "accuracy": 0.138672,
        "main_score": 0.102802,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.055526,
        "recall": 0.077148,
        "f1": 0.059516,
        "accuracy": 0.077148,
        "main_score": 0.059516,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.032935,
        "recall": 0.049805,
        "f1": 0.035839,
        "accuracy": 0.049805,
        "main_score": 0.035839,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ]
      },
      {
        "precision": 0.050221,
        "recall": 0.079102,
        "f1": 0.056319,
        "accuracy": 0.079102,
        "main_score": 0.056319,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.085828,
        "recall": 0.117188,
        "f1": 0.092817,
        "accuracy": 0.117188,
        "main_score": 0.092817,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.068204,
        "recall": 0.094727,
        "f1": 0.074485,
        "accuracy": 0.094727,
        "main_score": 0.074485,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.075124,
        "recall": 0.103516,
        "f1": 0.081312,
        "accuracy": 0.103516,
        "main_score": 0.081312,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.019062,
        "recall": 0.024414,
        "f1": 0.019686,
        "accuracy": 0.024414,
        "main_score": 0.019686,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.075579,
        "recall": 0.114258,
        "f1": 0.085267,
        "accuracy": 0.114258,
        "main_score": 0.085267,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.060548,
        "recall": 0.095703,
        "f1": 0.069063,
        "accuracy": 0.095703,
        "main_score": 0.069063,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.302648,
        "recall": 0.334961,
        "f1": 0.311279,
        "accuracy": 0.334961,
        "main_score": 0.311279,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.337828,
        "recall": 0.379883,
        "f1": 0.349085,
        "accuracy": 0.379883,
        "main_score": 0.349085,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.099256,
        "recall": 0.12207,
        "f1": 0.104337,
        "accuracy": 0.12207,
        "main_score": 0.104337,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.259133,
        "recall": 0.291016,
        "f1": 0.266902,
        "accuracy": 0.291016,
        "main_score": 0.266902,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.069364,
        "recall": 0.118164,
        "f1": 0.079416,
        "accuracy": 0.118164,
        "main_score": 0.079416,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.036803,
        "recall": 0.058594,
        "f1": 0.040709,
        "accuracy": 0.058594,
        "main_score": 0.040709,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.131569,
        "recall": 0.167969,
        "f1": 0.138518,
        "accuracy": 0.167969,
        "main_score": 0.138518,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.088773,
        "recall": 0.131836,
        "f1": 0.099678,
        "accuracy": 0.131836,
        "main_score": 0.099678,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.143921,
        "recall": 0.185547,
        "f1": 0.154428,
        "accuracy": 0.185547,
        "main_score": 0.154428,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.035727,
        "recall": 0.058594,
        "f1": 0.040227,
        "accuracy": 0.058594,
        "main_score": 0.040227,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.081953,
        "recall": 0.112305,
        "f1": 0.089039,
        "accuracy": 0.112305,
        "main_score": 0.089039,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.052149,
        "recall": 0.081055,
        "f1": 0.05877,
        "accuracy": 0.081055,
        "main_score": 0.05877,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.070247,
        "recall": 0.102539,
        "f1": 0.077964,
        "accuracy": 0.102539,
        "main_score": 0.077964,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.276054,
        "recall": 0.31543,
        "f1": 0.285646,
        "accuracy": 0.31543,
        "main_score": 0.285646,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019741,
        "recall": 0.033203,
        "f1": 0.022091,
        "accuracy": 0.033203,
        "main_score": 0.022091,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.053885,
        "recall": 0.085938,
        "f1": 0.061198,
        "accuracy": 0.085938,
        "main_score": 0.061198,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.365641,
        "recall": 0.408203,
        "f1": 0.376938,
        "accuracy": 0.408203,
        "main_score": 0.376938,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.158535,
        "recall": 0.201172,
        "f1": 0.169001,
        "accuracy": 0.201172,
        "main_score": 0.169001,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.201505,
        "recall": 0.239258,
        "f1": 0.210799,
        "accuracy": 0.239258,
        "main_score": 0.210799,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.111424,
        "recall": 0.134766,
        "f1": 0.115697,
        "accuracy": 0.134766,
        "main_score": 0.115697,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.097536,
        "recall": 0.143555,
        "f1": 0.108878,
        "accuracy": 0.143555,
        "main_score": 0.108878,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.077527,
        "recall": 0.12207,
        "f1": 0.087678,
        "accuracy": 0.12207,
        "main_score": 0.087678,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.051515,
        "recall": 0.104492,
        "f1": 0.063655,
        "accuracy": 0.104492,
        "main_score": 0.063655,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.026438,
        "recall": 0.050781,
        "f1": 0.031124,
        "accuracy": 0.050781,
        "main_score": 0.031124,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001989,
        "recall": 0.004883,
        "f1": 0.002023,
        "accuracy": 0.004883,
        "main_score": 0.002023,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.073561,
        "recall": 0.118164,
        "f1": 0.084184,
        "accuracy": 0.118164,
        "main_score": 0.084184,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.105974,
        "recall": 0.15918,
        "f1": 0.11985,
        "accuracy": 0.15918,
        "main_score": 0.11985,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.032073,
        "recall": 0.064453,
        "f1": 0.039065,
        "accuracy": 0.064453,
        "main_score": 0.039065,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003748,
        "recall": 0.017578,
        "f1": 0.004754,
        "accuracy": 0.017578,
        "main_score": 0.004754,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.067619,
        "recall": 0.107422,
        "f1": 0.076517,
        "accuracy": 0.107422,
        "main_score": 0.076517,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.048743,
        "recall": 0.084961,
        "f1": 0.056592,
        "accuracy": 0.084961,
        "main_score": 0.056592,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.111516,
        "recall": 0.157227,
        "f1": 0.123756,
        "accuracy": 0.157227,
        "main_score": 0.123756,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.069706,
        "recall": 0.110352,
        "f1": 0.079288,
        "accuracy": 0.110352,
        "main_score": 0.079288,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.083333,
        "recall": 0.129883,
        "f1": 0.094028,
        "accuracy": 0.129883,
        "main_score": 0.094028,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.104546,
        "recall": 0.148438,
        "f1": 0.114423,
        "accuracy": 0.148438,
        "main_score": 0.114423,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.020572,
        "recall": 0.041016,
        "f1": 0.024386,
        "accuracy": 0.041016,
        "main_score": 0.024386,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.052079,
        "recall": 0.084961,
        "f1": 0.059692,
        "accuracy": 0.084961,
        "main_score": 0.059692,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ]
      },
      {
        "precision": 0.043971,
        "recall": 0.074219,
        "f1": 0.050197,
        "accuracy": 0.074219,
        "main_score": 0.050197,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.030576,
        "recall": 0.066406,
        "f1": 0.037732,
        "accuracy": 0.066406,
        "main_score": 0.037732,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.053657,
        "recall": 0.09668,
        "f1": 0.063968,
        "accuracy": 0.09668,
        "main_score": 0.063968,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.077358,
        "recall": 0.118164,
        "f1": 0.087508,
        "accuracy": 0.118164,
        "main_score": 0.087508,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002648,
        "recall": 0.009766,
        "f1": 0.003105,
        "accuracy": 0.009766,
        "main_score": 0.003105,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.013417,
        "recall": 0.030273,
        "f1": 0.015786,
        "accuracy": 0.030273,
        "main_score": 0.015786,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.013607,
        "recall": 0.029297,
        "f1": 0.016032,
        "accuracy": 0.029297,
        "main_score": 0.016032,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.206958,
        "recall": 0.237305,
        "f1": 0.2144,
        "accuracy": 0.237305,
        "main_score": 0.2144,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.217087,
        "recall": 0.253906,
        "f1": 0.225652,
        "accuracy": 0.253906,
        "main_score": 0.225652,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.127135,
        "recall": 0.15332,
        "f1": 0.132565,
        "accuracy": 0.15332,
        "main_score": 0.132565,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.196098,
        "recall": 0.219727,
        "f1": 0.201943,
        "accuracy": 0.219727,
        "main_score": 0.201943,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.028351,
        "recall": 0.058594,
        "f1": 0.033745,
        "accuracy": 0.058594,
        "main_score": 0.033745,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.217162,
        "recall": 0.25,
        "f1": 0.224443,
        "accuracy": 0.25,
        "main_score": 0.224443,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.013713,
        "recall": 0.029297,
        "f1": 0.016434,
        "accuracy": 0.029297,
        "main_score": 0.016434,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.015369,
        "recall": 0.040039,
        "f1": 0.019275,
        "accuracy": 0.040039,
        "main_score": 0.019275,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.123302,
        "recall": 0.15332,
        "f1": 0.130939,
        "accuracy": 0.15332,
        "main_score": 0.130939,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.017003,
        "recall": 0.032227,
        "f1": 0.019274,
        "accuracy": 0.032227,
        "main_score": 0.019274,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.015512,
        "recall": 0.037109,
        "f1": 0.018905,
        "accuracy": 0.037109,
        "main_score": 0.018905,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.016642,
        "recall": 0.036133,
        "f1": 0.019631,
        "accuracy": 0.036133,
        "main_score": 0.019631,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.015371,
        "recall": 0.029297,
        "f1": 0.017312,
        "accuracy": 0.029297,
        "main_score": 0.017312,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.224436,
        "recall": 0.250977,
        "f1": 0.230733,
        "accuracy": 0.250977,
        "main_score": 0.230733,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.006407,
        "recall": 0.018555,
        "f1": 0.007904,
        "accuracy": 0.018555,
        "main_score": 0.007904,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.012295,
        "recall": 0.026367,
        "f1": 0.014587,
        "accuracy": 0.026367,
        "main_score": 0.014587,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.217454,
        "recall": 0.245117,
        "f1": 0.224303,
        "accuracy": 0.245117,
        "main_score": 0.224303,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.135332,
        "recall": 0.169922,
        "f1": 0.144414,
        "accuracy": 0.169922,
        "main_score": 0.144414,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.158136,
        "recall": 0.189453,
        "f1": 0.165939,
        "accuracy": 0.189453,
        "main_score": 0.165939,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.284006,
        "recall": 0.323242,
        "f1": 0.294138,
        "accuracy": 0.323242,
        "main_score": 0.294138,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.107598,
        "recall": 0.147461,
        "f1": 0.117222,
        "accuracy": 0.147461,
        "main_score": 0.117222,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.102499,
        "recall": 0.143555,
        "f1": 0.113444,
        "accuracy": 0.143555,
        "main_score": 0.113444,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.054106,
        "recall": 0.09082,
        "f1": 0.061549,
        "accuracy": 0.09082,
        "main_score": 0.061549,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.072879,
        "recall": 0.115234,
        "f1": 0.082905,
        "accuracy": 0.115234,
        "main_score": 0.082905,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001976,
        "recall": 0.004883,
        "f1": 0.001998,
        "accuracy": 0.004883,
        "main_score": 0.001998,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.032848,
        "recall": 0.056641,
        "f1": 0.037573,
        "accuracy": 0.056641,
        "main_score": 0.037573,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.071345,
        "recall": 0.104492,
        "f1": 0.079197,
        "accuracy": 0.104492,
        "main_score": 0.079197,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.071125,
        "recall": 0.109375,
        "f1": 0.080763,
        "accuracy": 0.109375,
        "main_score": 0.080763,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.056493,
        "recall": 0.077148,
        "f1": 0.060964,
        "accuracy": 0.077148,
        "main_score": 0.060964,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006547,
        "recall": 0.023438,
        "f1": 0.007674,
        "accuracy": 0.023438,
        "main_score": 0.007674,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.0161,
        "recall": 0.027344,
        "f1": 0.017943,
        "accuracy": 0.027344,
        "main_score": 0.017943,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.068034,
        "recall": 0.101562,
        "f1": 0.075476,
        "accuracy": 0.101562,
        "main_score": 0.075476,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.09837,
        "recall": 0.138672,
        "f1": 0.108106,
        "accuracy": 0.138672,
        "main_score": 0.108106,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.113759,
        "recall": 0.155273,
        "f1": 0.123778,
        "accuracy": 0.155273,
        "main_score": 0.123778,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.099221,
        "recall": 0.134766,
        "f1": 0.107443,
        "accuracy": 0.134766,
        "main_score": 0.107443,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.029888,
        "recall": 0.052734,
        "f1": 0.033935,
        "accuracy": 0.052734,
        "main_score": 0.033935,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.028474,
        "recall": 0.047852,
        "f1": 0.031763,
        "accuracy": 0.047852,
        "main_score": 0.031763,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.080881,
        "recall": 0.116211,
        "f1": 0.090504,
        "accuracy": 0.116211,
        "main_score": 0.090504,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.054957,
        "recall": 0.084961,
        "f1": 0.061813,
        "accuracy": 0.084961,
        "main_score": 0.061813,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.027511,
        "recall": 0.050781,
        "f1": 0.031682,
        "accuracy": 0.050781,
        "main_score": 0.031682,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.026449,
        "recall": 0.047852,
        "f1": 0.029795,
        "accuracy": 0.047852,
        "main_score": 0.029795,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.003139,
        "recall": 0.008789,
        "f1": 0.0033,
        "accuracy": 0.008789,
        "main_score": 0.0033,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.039939,
        "recall": 0.06543,
        "f1": 0.044705,
        "accuracy": 0.06543,
        "main_score": 0.044705,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.039825,
        "recall": 0.067383,
        "f1": 0.045996,
        "accuracy": 0.067383,
        "main_score": 0.045996,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.189927,
        "recall": 0.220703,
        "f1": 0.197554,
        "accuracy": 0.220703,
        "main_score": 0.197554,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.1627,
        "recall": 0.188477,
        "f1": 0.16904,
        "accuracy": 0.188477,
        "main_score": 0.16904,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.061685,
        "recall": 0.083984,
        "f1": 0.066885,
        "accuracy": 0.083984,
        "main_score": 0.066885,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.191128,
        "recall": 0.227539,
        "f1": 0.200838,
        "accuracy": 0.227539,
        "main_score": 0.200838,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.068069,
        "recall": 0.108398,
        "f1": 0.076881,
        "accuracy": 0.108398,
        "main_score": 0.076881,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.170522,
        "recall": 0.204102,
        "f1": 0.178296,
        "accuracy": 0.204102,
        "main_score": 0.178296,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.074702,
        "recall": 0.108398,
        "f1": 0.082419,
        "accuracy": 0.108398,
        "main_score": 0.082419,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.091175,
        "recall": 0.116211,
        "f1": 0.096206,
        "accuracy": 0.116211,
        "main_score": 0.096206,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.026224,
        "recall": 0.056641,
        "f1": 0.031793,
        "accuracy": 0.056641,
        "main_score": 0.031793,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.053794,
        "recall": 0.078125,
        "f1": 0.059151,
        "accuracy": 0.078125,
        "main_score": 0.059151,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.034226,
        "recall": 0.057617,
        "f1": 0.038865,
        "accuracy": 0.057617,
        "main_score": 0.038865,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.034941,
        "recall": 0.054688,
        "f1": 0.038525,
        "accuracy": 0.054688,
        "main_score": 0.038525,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.034703,
        "recall": 0.05957,
        "f1": 0.039315,
        "accuracy": 0.05957,
        "main_score": 0.039315,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.157214,
        "recall": 0.178711,
        "f1": 0.163121,
        "accuracy": 0.178711,
        "main_score": 0.163121,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.031075,
        "recall": 0.054688,
        "f1": 0.035373,
        "accuracy": 0.054688,
        "main_score": 0.035373,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ]
      },
      {
        "precision": 0.023026,
        "recall": 0.041992,
        "f1": 0.02621,
        "accuracy": 0.041992,
        "main_score": 0.02621,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.167065,
        "recall": 0.193359,
        "f1": 0.173116,
        "accuracy": 0.193359,
        "main_score": 0.173116,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.189914,
        "recall": 0.222656,
        "f1": 0.198678,
        "accuracy": 0.222656,
        "main_score": 0.198678,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.187371,
        "recall": 0.22168,
        "f1": 0.196424,
        "accuracy": 0.22168,
        "main_score": 0.196424,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.074897,
        "recall": 0.095703,
        "f1": 0.079185,
        "accuracy": 0.095703,
        "main_score": 0.079185,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.092476,
        "recall": 0.130859,
        "f1": 0.101108,
        "accuracy": 0.130859,
        "main_score": 0.101108,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.076667,
        "recall": 0.123047,
        "f1": 0.086394,
        "accuracy": 0.123047,
        "main_score": 0.086394,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.055303,
        "recall": 0.09375,
        "f1": 0.063873,
        "accuracy": 0.09375,
        "main_score": 0.063873,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.035976,
        "recall": 0.063477,
        "f1": 0.041136,
        "accuracy": 0.063477,
        "main_score": 0.041136,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001023,
        "recall": 0.004883,
        "f1": 0.001392,
        "accuracy": 0.004883,
        "main_score": 0.001392,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.065502,
        "recall": 0.114258,
        "f1": 0.076956,
        "accuracy": 0.114258,
        "main_score": 0.076956,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.105973,
        "recall": 0.149414,
        "f1": 0.116955,
        "accuracy": 0.149414,
        "main_score": 0.116955,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.038578,
        "recall": 0.064453,
        "f1": 0.044045,
        "accuracy": 0.064453,
        "main_score": 0.044045,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.115921,
        "recall": 0.150391,
        "f1": 0.124824,
        "accuracy": 0.150391,
        "main_score": 0.124824,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004204,
        "recall": 0.016602,
        "f1": 0.004932,
        "accuracy": 0.016602,
        "main_score": 0.004932,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.070607,
        "recall": 0.107422,
        "f1": 0.079679,
        "accuracy": 0.107422,
        "main_score": 0.079679,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.038354,
        "recall": 0.067383,
        "f1": 0.045347,
        "accuracy": 0.067383,
        "main_score": 0.045347,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.069289,
        "recall": 0.103516,
        "f1": 0.077138,
        "accuracy": 0.103516,
        "main_score": 0.077138,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.082597,
        "recall": 0.126953,
        "f1": 0.091251,
        "accuracy": 0.126953,
        "main_score": 0.091251,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.094354,
        "recall": 0.126953,
        "f1": 0.102596,
        "accuracy": 0.126953,
        "main_score": 0.102596,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.020376,
        "recall": 0.046875,
        "f1": 0.024673,
        "accuracy": 0.046875,
        "main_score": 0.024673,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.041835,
        "recall": 0.067383,
        "f1": 0.047144,
        "accuracy": 0.067383,
        "main_score": 0.047144,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.041565,
        "recall": 0.073242,
        "f1": 0.048049,
        "accuracy": 0.073242,
        "main_score": 0.048049,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.036453,
        "recall": 0.070312,
        "f1": 0.043371,
        "accuracy": 0.070312,
        "main_score": 0.043371,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.042222,
        "recall": 0.071289,
        "f1": 0.049095,
        "accuracy": 0.071289,
        "main_score": 0.049095,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.056858,
        "recall": 0.088867,
        "f1": 0.063942,
        "accuracy": 0.088867,
        "main_score": 0.063942,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002355,
        "recall": 0.007812,
        "f1": 0.00264,
        "accuracy": 0.007812,
        "main_score": 0.00264,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.117504,
        "recall": 0.167969,
        "f1": 0.130211,
        "accuracy": 0.167969,
        "main_score": 0.130211,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.104024,
        "recall": 0.141602,
        "f1": 0.113894,
        "accuracy": 0.141602,
        "main_score": 0.113894,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.061652,
        "recall": 0.100586,
        "f1": 0.070095,
        "accuracy": 0.100586,
        "main_score": 0.070095,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.055682,
        "recall": 0.094727,
        "f1": 0.065301,
        "accuracy": 0.094727,
        "main_score": 0.065301,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000615,
        "recall": 0.004883,
        "f1": 0.000883,
        "accuracy": 0.004883,
        "main_score": 0.000883,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.033423,
        "recall": 0.064453,
        "f1": 0.039887,
        "accuracy": 0.064453,
        "main_score": 0.039887,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.069192,
        "recall": 0.114258,
        "f1": 0.07978,
        "accuracy": 0.114258,
        "main_score": 0.07978,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.060907,
        "recall": 0.105469,
        "f1": 0.07162,
        "accuracy": 0.105469,
        "main_score": 0.07162,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.062862,
        "recall": 0.097656,
        "f1": 0.070341,
        "accuracy": 0.097656,
        "main_score": 0.070341,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006164,
        "recall": 0.021484,
        "f1": 0.007102,
        "accuracy": 0.021484,
        "main_score": 0.007102,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.102163,
        "recall": 0.140625,
        "f1": 0.112086,
        "accuracy": 0.140625,
        "main_score": 0.112086,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.02679,
        "recall": 0.043945,
        "f1": 0.030138,
        "accuracy": 0.043945,
        "main_score": 0.030138,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.069204,
        "recall": 0.103516,
        "f1": 0.076455,
        "accuracy": 0.103516,
        "main_score": 0.076455,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.114016,
        "recall": 0.155273,
        "f1": 0.124829,
        "accuracy": 0.155273,
        "main_score": 0.124829,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.092247,
        "recall": 0.128906,
        "f1": 0.101865,
        "accuracy": 0.128906,
        "main_score": 0.101865,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.023364,
        "recall": 0.054688,
        "f1": 0.029173,
        "accuracy": 0.054688,
        "main_score": 0.029173,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.03096,
        "recall": 0.047852,
        "f1": 0.03432,
        "accuracy": 0.047852,
        "main_score": 0.03432,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ]
      },
      {
        "precision": 0.068284,
        "recall": 0.107422,
        "f1": 0.078039,
        "accuracy": 0.107422,
        "main_score": 0.078039,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.049863,
        "recall": 0.088867,
        "f1": 0.058754,
        "accuracy": 0.088867,
        "main_score": 0.058754,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.023833,
        "recall": 0.049805,
        "f1": 0.029213,
        "accuracy": 0.049805,
        "main_score": 0.029213,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.030149,
        "recall": 0.056641,
        "f1": 0.035096,
        "accuracy": 0.056641,
        "main_score": 0.035096,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002099,
        "recall": 0.005859,
        "f1": 0.002218,
        "accuracy": 0.005859,
        "main_score": 0.002218,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.112545,
        "recall": 0.15625,
        "f1": 0.123003,
        "accuracy": 0.15625,
        "main_score": 0.123003,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.113627,
        "recall": 0.147461,
        "f1": 0.122669,
        "accuracy": 0.147461,
        "main_score": 0.122669,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.052036,
        "recall": 0.091797,
        "f1": 0.061453,
        "accuracy": 0.091797,
        "main_score": 0.061453,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.063996,
        "recall": 0.099609,
        "f1": 0.072381,
        "accuracy": 0.099609,
        "main_score": 0.072381,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.002936,
        "recall": 0.004883,
        "f1": 0.003268,
        "accuracy": 0.004883,
        "main_score": 0.003268,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.036902,
        "recall": 0.071289,
        "f1": 0.044136,
        "accuracy": 0.071289,
        "main_score": 0.044136,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.067355,
        "recall": 0.114258,
        "f1": 0.077992,
        "accuracy": 0.114258,
        "main_score": 0.077992,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.041807,
        "recall": 0.075195,
        "f1": 0.049606,
        "accuracy": 0.075195,
        "main_score": 0.049606,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.07989,
        "recall": 0.111328,
        "f1": 0.08653,
        "accuracy": 0.111328,
        "main_score": 0.08653,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006292,
        "recall": 0.024414,
        "f1": 0.007359,
        "accuracy": 0.024414,
        "main_score": 0.007359,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.128229,
        "recall": 0.176758,
        "f1": 0.140349,
        "accuracy": 0.176758,
        "main_score": 0.140349,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.020307,
        "recall": 0.038086,
        "f1": 0.023689,
        "accuracy": 0.038086,
        "main_score": 0.023689,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.083223,
        "recall": 0.118164,
        "f1": 0.090564,
        "accuracy": 0.118164,
        "main_score": 0.090564,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.123547,
        "recall": 0.160156,
        "f1": 0.133059,
        "accuracy": 0.160156,
        "main_score": 0.133059,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.10847,
        "recall": 0.148438,
        "f1": 0.118683,
        "accuracy": 0.148438,
        "main_score": 0.118683,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.030196,
        "recall": 0.058594,
        "f1": 0.035478,
        "accuracy": 0.058594,
        "main_score": 0.035478,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.039648,
        "recall": 0.057617,
        "f1": 0.043314,
        "accuracy": 0.057617,
        "main_score": 0.043314,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.077527,
        "recall": 0.117188,
        "f1": 0.088432,
        "accuracy": 0.117188,
        "main_score": 0.088432,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.037006,
        "recall": 0.0625,
        "f1": 0.042217,
        "accuracy": 0.0625,
        "main_score": 0.042217,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.0376,
        "recall": 0.067383,
        "f1": 0.043468,
        "accuracy": 0.067383,
        "main_score": 0.043468,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.042967,
        "recall": 0.063477,
        "f1": 0.047108,
        "accuracy": 0.063477,
        "main_score": 0.047108,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.002796,
        "recall": 0.008789,
        "f1": 0.003219,
        "accuracy": 0.008789,
        "main_score": 0.003219,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.124997,
        "recall": 0.168945,
        "f1": 0.13642,
        "accuracy": 0.168945,
        "main_score": 0.13642,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.096416,
        "recall": 0.144531,
        "f1": 0.108733,
        "accuracy": 0.144531,
        "main_score": 0.108733,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.080008,
        "recall": 0.12793,
        "f1": 0.092243,
        "accuracy": 0.12793,
        "main_score": 0.092243,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.058145,
        "recall": 0.101562,
        "f1": 0.067674,
        "accuracy": 0.101562,
        "main_score": 0.067674,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.00098,
        "recall": 0.001953,
        "f1": 0.000983,
        "accuracy": 0.001953,
        "main_score": 0.000983,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.05667,
        "recall": 0.103516,
        "f1": 0.065772,
        "accuracy": 0.103516,
        "main_score": 0.065772,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.091155,
        "recall": 0.140625,
        "f1": 0.102854,
        "accuracy": 0.140625,
        "main_score": 0.102854,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.067015,
        "recall": 0.115234,
        "f1": 0.078265,
        "accuracy": 0.115234,
        "main_score": 0.078265,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.093573,
        "recall": 0.129883,
        "f1": 0.101891,
        "accuracy": 0.129883,
        "main_score": 0.101891,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.003366,
        "recall": 0.015625,
        "f1": 0.004231,
        "accuracy": 0.015625,
        "main_score": 0.004231,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.101321,
        "recall": 0.152344,
        "f1": 0.11406,
        "accuracy": 0.152344,
        "main_score": 0.11406,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.023105,
        "recall": 0.043945,
        "f1": 0.027034,
        "accuracy": 0.043945,
        "main_score": 0.027034,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.085119,
        "recall": 0.121094,
        "f1": 0.093438,
        "accuracy": 0.121094,
        "main_score": 0.093438,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.116871,
        "recall": 0.161133,
        "f1": 0.128992,
        "accuracy": 0.161133,
        "main_score": 0.128992,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.105856,
        "recall": 0.158203,
        "f1": 0.119025,
        "accuracy": 0.158203,
        "main_score": 0.119025,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.030709,
        "recall": 0.068359,
        "f1": 0.036882,
        "accuracy": 0.068359,
        "main_score": 0.036882,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.053729,
        "recall": 0.084961,
        "f1": 0.060289,
        "accuracy": 0.084961,
        "main_score": 0.060289,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ]
      },
      {
        "precision": 0.053159,
        "recall": 0.094727,
        "f1": 0.062902,
        "accuracy": 0.094727,
        "main_score": 0.062902,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.057334,
        "recall": 0.107422,
        "f1": 0.068443,
        "accuracy": 0.107422,
        "main_score": 0.068443,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.025278,
        "recall": 0.049805,
        "f1": 0.029605,
        "accuracy": 0.049805,
        "main_score": 0.029605,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.0395,
        "recall": 0.064453,
        "f1": 0.04399,
        "accuracy": 0.064453,
        "main_score": 0.04399,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001161,
        "recall": 0.006836,
        "f1": 0.001319,
        "accuracy": 0.006836,
        "main_score": 0.001319,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.058207,
        "recall": 0.085938,
        "f1": 0.063928,
        "accuracy": 0.085938,
        "main_score": 0.063928,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.045392,
        "recall": 0.077148,
        "f1": 0.052582,
        "accuracy": 0.077148,
        "main_score": 0.052582,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.29119,
        "recall": 0.322266,
        "f1": 0.299557,
        "accuracy": 0.322266,
        "main_score": 0.299557,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.329184,
        "recall": 0.366211,
        "f1": 0.339047,
        "accuracy": 0.366211,
        "main_score": 0.339047,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.106631,
        "recall": 0.129883,
        "f1": 0.1127,
        "accuracy": 0.129883,
        "main_score": 0.1127,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.263627,
        "recall": 0.295898,
        "f1": 0.272099,
        "accuracy": 0.295898,
        "main_score": 0.272099,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.060832,
        "recall": 0.103516,
        "f1": 0.070299,
        "accuracy": 0.103516,
        "main_score": 0.070299,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.317047,
        "recall": 0.356445,
        "f1": 0.328031,
        "accuracy": 0.356445,
        "main_score": 0.328031,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.032107,
        "recall": 0.050781,
        "f1": 0.03544,
        "accuracy": 0.050781,
        "main_score": 0.03544,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.151572,
        "recall": 0.183594,
        "f1": 0.157188,
        "accuracy": 0.183594,
        "main_score": 0.157188,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.060031,
        "recall": 0.09668,
        "f1": 0.067722,
        "accuracy": 0.09668,
        "main_score": 0.067722,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.157723,
        "recall": 0.197266,
        "f1": 0.167715,
        "accuracy": 0.197266,
        "main_score": 0.167715,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.035202,
        "recall": 0.058594,
        "f1": 0.040354,
        "accuracy": 0.058594,
        "main_score": 0.040354,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.054047,
        "recall": 0.079102,
        "f1": 0.060451,
        "accuracy": 0.079102,
        "main_score": 0.060451,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.05481,
        "recall": 0.088867,
        "f1": 0.062335,
        "accuracy": 0.088867,
        "main_score": 0.062335,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.057677,
        "recall": 0.089844,
        "f1": 0.064169,
        "accuracy": 0.089844,
        "main_score": 0.064169,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.023461,
        "recall": 0.041016,
        "f1": 0.02699,
        "accuracy": 0.041016,
        "main_score": 0.02699,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ]
      },
      {
        "precision": 0.035557,
        "recall": 0.070312,
        "f1": 0.043032,
        "accuracy": 0.070312,
        "main_score": 0.043032,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.307322,
        "recall": 0.341797,
        "f1": 0.316082,
        "accuracy": 0.341797,
        "main_score": 0.316082,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.181483,
        "recall": 0.220703,
        "f1": 0.190792,
        "accuracy": 0.220703,
        "main_score": 0.190792,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.204315,
        "recall": 0.242188,
        "f1": 0.213761,
        "accuracy": 0.242188,
        "main_score": 0.213761,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.115465,
        "recall": 0.143555,
        "f1": 0.121395,
        "accuracy": 0.143555,
        "main_score": 0.121395,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.038851,
        "recall": 0.068359,
        "f1": 0.044133,
        "accuracy": 0.068359,
        "main_score": 0.044133,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.030676,
        "recall": 0.058594,
        "f1": 0.035655,
        "accuracy": 0.058594,
        "main_score": 0.035655,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.022081,
        "recall": 0.042969,
        "f1": 0.025979,
        "accuracy": 0.042969,
        "main_score": 0.025979,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.013937,
        "recall": 0.027344,
        "f1": 0.016031,
        "accuracy": 0.027344,
        "main_score": 0.016031,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.000779,
        "recall": 0.005859,
        "f1": 0.001158,
        "accuracy": 0.005859,
        "main_score": 0.001158,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027474,
        "recall": 0.054688,
        "f1": 0.032184,
        "accuracy": 0.054688,
        "main_score": 0.032184,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.035876,
        "recall": 0.063477,
        "f1": 0.04117,
        "accuracy": 0.063477,
        "main_score": 0.04117,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.014747,
        "recall": 0.038086,
        "f1": 0.018588,
        "accuracy": 0.038086,
        "main_score": 0.018588,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.052307,
        "recall": 0.076172,
        "f1": 0.057317,
        "accuracy": 0.076172,
        "main_score": 0.057317,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.002185,
        "recall": 0.012695,
        "f1": 0.002856,
        "accuracy": 0.012695,
        "main_score": 0.002856,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.030374,
        "recall": 0.056641,
        "f1": 0.035331,
        "accuracy": 0.056641,
        "main_score": 0.035331,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.017295,
        "recall": 0.035156,
        "f1": 0.020019,
        "accuracy": 0.035156,
        "main_score": 0.020019,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.042467,
        "recall": 0.068359,
        "f1": 0.047254,
        "accuracy": 0.068359,
        "main_score": 0.047254,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.029074,
        "recall": 0.058594,
        "f1": 0.034852,
        "accuracy": 0.058594,
        "main_score": 0.034852,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.04154,
        "recall": 0.06543,
        "f1": 0.046282,
        "accuracy": 0.06543,
        "main_score": 0.046282,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.055268,
        "recall": 0.084961,
        "f1": 0.061135,
        "accuracy": 0.084961,
        "main_score": 0.061135,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.010697,
        "recall": 0.022461,
        "f1": 0.012097,
        "accuracy": 0.022461,
        "main_score": 0.012097,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.021598,
        "recall": 0.043945,
        "f1": 0.025609,
        "accuracy": 0.043945,
        "main_score": 0.025609,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.013051,
        "recall": 0.03418,
        "f1": 0.016255,
        "accuracy": 0.03418,
        "main_score": 0.016255,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.016126,
        "recall": 0.033203,
        "f1": 0.018872,
        "accuracy": 0.033203,
        "main_score": 0.018872,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.022973,
        "recall": 0.045898,
        "f1": 0.026766,
        "accuracy": 0.045898,
        "main_score": 0.026766,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.00104,
        "recall": 0.005859,
        "f1": 0.001101,
        "accuracy": 0.005859,
        "main_score": 0.001101,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.066268,
        "recall": 0.097656,
        "f1": 0.072978,
        "accuracy": 0.097656,
        "main_score": 0.072978,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.119759,
        "recall": 0.163086,
        "f1": 0.131059,
        "accuracy": 0.163086,
        "main_score": 0.131059,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.026474,
        "recall": 0.050781,
        "f1": 0.031214,
        "accuracy": 0.050781,
        "main_score": 0.031214,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.054177,
        "recall": 0.094727,
        "f1": 0.063082,
        "accuracy": 0.094727,
        "main_score": 0.063082,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.001964,
        "recall": 0.003906,
        "f1": 0.001975,
        "accuracy": 0.003906,
        "main_score": 0.001975,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026693,
        "recall": 0.044922,
        "f1": 0.030465,
        "accuracy": 0.044922,
        "main_score": 0.030465,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.034976,
        "recall": 0.066406,
        "f1": 0.041402,
        "accuracy": 0.066406,
        "main_score": 0.041402,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.036149,
        "recall": 0.068359,
        "f1": 0.04279,
        "accuracy": 0.068359,
        "main_score": 0.04279,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.037205,
        "recall": 0.053711,
        "f1": 0.040218,
        "accuracy": 0.053711,
        "main_score": 0.040218,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004048,
        "recall": 0.016602,
        "f1": 0.004923,
        "accuracy": 0.016602,
        "main_score": 0.004923,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.082579,
        "recall": 0.115234,
        "f1": 0.091298,
        "accuracy": 0.115234,
        "main_score": 0.091298,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.01398,
        "recall": 0.022461,
        "f1": 0.015702,
        "accuracy": 0.022461,
        "main_score": 0.015702,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.039611,
        "recall": 0.057617,
        "f1": 0.043094,
        "accuracy": 0.057617,
        "main_score": 0.043094,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.052348,
        "recall": 0.086914,
        "f1": 0.060701,
        "accuracy": 0.086914,
        "main_score": 0.060701,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.062658,
        "recall": 0.09082,
        "f1": 0.069152,
        "accuracy": 0.09082,
        "main_score": 0.069152,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.055373,
        "recall": 0.079102,
        "f1": 0.060231,
        "accuracy": 0.079102,
        "main_score": 0.060231,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.018603,
        "recall": 0.041992,
        "f1": 0.0227,
        "accuracy": 0.041992,
        "main_score": 0.0227,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.022786,
        "recall": 0.03418,
        "f1": 0.024727,
        "accuracy": 0.03418,
        "main_score": 0.024727,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ]
      },
      {
        "precision": 0.028806,
        "recall": 0.054688,
        "f1": 0.034232,
        "accuracy": 0.054688,
        "main_score": 0.034232,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.018137,
        "recall": 0.032227,
        "f1": 0.021086,
        "accuracy": 0.032227,
        "main_score": 0.021086,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.021386,
        "recall": 0.041016,
        "f1": 0.024254,
        "accuracy": 0.041016,
        "main_score": 0.024254,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001992,
        "recall": 0.005859,
        "f1": 0.002031,
        "accuracy": 0.005859,
        "main_score": 0.002031,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.075726,
        "recall": 0.104492,
        "f1": 0.082961,
        "accuracy": 0.104492,
        "main_score": 0.082961,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.055461,
        "recall": 0.084961,
        "f1": 0.062621,
        "accuracy": 0.084961,
        "main_score": 0.062621,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.30429,
        "recall": 0.34375,
        "f1": 0.315235,
        "accuracy": 0.34375,
        "main_score": 0.315235,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.338873,
        "recall": 0.383789,
        "f1": 0.350748,
        "accuracy": 0.383789,
        "main_score": 0.350748,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.099528,
        "recall": 0.121094,
        "f1": 0.104385,
        "accuracy": 0.121094,
        "main_score": 0.104385,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.274239,
        "recall": 0.306641,
        "f1": 0.282178,
        "accuracy": 0.306641,
        "main_score": 0.282178,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.078936,
        "recall": 0.130859,
        "f1": 0.090709,
        "accuracy": 0.130859,
        "main_score": 0.090709,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.379397,
        "recall": 0.424805,
        "f1": 0.39187,
        "accuracy": 0.424805,
        "main_score": 0.39187,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.045797,
        "recall": 0.071289,
        "f1": 0.05064,
        "accuracy": 0.071289,
        "main_score": 0.05064,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.141586,
        "recall": 0.170898,
        "f1": 0.147604,
        "accuracy": 0.170898,
        "main_score": 0.147604,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.074858,
        "recall": 0.104492,
        "f1": 0.082201,
        "accuracy": 0.104492,
        "main_score": 0.082201,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.145608,
        "recall": 0.18457,
        "f1": 0.155778,
        "accuracy": 0.18457,
        "main_score": 0.155778,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.043736,
        "recall": 0.069336,
        "f1": 0.049225,
        "accuracy": 0.069336,
        "main_score": 0.049225,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.076694,
        "recall": 0.108398,
        "f1": 0.08478,
        "accuracy": 0.108398,
        "main_score": 0.08478,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.047513,
        "recall": 0.071289,
        "f1": 0.053333,
        "accuracy": 0.071289,
        "main_score": 0.053333,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.079548,
        "recall": 0.112305,
        "f1": 0.087631,
        "accuracy": 0.112305,
        "main_score": 0.087631,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.275336,
        "recall": 0.30957,
        "f1": 0.283326,
        "accuracy": 0.30957,
        "main_score": 0.283326,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.023299,
        "recall": 0.039062,
        "f1": 0.025649,
        "accuracy": 0.039062,
        "main_score": 0.025649,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ]
      },
      {
        "precision": 0.046513,
        "recall": 0.073242,
        "f1": 0.05281,
        "accuracy": 0.073242,
        "main_score": 0.05281,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.163138,
        "recall": 0.207031,
        "f1": 0.174346,
        "accuracy": 0.207031,
        "main_score": 0.174346,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.211181,
        "recall": 0.25,
        "f1": 0.220772,
        "accuracy": 0.25,
        "main_score": 0.220772,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.118952,
        "recall": 0.140625,
        "f1": 0.123121,
        "accuracy": 0.140625,
        "main_score": 0.123121,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.037457,
        "recall": 0.060547,
        "f1": 0.042186,
        "accuracy": 0.060547,
        "main_score": 0.042186,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.045178,
        "recall": 0.074219,
        "f1": 0.050623,
        "accuracy": 0.074219,
        "main_score": 0.050623,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.200398,
        "recall": 0.232422,
        "f1": 0.2079,
        "accuracy": 0.232422,
        "main_score": 0.2079,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.186298,
        "recall": 0.212891,
        "f1": 0.19309,
        "accuracy": 0.212891,
        "main_score": 0.19309,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.072925,
        "recall": 0.09668,
        "f1": 0.07869,
        "accuracy": 0.09668,
        "main_score": 0.07869,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.203577,
        "recall": 0.25,
        "f1": 0.215341,
        "accuracy": 0.25,
        "main_score": 0.215341,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.059186,
        "recall": 0.104492,
        "f1": 0.069612,
        "accuracy": 0.104492,
        "main_score": 0.069612,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.173384,
        "recall": 0.205078,
        "f1": 0.180766,
        "accuracy": 0.205078,
        "main_score": 0.180766,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.074008,
        "recall": 0.115234,
        "f1": 0.083347,
        "accuracy": 0.115234,
        "main_score": 0.083347,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.105861,
        "recall": 0.131836,
        "f1": 0.110612,
        "accuracy": 0.131836,
        "main_score": 0.110612,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.038133,
        "recall": 0.066406,
        "f1": 0.04365,
        "accuracy": 0.066406,
        "main_score": 0.04365,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.18653,
        "recall": 0.224609,
        "f1": 0.197173,
        "accuracy": 0.224609,
        "main_score": 0.197173,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.053001,
        "recall": 0.083008,
        "f1": 0.06042,
        "accuracy": 0.083008,
        "main_score": 0.06042,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.031918,
        "recall": 0.050781,
        "f1": 0.036118,
        "accuracy": 0.050781,
        "main_score": 0.036118,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.05509,
        "recall": 0.083008,
        "f1": 0.060645,
        "accuracy": 0.083008,
        "main_score": 0.060645,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.040721,
        "recall": 0.063477,
        "f1": 0.044681,
        "accuracy": 0.063477,
        "main_score": 0.044681,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.182022,
        "recall": 0.205078,
        "f1": 0.187535,
        "accuracy": 0.205078,
        "main_score": 0.187535,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.019465,
        "recall": 0.041016,
        "f1": 0.02297,
        "accuracy": 0.041016,
        "main_score": 0.02297,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ]
      },
      {
        "precision": 0.025204,
        "recall": 0.048828,
        "f1": 0.029001,
        "accuracy": 0.048828,
        "main_score": 0.029001,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.180982,
        "recall": 0.206055,
        "f1": 0.187231,
        "accuracy": 0.206055,
        "main_score": 0.187231,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.238951,
        "recall": 0.28125,
        "f1": 0.250522,
        "accuracy": 0.28125,
        "main_score": 0.250522,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.085298,
        "recall": 0.105469,
        "f1": 0.089468,
        "accuracy": 0.105469,
        "main_score": 0.089468,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.0438,
        "recall": 0.069336,
        "f1": 0.049001,
        "accuracy": 0.069336,
        "main_score": 0.049001,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.041466,
        "recall": 0.071289,
        "f1": 0.047853,
        "accuracy": 0.071289,
        "main_score": 0.047853,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.239074,
        "recall": 0.274414,
        "f1": 0.248395,
        "accuracy": 0.274414,
        "main_score": 0.248395,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.225515,
        "recall": 0.259766,
        "f1": 0.234775,
        "accuracy": 0.259766,
        "main_score": 0.234775,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.093016,
        "recall": 0.121094,
        "f1": 0.099601,
        "accuracy": 0.121094,
        "main_score": 0.099601,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.261158,
        "recall": 0.301758,
        "f1": 0.272287,
        "accuracy": 0.301758,
        "main_score": 0.272287,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.0693,
        "recall": 0.126953,
        "f1": 0.081672,
        "accuracy": 0.126953,
        "main_score": 0.081672,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.220008,
        "recall": 0.25293,
        "f1": 0.228452,
        "accuracy": 0.25293,
        "main_score": 0.228452,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.084459,
        "recall": 0.125977,
        "f1": 0.095034,
        "accuracy": 0.125977,
        "main_score": 0.095034,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.119682,
        "recall": 0.149414,
        "f1": 0.125174,
        "accuracy": 0.149414,
        "main_score": 0.125174,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.047253,
        "recall": 0.074219,
        "f1": 0.052682,
        "accuracy": 0.074219,
        "main_score": 0.052682,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.180205,
        "recall": 0.222656,
        "f1": 0.191364,
        "accuracy": 0.222656,
        "main_score": 0.191364,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.066778,
        "recall": 0.095703,
        "f1": 0.07377,
        "accuracy": 0.095703,
        "main_score": 0.07377,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.052138,
        "recall": 0.073242,
        "f1": 0.056375,
        "accuracy": 0.073242,
        "main_score": 0.056375,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.059072,
        "recall": 0.088867,
        "f1": 0.065732,
        "accuracy": 0.088867,
        "main_score": 0.065732,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.054742,
        "recall": 0.085938,
        "f1": 0.061202,
        "accuracy": 0.085938,
        "main_score": 0.061202,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.210428,
        "recall": 0.238281,
        "f1": 0.217988,
        "accuracy": 0.238281,
        "main_score": 0.217988,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.023369,
        "recall": 0.047852,
        "f1": 0.027767,
        "accuracy": 0.047852,
        "main_score": 0.027767,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ]
      },
      {
        "precision": 0.033154,
        "recall": 0.060547,
        "f1": 0.038248,
        "accuracy": 0.060547,
        "main_score": 0.038248,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.218375,
        "recall": 0.25293,
        "f1": 0.226582,
        "accuracy": 0.25293,
        "main_score": 0.226582,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.234995,
        "recall": 0.28418,
        "f1": 0.248858,
        "accuracy": 0.28418,
        "main_score": 0.248858,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.108055,
        "recall": 0.132812,
        "f1": 0.113412,
        "accuracy": 0.132812,
        "main_score": 0.113412,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.007695,
        "recall": 0.013672,
        "f1": 0.008638,
        "accuracy": 0.013672,
        "main_score": 0.008638,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.00575,
        "recall": 0.012695,
        "f1": 0.006672,
        "accuracy": 0.012695,
        "main_score": 0.006672,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.194313,
        "recall": 0.22168,
        "f1": 0.201254,
        "accuracy": 0.22168,
        "main_score": 0.201254,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.207218,
        "recall": 0.237305,
        "f1": 0.214318,
        "accuracy": 0.237305,
        "main_score": 0.214318,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.147303,
        "recall": 0.181641,
        "f1": 0.154376,
        "accuracy": 0.181641,
        "main_score": 0.154376,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.191981,
        "recall": 0.211914,
        "f1": 0.197242,
        "accuracy": 0.211914,
        "main_score": 0.197242,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.018361,
        "recall": 0.044922,
        "f1": 0.023401,
        "accuracy": 0.044922,
        "main_score": 0.023401,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.196768,
        "recall": 0.227539,
        "f1": 0.203689,
        "accuracy": 0.227539,
        "main_score": 0.203689,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.008166,
        "recall": 0.016602,
        "f1": 0.009362,
        "accuracy": 0.016602,
        "main_score": 0.009362,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.319556,
        "recall": 0.371094,
        "f1": 0.33251,
        "accuracy": 0.371094,
        "main_score": 0.33251,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.00719,
        "recall": 0.016602,
        "f1": 0.008444,
        "accuracy": 0.016602,
        "main_score": 0.008444,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.115408,
        "recall": 0.149414,
        "f1": 0.123815,
        "accuracy": 0.149414,
        "main_score": 0.123815,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.007268,
        "recall": 0.015625,
        "f1": 0.008121,
        "accuracy": 0.015625,
        "main_score": 0.008121,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.008946,
        "recall": 0.020508,
        "f1": 0.010507,
        "accuracy": 0.020508,
        "main_score": 0.010507,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.010241,
        "recall": 0.022461,
        "f1": 0.011642,
        "accuracy": 0.022461,
        "main_score": 0.011642,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.006084,
        "recall": 0.016602,
        "f1": 0.00752,
        "accuracy": 0.016602,
        "main_score": 0.00752,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.196026,
        "recall": 0.226562,
        "f1": 0.202998,
        "accuracy": 0.226562,
        "main_score": 0.202998,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.005554,
        "recall": 0.013672,
        "f1": 0.006749,
        "accuracy": 0.013672,
        "main_score": 0.006749,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.004884,
        "recall": 0.014648,
        "f1": 0.005952,
        "accuracy": 0.014648,
        "main_score": 0.005952,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.202751,
        "recall": 0.229492,
        "f1": 0.209347,
        "accuracy": 0.229492,
        "main_score": 0.209347,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.117686,
        "recall": 0.148438,
        "f1": 0.125667,
        "accuracy": 0.148438,
        "main_score": 0.125667,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.144345,
        "recall": 0.174805,
        "f1": 0.152076,
        "accuracy": 0.174805,
        "main_score": 0.152076,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      }
    ]
  },
  "evaluation_time": 15.866444826126099,
  "kg_co2_emissions": 0.0007783736357942576
}