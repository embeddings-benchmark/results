{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "task_name": "EmotionClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.20265,
        "f1": 0.185514,
        "f1_weighted": 0.218788,
        "scores_per_experiment": [
          {
            "accuracy": 0.2075,
            "f1": 0.181686,
            "f1_weighted": 0.229211
          },
          {
            "accuracy": 0.211,
            "f1": 0.196571,
            "f1_weighted": 0.227633
          },
          {
            "accuracy": 0.192,
            "f1": 0.172144,
            "f1_weighted": 0.208056
          },
          {
            "accuracy": 0.202,
            "f1": 0.185501,
            "f1_weighted": 0.219431
          },
          {
            "accuracy": 0.2145,
            "f1": 0.194937,
            "f1_weighted": 0.233191
          },
          {
            "accuracy": 0.191,
            "f1": 0.181076,
            "f1_weighted": 0.20449
          },
          {
            "accuracy": 0.22,
            "f1": 0.192894,
            "f1_weighted": 0.238151
          },
          {
            "accuracy": 0.1855,
            "f1": 0.170337,
            "f1_weighted": 0.200324
          },
          {
            "accuracy": 0.22,
            "f1": 0.204741,
            "f1_weighted": 0.232166
          },
          {
            "accuracy": 0.183,
            "f1": 0.17525,
            "f1_weighted": 0.195229
          }
        ],
        "main_score": 0.20265,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.19655,
        "f1": 0.176764,
        "f1_weighted": 0.215098,
        "scores_per_experiment": [
          {
            "accuracy": 0.183,
            "f1": 0.162588,
            "f1_weighted": 0.201735
          },
          {
            "accuracy": 0.198,
            "f1": 0.180357,
            "f1_weighted": 0.214758
          },
          {
            "accuracy": 0.1915,
            "f1": 0.169973,
            "f1_weighted": 0.208593
          },
          {
            "accuracy": 0.1955,
            "f1": 0.176448,
            "f1_weighted": 0.217191
          },
          {
            "accuracy": 0.213,
            "f1": 0.192324,
            "f1_weighted": 0.233006
          },
          {
            "accuracy": 0.18,
            "f1": 0.170804,
            "f1_weighted": 0.194982
          },
          {
            "accuracy": 0.2055,
            "f1": 0.177123,
            "f1_weighted": 0.22696
          },
          {
            "accuracy": 0.206,
            "f1": 0.184563,
            "f1_weighted": 0.224876
          },
          {
            "accuracy": 0.2085,
            "f1": 0.184007,
            "f1_weighted": 0.226974
          },
          {
            "accuracy": 0.1845,
            "f1": 0.169449,
            "f1_weighted": 0.201905
          }
        ],
        "main_score": 0.19655,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 17.292434453964233,
  "kg_co2_emissions": 0.0005985425961579957
}