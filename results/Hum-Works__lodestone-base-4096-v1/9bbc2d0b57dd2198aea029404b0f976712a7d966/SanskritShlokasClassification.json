{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.45718,
        "f1": 0.440303,
        "f1_weighted": 0.438166,
        "scores_per_experiment": [
          {
            "accuracy": 0.509138,
            "f1": 0.519901,
            "f1_weighted": 0.519453
          },
          {
            "accuracy": 0.467363,
            "f1": 0.448114,
            "f1_weighted": 0.444537
          },
          {
            "accuracy": 0.451697,
            "f1": 0.416805,
            "f1_weighted": 0.42106
          },
          {
            "accuracy": 0.48564,
            "f1": 0.450753,
            "f1_weighted": 0.442011
          },
          {
            "accuracy": 0.449086,
            "f1": 0.437268,
            "f1_weighted": 0.433867
          },
          {
            "accuracy": 0.456919,
            "f1": 0.439821,
            "f1_weighted": 0.443925
          },
          {
            "accuracy": 0.449086,
            "f1": 0.428664,
            "f1_weighted": 0.422471
          },
          {
            "accuracy": 0.368146,
            "f1": 0.354444,
            "f1_weighted": 0.35582
          },
          {
            "accuracy": 0.443864,
            "f1": 0.413748,
            "f1_weighted": 0.407673
          },
          {
            "accuracy": 0.490862,
            "f1": 0.493507,
            "f1_weighted": 0.490839
          }
        ],
        "main_score": 0.45718,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.442708,
        "f1": 0.432879,
        "f1_weighted": 0.428084,
        "scores_per_experiment": [
          {
            "accuracy": 0.510417,
            "f1": 0.527136,
            "f1_weighted": 0.523198
          },
          {
            "accuracy": 0.458333,
            "f1": 0.448611,
            "f1_weighted": 0.437402
          },
          {
            "accuracy": 0.40625,
            "f1": 0.357374,
            "f1_weighted": 0.367273
          },
          {
            "accuracy": 0.447917,
            "f1": 0.43494,
            "f1_weighted": 0.415247
          },
          {
            "accuracy": 0.4375,
            "f1": 0.429952,
            "f1_weighted": 0.420139
          },
          {
            "accuracy": 0.479167,
            "f1": 0.464234,
            "f1_weighted": 0.46781
          },
          {
            "accuracy": 0.447917,
            "f1": 0.451636,
            "f1_weighted": 0.442954
          },
          {
            "accuracy": 0.354167,
            "f1": 0.333687,
            "f1_weighted": 0.343976
          },
          {
            "accuracy": 0.4375,
            "f1": 0.425836,
            "f1_weighted": 0.414129
          },
          {
            "accuracy": 0.447917,
            "f1": 0.455383,
            "f1_weighted": 0.448713
          }
        ],
        "main_score": 0.442708,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 12.942509174346924,
  "kg_co2_emissions": 0.000387524492374798
}