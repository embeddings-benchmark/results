{
    "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
    "task_name": "NTREXBitextMining",
    "evaluation_time": null,
    "mteb_version": null,
    "scores": {
        "test": [
            {
                "hf_subset": "arb_Arab-hun_Latn",
                "languages": [
                    "arb-Arab",
                    "hun-Latn"
                ],
                "accuracy": 0.8607911867801703,
                "f1": 0.8234184610248707,
                "main_score": 0.8234184610248707,
                "precision": 0.8065598397596395,
                "recall": 0.8607911867801703
            },
            {
                "hf_subset": "ben_Beng-hun_Latn",
                "languages": [
                    "ben-Beng",
                    "hun-Latn"
                ],
                "accuracy": 0.40911367050575864,
                "f1": 0.36011757289563834,
                "main_score": 0.36011757289563834,
                "precision": 0.34369164343399783,
                "recall": 0.40911367050575864
            },
            {
                "hf_subset": "deu_Latn-hun_Latn",
                "languages": [
                    "deu-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9354031046569855,
                "f1": 0.9173760640961443,
                "main_score": 0.9173760640961443,
                "precision": 0.9087130696044067,
                "recall": 0.9354031046569855
            },
            {
                "hf_subset": "ell_Grek-hun_Latn",
                "languages": [
                    "ell-Grek",
                    "hun-Latn"
                ],
                "accuracy": 0.913870806209314,
                "f1": 0.8887998664663662,
                "main_score": 0.8887998664663662,
                "precision": 0.8769821398764814,
                "recall": 0.913870806209314
            },
            {
                "hf_subset": "eng_Latn-hun_Latn",
                "languages": [
                    "eng-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9469203805708563,
                "f1": 0.9304790519112001,
                "main_score": 0.9304790519112001,
                "precision": 0.9224670338841595,
                "recall": 0.9469203805708563
            },
            {
                "hf_subset": "fas_Arab-hun_Latn",
                "languages": [
                    "fas-Arab",
                    "hun-Latn"
                ],
                "accuracy": 0.8943415122684027,
                "f1": 0.8648138874979135,
                "main_score": 0.8648138874979135,
                "precision": 0.851235186112502,
                "recall": 0.8943415122684027
            },
            {
                "hf_subset": "fin_Latn-hun_Latn",
                "languages": [
                    "fin-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9073610415623434,
                "f1": 0.8810716074111167,
                "main_score": 0.8810716074111167,
                "precision": 0.8684860624269739,
                "recall": 0.9073610415623434
            },
            {
                "hf_subset": "fra_Latn-hun_Latn",
                "languages": [
                    "fra-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9303955933900852,
                "f1": 0.9097312635620098,
                "main_score": 0.9097312635620098,
                "precision": 0.8997245868803205,
                "recall": 0.9303955933900852
            },
            {
                "hf_subset": "heb_Hebr-hun_Latn",
                "languages": [
                    "heb-Hebr",
                    "hun-Latn"
                ],
                "accuracy": 0.8803204807210815,
                "f1": 0.8471540644299783,
                "main_score": 0.8471540644299783,
                "precision": 0.8314972458688032,
                "recall": 0.8803204807210815
            },
            {
                "hf_subset": "hin_Deva-hun_Latn",
                "languages": [
                    "hin-Deva",
                    "hun-Latn"
                ],
                "accuracy": 0.869804707060591,
                "f1": 0.8351527290936405,
                "main_score": 0.8351527290936405,
                "precision": 0.8192038057085628,
                "recall": 0.869804707060591
            },
            {
                "hf_subset": "hun_Latn-arb_Arab",
                "languages": [
                    "hun-Latn",
                    "arb-Arab"
                ],
                "accuracy": 0.8647971957936904,
                "f1": 0.8283592054748788,
                "main_score": 0.8283592054748788,
                "precision": 0.8118260724419963,
                "recall": 0.8647971957936904
            },
            {
                "hf_subset": "hun_Latn-ben_Beng",
                "languages": [
                    "hun-Latn",
                    "ben-Beng"
                ],
                "accuracy": 0.4186279419128693,
                "f1": 0.33232896964494363,
                "main_score": 0.33232896964494363,
                "precision": 0.30249043850094404,
                "recall": 0.4186279419128693
            },
            {
                "hf_subset": "hun_Latn-deu_Latn",
                "languages": [
                    "hun-Latn",
                    "deu-Latn"
                ],
                "accuracy": 0.9394091136705057,
                "f1": 0.9214989150392254,
                "main_score": 0.9214989150392254,
                "precision": 0.9128275746953765,
                "recall": 0.9394091136705057
            },
            {
                "hf_subset": "hun_Latn-ell_Grek",
                "languages": [
                    "hun-Latn",
                    "ell-Grek"
                ],
                "accuracy": 0.928392588883325,
                "f1": 0.9086296110832915,
                "main_score": 0.9086296110832915,
                "precision": 0.8993072942747456,
                "recall": 0.928392588883325
            },
            {
                "hf_subset": "hun_Latn-eng_Latn",
                "languages": [
                    "hun-Latn",
                    "eng-Latn"
                ],
                "accuracy": 0.9554331497245869,
                "f1": 0.9423301619095309,
                "main_score": 0.9423301619095309,
                "precision": 0.9359873143047905,
                "recall": 0.9554331497245869
            },
            {
                "hf_subset": "hun_Latn-fas_Arab",
                "languages": [
                    "hun-Latn",
                    "fas-Arab"
                ],
                "accuracy": 0.8943415122684027,
                "f1": 0.8654481722583875,
                "main_score": 0.8654481722583875,
                "precision": 0.8520447337673176,
                "recall": 0.8943415122684027
            },
            {
                "hf_subset": "hun_Latn-fin_Latn",
                "languages": [
                    "hun-Latn",
                    "fin-Latn"
                ],
                "accuracy": 0.8958437656484726,
                "f1": 0.8670839592722417,
                "main_score": 0.8670839592722417,
                "precision": 0.8537389417459522,
                "recall": 0.8958437656484726
            },
            {
                "hf_subset": "hun_Latn-fra_Latn",
                "languages": [
                    "hun-Latn",
                    "fra-Latn"
                ],
                "accuracy": 0.9213820731096645,
                "f1": 0.89883158070439,
                "main_score": 0.89883158070439,
                "precision": 0.888182273410115,
                "recall": 0.9213820731096645
            },
            {
                "hf_subset": "hun_Latn-heb_Hebr",
                "languages": [
                    "hun-Latn",
                    "heb-Hebr"
                ],
                "accuracy": 0.8693039559339009,
                "f1": 0.8332336166587544,
                "main_score": 0.8332336166587544,
                "precision": 0.8167334334835588,
                "recall": 0.8693039559339009
            },
            {
                "hf_subset": "hun_Latn-hin_Deva",
                "languages": [
                    "hun-Latn",
                    "hin-Deva"
                ],
                "accuracy": 0.8597896845267902,
                "f1": 0.8234685361375397,
                "main_score": 0.8234685361375397,
                "precision": 0.80728592889334,
                "recall": 0.8597896845267902
            },
            {
                "hf_subset": "hun_Latn-ind_Latn",
                "languages": [
                    "hun-Latn",
                    "ind-Latn"
                ],
                "accuracy": 0.9233850776164246,
                "f1": 0.9006843598731432,
                "main_score": 0.9006843598731432,
                "precision": 0.8897512936070773,
                "recall": 0.9233850776164246
            },
            {
                "hf_subset": "hun_Latn-jpn_Jpan",
                "languages": [
                    "hun-Latn",
                    "jpn-Jpan"
                ],
                "accuracy": 0.8748122183274912,
                "f1": 0.8408779836421298,
                "main_score": 0.8408779836421298,
                "precision": 0.8253380070105159,
                "recall": 0.8748122183274912
            },
            {
                "hf_subset": "hun_Latn-kor_Hang",
                "languages": [
                    "hun-Latn",
                    "kor-Hang"
                ],
                "accuracy": 0.8482724086129194,
                "f1": 0.8077859213062016,
                "main_score": 0.8077859213062016,
                "precision": 0.7898931730929726,
                "recall": 0.8482724086129194
            },
            {
                "hf_subset": "hun_Latn-lav_Latn",
                "languages": [
                    "hun-Latn",
                    "lav-Latn"
                ],
                "accuracy": 0.899849774661993,
                "f1": 0.870422300116842,
                "main_score": 0.870422300116842,
                "precision": 0.8565932231680855,
                "recall": 0.899849774661993
            },
            {
                "hf_subset": "hun_Latn-lit_Latn",
                "languages": [
                    "hun-Latn",
                    "lit-Latn"
                ],
                "accuracy": 0.9038557836755132,
                "f1": 0.8760474044399933,
                "main_score": 0.8760474044399933,
                "precision": 0.8628776498080455,
                "recall": 0.9038557836755132
            },
            {
                "hf_subset": "hun_Latn-nld_Latn",
                "languages": [
                    "hun-Latn",
                    "nld-Latn"
                ],
                "accuracy": 0.9364046069103655,
                "f1": 0.9181271907861792,
                "main_score": 0.9181271907861792,
                "precision": 0.9093807377733266,
                "recall": 0.9364046069103655
            },
            {
                "hf_subset": "hun_Latn-pol_Latn",
                "languages": [
                    "hun-Latn",
                    "pol-Latn"
                ],
                "accuracy": 0.912368552829244,
                "f1": 0.8885924124281661,
                "main_score": 0.8885924124281661,
                "precision": 0.877524620263729,
                "recall": 0.912368552829244
            },
            {
                "hf_subset": "hun_Latn-por_Latn",
                "languages": [
                    "hun-Latn",
                    "por-Latn"
                ],
                "accuracy": 0.9318978467701552,
                "f1": 0.9115172759138709,
                "main_score": 0.9115172759138709,
                "precision": 0.9019362376898683,
                "recall": 0.9318978467701552
            },
            {
                "hf_subset": "hun_Latn-rus_Cyrl",
                "languages": [
                    "hun-Latn",
                    "rus-Cyrl"
                ],
                "accuracy": 0.9223835753630446,
                "f1": 0.8993824069437489,
                "main_score": 0.8993824069437489,
                "precision": 0.8885411450509096,
                "recall": 0.9223835753630446
            },
            {
                "hf_subset": "hun_Latn-spa_Latn",
                "languages": [
                    "hun-Latn",
                    "spa-Latn"
                ],
                "accuracy": 0.9334001001502252,
                "f1": 0.9147888499415793,
                "main_score": 0.9147888499415793,
                "precision": 0.9058587881822734,
                "recall": 0.9334001001502252
            },
            {
                "hf_subset": "hun_Latn-swa_Latn",
                "languages": [
                    "hun-Latn",
                    "swa-Latn"
                ],
                "accuracy": 0.4076114171256886,
                "f1": 0.32341475401874825,
                "main_score": 0.32341475401874825,
                "precision": 0.29515621549076143,
                "recall": 0.4076114171256886
            },
            {
                "hf_subset": "hun_Latn-swe_Latn",
                "languages": [
                    "hun-Latn",
                    "swe-Latn"
                ],
                "accuracy": 0.9344016024036054,
                "f1": 0.91490569187114,
                "main_score": 0.91490569187114,
                "precision": 0.9056501418794859,
                "recall": 0.9344016024036054
            },
            {
                "hf_subset": "hun_Latn-tam_Taml",
                "languages": [
                    "hun-Latn",
                    "tam-Taml"
                ],
                "accuracy": 0.2759138708062093,
                "f1": 0.18875023187991868,
                "main_score": 0.18875023187991868,
                "precision": 0.1643982939607956,
                "recall": 0.2759138708062093
            },
            {
                "hf_subset": "hun_Latn-tur_Latn",
                "languages": [
                    "hun-Latn",
                    "tur-Latn"
                ],
                "accuracy": 0.913870806209314,
                "f1": 0.8890836254381572,
                "main_score": 0.8890836254381572,
                "precision": 0.8772325154398266,
                "recall": 0.913870806209314
            },
            {
                "hf_subset": "hun_Latn-vie_Latn",
                "languages": [
                    "hun-Latn",
                    "vie-Latn"
                ],
                "accuracy": 0.9113670505758636,
                "f1": 0.8862054987242769,
                "main_score": 0.8862054987242769,
                "precision": 0.8741445501585712,
                "recall": 0.9113670505758636
            },
            {
                "hf_subset": "hun_Latn-zho_Hant",
                "languages": [
                    "hun-Latn",
                    "zho-Hant"
                ],
                "accuracy": 0.9033550325488232,
                "f1": 0.8771574027708229,
                "main_score": 0.8771574027708229,
                "precision": 0.8653861744998451,
                "recall": 0.9033550325488232
            },
            {
                "hf_subset": "hun_Latn-zul_Latn",
                "languages": [
                    "hun-Latn",
                    "zul-Latn"
                ],
                "accuracy": 0.17626439659489235,
                "f1": 0.11826546194507252,
                "main_score": 0.11826546194507252,
                "precision": 0.10340822386979896,
                "recall": 0.17626439659489235
            },
            {
                "hf_subset": "ind_Latn-hun_Latn",
                "languages": [
                    "ind-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9293940911367051,
                "f1": 0.9091470539142046,
                "main_score": 0.9091470539142046,
                "precision": 0.8996411283592054,
                "recall": 0.9293940911367051
            },
            {
                "hf_subset": "jpn_Jpan-hun_Latn",
                "languages": [
                    "jpn-Jpan",
                    "hun-Latn"
                ],
                "accuracy": 0.8833249874812218,
                "f1": 0.8507260891337006,
                "main_score": 0.8507260891337006,
                "precision": 0.8354114505090969,
                "recall": 0.8833249874812218
            },
            {
                "hf_subset": "kor_Hang-hun_Latn",
                "languages": [
                    "kor-Hang",
                    "hun-Latn"
                ],
                "accuracy": 0.8607911867801703,
                "f1": 0.8232348522784175,
                "main_score": 0.8232348522784175,
                "precision": 0.8059339008512768,
                "recall": 0.8607911867801703
            },
            {
                "hf_subset": "lav_Latn-hun_Latn",
                "languages": [
                    "lav-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9073610415623434,
                "f1": 0.8825833989078856,
                "main_score": 0.8825833989078856,
                "precision": 0.8709480887998664,
                "recall": 0.9073610415623434
            },
            {
                "hf_subset": "lit_Latn-hun_Latn",
                "languages": [
                    "lit-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9188783174762143,
                "f1": 0.8959105324653646,
                "main_score": 0.8959105324653646,
                "precision": 0.8849106993824069,
                "recall": 0.9188783174762143
            },
            {
                "hf_subset": "nld_Latn-hun_Latn",
                "languages": [
                    "nld-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9298948422633951,
                "f1": 0.9093139709564347,
                "main_score": 0.9093139709564347,
                "precision": 0.8993072942747456,
                "recall": 0.9298948422633951
            },
            {
                "hf_subset": "pol_Latn-hun_Latn",
                "languages": [
                    "pol-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9143715573360041,
                "f1": 0.8910699382406944,
                "main_score": 0.8910699382406944,
                "precision": 0.8800701051577365,
                "recall": 0.9143715573360041
            },
            {
                "hf_subset": "por_Latn-hun_Latn",
                "languages": [
                    "por-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9298948422633951,
                "f1": 0.9102320146886997,
                "main_score": 0.9102320146886997,
                "precision": 0.9009764646970456,
                "recall": 0.9298948422633951
            },
            {
                "hf_subset": "rus_Cyrl-hun_Latn",
                "languages": [
                    "rus-Cyrl",
                    "hun-Latn"
                ],
                "accuracy": 0.9098647971957938,
                "f1": 0.883942580537473,
                "main_score": 0.883942580537473,
                "precision": 0.8716992154899015,
                "recall": 0.9098647971957938
            },
            {
                "hf_subset": "spa_Latn-hun_Latn",
                "languages": [
                    "spa-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9313970956434652,
                "f1": 0.9119846436321148,
                "main_score": 0.9119846436321148,
                "precision": 0.9026456351193457,
                "recall": 0.9313970956434652
            },
            {
                "hf_subset": "swa_Latn-hun_Latn",
                "languages": [
                    "swa-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.3905858788182273,
                "f1": 0.33983231699084565,
                "main_score": 0.33983231699084565,
                "precision": 0.32413764251869975,
                "recall": 0.3905858788182273
            },
            {
                "hf_subset": "swe_Latn-hun_Latn",
                "languages": [
                    "swe-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9303955933900852,
                "f1": 0.9101485561675847,
                "main_score": 0.9101485561675847,
                "precision": 0.9004757135703555,
                "recall": 0.9303955933900852
            },
            {
                "hf_subset": "tam_Taml-hun_Latn",
                "languages": [
                    "tam-Taml",
                    "hun-Latn"
                ],
                "accuracy": 0.27341011517275915,
                "f1": 0.24114490363365104,
                "main_score": 0.24114490363365104,
                "precision": 0.2301465131730559,
                "recall": 0.27341011517275915
            },
            {
                "hf_subset": "tur_Latn-hun_Latn",
                "languages": [
                    "tur-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9103655483224837,
                "f1": 0.884843932565515,
                "main_score": 0.884843932565515,
                "precision": 0.8731180103488567,
                "recall": 0.9103655483224837
            },
            {
                "hf_subset": "vie_Latn-hun_Latn",
                "languages": [
                    "vie-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.9038557836755132,
                "f1": 0.8773493573693874,
                "main_score": 0.8773493573693874,
                "precision": 0.865005842096478,
                "recall": 0.9038557836755132
            },
            {
                "hf_subset": "zho_Hant-hun_Latn",
                "languages": [
                    "zho-Hant",
                    "hun-Latn"
                ],
                "accuracy": 0.9033550325488232,
                "f1": 0.8759806376231013,
                "main_score": 0.8759806376231013,
                "precision": 0.863253213153063,
                "recall": 0.9033550325488232
            },
            {
                "hf_subset": "zul_Latn-hun_Latn",
                "languages": [
                    "zul-Latn",
                    "hun-Latn"
                ],
                "accuracy": 0.17676514772158236,
                "f1": 0.1390718634725667,
                "main_score": 0.1390718634725667,
                "precision": 0.12923210518264244,
                "recall": 0.17676514772158236
            }
        ]
    }
}