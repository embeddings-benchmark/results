{
  "dataset_revision": "aed6ff7eed647cd6eead02f70efa23a4e67329dc",
  "task_name": "IN22GenBitextMining",
  "mteb_version": "2.3.0",
  "scores": {
    "test": [
      {
        "precision": 0.736035,
        "recall": 0.80957,
        "f1": 0.758645,
        "accuracy": 0.80957,
        "main_score": 0.758645,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.728206,
        "recall": 0.799805,
        "f1": 0.749805,
        "accuracy": 0.799805,
        "main_score": 0.749805,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.059886,
        "recall": 0.119141,
        "f1": 0.071496,
        "accuracy": 0.119141,
        "main_score": 0.071496,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.560679,
        "recall": 0.65918,
        "f1": 0.589483,
        "accuracy": 0.65918,
        "main_score": 0.589483,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.908366,
        "recall": 0.935547,
        "f1": 0.916797,
        "accuracy": 0.935547,
        "main_score": 0.916797,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.527824,
        "recall": 0.619141,
        "f1": 0.553709,
        "accuracy": 0.619141,
        "main_score": 0.553709,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.858805,
        "recall": 0.902344,
        "f1": 0.872786,
        "accuracy": 0.902344,
        "main_score": 0.872786,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.913249,
        "recall": 0.938477,
        "f1": 0.921387,
        "accuracy": 0.938477,
        "main_score": 0.921387,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.823812,
        "recall": 0.87207,
        "f1": 0.839062,
        "accuracy": 0.87207,
        "main_score": 0.839062,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.284663,
        "recall": 0.390625,
        "f1": 0.31198,
        "accuracy": 0.390625,
        "main_score": 0.31198,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.735303,
        "recall": 0.80957,
        "f1": 0.758822,
        "accuracy": 0.80957,
        "main_score": 0.758822,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.825277,
        "recall": 0.874023,
        "f1": 0.84069,
        "accuracy": 0.874023,
        "main_score": 0.84069,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.872673,
        "recall": 0.910156,
        "f1": 0.884342,
        "accuracy": 0.910156,
        "main_score": 0.884342,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 6.6e-05,
        "recall": 0.003906,
        "f1": 0.000128,
        "accuracy": 0.003906,
        "main_score": 0.000128,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.864014,
        "recall": 0.904297,
        "f1": 0.876855,
        "accuracy": 0.904297,
        "main_score": 0.876855,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.709049,
        "recall": 0.789062,
        "f1": 0.733626,
        "accuracy": 0.789062,
        "main_score": 0.733626,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.640519,
        "recall": 0.731445,
        "f1": 0.668088,
        "accuracy": 0.731445,
        "main_score": 0.668088,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.614024,
        "recall": 0.706055,
        "f1": 0.641623,
        "accuracy": 0.706055,
        "main_score": 0.641623,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 0.000183,
        "recall": 0.003906,
        "f1": 0.00034,
        "accuracy": 0.003906,
        "main_score": 0.00034,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.377789,
        "recall": 0.486328,
        "f1": 0.407006,
        "accuracy": 0.486328,
        "main_score": 0.407006,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.809408,
        "recall": 0.864258,
        "f1": 0.826953,
        "accuracy": 0.864258,
        "main_score": 0.826953,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.824788,
        "recall": 0.875977,
        "f1": 0.841374,
        "accuracy": 0.875977,
        "main_score": 0.841374,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.887126,
        "recall": 0.921875,
        "f1": 0.898177,
        "accuracy": 0.921875,
        "main_score": 0.898177,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.07091,
        "recall": 0.102539,
        "f1": 0.077203,
        "accuracy": 0.102539,
        "main_score": 0.077203,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.56531,
        "recall": 0.652344,
        "f1": 0.589592,
        "accuracy": 0.652344,
        "main_score": 0.589592,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.863802,
        "recall": 0.904297,
        "f1": 0.876465,
        "accuracy": 0.904297,
        "main_score": 0.876465,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.538105,
        "recall": 0.624023,
        "f1": 0.562459,
        "accuracy": 0.624023,
        "main_score": 0.562459,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.86027,
        "recall": 0.90332,
        "f1": 0.874251,
        "accuracy": 0.90332,
        "main_score": 0.874251,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.883659,
        "recall": 0.918945,
        "f1": 0.89502,
        "accuracy": 0.918945,
        "main_score": 0.89502,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.804688,
        "recall": 0.862305,
        "f1": 0.823079,
        "accuracy": 0.862305,
        "main_score": 0.823079,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.312127,
        "recall": 0.386719,
        "f1": 0.329918,
        "accuracy": 0.386719,
        "main_score": 0.329918,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.725432,
        "recall": 0.799805,
        "f1": 0.748356,
        "accuracy": 0.799805,
        "main_score": 0.748356,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.805501,
        "recall": 0.861328,
        "f1": 0.823372,
        "accuracy": 0.861328,
        "main_score": 0.823372,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.843506,
        "recall": 0.889648,
        "f1": 0.858464,
        "accuracy": 0.889648,
        "main_score": 0.858464,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.000977,
        "f1": 1.2e-05,
        "accuracy": 0.000977,
        "main_score": 1.2e-05,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.852539,
        "recall": 0.897461,
        "f1": 0.866992,
        "accuracy": 0.897461,
        "main_score": 0.866992,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.709554,
        "recall": 0.78418,
        "f1": 0.732199,
        "accuracy": 0.78418,
        "main_score": 0.732199,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.635686,
        "recall": 0.719727,
        "f1": 0.660726,
        "accuracy": 0.719727,
        "main_score": 0.660726,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.581246,
        "recall": 0.671875,
        "f1": 0.607138,
        "accuracy": 0.671875,
        "main_score": 0.607138,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000982,
        "recall": 0.001953,
        "f1": 0.000987,
        "accuracy": 0.001953,
        "main_score": 0.000987,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.364406,
        "recall": 0.446289,
        "f1": 0.385085,
        "accuracy": 0.446289,
        "main_score": 0.385085,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.779378,
        "recall": 0.842773,
        "f1": 0.799479,
        "accuracy": 0.842773,
        "main_score": 0.799479,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.791188,
        "recall": 0.848633,
        "f1": 0.809163,
        "accuracy": 0.848633,
        "main_score": 0.809163,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.856445,
        "recall": 0.901367,
        "f1": 0.870931,
        "accuracy": 0.901367,
        "main_score": 0.870931,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      }
    ]
  },
  "evaluation_time": 105.85833239555359,
  "kg_co2_emissions": null
}