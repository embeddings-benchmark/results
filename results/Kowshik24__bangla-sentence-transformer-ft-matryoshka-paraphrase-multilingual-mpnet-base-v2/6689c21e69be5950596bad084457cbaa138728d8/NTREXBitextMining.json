{
  "dataset_revision": "66b8b27efc99658903127730575e9fa0cb9f075c",
  "task_name": "NTREXBitextMining",
  "mteb_version": "2.3.0",
  "scores": {
    "test": [
      {
        "precision": 0.710073,
        "recall": 0.789184,
        "f1": 0.734468,
        "accuracy": 0.789184,
        "main_score": 0.734468,
        "hf_subset": "arb_Arab-ben_Beng",
        "languages": [
          "arb-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.771257,
        "recall": 0.83325,
        "f1": 0.790536,
        "accuracy": 0.83325,
        "main_score": 0.790536,
        "hf_subset": "ben_Beng-arb_Arab",
        "languages": [
          "ben-Beng",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.7946,
        "recall": 0.849775,
        "f1": 0.811684,
        "accuracy": 0.849775,
        "main_score": 0.811684,
        "hf_subset": "ben_Beng-deu_Latn",
        "languages": [
          "ben-Beng",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.008514,
        "recall": 0.029044,
        "f1": 0.011052,
        "accuracy": 0.029044,
        "main_score": 0.011052,
        "hf_subset": "ben_Beng-div_Thaa",
        "languages": [
          "ben-Beng",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.854448,
        "recall": 0.898848,
        "f1": 0.86862,
        "accuracy": 0.898848,
        "main_score": 0.86862,
        "hf_subset": "ben_Beng-ell_Grek",
        "languages": [
          "ben-Beng",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.833559,
        "recall": 0.882824,
        "f1": 0.849107,
        "accuracy": 0.882824,
        "main_score": 0.849107,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.323645,
        "recall": 0.431147,
        "f1": 0.350611,
        "accuracy": 0.431147,
        "main_score": 0.350611,
        "hf_subset": "ben_Beng-eus_Latn",
        "languages": [
          "ben-Beng",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.793144,
        "recall": 0.852779,
        "f1": 0.811888,
        "accuracy": 0.852779,
        "main_score": 0.811888,
        "hf_subset": "ben_Beng-fas_Arab",
        "languages": [
          "ben-Beng",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.763245,
        "recall": 0.827241,
        "f1": 0.782726,
        "accuracy": 0.827241,
        "main_score": 0.782726,
        "hf_subset": "ben_Beng-fin_Latn",
        "languages": [
          "ben-Beng",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.78587,
        "recall": 0.84677,
        "f1": 0.8046,
        "accuracy": 0.84677,
        "main_score": 0.8046,
        "hf_subset": "ben_Beng-fra_Latn",
        "languages": [
          "ben-Beng",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.766834,
        "recall": 0.832248,
        "f1": 0.787341,
        "accuracy": 0.832248,
        "main_score": 0.787341,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.805959,
        "recall": 0.861292,
        "f1": 0.823345,
        "accuracy": 0.861292,
        "main_score": 0.823345,
        "hf_subset": "ben_Beng-heb_Hebr",
        "languages": [
          "ben-Beng",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.821891,
        "recall": 0.872308,
        "f1": 0.837857,
        "accuracy": 0.872308,
        "main_score": 0.837857,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.753497,
        "recall": 0.818728,
        "f1": 0.773262,
        "accuracy": 0.818728,
        "main_score": 0.773262,
        "hf_subset": "ben_Beng-hun_Latn",
        "languages": [
          "ben-Beng",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.781597,
        "recall": 0.841262,
        "f1": 0.799943,
        "accuracy": 0.841262,
        "main_score": 0.799943,
        "hf_subset": "ben_Beng-ind_Latn",
        "languages": [
          "ben-Beng",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.797964,
        "recall": 0.853781,
        "f1": 0.815607,
        "accuracy": 0.853781,
        "main_score": 0.815607,
        "hf_subset": "ben_Beng-jpn_Jpan",
        "languages": [
          "ben-Beng",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.712916,
        "recall": 0.787682,
        "f1": 0.735748,
        "accuracy": 0.787682,
        "main_score": 0.735748,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.775902,
        "recall": 0.837256,
        "f1": 0.794894,
        "accuracy": 0.837256,
        "main_score": 0.794894,
        "hf_subset": "ben_Beng-kor_Hang",
        "languages": [
          "ben-Beng",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.758634,
        "recall": 0.826239,
        "f1": 0.779611,
        "accuracy": 0.826239,
        "main_score": 0.779611,
        "hf_subset": "ben_Beng-lit_Latn",
        "languages": [
          "ben-Beng",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.82215,
        "recall": 0.874311,
        "f1": 0.838708,
        "accuracy": 0.874311,
        "main_score": 0.838708,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.783408,
        "recall": 0.841763,
        "f1": 0.801362,
        "accuracy": 0.841763,
        "main_score": 0.801362,
        "hf_subset": "ben_Beng-nep_Deva",
        "languages": [
          "ben-Beng",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.789009,
        "recall": 0.846269,
        "f1": 0.806622,
        "accuracy": 0.846269,
        "main_score": 0.806622,
        "hf_subset": "ben_Beng-nld_Latn",
        "languages": [
          "ben-Beng",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.62213,
        "recall": 0.71357,
        "f1": 0.649262,
        "accuracy": 0.71357,
        "main_score": 0.649262,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.773131,
        "recall": 0.833751,
        "f1": 0.791581,
        "accuracy": 0.833751,
        "main_score": 0.791581,
        "hf_subset": "ben_Beng-pol_Latn",
        "languages": [
          "ben-Beng",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.801135,
        "recall": 0.855784,
        "f1": 0.817762,
        "accuracy": 0.855784,
        "main_score": 0.817762,
        "hf_subset": "ben_Beng-por_Latn",
        "languages": [
          "ben-Beng",
          "por-Latn"
        ]
      },
      {
        "precision": 0.805254,
        "recall": 0.858788,
        "f1": 0.822041,
        "accuracy": 0.858788,
        "main_score": 0.822041,
        "hf_subset": "ben_Beng-rus_Cyrl",
        "languages": [
          "ben-Beng",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.666208,
        "recall": 0.750626,
        "f1": 0.691626,
        "accuracy": 0.750626,
        "main_score": 0.691626,
        "hf_subset": "ben_Beng-sin_Sinh",
        "languages": [
          "ben-Beng",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.482193,
        "recall": 0.591387,
        "f1": 0.513157,
        "accuracy": 0.591387,
        "main_score": 0.513157,
        "hf_subset": "ben_Beng-snd_Arab",
        "languages": [
          "ben-Beng",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.806118,
        "recall": 0.861793,
        "f1": 0.823545,
        "accuracy": 0.861793,
        "main_score": 0.823545,
        "hf_subset": "ben_Beng-spa_Latn",
        "languages": [
          "ben-Beng",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.201799,
        "recall": 0.302454,
        "f1": 0.224537,
        "accuracy": 0.302454,
        "main_score": 0.224537,
        "hf_subset": "ben_Beng-swa_Latn",
        "languages": [
          "ben-Beng",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.784106,
        "recall": 0.844266,
        "f1": 0.802698,
        "accuracy": 0.844266,
        "main_score": 0.802698,
        "hf_subset": "ben_Beng-swe_Latn",
        "languages": [
          "ben-Beng",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.678776,
        "recall": 0.759639,
        "f1": 0.703183,
        "accuracy": 0.759639,
        "main_score": 0.703183,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.692276,
        "recall": 0.77366,
        "f1": 0.71738,
        "accuracy": 0.77366,
        "main_score": 0.71738,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.740574,
        "recall": 0.808713,
        "f1": 0.761396,
        "accuracy": 0.808713,
        "main_score": 0.761396,
        "hf_subset": "ben_Beng-tur_Latn",
        "languages": [
          "ben-Beng",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.810666,
        "recall": 0.864797,
        "f1": 0.827875,
        "accuracy": 0.864797,
        "main_score": 0.827875,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.761252,
        "recall": 0.826239,
        "f1": 0.781297,
        "accuracy": 0.826239,
        "main_score": 0.781297,
        "hf_subset": "ben_Beng-vie_Latn",
        "languages": [
          "ben-Beng",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.766016,
        "recall": 0.829745,
        "f1": 0.786113,
        "accuracy": 0.829745,
        "main_score": 0.786113,
        "hf_subset": "ben_Beng-zho_Hant",
        "languages": [
          "ben-Beng",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.04668,
        "recall": 0.096645,
        "f1": 0.055578,
        "accuracy": 0.096645,
        "main_score": 0.055578,
        "hf_subset": "ben_Beng-zul_Latn",
        "languages": [
          "ben-Beng",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.722055,
        "recall": 0.798698,
        "f1": 0.74541,
        "accuracy": 0.798698,
        "main_score": 0.74541,
        "hf_subset": "deu_Latn-ben_Beng",
        "languages": [
          "deu-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.006696,
        "recall": 0.012519,
        "f1": 0.00749,
        "accuracy": 0.012519,
        "main_score": 0.00749,
        "hf_subset": "div_Thaa-ben_Beng",
        "languages": [
          "div-Thaa",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.795602,
        "recall": 0.854782,
        "f1": 0.813771,
        "accuracy": 0.854782,
        "main_score": 0.813771,
        "hf_subset": "ell_Grek-ben_Beng",
        "languages": [
          "ell-Grek",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.773627,
        "recall": 0.838257,
        "f1": 0.79344,
        "accuracy": 0.838257,
        "main_score": 0.79344,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.384353,
        "recall": 0.478217,
        "f1": 0.410261,
        "accuracy": 0.478217,
        "main_score": 0.410261,
        "hf_subset": "eus_Latn-ben_Beng",
        "languages": [
          "eus-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.739923,
        "recall": 0.810716,
        "f1": 0.761403,
        "accuracy": 0.810716,
        "main_score": 0.761403,
        "hf_subset": "fas_Arab-ben_Beng",
        "languages": [
          "fas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.701048,
        "recall": 0.779169,
        "f1": 0.724471,
        "accuracy": 0.779169,
        "main_score": 0.724471,
        "hf_subset": "fin_Latn-ben_Beng",
        "languages": [
          "fin-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.714647,
        "recall": 0.790686,
        "f1": 0.737699,
        "accuracy": 0.790686,
        "main_score": 0.737699,
        "hf_subset": "fra_Latn-ben_Beng",
        "languages": [
          "fra-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.776248,
        "recall": 0.839259,
        "f1": 0.796128,
        "accuracy": 0.839259,
        "main_score": 0.796128,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.751074,
        "recall": 0.81973,
        "f1": 0.772134,
        "accuracy": 0.81973,
        "main_score": 0.772134,
        "hf_subset": "heb_Hebr-ben_Beng",
        "languages": [
          "heb-Hebr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.802554,
        "recall": 0.857286,
        "f1": 0.819529,
        "accuracy": 0.857286,
        "main_score": 0.819529,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.687231,
        "recall": 0.768152,
        "f1": 0.711186,
        "accuracy": 0.768152,
        "main_score": 0.711186,
        "hf_subset": "hun_Latn-ben_Beng",
        "languages": [
          "hun-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.733692,
        "recall": 0.805208,
        "f1": 0.755104,
        "accuracy": 0.805208,
        "main_score": 0.755104,
        "hf_subset": "ind_Latn-ben_Beng",
        "languages": [
          "ind-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.739634,
        "recall": 0.810215,
        "f1": 0.761158,
        "accuracy": 0.810215,
        "main_score": 0.761158,
        "hf_subset": "jpn_Jpan-ben_Beng",
        "languages": [
          "jpn-Jpan",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.725017,
        "recall": 0.796695,
        "f1": 0.746731,
        "accuracy": 0.796695,
        "main_score": 0.746731,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.740665,
        "recall": 0.810716,
        "f1": 0.761847,
        "accuracy": 0.810716,
        "main_score": 0.761847,
        "hf_subset": "kor_Hang-ben_Beng",
        "languages": [
          "kor-Hang",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.705864,
        "recall": 0.783175,
        "f1": 0.728962,
        "accuracy": 0.783175,
        "main_score": 0.728962,
        "hf_subset": "lit_Latn-ben_Beng",
        "languages": [
          "lit-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.799291,
        "recall": 0.855784,
        "f1": 0.817076,
        "accuracy": 0.855784,
        "main_score": 0.817076,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.782415,
        "recall": 0.841763,
        "f1": 0.800601,
        "accuracy": 0.841763,
        "main_score": 0.800601,
        "hf_subset": "nep_Deva-ben_Beng",
        "languages": [
          "nep-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.730462,
        "recall": 0.804206,
        "f1": 0.752668,
        "accuracy": 0.804206,
        "main_score": 0.752668,
        "hf_subset": "nld_Latn-ben_Beng",
        "languages": [
          "nld-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.646011,
        "recall": 0.7336,
        "f1": 0.672793,
        "accuracy": 0.7336,
        "main_score": 0.672793,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.694284,
        "recall": 0.775163,
        "f1": 0.718688,
        "accuracy": 0.775163,
        "main_score": 0.718688,
        "hf_subset": "pol_Latn-ben_Beng",
        "languages": [
          "pol-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.730558,
        "recall": 0.801703,
        "f1": 0.751805,
        "accuracy": 0.801703,
        "main_score": 0.751805,
        "hf_subset": "por_Latn-ben_Beng",
        "languages": [
          "por-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.743265,
        "recall": 0.815223,
        "f1": 0.765324,
        "accuracy": 0.815223,
        "main_score": 0.765324,
        "hf_subset": "rus_Cyrl-ben_Beng",
        "languages": [
          "rus-Cyrl",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.658452,
        "recall": 0.743115,
        "f1": 0.683881,
        "accuracy": 0.743115,
        "main_score": 0.683881,
        "hf_subset": "sin_Sinh-ben_Beng",
        "languages": [
          "sin-Sinh",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.523516,
        "recall": 0.621432,
        "f1": 0.551728,
        "accuracy": 0.621432,
        "main_score": 0.551728,
        "hf_subset": "snd_Arab-ben_Beng",
        "languages": [
          "snd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.738292,
        "recall": 0.809715,
        "f1": 0.759723,
        "accuracy": 0.809715,
        "main_score": 0.759723,
        "hf_subset": "spa_Latn-ben_Beng",
        "languages": [
          "spa-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.261296,
        "recall": 0.327491,
        "f1": 0.277415,
        "accuracy": 0.327491,
        "main_score": 0.277415,
        "hf_subset": "swa_Latn-ben_Beng",
        "languages": [
          "swa-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.736676,
        "recall": 0.808713,
        "f1": 0.758575,
        "accuracy": 0.808713,
        "main_score": 0.758575,
        "hf_subset": "swe_Latn-ben_Beng",
        "languages": [
          "swe-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.672756,
        "recall": 0.755133,
        "f1": 0.697409,
        "accuracy": 0.755133,
        "main_score": 0.697409,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.684577,
        "recall": 0.765648,
        "f1": 0.70914,
        "accuracy": 0.765648,
        "main_score": 0.70914,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.700551,
        "recall": 0.778668,
        "f1": 0.724168,
        "accuracy": 0.778668,
        "main_score": 0.724168,
        "hf_subset": "tur_Latn-ben_Beng",
        "languages": [
          "tur-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.784343,
        "recall": 0.844767,
        "f1": 0.803231,
        "accuracy": 0.844767,
        "main_score": 0.803231,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.68673,
        "recall": 0.768653,
        "f1": 0.710912,
        "accuracy": 0.768653,
        "main_score": 0.710912,
        "hf_subset": "vie_Latn-ben_Beng",
        "languages": [
          "vie-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.68418,
        "recall": 0.767651,
        "f1": 0.709151,
        "accuracy": 0.767651,
        "main_score": 0.709151,
        "hf_subset": "zho_Hant-ben_Beng",
        "languages": [
          "zho-Hant",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.053895,
        "recall": 0.071607,
        "f1": 0.057703,
        "accuracy": 0.071607,
        "main_score": 0.057703,
        "hf_subset": "zul_Latn-ben_Beng",
        "languages": [
          "zul-Latn",
          "ben-Beng"
        ]
      }
    ]
  },
  "evaluation_time": 275.50671553611755,
  "kg_co2_emissions": null
}