{
  "dataset_revision": "2747bf03e02df02cc08b9cce64d0d053fef2a826",
  "task_name": "IN22ConvBitextMining",
  "mteb_version": "2.3.0",
  "scores": {
    "test": [
      {
        "precision": 0.401119,
        "recall": 0.492349,
        "f1": 0.427221,
        "accuracy": 0.492349,
        "main_score": 0.427221,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.345055,
        "recall": 0.449767,
        "f1": 0.372249,
        "accuracy": 0.449767,
        "main_score": 0.372249,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.019279,
        "recall": 0.041251,
        "f1": 0.023088,
        "accuracy": 0.041251,
        "main_score": 0.023088,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ]
      },
      {
        "precision": 0.184343,
        "recall": 0.270792,
        "f1": 0.203695,
        "accuracy": 0.270792,
        "main_score": 0.203695,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ]
      },
      {
        "precision": 0.688362,
        "recall": 0.76181,
        "f1": 0.710419,
        "accuracy": 0.76181,
        "main_score": 0.710419,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.166111,
        "recall": 0.244844,
        "f1": 0.183781,
        "accuracy": 0.244844,
        "main_score": 0.183781,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.63798,
        "recall": 0.715236,
        "f1": 0.661258,
        "accuracy": 0.715236,
        "main_score": 0.661258,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.687758,
        "recall": 0.762475,
        "f1": 0.710405,
        "accuracy": 0.762475,
        "main_score": 0.710405,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.45541,
        "recall": 0.556221,
        "f1": 0.484236,
        "accuracy": 0.556221,
        "main_score": 0.484236,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.064608,
        "recall": 0.115768,
        "f1": 0.074672,
        "accuracy": 0.115768,
        "main_score": 0.074672,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.268871,
        "recall": 0.347305,
        "f1": 0.287949,
        "accuracy": 0.347305,
        "main_score": 0.287949,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.574296,
        "recall": 0.660679,
        "f1": 0.599506,
        "accuracy": 0.660679,
        "main_score": 0.599506,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.66932,
        "recall": 0.743846,
        "f1": 0.69133,
        "accuracy": 0.743846,
        "main_score": 0.69133,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000177,
        "recall": 0.005988,
        "f1": 0.00033,
        "accuracy": 0.005988,
        "main_score": 0.00033,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.635064,
        "recall": 0.72189,
        "f1": 0.661272,
        "accuracy": 0.72189,
        "main_score": 0.661272,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.513928,
        "recall": 0.614105,
        "f1": 0.54255,
        "accuracy": 0.614105,
        "main_score": 0.54255,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.518957,
        "recall": 0.610778,
        "f1": 0.545859,
        "accuracy": 0.610778,
        "main_score": 0.545859,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.247168,
        "recall": 0.329341,
        "f1": 0.267543,
        "accuracy": 0.329341,
        "main_score": 0.267543,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ]
      },
      {
        "precision": 9.4e-05,
        "recall": 0.003327,
        "f1": 0.000181,
        "accuracy": 0.003327,
        "main_score": 0.000181,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.112701,
        "recall": 0.176314,
        "f1": 0.126531,
        "accuracy": 0.176314,
        "main_score": 0.126531,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ]
      },
      {
        "precision": 0.447127,
        "recall": 0.548237,
        "f1": 0.475955,
        "accuracy": 0.548237,
        "main_score": 0.475955,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.558555,
        "recall": 0.648703,
        "f1": 0.584934,
        "accuracy": 0.648703,
        "main_score": 0.584934,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.649933,
        "recall": 0.73187,
        "f1": 0.674762,
        "accuracy": 0.73187,
        "main_score": 0.674762,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.022682,
        "recall": 0.036593,
        "f1": 0.025304,
        "accuracy": 0.036593,
        "main_score": 0.025304,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.24218,
        "recall": 0.315369,
        "f1": 0.260998,
        "accuracy": 0.315369,
        "main_score": 0.260998,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.662122,
        "recall": 0.745176,
        "f1": 0.686711,
        "accuracy": 0.745176,
        "main_score": 0.686711,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.194022,
        "recall": 0.261477,
        "f1": 0.2106,
        "accuracy": 0.261477,
        "main_score": 0.2106,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.628416,
        "recall": 0.71191,
        "f1": 0.653086,
        "accuracy": 0.71191,
        "main_score": 0.653086,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.658006,
        "recall": 0.740519,
        "f1": 0.682702,
        "accuracy": 0.740519,
        "main_score": 0.682702,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.450112,
        "recall": 0.542914,
        "f1": 0.476204,
        "accuracy": 0.542914,
        "main_score": 0.476204,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.086765,
        "recall": 0.121756,
        "f1": 0.094964,
        "accuracy": 0.121756,
        "main_score": 0.094964,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.328052,
        "recall": 0.409847,
        "f1": 0.350643,
        "accuracy": 0.409847,
        "main_score": 0.350643,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.556262,
        "recall": 0.646707,
        "f1": 0.582743,
        "accuracy": 0.646707,
        "main_score": 0.582743,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.625854,
        "recall": 0.713906,
        "f1": 0.652117,
        "accuracy": 0.713906,
        "main_score": 0.652117,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001358,
        "recall": 0.003327,
        "f1": 0.001385,
        "accuracy": 0.003327,
        "main_score": 0.001385,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.633895,
        "recall": 0.716567,
        "f1": 0.658619,
        "accuracy": 0.716567,
        "main_score": 0.658619,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.521552,
        "recall": 0.611444,
        "f1": 0.547597,
        "accuracy": 0.611444,
        "main_score": 0.547597,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.528235,
        "recall": 0.621424,
        "f1": 0.555421,
        "accuracy": 0.621424,
        "main_score": 0.555421,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.269485,
        "recall": 0.343313,
        "f1": 0.288942,
        "accuracy": 0.343313,
        "main_score": 0.288942,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 1.8e-05,
        "recall": 0.001996,
        "f1": 3.5e-05,
        "accuracy": 0.001996,
        "main_score": 3.5e-05,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.154283,
        "recall": 0.204258,
        "f1": 0.165728,
        "accuracy": 0.204258,
        "main_score": 0.165728,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.438916,
        "recall": 0.535595,
        "f1": 0.466643,
        "accuracy": 0.535595,
        "main_score": 0.466643,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.531309,
        "recall": 0.62475,
        "f1": 0.558873,
        "accuracy": 0.62475,
        "main_score": 0.558873,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.631456,
        "recall": 0.718563,
        "f1": 0.657696,
        "accuracy": 0.718563,
        "main_score": 0.657696,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      }
    ]
  },
  "evaluation_time": 76.9547529220581,
  "kg_co2_emissions": null
}