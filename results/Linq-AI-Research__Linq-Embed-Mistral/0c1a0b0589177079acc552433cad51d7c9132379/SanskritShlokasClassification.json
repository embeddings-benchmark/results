{
  "dataset_revision": "5a79d6472db143690c7ce6e974995d3610eee7f0",
  "task_name": "SanskritShlokasClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "train": [
      {
        "accuracy": 0.75483,
        "f1": 0.754755,
        "f1_weighted": 0.754103,
        "scores_per_experiment": [
          {
            "accuracy": 0.765013,
            "f1": 0.765583,
            "f1_weighted": 0.765587
          },
          {
            "accuracy": 0.681462,
            "f1": 0.67997,
            "f1_weighted": 0.677112
          },
          {
            "accuracy": 0.715405,
            "f1": 0.715895,
            "f1_weighted": 0.714559
          },
          {
            "accuracy": 0.725849,
            "f1": 0.726027,
            "f1_weighted": 0.722825
          },
          {
            "accuracy": 0.825065,
            "f1": 0.822953,
            "f1_weighted": 0.823319
          },
          {
            "accuracy": 0.859008,
            "f1": 0.856873,
            "f1_weighted": 0.857755
          },
          {
            "accuracy": 0.75718,
            "f1": 0.759213,
            "f1_weighted": 0.759361
          },
          {
            "accuracy": 0.75718,
            "f1": 0.753665,
            "f1_weighted": 0.753542
          },
          {
            "accuracy": 0.738903,
            "f1": 0.739696,
            "f1_weighted": 0.738559
          },
          {
            "accuracy": 0.723238,
            "f1": 0.727677,
            "f1_weighted": 0.728411
          }
        ],
        "main_score": 0.75483,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.744792,
        "f1": 0.74817,
        "f1_weighted": 0.743131,
        "scores_per_experiment": [
          {
            "accuracy": 0.739583,
            "f1": 0.742811,
            "f1_weighted": 0.738164
          },
          {
            "accuracy": 0.677083,
            "f1": 0.677015,
            "f1_weighted": 0.666979
          },
          {
            "accuracy": 0.739583,
            "f1": 0.749784,
            "f1_weighted": 0.739186
          },
          {
            "accuracy": 0.770833,
            "f1": 0.77441,
            "f1_weighted": 0.767664
          },
          {
            "accuracy": 0.822917,
            "f1": 0.818169,
            "f1_weighted": 0.819324
          },
          {
            "accuracy": 0.833333,
            "f1": 0.83573,
            "f1_weighted": 0.83317
          },
          {
            "accuracy": 0.78125,
            "f1": 0.783333,
            "f1_weighted": 0.780729
          },
          {
            "accuracy": 0.822917,
            "f1": 0.822125,
            "f1_weighted": 0.820922
          },
          {
            "accuracy": 0.645833,
            "f1": 0.64883,
            "f1_weighted": 0.642763
          },
          {
            "accuracy": 0.614583,
            "f1": 0.629489,
            "f1_weighted": 0.622412
          }
        ],
        "main_score": 0.744792,
        "hf_subset": "default",
        "languages": [
          "san-Deva"
        ]
      }
    ]
  },
  "evaluation_time": 19.155025005340576,
  "kg_co2_emissions": 0.0008997149560094204
}