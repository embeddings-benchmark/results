{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.190723,
        "f1": 0.151557,
        "f1_weighted": 0.179893,
        "scores_per_experiment": [
          {
            "accuracy": 0.187988,
            "f1": 0.144278,
            "f1_weighted": 0.174327
          },
          {
            "accuracy": 0.172363,
            "f1": 0.137257,
            "f1_weighted": 0.157317
          },
          {
            "accuracy": 0.187012,
            "f1": 0.138332,
            "f1_weighted": 0.177255
          },
          {
            "accuracy": 0.189941,
            "f1": 0.158429,
            "f1_weighted": 0.182842
          },
          {
            "accuracy": 0.185059,
            "f1": 0.148738,
            "f1_weighted": 0.18116
          },
          {
            "accuracy": 0.200195,
            "f1": 0.168642,
            "f1_weighted": 0.190093
          },
          {
            "accuracy": 0.210449,
            "f1": 0.15651,
            "f1_weighted": 0.192492
          },
          {
            "accuracy": 0.193848,
            "f1": 0.158566,
            "f1_weighted": 0.175587
          },
          {
            "accuracy": 0.1875,
            "f1": 0.152645,
            "f1_weighted": 0.18266
          },
          {
            "accuracy": 0.192871,
            "f1": 0.152173,
            "f1_weighted": 0.185199
          }
        ],
        "main_score": 0.190723,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.181445,
        "f1": 0.151904,
        "f1_weighted": 0.167839,
        "scores_per_experiment": [
          {
            "accuracy": 0.176758,
            "f1": 0.12929,
            "f1_weighted": 0.15236
          },
          {
            "accuracy": 0.18457,
            "f1": 0.160472,
            "f1_weighted": 0.170548
          },
          {
            "accuracy": 0.178223,
            "f1": 0.151031,
            "f1_weighted": 0.163643
          },
          {
            "accuracy": 0.177734,
            "f1": 0.143689,
            "f1_weighted": 0.162979
          },
          {
            "accuracy": 0.16748,
            "f1": 0.142359,
            "f1_weighted": 0.159914
          },
          {
            "accuracy": 0.180176,
            "f1": 0.156188,
            "f1_weighted": 0.16911
          },
          {
            "accuracy": 0.196289,
            "f1": 0.158908,
            "f1_weighted": 0.180003
          },
          {
            "accuracy": 0.184082,
            "f1": 0.153729,
            "f1_weighted": 0.16863
          },
          {
            "accuracy": 0.181641,
            "f1": 0.165491,
            "f1_weighted": 0.173876
          },
          {
            "accuracy": 0.1875,
            "f1": 0.157884,
            "f1_weighted": 0.177329
          }
        ],
        "main_score": 0.181445,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 2365.076847076416,
  "kg_co2_emissions": 0.13827671216851745
}