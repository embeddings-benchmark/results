{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "task_name": "PoemSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.545714,
        "f1": 0.415887,
        "f1_weighted": 0.593541,
        "scores_per_experiment": [
          {
            "accuracy": 0.542857,
            "f1": 0.431647,
            "f1_weighted": 0.586375
          },
          {
            "accuracy": 0.495238,
            "f1": 0.405526,
            "f1_weighted": 0.560053
          },
          {
            "accuracy": 0.580952,
            "f1": 0.431373,
            "f1_weighted": 0.649626
          },
          {
            "accuracy": 0.609524,
            "f1": 0.463698,
            "f1_weighted": 0.66989
          },
          {
            "accuracy": 0.619048,
            "f1": 0.425993,
            "f1_weighted": 0.658362
          },
          {
            "accuracy": 0.47619,
            "f1": 0.363231,
            "f1_weighted": 0.48884
          },
          {
            "accuracy": 0.571429,
            "f1": 0.468583,
            "f1_weighted": 0.635167
          },
          {
            "accuracy": 0.542857,
            "f1": 0.387472,
            "f1_weighted": 0.587948
          },
          {
            "accuracy": 0.466667,
            "f1": 0.360957,
            "f1_weighted": 0.512905
          },
          {
            "accuracy": 0.552381,
            "f1": 0.420388,
            "f1_weighted": 0.586247
          }
        ],
        "main_score": 0.545714,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.534615,
        "f1": 0.415725,
        "f1_weighted": 0.577919,
        "scores_per_experiment": [
          {
            "accuracy": 0.538462,
            "f1": 0.414084,
            "f1_weighted": 0.569381
          },
          {
            "accuracy": 0.538462,
            "f1": 0.453722,
            "f1_weighted": 0.58252
          },
          {
            "accuracy": 0.548077,
            "f1": 0.427436,
            "f1_weighted": 0.614897
          },
          {
            "accuracy": 0.634615,
            "f1": 0.494475,
            "f1_weighted": 0.696187
          },
          {
            "accuracy": 0.605769,
            "f1": 0.444612,
            "f1_weighted": 0.660989
          },
          {
            "accuracy": 0.480769,
            "f1": 0.369489,
            "f1_weighted": 0.495792
          },
          {
            "accuracy": 0.5,
            "f1": 0.399801,
            "f1_weighted": 0.554215
          },
          {
            "accuracy": 0.548077,
            "f1": 0.388076,
            "f1_weighted": 0.59329
          },
          {
            "accuracy": 0.471154,
            "f1": 0.380435,
            "f1_weighted": 0.503972
          },
          {
            "accuracy": 0.480769,
            "f1": 0.385118,
            "f1_weighted": 0.507945
          }
        ],
        "main_score": 0.534615,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 12.732804775238037,
  "kg_co2_emissions": 0.0003778463520658943
}