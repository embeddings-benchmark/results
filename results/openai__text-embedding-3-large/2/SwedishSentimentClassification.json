{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.948193,
        "f1": 0.948079,
        "f1_weighted": 0.948086,
        "ap": 0.912782,
        "ap_weighted": 0.912782,
        "scores_per_experiment": [
          {
            "accuracy": 0.959961,
            "f1": 0.959924,
            "f1_weighted": 0.959928,
            "ap": 0.930784,
            "ap_weighted": 0.930784
          },
          {
            "accuracy": 0.963867,
            "f1": 0.963864,
            "f1_weighted": 0.963865,
            "ap": 0.944815,
            "ap_weighted": 0.944815
          },
          {
            "accuracy": 0.963379,
            "f1": 0.963358,
            "f1_weighted": 0.96336,
            "ap": 0.937952,
            "ap_weighted": 0.937952
          },
          {
            "accuracy": 0.932617,
            "f1": 0.932559,
            "f1_weighted": 0.932565,
            "ap": 0.894437,
            "ap_weighted": 0.894437
          },
          {
            "accuracy": 0.94873,
            "f1": 0.948638,
            "f1_weighted": 0.948644,
            "ap": 0.911221,
            "ap_weighted": 0.911221
          },
          {
            "accuracy": 0.959961,
            "f1": 0.959937,
            "f1_weighted": 0.95994,
            "ap": 0.933042,
            "ap_weighted": 0.933042
          },
          {
            "accuracy": 0.94043,
            "f1": 0.940287,
            "f1_weighted": 0.940296,
            "ap": 0.898175,
            "ap_weighted": 0.898175
          },
          {
            "accuracy": 0.950195,
            "f1": 0.95009,
            "f1_weighted": 0.950097,
            "ap": 0.911981,
            "ap_weighted": 0.911981
          },
          {
            "accuracy": 0.949219,
            "f1": 0.949097,
            "f1_weighted": 0.949105,
            "ap": 0.909689,
            "ap_weighted": 0.909689
          },
          {
            "accuracy": 0.913574,
            "f1": 0.913037,
            "f1_weighted": 0.913057,
            "ap": 0.855725,
            "ap_weighted": 0.855725
          }
        ],
        "main_score": 0.948193,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.947314,
        "f1": 0.947195,
        "f1_weighted": 0.947199,
        "ap": 0.912151,
        "ap_weighted": 0.912151,
        "scores_per_experiment": [
          {
            "accuracy": 0.964355,
            "f1": 0.964332,
            "f1_weighted": 0.964333,
            "ap": 0.938083,
            "ap_weighted": 0.938083
          },
          {
            "accuracy": 0.958984,
            "f1": 0.958982,
            "f1_weighted": 0.958982,
            "ap": 0.93787,
            "ap_weighted": 0.93787
          },
          {
            "accuracy": 0.966309,
            "f1": 0.9663,
            "f1_weighted": 0.966301,
            "ap": 0.944732,
            "ap_weighted": 0.944732
          },
          {
            "accuracy": 0.929688,
            "f1": 0.929623,
            "f1_weighted": 0.929627,
            "ap": 0.889817,
            "ap_weighted": 0.889817
          },
          {
            "accuracy": 0.952148,
            "f1": 0.952082,
            "f1_weighted": 0.952086,
            "ap": 0.917244,
            "ap_weighted": 0.917244
          },
          {
            "accuracy": 0.960449,
            "f1": 0.960435,
            "f1_weighted": 0.960436,
            "ap": 0.935373,
            "ap_weighted": 0.935373
          },
          {
            "accuracy": 0.938965,
            "f1": 0.938839,
            "f1_weighted": 0.938844,
            "ap": 0.896965,
            "ap_weighted": 0.896965
          },
          {
            "accuracy": 0.944824,
            "f1": 0.944695,
            "f1_weighted": 0.9447,
            "ap": 0.903662,
            "ap_weighted": 0.903662
          },
          {
            "accuracy": 0.94873,
            "f1": 0.948625,
            "f1_weighted": 0.948629,
            "ap": 0.909792,
            "ap_weighted": 0.909792
          },
          {
            "accuracy": 0.908691,
            "f1": 0.908035,
            "f1_weighted": 0.90805,
            "ap": 0.847975,
            "ap_weighted": 0.847975
          }
        ],
        "main_score": 0.947314,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 199.2603714466095,
  "kg_co2_emissions": null
}