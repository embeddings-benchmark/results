{
  "dataset_revision": "329d529d875a00c47ec71954a1a96ae167584770",
  "evaluation_time": 32.59864091873169,
  "kg_co2_emissions": null,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.49326923076923074,
        "f1": 0.3840786389643639,
        "f1_weighted": 0.5515057972099181,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.49326923076923074,
        "scores_per_experiment": [
          {
            "accuracy": 0.4326923076923077,
            "f1": 0.32756410256410257,
            "f1_weighted": 0.5071252465483235
          },
          {
            "accuracy": 0.5192307692307693,
            "f1": 0.43202530549512397,
            "f1_weighted": 0.5716423219710877
          },
          {
            "accuracy": 0.5384615384615384,
            "f1": 0.4340384615384616,
            "f1_weighted": 0.589371301775148
          },
          {
            "accuracy": 0.5288461538461539,
            "f1": 0.42002980718477345,
            "f1_weighted": 0.6066316209328597
          },
          {
            "accuracy": 0.5192307692307693,
            "f1": 0.3834305408271474,
            "f1_weighted": 0.575140712945591
          },
          {
            "accuracy": 0.5096153846153846,
            "f1": 0.4032564109124091,
            "f1_weighted": 0.5495003585033519
          },
          {
            "accuracy": 0.46153846153846156,
            "f1": 0.3653305834528934,
            "f1_weighted": 0.5058722363241732
          },
          {
            "accuracy": 0.4807692307692308,
            "f1": 0.36332417582417575,
            "f1_weighted": 0.5477863482671175
          },
          {
            "accuracy": 0.46153846153846156,
            "f1": 0.34015579617079295,
            "f1_weighted": 0.5164185005388003
          },
          {
            "accuracy": 0.4807692307692308,
            "f1": 0.37163120567375885,
            "f1_weighted": 0.5455693242927285
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5342857142857144,
        "f1": 0.3979946134795357,
        "f1_weighted": 0.5902090846769291,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5342857142857144,
        "scores_per_experiment": [
          {
            "accuracy": 0.5428571428571428,
            "f1": 0.4172118380062305,
            "f1_weighted": 0.5950838154576472
          },
          {
            "accuracy": 0.5619047619047619,
            "f1": 0.43503089309118137,
            "f1_weighted": 0.6288353349203378
          },
          {
            "accuracy": 0.49523809523809526,
            "f1": 0.38974090048052745,
            "f1_weighted": 0.5616359845664526
          },
          {
            "accuracy": 0.5714285714285714,
            "f1": 0.4502994211191696,
            "f1_weighted": 0.6520294414924797
          },
          {
            "accuracy": 0.580952380952381,
            "f1": 0.3981967787114846,
            "f1_weighted": 0.623626117113512
          },
          {
            "accuracy": 0.5047619047619047,
            "f1": 0.36699515480003286,
            "f1_weighted": 0.5395098487781415
          },
          {
            "accuracy": 0.49523809523809526,
            "f1": 0.39132195458499563,
            "f1_weighted": 0.5540104874178126
          },
          {
            "accuracy": 0.5142857142857142,
            "f1": 0.3453458306399483,
            "f1_weighted": 0.5717466473768994
          },
          {
            "accuracy": 0.5619047619047619,
            "f1": 0.4064546010504353,
            "f1_weighted": 0.6065289041006718
          },
          {
            "accuracy": 0.5142857142857142,
            "f1": 0.37934876231135084,
            "f1_weighted": 0.5690842655453373
          }
        ]
      }
    ]
  },
  "task_name": "PoemSentimentClassification"
}