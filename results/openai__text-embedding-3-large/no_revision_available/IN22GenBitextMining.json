{
  "dataset_revision": "ec381535fe3ddf699297a023bcecaa548096ed68",
  "evaluation_time": 882.8750162124634,
  "kg_co2_emissions": null,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.87890625,
        "f1": 0.8455620659722223,
        "hf_subset": "asm_Beng-ben_Beng",
        "languages": [
          "asm-Beng",
          "ben-Beng"
        ],
        "main_score": 0.8455620659722223,
        "precision": 0.8306884765625,
        "recall": 0.87890625
      },
      {
        "accuracy": 0.2490234375,
        "f1": 0.1849643412143412,
        "hf_subset": "asm_Beng-brx_Deva",
        "languages": [
          "asm-Beng",
          "brx-Deva"
        ],
        "main_score": 0.1849643412143412,
        "precision": 0.1637612599696499,
        "recall": 0.2490234375
      },
      {
        "accuracy": 0.6533203125,
        "f1": 0.5898677765376985,
        "hf_subset": "asm_Beng-doi_Deva",
        "languages": [
          "asm-Beng",
          "doi-Deva"
        ],
        "main_score": 0.5898677765376985,
        "precision": 0.5639171781994048,
        "recall": 0.6533203125
      },
      {
        "accuracy": 0.6923828125,
        "f1": 0.6272429935515873,
        "hf_subset": "asm_Beng-eng_Latn",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ],
        "main_score": 0.6272429935515873,
        "precision": 0.6012858072916667,
        "recall": 0.6923828125
      },
      {
        "accuracy": 0.544921875,
        "f1": 0.47885354662698415,
        "hf_subset": "asm_Beng-gom_Deva",
        "languages": [
          "asm-Beng",
          "gom-Deva"
        ],
        "main_score": 0.47885354662698415,
        "precision": 0.4524983723958333,
        "recall": 0.544921875
      },
      {
        "accuracy": 0.64453125,
        "f1": 0.5805385044642857,
        "hf_subset": "asm_Beng-guj_Gujr",
        "languages": [
          "asm-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.5805385044642857,
        "precision": 0.5542805989583333,
        "recall": 0.64453125
      },
      {
        "accuracy": 0.798828125,
        "f1": 0.7518771701388889,
        "hf_subset": "asm_Beng-hin_Deva",
        "languages": [
          "asm-Beng",
          "hin-Deva"
        ],
        "main_score": 0.7518771701388889,
        "precision": 0.731985134548611,
        "recall": 0.798828125
      },
      {
        "accuracy": 0.587890625,
        "f1": 0.5245930989583333,
        "hf_subset": "asm_Beng-kan_Knda",
        "languages": [
          "asm-Beng",
          "kan-Knda"
        ],
        "main_score": 0.5245930989583333,
        "precision": 0.49899476066468257,
        "recall": 0.587890625
      },
      {
        "accuracy": 0.3994140625,
        "f1": 0.3390740065056471,
        "hf_subset": "asm_Beng-kas_Arab",
        "languages": [
          "asm-Beng",
          "kas-Arab"
        ],
        "main_score": 0.3390740065056471,
        "precision": 0.3173696718862734,
        "recall": 0.3994140625
      },
      {
        "accuracy": 0.7578125,
        "f1": 0.7055059523809524,
        "hf_subset": "asm_Beng-mai_Deva",
        "languages": [
          "asm-Beng",
          "mai-Deva"
        ],
        "main_score": 0.7055059523809524,
        "precision": 0.6831705729166666,
        "recall": 0.7578125
      },
      {
        "accuracy": 0.5302734375,
        "f1": 0.45708472842261905,
        "hf_subset": "asm_Beng-mal_Mlym",
        "languages": [
          "asm-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.45708472842261905,
        "precision": 0.4281587146577381,
        "recall": 0.5302734375
      },
      {
        "accuracy": 0.716796875,
        "f1": 0.6546875,
        "hf_subset": "asm_Beng-mar_Deva",
        "languages": [
          "asm-Beng",
          "mar-Deva"
        ],
        "main_score": 0.6546875,
        "precision": 0.6279971168154762,
        "recall": 0.716796875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0021503147105080027,
        "hf_subset": "asm_Beng-mni_Mtei",
        "languages": [
          "asm-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0021503147105080027,
        "precision": 0.0013632266813347262,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.78515625,
        "f1": 0.7350748697916667,
        "hf_subset": "asm_Beng-npi_Deva",
        "languages": [
          "asm-Beng",
          "npi-Deva"
        ],
        "main_score": 0.7350748697916667,
        "precision": 0.7130084325396826,
        "recall": 0.78515625
      },
      {
        "accuracy": 0.509765625,
        "f1": 0.4367086743551587,
        "hf_subset": "asm_Beng-ory_Orya",
        "languages": [
          "asm-Beng",
          "ory-Orya"
        ],
        "main_score": 0.4367086743551587,
        "precision": 0.40933547247023805,
        "recall": 0.509765625
      },
      {
        "accuracy": 0.5244140625,
        "f1": 0.4577923487103175,
        "hf_subset": "asm_Beng-pan_Guru",
        "languages": [
          "asm-Beng",
          "pan-Guru"
        ],
        "main_score": 0.4577923487103175,
        "precision": 0.43120930989583334,
        "recall": 0.5244140625
      },
      {
        "accuracy": 0.697265625,
        "f1": 0.6342308407738095,
        "hf_subset": "asm_Beng-san_Deva",
        "languages": [
          "asm-Beng",
          "san-Deva"
        ],
        "main_score": 0.6342308407738095,
        "precision": 0.6070060961174242,
        "recall": 0.697265625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0014401619430916305,
        "hf_subset": "asm_Beng-sat_Olck",
        "languages": [
          "asm-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0014401619430916305,
        "precision": 0.0008667212171240685,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.513671875,
        "f1": 0.44656808035714285,
        "hf_subset": "asm_Beng-snd_Deva",
        "languages": [
          "asm-Beng",
          "snd-Deva"
        ],
        "main_score": 0.44656808035714285,
        "precision": 0.4198102678571429,
        "recall": 0.513671875
      },
      {
        "accuracy": 0.3037109375,
        "f1": 0.2400482438568376,
        "hf_subset": "asm_Beng-tam_Taml",
        "languages": [
          "asm-Beng",
          "tam-Taml"
        ],
        "main_score": 0.2400482438568376,
        "precision": 0.21835356212797621,
        "recall": 0.3037109375
      },
      {
        "accuracy": 0.5302734375,
        "f1": 0.4601183430284993,
        "hf_subset": "asm_Beng-tel_Telu",
        "languages": [
          "asm-Beng",
          "tel-Telu"
        ],
        "main_score": 0.4601183430284993,
        "precision": 0.4322881789434524,
        "recall": 0.5302734375
      },
      {
        "accuracy": 0.6796875,
        "f1": 0.6164620535714286,
        "hf_subset": "asm_Beng-urd_Arab",
        "languages": [
          "asm-Beng",
          "urd-Arab"
        ],
        "main_score": 0.6164620535714286,
        "precision": 0.591357421875,
        "recall": 0.6796875
      },
      {
        "accuracy": 0.884765625,
        "f1": 0.8528831845238095,
        "hf_subset": "ben_Beng-asm_Beng",
        "languages": [
          "ben-Beng",
          "asm-Beng"
        ],
        "main_score": 0.8528831845238095,
        "precision": 0.838134765625,
        "recall": 0.884765625
      },
      {
        "accuracy": 0.28515625,
        "f1": 0.21978309234168608,
        "hf_subset": "ben_Beng-brx_Deva",
        "languages": [
          "ben-Beng",
          "brx-Deva"
        ],
        "main_score": 0.21978309234168608,
        "precision": 0.19863278811032717,
        "recall": 0.28515625
      },
      {
        "accuracy": 0.763671875,
        "f1": 0.7063825334821429,
        "hf_subset": "ben_Beng-doi_Deva",
        "languages": [
          "ben-Beng",
          "doi-Deva"
        ],
        "main_score": 0.7063825334821429,
        "precision": 0.6814057849702382,
        "recall": 0.763671875
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.8754557291666666,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ],
        "main_score": 0.8754557291666666,
        "precision": 0.8619791666666667,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.630859375,
        "f1": 0.565283203125,
        "hf_subset": "ben_Beng-gom_Deva",
        "languages": [
          "ben-Beng",
          "gom-Deva"
        ],
        "main_score": 0.565283203125,
        "precision": 0.5380650111607143,
        "recall": 0.630859375
      },
      {
        "accuracy": 0.775390625,
        "f1": 0.7258138020833333,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ],
        "main_score": 0.7258138020833333,
        "precision": 0.7041341145833333,
        "recall": 0.775390625
      },
      {
        "accuracy": 0.9375,
        "f1": 0.91845703125,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ],
        "main_score": 0.91845703125,
        "precision": 0.9093424479166666,
        "recall": 0.9375
      },
      {
        "accuracy": 0.751953125,
        "f1": 0.6979817708333333,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ],
        "main_score": 0.6979817708333333,
        "precision": 0.6740234375,
        "recall": 0.751953125
      },
      {
        "accuracy": 0.501953125,
        "f1": 0.4310291108630952,
        "hf_subset": "ben_Beng-kas_Arab",
        "languages": [
          "ben-Beng",
          "kas-Arab"
        ],
        "main_score": 0.4310291108630952,
        "precision": 0.4046154203869048,
        "recall": 0.501953125
      },
      {
        "accuracy": 0.869140625,
        "f1": 0.8344401041666666,
        "hf_subset": "ben_Beng-mai_Deva",
        "languages": [
          "ben-Beng",
          "mai-Deva"
        ],
        "main_score": 0.8344401041666666,
        "precision": 0.8187174479166667,
        "recall": 0.869140625
      },
      {
        "accuracy": 0.6708984375,
        "f1": 0.6039574032738095,
        "hf_subset": "ben_Beng-mal_Mlym",
        "languages": [
          "ben-Beng",
          "mal-Mlym"
        ],
        "main_score": 0.6039574032738095,
        "precision": 0.57568359375,
        "recall": 0.6708984375
      },
      {
        "accuracy": 0.841796875,
        "f1": 0.8053385416666667,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ],
        "main_score": 0.8053385416666667,
        "precision": 0.789013671875,
        "recall": 0.841796875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0024711399461710758,
        "hf_subset": "ben_Beng-mni_Mtei",
        "languages": [
          "ben-Beng",
          "mni-Mtei"
        ],
        "main_score": 0.0024711399461710758,
        "precision": 0.0016264312772342328,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.8837890625,
        "f1": 0.85234375,
        "hf_subset": "ben_Beng-npi_Deva",
        "languages": [
          "ben-Beng",
          "npi-Deva"
        ],
        "main_score": 0.85234375,
        "precision": 0.8377278645833334,
        "recall": 0.8837890625
      },
      {
        "accuracy": 0.576171875,
        "f1": 0.5087658110119047,
        "hf_subset": "ben_Beng-ory_Orya",
        "languages": [
          "ben-Beng",
          "ory-Orya"
        ],
        "main_score": 0.5087658110119047,
        "precision": 0.48274739583333337,
        "recall": 0.576171875
      },
      {
        "accuracy": 0.6572265625,
        "f1": 0.5888997395833333,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ],
        "main_score": 0.5888997395833333,
        "precision": 0.5606119791666666,
        "recall": 0.6572265625
      },
      {
        "accuracy": 0.8330078125,
        "f1": 0.7921875,
        "hf_subset": "ben_Beng-san_Deva",
        "languages": [
          "ben-Beng",
          "san-Deva"
        ],
        "main_score": 0.7921875,
        "precision": 0.7740071614583333,
        "recall": 0.8330078125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0023725126592643374,
        "hf_subset": "ben_Beng-sat_Olck",
        "languages": [
          "ben-Beng",
          "sat-Olck"
        ],
        "main_score": 0.0023725126592643374,
        "precision": 0.0018693991010620109,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.6162109375,
        "f1": 0.5488978794642858,
        "hf_subset": "ben_Beng-snd_Deva",
        "languages": [
          "ben-Beng",
          "snd-Deva"
        ],
        "main_score": 0.5488978794642858,
        "precision": 0.5207682291666667,
        "recall": 0.6162109375
      },
      {
        "accuracy": 0.4462890625,
        "f1": 0.37774135044642854,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ],
        "main_score": 0.37774135044642854,
        "precision": 0.35081767733134916,
        "recall": 0.4462890625
      },
      {
        "accuracy": 0.6484375,
        "f1": 0.5854399181547619,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ],
        "main_score": 0.5854399181547619,
        "precision": 0.5601725260416667,
        "recall": 0.6484375
      },
      {
        "accuracy": 0.8603515625,
        "f1": 0.8230003720238095,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ],
        "main_score": 0.8230003720238095,
        "precision": 0.8058268229166667,
        "recall": 0.8603515625
      },
      {
        "accuracy": 0.216796875,
        "f1": 0.1644055360415352,
        "hf_subset": "brx_Deva-asm_Beng",
        "languages": [
          "brx-Deva",
          "asm-Beng"
        ],
        "main_score": 0.1644055360415352,
        "precision": 0.15106764480608023,
        "recall": 0.216796875
      },
      {
        "accuracy": 0.2353515625,
        "f1": 0.18472120479347043,
        "hf_subset": "brx_Deva-ben_Beng",
        "languages": [
          "brx-Deva",
          "ben-Beng"
        ],
        "main_score": 0.18472120479347043,
        "precision": 0.1698220538387184,
        "recall": 0.2353515625
      },
      {
        "accuracy": 0.2802734375,
        "f1": 0.22557603509147264,
        "hf_subset": "brx_Deva-doi_Deva",
        "languages": [
          "brx-Deva",
          "doi-Deva"
        ],
        "main_score": 0.22557603509147264,
        "precision": 0.21105247156272547,
        "recall": 0.2802734375
      },
      {
        "accuracy": 0.2177734375,
        "f1": 0.17201059389969306,
        "hf_subset": "brx_Deva-eng_Latn",
        "languages": [
          "brx-Deva",
          "eng-Latn"
        ],
        "main_score": 0.17201059389969306,
        "precision": 0.16080578297411077,
        "recall": 0.2177734375
      },
      {
        "accuracy": 0.2509765625,
        "f1": 0.20354645896638082,
        "hf_subset": "brx_Deva-gom_Deva",
        "languages": [
          "brx-Deva",
          "gom-Deva"
        ],
        "main_score": 0.20354645896638082,
        "precision": 0.18953816686618102,
        "recall": 0.2509765625
      },
      {
        "accuracy": 0.228515625,
        "f1": 0.18285616839159405,
        "hf_subset": "brx_Deva-guj_Gujr",
        "languages": [
          "brx-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.18285616839159405,
        "precision": 0.1705671564954653,
        "recall": 0.228515625
      },
      {
        "accuracy": 0.2744140625,
        "f1": 0.22286176516622525,
        "hf_subset": "brx_Deva-hin_Deva",
        "languages": [
          "brx-Deva",
          "hin-Deva"
        ],
        "main_score": 0.22286176516622525,
        "precision": 0.21071285068151824,
        "recall": 0.2744140625
      },
      {
        "accuracy": 0.154296875,
        "f1": 0.11164022266772256,
        "hf_subset": "brx_Deva-kan_Knda",
        "languages": [
          "brx-Deva",
          "kan-Knda"
        ],
        "main_score": 0.11164022266772256,
        "precision": 0.1026023513699095,
        "recall": 0.154296875
      },
      {
        "accuracy": 0.15234375,
        "f1": 0.1256660171621961,
        "hf_subset": "brx_Deva-kas_Arab",
        "languages": [
          "brx-Deva",
          "kas-Arab"
        ],
        "main_score": 0.1256660171621961,
        "precision": 0.11872081501957847,
        "recall": 0.15234375
      },
      {
        "accuracy": 0.2802734375,
        "f1": 0.22807717817483442,
        "hf_subset": "brx_Deva-mai_Deva",
        "languages": [
          "brx-Deva",
          "mai-Deva"
        ],
        "main_score": 0.22807717817483442,
        "precision": 0.21456015401584894,
        "recall": 0.2802734375
      },
      {
        "accuracy": 0.1767578125,
        "f1": 0.13973909269576415,
        "hf_subset": "brx_Deva-mal_Mlym",
        "languages": [
          "brx-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.13973909269576415,
        "precision": 0.13121118963447387,
        "recall": 0.1767578125
      },
      {
        "accuracy": 0.259765625,
        "f1": 0.20594260069357728,
        "hf_subset": "brx_Deva-mar_Deva",
        "languages": [
          "brx-Deva",
          "mar-Deva"
        ],
        "main_score": 0.20594260069357728,
        "precision": 0.19201059888039448,
        "recall": 0.259765625
      },
      {
        "accuracy": 0.015625,
        "f1": 0.00866330504834007,
        "hf_subset": "brx_Deva-mni_Mtei",
        "languages": [
          "brx-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.00866330504834007,
        "precision": 0.007449858312671141,
        "recall": 0.015625
      },
      {
        "accuracy": 0.2666015625,
        "f1": 0.21280053480909408,
        "hf_subset": "brx_Deva-npi_Deva",
        "languages": [
          "brx-Deva",
          "npi-Deva"
        ],
        "main_score": 0.21280053480909408,
        "precision": 0.19809523596026127,
        "recall": 0.2666015625
      },
      {
        "accuracy": 0.1357421875,
        "f1": 0.09706830618430481,
        "hf_subset": "brx_Deva-ory_Orya",
        "languages": [
          "brx-Deva",
          "ory-Orya"
        ],
        "main_score": 0.09706830618430481,
        "precision": 0.08783678834333823,
        "recall": 0.1357421875
      },
      {
        "accuracy": 0.220703125,
        "f1": 0.17510505621812517,
        "hf_subset": "brx_Deva-pan_Guru",
        "languages": [
          "brx-Deva",
          "pan-Guru"
        ],
        "main_score": 0.17510505621812517,
        "precision": 0.1636880852453434,
        "recall": 0.220703125
      },
      {
        "accuracy": 0.232421875,
        "f1": 0.18216235930961044,
        "hf_subset": "brx_Deva-san_Deva",
        "languages": [
          "brx-Deva",
          "san-Deva"
        ],
        "main_score": 0.18216235930961044,
        "precision": 0.16883449431012723,
        "recall": 0.232421875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0025935902243706095,
        "hf_subset": "brx_Deva-sat_Olck",
        "languages": [
          "brx-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0025935902243706095,
        "precision": 0.002300983073975536,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.271484375,
        "f1": 0.2372527591765873,
        "hf_subset": "brx_Deva-snd_Deva",
        "languages": [
          "brx-Deva",
          "snd-Deva"
        ],
        "main_score": 0.2372527591765873,
        "precision": 0.22528870597718254,
        "recall": 0.271484375
      },
      {
        "accuracy": 0.1337890625,
        "f1": 0.09696778724237365,
        "hf_subset": "brx_Deva-tam_Taml",
        "languages": [
          "brx-Deva",
          "tam-Taml"
        ],
        "main_score": 0.09696778724237365,
        "precision": 0.08839650777292121,
        "recall": 0.1337890625
      },
      {
        "accuracy": 0.201171875,
        "f1": 0.15979050215082047,
        "hf_subset": "brx_Deva-tel_Telu",
        "languages": [
          "brx-Deva",
          "tel-Telu"
        ],
        "main_score": 0.15979050215082047,
        "precision": 0.1485024538203572,
        "recall": 0.201171875
      },
      {
        "accuracy": 0.185546875,
        "f1": 0.14603797644851507,
        "hf_subset": "brx_Deva-urd_Arab",
        "languages": [
          "brx-Deva",
          "urd-Arab"
        ],
        "main_score": 0.14603797644851507,
        "precision": 0.13576054182171463,
        "recall": 0.185546875
      },
      {
        "accuracy": 0.6376953125,
        "f1": 0.5733933221726191,
        "hf_subset": "doi_Deva-asm_Beng",
        "languages": [
          "doi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.5733933221726191,
        "precision": 0.5470145089285714,
        "recall": 0.6376953125
      },
      {
        "accuracy": 0.76171875,
        "f1": 0.7081380208333333,
        "hf_subset": "doi_Deva-ben_Beng",
        "languages": [
          "doi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7081380208333333,
        "precision": 0.684326171875,
        "recall": 0.76171875
      },
      {
        "accuracy": 0.3046875,
        "f1": 0.23790690104166667,
        "hf_subset": "doi_Deva-brx_Deva",
        "languages": [
          "doi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.23790690104166667,
        "precision": 0.21557736967893218,
        "recall": 0.3046875
      },
      {
        "accuracy": 0.8251953125,
        "f1": 0.7821583581349206,
        "hf_subset": "doi_Deva-eng_Latn",
        "languages": [
          "doi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.7821583581349206,
        "precision": 0.7642740885416667,
        "recall": 0.8251953125
      },
      {
        "accuracy": 0.6982421875,
        "f1": 0.6436709449404762,
        "hf_subset": "doi_Deva-gom_Deva",
        "languages": [
          "doi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6436709449404762,
        "precision": 0.6205674913194444,
        "recall": 0.6982421875
      },
      {
        "accuracy": 0.7275390625,
        "f1": 0.6740118117559524,
        "hf_subset": "doi_Deva-guj_Gujr",
        "languages": [
          "doi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6740118117559524,
        "precision": 0.6513439360119049,
        "recall": 0.7275390625
      },
      {
        "accuracy": 0.935546875,
        "f1": 0.9162434895833333,
        "hf_subset": "doi_Deva-hin_Deva",
        "languages": [
          "doi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9162434895833333,
        "precision": 0.9073079427083333,
        "recall": 0.935546875
      },
      {
        "accuracy": 0.595703125,
        "f1": 0.5283141121031747,
        "hf_subset": "doi_Deva-kan_Knda",
        "languages": [
          "doi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.5283141121031747,
        "precision": 0.5019256107390874,
        "recall": 0.595703125
      },
      {
        "accuracy": 0.5615234375,
        "f1": 0.4905264494619963,
        "hf_subset": "doi_Deva-kas_Arab",
        "languages": [
          "doi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.4905264494619963,
        "precision": 0.46311616443452386,
        "recall": 0.5615234375
      },
      {
        "accuracy": 0.904296875,
        "f1": 0.87626953125,
        "hf_subset": "doi_Deva-mai_Deva",
        "languages": [
          "doi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.87626953125,
        "precision": 0.86328125,
        "recall": 0.904296875
      },
      {
        "accuracy": 0.5341796875,
        "f1": 0.4657869853670635,
        "hf_subset": "doi_Deva-mal_Mlym",
        "languages": [
          "doi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.4657869853670635,
        "precision": 0.4402510737959956,
        "recall": 0.5341796875
      },
      {
        "accuracy": 0.796875,
        "f1": 0.7531947544642857,
        "hf_subset": "doi_Deva-mar_Deva",
        "languages": [
          "doi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7531947544642857,
        "precision": 0.733837890625,
        "recall": 0.796875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003250238621332371,
        "hf_subset": "doi_Deva-mni_Mtei",
        "languages": [
          "doi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.003250238621332371,
        "precision": 0.0027023199264972738,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.884765625,
        "f1": 0.8529296875000001,
        "hf_subset": "doi_Deva-npi_Deva",
        "languages": [
          "doi-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8529296875000001,
        "precision": 0.8379720052083334,
        "recall": 0.884765625
      },
      {
        "accuracy": 0.4091796875,
        "f1": 0.33673664659992786,
        "hf_subset": "doi_Deva-ory_Orya",
        "languages": [
          "doi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.33673664659992786,
        "precision": 0.31100376674107144,
        "recall": 0.4091796875
      },
      {
        "accuracy": 0.71875,
        "f1": 0.6624674479166666,
        "hf_subset": "doi_Deva-pan_Guru",
        "languages": [
          "doi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6624674479166666,
        "precision": 0.6396507626488095,
        "recall": 0.71875
      },
      {
        "accuracy": 0.7607421875,
        "f1": 0.7080612909226189,
        "hf_subset": "doi_Deva-san_Deva",
        "languages": [
          "doi-Deva",
          "san-Deva"
        ],
        "main_score": 0.7080612909226189,
        "precision": 0.6866629464285714,
        "recall": 0.7607421875
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0005971729561458422,
        "hf_subset": "doi_Deva-sat_Olck",
        "languages": [
          "doi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0005971729561458422,
        "precision": 0.0003239088239505372,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.759765625,
        "f1": 0.7107445126488094,
        "hf_subset": "doi_Deva-snd_Deva",
        "languages": [
          "doi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.7107445126488094,
        "precision": 0.6896902901785714,
        "recall": 0.759765625
      },
      {
        "accuracy": 0.3369140625,
        "f1": 0.2681464477362915,
        "hf_subset": "doi_Deva-tam_Taml",
        "languages": [
          "doi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.2681464477362915,
        "precision": 0.24453318762400794,
        "recall": 0.3369140625
      },
      {
        "accuracy": 0.548828125,
        "f1": 0.4804082961309524,
        "hf_subset": "doi_Deva-tel_Telu",
        "languages": [
          "doi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.4804082961309524,
        "precision": 0.45310872395833335,
        "recall": 0.548828125
      },
      {
        "accuracy": 0.8251953125,
        "f1": 0.7807524181547619,
        "hf_subset": "doi_Deva-urd_Arab",
        "languages": [
          "doi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7807524181547619,
        "precision": 0.7616699218749999,
        "recall": 0.8251953125
      },
      {
        "accuracy": 0.6875,
        "f1": 0.6194754464285714,
        "hf_subset": "eng_Latn-asm_Beng",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ],
        "main_score": 0.6194754464285714,
        "precision": 0.5915279327876983,
        "recall": 0.6875
      },
      {
        "accuracy": 0.8662109375,
        "f1": 0.8298363095238095,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ],
        "main_score": 0.8298363095238095,
        "precision": 0.8144368489583333,
        "recall": 0.8662109375
      },
      {
        "accuracy": 0.2421875,
        "f1": 0.16660495266452297,
        "hf_subset": "eng_Latn-brx_Deva",
        "languages": [
          "eng-Latn",
          "brx-Deva"
        ],
        "main_score": 0.16660495266452297,
        "precision": 0.14489210604933261,
        "recall": 0.2421875
      },
      {
        "accuracy": 0.8203125,
        "f1": 0.7712890625,
        "hf_subset": "eng_Latn-doi_Deva",
        "languages": [
          "eng-Latn",
          "doi-Deva"
        ],
        "main_score": 0.7712890625,
        "precision": 0.7498697916666667,
        "recall": 0.8203125
      },
      {
        "accuracy": 0.654296875,
        "f1": 0.5787992931547619,
        "hf_subset": "eng_Latn-gom_Deva",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ],
        "main_score": 0.5787992931547619,
        "precision": 0.5483258928571428,
        "recall": 0.654296875
      },
      {
        "accuracy": 0.7314453125,
        "f1": 0.6678431919642858,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ],
        "main_score": 0.6678431919642858,
        "precision": 0.6409667968749999,
        "recall": 0.7314453125
      },
      {
        "accuracy": 0.9873046875,
        "f1": 0.9832356770833333,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ],
        "main_score": 0.9832356770833333,
        "precision": 0.9812825520833334,
        "recall": 0.9873046875
      },
      {
        "accuracy": 0.740234375,
        "f1": 0.6768391927083333,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ],
        "main_score": 0.6768391927083333,
        "precision": 0.6502046130952381,
        "recall": 0.740234375
      },
      {
        "accuracy": 0.564453125,
        "f1": 0.48270483856421353,
        "hf_subset": "eng_Latn-kas_Arab",
        "languages": [
          "eng-Latn",
          "kas-Arab"
        ],
        "main_score": 0.48270483856421353,
        "precision": 0.4522728329613095,
        "recall": 0.564453125
      },
      {
        "accuracy": 0.908203125,
        "f1": 0.88154296875,
        "hf_subset": "eng_Latn-mai_Deva",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ],
        "main_score": 0.88154296875,
        "precision": 0.8692545572916666,
        "recall": 0.908203125
      },
      {
        "accuracy": 0.6494140625,
        "f1": 0.5771577380952381,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ],
        "main_score": 0.5771577380952381,
        "precision": 0.5490234375,
        "recall": 0.6494140625
      },
      {
        "accuracy": 0.8583984375,
        "f1": 0.8212076822916666,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ],
        "main_score": 0.8212076822916666,
        "precision": 0.8052339099702381,
        "recall": 0.8583984375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002045161326407663,
        "hf_subset": "eng_Latn-mni_Mtei",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ],
        "main_score": 0.002045161326407663,
        "precision": 0.0015903934737429189,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.8828125,
        "f1": 0.8501813616071429,
        "hf_subset": "eng_Latn-npi_Deva",
        "languages": [
          "eng-Latn",
          "npi-Deva"
        ],
        "main_score": 0.8501813616071429,
        "precision": 0.8351236979166667,
        "recall": 0.8828125
      },
      {
        "accuracy": 0.361328125,
        "f1": 0.2881171218487395,
        "hf_subset": "eng_Latn-ory_Orya",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ],
        "main_score": 0.2881171218487395,
        "precision": 0.2652063146814123,
        "recall": 0.361328125
      },
      {
        "accuracy": 0.6201171875,
        "f1": 0.5479151870265151,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ],
        "main_score": 0.5479151870265151,
        "precision": 0.5204380580357143,
        "recall": 0.6201171875
      },
      {
        "accuracy": 0.8408203125,
        "f1": 0.7991861979166667,
        "hf_subset": "eng_Latn-san_Deva",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ],
        "main_score": 0.7991861979166667,
        "precision": 0.7804524739583334,
        "recall": 0.8408203125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.0060392182411096885,
        "hf_subset": "eng_Latn-sat_Olck",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ],
        "main_score": 0.0060392182411096885,
        "precision": 0.00522318146275501,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.6650390625,
        "f1": 0.5879960317460318,
        "hf_subset": "eng_Latn-snd_Deva",
        "languages": [
          "eng-Latn",
          "snd-Deva"
        ],
        "main_score": 0.5879960317460318,
        "precision": 0.5564177982390873,
        "recall": 0.6650390625
      },
      {
        "accuracy": 0.4208984375,
        "f1": 0.3441802229888168,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ],
        "main_score": 0.3441802229888168,
        "precision": 0.31587146577380953,
        "recall": 0.4208984375
      },
      {
        "accuracy": 0.5703125,
        "f1": 0.49196273561507936,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ],
        "main_score": 0.49196273561507936,
        "precision": 0.46157497829861116,
        "recall": 0.5703125
      },
      {
        "accuracy": 0.9580078125,
        "f1": 0.9444986979166666,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ],
        "main_score": 0.9444986979166666,
        "precision": 0.93798828125,
        "recall": 0.9580078125
      },
      {
        "accuracy": 0.55078125,
        "f1": 0.4872394640949328,
        "hf_subset": "gom_Deva-asm_Beng",
        "languages": [
          "gom-Deva",
          "asm-Beng"
        ],
        "main_score": 0.4872394640949328,
        "precision": 0.4631537543402777,
        "recall": 0.55078125
      },
      {
        "accuracy": 0.6318359375,
        "f1": 0.5737520509004884,
        "hf_subset": "gom_Deva-ben_Beng",
        "languages": [
          "gom-Deva",
          "ben-Beng"
        ],
        "main_score": 0.5737520509004884,
        "precision": 0.5504069010416667,
        "recall": 0.6318359375
      },
      {
        "accuracy": 0.29296875,
        "f1": 0.22510838364109848,
        "hf_subset": "gom_Deva-brx_Deva",
        "languages": [
          "gom-Deva",
          "brx-Deva"
        ],
        "main_score": 0.22510838364109848,
        "precision": 0.20336928836172785,
        "recall": 0.29296875
      },
      {
        "accuracy": 0.69140625,
        "f1": 0.636243644593254,
        "hf_subset": "gom_Deva-doi_Deva",
        "languages": [
          "gom-Deva",
          "doi-Deva"
        ],
        "main_score": 0.636243644593254,
        "precision": 0.6135672433035715,
        "recall": 0.69140625
      },
      {
        "accuracy": 0.6494140625,
        "f1": 0.5858248007417929,
        "hf_subset": "gom_Deva-eng_Latn",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ],
        "main_score": 0.5858248007417929,
        "precision": 0.5613378483495671,
        "recall": 0.6494140625
      },
      {
        "accuracy": 0.6220703125,
        "f1": 0.559726097470238,
        "hf_subset": "gom_Deva-guj_Gujr",
        "languages": [
          "gom-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.559726097470238,
        "precision": 0.5344842819940476,
        "recall": 0.6220703125
      },
      {
        "accuracy": 0.7490234375,
        "f1": 0.7001171029491342,
        "hf_subset": "gom_Deva-hin_Deva",
        "languages": [
          "gom-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7001171029491342,
        "precision": 0.6795084635416666,
        "recall": 0.7490234375
      },
      {
        "accuracy": 0.53125,
        "f1": 0.4657054859203297,
        "hf_subset": "gom_Deva-kan_Knda",
        "languages": [
          "gom-Deva",
          "kan-Knda"
        ],
        "main_score": 0.4657054859203297,
        "precision": 0.44139504334386,
        "recall": 0.53125
      },
      {
        "accuracy": 0.4072265625,
        "f1": 0.3473780071924603,
        "hf_subset": "gom_Deva-kas_Arab",
        "languages": [
          "gom-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3473780071924603,
        "precision": 0.32526622953869044,
        "recall": 0.4072265625
      },
      {
        "accuracy": 0.73828125,
        "f1": 0.6871837797619048,
        "hf_subset": "gom_Deva-mai_Deva",
        "languages": [
          "gom-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6871837797619048,
        "precision": 0.6660225408272282,
        "recall": 0.73828125
      },
      {
        "accuracy": 0.47265625,
        "f1": 0.4116582961309524,
        "hf_subset": "gom_Deva-mal_Mlym",
        "languages": [
          "gom-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.4116582961309524,
        "precision": 0.38897960492198774,
        "recall": 0.47265625
      },
      {
        "accuracy": 0.82421875,
        "f1": 0.7832682291666666,
        "hf_subset": "gom_Deva-mar_Deva",
        "languages": [
          "gom-Deva",
          "mar-Deva"
        ],
        "main_score": 0.7832682291666666,
        "precision": 0.7651963975694445,
        "recall": 0.82421875
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.002038260057894104,
        "hf_subset": "gom_Deva-mni_Mtei",
        "languages": [
          "gom-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002038260057894104,
        "precision": 0.0012083809003916278,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.71484375,
        "f1": 0.6610412374084249,
        "hf_subset": "gom_Deva-npi_Deva",
        "languages": [
          "gom-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6610412374084249,
        "precision": 0.6383572048611111,
        "recall": 0.71484375
      },
      {
        "accuracy": 0.3095703125,
        "f1": 0.2504949748602092,
        "hf_subset": "gom_Deva-ory_Orya",
        "languages": [
          "gom-Deva",
          "ory-Orya"
        ],
        "main_score": 0.2504949748602092,
        "precision": 0.23026194093088623,
        "recall": 0.3095703125
      },
      {
        "accuracy": 0.515625,
        "f1": 0.4541178385416667,
        "hf_subset": "gom_Deva-pan_Guru",
        "languages": [
          "gom-Deva",
          "pan-Guru"
        ],
        "main_score": 0.4541178385416667,
        "precision": 0.4290294828869048,
        "recall": 0.515625
      },
      {
        "accuracy": 0.6630859375,
        "f1": 0.6067134796626983,
        "hf_subset": "gom_Deva-san_Deva",
        "languages": [
          "gom-Deva",
          "san-Deva"
        ],
        "main_score": 0.6067134796626983,
        "precision": 0.5831570095486112,
        "recall": 0.6630859375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004100747378009024,
        "hf_subset": "gom_Deva-sat_Olck",
        "languages": [
          "gom-Deva",
          "sat-Olck"
        ],
        "main_score": 0.004100747378009024,
        "precision": 0.0033423685690457863,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.6005859375,
        "f1": 0.5455157453606443,
        "hf_subset": "gom_Deva-snd_Deva",
        "languages": [
          "gom-Deva",
          "snd-Deva"
        ],
        "main_score": 0.5455157453606443,
        "precision": 0.5234334309895833,
        "recall": 0.6005859375
      },
      {
        "accuracy": 0.3056640625,
        "f1": 0.24033985220508655,
        "hf_subset": "gom_Deva-tam_Taml",
        "languages": [
          "gom-Deva",
          "tam-Taml"
        ],
        "main_score": 0.24033985220508655,
        "precision": 0.21692291174282213,
        "recall": 0.3056640625
      },
      {
        "accuracy": 0.47265625,
        "f1": 0.40518508184523805,
        "hf_subset": "gom_Deva-tel_Telu",
        "languages": [
          "gom-Deva",
          "tel-Telu"
        ],
        "main_score": 0.40518508184523805,
        "precision": 0.3795453136273449,
        "recall": 0.47265625
      },
      {
        "accuracy": 0.607421875,
        "f1": 0.5385068598935787,
        "hf_subset": "gom_Deva-urd_Arab",
        "languages": [
          "gom-Deva",
          "urd-Arab"
        ],
        "main_score": 0.5385068598935787,
        "precision": 0.5117644779265873,
        "recall": 0.607421875
      },
      {
        "accuracy": 0.6572265625,
        "f1": 0.5939639136904762,
        "hf_subset": "guj_Gujr-asm_Beng",
        "languages": [
          "guj-Gujr",
          "asm-Beng"
        ],
        "main_score": 0.5939639136904762,
        "precision": 0.5680361793154762,
        "recall": 0.6572265625
      },
      {
        "accuracy": 0.771484375,
        "f1": 0.7217122395833333,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ],
        "main_score": 0.7217122395833333,
        "precision": 0.7006184895833333,
        "recall": 0.771484375
      },
      {
        "accuracy": 0.27734375,
        "f1": 0.21401522197420633,
        "hf_subset": "guj_Gujr-brx_Deva",
        "languages": [
          "guj-Gujr",
          "brx-Deva"
        ],
        "main_score": 0.21401522197420633,
        "precision": 0.19344848131469228,
        "recall": 0.27734375
      },
      {
        "accuracy": 0.712890625,
        "f1": 0.6564964657738095,
        "hf_subset": "guj_Gujr-doi_Deva",
        "languages": [
          "guj-Gujr",
          "doi-Deva"
        ],
        "main_score": 0.6564964657738095,
        "precision": 0.6320149739583334,
        "recall": 0.712890625
      },
      {
        "accuracy": 0.7099609375,
        "f1": 0.6499699844426406,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ],
        "main_score": 0.6499699844426406,
        "precision": 0.6264020647321429,
        "recall": 0.7099609375
      },
      {
        "accuracy": 0.634765625,
        "f1": 0.5740311879960317,
        "hf_subset": "guj_Gujr-gom_Deva",
        "languages": [
          "guj-Gujr",
          "gom-Deva"
        ],
        "main_score": 0.5740311879960317,
        "precision": 0.5489013671874999,
        "recall": 0.634765625
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8077473958333333,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ],
        "main_score": 0.8077473958333333,
        "precision": 0.7915364583333333,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.6875,
        "f1": 0.6295619419642857,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ],
        "main_score": 0.6295619419642857,
        "precision": 0.6055013020833333,
        "recall": 0.6875
      },
      {
        "accuracy": 0.42578125,
        "f1": 0.355964464680285,
        "hf_subset": "guj_Gujr-kas_Arab",
        "languages": [
          "guj-Gujr",
          "kas-Arab"
        ],
        "main_score": 0.355964464680285,
        "precision": 0.33060244605654765,
        "recall": 0.42578125
      },
      {
        "accuracy": 0.7841796875,
        "f1": 0.7377976190476191,
        "hf_subset": "guj_Gujr-mai_Deva",
        "languages": [
          "guj-Gujr",
          "mai-Deva"
        ],
        "main_score": 0.7377976190476191,
        "precision": 0.7176432291666667,
        "recall": 0.7841796875
      },
      {
        "accuracy": 0.615234375,
        "f1": 0.5532800803796898,
        "hf_subset": "guj_Gujr-mal_Mlym",
        "languages": [
          "guj-Gujr",
          "mal-Mlym"
        ],
        "main_score": 0.5532800803796898,
        "precision": 0.5287446521577381,
        "recall": 0.615234375
      },
      {
        "accuracy": 0.8046875,
        "f1": 0.7617513020833333,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ],
        "main_score": 0.7617513020833333,
        "precision": 0.7426595052083333,
        "recall": 0.8046875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0038285623674374153,
        "hf_subset": "guj_Gujr-mni_Mtei",
        "languages": [
          "guj-Gujr",
          "mni-Mtei"
        ],
        "main_score": 0.0038285623674374153,
        "precision": 0.003100784811054066,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.80078125,
        "f1": 0.7557314918154762,
        "hf_subset": "guj_Gujr-npi_Deva",
        "languages": [
          "guj-Gujr",
          "npi-Deva"
        ],
        "main_score": 0.7557314918154762,
        "precision": 0.7358979724702381,
        "recall": 0.80078125
      },
      {
        "accuracy": 0.462890625,
        "f1": 0.3978583933199476,
        "hf_subset": "guj_Gujr-ory_Orya",
        "languages": [
          "guj-Gujr",
          "ory-Orya"
        ],
        "main_score": 0.3978583933199476,
        "precision": 0.37370566716269843,
        "recall": 0.462890625
      },
      {
        "accuracy": 0.6630859375,
        "f1": 0.6075869605654762,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ],
        "main_score": 0.6075869605654762,
        "precision": 0.5847260974702381,
        "recall": 0.6630859375
      },
      {
        "accuracy": 0.734375,
        "f1": 0.6768415178571429,
        "hf_subset": "guj_Gujr-san_Deva",
        "languages": [
          "guj-Gujr",
          "san-Deva"
        ],
        "main_score": 0.6768415178571429,
        "precision": 0.6530598958333333,
        "recall": 0.734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.003689010160168166,
        "hf_subset": "guj_Gujr-sat_Olck",
        "languages": [
          "guj-Gujr",
          "sat-Olck"
        ],
        "main_score": 0.003689010160168166,
        "precision": 0.0027215185366808083,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.615234375,
        "f1": 0.5509928385416667,
        "hf_subset": "guj_Gujr-snd_Deva",
        "languages": [
          "guj-Gujr",
          "snd-Deva"
        ],
        "main_score": 0.5509928385416667,
        "precision": 0.5234956287202381,
        "recall": 0.615234375
      },
      {
        "accuracy": 0.34765625,
        "f1": 0.2797735305059524,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ],
        "main_score": 0.2797735305059524,
        "precision": 0.25413798983134916,
        "recall": 0.34765625
      },
      {
        "accuracy": 0.625,
        "f1": 0.5602422805059524,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ],
        "main_score": 0.5602422805059524,
        "precision": 0.5341099330357143,
        "recall": 0.625
      },
      {
        "accuracy": 0.7275390625,
        "f1": 0.6680385044642857,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ],
        "main_score": 0.6680385044642857,
        "precision": 0.6433268229166667,
        "recall": 0.7275390625
      },
      {
        "accuracy": 0.775390625,
        "f1": 0.718173363095238,
        "hf_subset": "hin_Deva-asm_Beng",
        "languages": [
          "hin-Deva",
          "asm-Beng"
        ],
        "main_score": 0.718173363095238,
        "precision": 0.6943196614583333,
        "recall": 0.775390625
      },
      {
        "accuracy": 0.9208984375,
        "f1": 0.8957356770833333,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8957356770833333,
        "precision": 0.883544921875,
        "recall": 0.9208984375
      },
      {
        "accuracy": 0.314453125,
        "f1": 0.23810596584291072,
        "hf_subset": "hin_Deva-brx_Deva",
        "languages": [
          "hin-Deva",
          "brx-Deva"
        ],
        "main_score": 0.23810596584291072,
        "precision": 0.21487323711444806,
        "recall": 0.314453125
      },
      {
        "accuracy": 0.916015625,
        "f1": 0.89052734375,
        "hf_subset": "hin_Deva-doi_Deva",
        "languages": [
          "hin-Deva",
          "doi-Deva"
        ],
        "main_score": 0.89052734375,
        "precision": 0.8786946614583333,
        "recall": 0.916015625
      },
      {
        "accuracy": 0.9892578125,
        "f1": 0.9856770833333333,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ],
        "main_score": 0.9856770833333333,
        "precision": 0.98388671875,
        "recall": 0.9892578125
      },
      {
        "accuracy": 0.740234375,
        "f1": 0.6845052083333334,
        "hf_subset": "hin_Deva-gom_Deva",
        "languages": [
          "hin-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6845052083333334,
        "precision": 0.6606166294642857,
        "recall": 0.740234375
      },
      {
        "accuracy": 0.8291015625,
        "f1": 0.7861839657738094,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7861839657738094,
        "precision": 0.76728515625,
        "recall": 0.8291015625
      },
      {
        "accuracy": 0.8115234375,
        "f1": 0.7642261059253247,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7642261059253247,
        "precision": 0.7435872395833334,
        "recall": 0.8115234375
      },
      {
        "accuracy": 0.5908203125,
        "f1": 0.520503162202381,
        "hf_subset": "hin_Deva-kas_Arab",
        "languages": [
          "hin-Deva",
          "kas-Arab"
        ],
        "main_score": 0.520503162202381,
        "precision": 0.4947044735863096,
        "recall": 0.5908203125
      },
      {
        "accuracy": 0.96484375,
        "f1": 0.9534505208333333,
        "hf_subset": "hin_Deva-mai_Deva",
        "languages": [
          "hin-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9534505208333333,
        "precision": 0.9479166666666667,
        "recall": 0.96484375
      },
      {
        "accuracy": 0.7119140625,
        "f1": 0.6537582859848485,
        "hf_subset": "hin_Deva-mal_Mlym",
        "languages": [
          "hin-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.6537582859848485,
        "precision": 0.6301726810515873,
        "recall": 0.7119140625
      },
      {
        "accuracy": 0.9365234375,
        "f1": 0.9171735491071429,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ],
        "main_score": 0.9171735491071429,
        "precision": 0.907958984375,
        "recall": 0.9365234375
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.002688822522513219,
        "hf_subset": "hin_Deva-mni_Mtei",
        "languages": [
          "hin-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.002688822522513219,
        "precision": 0.0016945923116636493,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.953125,
        "f1": 0.9384765625,
        "hf_subset": "hin_Deva-npi_Deva",
        "languages": [
          "hin-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9384765625,
        "precision": 0.9314778645833334,
        "recall": 0.953125
      },
      {
        "accuracy": 0.5107421875,
        "f1": 0.435494242086039,
        "hf_subset": "hin_Deva-ory_Orya",
        "languages": [
          "hin-Deva",
          "ory-Orya"
        ],
        "main_score": 0.435494242086039,
        "precision": 0.40900375124007937,
        "recall": 0.5107421875
      },
      {
        "accuracy": 0.744140625,
        "f1": 0.687504650297619,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ],
        "main_score": 0.687504650297619,
        "precision": 0.6642252604166666,
        "recall": 0.744140625
      },
      {
        "accuracy": 0.9013671875,
        "f1": 0.87431640625,
        "hf_subset": "hin_Deva-san_Deva",
        "languages": [
          "hin-Deva",
          "san-Deva"
        ],
        "main_score": 0.87431640625,
        "precision": 0.8621419270833334,
        "recall": 0.9013671875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0023022761276701048,
        "hf_subset": "hin_Deva-sat_Olck",
        "languages": [
          "hin-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0023022761276701048,
        "precision": 0.0018117231430736366,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.7646484375,
        "f1": 0.7077225942460317,
        "hf_subset": "hin_Deva-snd_Deva",
        "languages": [
          "hin-Deva",
          "snd-Deva"
        ],
        "main_score": 0.7077225942460317,
        "precision": 0.6837809244791667,
        "recall": 0.7646484375
      },
      {
        "accuracy": 0.4853515625,
        "f1": 0.4132533482142857,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ],
        "main_score": 0.4132533482142857,
        "precision": 0.3851097470238095,
        "recall": 0.4853515625
      },
      {
        "accuracy": 0.685546875,
        "f1": 0.6211712549603174,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ],
        "main_score": 0.6211712549603174,
        "precision": 0.5950764973958333,
        "recall": 0.685546875
      },
      {
        "accuracy": 0.9658203125,
        "f1": 0.9544270833333334,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ],
        "main_score": 0.9544270833333334,
        "precision": 0.94873046875,
        "recall": 0.9658203125
      },
      {
        "accuracy": 0.5849609375,
        "f1": 0.5185570126488095,
        "hf_subset": "kan_Knda-asm_Beng",
        "languages": [
          "kan-Knda",
          "asm-Beng"
        ],
        "main_score": 0.5185570126488095,
        "precision": 0.49216424851190477,
        "recall": 0.5849609375
      },
      {
        "accuracy": 0.7431640625,
        "f1": 0.686235119047619,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ],
        "main_score": 0.686235119047619,
        "precision": 0.66142578125,
        "recall": 0.7431640625
      },
      {
        "accuracy": 0.189453125,
        "f1": 0.13617588095384148,
        "hf_subset": "kan_Knda-brx_Deva",
        "languages": [
          "kan-Knda",
          "brx-Deva"
        ],
        "main_score": 0.13617588095384148,
        "precision": 0.12027833819826007,
        "recall": 0.189453125
      },
      {
        "accuracy": 0.607421875,
        "f1": 0.5410443018353175,
        "hf_subset": "kan_Knda-doi_Deva",
        "languages": [
          "kan-Knda",
          "doi-Deva"
        ],
        "main_score": 0.5410443018353175,
        "precision": 0.5152680896577381,
        "recall": 0.607421875
      },
      {
        "accuracy": 0.7060546875,
        "f1": 0.6431485615079364,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ],
        "main_score": 0.6431485615079364,
        "precision": 0.6188038659474207,
        "recall": 0.7060546875
      },
      {
        "accuracy": 0.5341796875,
        "f1": 0.4644011966765873,
        "hf_subset": "kan_Knda-gom_Deva",
        "languages": [
          "kan-Knda",
          "gom-Deva"
        ],
        "main_score": 0.4644011966765873,
        "precision": 0.4379162016369047,
        "recall": 0.5341796875
      },
      {
        "accuracy": 0.6953125,
        "f1": 0.6381184895833334,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ],
        "main_score": 0.6381184895833334,
        "precision": 0.612939453125,
        "recall": 0.6953125
      },
      {
        "accuracy": 0.83203125,
        "f1": 0.7900553385416667,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ],
        "main_score": 0.7900553385416667,
        "precision": 0.7710379464285715,
        "recall": 0.83203125
      },
      {
        "accuracy": 0.3544921875,
        "f1": 0.2922337644993895,
        "hf_subset": "kan_Knda-kas_Arab",
        "languages": [
          "kan-Knda",
          "kas-Arab"
        ],
        "main_score": 0.2922337644993895,
        "precision": 0.271239012181395,
        "recall": 0.3544921875
      },
      {
        "accuracy": 0.716796875,
        "f1": 0.6601748511904761,
        "hf_subset": "kan_Knda-mai_Deva",
        "languages": [
          "kan-Knda",
          "mai-Deva"
        ],
        "main_score": 0.6601748511904761,
        "precision": 0.635888671875,
        "recall": 0.716796875
      },
      {
        "accuracy": 0.673828125,
        "f1": 0.607963634672619,
        "hf_subset": "kan_Knda-mal_Mlym",
        "languages": [
          "kan-Knda",
          "mal-Mlym"
        ],
        "main_score": 0.607963634672619,
        "precision": 0.579403831845238,
        "recall": 0.673828125
      },
      {
        "accuracy": 0.7568359375,
        "f1": 0.7054361979166666,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ],
        "main_score": 0.7054361979166666,
        "precision": 0.68388671875,
        "recall": 0.7568359375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.002208641235473983,
        "hf_subset": "kan_Knda-mni_Mtei",
        "languages": [
          "kan-Knda",
          "mni-Mtei"
        ],
        "main_score": 0.002208641235473983,
        "precision": 0.0017843896554834056,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.705078125,
        "f1": 0.6420084635416667,
        "hf_subset": "kan_Knda-npi_Deva",
        "languages": [
          "kan-Knda",
          "npi-Deva"
        ],
        "main_score": 0.6420084635416667,
        "precision": 0.615438988095238,
        "recall": 0.705078125
      },
      {
        "accuracy": 0.42578125,
        "f1": 0.3617575024801587,
        "hf_subset": "kan_Knda-ory_Orya",
        "languages": [
          "kan-Knda",
          "ory-Orya"
        ],
        "main_score": 0.3617575024801587,
        "precision": 0.3382033331252081,
        "recall": 0.42578125
      },
      {
        "accuracy": 0.5458984375,
        "f1": 0.4762130230880231,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ],
        "main_score": 0.4762130230880231,
        "precision": 0.44905722261679293,
        "recall": 0.5458984375
      },
      {
        "accuracy": 0.7734375,
        "f1": 0.7211449032738095,
        "hf_subset": "kan_Knda-san_Deva",
        "languages": [
          "kan-Knda",
          "san-Deva"
        ],
        "main_score": 0.7211449032738095,
        "precision": 0.697705078125,
        "recall": 0.7734375
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0030514106738914037,
        "hf_subset": "kan_Knda-sat_Olck",
        "languages": [
          "kan-Knda",
          "sat-Olck"
        ],
        "main_score": 0.0030514106738914037,
        "precision": 0.0020057703187902776,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.46484375,
        "f1": 0.39957002983485057,
        "hf_subset": "kan_Knda-snd_Deva",
        "languages": [
          "kan-Knda",
          "snd-Deva"
        ],
        "main_score": 0.39957002983485057,
        "precision": 0.37573879164455337,
        "recall": 0.46484375
      },
      {
        "accuracy": 0.458984375,
        "f1": 0.39271692933802305,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ],
        "main_score": 0.39271692933802305,
        "precision": 0.3674793061755952,
        "recall": 0.458984375
      },
      {
        "accuracy": 0.732421875,
        "f1": 0.6791713169642857,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ],
        "main_score": 0.6791713169642857,
        "precision": 0.6568033854166667,
        "recall": 0.732421875
      },
      {
        "accuracy": 0.6943359375,
        "f1": 0.6356554524034992,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ],
        "main_score": 0.6356554524034992,
        "precision": 0.6112967354910714,
        "recall": 0.6943359375
      },
      {
        "accuracy": 0.42578125,
        "f1": 0.3548572358630952,
        "hf_subset": "kas_Arab-asm_Beng",
        "languages": [
          "kas-Arab",
          "asm-Beng"
        ],
        "main_score": 0.3548572358630952,
        "precision": 0.32840246775793647,
        "recall": 0.42578125
      },
      {
        "accuracy": 0.50390625,
        "f1": 0.42494828305375176,
        "hf_subset": "kas_Arab-ben_Beng",
        "languages": [
          "kas-Arab",
          "ben-Beng"
        ],
        "main_score": 0.42494828305375176,
        "precision": 0.39480484250992065,
        "recall": 0.50390625
      },
      {
        "accuracy": 0.19140625,
        "f1": 0.13177878787368677,
        "hf_subset": "kas_Arab-brx_Deva",
        "languages": [
          "kas-Arab",
          "brx-Deva"
        ],
        "main_score": 0.13177878787368677,
        "precision": 0.11453924172558527,
        "recall": 0.19140625
      },
      {
        "accuracy": 0.55859375,
        "f1": 0.4970315600198413,
        "hf_subset": "kas_Arab-doi_Deva",
        "languages": [
          "kas-Arab",
          "doi-Deva"
        ],
        "main_score": 0.4970315600198413,
        "precision": 0.47269151475694443,
        "recall": 0.55859375
      },
      {
        "accuracy": 0.599609375,
        "f1": 0.5267996651785715,
        "hf_subset": "kas_Arab-eng_Latn",
        "languages": [
          "kas-Arab",
          "eng-Latn"
        ],
        "main_score": 0.5267996651785715,
        "precision": 0.4993268694196428,
        "recall": 0.599609375
      },
      {
        "accuracy": 0.40625,
        "f1": 0.3355633624188311,
        "hf_subset": "kas_Arab-gom_Deva",
        "languages": [
          "kas-Arab",
          "gom-Deva"
        ],
        "main_score": 0.3355633624188311,
        "precision": 0.3101592905792125,
        "recall": 0.40625
      },
      {
        "accuracy": 0.453125,
        "f1": 0.3836278521825397,
        "hf_subset": "kas_Arab-guj_Gujr",
        "languages": [
          "kas-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.3836278521825397,
        "precision": 0.3567785838293651,
        "recall": 0.453125
      },
      {
        "accuracy": 0.626953125,
        "f1": 0.5589727492559524,
        "hf_subset": "kas_Arab-hin_Deva",
        "languages": [
          "kas-Arab",
          "hin-Deva"
        ],
        "main_score": 0.5589727492559524,
        "precision": 0.5317530071924603,
        "recall": 0.626953125
      },
      {
        "accuracy": 0.3505859375,
        "f1": 0.2717050256601038,
        "hf_subset": "kas_Arab-kan_Knda",
        "languages": [
          "kas-Arab",
          "kan-Knda"
        ],
        "main_score": 0.2717050256601038,
        "precision": 0.24368024553571427,
        "recall": 0.3505859375
      },
      {
        "accuracy": 0.6005859375,
        "f1": 0.5333705357142857,
        "hf_subset": "kas_Arab-mai_Deva",
        "languages": [
          "kas-Arab",
          "mai-Deva"
        ],
        "main_score": 0.5333705357142857,
        "precision": 0.5058919270833333,
        "recall": 0.6005859375
      },
      {
        "accuracy": 0.3779296875,
        "f1": 0.3058733258928571,
        "hf_subset": "kas_Arab-mal_Mlym",
        "languages": [
          "kas-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.3058733258928571,
        "precision": 0.2801826970772283,
        "recall": 0.3779296875
      },
      {
        "accuracy": 0.5166015625,
        "f1": 0.44093361066017317,
        "hf_subset": "kas_Arab-mar_Deva",
        "languages": [
          "kas-Arab",
          "mar-Deva"
        ],
        "main_score": 0.44093361066017317,
        "precision": 0.4119109623015873,
        "recall": 0.5166015625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0023859910004211476,
        "hf_subset": "kas_Arab-mni_Mtei",
        "languages": [
          "kas-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0023859910004211476,
        "precision": 0.0018671782239897644,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.5810546875,
        "f1": 0.5114955357142857,
        "hf_subset": "kas_Arab-npi_Deva",
        "languages": [
          "kas-Arab",
          "npi-Deva"
        ],
        "main_score": 0.5114955357142857,
        "precision": 0.48337673611111115,
        "recall": 0.5810546875
      },
      {
        "accuracy": 0.2275390625,
        "f1": 0.16902056277056277,
        "hf_subset": "kas_Arab-ory_Orya",
        "languages": [
          "kas-Arab",
          "ory-Orya"
        ],
        "main_score": 0.16902056277056277,
        "precision": 0.1500861009650072,
        "recall": 0.2275390625
      },
      {
        "accuracy": 0.4287109375,
        "f1": 0.3607688427024365,
        "hf_subset": "kas_Arab-pan_Guru",
        "languages": [
          "kas-Arab",
          "pan-Guru"
        ],
        "main_score": 0.3607688427024365,
        "precision": 0.33611653645833334,
        "recall": 0.4287109375
      },
      {
        "accuracy": 0.4892578125,
        "f1": 0.40978584674873736,
        "hf_subset": "kas_Arab-san_Deva",
        "languages": [
          "kas-Arab",
          "san-Deva"
        ],
        "main_score": 0.40978584674873736,
        "precision": 0.3801784343044109,
        "recall": 0.4892578125
      },
      {
        "accuracy": 0.0146484375,
        "f1": 0.0040793968556405895,
        "hf_subset": "kas_Arab-sat_Olck",
        "languages": [
          "kas-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0040793968556405895,
        "precision": 0.003231913840387857,
        "recall": 0.0146484375
      },
      {
        "accuracy": 0.4501953125,
        "f1": 0.38263360445977634,
        "hf_subset": "kas_Arab-snd_Deva",
        "languages": [
          "kas-Arab",
          "snd-Deva"
        ],
        "main_score": 0.38263360445977634,
        "precision": 0.3576423766121032,
        "recall": 0.4501953125
      },
      {
        "accuracy": 0.23046875,
        "f1": 0.17262604474518536,
        "hf_subset": "kas_Arab-tam_Taml",
        "languages": [
          "kas-Arab",
          "tam-Taml"
        ],
        "main_score": 0.17262604474518536,
        "precision": 0.1560501076614358,
        "recall": 0.23046875
      },
      {
        "accuracy": 0.357421875,
        "f1": 0.28781932043650793,
        "hf_subset": "kas_Arab-tel_Telu",
        "languages": [
          "kas-Arab",
          "tel-Telu"
        ],
        "main_score": 0.28781932043650793,
        "precision": 0.2617857917906746,
        "recall": 0.357421875
      },
      {
        "accuracy": 0.8310546875,
        "f1": 0.7891322544642857,
        "hf_subset": "kas_Arab-urd_Arab",
        "languages": [
          "kas-Arab",
          "urd-Arab"
        ],
        "main_score": 0.7891322544642857,
        "precision": 0.770263671875,
        "recall": 0.8310546875
      },
      {
        "accuracy": 0.75,
        "f1": 0.6915550595238095,
        "hf_subset": "mai_Deva-asm_Beng",
        "languages": [
          "mai-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6915550595238095,
        "precision": 0.6658854166666667,
        "recall": 0.75
      },
      {
        "accuracy": 0.869140625,
        "f1": 0.8345377604166666,
        "hf_subset": "mai_Deva-ben_Beng",
        "languages": [
          "mai-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8345377604166666,
        "precision": 0.8191731770833333,
        "recall": 0.869140625
      },
      {
        "accuracy": 0.3095703125,
        "f1": 0.2424986496947513,
        "hf_subset": "mai_Deva-brx_Deva",
        "languages": [
          "mai-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2424986496947513,
        "precision": 0.22132490854414683,
        "recall": 0.3095703125
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8667317708333333,
        "hf_subset": "mai_Deva-doi_Deva",
        "languages": [
          "mai-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8667317708333333,
        "precision": 0.8537923177083333,
        "recall": 0.8955078125
      },
      {
        "accuracy": 0.919921875,
        "f1": 0.8957356770833333,
        "hf_subset": "mai_Deva-eng_Latn",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8957356770833333,
        "precision": 0.8843912760416667,
        "recall": 0.919921875
      },
      {
        "accuracy": 0.740234375,
        "f1": 0.6863955543154763,
        "hf_subset": "mai_Deva-gom_Deva",
        "languages": [
          "mai-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6863955543154763,
        "precision": 0.6636486235119048,
        "recall": 0.740234375
      },
      {
        "accuracy": 0.7919921875,
        "f1": 0.7453334263392857,
        "hf_subset": "mai_Deva-guj_Gujr",
        "languages": [
          "mai-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.7453334263392857,
        "precision": 0.7252697172619047,
        "recall": 0.7919921875
      },
      {
        "accuracy": 0.978515625,
        "f1": 0.9715169270833334,
        "hf_subset": "mai_Deva-hin_Deva",
        "languages": [
          "mai-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9715169270833334,
        "precision": 0.9680989583333334,
        "recall": 0.978515625
      },
      {
        "accuracy": 0.7099609375,
        "f1": 0.6509889632936507,
        "hf_subset": "mai_Deva-kan_Knda",
        "languages": [
          "mai-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6509889632936507,
        "precision": 0.6265706380208333,
        "recall": 0.7099609375
      },
      {
        "accuracy": 0.587890625,
        "f1": 0.5140144469246031,
        "hf_subset": "mai_Deva-kas_Arab",
        "languages": [
          "mai-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5140144469246031,
        "precision": 0.4858960348462302,
        "recall": 0.587890625
      },
      {
        "accuracy": 0.5986328125,
        "f1": 0.5327397157963564,
        "hf_subset": "mai_Deva-mal_Mlym",
        "languages": [
          "mai-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5327397157963564,
        "precision": 0.5067014663938492,
        "recall": 0.5986328125
      },
      {
        "accuracy": 0.8955078125,
        "f1": 0.8674339657738095,
        "hf_subset": "mai_Deva-mar_Deva",
        "languages": [
          "mai-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8674339657738095,
        "precision": 0.8544921875,
        "recall": 0.8955078125
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0028749527985223898,
        "hf_subset": "mai_Deva-mni_Mtei",
        "languages": [
          "mai-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0028749527985223898,
        "precision": 0.0021861244321724664,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.94921875,
        "f1": 0.9327799479166667,
        "hf_subset": "mai_Deva-npi_Deva",
        "languages": [
          "mai-Deva",
          "npi-Deva"
        ],
        "main_score": 0.9327799479166667,
        "precision": 0.9246419270833334,
        "recall": 0.94921875
      },
      {
        "accuracy": 0.490234375,
        "f1": 0.42167491796398043,
        "hf_subset": "mai_Deva-ory_Orya",
        "languages": [
          "mai-Deva",
          "ory-Orya"
        ],
        "main_score": 0.42167491796398043,
        "precision": 0.39565933469742065,
        "recall": 0.490234375
      },
      {
        "accuracy": 0.671875,
        "f1": 0.6077683221726191,
        "hf_subset": "mai_Deva-pan_Guru",
        "languages": [
          "mai-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6077683221726191,
        "precision": 0.5813081287202381,
        "recall": 0.671875
      },
      {
        "accuracy": 0.853515625,
        "f1": 0.81337890625,
        "hf_subset": "mai_Deva-san_Deva",
        "languages": [
          "mai-Deva",
          "san-Deva"
        ],
        "main_score": 0.81337890625,
        "precision": 0.7951985677083333,
        "recall": 0.853515625
      },
      {
        "accuracy": 0.01171875,
        "f1": 0.0037673603681672944,
        "hf_subset": "mai_Deva-sat_Olck",
        "languages": [
          "mai-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0037673603681672944,
        "precision": 0.00280986759839639,
        "recall": 0.01171875
      },
      {
        "accuracy": 0.716796875,
        "f1": 0.6598028273809524,
        "hf_subset": "mai_Deva-snd_Deva",
        "languages": [
          "mai-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6598028273809524,
        "precision": 0.636083984375,
        "recall": 0.716796875
      },
      {
        "accuracy": 0.37109375,
        "f1": 0.301593501984127,
        "hf_subset": "mai_Deva-tam_Taml",
        "languages": [
          "mai-Deva",
          "tam-Taml"
        ],
        "main_score": 0.301593501984127,
        "precision": 0.276258293030754,
        "recall": 0.37109375
      },
      {
        "accuracy": 0.611328125,
        "f1": 0.5409094432043651,
        "hf_subset": "mai_Deva-tel_Telu",
        "languages": [
          "mai-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5409094432043651,
        "precision": 0.5117059616815476,
        "recall": 0.611328125
      },
      {
        "accuracy": 0.8828125,
        "f1": 0.8494954427083333,
        "hf_subset": "mai_Deva-urd_Arab",
        "languages": [
          "mai-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8494954427083333,
        "precision": 0.8342866443452381,
        "recall": 0.8828125
      },
      {
        "accuracy": 0.5361328125,
        "f1": 0.462975105406746,
        "hf_subset": "mal_Mlym-asm_Beng",
        "languages": [
          "mal-Mlym",
          "asm-Beng"
        ],
        "main_score": 0.462975105406746,
        "precision": 0.43497837611607143,
        "recall": 0.5361328125
      },
      {
        "accuracy": 0.65625,
        "f1": 0.5936360677083333,
        "hf_subset": "mal_Mlym-ben_Beng",
        "languages": [
          "mal-Mlym",
          "ben-Beng"
        ],
        "main_score": 0.5936360677083333,
        "precision": 0.5693289620535714,
        "recall": 0.65625
      },
      {
        "accuracy": 0.220703125,
        "f1": 0.1592643088248557,
        "hf_subset": "mal_Mlym-brx_Deva",
        "languages": [
          "mal-Mlym",
          "brx-Deva"
        ],
        "main_score": 0.1592643088248557,
        "precision": 0.139129577020202,
        "recall": 0.220703125
      },
      {
        "accuracy": 0.55859375,
        "f1": 0.48682875826430516,
        "hf_subset": "mal_Mlym-doi_Deva",
        "languages": [
          "mal-Mlym",
          "doi-Deva"
        ],
        "main_score": 0.48682875826430516,
        "precision": 0.45874372209821435,
        "recall": 0.55859375
      },
      {
        "accuracy": 0.650390625,
        "f1": 0.5776732165404039,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ],
        "main_score": 0.5776732165404039,
        "precision": 0.5481058139993686,
        "recall": 0.650390625
      },
      {
        "accuracy": 0.4765625,
        "f1": 0.4103724888392857,
        "hf_subset": "mal_Mlym-gom_Deva",
        "languages": [
          "mal-Mlym",
          "gom-Deva"
        ],
        "main_score": 0.4103724888392857,
        "precision": 0.384321521577381,
        "recall": 0.4765625
      },
      {
        "accuracy": 0.6005859375,
        "f1": 0.5364141555059524,
        "hf_subset": "mal_Mlym-guj_Gujr",
        "languages": [
          "mal-Mlym",
          "guj-Gujr"
        ],
        "main_score": 0.5364141555059524,
        "precision": 0.5102868810876623,
        "recall": 0.6005859375
      },
      {
        "accuracy": 0.7099609375,
        "f1": 0.653467642383658,
        "hf_subset": "mal_Mlym-hin_Deva",
        "languages": [
          "mal-Mlym",
          "hin-Deva"
        ],
        "main_score": 0.653467642383658,
        "precision": 0.6311422681051587,
        "recall": 0.7099609375
      },
      {
        "accuracy": 0.666015625,
        "f1": 0.5990466889880952,
        "hf_subset": "mal_Mlym-kan_Knda",
        "languages": [
          "mal-Mlym",
          "kan-Knda"
        ],
        "main_score": 0.5990466889880952,
        "precision": 0.5713076636904761,
        "recall": 0.666015625
      },
      {
        "accuracy": 0.37109375,
        "f1": 0.310380965605575,
        "hf_subset": "mal_Mlym-kas_Arab",
        "languages": [
          "mal-Mlym",
          "kas-Arab"
        ],
        "main_score": 0.310380965605575,
        "precision": 0.28958030359397546,
        "recall": 0.37109375
      },
      {
        "accuracy": 0.5927734375,
        "f1": 0.5183314732142856,
        "hf_subset": "mal_Mlym-mai_Deva",
        "languages": [
          "mal-Mlym",
          "mai-Deva"
        ],
        "main_score": 0.5183314732142856,
        "precision": 0.48783756933170996,
        "recall": 0.5927734375
      },
      {
        "accuracy": 0.62890625,
        "f1": 0.5676881820436508,
        "hf_subset": "mal_Mlym-mar_Deva",
        "languages": [
          "mal-Mlym",
          "mar-Deva"
        ],
        "main_score": 0.5676881820436508,
        "precision": 0.5430094401041667,
        "recall": 0.62890625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.002609530362215909,
        "hf_subset": "mal_Mlym-mni_Mtei",
        "languages": [
          "mal-Mlym",
          "mni-Mtei"
        ],
        "main_score": 0.002609530362215909,
        "precision": 0.002022349167188805,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.62109375,
        "f1": 0.5500620744273088,
        "hf_subset": "mal_Mlym-npi_Deva",
        "languages": [
          "mal-Mlym",
          "npi-Deva"
        ],
        "main_score": 0.5500620744273088,
        "precision": 0.521078636532738,
        "recall": 0.62109375
      },
      {
        "accuracy": 0.3662109375,
        "f1": 0.29974268353174605,
        "hf_subset": "mal_Mlym-ory_Orya",
        "languages": [
          "mal-Mlym",
          "ory-Orya"
        ],
        "main_score": 0.29974268353174605,
        "precision": 0.2769225105406746,
        "recall": 0.3662109375
      },
      {
        "accuracy": 0.4931640625,
        "f1": 0.4212625915750915,
        "hf_subset": "mal_Mlym-pan_Guru",
        "languages": [
          "mal-Mlym",
          "pan-Guru"
        ],
        "main_score": 0.4212625915750915,
        "precision": 0.393592277405754,
        "recall": 0.4931640625
      },
      {
        "accuracy": 0.6611328125,
        "f1": 0.5964239211309523,
        "hf_subset": "mal_Mlym-san_Deva",
        "languages": [
          "mal-Mlym",
          "san-Deva"
        ],
        "main_score": 0.5964239211309523,
        "precision": 0.570166015625,
        "recall": 0.6611328125
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.002641639825092964,
        "hf_subset": "mal_Mlym-sat_Olck",
        "languages": [
          "mal-Mlym",
          "sat-Olck"
        ],
        "main_score": 0.002641639825092964,
        "precision": 0.0020417843703719528,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.4267578125,
        "f1": 0.3608943655086233,
        "hf_subset": "mal_Mlym-snd_Deva",
        "languages": [
          "mal-Mlym",
          "snd-Deva"
        ],
        "main_score": 0.3608943655086233,
        "precision": 0.3363664899553571,
        "recall": 0.4267578125
      },
      {
        "accuracy": 0.4765625,
        "f1": 0.40577799479166665,
        "hf_subset": "mal_Mlym-tam_Taml",
        "languages": [
          "mal-Mlym",
          "tam-Taml"
        ],
        "main_score": 0.40577799479166665,
        "precision": 0.37788473462301586,
        "recall": 0.4765625
      },
      {
        "accuracy": 0.609375,
        "f1": 0.546733165922619,
        "hf_subset": "mal_Mlym-tel_Telu",
        "languages": [
          "mal-Mlym",
          "tel-Telu"
        ],
        "main_score": 0.546733165922619,
        "precision": 0.5215696304563492,
        "recall": 0.609375
      },
      {
        "accuracy": 0.6337890625,
        "f1": 0.5699459015376984,
        "hf_subset": "mal_Mlym-urd_Arab",
        "languages": [
          "mal-Mlym",
          "urd-Arab"
        ],
        "main_score": 0.5699459015376984,
        "precision": 0.5447765531994048,
        "recall": 0.6337890625
      },
      {
        "accuracy": 0.7001953125,
        "f1": 0.6437383742559524,
        "hf_subset": "mar_Deva-asm_Beng",
        "languages": [
          "mar-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6437383742559524,
        "precision": 0.6204031808035714,
        "recall": 0.7001953125
      },
      {
        "accuracy": 0.8544921875,
        "f1": 0.8195172991071429,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8195172991071429,
        "precision": 0.803662109375,
        "recall": 0.8544921875
      },
      {
        "accuracy": 0.296875,
        "f1": 0.22865700551504417,
        "hf_subset": "mar_Deva-brx_Deva",
        "languages": [
          "mar-Deva",
          "brx-Deva"
        ],
        "main_score": 0.22865700551504417,
        "precision": 0.2073571583581349,
        "recall": 0.296875
      },
      {
        "accuracy": 0.7978515625,
        "f1": 0.7473307291666667,
        "hf_subset": "mar_Deva-doi_Deva",
        "languages": [
          "mar-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7473307291666667,
        "precision": 0.7248046875,
        "recall": 0.7978515625
      },
      {
        "accuracy": 0.8701171875,
        "f1": 0.8329613095238095,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8329613095238095,
        "precision": 0.8159505208333333,
        "recall": 0.8701171875
      },
      {
        "accuracy": 0.8203125,
        "f1": 0.7749348958333333,
        "hf_subset": "mar_Deva-gom_Deva",
        "languages": [
          "mar-Deva",
          "gom-Deva"
        ],
        "main_score": 0.7749348958333333,
        "precision": 0.754345703125,
        "recall": 0.8203125
      },
      {
        "accuracy": 0.787109375,
        "f1": 0.739018322172619,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.739018322172619,
        "precision": 0.7176199776785714,
        "recall": 0.787109375
      },
      {
        "accuracy": 0.94140625,
        "f1": 0.9248046875,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9248046875,
        "precision": 0.9168294270833333,
        "recall": 0.94140625
      },
      {
        "accuracy": 0.7783203125,
        "f1": 0.7285993303571427,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ],
        "main_score": 0.7285993303571427,
        "precision": 0.7072102864583334,
        "recall": 0.7783203125
      },
      {
        "accuracy": 0.4892578125,
        "f1": 0.41524832589285715,
        "hf_subset": "mar_Deva-kas_Arab",
        "languages": [
          "mar-Deva",
          "kas-Arab"
        ],
        "main_score": 0.41524832589285715,
        "precision": 0.38878813244047616,
        "recall": 0.4892578125
      },
      {
        "accuracy": 0.8994140625,
        "f1": 0.8709170386904761,
        "hf_subset": "mar_Deva-mai_Deva",
        "languages": [
          "mar-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8709170386904761,
        "precision": 0.8578287760416666,
        "recall": 0.8994140625
      },
      {
        "accuracy": 0.6318359375,
        "f1": 0.5719190585889805,
        "hf_subset": "mar_Deva-mal_Mlym",
        "languages": [
          "mar-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5719190585889805,
        "precision": 0.5464692615327381,
        "recall": 0.6318359375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0021594597924774156,
        "hf_subset": "mar_Deva-mni_Mtei",
        "languages": [
          "mar-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0021594597924774156,
        "precision": 0.001753203268442016,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.9052734375,
        "f1": 0.8766927083333333,
        "hf_subset": "mar_Deva-npi_Deva",
        "languages": [
          "mar-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8766927083333333,
        "precision": 0.8631998697916666,
        "recall": 0.9052734375
      },
      {
        "accuracy": 0.435546875,
        "f1": 0.362955136481676,
        "hf_subset": "mar_Deva-ory_Orya",
        "languages": [
          "mar-Deva",
          "ory-Orya"
        ],
        "main_score": 0.362955136481676,
        "precision": 0.33716614738343254,
        "recall": 0.435546875
      },
      {
        "accuracy": 0.6591796875,
        "f1": 0.596244884672619,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ],
        "main_score": 0.596244884672619,
        "precision": 0.5703706287202381,
        "recall": 0.6591796875
      },
      {
        "accuracy": 0.8447265625,
        "f1": 0.8083682105654761,
        "hf_subset": "mar_Deva-san_Deva",
        "languages": [
          "mar-Deva",
          "san-Deva"
        ],
        "main_score": 0.8083682105654761,
        "precision": 0.7920503162202381,
        "recall": 0.8447265625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003058486599450426,
        "hf_subset": "mar_Deva-sat_Olck",
        "languages": [
          "mar-Deva",
          "sat-Olck"
        ],
        "main_score": 0.003058486599450426,
        "precision": 0.0025757203999792603,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.6669921875,
        "f1": 0.6043884013122294,
        "hf_subset": "mar_Deva-snd_Deva",
        "languages": [
          "mar-Deva",
          "snd-Deva"
        ],
        "main_score": 0.6043884013122294,
        "precision": 0.5788930145375457,
        "recall": 0.6669921875
      },
      {
        "accuracy": 0.4130859375,
        "f1": 0.34436372004731375,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ],
        "main_score": 0.34436372004731375,
        "precision": 0.31777847532242065,
        "recall": 0.4130859375
      },
      {
        "accuracy": 0.6220703125,
        "f1": 0.5556384858630953,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5556384858630953,
        "precision": 0.5291457403273809,
        "recall": 0.6220703125
      },
      {
        "accuracy": 0.8369140625,
        "f1": 0.7986328125,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7986328125,
        "precision": 0.7818033854166666,
        "recall": 0.8369140625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002995834740361448,
        "hf_subset": "mni_Mtei-asm_Beng",
        "languages": [
          "mni-Mtei",
          "asm-Beng"
        ],
        "main_score": 0.002995834740361448,
        "precision": 0.0029633843450556936,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0026051972731660233,
        "hf_subset": "mni_Mtei-ben_Beng",
        "languages": [
          "mni-Mtei",
          "ben-Beng"
        ],
        "main_score": 0.0026051972731660233,
        "precision": 0.002058885325600442,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.001655731394565906,
        "hf_subset": "mni_Mtei-brx_Deva",
        "languages": [
          "mni-Mtei",
          "brx-Deva"
        ],
        "main_score": 0.001655731394565906,
        "precision": 0.0014790654196805305,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0013097127278645833,
        "hf_subset": "mni_Mtei-doi_Deva",
        "languages": [
          "mni-Mtei",
          "doi-Deva"
        ],
        "main_score": 0.0013097127278645833,
        "precision": 0.0009064101492869875,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.0021158854166666665,
        "hf_subset": "mni_Mtei-eng_Latn",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ],
        "main_score": 0.0021158854166666665,
        "precision": 0.0017903645833333333,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.001953125,
        "f1": 0.0004908511513157895,
        "hf_subset": "mni_Mtei-gom_Deva",
        "languages": [
          "mni-Mtei",
          "gom-Deva"
        ],
        "main_score": 0.0004908511513157895,
        "precision": 0.0003268074769433465,
        "recall": 0.001953125
      },
      {
        "accuracy": 0.0009765625,
        "f1": 2.1896020179372197e-06,
        "hf_subset": "mni_Mtei-guj_Gujr",
        "languages": [
          "mni-Mtei",
          "guj-Gujr"
        ],
        "main_score": 2.1896020179372197e-06,
        "precision": 1.0960297418630753e-06,
        "recall": 0.0009765625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0029947916666666664,
        "hf_subset": "mni_Mtei-hin_Deva",
        "languages": [
          "mni-Mtei",
          "hin-Deva"
        ],
        "main_score": 0.0029947916666666664,
        "precision": 0.002685546875,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0038103492552645094,
        "hf_subset": "mni_Mtei-kan_Knda",
        "languages": [
          "mni-Mtei",
          "kan-Knda"
        ],
        "main_score": 0.0038103492552645094,
        "precision": 0.003542056178774929,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002930939503205128,
        "hf_subset": "mni_Mtei-kas_Arab",
        "languages": [
          "mni-Mtei",
          "kas-Arab"
        ],
        "main_score": 0.002930939503205128,
        "precision": 0.002064079469507101,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0029320350060096155,
        "hf_subset": "mni_Mtei-mai_Deva",
        "languages": [
          "mni-Mtei",
          "mai-Deva"
        ],
        "main_score": 0.0029320350060096155,
        "precision": 0.0029308626654632975,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0035491070989574196,
        "hf_subset": "mni_Mtei-mal_Mlym",
        "languages": [
          "mni-Mtei",
          "mal-Mlym"
        ],
        "main_score": 0.0035491070989574196,
        "precision": 0.0030872443284415112,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0017987112713675213,
        "hf_subset": "mni_Mtei-mar_Deva",
        "languages": [
          "mni-Mtei",
          "mar-Deva"
        ],
        "main_score": 0.0017987112713675213,
        "precision": 0.0012754016497225162,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0038787147873796694,
        "hf_subset": "mni_Mtei-npi_Deva",
        "languages": [
          "mni-Mtei",
          "npi-Deva"
        ],
        "main_score": 0.0038787147873796694,
        "precision": 0.003485005579846403,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0016916454081632652,
        "hf_subset": "mni_Mtei-ory_Orya",
        "languages": [
          "mni-Mtei",
          "ory-Orya"
        ],
        "main_score": 0.0016916454081632652,
        "precision": 0.0014973769994742303,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0036943632473481194,
        "hf_subset": "mni_Mtei-pan_Guru",
        "languages": [
          "mni-Mtei",
          "pan-Guru"
        ],
        "main_score": 0.0036943632473481194,
        "precision": 0.00289085525788945,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002734375,
        "hf_subset": "mni_Mtei-san_Deva",
        "languages": [
          "mni-Mtei",
          "san-Deva"
        ],
        "main_score": 0.002734375,
        "precision": 0.0021455820540935673,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003889992651641011,
        "hf_subset": "mni_Mtei-sat_Olck",
        "languages": [
          "mni-Mtei",
          "sat-Olck"
        ],
        "main_score": 0.003889992651641011,
        "precision": 0.002957791210772296,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.000971071047657139,
        "hf_subset": "mni_Mtei-snd_Deva",
        "languages": [
          "mni-Mtei",
          "snd-Deva"
        ],
        "main_score": 0.000971071047657139,
        "precision": 0.0006717856413398693,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0029296875,
        "f1": 0.00011697860962566846,
        "hf_subset": "mni_Mtei-tam_Taml",
        "languages": [
          "mni-Mtei",
          "tam-Taml"
        ],
        "main_score": 0.00011697860962566846,
        "precision": 6.0712601202807255e-05,
        "recall": 0.0029296875
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0026302460124707177,
        "hf_subset": "mni_Mtei-tel_Telu",
        "languages": [
          "mni-Mtei",
          "tel-Telu"
        ],
        "main_score": 0.0026302460124707177,
        "precision": 0.0024545400091126194,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.002983940972222222,
        "hf_subset": "mni_Mtei-urd_Arab",
        "languages": [
          "mni-Mtei",
          "urd-Arab"
        ],
        "main_score": 0.002983940972222222,
        "precision": 0.002400716145833333,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.7734375,
        "f1": 0.7214704241071428,
        "hf_subset": "npi_Deva-asm_Beng",
        "languages": [
          "npi-Deva",
          "asm-Beng"
        ],
        "main_score": 0.7214704241071428,
        "precision": 0.6990397135416666,
        "recall": 0.7734375
      },
      {
        "accuracy": 0.88671875,
        "f1": 0.8545572916666666,
        "hf_subset": "npi_Deva-ben_Beng",
        "languages": [
          "npi-Deva",
          "ben-Beng"
        ],
        "main_score": 0.8545572916666666,
        "precision": 0.839111328125,
        "recall": 0.88671875
      },
      {
        "accuracy": 0.2919921875,
        "f1": 0.22892690514156142,
        "hf_subset": "npi_Deva-brx_Deva",
        "languages": [
          "npi-Deva",
          "brx-Deva"
        ],
        "main_score": 0.22892690514156142,
        "precision": 0.20886799425617786,
        "recall": 0.2919921875
      },
      {
        "accuracy": 0.8720703125,
        "f1": 0.8375837053571429,
        "hf_subset": "npi_Deva-doi_Deva",
        "languages": [
          "npi-Deva",
          "doi-Deva"
        ],
        "main_score": 0.8375837053571429,
        "precision": 0.822216796875,
        "recall": 0.8720703125
      },
      {
        "accuracy": 0.912109375,
        "f1": 0.8864118303571429,
        "hf_subset": "npi_Deva-eng_Latn",
        "languages": [
          "npi-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8864118303571429,
        "precision": 0.8746256510416667,
        "recall": 0.912109375
      },
      {
        "accuracy": 0.71875,
        "f1": 0.6595424107142858,
        "hf_subset": "npi_Deva-gom_Deva",
        "languages": [
          "npi-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6595424107142858,
        "precision": 0.6348981584821428,
        "recall": 0.71875
      },
      {
        "accuracy": 0.7880859375,
        "f1": 0.737744140625,
        "hf_subset": "npi_Deva-guj_Gujr",
        "languages": [
          "npi-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.737744140625,
        "precision": 0.7154227120535714,
        "recall": 0.7880859375
      },
      {
        "accuracy": 0.970703125,
        "f1": 0.9611002604166666,
        "hf_subset": "npi_Deva-hin_Deva",
        "languages": [
          "npi-Deva",
          "hin-Deva"
        ],
        "main_score": 0.9611002604166666,
        "precision": 0.9563802083333334,
        "recall": 0.970703125
      },
      {
        "accuracy": 0.7109375,
        "f1": 0.6486700148809523,
        "hf_subset": "npi_Deva-kan_Knda",
        "languages": [
          "npi-Deva",
          "kan-Knda"
        ],
        "main_score": 0.6486700148809523,
        "precision": 0.6219475023674242,
        "recall": 0.7109375
      },
      {
        "accuracy": 0.5751953125,
        "f1": 0.5085526723710317,
        "hf_subset": "npi_Deva-kas_Arab",
        "languages": [
          "npi-Deva",
          "kas-Arab"
        ],
        "main_score": 0.5085526723710317,
        "precision": 0.48292216951884925,
        "recall": 0.5751953125
      },
      {
        "accuracy": 0.943359375,
        "f1": 0.9259440104166666,
        "hf_subset": "npi_Deva-mai_Deva",
        "languages": [
          "npi-Deva",
          "mai-Deva"
        ],
        "main_score": 0.9259440104166666,
        "precision": 0.9178059895833333,
        "recall": 0.943359375
      },
      {
        "accuracy": 0.619140625,
        "f1": 0.5475167410714286,
        "hf_subset": "npi_Deva-mal_Mlym",
        "languages": [
          "npi-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5475167410714286,
        "precision": 0.5177897135416667,
        "recall": 0.619140625
      },
      {
        "accuracy": 0.8974609375,
        "f1": 0.8676432291666667,
        "hf_subset": "npi_Deva-mar_Deva",
        "languages": [
          "npi-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8676432291666667,
        "precision": 0.853515625,
        "recall": 0.8974609375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0026522626764172237,
        "hf_subset": "npi_Deva-mni_Mtei",
        "languages": [
          "npi-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0026522626764172237,
        "precision": 0.0023448508993700263,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.4892578125,
        "f1": 0.41230856274801586,
        "hf_subset": "npi_Deva-ory_Orya",
        "languages": [
          "npi-Deva",
          "ory-Orya"
        ],
        "main_score": 0.41230856274801586,
        "precision": 0.3820731026785714,
        "recall": 0.4892578125
      },
      {
        "accuracy": 0.6845703125,
        "f1": 0.6218470982142857,
        "hf_subset": "npi_Deva-pan_Guru",
        "languages": [
          "npi-Deva",
          "pan-Guru"
        ],
        "main_score": 0.6218470982142857,
        "precision": 0.5948893229166667,
        "recall": 0.6845703125
      },
      {
        "accuracy": 0.8544921875,
        "f1": 0.8182942708333333,
        "hf_subset": "npi_Deva-san_Deva",
        "languages": [
          "npi-Deva",
          "san-Deva"
        ],
        "main_score": 0.8182942708333333,
        "precision": 0.8022786458333333,
        "recall": 0.8544921875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.002919195835199944,
        "hf_subset": "npi_Deva-sat_Olck",
        "languages": [
          "npi-Deva",
          "sat-Olck"
        ],
        "main_score": 0.002919195835199944,
        "precision": 0.002500172647835825,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.6923828125,
        "f1": 0.630926029265873,
        "hf_subset": "npi_Deva-snd_Deva",
        "languages": [
          "npi-Deva",
          "snd-Deva"
        ],
        "main_score": 0.630926029265873,
        "precision": 0.6061035156250001,
        "recall": 0.6923828125
      },
      {
        "accuracy": 0.390625,
        "f1": 0.32267480241113056,
        "hf_subset": "npi_Deva-tam_Taml",
        "languages": [
          "npi-Deva",
          "tam-Taml"
        ],
        "main_score": 0.32267480241113056,
        "precision": 0.29672154017857144,
        "recall": 0.390625
      },
      {
        "accuracy": 0.63671875,
        "f1": 0.5659691220238096,
        "hf_subset": "npi_Deva-tel_Telu",
        "languages": [
          "npi-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5659691220238096,
        "precision": 0.5373697916666667,
        "recall": 0.63671875
      },
      {
        "accuracy": 0.8759765625,
        "f1": 0.8420247395833333,
        "hf_subset": "npi_Deva-urd_Arab",
        "languages": [
          "npi-Deva",
          "urd-Arab"
        ],
        "main_score": 0.8420247395833333,
        "precision": 0.826416015625,
        "recall": 0.8759765625
      },
      {
        "accuracy": 0.4287109375,
        "f1": 0.36527467757936505,
        "hf_subset": "ory_Orya-asm_Beng",
        "languages": [
          "ory-Orya",
          "asm-Beng"
        ],
        "main_score": 0.36527467757936505,
        "precision": 0.3449765348660896,
        "recall": 0.4287109375
      },
      {
        "accuracy": 0.5087890625,
        "f1": 0.43789593110882175,
        "hf_subset": "ory_Orya-ben_Beng",
        "languages": [
          "ory-Orya",
          "ben-Beng"
        ],
        "main_score": 0.43789593110882175,
        "precision": 0.4140815347846598,
        "recall": 0.5087890625
      },
      {
        "accuracy": 0.1513671875,
        "f1": 0.10572282535173161,
        "hf_subset": "ory_Orya-brx_Deva",
        "languages": [
          "ory-Orya",
          "brx-Deva"
        ],
        "main_score": 0.10572282535173161,
        "precision": 0.09405294636485194,
        "recall": 0.1513671875
      },
      {
        "accuracy": 0.3603515625,
        "f1": 0.2974797210550887,
        "hf_subset": "ory_Orya-doi_Deva",
        "languages": [
          "ory-Orya",
          "doi-Deva"
        ],
        "main_score": 0.2974797210550887,
        "precision": 0.27695668724721456,
        "recall": 0.3603515625
      },
      {
        "accuracy": 0.2939453125,
        "f1": 0.23252484357579714,
        "hf_subset": "ory_Orya-eng_Latn",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ],
        "main_score": 0.23252484357579714,
        "precision": 0.21499814154971947,
        "recall": 0.2939453125
      },
      {
        "accuracy": 0.287109375,
        "f1": 0.23117279978098593,
        "hf_subset": "ory_Orya-gom_Deva",
        "languages": [
          "ory-Orya",
          "gom-Deva"
        ],
        "main_score": 0.23117279978098593,
        "precision": 0.2134139352401071,
        "recall": 0.287109375
      },
      {
        "accuracy": 0.4072265625,
        "f1": 0.3547727543404818,
        "hf_subset": "ory_Orya-guj_Gujr",
        "languages": [
          "ory-Orya",
          "guj-Gujr"
        ],
        "main_score": 0.3547727543404818,
        "precision": 0.3378425318358306,
        "recall": 0.4072265625
      },
      {
        "accuracy": 0.484375,
        "f1": 0.41350013727081736,
        "hf_subset": "ory_Orya-hin_Deva",
        "languages": [
          "ory-Orya",
          "hin-Deva"
        ],
        "main_score": 0.41350013727081736,
        "precision": 0.3887054870776436,
        "recall": 0.484375
      },
      {
        "accuracy": 0.3876953125,
        "f1": 0.323272197637432,
        "hf_subset": "ory_Orya-kan_Knda",
        "languages": [
          "ory-Orya",
          "kan-Knda"
        ],
        "main_score": 0.323272197637432,
        "precision": 0.302137199280754,
        "recall": 0.3876953125
      },
      {
        "accuracy": 0.193359375,
        "f1": 0.15921136506212333,
        "hf_subset": "ory_Orya-kas_Arab",
        "languages": [
          "ory-Orya",
          "kas-Arab"
        ],
        "main_score": 0.15921136506212333,
        "precision": 0.14965217210090256,
        "recall": 0.193359375
      },
      {
        "accuracy": 0.421875,
        "f1": 0.3608021210560273,
        "hf_subset": "ory_Orya-mai_Deva",
        "languages": [
          "ory-Orya",
          "mai-Deva"
        ],
        "main_score": 0.3608021210560273,
        "precision": 0.3404370857007576,
        "recall": 0.421875
      },
      {
        "accuracy": 0.3330078125,
        "f1": 0.2711929075698607,
        "hf_subset": "ory_Orya-mal_Mlym",
        "languages": [
          "ory-Orya",
          "mal-Mlym"
        ],
        "main_score": 0.2711929075698607,
        "precision": 0.252457512361005,
        "recall": 0.3330078125
      },
      {
        "accuracy": 0.392578125,
        "f1": 0.32825333112557376,
        "hf_subset": "ory_Orya-mar_Deva",
        "languages": [
          "ory-Orya",
          "mar-Deva"
        ],
        "main_score": 0.32825333112557376,
        "precision": 0.3060658685390131,
        "recall": 0.392578125
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.004639145006693369,
        "hf_subset": "ory_Orya-mni_Mtei",
        "languages": [
          "ory-Orya",
          "mni-Mtei"
        ],
        "main_score": 0.004639145006693369,
        "precision": 0.0033620625984768907,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.451171875,
        "f1": 0.3842148175558102,
        "hf_subset": "ory_Orya-npi_Deva",
        "languages": [
          "ory-Orya",
          "npi-Deva"
        ],
        "main_score": 0.3842148175558102,
        "precision": 0.3616395364076028,
        "recall": 0.451171875
      },
      {
        "accuracy": 0.35546875,
        "f1": 0.30735437151709766,
        "hf_subset": "ory_Orya-pan_Guru",
        "languages": [
          "ory-Orya",
          "pan-Guru"
        ],
        "main_score": 0.30735437151709766,
        "precision": 0.2923788180135837,
        "recall": 0.35546875
      },
      {
        "accuracy": 0.3974609375,
        "f1": 0.3310081996221784,
        "hf_subset": "ory_Orya-san_Deva",
        "languages": [
          "ory-Orya",
          "san-Deva"
        ],
        "main_score": 0.3310081996221784,
        "precision": 0.30941585947689465,
        "recall": 0.3974609375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0015824145064907715,
        "hf_subset": "ory_Orya-sat_Olck",
        "languages": [
          "ory-Orya",
          "sat-Olck"
        ],
        "main_score": 0.0015824145064907715,
        "precision": 0.000962446994837758,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.2724609375,
        "f1": 0.22904084476607092,
        "hf_subset": "ory_Orya-snd_Deva",
        "languages": [
          "ory-Orya",
          "snd-Deva"
        ],
        "main_score": 0.22904084476607092,
        "precision": 0.21364823598710317,
        "recall": 0.2724609375
      },
      {
        "accuracy": 0.1796875,
        "f1": 0.14052873133880567,
        "hf_subset": "ory_Orya-tam_Taml",
        "languages": [
          "ory-Orya",
          "tam-Taml"
        ],
        "main_score": 0.14052873133880567,
        "precision": 0.129476191440367,
        "recall": 0.1796875
      },
      {
        "accuracy": 0.3310546875,
        "f1": 0.2777340172847985,
        "hf_subset": "ory_Orya-tel_Telu",
        "languages": [
          "ory-Orya",
          "tel-Telu"
        ],
        "main_score": 0.2777340172847985,
        "precision": 0.26016308267413324,
        "recall": 0.3310546875
      },
      {
        "accuracy": 0.345703125,
        "f1": 0.2854821935876623,
        "hf_subset": "ory_Orya-urd_Arab",
        "languages": [
          "ory-Orya",
          "urd-Arab"
        ],
        "main_score": 0.2854821935876623,
        "precision": 0.2670703482715201,
        "recall": 0.345703125
      },
      {
        "accuracy": 0.5107421875,
        "f1": 0.44048549107142854,
        "hf_subset": "pan_Guru-asm_Beng",
        "languages": [
          "pan-Guru",
          "asm-Beng"
        ],
        "main_score": 0.44048549107142854,
        "precision": 0.41279994419642857,
        "recall": 0.5107421875
      },
      {
        "accuracy": 0.6494140625,
        "f1": 0.5811818660939754,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ],
        "main_score": 0.5811818660939754,
        "precision": 0.5540376209077381,
        "recall": 0.6494140625
      },
      {
        "accuracy": 0.2548828125,
        "f1": 0.1936233498489358,
        "hf_subset": "pan_Guru-brx_Deva",
        "languages": [
          "pan-Guru",
          "brx-Deva"
        ],
        "main_score": 0.1936233498489358,
        "precision": 0.17424317490235458,
        "recall": 0.2548828125
      },
      {
        "accuracy": 0.7412109375,
        "f1": 0.6863823784722223,
        "hf_subset": "pan_Guru-doi_Deva",
        "languages": [
          "pan-Guru",
          "doi-Deva"
        ],
        "main_score": 0.6863823784722223,
        "precision": 0.6623779296875,
        "recall": 0.7412109375
      },
      {
        "accuracy": 0.599609375,
        "f1": 0.5247613551812771,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ],
        "main_score": 0.5247613551812771,
        "precision": 0.4967455667162698,
        "recall": 0.599609375
      },
      {
        "accuracy": 0.509765625,
        "f1": 0.44443746899801584,
        "hf_subset": "pan_Guru-gom_Deva",
        "languages": [
          "pan-Guru",
          "gom-Deva"
        ],
        "main_score": 0.44443746899801584,
        "precision": 0.41879185267857144,
        "recall": 0.509765625
      },
      {
        "accuracy": 0.6748046875,
        "f1": 0.6190724206349206,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ],
        "main_score": 0.6190724206349206,
        "precision": 0.5959929935515873,
        "recall": 0.6748046875
      },
      {
        "accuracy": 0.7705078125,
        "f1": 0.7179097269917583,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ],
        "main_score": 0.7179097269917583,
        "precision": 0.6959472656250001,
        "recall": 0.7705078125
      },
      {
        "accuracy": 0.541015625,
        "f1": 0.46823550798160174,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ],
        "main_score": 0.46823550798160174,
        "precision": 0.44028552827380957,
        "recall": 0.541015625
      },
      {
        "accuracy": 0.4150390625,
        "f1": 0.3519207138347763,
        "hf_subset": "pan_Guru-kas_Arab",
        "languages": [
          "pan-Guru",
          "kas-Arab"
        ],
        "main_score": 0.3519207138347763,
        "precision": 0.3277285621279762,
        "recall": 0.4150390625
      },
      {
        "accuracy": 0.6865234375,
        "f1": 0.6264067150297619,
        "hf_subset": "pan_Guru-mai_Deva",
        "languages": [
          "pan-Guru",
          "mai-Deva"
        ],
        "main_score": 0.6264067150297619,
        "precision": 0.6012462797619047,
        "recall": 0.6865234375
      },
      {
        "accuracy": 0.4951171875,
        "f1": 0.434260363117785,
        "hf_subset": "pan_Guru-mal_Mlym",
        "languages": [
          "pan-Guru",
          "mal-Mlym"
        ],
        "main_score": 0.434260363117785,
        "precision": 0.4111258370535714,
        "recall": 0.4951171875
      },
      {
        "accuracy": 0.646484375,
        "f1": 0.5794596354166666,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ],
        "main_score": 0.5794596354166666,
        "precision": 0.5517438616071428,
        "recall": 0.646484375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003285007487521581,
        "hf_subset": "pan_Guru-mni_Mtei",
        "languages": [
          "pan-Guru",
          "mni-Mtei"
        ],
        "main_score": 0.003285007487521581,
        "precision": 0.002508161054685339,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.6708984375,
        "f1": 0.608544921875,
        "hf_subset": "pan_Guru-npi_Deva",
        "languages": [
          "pan-Guru",
          "npi-Deva"
        ],
        "main_score": 0.608544921875,
        "precision": 0.5828000992063491,
        "recall": 0.6708984375
      },
      {
        "accuracy": 0.3828125,
        "f1": 0.31668301316738817,
        "hf_subset": "pan_Guru-ory_Orya",
        "languages": [
          "pan-Guru",
          "ory-Orya"
        ],
        "main_score": 0.31668301316738817,
        "precision": 0.2916852678571428,
        "recall": 0.3828125
      },
      {
        "accuracy": 0.5947265625,
        "f1": 0.5262068226911977,
        "hf_subset": "pan_Guru-san_Deva",
        "languages": [
          "pan-Guru",
          "san-Deva"
        ],
        "main_score": 0.5262068226911977,
        "precision": 0.5000348772321428,
        "recall": 0.5947265625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0010554440795875037,
        "hf_subset": "pan_Guru-sat_Olck",
        "languages": [
          "pan-Guru",
          "sat-Olck"
        ],
        "main_score": 0.0010554440795875037,
        "precision": 0.0005809072863537743,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.5791015625,
        "f1": 0.5162737869769118,
        "hf_subset": "pan_Guru-snd_Deva",
        "languages": [
          "pan-Guru",
          "snd-Deva"
        ],
        "main_score": 0.5162737869769118,
        "precision": 0.49154730902777777,
        "recall": 0.5791015625
      },
      {
        "accuracy": 0.3388671875,
        "f1": 0.26854926215277775,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ],
        "main_score": 0.26854926215277775,
        "precision": 0.24342751974587912,
        "recall": 0.3388671875
      },
      {
        "accuracy": 0.4853515625,
        "f1": 0.4208868117559524,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ],
        "main_score": 0.4208868117559524,
        "precision": 0.3961801436410812,
        "recall": 0.4853515625
      },
      {
        "accuracy": 0.69921875,
        "f1": 0.6372597346230158,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ],
        "main_score": 0.6372597346230158,
        "precision": 0.6126464843749999,
        "recall": 0.69921875
      },
      {
        "accuracy": 0.6787109375,
        "f1": 0.6096803695436508,
        "hf_subset": "san_Deva-asm_Beng",
        "languages": [
          "san-Deva",
          "asm-Beng"
        ],
        "main_score": 0.6096803695436508,
        "precision": 0.5813883463541667,
        "recall": 0.6787109375
      },
      {
        "accuracy": 0.8310546875,
        "f1": 0.7913922991071428,
        "hf_subset": "san_Deva-ben_Beng",
        "languages": [
          "san-Deva",
          "ben-Beng"
        ],
        "main_score": 0.7913922991071428,
        "precision": 0.7734375,
        "recall": 0.8310546875
      },
      {
        "accuracy": 0.2900390625,
        "f1": 0.2180168174222632,
        "hf_subset": "san_Deva-brx_Deva",
        "languages": [
          "san-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2180168174222632,
        "precision": 0.19607084355404092,
        "recall": 0.2900390625
      },
      {
        "accuracy": 0.755859375,
        "f1": 0.702055431547619,
        "hf_subset": "san_Deva-doi_Deva",
        "languages": [
          "san-Deva",
          "doi-Deva"
        ],
        "main_score": 0.702055431547619,
        "precision": 0.679443359375,
        "recall": 0.755859375
      },
      {
        "accuracy": 0.84765625,
        "f1": 0.8149288862179487,
        "hf_subset": "san_Deva-eng_Latn",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ],
        "main_score": 0.8149288862179487,
        "precision": 0.8022453187003968,
        "recall": 0.84765625
      },
      {
        "accuracy": 0.6640625,
        "f1": 0.6043283664891395,
        "hf_subset": "san_Deva-gom_Deva",
        "languages": [
          "san-Deva",
          "gom-Deva"
        ],
        "main_score": 0.6043283664891395,
        "precision": 0.5807427300347221,
        "recall": 0.6640625
      },
      {
        "accuracy": 0.732421875,
        "f1": 0.6771693638392857,
        "hf_subset": "san_Deva-guj_Gujr",
        "languages": [
          "san-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.6771693638392857,
        "precision": 0.6548758370535714,
        "recall": 0.732421875
      },
      {
        "accuracy": 0.9130859375,
        "f1": 0.8884114583333333,
        "hf_subset": "san_Deva-hin_Deva",
        "languages": [
          "san-Deva",
          "hin-Deva"
        ],
        "main_score": 0.8884114583333333,
        "precision": 0.8765462239583333,
        "recall": 0.9130859375
      },
      {
        "accuracy": 0.7470703125,
        "f1": 0.69091796875,
        "hf_subset": "san_Deva-kan_Knda",
        "languages": [
          "san-Deva",
          "kan-Knda"
        ],
        "main_score": 0.69091796875,
        "precision": 0.667236328125,
        "recall": 0.7470703125
      },
      {
        "accuracy": 0.494140625,
        "f1": 0.41968238467261904,
        "hf_subset": "san_Deva-kas_Arab",
        "languages": [
          "san-Deva",
          "kas-Arab"
        ],
        "main_score": 0.41968238467261904,
        "precision": 0.3928381893713925,
        "recall": 0.494140625
      },
      {
        "accuracy": 0.8466796875,
        "f1": 0.8067925347222222,
        "hf_subset": "san_Deva-mai_Deva",
        "languages": [
          "san-Deva",
          "mai-Deva"
        ],
        "main_score": 0.8067925347222222,
        "precision": 0.7888916015625,
        "recall": 0.8466796875
      },
      {
        "accuracy": 0.65625,
        "f1": 0.5904374379960318,
        "hf_subset": "san_Deva-mal_Mlym",
        "languages": [
          "san-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.5904374379960318,
        "precision": 0.5630289713541667,
        "recall": 0.65625
      },
      {
        "accuracy": 0.8505859375,
        "f1": 0.8131184895833333,
        "hf_subset": "san_Deva-mar_Deva",
        "languages": [
          "san-Deva",
          "mar-Deva"
        ],
        "main_score": 0.8131184895833333,
        "precision": 0.7959798177083333,
        "recall": 0.8505859375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.001658015752506593,
        "hf_subset": "san_Deva-mni_Mtei",
        "languages": [
          "san-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.001658015752506593,
        "precision": 0.001341159884501065,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.84765625,
        "f1": 0.8098307291666667,
        "hf_subset": "san_Deva-npi_Deva",
        "languages": [
          "san-Deva",
          "npi-Deva"
        ],
        "main_score": 0.8098307291666667,
        "precision": 0.7931315104166667,
        "recall": 0.84765625
      },
      {
        "accuracy": 0.435546875,
        "f1": 0.36268220711580085,
        "hf_subset": "san_Deva-ory_Orya",
        "languages": [
          "san-Deva",
          "ory-Orya"
        ],
        "main_score": 0.36268220711580085,
        "precision": 0.33683417277167277,
        "recall": 0.435546875
      },
      {
        "accuracy": 0.59375,
        "f1": 0.5254098820016789,
        "hf_subset": "san_Deva-pan_Guru",
        "languages": [
          "san-Deva",
          "pan-Guru"
        ],
        "main_score": 0.5254098820016789,
        "precision": 0.49938933137175323,
        "recall": 0.59375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0024481099856572177,
        "hf_subset": "san_Deva-sat_Olck",
        "languages": [
          "san-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0024481099856572177,
        "precision": 0.0018660478360020111,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.62109375,
        "f1": 0.557396439281205,
        "hf_subset": "san_Deva-snd_Deva",
        "languages": [
          "san-Deva",
          "snd-Deva"
        ],
        "main_score": 0.557396439281205,
        "precision": 0.532881091889881,
        "recall": 0.62109375
      },
      {
        "accuracy": 0.40625,
        "f1": 0.3413419208829365,
        "hf_subset": "san_Deva-tam_Taml",
        "languages": [
          "san-Deva",
          "tam-Taml"
        ],
        "main_score": 0.3413419208829365,
        "precision": 0.3172235398065476,
        "recall": 0.40625
      },
      {
        "accuracy": 0.62109375,
        "f1": 0.5534195188492064,
        "hf_subset": "san_Deva-tel_Telu",
        "languages": [
          "san-Deva",
          "tel-Telu"
        ],
        "main_score": 0.5534195188492064,
        "precision": 0.5268012152777777,
        "recall": 0.62109375
      },
      {
        "accuracy": 0.830078125,
        "f1": 0.7861002604166667,
        "hf_subset": "san_Deva-urd_Arab",
        "languages": [
          "san-Deva",
          "urd-Arab"
        ],
        "main_score": 0.7861002604166667,
        "precision": 0.7659505208333333,
        "recall": 0.830078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002795429859145956,
        "hf_subset": "sat_Olck-asm_Beng",
        "languages": [
          "sat-Olck",
          "asm-Beng"
        ],
        "main_score": 0.002795429859145956,
        "precision": 0.0025417672110981996,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.002418954445437449,
        "hf_subset": "sat_Olck-ben_Beng",
        "languages": [
          "sat-Olck",
          "ben-Beng"
        ],
        "main_score": 0.002418954445437449,
        "precision": 0.0022143481821619852,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.001867094494047619,
        "hf_subset": "sat_Olck-brx_Deva",
        "languages": [
          "sat-Olck",
          "brx-Deva"
        ],
        "main_score": 0.001867094494047619,
        "precision": 0.0012462797619047618,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.003374215404985841,
        "hf_subset": "sat_Olck-doi_Deva",
        "languages": [
          "sat-Olck",
          "doi-Deva"
        ],
        "main_score": 0.003374215404985841,
        "precision": 0.003187403236231361,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0034018590829608415,
        "hf_subset": "sat_Olck-eng_Latn",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ],
        "main_score": 0.0034018590829608415,
        "precision": 0.0031965111618992258,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.004968772546897547,
        "hf_subset": "sat_Olck-gom_Deva",
        "languages": [
          "sat-Olck",
          "gom-Deva"
        ],
        "main_score": 0.004968772546897547,
        "precision": 0.0045186355881300854,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.00397565106984183,
        "hf_subset": "sat_Olck-guj_Gujr",
        "languages": [
          "sat-Olck",
          "guj-Gujr"
        ],
        "main_score": 0.00397565106984183,
        "precision": 0.003543135673887173,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.005859375,
        "f1": 0.0013016865983141957,
        "hf_subset": "sat_Olck-hin_Deva",
        "languages": [
          "sat-Olck",
          "hin-Deva"
        ],
        "main_score": 0.0013016865983141957,
        "precision": 0.0011517003819723653,
        "recall": 0.005859375
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0022625024546633664,
        "hf_subset": "sat_Olck-kan_Knda",
        "languages": [
          "sat-Olck",
          "kan-Knda"
        ],
        "main_score": 0.0022625024546633664,
        "precision": 0.0018117638790246212,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.003195533020900668,
        "hf_subset": "sat_Olck-kas_Arab",
        "languages": [
          "sat-Olck",
          "kas-Arab"
        ],
        "main_score": 0.003195533020900668,
        "precision": 0.0030677564216382578,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0034748896007266543,
        "hf_subset": "sat_Olck-mai_Deva",
        "languages": [
          "sat-Olck",
          "mai-Deva"
        ],
        "main_score": 0.0034748896007266543,
        "precision": 0.00325587475987022,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003749831044037218,
        "hf_subset": "sat_Olck-mal_Mlym",
        "languages": [
          "sat-Olck",
          "mal-Mlym"
        ],
        "main_score": 0.003749831044037218,
        "precision": 0.0033930897732447427,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.003737392880235144,
        "hf_subset": "sat_Olck-mar_Deva",
        "languages": [
          "sat-Olck",
          "mar-Deva"
        ],
        "main_score": 0.003737392880235144,
        "precision": 0.003196545814705097,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.0244140625,
        "f1": 0.012027907841960832,
        "hf_subset": "sat_Olck-mni_Mtei",
        "languages": [
          "sat-Olck",
          "mni-Mtei"
        ],
        "main_score": 0.012027907841960832,
        "precision": 0.01052414384010551,
        "recall": 0.0244140625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.005236080109126984,
        "hf_subset": "sat_Olck-npi_Deva",
        "languages": [
          "sat-Olck",
          "npi-Deva"
        ],
        "main_score": 0.005236080109126984,
        "precision": 0.0044828753441010175,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0037554502721098603,
        "hf_subset": "sat_Olck-ory_Orya",
        "languages": [
          "sat-Olck",
          "ory-Orya"
        ],
        "main_score": 0.0037554502721098603,
        "precision": 0.003508239300042475,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.003815013070381454,
        "hf_subset": "sat_Olck-pan_Guru",
        "languages": [
          "sat-Olck",
          "pan-Guru"
        ],
        "main_score": 0.003815013070381454,
        "precision": 0.002909793620242839,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.004335206055245854,
        "hf_subset": "sat_Olck-san_Deva",
        "languages": [
          "sat-Olck",
          "san-Deva"
        ],
        "main_score": 0.004335206055245854,
        "precision": 0.003585217015639177,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.00390625,
        "f1": 0.0020715593973524076,
        "hf_subset": "sat_Olck-snd_Deva",
        "languages": [
          "sat-Olck",
          "snd-Deva"
        ],
        "main_score": 0.0020715593973524076,
        "precision": 0.0020159357244318183,
        "recall": 0.00390625
      },
      {
        "accuracy": 0.0048828125,
        "f1": 0.0015726681297519008,
        "hf_subset": "sat_Olck-tam_Taml",
        "languages": [
          "sat-Olck",
          "tam-Taml"
        ],
        "main_score": 0.0015726681297519008,
        "precision": 0.0013577381751364059,
        "recall": 0.0048828125
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.002108713158605262,
        "hf_subset": "sat_Olck-tel_Telu",
        "languages": [
          "sat-Olck",
          "tel-Telu"
        ],
        "main_score": 0.002108713158605262,
        "precision": 0.001733660504690958,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.006080330510465783,
        "hf_subset": "sat_Olck-urd_Arab",
        "languages": [
          "sat-Olck",
          "urd-Arab"
        ],
        "main_score": 0.006080330510465783,
        "precision": 0.005685133334524561,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.4921875,
        "f1": 0.4275289868551587,
        "hf_subset": "snd_Deva-asm_Beng",
        "languages": [
          "snd-Deva",
          "asm-Beng"
        ],
        "main_score": 0.4275289868551587,
        "precision": 0.40452793096405226,
        "recall": 0.4921875
      },
      {
        "accuracy": 0.59375,
        "f1": 0.526520013189935,
        "hf_subset": "snd_Deva-ben_Beng",
        "languages": [
          "snd-Deva",
          "ben-Beng"
        ],
        "main_score": 0.526520013189935,
        "precision": 0.5025340246775793,
        "recall": 0.59375
      },
      {
        "accuracy": 0.3125,
        "f1": 0.2510527214054328,
        "hf_subset": "snd_Deva-brx_Deva",
        "languages": [
          "snd-Deva",
          "brx-Deva"
        ],
        "main_score": 0.2510527214054328,
        "precision": 0.22973506297050073,
        "recall": 0.3125
      },
      {
        "accuracy": 0.767578125,
        "f1": 0.7221819196428572,
        "hf_subset": "snd_Deva-doi_Deva",
        "languages": [
          "snd-Deva",
          "doi-Deva"
        ],
        "main_score": 0.7221819196428572,
        "precision": 0.7034303099244505,
        "recall": 0.767578125
      },
      {
        "accuracy": 0.6455078125,
        "f1": 0.585422782909071,
        "hf_subset": "snd_Deva-eng_Latn",
        "languages": [
          "snd-Deva",
          "eng-Latn"
        ],
        "main_score": 0.585422782909071,
        "precision": 0.5644764293323863,
        "recall": 0.6455078125
      },
      {
        "accuracy": 0.595703125,
        "f1": 0.5339835999503968,
        "hf_subset": "snd_Deva-gom_Deva",
        "languages": [
          "snd-Deva",
          "gom-Deva"
        ],
        "main_score": 0.5339835999503968,
        "precision": 0.5097912016369047,
        "recall": 0.595703125
      },
      {
        "accuracy": 0.6064453125,
        "f1": 0.542002404062951,
        "hf_subset": "snd_Deva-guj_Gujr",
        "languages": [
          "snd-Deva",
          "guj-Gujr"
        ],
        "main_score": 0.542002404062951,
        "precision": 0.5176037016369047,
        "recall": 0.6064453125
      },
      {
        "accuracy": 0.759765625,
        "f1": 0.7111359126984127,
        "hf_subset": "snd_Deva-hin_Deva",
        "languages": [
          "snd-Deva",
          "hin-Deva"
        ],
        "main_score": 0.7111359126984127,
        "precision": 0.6920623403289419,
        "recall": 0.759765625
      },
      {
        "accuracy": 0.4453125,
        "f1": 0.37375444650835277,
        "hf_subset": "snd_Deva-kan_Knda",
        "languages": [
          "snd-Deva",
          "kan-Knda"
        ],
        "main_score": 0.37375444650835277,
        "precision": 0.34975404816282574,
        "recall": 0.4453125
      },
      {
        "accuracy": 0.4345703125,
        "f1": 0.3734003680781024,
        "hf_subset": "snd_Deva-kas_Arab",
        "languages": [
          "snd-Deva",
          "kas-Arab"
        ],
        "main_score": 0.3734003680781024,
        "precision": 0.35163612971230157,
        "recall": 0.4345703125
      },
      {
        "accuracy": 0.7236328125,
        "f1": 0.6683082921852453,
        "hf_subset": "snd_Deva-mai_Deva",
        "languages": [
          "snd-Deva",
          "mai-Deva"
        ],
        "main_score": 0.6683082921852453,
        "precision": 0.6463983444940476,
        "recall": 0.7236328125
      },
      {
        "accuracy": 0.4140625,
        "f1": 0.3505677238343254,
        "hf_subset": "snd_Deva-mal_Mlym",
        "languages": [
          "snd-Deva",
          "mal-Mlym"
        ],
        "main_score": 0.3505677238343254,
        "precision": 0.32945261988146546,
        "recall": 0.4140625
      },
      {
        "accuracy": 0.6484375,
        "f1": 0.5903189258658008,
        "hf_subset": "snd_Deva-mar_Deva",
        "languages": [
          "snd-Deva",
          "mar-Deva"
        ],
        "main_score": 0.5903189258658008,
        "precision": 0.5685915375856783,
        "recall": 0.6484375
      },
      {
        "accuracy": 0.0068359375,
        "f1": 0.0017311222860791828,
        "hf_subset": "snd_Deva-mni_Mtei",
        "languages": [
          "snd-Deva",
          "mni-Mtei"
        ],
        "main_score": 0.0017311222860791828,
        "precision": 0.0012057215220655057,
        "recall": 0.0068359375
      },
      {
        "accuracy": 0.69140625,
        "f1": 0.6348218666429435,
        "hf_subset": "snd_Deva-npi_Deva",
        "languages": [
          "snd-Deva",
          "npi-Deva"
        ],
        "main_score": 0.6348218666429435,
        "precision": 0.6126187939664502,
        "recall": 0.69140625
      },
      {
        "accuracy": 0.2978515625,
        "f1": 0.23576764489850427,
        "hf_subset": "snd_Deva-ory_Orya",
        "languages": [
          "snd-Deva",
          "ory-Orya"
        ],
        "main_score": 0.23576764489850427,
        "precision": 0.21502776466155374,
        "recall": 0.2978515625
      },
      {
        "accuracy": 0.5615234375,
        "f1": 0.4995749872728697,
        "hf_subset": "snd_Deva-pan_Guru",
        "languages": [
          "snd-Deva",
          "pan-Guru"
        ],
        "main_score": 0.4995749872728697,
        "precision": 0.47652297247023806,
        "recall": 0.5615234375
      },
      {
        "accuracy": 0.5908203125,
        "f1": 0.5247028216780478,
        "hf_subset": "snd_Deva-san_Deva",
        "languages": [
          "snd-Deva",
          "san-Deva"
        ],
        "main_score": 0.5247028216780478,
        "precision": 0.5007063149409983,
        "recall": 0.5908203125
      },
      {
        "accuracy": 0.0078125,
        "f1": 0.0013770907417140427,
        "hf_subset": "snd_Deva-sat_Olck",
        "languages": [
          "snd-Deva",
          "sat-Olck"
        ],
        "main_score": 0.0013770907417140427,
        "precision": 0.000886922518569444,
        "recall": 0.0078125
      },
      {
        "accuracy": 0.2666015625,
        "f1": 0.201529792906746,
        "hf_subset": "snd_Deva-tam_Taml",
        "languages": [
          "snd-Deva",
          "tam-Taml"
        ],
        "main_score": 0.201529792906746,
        "precision": 0.1807300328985761,
        "recall": 0.2666015625
      },
      {
        "accuracy": 0.4453125,
        "f1": 0.37901398189484126,
        "hf_subset": "snd_Deva-tel_Telu",
        "languages": [
          "snd-Deva",
          "tel-Telu"
        ],
        "main_score": 0.37901398189484126,
        "precision": 0.355304178371159,
        "recall": 0.4453125
      },
      {
        "accuracy": 0.625,
        "f1": 0.5575509559884559,
        "hf_subset": "snd_Deva-urd_Arab",
        "languages": [
          "snd-Deva",
          "urd-Arab"
        ],
        "main_score": 0.5575509559884559,
        "precision": 0.5323860799459587,
        "recall": 0.625
      },
      {
        "accuracy": 0.291015625,
        "f1": 0.24231448889652013,
        "hf_subset": "tam_Taml-asm_Beng",
        "languages": [
          "tam-Taml",
          "asm-Beng"
        ],
        "main_score": 0.24231448889652013,
        "precision": 0.2251005879593685,
        "recall": 0.291015625
      },
      {
        "accuracy": 0.396484375,
        "f1": 0.33537403893849205,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ],
        "main_score": 0.33537403893849205,
        "precision": 0.3136113615117522,
        "recall": 0.396484375
      },
      {
        "accuracy": 0.1533203125,
        "f1": 0.11444139607597424,
        "hf_subset": "tam_Taml-brx_Deva",
        "languages": [
          "tam-Taml",
          "brx-Deva"
        ],
        "main_score": 0.11444139607597424,
        "precision": 0.10367537143788685,
        "recall": 0.1533203125
      },
      {
        "accuracy": 0.302734375,
        "f1": 0.24907240654310964,
        "hf_subset": "tam_Taml-doi_Deva",
        "languages": [
          "tam-Taml",
          "doi-Deva"
        ],
        "main_score": 0.24907240654310964,
        "precision": 0.2290150848500458,
        "recall": 0.302734375
      },
      {
        "accuracy": 0.3828125,
        "f1": 0.31564587755994006,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ],
        "main_score": 0.31564587755994006,
        "precision": 0.2935504599567099,
        "recall": 0.3828125
      },
      {
        "accuracy": 0.26171875,
        "f1": 0.21446087549603174,
        "hf_subset": "tam_Taml-gom_Deva",
        "languages": [
          "tam-Taml",
          "gom-Deva"
        ],
        "main_score": 0.21446087549603174,
        "precision": 0.19820269519976552,
        "recall": 0.26171875
      },
      {
        "accuracy": 0.3427734375,
        "f1": 0.280703858316163,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ],
        "main_score": 0.280703858316163,
        "precision": 0.2586418030753968,
        "recall": 0.3427734375
      },
      {
        "accuracy": 0.4619140625,
        "f1": 0.3967232311958874,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ],
        "main_score": 0.3967232311958874,
        "precision": 0.37177893944035945,
        "recall": 0.4619140625
      },
      {
        "accuracy": 0.4248046875,
        "f1": 0.35486188616071423,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ],
        "main_score": 0.35486188616071423,
        "precision": 0.32883269074675325,
        "recall": 0.4248046875
      },
      {
        "accuracy": 0.2099609375,
        "f1": 0.17127061555772494,
        "hf_subset": "tam_Taml-kas_Arab",
        "languages": [
          "tam-Taml",
          "kas-Arab"
        ],
        "main_score": 0.17127061555772494,
        "precision": 0.15866034464667278,
        "recall": 0.2099609375
      },
      {
        "accuracy": 0.337890625,
        "f1": 0.27203378760995944,
        "hf_subset": "tam_Taml-mai_Deva",
        "languages": [
          "tam-Taml",
          "mai-Deva"
        ],
        "main_score": 0.27203378760995944,
        "precision": 0.24945165240575398,
        "recall": 0.337890625
      },
      {
        "accuracy": 0.4541015625,
        "f1": 0.3968723378731021,
        "hf_subset": "tam_Taml-mal_Mlym",
        "languages": [
          "tam-Taml",
          "mal-Mlym"
        ],
        "main_score": 0.3968723378731021,
        "precision": 0.375044776729347,
        "recall": 0.4541015625
      },
      {
        "accuracy": 0.3701171875,
        "f1": 0.31197916666666664,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ],
        "main_score": 0.31197916666666664,
        "precision": 0.29223248810651153,
        "recall": 0.3701171875
      },
      {
        "accuracy": 0.009765625,
        "f1": 0.0026832935842248926,
        "hf_subset": "tam_Taml-mni_Mtei",
        "languages": [
          "tam-Taml",
          "mni-Mtei"
        ],
        "main_score": 0.0026832935842248926,
        "precision": 0.0020354485245171893,
        "recall": 0.009765625
      },
      {
        "accuracy": 0.3427734375,
        "f1": 0.283038362717246,
        "hf_subset": "tam_Taml-npi_Deva",
        "languages": [
          "tam-Taml",
          "npi-Deva"
        ],
        "main_score": 0.283038362717246,
        "precision": 0.26223900204613093,
        "recall": 0.3427734375
      },
      {
        "accuracy": 0.2119140625,
        "f1": 0.16496881482233045,
        "hf_subset": "tam_Taml-ory_Orya",
        "languages": [
          "tam-Taml",
          "ory-Orya"
        ],
        "main_score": 0.16496881482233045,
        "precision": 0.15049138144841268,
        "recall": 0.2119140625
      },
      {
        "accuracy": 0.32421875,
        "f1": 0.26892206101190474,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ],
        "main_score": 0.26892206101190474,
        "precision": 0.2501662833694084,
        "recall": 0.32421875
      },
      {
        "accuracy": 0.3916015625,
        "f1": 0.322208271329365,
        "hf_subset": "tam_Taml-san_Deva",
        "languages": [
          "tam-Taml",
          "san-Deva"
        ],
        "main_score": 0.322208271329365,
        "precision": 0.2969342912946429,
        "recall": 0.3916015625
      },
      {
        "accuracy": 0.0126953125,
        "f1": 0.003596851222454261,
        "hf_subset": "tam_Taml-sat_Olck",
        "languages": [
          "tam-Taml",
          "sat-Olck"
        ],
        "main_score": 0.003596851222454261,
        "precision": 0.0029455656051400538,
        "recall": 0.0126953125
      },
      {
        "accuracy": 0.2548828125,
        "f1": 0.20884077573787688,
        "hf_subset": "tam_Taml-snd_Deva",
        "languages": [
          "tam-Taml",
          "snd-Deva"
        ],
        "main_score": 0.20884077573787688,
        "precision": 0.19267965649801588,
        "recall": 0.2548828125
      },
      {
        "accuracy": 0.376953125,
        "f1": 0.32115272422889607,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ],
        "main_score": 0.32115272422889607,
        "precision": 0.3012951078869048,
        "recall": 0.376953125
      },
      {
        "accuracy": 0.38671875,
        "f1": 0.3220718625992064,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ],
        "main_score": 0.3220718625992064,
        "precision": 0.3004363285369145,
        "recall": 0.38671875
      },
      {
        "accuracy": 0.529296875,
        "f1": 0.4601663256448412,
        "hf_subset": "tel_Telu-asm_Beng",
        "languages": [
          "tel-Telu",
          "asm-Beng"
        ],
        "main_score": 0.4601663256448412,
        "precision": 0.4328407893105159,
        "recall": 0.529296875
      },
      {
        "accuracy": 0.6328125,
        "f1": 0.5652538216991342,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ],
        "main_score": 0.5652538216991342,
        "precision": 0.5375999813988095,
        "recall": 0.6328125
      },
      {
        "accuracy": 0.244140625,
        "f1": 0.18447653149801588,
        "hf_subset": "tel_Telu-brx_Deva",
        "languages": [
          "tel-Telu",
          "brx-Deva"
        ],
        "main_score": 0.18447653149801588,
        "precision": 0.1655049937233416,
        "recall": 0.244140625
      },
      {
        "accuracy": 0.5400390625,
        "f1": 0.4678276909722222,
        "hf_subset": "tel_Telu-doi_Deva",
        "languages": [
          "tel-Telu",
          "doi-Deva"
        ],
        "main_score": 0.4678276909722222,
        "precision": 0.4399332682291667,
        "recall": 0.5400390625
      },
      {
        "accuracy": 0.55859375,
        "f1": 0.4853770903575591,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ],
        "main_score": 0.4853770903575591,
        "precision": 0.45941491505456356,
        "recall": 0.55859375
      },
      {
        "accuracy": 0.490234375,
        "f1": 0.4160412016369048,
        "hf_subset": "tel_Telu-gom_Deva",
        "languages": [
          "tel-Telu",
          "gom-Deva"
        ],
        "main_score": 0.4160412016369048,
        "precision": 0.3866141183035714,
        "recall": 0.490234375
      },
      {
        "accuracy": 0.64453125,
        "f1": 0.5828179253472223,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ],
        "main_score": 0.5828179253472223,
        "precision": 0.5563650948660714,
        "recall": 0.64453125
      },
      {
        "accuracy": 0.68359375,
        "f1": 0.6218409682765151,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ],
        "main_score": 0.6218409682765151,
        "precision": 0.5966727120535714,
        "recall": 0.68359375
      },
      {
        "accuracy": 0.724609375,
        "f1": 0.6671084449404762,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ],
        "main_score": 0.6671084449404762,
        "precision": 0.64287109375,
        "recall": 0.724609375
      },
      {
        "accuracy": 0.3603515625,
        "f1": 0.29957825377747255,
        "hf_subset": "tel_Telu-kas_Arab",
        "languages": [
          "tel-Telu",
          "kas-Arab"
        ],
        "main_score": 0.29957825377747255,
        "precision": 0.27860436817956347,
        "recall": 0.3603515625
      },
      {
        "accuracy": 0.59375,
        "f1": 0.5246520027281746,
        "hf_subset": "tel_Telu-mai_Deva",
        "languages": [
          "tel-Telu",
          "mai-Deva"
        ],
        "main_score": 0.5246520027281746,
        "precision": 0.4970877511160714,
        "recall": 0.59375
      },
      {
        "accuracy": 0.6318359375,
        "f1": 0.5672929772050865,
        "hf_subset": "tel_Telu-mal_Mlym",
        "languages": [
          "tel-Telu",
          "mal-Mlym"
        ],
        "main_score": 0.5672929772050865,
        "precision": 0.5400158110119047,
        "recall": 0.6318359375
      },
      {
        "accuracy": 0.5966796875,
        "f1": 0.5316150483630953,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ],
        "main_score": 0.5316150483630953,
        "precision": 0.5048921130952381,
        "recall": 0.5966796875
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.003377567974305107,
        "hf_subset": "tel_Telu-mni_Mtei",
        "languages": [
          "tel-Telu",
          "mni-Mtei"
        ],
        "main_score": 0.003377567974305107,
        "precision": 0.0022440831801470587,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.6162109375,
        "f1": 0.5513555617559524,
        "hf_subset": "tel_Telu-npi_Deva",
        "languages": [
          "tel-Telu",
          "npi-Deva"
        ],
        "main_score": 0.5513555617559524,
        "precision": 0.5250689794146826,
        "recall": 0.6162109375
      },
      {
        "accuracy": 0.3876953125,
        "f1": 0.32341347346230154,
        "hf_subset": "tel_Telu-ory_Orya",
        "languages": [
          "tel-Telu",
          "ory-Orya"
        ],
        "main_score": 0.32341347346230154,
        "precision": 0.3001523324765512,
        "recall": 0.3876953125
      },
      {
        "accuracy": 0.5,
        "f1": 0.4295613078327922,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ],
        "main_score": 0.4295613078327922,
        "precision": 0.4026080419146825,
        "recall": 0.5
      },
      {
        "accuracy": 0.6337890625,
        "f1": 0.5664248511904761,
        "hf_subset": "tel_Telu-san_Deva",
        "languages": [
          "tel-Telu",
          "san-Deva"
        ],
        "main_score": 0.5664248511904761,
        "precision": 0.5399836816829005,
        "recall": 0.6337890625
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0027971750599278173,
        "hf_subset": "tel_Telu-sat_Olck",
        "languages": [
          "tel-Telu",
          "sat-Olck"
        ],
        "main_score": 0.0027971750599278173,
        "precision": 0.002157012623394217,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.453125,
        "f1": 0.3835542224702381,
        "hf_subset": "tel_Telu-snd_Deva",
        "languages": [
          "tel-Telu",
          "snd-Deva"
        ],
        "main_score": 0.3835542224702381,
        "precision": 0.3557493179563492,
        "recall": 0.453125
      },
      {
        "accuracy": 0.4091796875,
        "f1": 0.3406366257440476,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ],
        "main_score": 0.3406366257440476,
        "precision": 0.31434035528273807,
        "recall": 0.4091796875
      },
      {
        "accuracy": 0.556640625,
        "f1": 0.483758906024531,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ],
        "main_score": 0.483758906024531,
        "precision": 0.4559702070932539,
        "recall": 0.556640625
      },
      {
        "accuracy": 0.6826171875,
        "f1": 0.6187414744543651,
        "hf_subset": "urd_Arab-asm_Beng",
        "languages": [
          "urd-Arab",
          "asm-Beng"
        ],
        "main_score": 0.6187414744543651,
        "precision": 0.591488792782738,
        "recall": 0.6826171875
      },
      {
        "accuracy": 0.8681640625,
        "f1": 0.8326822916666667,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ],
        "main_score": 0.8326822916666667,
        "precision": 0.8162760416666667,
        "recall": 0.8681640625
      },
      {
        "accuracy": 0.2490234375,
        "f1": 0.18200923154536436,
        "hf_subset": "urd_Arab-brx_Deva",
        "languages": [
          "urd-Arab",
          "brx-Deva"
        ],
        "main_score": 0.18200923154536436,
        "precision": 0.1612675026419082,
        "recall": 0.2490234375
      },
      {
        "accuracy": 0.822265625,
        "f1": 0.7757510230654762,
        "hf_subset": "urd_Arab-doi_Deva",
        "languages": [
          "urd-Arab",
          "doi-Deva"
        ],
        "main_score": 0.7757510230654762,
        "precision": 0.7546154203869048,
        "recall": 0.822265625
      },
      {
        "accuracy": 0.9775390625,
        "f1": 0.9703776041666666,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ],
        "main_score": 0.9703776041666666,
        "precision": 0.9669596354166666,
        "recall": 0.9775390625
      },
      {
        "accuracy": 0.6142578125,
        "f1": 0.544384765625,
        "hf_subset": "urd_Arab-gom_Deva",
        "languages": [
          "urd-Arab",
          "gom-Deva"
        ],
        "main_score": 0.544384765625,
        "precision": 0.5154552641369048,
        "recall": 0.6142578125
      },
      {
        "accuracy": 0.7236328125,
        "f1": 0.6657924107142856,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ],
        "main_score": 0.6657924107142856,
        "precision": 0.6414496527777778,
        "recall": 0.7236328125
      },
      {
        "accuracy": 0.9716796875,
        "f1": 0.9632161458333333,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ],
        "main_score": 0.9632161458333333,
        "precision": 0.958984375,
        "recall": 0.9716796875
      },
      {
        "accuracy": 0.7109375,
        "f1": 0.6508486793154762,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ],
        "main_score": 0.6508486793154762,
        "precision": 0.6261486235119047,
        "recall": 0.7109375
      },
      {
        "accuracy": 0.8154296875,
        "f1": 0.7690150669642857,
        "hf_subset": "urd_Arab-kas_Arab",
        "languages": [
          "urd-Arab",
          "kas-Arab"
        ],
        "main_score": 0.7690150669642857,
        "precision": 0.7490885416666666,
        "recall": 0.8154296875
      },
      {
        "accuracy": 0.884765625,
        "f1": 0.8527669270833333,
        "hf_subset": "urd_Arab-mai_Deva",
        "languages": [
          "urd-Arab",
          "mai-Deva"
        ],
        "main_score": 0.8527669270833333,
        "precision": 0.8380045572916667,
        "recall": 0.884765625
      },
      {
        "accuracy": 0.6552734375,
        "f1": 0.5936569940476191,
        "hf_subset": "urd_Arab-mal_Mlym",
        "languages": [
          "urd-Arab",
          "mal-Mlym"
        ],
        "main_score": 0.5936569940476191,
        "precision": 0.5687934027777777,
        "recall": 0.6552734375
      },
      {
        "accuracy": 0.83984375,
        "f1": 0.7963541666666667,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ],
        "main_score": 0.7963541666666667,
        "precision": 0.7767578125,
        "recall": 0.83984375
      },
      {
        "accuracy": 0.0107421875,
        "f1": 0.0031893965126811594,
        "hf_subset": "urd_Arab-mni_Mtei",
        "languages": [
          "urd-Arab",
          "mni-Mtei"
        ],
        "main_score": 0.0031893965126811594,
        "precision": 0.002633546647608515,
        "recall": 0.0107421875
      },
      {
        "accuracy": 0.8720703125,
        "f1": 0.8353515625,
        "hf_subset": "urd_Arab-npi_Deva",
        "languages": [
          "urd-Arab",
          "npi-Deva"
        ],
        "main_score": 0.8353515625,
        "precision": 0.8179524739583334,
        "recall": 0.8720703125
      },
      {
        "accuracy": 0.3955078125,
        "f1": 0.3196630788915945,
        "hf_subset": "urd_Arab-ory_Orya",
        "languages": [
          "urd-Arab",
          "ory-Orya"
        ],
        "main_score": 0.3196630788915945,
        "precision": 0.2931849644496129,
        "recall": 0.3955078125
      },
      {
        "accuracy": 0.689453125,
        "f1": 0.6230375744047618,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ],
        "main_score": 0.6230375744047618,
        "precision": 0.595654296875,
        "recall": 0.689453125
      },
      {
        "accuracy": 0.8310546875,
        "f1": 0.7860026041666666,
        "hf_subset": "urd_Arab-san_Deva",
        "languages": [
          "urd-Arab",
          "san-Deva"
        ],
        "main_score": 0.7860026041666666,
        "precision": 0.7652180989583333,
        "recall": 0.8310546875
      },
      {
        "accuracy": 0.0087890625,
        "f1": 0.0018186223087556601,
        "hf_subset": "urd_Arab-sat_Olck",
        "languages": [
          "urd-Arab",
          "sat-Olck"
        ],
        "main_score": 0.0018186223087556601,
        "precision": 0.0014536065040732591,
        "recall": 0.0087890625
      },
      {
        "accuracy": 0.6591796875,
        "f1": 0.5882122705853174,
        "hf_subset": "urd_Arab-snd_Deva",
        "languages": [
          "urd-Arab",
          "snd-Deva"
        ],
        "main_score": 0.5882122705853174,
        "precision": 0.5603690011160714,
        "recall": 0.6591796875
      },
      {
        "accuracy": 0.4345703125,
        "f1": 0.3612451946924603,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ],
        "main_score": 0.3612451946924603,
        "precision": 0.33292216951884923,
        "recall": 0.4345703125
      },
      {
        "accuracy": 0.580078125,
        "f1": 0.5124170696924604,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ],
        "main_score": 0.5124170696924604,
        "precision": 0.48558601500496035,
        "recall": 0.580078125
      }
    ]
  },
  "task_name": "IN22GenBitextMining"
}