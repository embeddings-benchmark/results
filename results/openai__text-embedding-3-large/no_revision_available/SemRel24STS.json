{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 468.94450759887695,
  "kg_co2_emissions": null,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.8395557641122305,
        "cosine_spearman": 0.810952645610428,
        "euclidean_pearson": 0.8174253604996761,
        "euclidean_spearman": 0.810952645610428,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.810952645610428,
        "manhattan_pearson": 0.8159328728685105,
        "manhattan_spearman": 0.8103569434620873,
        "pearson": 0.8395557641122305,
        "spearman": 0.810952645610428
      },
      {
        "cosine_pearson": 0.7206577199856167,
        "cosine_spearman": 0.703932429730857,
        "euclidean_pearson": 0.7053526555995017,
        "euclidean_spearman": 0.703932429730857,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.703932429730857,
        "manhattan_pearson": 0.706045933437464,
        "manhattan_spearman": 0.7045578198799106,
        "pearson": 0.7206577199856167,
        "spearman": 0.703932429730857
      },
      {
        "cosine_pearson": 0.6778943483709551,
        "cosine_spearman": 0.6876041241031626,
        "euclidean_pearson": 0.6682422541652914,
        "euclidean_spearman": 0.6876041241031626,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.6876041241031626,
        "manhattan_pearson": 0.6673181765798476,
        "manhattan_spearman": 0.6873108656073192,
        "pearson": 0.6778943483709551,
        "spearman": 0.6876041241031626
      },
      {
        "cosine_pearson": 0.5566937079772044,
        "cosine_spearman": 0.509933355316795,
        "euclidean_pearson": 0.5574886898652354,
        "euclidean_spearman": 0.509933355316795,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.509933355316795,
        "manhattan_pearson": 0.5594046687249523,
        "manhattan_spearman": 0.5110455865535256,
        "pearson": 0.5566937079772044,
        "spearman": 0.509933355316795
      },
      {
        "cosine_pearson": 0.4639025722437949,
        "cosine_spearman": 0.4469764749201779,
        "euclidean_pearson": 0.45638982027701336,
        "euclidean_spearman": 0.4469764749201779,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.4469764749201779,
        "manhattan_pearson": 0.4532052353838315,
        "manhattan_spearman": 0.44440074332491664,
        "pearson": 0.4639025722437949,
        "spearman": 0.4469764749201779
      },
      {
        "cosine_pearson": 0.8402374918981952,
        "cosine_spearman": 0.8304893821353235,
        "euclidean_pearson": 0.8338620388031395,
        "euclidean_spearman": 0.8304893821353235,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8304893821353235,
        "manhattan_pearson": 0.8326082567119981,
        "manhattan_spearman": 0.828402575309367,
        "pearson": 0.8402374918981952,
        "spearman": 0.8304893821353235
      },
      {
        "cosine_pearson": 0.4864857038302435,
        "cosine_spearman": 0.47178086339027414,
        "euclidean_pearson": 0.4890905306976998,
        "euclidean_spearman": 0.47178086339027414,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.47178086339027414,
        "manhattan_pearson": 0.4886726185344754,
        "manhattan_spearman": 0.47045312991755783,
        "pearson": 0.4864857038302435,
        "spearman": 0.47178086339027414
      },
      {
        "cosine_pearson": 0.7873545587560751,
        "cosine_spearman": 0.8021950362007414,
        "euclidean_pearson": 0.7621955720113646,
        "euclidean_spearman": 0.802189452360928,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.8021950362007414,
        "manhattan_pearson": 0.760557298109796,
        "manhattan_spearman": 0.8019826518101125,
        "pearson": 0.7873545587560751,
        "spearman": 0.8021950362007414
      },
      {
        "cosine_pearson": 0.5057110627524289,
        "cosine_spearman": 0.5093128737411579,
        "euclidean_pearson": 0.5240287817893856,
        "euclidean_spearman": 0.5093128737411579,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.5093128737411579,
        "manhattan_pearson": 0.5227475097672373,
        "manhattan_spearman": 0.5088806463427888,
        "pearson": 0.5057110627524289,
        "spearman": 0.5093128737411579
      },
      {
        "cosine_pearson": 0.5336577707735624,
        "cosine_spearman": 0.5161975357442868,
        "euclidean_pearson": 0.5359890294734051,
        "euclidean_spearman": 0.5161975357442868,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.5161975357442868,
        "manhattan_pearson": 0.5414924998697827,
        "manhattan_spearman": 0.5238187146789611,
        "pearson": 0.5336577707735624,
        "spearman": 0.5161975357442868
      },
      {
        "cosine_pearson": 0.7734958278069244,
        "cosine_spearman": 0.7664954817380014,
        "euclidean_pearson": 0.7602265664119335,
        "euclidean_spearman": 0.7664954817380014,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.7664954817380014,
        "manhattan_pearson": 0.7595264696556944,
        "manhattan_spearman": 0.7657519962036282,
        "pearson": 0.7734958278069244,
        "spearman": 0.7664954817380014
      },
      {
        "cosine_pearson": 0.7942664170813045,
        "cosine_spearman": 0.7738976195742044,
        "euclidean_pearson": 0.7800835629858595,
        "euclidean_spearman": 0.7738976195742044,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.7738976195742044,
        "manhattan_pearson": 0.7804599221236477,
        "manhattan_spearman": 0.7757999046245257,
        "pearson": 0.7942664170813045,
        "spearman": 0.7738976195742044
      }
    ]
  },
  "task_name": "SemRel24STS"
}