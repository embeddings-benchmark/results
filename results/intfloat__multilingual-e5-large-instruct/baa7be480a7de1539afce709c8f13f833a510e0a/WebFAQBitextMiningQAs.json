{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQAs",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.970177,
        "recall": 0.978528,
        "f1": 0.972904,
        "accuracy": 0.978528,
        "main_score": 0.972904,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.995954,
        "recall": 0.997303,
        "f1": 0.996404,
        "accuracy": 0.997303,
        "main_score": 0.996404,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.996681,
        "recall": 0.997788,
        "f1": 0.99705,
        "accuracy": 0.997788,
        "main_score": 0.99705,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.996528,
        "recall": 0.997685,
        "f1": 0.996914,
        "accuracy": 0.997685,
        "main_score": 0.996914,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.994949,
        "recall": 0.996392,
        "f1": 0.99543,
        "accuracy": 0.996392,
        "main_score": 0.99543,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.990647,
        "recall": 0.99356,
        "f1": 0.991567,
        "accuracy": 0.99356,
        "main_score": 0.991567,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.995356,
        "recall": 0.996904,
        "f1": 0.995872,
        "accuracy": 0.996904,
        "main_score": 0.995872,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.924359,
        "recall": 0.942857,
        "f1": 0.930183,
        "accuracy": 0.942857,
        "main_score": 0.930183,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.986884,
        "recall": 0.991256,
        "f1": 0.988341,
        "accuracy": 0.991256,
        "main_score": 0.988341,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.998204,
        "recall": 0.998653,
        "f1": 0.998316,
        "accuracy": 0.998653,
        "main_score": 0.998316,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.99633,
        "recall": 0.997554,
        "f1": 0.996738,
        "accuracy": 0.997554,
        "main_score": 0.996738,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.986337,
        "recall": 0.990515,
        "f1": 0.987692,
        "accuracy": 0.990515,
        "main_score": 0.987692,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.996101,
        "recall": 0.9974,
        "f1": 0.996534,
        "accuracy": 0.9974,
        "main_score": 0.996534,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.994197,
        "recall": 0.996132,
        "f1": 0.994842,
        "accuracy": 0.996132,
        "main_score": 0.994842,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.989865,
        "recall": 0.993243,
        "f1": 0.990991,
        "accuracy": 0.993243,
        "main_score": 0.990991,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.993017,
        "recall": 0.995345,
        "f1": 0.993793,
        "accuracy": 0.995345,
        "main_score": 0.993793,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.999109,
        "recall": 0.999406,
        "f1": 0.999208,
        "accuracy": 0.999406,
        "main_score": 0.999208,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.994714,
        "recall": 0.996269,
        "f1": 0.99518,
        "accuracy": 0.996269,
        "main_score": 0.99518,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.999412,
        "recall": 0.999608,
        "f1": 0.999477,
        "accuracy": 0.999608,
        "main_score": 0.999477,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.994307,
        "recall": 0.99562,
        "f1": 0.994647,
        "accuracy": 0.99562,
        "main_score": 0.994647,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.995856,
        "recall": 0.997238,
        "f1": 0.996317,
        "accuracy": 0.997238,
        "main_score": 0.996317,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.990791,
        "recall": 0.992996,
        "f1": 0.99144,
        "accuracy": 0.992996,
        "main_score": 0.99144,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.990415,
        "recall": 0.99361,
        "f1": 0.99148,
        "accuracy": 0.99361,
        "main_score": 0.99148,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.997172,
        "recall": 0.998115,
        "f1": 0.997487,
        "accuracy": 0.998115,
        "main_score": 0.997487,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.998938,
        "recall": 0.999292,
        "f1": 0.999056,
        "accuracy": 0.999292,
        "main_score": 0.999056,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.997409,
        "recall": 0.998273,
        "f1": 0.997697,
        "accuracy": 0.998273,
        "main_score": 0.997697,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.998538,
        "recall": 0.999025,
        "f1": 0.9987,
        "accuracy": 0.999025,
        "main_score": 0.9987,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.992586,
        "recall": 0.995058,
        "f1": 0.99341,
        "accuracy": 0.995058,
        "main_score": 0.99341,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.997653,
        "recall": 0.998435,
        "f1": 0.997913,
        "accuracy": 0.998435,
        "main_score": 0.997913,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.988349,
        "recall": 0.991823,
        "f1": 0.989443,
        "accuracy": 0.991823,
        "main_score": 0.989443,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.992402,
        "recall": 0.994935,
        "f1": 0.993247,
        "accuracy": 0.994935,
        "main_score": 0.993247,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.966531,
        "recall": 0.97561,
        "f1": 0.969173,
        "accuracy": 0.97561,
        "main_score": 0.969173,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.989241,
        "recall": 0.992827,
        "f1": 0.990436,
        "accuracy": 0.992827,
        "main_score": 0.990436,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.993666,
        "recall": 0.995249,
        "f1": 0.994194,
        "accuracy": 0.995249,
        "main_score": 0.994194,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.985249,
        "recall": 0.989964,
        "f1": 0.98677,
        "accuracy": 0.989964,
        "main_score": 0.98677,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.97033,
        "recall": 0.98022,
        "f1": 0.973626,
        "accuracy": 0.98022,
        "main_score": 0.973626,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.994886,
        "recall": 0.996197,
        "f1": 0.995298,
        "accuracy": 0.996197,
        "main_score": 0.995298,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.997617,
        "recall": 0.998411,
        "f1": 0.997882,
        "accuracy": 0.998411,
        "main_score": 0.997882,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.975193,
        "recall": 0.982175,
        "f1": 0.977243,
        "accuracy": 0.982175,
        "main_score": 0.977243,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.982966,
        "recall": 0.987976,
        "f1": 0.984636,
        "accuracy": 0.987976,
        "main_score": 0.984636,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.989768,
        "recall": 0.993179,
        "f1": 0.990905,
        "accuracy": 0.993179,
        "main_score": 0.990905,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.998271,
        "recall": 0.998847,
        "f1": 0.998463,
        "accuracy": 0.998847,
        "main_score": 0.998463,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.993688,
        "recall": 0.995529,
        "f1": 0.994301,
        "accuracy": 0.995529,
        "main_score": 0.994301,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.995547,
        "recall": 0.996857,
        "f1": 0.995984,
        "accuracy": 0.996857,
        "main_score": 0.995984,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.996828,
        "recall": 0.997804,
        "f1": 0.997154,
        "accuracy": 0.997804,
        "main_score": 0.997154,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.99443,
        "recall": 0.996158,
        "f1": 0.995006,
        "accuracy": 0.996158,
        "main_score": 0.995006,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.988147,
        "recall": 0.991266,
        "f1": 0.989135,
        "accuracy": 0.991266,
        "main_score": 0.989135,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.992446,
        "recall": 0.994639,
        "f1": 0.993177,
        "accuracy": 0.994639,
        "main_score": 0.993177,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.990152,
        "recall": 0.992999,
        "f1": 0.991086,
        "accuracy": 0.992999,
        "main_score": 0.991086,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.996017,
        "recall": 0.997188,
        "f1": 0.996407,
        "accuracy": 0.997188,
        "main_score": 0.996407,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.99783,
        "recall": 0.998521,
        "f1": 0.998058,
        "accuracy": 0.998521,
        "main_score": 0.998058,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.989796,
        "recall": 0.993197,
        "f1": 0.99093,
        "accuracy": 0.993197,
        "main_score": 0.99093,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.997516,
        "recall": 0.998297,
        "f1": 0.997773,
        "accuracy": 0.998297,
        "main_score": 0.997773,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.998698,
        "recall": 0.999085,
        "f1": 0.998827,
        "accuracy": 0.999085,
        "main_score": 0.998827,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.998922,
        "recall": 0.999281,
        "f1": 0.999042,
        "accuracy": 0.999281,
        "main_score": 0.999042,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.99735,
        "recall": 0.998233,
        "f1": 0.997644,
        "accuracy": 0.998233,
        "main_score": 0.997644,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.998332,
        "recall": 0.998888,
        "f1": 0.998518,
        "accuracy": 0.998888,
        "main_score": 0.998518,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.99761,
        "recall": 0.998278,
        "f1": 0.99783,
        "accuracy": 0.998278,
        "main_score": 0.99783,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.99922,
        "recall": 0.99948,
        "f1": 0.999307,
        "accuracy": 0.99948,
        "main_score": 0.999307,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.995677,
        "recall": 0.997118,
        "f1": 0.996158,
        "accuracy": 0.997118,
        "main_score": 0.996158,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.995392,
        "recall": 0.99675,
        "f1": 0.995834,
        "accuracy": 0.99675,
        "main_score": 0.995834,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.996799,
        "recall": 0.997821,
        "f1": 0.99714,
        "accuracy": 0.997821,
        "main_score": 0.99714,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.993224,
        "recall": 0.995309,
        "f1": 0.993875,
        "accuracy": 0.995309,
        "main_score": 0.993875,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.993793,
        "recall": 0.995628,
        "f1": 0.994396,
        "accuracy": 0.995628,
        "main_score": 0.994396,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.991654,
        "recall": 0.994234,
        "f1": 0.992463,
        "accuracy": 0.994234,
        "main_score": 0.992463,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.994774,
        "recall": 0.996311,
        "f1": 0.995274,
        "accuracy": 0.996311,
        "main_score": 0.995274,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.994973,
        "recall": 0.996604,
        "f1": 0.995505,
        "accuracy": 0.996604,
        "main_score": 0.995505,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.994062,
        "recall": 0.995249,
        "f1": 0.994458,
        "accuracy": 0.995249,
        "main_score": 0.994458,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.995177,
        "recall": 0.996785,
        "f1": 0.995713,
        "accuracy": 0.996785,
        "main_score": 0.995713,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.995902,
        "recall": 0.997268,
        "f1": 0.996357,
        "accuracy": 0.997268,
        "main_score": 0.996357,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.995192,
        "recall": 0.996795,
        "f1": 0.995726,
        "accuracy": 0.996795,
        "main_score": 0.995726,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.995906,
        "recall": 0.997162,
        "f1": 0.996325,
        "accuracy": 0.997162,
        "main_score": 0.996325,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.995164,
        "recall": 0.996423,
        "f1": 0.995562,
        "accuracy": 0.996423,
        "main_score": 0.995562,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.995316,
        "recall": 0.996613,
        "f1": 0.995743,
        "accuracy": 0.996613,
        "main_score": 0.995743,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.991369,
        "recall": 0.993452,
        "f1": 0.992063,
        "accuracy": 0.993452,
        "main_score": 0.992063,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.993559,
        "recall": 0.995403,
        "f1": 0.994164,
        "accuracy": 0.995403,
        "main_score": 0.994164,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.995957,
        "recall": 0.997047,
        "f1": 0.996309,
        "accuracy": 0.997047,
        "main_score": 0.996309,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.997748,
        "recall": 0.998498,
        "f1": 0.997998,
        "accuracy": 0.998498,
        "main_score": 0.997998,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.993876,
        "recall": 0.9953,
        "f1": 0.994327,
        "accuracy": 0.9953,
        "main_score": 0.994327,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.996191,
        "recall": 0.99723,
        "f1": 0.996537,
        "accuracy": 0.99723,
        "main_score": 0.996537,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.994593,
        "recall": 0.996232,
        "f1": 0.995133,
        "accuracy": 0.996232,
        "main_score": 0.995133,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.996221,
        "recall": 0.99724,
        "f1": 0.99655,
        "accuracy": 0.99724,
        "main_score": 0.99655,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.994275,
        "recall": 0.996183,
        "f1": 0.994911,
        "accuracy": 0.996183,
        "main_score": 0.994911,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.99221,
        "recall": 0.994334,
        "f1": 0.992918,
        "accuracy": 0.994334,
        "main_score": 0.992918,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.99539,
        "recall": 0.996927,
        "f1": 0.995902,
        "accuracy": 0.996927,
        "main_score": 0.995902,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.997736,
        "recall": 0.99842,
        "f1": 0.997946,
        "accuracy": 0.99842,
        "main_score": 0.997946,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.988957,
        "recall": 0.991077,
        "f1": 0.989612,
        "accuracy": 0.991077,
        "main_score": 0.989612,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.9957,
        "recall": 0.996829,
        "f1": 0.996073,
        "accuracy": 0.996829,
        "main_score": 0.996073,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.99453,
        "recall": 0.995986,
        "f1": 0.995002,
        "accuracy": 0.995986,
        "main_score": 0.995002,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.991556,
        "recall": 0.993481,
        "f1": 0.992198,
        "accuracy": 0.993481,
        "main_score": 0.992198,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.990019,
        "recall": 0.993036,
        "f1": 0.991024,
        "accuracy": 0.993036,
        "main_score": 0.991024,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.995837,
        "recall": 0.997133,
        "f1": 0.996246,
        "accuracy": 0.997133,
        "main_score": 0.996246,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.997445,
        "recall": 0.998296,
        "f1": 0.997729,
        "accuracy": 0.998296,
        "main_score": 0.997729,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.996359,
        "recall": 0.997573,
        "f1": 0.996764,
        "accuracy": 0.997573,
        "main_score": 0.996764,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.996134,
        "recall": 0.997423,
        "f1": 0.996564,
        "accuracy": 0.997423,
        "main_score": 0.996564,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.997082,
        "recall": 0.998054,
        "f1": 0.997406,
        "accuracy": 0.998054,
        "main_score": 0.997406,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.990523,
        "recall": 0.993331,
        "f1": 0.99143,
        "accuracy": 0.993331,
        "main_score": 0.99143,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.998049,
        "recall": 0.998537,
        "f1": 0.998171,
        "accuracy": 0.998537,
        "main_score": 0.998171,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.99789,
        "recall": 0.998594,
        "f1": 0.998125,
        "accuracy": 0.998594,
        "main_score": 0.998125,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.998698,
        "recall": 0.999132,
        "f1": 0.998843,
        "accuracy": 0.999132,
        "main_score": 0.998843,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.999603,
        "recall": 0.999735,
        "f1": 0.999647,
        "accuracy": 0.999735,
        "main_score": 0.999647,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.99324,
        "recall": 0.995124,
        "f1": 0.993868,
        "accuracy": 0.995124,
        "main_score": 0.993868,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.999384,
        "recall": 0.999572,
        "f1": 0.999447,
        "accuracy": 0.999572,
        "main_score": 0.999447,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.998387,
        "recall": 0.998925,
        "f1": 0.998566,
        "accuracy": 0.998925,
        "main_score": 0.998566,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.997279,
        "recall": 0.998065,
        "f1": 0.997534,
        "accuracy": 0.998065,
        "main_score": 0.997534,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.976568,
        "recall": 0.984127,
        "f1": 0.979025,
        "accuracy": 0.984127,
        "main_score": 0.979025,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.997972,
        "recall": 0.998648,
        "f1": 0.998197,
        "accuracy": 0.998648,
        "main_score": 0.998197,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.998398,
        "recall": 0.998627,
        "f1": 0.998474,
        "accuracy": 0.998627,
        "main_score": 0.998474,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.992786,
        "recall": 0.994789,
        "f1": 0.993409,
        "accuracy": 0.994789,
        "main_score": 0.993409,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.99581,
        "recall": 0.997207,
        "f1": 0.996276,
        "accuracy": 0.997207,
        "main_score": 0.996276,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.996058,
        "recall": 0.997203,
        "f1": 0.996412,
        "accuracy": 0.997203,
        "main_score": 0.996412,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.99838,
        "recall": 0.998687,
        "f1": 0.998468,
        "accuracy": 0.998687,
        "main_score": 0.998468,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.995665,
        "recall": 0.99711,
        "f1": 0.996146,
        "accuracy": 0.99711,
        "main_score": 0.996146,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.998241,
        "recall": 0.998827,
        "f1": 0.998436,
        "accuracy": 0.998827,
        "main_score": 0.998436,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.959133,
        "recall": 0.970149,
        "f1": 0.962687,
        "accuracy": 0.970149,
        "main_score": 0.962687,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.997982,
        "recall": 0.998591,
        "f1": 0.998175,
        "accuracy": 0.998591,
        "main_score": 0.998175,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.996749,
        "recall": 0.997749,
        "f1": 0.997062,
        "accuracy": 0.997749,
        "main_score": 0.997062,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.996251,
        "recall": 0.997234,
        "f1": 0.996564,
        "accuracy": 0.997234,
        "main_score": 0.996564,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.996373,
        "recall": 0.997421,
        "f1": 0.996709,
        "accuracy": 0.997421,
        "main_score": 0.996709,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.997148,
        "recall": 0.998026,
        "f1": 0.997422,
        "accuracy": 0.998026,
        "main_score": 0.997422,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.993795,
        "recall": 0.995513,
        "f1": 0.994323,
        "accuracy": 0.995513,
        "main_score": 0.994323,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.996897,
        "recall": 0.997931,
        "f1": 0.997241,
        "accuracy": 0.997931,
        "main_score": 0.997241,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.995813,
        "recall": 0.996925,
        "f1": 0.996165,
        "accuracy": 0.996925,
        "main_score": 0.996165,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.987624,
        "recall": 0.990099,
        "f1": 0.988119,
        "accuracy": 0.990099,
        "main_score": 0.988119,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.999001,
        "recall": 0.999334,
        "f1": 0.999112,
        "accuracy": 0.999334,
        "main_score": 0.999112,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.984439,
        "recall": 0.988943,
        "f1": 0.985872,
        "accuracy": 0.988943,
        "main_score": 0.985872,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.996164,
        "recall": 0.997395,
        "f1": 0.996562,
        "accuracy": 0.997395,
        "main_score": 0.996562,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.992375,
        "recall": 0.993912,
        "f1": 0.992792,
        "accuracy": 0.993912,
        "main_score": 0.992792,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.997627,
        "recall": 0.998418,
        "f1": 0.99789,
        "accuracy": 0.998418,
        "main_score": 0.99789,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.99674,
        "recall": 0.997379,
        "f1": 0.996942,
        "accuracy": 0.997379,
        "main_score": 0.996942,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 4940.466865062714,
  "kg_co2_emissions": null
}