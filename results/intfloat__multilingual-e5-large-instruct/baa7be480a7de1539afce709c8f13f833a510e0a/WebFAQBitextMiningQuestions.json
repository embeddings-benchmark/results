{
  "dataset_revision": "a1bc0e8fd36c3d5015bd64c14ca098596774784a",
  "task_name": "WebFAQBitextMiningQuestions",
  "mteb_version": "1.36.1",
  "scores": {
    "default": [
      {
        "precision": 0.995074,
        "recall": 0.996716,
        "f1": 0.995621,
        "accuracy": 0.996716,
        "main_score": 0.995621,
        "hf_subset": "ara-fas",
        "languages": [
          "ara-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.941207,
        "recall": 0.9591,
        "f1": 0.947001,
        "accuracy": 0.9591,
        "main_score": 0.947001,
        "hf_subset": "ara-heb",
        "languages": [
          "ara-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.985373,
        "recall": 0.989627,
        "f1": 0.986757,
        "accuracy": 0.989627,
        "main_score": 0.986757,
        "hf_subset": "jpn-kor",
        "languages": [
          "jpn-Jpan",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.988324,
        "recall": 0.991888,
        "f1": 0.98943,
        "accuracy": 0.991888,
        "main_score": 0.98943,
        "hf_subset": "jpn-vie",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.987847,
        "recall": 0.991898,
        "f1": 0.989198,
        "accuracy": 0.991898,
        "main_score": 0.989198,
        "hf_subset": "jpn-zho",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.98076,
        "recall": 0.987013,
        "f1": 0.982804,
        "accuracy": 0.987013,
        "main_score": 0.982804,
        "hf_subset": "kor-vie",
        "languages": [
          "kor-Kore",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.986507,
        "recall": 0.9908,
        "f1": 0.987887,
        "accuracy": 0.9908,
        "main_score": 0.987887,
        "hf_subset": "kor-zho",
        "languages": [
          "kor-Kore",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.988906,
        "recall": 0.99226,
        "f1": 0.989938,
        "accuracy": 0.99226,
        "main_score": 0.989938,
        "hf_subset": "vie-zho",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.894322,
        "recall": 0.916484,
        "f1": 0.901245,
        "accuracy": 0.916484,
        "main_score": 0.901245,
        "hf_subset": "ind-msa",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.988095,
        "recall": 0.992063,
        "f1": 0.989418,
        "accuracy": 0.992063,
        "main_score": 0.989418,
        "hf_subset": "ind-tgl",
        "languages": [
          "ind-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.958797,
        "recall": 0.972178,
        "f1": 0.963169,
        "accuracy": 0.972178,
        "main_score": 0.963169,
        "hf_subset": "ind-tha",
        "languages": [
          "ind-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.992144,
        "recall": 0.994613,
        "f1": 0.992929,
        "accuracy": 0.994613,
        "main_score": 0.992929,
        "hf_subset": "bul-ces",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.995775,
        "recall": 0.997183,
        "f1": 0.996244,
        "accuracy": 0.997183,
        "main_score": 0.996244,
        "hf_subset": "bul-lav",
        "languages": [
          "bul-Cyrl",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.994396,
        "recall": 0.996264,
        "f1": 0.995019,
        "accuracy": 0.996264,
        "main_score": 0.995019,
        "hf_subset": "bul-lit",
        "languages": [
          "bul-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.99052,
        "recall": 0.993272,
        "f1": 0.991437,
        "accuracy": 0.993272,
        "main_score": 0.991437,
        "hf_subset": "bul-pol",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.974368,
        "recall": 0.982385,
        "f1": 0.976965,
        "accuracy": 0.982385,
        "main_score": 0.976965,
        "hf_subset": "bul-rus",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.985702,
        "recall": 0.990468,
        "f1": 0.987291,
        "accuracy": 0.990468,
        "main_score": 0.987291,
        "hf_subset": "bul-slk",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.980013,
        "recall": 0.98646,
        "f1": 0.982108,
        "accuracy": 0.98646,
        "main_score": 0.982108,
        "hf_subset": "bul-slv",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.970721,
        "recall": 0.97973,
        "f1": 0.973536,
        "accuracy": 0.97973,
        "main_score": 0.973536,
        "hf_subset": "bul-srp",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.98324,
        "recall": 0.988827,
        "f1": 0.985102,
        "accuracy": 0.988827,
        "main_score": 0.985102,
        "hf_subset": "bul-ukr",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.991429,
        "recall": 0.994286,
        "f1": 0.992381,
        "accuracy": 0.994286,
        "main_score": 0.992381,
        "hf_subset": "ces-lav",
        "languages": [
          "ces-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.997006,
        "recall": 0.998004,
        "f1": 0.997339,
        "accuracy": 0.998004,
        "main_score": 0.997339,
        "hf_subset": "ces-lit",
        "languages": [
          "ces-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.99005,
        "recall": 0.993169,
        "f1": 0.99109,
        "accuracy": 0.993169,
        "main_score": 0.99109,
        "hf_subset": "ces-pol",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.981732,
        "recall": 0.987407,
        "f1": 0.98352,
        "accuracy": 0.987407,
        "main_score": 0.98352,
        "hf_subset": "ces-rus",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.993532,
        "recall": 0.995688,
        "f1": 0.994251,
        "accuracy": 0.995688,
        "main_score": 0.994251,
        "hf_subset": "ces-slk",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.989051,
        "recall": 0.992701,
        "f1": 0.990268,
        "accuracy": 0.992701,
        "main_score": 0.990268,
        "hf_subset": "ces-slv",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.987569,
        "recall": 0.991713,
        "f1": 0.98895,
        "accuracy": 0.991713,
        "main_score": 0.98895,
        "hf_subset": "ces-srp",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.97808,
        "recall": 0.984436,
        "f1": 0.980156,
        "accuracy": 0.984436,
        "main_score": 0.980156,
        "hf_subset": "ces-ukr",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.980831,
        "recall": 0.98722,
        "f1": 0.982961,
        "accuracy": 0.98722,
        "main_score": 0.982961,
        "hf_subset": "hrv-slk",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.994275,
        "recall": 0.996183,
        "f1": 0.994911,
        "accuracy": 0.996183,
        "main_score": 0.994911,
        "hf_subset": "kat-rus",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.987276,
        "recall": 0.991517,
        "f1": 0.98869,
        "accuracy": 0.991517,
        "main_score": 0.98869,
        "hf_subset": "lav-lit",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.992114,
        "recall": 0.994742,
        "f1": 0.99299,
        "accuracy": 0.994742,
        "main_score": 0.99299,
        "hf_subset": "lav-pol",
        "languages": [
          "lav-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.991501,
        "recall": 0.994334,
        "f1": 0.992446,
        "accuracy": 0.994334,
        "main_score": 0.992446,
        "hf_subset": "lav-rus",
        "languages": [
          "lav-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.996198,
        "recall": 0.997465,
        "f1": 0.99662,
        "accuracy": 0.997465,
        "main_score": 0.99662,
        "hf_subset": "lav-slk",
        "languages": [
          "lav-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.991313,
        "recall": 0.994208,
        "f1": 0.992278,
        "accuracy": 0.994208,
        "main_score": 0.992278,
        "hf_subset": "lav-slv",
        "languages": [
          "lav-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.992228,
        "recall": 0.994819,
        "f1": 0.993092,
        "accuracy": 0.994819,
        "main_score": 0.993092,
        "hf_subset": "lav-ukr",
        "languages": [
          "lav-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.994152,
        "recall": 0.996101,
        "f1": 0.994802,
        "accuracy": 0.996101,
        "main_score": 0.994802,
        "hf_subset": "lit-pol",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.996878,
        "recall": 0.997919,
        "f1": 0.997225,
        "accuracy": 0.997919,
        "main_score": 0.997225,
        "hf_subset": "lit-rus",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.991657,
        "recall": 0.994179,
        "f1": 0.992433,
        "accuracy": 0.994179,
        "main_score": 0.992433,
        "hf_subset": "lit-slk",
        "languages": [
          "lit-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.990115,
        "recall": 0.99341,
        "f1": 0.991214,
        "accuracy": 0.99341,
        "main_score": 0.991214,
        "hf_subset": "lit-slv",
        "languages": [
          "lit-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.985655,
        "recall": 0.989045,
        "f1": 0.986698,
        "accuracy": 0.989045,
        "main_score": 0.986698,
        "hf_subset": "lit-ukr",
        "languages": [
          "lit-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.976233,
        "recall": 0.983446,
        "f1": 0.97856,
        "accuracy": 0.983446,
        "main_score": 0.97856,
        "hf_subset": "pol-rus",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.992961,
        "recall": 0.994786,
        "f1": 0.99357,
        "accuracy": 0.994786,
        "main_score": 0.99357,
        "hf_subset": "pol-slk",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.984805,
        "recall": 0.98987,
        "f1": 0.986493,
        "accuracy": 0.98987,
        "main_score": 0.986493,
        "hf_subset": "pol-slv",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.981369,
        "recall": 0.985772,
        "f1": 0.982724,
        "accuracy": 0.985772,
        "main_score": 0.982724,
        "hf_subset": "pol-srp",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.984107,
        "recall": 0.98903,
        "f1": 0.985724,
        "accuracy": 0.98903,
        "main_score": 0.985724,
        "hf_subset": "pol-ukr",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.983373,
        "recall": 0.987332,
        "f1": 0.984693,
        "accuracy": 0.987332,
        "main_score": 0.984693,
        "hf_subset": "rus-slk",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.980839,
        "recall": 0.987226,
        "f1": 0.982968,
        "accuracy": 0.987226,
        "main_score": 0.982968,
        "hf_subset": "rus-slv",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.976923,
        "recall": 0.984615,
        "f1": 0.979487,
        "accuracy": 0.984615,
        "main_score": 0.979487,
        "hf_subset": "rus-srp",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.987433,
        "recall": 0.991214,
        "f1": 0.988667,
        "accuracy": 0.991214,
        "main_score": 0.988667,
        "hf_subset": "rus-ukr",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.983916,
        "recall": 0.98888,
        "f1": 0.985491,
        "accuracy": 0.98888,
        "main_score": 0.985491,
        "hf_subset": "slk-slv",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.97861,
        "recall": 0.98574,
        "f1": 0.980986,
        "accuracy": 0.98574,
        "main_score": 0.980986,
        "hf_subset": "slk-srp",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.993644,
        "recall": 0.995763,
        "f1": 0.99435,
        "accuracy": 0.995763,
        "main_score": 0.99435,
        "hf_subset": "slk-ukr",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.981964,
        "recall": 0.987976,
        "f1": 0.983968,
        "accuracy": 0.987976,
        "main_score": 0.983968,
        "hf_subset": "slv-srp",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.982037,
        "recall": 0.987722,
        "f1": 0.983856,
        "accuracy": 0.987722,
        "main_score": 0.983856,
        "hf_subset": "slv-ukr",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.995033,
        "recall": 0.996689,
        "f1": 0.995585,
        "accuracy": 0.996689,
        "main_score": 0.995585,
        "hf_subset": "cat-deu",
        "languages": [
          "cat-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.989967,
        "recall": 0.993311,
        "f1": 0.991081,
        "accuracy": 0.993311,
        "main_score": 0.991081,
        "hf_subset": "cat-fra",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.996411,
        "recall": 0.997608,
        "f1": 0.99681,
        "accuracy": 0.997608,
        "main_score": 0.99681,
        "hf_subset": "cat-ita",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "cat-por",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.995468,
        "recall": 0.996979,
        "f1": 0.995972,
        "accuracy": 0.996979,
        "main_score": 0.995972,
        "hf_subset": "cat-spa",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.987203,
        "recall": 0.991469,
        "f1": 0.988625,
        "accuracy": 0.991469,
        "main_score": 0.988625,
        "hf_subset": "dan-deu",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.982991,
        "recall": 0.988427,
        "f1": 0.984789,
        "accuracy": 0.988427,
        "main_score": 0.984789,
        "hf_subset": "dan-fra",
        "languages": [
          "dan-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.981651,
        "recall": 0.987768,
        "f1": 0.98369,
        "accuracy": 0.987768,
        "main_score": 0.98369,
        "hf_subset": "dan-isl",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.982452,
        "recall": 0.988214,
        "f1": 0.984372,
        "accuracy": 0.988214,
        "main_score": 0.984372,
        "hf_subset": "dan-ita",
        "languages": [
          "dan-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.990607,
        "recall": 0.993657,
        "f1": 0.991624,
        "accuracy": 0.993657,
        "main_score": 0.991624,
        "hf_subset": "dan-nld",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.99078,
        "recall": 0.993469,
        "f1": 0.991676,
        "accuracy": 0.993469,
        "main_score": 0.991676,
        "hf_subset": "dan-nor",
        "languages": [
          "dan-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.981961,
        "recall": 0.987211,
        "f1": 0.983676,
        "accuracy": 0.987211,
        "main_score": 0.983676,
        "hf_subset": "dan-por",
        "languages": [
          "dan-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.98603,
        "recall": 0.990253,
        "f1": 0.987411,
        "accuracy": 0.990253,
        "main_score": 0.987411,
        "hf_subset": "dan-ron",
        "languages": [
          "dan-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.981611,
        "recall": 0.987118,
        "f1": 0.983431,
        "accuracy": 0.987118,
        "main_score": 0.983431,
        "hf_subset": "dan-spa",
        "languages": [
          "dan-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.986254,
        "recall": 0.990394,
        "f1": 0.987621,
        "accuracy": 0.990394,
        "main_score": 0.987621,
        "hf_subset": "dan-swe",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.973052,
        "recall": 0.981318,
        "f1": 0.975735,
        "accuracy": 0.981318,
        "main_score": 0.975735,
        "hf_subset": "deu-fra",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.984694,
        "recall": 0.989796,
        "f1": 0.986395,
        "accuracy": 0.989796,
        "main_score": 0.986395,
        "hf_subset": "deu-isl",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.979587,
        "recall": 0.986001,
        "f1": 0.981689,
        "accuracy": 0.986001,
        "main_score": 0.981689,
        "hf_subset": "deu-ita",
        "languages": [
          "deu-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.984554,
        "recall": 0.989304,
        "f1": 0.986102,
        "accuracy": 0.989304,
        "main_score": 0.986102,
        "hf_subset": "deu-nld",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.992993,
        "recall": 0.995329,
        "f1": 0.993772,
        "accuracy": 0.995329,
        "main_score": 0.993772,
        "hf_subset": "deu-nor",
        "languages": [
          "deu-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.986306,
        "recall": 0.990547,
        "f1": 0.987705,
        "accuracy": 0.990547,
        "main_score": 0.987705,
        "hf_subset": "deu-por",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.991662,
        "recall": 0.994441,
        "f1": 0.992588,
        "accuracy": 0.994441,
        "main_score": 0.992588,
        "hf_subset": "deu-ron",
        "languages": [
          "deu-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.977401,
        "recall": 0.984194,
        "f1": 0.979612,
        "accuracy": 0.984194,
        "main_score": 0.979612,
        "hf_subset": "deu-spa",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.989489,
        "recall": 0.992897,
        "f1": 0.990616,
        "accuracy": 0.992897,
        "main_score": 0.990616,
        "hf_subset": "deu-swe",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.98367,
        "recall": 0.988473,
        "f1": 0.98511,
        "accuracy": 0.988473,
        "main_score": 0.98511,
        "hf_subset": "fra-isl",
        "languages": [
          "fra-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.976082,
        "recall": 0.983752,
        "f1": 0.978614,
        "accuracy": 0.983752,
        "main_score": 0.978614,
        "hf_subset": "fra-ita",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.977016,
        "recall": 0.984132,
        "f1": 0.979352,
        "accuracy": 0.984132,
        "main_score": 0.979352,
        "hf_subset": "fra-nld",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.98534,
        "recall": 0.989836,
        "f1": 0.986839,
        "accuracy": 0.989836,
        "main_score": 0.986839,
        "hf_subset": "fra-nor",
        "languages": [
          "fra-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.98131,
        "recall": 0.98726,
        "f1": 0.983269,
        "accuracy": 0.98726,
        "main_score": 0.983269,
        "hf_subset": "fra-por",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.987001,
        "recall": 0.990895,
        "f1": 0.988265,
        "accuracy": 0.990895,
        "main_score": 0.988265,
        "hf_subset": "fra-ron",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.973972,
        "recall": 0.98194,
        "f1": 0.97658,
        "accuracy": 0.98194,
        "main_score": 0.97658,
        "hf_subset": "fra-spa",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.985085,
        "recall": 0.990012,
        "f1": 0.986716,
        "accuracy": 0.990012,
        "main_score": 0.986716,
        "hf_subset": "fra-swe",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.989311,
        "recall": 0.992874,
        "f1": 0.990499,
        "accuracy": 0.992874,
        "main_score": 0.990499,
        "hf_subset": "isl-ita",
        "languages": [
          "isl-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.980707,
        "recall": 0.987138,
        "f1": 0.982851,
        "accuracy": 0.987138,
        "main_score": 0.982851,
        "hf_subset": "isl-nld",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.978006,
        "recall": 0.985337,
        "f1": 0.98045,
        "accuracy": 0.985337,
        "main_score": 0.98045,
        "hf_subset": "isl-por",
        "languages": [
          "isl-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.987705,
        "recall": 0.991803,
        "f1": 0.989071,
        "accuracy": 0.991803,
        "main_score": 0.989071,
        "hf_subset": "isl-spa",
        "languages": [
          "isl-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.990385,
        "recall": 0.99359,
        "f1": 0.991453,
        "accuracy": 0.99359,
        "main_score": 0.991453,
        "hf_subset": "isl-swe",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.984261,
        "recall": 0.989301,
        "f1": 0.985917,
        "accuracy": 0.989301,
        "main_score": 0.985917,
        "hf_subset": "ita-nld",
        "languages": [
          "ita-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.982909,
        "recall": 0.988076,
        "f1": 0.984632,
        "accuracy": 0.988076,
        "main_score": 0.984632,
        "hf_subset": "ita-nor",
        "languages": [
          "ita-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.984575,
        "recall": 0.989107,
        "f1": 0.98607,
        "accuracy": 0.989107,
        "main_score": 0.98607,
        "hf_subset": "ita-por",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.9875,
        "recall": 0.990774,
        "f1": 0.988591,
        "accuracy": 0.990774,
        "main_score": 0.988591,
        "hf_subset": "ita-ron",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.975938,
        "recall": 0.983247,
        "f1": 0.978338,
        "accuracy": 0.983247,
        "main_score": 0.978338,
        "hf_subset": "ita-spa",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.987098,
        "recall": 0.991141,
        "f1": 0.988434,
        "accuracy": 0.991141,
        "main_score": 0.988434,
        "hf_subset": "ita-swe",
        "languages": [
          "ita-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.989302,
        "recall": 0.992868,
        "f1": 0.99049,
        "accuracy": 0.992868,
        "main_score": 0.99049,
        "hf_subset": "nld-nor",
        "languages": [
          "nld-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.983502,
        "recall": 0.988178,
        "f1": 0.985045,
        "accuracy": 0.988178,
        "main_score": 0.985045,
        "hf_subset": "nld-por",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.985226,
        "recall": 0.989612,
        "f1": 0.986669,
        "accuracy": 0.989612,
        "main_score": 0.986669,
        "hf_subset": "nld-ron",
        "languages": [
          "nld-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.981057,
        "recall": 0.986813,
        "f1": 0.982958,
        "accuracy": 0.986813,
        "main_score": 0.982958,
        "hf_subset": "nld-spa",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.987119,
        "recall": 0.990733,
        "f1": 0.988302,
        "accuracy": 0.990733,
        "main_score": 0.988302,
        "hf_subset": "nld-swe",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.987834,
        "recall": 0.991889,
        "f1": 0.989186,
        "accuracy": 0.991889,
        "main_score": 0.989186,
        "hf_subset": "nor-por",
        "languages": [
          "nor-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.983947,
        "recall": 0.98796,
        "f1": 0.985246,
        "accuracy": 0.98796,
        "main_score": 0.985246,
        "hf_subset": "nor-ron",
        "languages": [
          "nor-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.987835,
        "recall": 0.991548,
        "f1": 0.989051,
        "accuracy": 0.991548,
        "main_score": 0.989051,
        "hf_subset": "nor-spa",
        "languages": [
          "nor-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.987941,
        "recall": 0.991785,
        "f1": 0.989205,
        "accuracy": 0.991785,
        "main_score": 0.989205,
        "hf_subset": "nor-swe",
        "languages": [
          "nor-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.977638,
        "recall": 0.983477,
        "f1": 0.979566,
        "accuracy": 0.983477,
        "main_score": 0.979566,
        "hf_subset": "por-ron",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.983597,
        "recall": 0.988436,
        "f1": 0.985192,
        "accuracy": 0.988436,
        "main_score": 0.985192,
        "hf_subset": "por-spa",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.987682,
        "recall": 0.991499,
        "f1": 0.988941,
        "accuracy": 0.991499,
        "main_score": 0.988941,
        "hf_subset": "por-swe",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.985877,
        "recall": 0.98963,
        "f1": 0.987111,
        "accuracy": 0.98963,
        "main_score": 0.987111,
        "hf_subset": "ron-spa",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.980501,
        "recall": 0.986537,
        "f1": 0.982513,
        "accuracy": 0.986537,
        "main_score": 0.982513,
        "hf_subset": "ron-swe",
        "languages": [
          "ron-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.988466,
        "recall": 0.992219,
        "f1": 0.989694,
        "accuracy": 0.992219,
        "main_score": 0.989694,
        "hf_subset": "spa-swe",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.994889,
        "recall": 0.996593,
        "f1": 0.995457,
        "accuracy": 0.996593,
        "main_score": 0.995457,
        "hf_subset": "ben-hin",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.99735,
        "recall": 0.998233,
        "f1": 0.997644,
        "accuracy": 0.998233,
        "main_score": 0.997644,
        "hf_subset": "ben-mar",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.996926,
        "recall": 0.997951,
        "f1": 0.997268,
        "accuracy": 0.997951,
        "main_score": 0.997268,
        "hf_subset": "ben-urd",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.995122,
        "recall": 0.996748,
        "f1": 0.995664,
        "accuracy": 0.996748,
        "main_score": 0.995664,
        "hf_subset": "hin-mar",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "hin-urd",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.972222,
        "recall": 0.981481,
        "f1": 0.975309,
        "accuracy": 0.981481,
        "main_score": 0.975309,
        "hf_subset": "mar-urd",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.992718,
        "recall": 0.995146,
        "f1": 0.993528,
        "accuracy": 0.995146,
        "main_score": 0.993528,
        "hf_subset": "aze-kaz",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.989261,
        "recall": 0.992268,
        "f1": 0.99012,
        "accuracy": 0.992268,
        "main_score": 0.99012,
        "hf_subset": "aze-tur",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.986765,
        "recall": 0.991176,
        "f1": 0.988235,
        "accuracy": 0.991176,
        "main_score": 0.988235,
        "hf_subset": "kaz-tur",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.988608,
        "recall": 0.992405,
        "f1": 0.989873,
        "accuracy": 0.992405,
        "main_score": 0.989873,
        "hf_subset": "est-fin",
        "languages": [
          "est-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.988872,
        "recall": 0.992582,
        "f1": 0.990109,
        "accuracy": 0.992582,
        "main_score": 0.990109,
        "hf_subset": "est-hun",
        "languages": [
          "est-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.988327,
        "recall": 0.992218,
        "f1": 0.989624,
        "accuracy": 0.992218,
        "main_score": 0.989624,
        "hf_subset": "fin-hun",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.980402,
        "recall": 0.986662,
        "f1": 0.982479,
        "accuracy": 0.986662,
        "main_score": 0.982479,
        "hf_subset": "ara-eng",
        "languages": [
          "ara-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.997512,
        "recall": 0.998342,
        "f1": 0.997789,
        "accuracy": 0.998342,
        "main_score": 0.997789,
        "hf_subset": "aze-eng",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.996952,
        "recall": 0.997805,
        "f1": 0.997196,
        "accuracy": 0.997805,
        "main_score": 0.997196,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.994374,
        "recall": 0.996249,
        "f1": 0.994999,
        "accuracy": 0.996249,
        "main_score": 0.994999,
        "hf_subset": "bul-eng",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.990017,
        "recall": 0.993056,
        "f1": 0.99103,
        "accuracy": 0.993056,
        "main_score": 0.99103,
        "hf_subset": "cat-eng",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.994834,
        "recall": 0.996556,
        "f1": 0.995408,
        "accuracy": 0.996556,
        "main_score": 0.995408,
        "hf_subset": "ces-eng",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.986148,
        "recall": 0.99047,
        "f1": 0.987589,
        "accuracy": 0.99047,
        "main_score": 0.987589,
        "hf_subset": "dan-eng",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.985383,
        "recall": 0.989933,
        "f1": 0.986886,
        "accuracy": 0.989933,
        "main_score": 0.986886,
        "hf_subset": "deu-eng",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.989785,
        "recall": 0.99319,
        "f1": 0.99092,
        "accuracy": 0.99319,
        "main_score": 0.99092,
        "hf_subset": "ell-eng",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.996026,
        "recall": 0.997351,
        "f1": 0.996468,
        "accuracy": 0.997351,
        "main_score": 0.996468,
        "hf_subset": "eng-est",
        "languages": [
          "eng-Latn",
          "est-Latn"
        ]
      },
      {
        "precision": 0.994604,
        "recall": 0.996403,
        "f1": 0.995204,
        "accuracy": 0.996403,
        "main_score": 0.995204,
        "hf_subset": "eng-fas",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.9924,
        "recall": 0.994772,
        "f1": 0.993175,
        "accuracy": 0.994772,
        "main_score": 0.993175,
        "hf_subset": "eng-fin",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.97703,
        "recall": 0.984116,
        "f1": 0.979348,
        "accuracy": 0.984116,
        "main_score": 0.979348,
        "hf_subset": "eng-fra",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.971466,
        "recall": 0.980726,
        "f1": 0.97449,
        "accuracy": 0.980726,
        "main_score": 0.97449,
        "hf_subset": "eng-heb",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.995944,
        "recall": 0.997296,
        "f1": 0.996395,
        "accuracy": 0.997296,
        "main_score": 0.996395,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.995536,
        "recall": 0.997024,
        "f1": 0.996032,
        "accuracy": 0.997024,
        "main_score": 0.996032,
        "hf_subset": "eng-hrv",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.996796,
        "recall": 0.997712,
        "f1": 0.997101,
        "accuracy": 0.997712,
        "main_score": 0.997101,
        "hf_subset": "eng-hun",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.99117,
        "recall": 0.993631,
        "f1": 0.99199,
        "accuracy": 0.993631,
        "main_score": 0.99199,
        "hf_subset": "eng-ind",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.98743,
        "recall": 0.99162,
        "f1": 0.988827,
        "accuracy": 0.99162,
        "main_score": 0.988827,
        "hf_subset": "eng-isl",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.98202,
        "recall": 0.987793,
        "f1": 0.983911,
        "accuracy": 0.987793,
        "main_score": 0.983911,
        "hf_subset": "eng-ita",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.990018,
        "recall": 0.992908,
        "f1": 0.990938,
        "accuracy": 0.992908,
        "main_score": 0.990938,
        "hf_subset": "eng-jpn",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.989884,
        "recall": 0.991329,
        "f1": 0.990366,
        "accuracy": 0.991329,
        "main_score": 0.990366,
        "hf_subset": "eng-kaz",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.992572,
        "recall": 0.994918,
        "f1": 0.993354,
        "accuracy": 0.994918,
        "main_score": 0.993354,
        "hf_subset": "eng-kor",
        "languages": [
          "eng-Latn",
          "kor-Kore"
        ]
      },
      {
        "precision": 0.987488,
        "recall": 0.991659,
        "f1": 0.988879,
        "accuracy": 0.991659,
        "main_score": 0.988879,
        "hf_subset": "eng-lav",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.994937,
        "recall": 0.996624,
        "f1": 0.995499,
        "accuracy": 0.996624,
        "main_score": 0.995499,
        "hf_subset": "eng-lit",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 1.0,
        "recall": 1.0,
        "f1": 1.0,
        "accuracy": 1.0,
        "main_score": 1.0,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.954869,
        "recall": 0.965885,
        "f1": 0.958422,
        "accuracy": 0.965885,
        "main_score": 0.958422,
        "hf_subset": "eng-msa",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.985162,
        "recall": 0.989752,
        "f1": 0.986656,
        "accuracy": 0.989752,
        "main_score": 0.986656,
        "hf_subset": "eng-nld",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.991685,
        "recall": 0.994374,
        "f1": 0.992561,
        "accuracy": 0.994374,
        "main_score": 0.992561,
        "hf_subset": "eng-nor",
        "languages": [
          "eng-Latn",
          "nor-Latn"
        ]
      },
      {
        "precision": 0.991458,
        "recall": 0.994176,
        "f1": 0.992356,
        "accuracy": 0.994176,
        "main_score": 0.992356,
        "hf_subset": "eng-pol",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.991698,
        "recall": 0.994277,
        "f1": 0.992544,
        "accuracy": 0.994277,
        "main_score": 0.992544,
        "hf_subset": "eng-por",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.994077,
        "recall": 0.996051,
        "f1": 0.994735,
        "accuracy": 0.996051,
        "main_score": 0.994735,
        "hf_subset": "eng-ron",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.982479,
        "recall": 0.987927,
        "f1": 0.984238,
        "accuracy": 0.987927,
        "main_score": 0.984238,
        "hf_subset": "eng-rus",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.992595,
        "recall": 0.995063,
        "f1": 0.993417,
        "accuracy": 0.995063,
        "main_score": 0.993417,
        "hf_subset": "eng-slk",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.988851,
        "recall": 0.992414,
        "f1": 0.99,
        "accuracy": 0.992414,
        "main_score": 0.99,
        "hf_subset": "eng-slv",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.980999,
        "recall": 0.986853,
        "f1": 0.982914,
        "accuracy": 0.986853,
        "main_score": 0.982914,
        "hf_subset": "eng-spa",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.986249,
        "recall": 0.990099,
        "f1": 0.987349,
        "accuracy": 0.990099,
        "main_score": 0.987349,
        "hf_subset": "eng-srp",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.99209,
        "recall": 0.994671,
        "f1": 0.99295,
        "accuracy": 0.994671,
        "main_score": 0.99295,
        "hf_subset": "eng-swe",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.994555,
        "recall": 0.99637,
        "f1": 0.99516,
        "accuracy": 0.99637,
        "main_score": 0.99516,
        "hf_subset": "eng-tgl",
        "languages": [
          "eng-Latn",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.976966,
        "recall": 0.984029,
        "f1": 0.979197,
        "accuracy": 0.984029,
        "main_score": 0.979197,
        "hf_subset": "eng-tha",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.991714,
        "recall": 0.994355,
        "f1": 0.992582,
        "accuracy": 0.994355,
        "main_score": 0.992582,
        "hf_subset": "eng-tur",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.983854,
        "recall": 0.988618,
        "f1": 0.985398,
        "accuracy": 0.988618,
        "main_score": 0.985398,
        "hf_subset": "eng-ukr",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.988806,
        "recall": 0.992537,
        "f1": 0.99005,
        "accuracy": 0.992537,
        "main_score": 0.99005,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.991957,
        "recall": 0.994462,
        "f1": 0.992748,
        "accuracy": 0.994462,
        "main_score": 0.992748,
        "hf_subset": "eng-vie",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.987279,
        "recall": 0.990926,
        "f1": 0.988452,
        "accuracy": 0.990926,
        "main_score": 0.988452,
        "hf_subset": "eng-zho",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      }
    ]
  },
  "evaluation_time": 1970.6495025157928,
  "kg_co2_emissions": null
}