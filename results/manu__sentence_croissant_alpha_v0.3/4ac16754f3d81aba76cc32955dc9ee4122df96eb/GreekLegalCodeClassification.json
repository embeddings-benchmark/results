{
  "dataset_revision": "de0fdb34424f07d1ac6f0ede23ee0ed44bd9f5d1",
  "task_name": "GreekLegalCodeClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.161621,
        "f1": 0.127585,
        "f1_weighted": 0.170109,
        "scores_per_experiment": [
          {
            "accuracy": 0.159668,
            "f1": 0.134417,
            "f1_weighted": 0.171585
          },
          {
            "accuracy": 0.154785,
            "f1": 0.126082,
            "f1_weighted": 0.160345
          },
          {
            "accuracy": 0.152832,
            "f1": 0.112358,
            "f1_weighted": 0.161977
          },
          {
            "accuracy": 0.154785,
            "f1": 0.118022,
            "f1_weighted": 0.16146
          },
          {
            "accuracy": 0.161621,
            "f1": 0.133436,
            "f1_weighted": 0.166349
          },
          {
            "accuracy": 0.150391,
            "f1": 0.122346,
            "f1_weighted": 0.15528
          },
          {
            "accuracy": 0.181152,
            "f1": 0.145254,
            "f1_weighted": 0.193164
          },
          {
            "accuracy": 0.165039,
            "f1": 0.128409,
            "f1_weighted": 0.174762
          },
          {
            "accuracy": 0.162598,
            "f1": 0.121194,
            "f1_weighted": 0.170072
          },
          {
            "accuracy": 0.17334,
            "f1": 0.134336,
            "f1_weighted": 0.186098
          }
        ],
        "main_score": 0.161621,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.158594,
        "f1": 0.136902,
        "f1_weighted": 0.16302,
        "scores_per_experiment": [
          {
            "accuracy": 0.149414,
            "f1": 0.128814,
            "f1_weighted": 0.1555
          },
          {
            "accuracy": 0.163086,
            "f1": 0.141774,
            "f1_weighted": 0.169064
          },
          {
            "accuracy": 0.145508,
            "f1": 0.120529,
            "f1_weighted": 0.147419
          },
          {
            "accuracy": 0.155273,
            "f1": 0.13619,
            "f1_weighted": 0.158567
          },
          {
            "accuracy": 0.163086,
            "f1": 0.139548,
            "f1_weighted": 0.165684
          },
          {
            "accuracy": 0.152344,
            "f1": 0.135854,
            "f1_weighted": 0.157069
          },
          {
            "accuracy": 0.178711,
            "f1": 0.15198,
            "f1_weighted": 0.1853
          },
          {
            "accuracy": 0.154297,
            "f1": 0.133891,
            "f1_weighted": 0.157652
          },
          {
            "accuracy": 0.157227,
            "f1": 0.136059,
            "f1_weighted": 0.162801
          },
          {
            "accuracy": 0.166992,
            "f1": 0.144382,
            "f1_weighted": 0.171148
          }
        ],
        "main_score": 0.158594,
        "hf_subset": "default",
        "languages": [
          "ell-Grek"
        ]
      }
    ]
  },
  "evaluation_time": 5877.827909231186,
  "kg_co2_emissions": 0.31646899468805023
}