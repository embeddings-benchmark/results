{
  "dataset_revision": "ed1c933c2b3617e5700d8a7ebe07f5975969a453",
  "task_name": "WebLINXCandidatesReranking",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "map": 0.111291,
        "mrr": 0.093092,
        "nAUC_map_max": -0.139951,
        "nAUC_map_std": 0.01253,
        "nAUC_map_diff1": 0.014241,
        "nAUC_mrr_max": -0.145698,
        "nAUC_mrr_std": 0.019511,
        "nAUC_mrr_diff1": 0.015663,
        "main_score": 0.093092,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_iid": [
      {
        "map": 0.100199,
        "mrr": 0.081165,
        "nAUC_map_max": -0.017753,
        "nAUC_map_std": 0.069433,
        "nAUC_map_diff1": 0.056808,
        "nAUC_mrr_max": -0.029295,
        "nAUC_mrr_std": 0.055587,
        "nAUC_mrr_diff1": 0.057351,
        "main_score": 0.081165,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_cat": [
      {
        "map": 0.071426,
        "mrr": 0.051937,
        "nAUC_map_max": -0.145804,
        "nAUC_map_std": 0.391363,
        "nAUC_map_diff1": 0.081962,
        "nAUC_mrr_max": -0.142129,
        "nAUC_mrr_std": 0.348861,
        "nAUC_mrr_diff1": 0.07825,
        "main_score": 0.051937,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_geo": [
      {
        "map": 0.121569,
        "mrr": 0.102984,
        "nAUC_map_max": -0.08259,
        "nAUC_map_std": -0.024617,
        "nAUC_map_diff1": 0.052885,
        "nAUC_mrr_max": -0.078849,
        "nAUC_mrr_std": -0.031539,
        "nAUC_mrr_diff1": 0.04516,
        "main_score": 0.102984,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_vis": [
      {
        "map": 0.103469,
        "mrr": 0.083257,
        "nAUC_map_max": -0.059006,
        "nAUC_map_std": 0.048482,
        "nAUC_map_diff1": 0.117003,
        "nAUC_mrr_max": -0.058892,
        "nAUC_mrr_std": 0.027584,
        "nAUC_mrr_diff1": 0.117414,
        "main_score": 0.083257,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test_web": [
      {
        "map": 0.080749,
        "mrr": 0.061852,
        "nAUC_map_max": 0.014838,
        "nAUC_map_std": 0.040984,
        "nAUC_map_diff1": 0.188981,
        "nAUC_mrr_max": -0.002139,
        "nAUC_mrr_std": 0.019085,
        "nAUC_mrr_diff1": 0.186151,
        "main_score": 0.061852,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 48970.83314371109,
  "kg_co2_emissions": 4.614954302155871
}