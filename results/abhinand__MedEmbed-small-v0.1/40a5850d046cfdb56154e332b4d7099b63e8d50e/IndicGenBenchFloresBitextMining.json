{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "precision": 0.012419,
        "recall": 0.016048,
        "f1": 0.012678,
        "accuracy": 0.016048,
        "main_score": 0.012678,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019116,
        "recall": 0.052156,
        "f1": 0.022969,
        "accuracy": 0.052156,
        "main_score": 0.022969,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.022329,
        "recall": 0.034102,
        "f1": 0.024112,
        "accuracy": 0.034102,
        "main_score": 0.024112,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023487,
        "recall": 0.069208,
        "f1": 0.028788,
        "accuracy": 0.069208,
        "main_score": 0.028788,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.008861,
        "recall": 0.011033,
        "f1": 0.009196,
        "accuracy": 0.011033,
        "main_score": 0.009196,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021353,
        "recall": 0.054162,
        "f1": 0.02593,
        "accuracy": 0.054162,
        "main_score": 0.02593,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.035087,
        "recall": 0.044132,
        "f1": 0.0365,
        "accuracy": 0.044132,
        "main_score": 0.0365,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.035581,
        "recall": 0.088265,
        "f1": 0.044064,
        "accuracy": 0.088265,
        "main_score": 0.044064,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.032449,
        "recall": 0.044132,
        "f1": 0.034024,
        "accuracy": 0.044132,
        "main_score": 0.034024,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.042963,
        "recall": 0.097292,
        "f1": 0.051022,
        "accuracy": 0.097292,
        "main_score": 0.051022,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.012539,
        "recall": 0.014042,
        "f1": 0.012707,
        "accuracy": 0.014042,
        "main_score": 0.012707,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022482,
        "recall": 0.055165,
        "f1": 0.026354,
        "accuracy": 0.055165,
        "main_score": 0.026354,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.032452,
        "recall": 0.039117,
        "f1": 0.033772,
        "accuracy": 0.039117,
        "main_score": 0.033772,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022443,
        "recall": 0.064193,
        "f1": 0.027835,
        "accuracy": 0.064193,
        "main_score": 0.027835,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.065986,
        "recall": 0.079238,
        "f1": 0.067756,
        "accuracy": 0.079238,
        "main_score": 0.067756,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.039374,
        "recall": 0.109328,
        "f1": 0.05003,
        "accuracy": 0.109328,
        "main_score": 0.05003,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.02118,
        "recall": 0.025075,
        "f1": 0.02161,
        "accuracy": 0.025075,
        "main_score": 0.02161,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.029585,
        "recall": 0.067202,
        "f1": 0.035684,
        "accuracy": 0.067202,
        "main_score": 0.035684,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.022034,
        "recall": 0.028084,
        "f1": 0.023189,
        "accuracy": 0.028084,
        "main_score": 0.023189,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018149,
        "recall": 0.051153,
        "f1": 0.022033,
        "accuracy": 0.051153,
        "main_score": 0.022033,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.020563,
        "recall": 0.022066,
        "f1": 0.020731,
        "accuracy": 0.022066,
        "main_score": 0.020731,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026892,
        "recall": 0.066199,
        "f1": 0.032052,
        "accuracy": 0.066199,
        "main_score": 0.032052,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.02292,
        "recall": 0.026078,
        "f1": 0.023271,
        "accuracy": 0.026078,
        "main_score": 0.023271,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030764,
        "recall": 0.074223,
        "f1": 0.036691,
        "accuracy": 0.074223,
        "main_score": 0.036691,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.041866,
        "recall": 0.054162,
        "f1": 0.044569,
        "accuracy": 0.054162,
        "main_score": 0.044569,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.039664,
        "recall": 0.097292,
        "f1": 0.048274,
        "accuracy": 0.097292,
        "main_score": 0.048274,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.03314,
        "recall": 0.041123,
        "f1": 0.034479,
        "accuracy": 0.041123,
        "main_score": 0.034479,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031764,
        "recall": 0.084253,
        "f1": 0.039724,
        "accuracy": 0.084253,
        "main_score": 0.039724,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.109766,
        "recall": 0.127382,
        "f1": 0.113541,
        "accuracy": 0.127382,
        "main_score": 0.113541,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.087668,
        "recall": 0.17653,
        "f1": 0.104294,
        "accuracy": 0.17653,
        "main_score": 0.104294,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.027417,
        "recall": 0.033099,
        "f1": 0.028922,
        "accuracy": 0.033099,
        "main_score": 0.028922,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030555,
        "recall": 0.072217,
        "f1": 0.036101,
        "accuracy": 0.072217,
        "main_score": 0.036101,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006543,
        "recall": 0.009027,
        "f1": 0.006732,
        "accuracy": 0.009027,
        "main_score": 0.006732,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026106,
        "recall": 0.052156,
        "f1": 0.029721,
        "accuracy": 0.052156,
        "main_score": 0.029721,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.009028,
        "recall": 0.01003,
        "f1": 0.009029,
        "accuracy": 0.01003,
        "main_score": 0.009029,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022913,
        "recall": 0.051153,
        "f1": 0.026295,
        "accuracy": 0.051153,
        "main_score": 0.026295,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.006555,
        "recall": 0.009027,
        "f1": 0.006756,
        "accuracy": 0.009027,
        "main_score": 0.006756,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008807,
        "recall": 0.032096,
        "f1": 0.011472,
        "accuracy": 0.032096,
        "main_score": 0.011472,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.009362,
        "recall": 0.012036,
        "f1": 0.009865,
        "accuracy": 0.012036,
        "main_score": 0.009865,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020154,
        "recall": 0.055165,
        "f1": 0.024557,
        "accuracy": 0.055165,
        "main_score": 0.024557,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.011034,
        "recall": 0.013039,
        "f1": 0.01137,
        "accuracy": 0.013039,
        "main_score": 0.01137,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026351,
        "recall": 0.054162,
        "f1": 0.029393,
        "accuracy": 0.054162,
        "main_score": 0.029393,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.015247,
        "recall": 0.017051,
        "f1": 0.015382,
        "accuracy": 0.017051,
        "main_score": 0.015382,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.029238,
        "recall": 0.067202,
        "f1": 0.034369,
        "accuracy": 0.067202,
        "main_score": 0.034369,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.001012,
        "recall": 0.003009,
        "f1": 0.001021,
        "accuracy": 0.003009,
        "main_score": 0.001021,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019181,
        "recall": 0.044132,
        "f1": 0.022869,
        "accuracy": 0.044132,
        "main_score": 0.022869,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.013542,
        "recall": 0.015045,
        "f1": 0.01371,
        "accuracy": 0.015045,
        "main_score": 0.01371,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024159,
        "recall": 0.058175,
        "f1": 0.028734,
        "accuracy": 0.058175,
        "main_score": 0.028734,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.011034,
        "recall": 0.013039,
        "f1": 0.01137,
        "accuracy": 0.013039,
        "main_score": 0.01137,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031093,
        "recall": 0.065196,
        "f1": 0.035712,
        "accuracy": 0.065196,
        "main_score": 0.035712,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.01739,
        "recall": 0.028084,
        "f1": 0.018868,
        "accuracy": 0.028084,
        "main_score": 0.018868,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023728,
        "recall": 0.067202,
        "f1": 0.029718,
        "accuracy": 0.067202,
        "main_score": 0.029718,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.006019,
        "recall": 0.008024,
        "f1": 0.006355,
        "accuracy": 0.008024,
        "main_score": 0.006355,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021834,
        "recall": 0.048144,
        "f1": 0.025766,
        "accuracy": 0.048144,
        "main_score": 0.025766,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.005518,
        "recall": 0.007021,
        "f1": 0.005686,
        "accuracy": 0.007021,
        "main_score": 0.005686,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024658,
        "recall": 0.059178,
        "f1": 0.029099,
        "accuracy": 0.059178,
        "main_score": 0.029099,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.008603,
        "recall": 0.01003,
        "f1": 0.008836,
        "accuracy": 0.01003,
        "main_score": 0.008836,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002288,
        "recall": 0.019057,
        "f1": 0.00362,
        "accuracy": 0.019057,
        "main_score": 0.00362,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.01294,
        "recall": 0.01581,
        "f1": 0.013026,
        "accuracy": 0.01581,
        "main_score": 0.013026,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01868,
        "recall": 0.057312,
        "f1": 0.023491,
        "accuracy": 0.057312,
        "main_score": 0.023491,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.019727,
        "recall": 0.029644,
        "f1": 0.021461,
        "accuracy": 0.029644,
        "main_score": 0.021461,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026058,
        "recall": 0.070158,
        "f1": 0.032503,
        "accuracy": 0.070158,
        "main_score": 0.032503,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.013351,
        "recall": 0.016798,
        "f1": 0.013527,
        "accuracy": 0.016798,
        "main_score": 0.013527,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022353,
        "recall": 0.0583,
        "f1": 0.026841,
        "accuracy": 0.0583,
        "main_score": 0.026841,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.027149,
        "recall": 0.034585,
        "f1": 0.028302,
        "accuracy": 0.034585,
        "main_score": 0.028302,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.039743,
        "recall": 0.088933,
        "f1": 0.047092,
        "accuracy": 0.088933,
        "main_score": 0.047092,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.013919,
        "recall": 0.024704,
        "f1": 0.015585,
        "accuracy": 0.024704,
        "main_score": 0.015585,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.02768,
        "recall": 0.070158,
        "f1": 0.033869,
        "accuracy": 0.070158,
        "main_score": 0.033869,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.008,
        "recall": 0.012846,
        "f1": 0.00849,
        "accuracy": 0.012846,
        "main_score": 0.00849,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020774,
        "recall": 0.054348,
        "f1": 0.024845,
        "accuracy": 0.054348,
        "main_score": 0.024845,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.013902,
        "recall": 0.018775,
        "f1": 0.01474,
        "accuracy": 0.018775,
        "main_score": 0.01474,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026018,
        "recall": 0.068182,
        "f1": 0.031802,
        "accuracy": 0.068182,
        "main_score": 0.031802,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.066871,
        "recall": 0.08004,
        "f1": 0.069624,
        "accuracy": 0.08004,
        "main_score": 0.069624,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.058744,
        "recall": 0.131423,
        "f1": 0.070177,
        "accuracy": 0.131423,
        "main_score": 0.070177,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.008335,
        "recall": 0.011858,
        "f1": 0.008911,
        "accuracy": 0.011858,
        "main_score": 0.008911,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012195,
        "recall": 0.046443,
        "f1": 0.016378,
        "accuracy": 0.046443,
        "main_score": 0.016378,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.012291,
        "recall": 0.017787,
        "f1": 0.012882,
        "accuracy": 0.017787,
        "main_score": 0.012882,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017838,
        "recall": 0.041502,
        "f1": 0.021059,
        "accuracy": 0.041502,
        "main_score": 0.021059,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.014318,
        "recall": 0.019763,
        "f1": 0.014931,
        "accuracy": 0.019763,
        "main_score": 0.014931,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026698,
        "recall": 0.057312,
        "f1": 0.031951,
        "accuracy": 0.057312,
        "main_score": 0.031951,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.029113,
        "recall": 0.033597,
        "f1": 0.029405,
        "accuracy": 0.033597,
        "main_score": 0.029405,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.03107,
        "recall": 0.076087,
        "f1": 0.036969,
        "accuracy": 0.076087,
        "main_score": 0.036969,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.026376,
        "recall": 0.032609,
        "f1": 0.027473,
        "accuracy": 0.032609,
        "main_score": 0.027473,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.029145,
        "recall": 0.082016,
        "f1": 0.036683,
        "accuracy": 0.082016,
        "main_score": 0.036683,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.026085,
        "recall": 0.035573,
        "f1": 0.027894,
        "accuracy": 0.035573,
        "main_score": 0.027894,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.035444,
        "recall": 0.085968,
        "f1": 0.042618,
        "accuracy": 0.085968,
        "main_score": 0.042618,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.077027,
        "recall": 0.083992,
        "f1": 0.078791,
        "accuracy": 0.083992,
        "main_score": 0.078791,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.069343,
        "recall": 0.144269,
        "f1": 0.082385,
        "accuracy": 0.144269,
        "main_score": 0.082385,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.031713,
        "recall": 0.038538,
        "f1": 0.032859,
        "accuracy": 0.038538,
        "main_score": 0.032859,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.032264,
        "recall": 0.068182,
        "f1": 0.036405,
        "accuracy": 0.068182,
        "main_score": 0.036405,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.006269,
        "recall": 0.009881,
        "f1": 0.006444,
        "accuracy": 0.009881,
        "main_score": 0.006444,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021729,
        "recall": 0.050395,
        "f1": 0.024923,
        "accuracy": 0.050395,
        "main_score": 0.024923,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.002387,
        "recall": 0.005929,
        "f1": 0.002622,
        "accuracy": 0.005929,
        "main_score": 0.002622,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015692,
        "recall": 0.032609,
        "f1": 0.01784,
        "accuracy": 0.032609,
        "main_score": 0.01784,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.002076,
        "recall": 0.003953,
        "f1": 0.002158,
        "accuracy": 0.003953,
        "main_score": 0.002158,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009228,
        "recall": 0.024704,
        "f1": 0.011622,
        "accuracy": 0.024704,
        "main_score": 0.011622,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.004286,
        "recall": 0.007905,
        "f1": 0.004785,
        "accuracy": 0.007905,
        "main_score": 0.004785,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027528,
        "recall": 0.057312,
        "f1": 0.03219,
        "accuracy": 0.057312,
        "main_score": 0.03219,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.009343,
        "recall": 0.014822,
        "f1": 0.009935,
        "accuracy": 0.014822,
        "main_score": 0.009935,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021016,
        "recall": 0.052372,
        "f1": 0.025155,
        "accuracy": 0.052372,
        "main_score": 0.025155,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.023566,
        "recall": 0.029644,
        "f1": 0.02457,
        "accuracy": 0.029644,
        "main_score": 0.02457,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.040642,
        "recall": 0.093874,
        "f1": 0.047823,
        "accuracy": 0.093874,
        "main_score": 0.047823,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.00152,
        "recall": 0.004941,
        "f1": 0.001821,
        "accuracy": 0.004941,
        "main_score": 0.001821,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0175,
        "recall": 0.035573,
        "f1": 0.019627,
        "accuracy": 0.035573,
        "main_score": 0.019627,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.011698,
        "recall": 0.014822,
        "f1": 0.012032,
        "accuracy": 0.014822,
        "main_score": 0.012032,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.029764,
        "recall": 0.066206,
        "f1": 0.03427,
        "accuracy": 0.066206,
        "main_score": 0.03427,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.010715,
        "recall": 0.014822,
        "f1": 0.011055,
        "accuracy": 0.014822,
        "main_score": 0.011055,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028879,
        "recall": 0.063241,
        "f1": 0.033761,
        "accuracy": 0.063241,
        "main_score": 0.033761,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.011806,
        "recall": 0.016798,
        "f1": 0.012607,
        "accuracy": 0.016798,
        "main_score": 0.012607,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014835,
        "recall": 0.050395,
        "f1": 0.019877,
        "accuracy": 0.050395,
        "main_score": 0.019877,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.005276,
        "recall": 0.007905,
        "f1": 0.005447,
        "accuracy": 0.007905,
        "main_score": 0.005447,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018102,
        "recall": 0.048419,
        "f1": 0.021389,
        "accuracy": 0.048419,
        "main_score": 0.021389,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.013181,
        "recall": 0.016798,
        "f1": 0.013681,
        "accuracy": 0.016798,
        "main_score": 0.013681,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027755,
        "recall": 0.067194,
        "f1": 0.032844,
        "accuracy": 0.067194,
        "main_score": 0.032844,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 0.005767,
        "recall": 0.008893,
        "f1": 0.006428,
        "accuracy": 0.008893,
        "main_score": 0.006428,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004319,
        "recall": 0.023715,
        "f1": 0.005783,
        "accuracy": 0.023715,
        "main_score": 0.005783,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 50.10285139083862,
  "kg_co2_emissions": 0.0027384661455796557
}