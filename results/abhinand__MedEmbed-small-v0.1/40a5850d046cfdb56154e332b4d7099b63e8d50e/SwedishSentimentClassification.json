{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.707568,
        "f1": 0.706246,
        "f1_weighted": 0.70624,
        "ap": 0.649487,
        "ap_weighted": 0.649487,
        "scores_per_experiment": [
          {
            "accuracy": 0.728027,
            "f1": 0.724584,
            "f1_weighted": 0.724674,
            "ap": 0.657668,
            "ap_weighted": 0.657668
          },
          {
            "accuracy": 0.685547,
            "f1": 0.684911,
            "f1_weighted": 0.68487,
            "ap": 0.632199,
            "ap_weighted": 0.632199
          },
          {
            "accuracy": 0.668945,
            "f1": 0.66868,
            "f1_weighted": 0.668652,
            "ap": 0.616274,
            "ap_weighted": 0.616274
          },
          {
            "accuracy": 0.692871,
            "f1": 0.689051,
            "f1_weighted": 0.68895,
            "ap": 0.646063,
            "ap_weighted": 0.646063
          },
          {
            "accuracy": 0.703125,
            "f1": 0.703102,
            "f1_weighted": 0.703094,
            "ap": 0.645055,
            "ap_weighted": 0.645055
          },
          {
            "accuracy": 0.728516,
            "f1": 0.728282,
            "f1_weighted": 0.728306,
            "ap": 0.664968,
            "ap_weighted": 0.664968
          },
          {
            "accuracy": 0.728516,
            "f1": 0.724986,
            "f1_weighted": 0.725078,
            "ap": 0.657988,
            "ap_weighted": 0.657988
          },
          {
            "accuracy": 0.737793,
            "f1": 0.737102,
            "f1_weighted": 0.737062,
            "ap": 0.683548,
            "ap_weighted": 0.683548
          },
          {
            "accuracy": 0.686035,
            "f1": 0.685963,
            "f1_weighted": 0.685949,
            "ap": 0.630219,
            "ap_weighted": 0.630219
          },
          {
            "accuracy": 0.716309,
            "f1": 0.715796,
            "f1_weighted": 0.71576,
            "ap": 0.660893,
            "ap_weighted": 0.660893
          }
        ],
        "main_score": 0.707568,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.704688,
        "f1": 0.703108,
        "f1_weighted": 0.703102,
        "ap": 0.647257,
        "ap_weighted": 0.647257,
        "scores_per_experiment": [
          {
            "accuracy": 0.709473,
            "f1": 0.705461,
            "f1_weighted": 0.705529,
            "ap": 0.641086,
            "ap_weighted": 0.641086
          },
          {
            "accuracy": 0.70752,
            "f1": 0.706719,
            "f1_weighted": 0.706689,
            "ap": 0.652937,
            "ap_weighted": 0.652937
          },
          {
            "accuracy": 0.660156,
            "f1": 0.659344,
            "f1_weighted": 0.659312,
            "ap": 0.60957,
            "ap_weighted": 0.60957
          },
          {
            "accuracy": 0.696289,
            "f1": 0.692272,
            "f1_weighted": 0.692203,
            "ap": 0.649319,
            "ap_weighted": 0.649319
          },
          {
            "accuracy": 0.71582,
            "f1": 0.715722,
            "f1_weighted": 0.715712,
            "ap": 0.6573,
            "ap_weighted": 0.6573
          },
          {
            "accuracy": 0.72998,
            "f1": 0.729578,
            "f1_weighted": 0.729598,
            "ap": 0.664995,
            "ap_weighted": 0.664995
          },
          {
            "accuracy": 0.706543,
            "f1": 0.702353,
            "f1_weighted": 0.702422,
            "ap": 0.638522,
            "ap_weighted": 0.638522
          },
          {
            "accuracy": 0.749023,
            "f1": 0.748399,
            "f1_weighted": 0.748375,
            "ap": 0.694481,
            "ap_weighted": 0.694481
          },
          {
            "accuracy": 0.662598,
            "f1": 0.662435,
            "f1_weighted": 0.66242,
            "ap": 0.609969,
            "ap_weighted": 0.609969
          },
          {
            "accuracy": 0.709473,
            "f1": 0.708792,
            "f1_weighted": 0.708765,
            "ap": 0.654391,
            "ap_weighted": 0.654391
          }
        ],
        "main_score": 0.704688,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 15.948780536651611,
  "kg_co2_emissions": 0.0005313674759309527
}