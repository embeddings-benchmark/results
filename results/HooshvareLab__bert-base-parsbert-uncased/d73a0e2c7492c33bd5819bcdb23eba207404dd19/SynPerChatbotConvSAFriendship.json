{
  "dataset_revision": "9dae119101e9b4e9bb40d5b9d29ffd7a621f9942",
  "task_name": "SynPerChatbotConvSAFriendship",
  "mteb_version": "1.25.8",
  "scores": {
    "test": [
      {
        "accuracy": 0.623188,
        "f1": 0.605663,
        "f1_weighted": 0.633027,
        "ap": 0.730346,
        "ap_weighted": 0.730346,
        "scores_per_experiment": [
          {
            "accuracy": 0.630435,
            "f1": 0.61336,
            "f1_weighted": 0.640444,
            "ap": 0.733913,
            "ap_weighted": 0.733913
          },
          {
            "accuracy": 0.572464,
            "f1": 0.560248,
            "f1_weighted": 0.584679,
            "ap": 0.706837,
            "ap_weighted": 0.706837
          },
          {
            "accuracy": 0.637681,
            "f1": 0.614267,
            "f1_weighted": 0.645945,
            "ap": 0.730208,
            "ap_weighted": 0.730208
          },
          {
            "accuracy": 0.557971,
            "f1": 0.545342,
            "f1_weighted": 0.5706,
            "ap": 0.698173,
            "ap_weighted": 0.698173
          },
          {
            "accuracy": 0.681159,
            "f1": 0.660555,
            "f1_weighted": 0.688432,
            "ap": 0.75942,
            "ap_weighted": 0.75942
          },
          {
            "accuracy": 0.695652,
            "f1": 0.680556,
            "f1_weighted": 0.703704,
            "ap": 0.777794,
            "ap_weighted": 0.777794
          },
          {
            "accuracy": 0.666667,
            "f1": 0.642326,
            "f1_weighted": 0.673428,
            "ap": 0.745847,
            "ap_weighted": 0.745847
          },
          {
            "accuracy": 0.543478,
            "f1": 0.519217,
            "f1_weighted": 0.555218,
            "ap": 0.679136,
            "ap_weighted": 0.679136
          },
          {
            "accuracy": 0.623188,
            "f1": 0.609321,
            "f1_weighted": 0.633856,
            "ap": 0.7343,
            "ap_weighted": 0.7343
          },
          {
            "accuracy": 0.623188,
            "f1": 0.611436,
            "f1_weighted": 0.633961,
            "ap": 0.737836,
            "ap_weighted": 0.737836
          }
        ],
        "main_score": 0.623188,
        "hf_subset": "default",
        "languages": [
          "fas-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 9.771921396255493,
  "kg_co2_emissions": null
}