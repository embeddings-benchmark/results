{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.707324,
        "f1": 0.705434,
        "f1_weighted": 0.705463,
        "ap": 0.646817,
        "ap_weighted": 0.646817,
        "scores_per_experiment": [
          {
            "accuracy": 0.712402,
            "f1": 0.707873,
            "f1_weighted": 0.70798,
            "ap": 0.643463,
            "ap_weighted": 0.643463
          },
          {
            "accuracy": 0.699219,
            "f1": 0.697508,
            "f1_weighted": 0.697575,
            "ap": 0.635378,
            "ap_weighted": 0.635378
          },
          {
            "accuracy": 0.722656,
            "f1": 0.722652,
            "f1_weighted": 0.722649,
            "ap": 0.662776,
            "ap_weighted": 0.662776
          },
          {
            "accuracy": 0.710449,
            "f1": 0.710449,
            "f1_weighted": 0.710447,
            "ap": 0.651117,
            "ap_weighted": 0.651117
          },
          {
            "accuracy": 0.732422,
            "f1": 0.732127,
            "f1_weighted": 0.732101,
            "ap": 0.675652,
            "ap_weighted": 0.675652
          },
          {
            "accuracy": 0.6875,
            "f1": 0.684179,
            "f1_weighted": 0.684085,
            "ap": 0.639771,
            "ap_weighted": 0.639771
          },
          {
            "accuracy": 0.68457,
            "f1": 0.677747,
            "f1_weighted": 0.677885,
            "ap": 0.619788,
            "ap_weighted": 0.619788
          },
          {
            "accuracy": 0.722168,
            "f1": 0.722067,
            "f1_weighted": 0.722083,
            "ap": 0.660044,
            "ap_weighted": 0.660044
          },
          {
            "accuracy": 0.673828,
            "f1": 0.671774,
            "f1_weighted": 0.67185,
            "ap": 0.614276,
            "ap_weighted": 0.614276
          },
          {
            "accuracy": 0.728027,
            "f1": 0.727965,
            "f1_weighted": 0.727977,
            "ap": 0.665905,
            "ap_weighted": 0.665905
          }
        ],
        "main_score": 0.707324,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.708545,
        "f1": 0.70644,
        "f1_weighted": 0.706457,
        "ap": 0.647766,
        "ap_weighted": 0.647766,
        "scores_per_experiment": [
          {
            "accuracy": 0.724609,
            "f1": 0.720444,
            "f1_weighted": 0.72051,
            "ap": 0.653612,
            "ap_weighted": 0.653612
          },
          {
            "accuracy": 0.710938,
            "f1": 0.709657,
            "f1_weighted": 0.709695,
            "ap": 0.645603,
            "ap_weighted": 0.645603
          },
          {
            "accuracy": 0.736328,
            "f1": 0.736272,
            "f1_weighted": 0.736264,
            "ap": 0.676711,
            "ap_weighted": 0.676711
          },
          {
            "accuracy": 0.718262,
            "f1": 0.71825,
            "f1_weighted": 0.718247,
            "ap": 0.658373,
            "ap_weighted": 0.658373
          },
          {
            "accuracy": 0.721191,
            "f1": 0.720664,
            "f1_weighted": 0.72064,
            "ap": 0.665251,
            "ap_weighted": 0.665251
          },
          {
            "accuracy": 0.669922,
            "f1": 0.665248,
            "f1_weighted": 0.665171,
            "ap": 0.623989,
            "ap_weighted": 0.623989
          },
          {
            "accuracy": 0.669922,
            "f1": 0.661976,
            "f1_weighted": 0.662077,
            "ap": 0.607799,
            "ap_weighted": 0.607799
          },
          {
            "accuracy": 0.711426,
            "f1": 0.711117,
            "f1_weighted": 0.711135,
            "ap": 0.648585,
            "ap_weighted": 0.648585
          },
          {
            "accuracy": 0.687012,
            "f1": 0.684967,
            "f1_weighted": 0.685016,
            "ap": 0.624467,
            "ap_weighted": 0.624467
          },
          {
            "accuracy": 0.73584,
            "f1": 0.735807,
            "f1_weighted": 0.735812,
            "ap": 0.673274,
            "ap_weighted": 0.673274
          }
        ],
        "main_score": 0.708545,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 186.33251309394836,
  "kg_co2_emissions": 0.015595640543719355
}