{
  "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
  "task_name": "NTREXBitextMining",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "precision": 0.043205,
        "recall": 0.057086,
        "f1": 0.04658,
        "accuracy": 0.057086,
        "main_score": 0.04658,
        "hf_subset": "afr_Latn-dan_Latn",
        "languages": [
          "afr-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.047198,
        "recall": 0.062594,
        "f1": 0.050501,
        "accuracy": 0.062594,
        "main_score": 0.050501,
        "hf_subset": "afr_Latn-deu_Latn",
        "languages": [
          "afr-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.030795,
        "recall": 0.048072,
        "f1": 0.033444,
        "accuracy": 0.048072,
        "main_score": 0.033444,
        "hf_subset": "afr_Latn-eng_Latn",
        "languages": [
          "afr-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019033,
        "recall": 0.027041,
        "f1": 0.020598,
        "accuracy": 0.027041,
        "main_score": 0.020598,
        "hf_subset": "afr_Latn-fao_Latn",
        "languages": [
          "afr-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.01655,
        "recall": 0.022534,
        "f1": 0.017709,
        "accuracy": 0.022534,
        "main_score": 0.017709,
        "hf_subset": "afr_Latn-isl_Latn",
        "languages": [
          "afr-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.048254,
        "recall": 0.063595,
        "f1": 0.051442,
        "accuracy": 0.063595,
        "main_score": 0.051442,
        "hf_subset": "afr_Latn-ltz_Latn",
        "languages": [
          "afr-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.193309,
        "recall": 0.249374,
        "f1": 0.205453,
        "accuracy": 0.249374,
        "main_score": 0.205453,
        "hf_subset": "afr_Latn-nld_Latn",
        "languages": [
          "afr-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.03329,
        "recall": 0.043065,
        "f1": 0.035175,
        "accuracy": 0.043065,
        "main_score": 0.035175,
        "hf_subset": "afr_Latn-nno_Latn",
        "languages": [
          "afr-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.046584,
        "recall": 0.062093,
        "f1": 0.049974,
        "accuracy": 0.062093,
        "main_score": 0.049974,
        "hf_subset": "afr_Latn-nob_Latn",
        "languages": [
          "afr-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.033472,
        "recall": 0.047071,
        "f1": 0.035542,
        "accuracy": 0.047071,
        "main_score": 0.035542,
        "hf_subset": "afr_Latn-swe_Latn",
        "languages": [
          "afr-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.048907,
        "recall": 0.062594,
        "f1": 0.051959,
        "accuracy": 0.062594,
        "main_score": 0.051959,
        "hf_subset": "amh_Ethi-eng_Latn",
        "languages": [
          "amh-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009234,
        "recall": 0.018528,
        "f1": 0.010834,
        "accuracy": 0.018528,
        "main_score": 0.010834,
        "hf_subset": "amh_Ethi-hau_Latn",
        "languages": [
          "amh-Ethi",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.009694,
        "recall": 0.019529,
        "f1": 0.011181,
        "accuracy": 0.019529,
        "main_score": 0.011181,
        "hf_subset": "amh_Ethi-ibo_Latn",
        "languages": [
          "amh-Ethi",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.010023,
        "recall": 0.016525,
        "f1": 0.011109,
        "accuracy": 0.016525,
        "main_score": 0.011109,
        "hf_subset": "amh_Ethi-nso_Latn",
        "languages": [
          "amh-Ethi",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.003287,
        "recall": 0.008012,
        "f1": 0.003936,
        "accuracy": 0.008012,
        "main_score": 0.003936,
        "hf_subset": "amh_Ethi-orm_Ethi",
        "languages": [
          "amh-Ethi",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.006758,
        "recall": 0.01302,
        "f1": 0.007628,
        "accuracy": 0.01302,
        "main_score": 0.007628,
        "hf_subset": "amh_Ethi-som_Latn",
        "languages": [
          "amh-Ethi",
          "som-Latn"
        ]
      },
      {
        "precision": 0.006812,
        "recall": 0.01302,
        "f1": 0.007898,
        "accuracy": 0.01302,
        "main_score": 0.007898,
        "hf_subset": "amh_Ethi-ssw_Latn",
        "languages": [
          "amh-Ethi",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.004492,
        "recall": 0.010015,
        "f1": 0.005463,
        "accuracy": 0.010015,
        "main_score": 0.005463,
        "hf_subset": "amh_Ethi-swa_Latn",
        "languages": [
          "amh-Ethi",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.064027,
        "recall": 0.087131,
        "f1": 0.069773,
        "accuracy": 0.087131,
        "main_score": 0.069773,
        "hf_subset": "amh_Ethi-tir_Ethi",
        "languages": [
          "amh-Ethi",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.00799,
        "recall": 0.015023,
        "f1": 0.009003,
        "accuracy": 0.015023,
        "main_score": 0.009003,
        "hf_subset": "amh_Ethi-tsn_Latn",
        "languages": [
          "amh-Ethi",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.00898,
        "recall": 0.014522,
        "f1": 0.009781,
        "accuracy": 0.014522,
        "main_score": 0.009781,
        "hf_subset": "amh_Ethi-wol_Latn",
        "languages": [
          "amh-Ethi",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.003909,
        "recall": 0.009514,
        "f1": 0.004642,
        "accuracy": 0.009514,
        "main_score": 0.004642,
        "hf_subset": "amh_Ethi-xho_Latn",
        "languages": [
          "amh-Ethi",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.00793,
        "recall": 0.016024,
        "f1": 0.0092,
        "accuracy": 0.016024,
        "main_score": 0.0092,
        "hf_subset": "amh_Ethi-yor_Latn",
        "languages": [
          "amh-Ethi",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.010206,
        "recall": 0.016525,
        "f1": 0.011199,
        "accuracy": 0.016525,
        "main_score": 0.011199,
        "hf_subset": "amh_Ethi-zul_Latn",
        "languages": [
          "amh-Ethi",
          "zul-Latn"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001502,
        "f1": 9e-06,
        "accuracy": 0.001502,
        "main_score": 9e-06,
        "hf_subset": "arb_Arab-ben_Beng",
        "languages": [
          "arb-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "arb_Arab-ckb_Arab",
        "languages": [
          "arb-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 4e-06,
        "accuracy": 0.000501,
        "main_score": 4e-06,
        "hf_subset": "arb_Arab-deu_Latn",
        "languages": [
          "arb-Arab",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "arb_Arab-ell_Grek",
        "languages": [
          "arb-Arab",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-eng_Latn",
        "languages": [
          "arb-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001061,
        "recall": 0.003005,
        "f1": 0.001116,
        "accuracy": 0.003005,
        "main_score": 0.001116,
        "hf_subset": "arb_Arab-fas_Arab",
        "languages": [
          "arb-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.001002,
        "f1": 1.8e-05,
        "accuracy": 0.001002,
        "main_score": 1.8e-05,
        "hf_subset": "arb_Arab-fin_Latn",
        "languages": [
          "arb-Arab",
          "fin-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-fra_Latn",
        "languages": [
          "arb-Arab",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000252,
        "recall": 0.001502,
        "f1": 0.000336,
        "accuracy": 0.001502,
        "main_score": 0.000336,
        "hf_subset": "arb_Arab-heb_Hebr",
        "languages": [
          "arb-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-hin_Deva",
        "languages": [
          "arb-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-hun_Latn",
        "languages": [
          "arb-Arab",
          "hun-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-ind_Latn",
        "languages": [
          "arb-Arab",
          "ind-Latn"
        ]
      },
      {
        "precision": 1.9e-05,
        "recall": 0.001502,
        "f1": 3.8e-05,
        "accuracy": 0.001502,
        "main_score": 3.8e-05,
        "hf_subset": "arb_Arab-jpn_Jpan",
        "languages": [
          "arb-Arab",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000503,
        "accuracy": 0.001002,
        "main_score": 0.000503,
        "hf_subset": "arb_Arab-kmr_Latn",
        "languages": [
          "arb-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000585,
        "recall": 0.001502,
        "f1": 0.000645,
        "accuracy": 0.001502,
        "main_score": 0.000645,
        "hf_subset": "arb_Arab-kor_Hang",
        "languages": [
          "arb-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "arb_Arab-lit_Latn",
        "languages": [
          "arb-Arab",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.097313,
        "recall": 0.151227,
        "f1": 0.109671,
        "accuracy": 0.151227,
        "main_score": 0.109671,
        "hf_subset": "arb_Arab-mey_Arab",
        "languages": [
          "arb-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 2.5e-05,
        "recall": 0.001002,
        "f1": 4.8e-05,
        "accuracy": 0.001002,
        "main_score": 4.8e-05,
        "hf_subset": "arb_Arab-nld_Latn",
        "languages": [
          "arb-Arab",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-pol_Latn",
        "languages": [
          "arb-Arab",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-por_Latn",
        "languages": [
          "arb-Arab",
          "por-Latn"
        ]
      },
      {
        "precision": 0.00028,
        "recall": 0.002504,
        "f1": 0.000392,
        "accuracy": 0.002504,
        "main_score": 0.000392,
        "hf_subset": "arb_Arab-prs_Arab",
        "languages": [
          "arb-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000795,
        "recall": 0.002003,
        "f1": 0.000955,
        "accuracy": 0.002003,
        "main_score": 0.000955,
        "hf_subset": "arb_Arab-pus_Arab",
        "languages": [
          "arb-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.000102,
        "recall": 0.001002,
        "f1": 0.000171,
        "accuracy": 0.001002,
        "main_score": 0.000171,
        "hf_subset": "arb_Arab-rus_Cyrl",
        "languages": [
          "arb-Arab",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.013166,
        "recall": 0.026039,
        "f1": 0.014782,
        "accuracy": 0.026039,
        "main_score": 0.014782,
        "hf_subset": "arb_Arab-shi_Arab",
        "languages": [
          "arb-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-spa_Latn",
        "languages": [
          "arb-Arab",
          "spa-Latn"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.000501,
        "f1": 2.2e-05,
        "accuracy": 0.000501,
        "main_score": 2.2e-05,
        "hf_subset": "arb_Arab-swa_Latn",
        "languages": [
          "arb-Arab",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-swe_Latn",
        "languages": [
          "arb-Arab",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000167,
        "recall": 0.001002,
        "f1": 0.000251,
        "accuracy": 0.001002,
        "main_score": 0.000251,
        "hf_subset": "arb_Arab-tam_Taml",
        "languages": [
          "arb-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000167,
        "recall": 0.001002,
        "f1": 0.000251,
        "accuracy": 0.001002,
        "main_score": 0.000251,
        "hf_subset": "arb_Arab-tgk_Cyrl",
        "languages": [
          "arb-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "arb_Arab-tur_Latn",
        "languages": [
          "arb-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 5e-06,
        "accuracy": 0.000501,
        "main_score": 5e-06,
        "hf_subset": "arb_Arab-vie_Latn",
        "languages": [
          "arb-Arab",
          "vie-Latn"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.001502,
        "f1": 1.5e-05,
        "accuracy": 0.001502,
        "main_score": 1.5e-05,
        "hf_subset": "arb_Arab-zho_Hant",
        "languages": [
          "arb-Arab",
          "zho-Hant"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 5e-06,
        "accuracy": 0.000501,
        "main_score": 5e-06,
        "hf_subset": "arb_Arab-zul_Latn",
        "languages": [
          "arb-Arab",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.001016,
        "recall": 0.002504,
        "f1": 0.001031,
        "accuracy": 0.002504,
        "main_score": 0.001031,
        "hf_subset": "aze_Latn-bak_Cyrl",
        "languages": [
          "aze-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.003892,
        "recall": 0.007511,
        "f1": 0.004086,
        "accuracy": 0.007511,
        "main_score": 0.004086,
        "hf_subset": "aze_Latn-eng_Latn",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001107,
        "recall": 0.002003,
        "f1": 0.001179,
        "accuracy": 0.002003,
        "main_score": 0.001179,
        "hf_subset": "aze_Latn-kaz_Cyrl",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.000764,
        "recall": 0.002504,
        "f1": 0.000946,
        "accuracy": 0.002504,
        "main_score": 0.000946,
        "hf_subset": "aze_Latn-kir_Cyrl",
        "languages": [
          "aze-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.001568,
        "recall": 0.003505,
        "f1": 0.001791,
        "accuracy": 0.003505,
        "main_score": 0.001791,
        "hf_subset": "aze_Latn-tat_Cyrl",
        "languages": [
          "aze-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.002126,
        "recall": 0.004507,
        "f1": 0.002215,
        "accuracy": 0.004507,
        "main_score": 0.002215,
        "hf_subset": "aze_Latn-tuk_Latn",
        "languages": [
          "aze-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.012182,
        "recall": 0.017026,
        "f1": 0.013129,
        "accuracy": 0.017026,
        "main_score": 0.013129,
        "hf_subset": "aze_Latn-tur_Latn",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000574,
        "recall": 0.003505,
        "f1": 0.000867,
        "accuracy": 0.003505,
        "main_score": 0.000867,
        "hf_subset": "aze_Latn-uig_Arab",
        "languages": [
          "aze-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.004289,
        "recall": 0.008513,
        "f1": 0.004643,
        "accuracy": 0.008513,
        "main_score": 0.004643,
        "hf_subset": "aze_Latn-uzb_Latn",
        "languages": [
          "aze-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.000509,
        "recall": 0.002003,
        "f1": 0.000516,
        "accuracy": 0.002003,
        "main_score": 0.000516,
        "hf_subset": "bak_Cyrl-aze_Latn",
        "languages": [
          "bak-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.00278,
        "recall": 0.005008,
        "f1": 0.002887,
        "accuracy": 0.005008,
        "main_score": 0.002887,
        "hf_subset": "bak_Cyrl-eng_Latn",
        "languages": [
          "bak-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021391,
        "recall": 0.049574,
        "f1": 0.026465,
        "accuracy": 0.049574,
        "main_score": 0.026465,
        "hf_subset": "bak_Cyrl-kaz_Cyrl",
        "languages": [
          "bak-Cyrl",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.019928,
        "recall": 0.042564,
        "f1": 0.024316,
        "accuracy": 0.042564,
        "main_score": 0.024316,
        "hf_subset": "bak_Cyrl-kir_Cyrl",
        "languages": [
          "bak-Cyrl",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.069984,
        "recall": 0.114672,
        "f1": 0.080545,
        "accuracy": 0.114672,
        "main_score": 0.080545,
        "hf_subset": "bak_Cyrl-tat_Cyrl",
        "languages": [
          "bak-Cyrl",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 4e-05,
        "recall": 0.001502,
        "f1": 7.5e-05,
        "accuracy": 0.001502,
        "main_score": 7.5e-05,
        "hf_subset": "bak_Cyrl-tuk_Latn",
        "languages": [
          "bak-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.000352,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "bak_Cyrl-tur_Latn",
        "languages": [
          "bak-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000282,
        "recall": 0.001502,
        "f1": 0.000394,
        "accuracy": 0.001502,
        "main_score": 0.000394,
        "hf_subset": "bak_Cyrl-uig_Arab",
        "languages": [
          "bak-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.000179,
        "recall": 0.002504,
        "f1": 0.000315,
        "accuracy": 0.002504,
        "main_score": 0.000315,
        "hf_subset": "bak_Cyrl-uzb_Latn",
        "languages": [
          "bak-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "bel_Cyrl-bos_Latn",
        "languages": [
          "bel-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.009,
        "recall": 0.018528,
        "f1": 0.010456,
        "accuracy": 0.018528,
        "main_score": 0.010456,
        "hf_subset": "bel_Cyrl-bul_Cyrl",
        "languages": [
          "bel-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "bel_Cyrl-ces_Latn",
        "languages": [
          "bel-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 2.6e-05,
        "recall": 0.001502,
        "f1": 5e-05,
        "accuracy": 0.001502,
        "main_score": 5e-05,
        "hf_subset": "bel_Cyrl-eng_Latn",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000504,
        "accuracy": 0.001002,
        "main_score": 0.000504,
        "hf_subset": "bel_Cyrl-hrv_Latn",
        "languages": [
          "bel-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.004529,
        "recall": 0.011017,
        "f1": 0.005587,
        "accuracy": 0.011017,
        "main_score": 0.005587,
        "hf_subset": "bel_Cyrl-mkd_Cyrl",
        "languages": [
          "bel-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 5.6e-05,
        "recall": 0.001002,
        "f1": 0.000101,
        "accuracy": 0.001002,
        "main_score": 0.000101,
        "hf_subset": "bel_Cyrl-pol_Latn",
        "languages": [
          "bel-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.033548,
        "recall": 0.051077,
        "f1": 0.036443,
        "accuracy": 0.051077,
        "main_score": 0.036443,
        "hf_subset": "bel_Cyrl-rus_Cyrl",
        "languages": [
          "bel-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.000507,
        "recall": 0.001002,
        "f1": 0.000512,
        "accuracy": 0.001002,
        "main_score": 0.000512,
        "hf_subset": "bel_Cyrl-slk_Latn",
        "languages": [
          "bel-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "bel_Cyrl-slv_Latn",
        "languages": [
          "bel-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.006977,
        "recall": 0.014021,
        "f1": 0.007941,
        "accuracy": 0.014021,
        "main_score": 0.007941,
        "hf_subset": "bel_Cyrl-srp_Cyrl",
        "languages": [
          "bel-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.002003,
        "f1": 1.7e-05,
        "accuracy": 0.002003,
        "main_score": 1.7e-05,
        "hf_subset": "bel_Cyrl-srp_Latn",
        "languages": [
          "bel-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.034494,
        "recall": 0.064597,
        "f1": 0.038992,
        "accuracy": 0.064597,
        "main_score": 0.038992,
        "hf_subset": "bel_Cyrl-ukr_Cyrl",
        "languages": [
          "bel-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.017528,
        "recall": 0.030045,
        "f1": 0.019067,
        "accuracy": 0.030045,
        "main_score": 0.019067,
        "hf_subset": "bem_Latn-eng_Latn",
        "languages": [
          "bem-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005643,
        "recall": 0.010015,
        "f1": 0.006025,
        "accuracy": 0.010015,
        "main_score": 0.006025,
        "hf_subset": "bem_Latn-ewe_Latn",
        "languages": [
          "bem-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.006583,
        "recall": 0.010015,
        "f1": 0.006878,
        "accuracy": 0.010015,
        "main_score": 0.006878,
        "hf_subset": "bem_Latn-fuc_Latn",
        "languages": [
          "bem-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.011063,
        "recall": 0.016525,
        "f1": 0.011916,
        "accuracy": 0.016525,
        "main_score": 0.011916,
        "hf_subset": "bem_Latn-kin_Latn",
        "languages": [
          "bem-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.005091,
        "recall": 0.009514,
        "f1": 0.005658,
        "accuracy": 0.009514,
        "main_score": 0.005658,
        "hf_subset": "bem_Latn-nde_Latn",
        "languages": [
          "bem-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.014601,
        "recall": 0.025038,
        "f1": 0.016293,
        "accuracy": 0.025038,
        "main_score": 0.016293,
        "hf_subset": "bem_Latn-nya_Latn",
        "languages": [
          "bem-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.007433,
        "recall": 0.011517,
        "f1": 0.008131,
        "accuracy": 0.011517,
        "main_score": 0.008131,
        "hf_subset": "bem_Latn-sna_Latn",
        "languages": [
          "bem-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.007641,
        "recall": 0.011517,
        "f1": 0.008016,
        "accuracy": 0.011517,
        "main_score": 0.008016,
        "hf_subset": "bem_Latn-ven_Latn",
        "languages": [
          "bem-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.000541,
        "recall": 0.001502,
        "f1": 0.000576,
        "accuracy": 0.001502,
        "main_score": 0.000576,
        "hf_subset": "ben_Beng-arb_Arab",
        "languages": [
          "ben-Beng",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000505,
        "recall": 0.001502,
        "f1": 0.000509,
        "accuracy": 0.001502,
        "main_score": 0.000509,
        "hf_subset": "ben_Beng-deu_Latn",
        "languages": [
          "ben-Beng",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-div_Thaa",
        "languages": [
          "ben-Beng",
          "div-Thaa"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "ben_Beng-ell_Grek",
        "languages": [
          "ben-Beng",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "ben_Beng-eus_Latn",
        "languages": [
          "ben-Beng",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.000545,
        "recall": 0.001502,
        "f1": 0.000583,
        "accuracy": 0.001502,
        "main_score": 0.000583,
        "hf_subset": "ben_Beng-fas_Arab",
        "languages": [
          "ben-Beng",
          "fas-Arab"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001002,
        "f1": 1e-05,
        "accuracy": 0.001002,
        "main_score": 1e-05,
        "hf_subset": "ben_Beng-fin_Latn",
        "languages": [
          "ben-Beng",
          "fin-Latn"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.001502,
        "f1": 1.7e-05,
        "accuracy": 0.001502,
        "main_score": 1.7e-05,
        "hf_subset": "ben_Beng-fra_Latn",
        "languages": [
          "ben-Beng",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000125,
        "recall": 0.000501,
        "f1": 0.0002,
        "accuracy": 0.000501,
        "main_score": 0.0002,
        "hf_subset": "ben_Beng-heb_Hebr",
        "languages": [
          "ben-Beng",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000167,
        "recall": 0.000501,
        "f1": 0.00025,
        "accuracy": 0.000501,
        "main_score": 0.00025,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.000501,
        "f1": 1.1e-05,
        "accuracy": 0.000501,
        "main_score": 1.1e-05,
        "hf_subset": "ben_Beng-hun_Latn",
        "languages": [
          "ben-Beng",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.000515,
        "recall": 0.001502,
        "f1": 0.000529,
        "accuracy": 0.001502,
        "main_score": 0.000529,
        "hf_subset": "ben_Beng-ind_Latn",
        "languages": [
          "ben-Beng",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.00025,
        "recall": 0.000501,
        "f1": 0.000334,
        "accuracy": 0.000501,
        "main_score": 0.000334,
        "hf_subset": "ben_Beng-jpn_Jpan",
        "languages": [
          "ben-Beng",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 2e-06,
        "accuracy": 0.001002,
        "main_score": 2e-06,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000604,
        "recall": 0.002003,
        "f1": 0.000674,
        "accuracy": 0.002003,
        "main_score": 0.000674,
        "hf_subset": "ben_Beng-kor_Hang",
        "languages": [
          "ben-Beng",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-lit_Latn",
        "languages": [
          "ben-Beng",
          "lit-Latn"
        ]
      },
      {
        "precision": 9.6e-05,
        "recall": 0.002003,
        "f1": 0.000168,
        "accuracy": 0.002003,
        "main_score": 0.000168,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000252,
        "recall": 0.001002,
        "f1": 0.000338,
        "accuracy": 0.001002,
        "main_score": 0.000338,
        "hf_subset": "ben_Beng-nep_Deva",
        "languages": [
          "ben-Beng",
          "nep-Deva"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 4e-06,
        "accuracy": 0.000501,
        "main_score": 4e-06,
        "hf_subset": "ben_Beng-nld_Latn",
        "languages": [
          "ben-Beng",
          "nld-Latn"
        ]
      },
      {
        "precision": 1.8e-05,
        "recall": 0.001002,
        "f1": 3.5e-05,
        "accuracy": 0.001002,
        "main_score": 3.5e-05,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "ben_Beng-pol_Latn",
        "languages": [
          "ben-Beng",
          "pol-Latn"
        ]
      },
      {
        "precision": 2.1e-05,
        "recall": 0.001002,
        "f1": 4.1e-05,
        "accuracy": 0.001002,
        "main_score": 4.1e-05,
        "hf_subset": "ben_Beng-por_Latn",
        "languages": [
          "ben-Beng",
          "por-Latn"
        ]
      },
      {
        "precision": 8e-06,
        "recall": 0.000501,
        "f1": 1.6e-05,
        "accuracy": 0.000501,
        "main_score": 1.6e-05,
        "hf_subset": "ben_Beng-rus_Cyrl",
        "languages": [
          "ben-Beng",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 2e-06,
        "accuracy": 0.001002,
        "main_score": 2e-06,
        "hf_subset": "ben_Beng-sin_Sinh",
        "languages": [
          "ben-Beng",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "ben_Beng-snd_Arab",
        "languages": [
          "ben-Beng",
          "snd-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-spa_Latn",
        "languages": [
          "ben-Beng",
          "spa-Latn"
        ]
      },
      {
        "precision": 8.3e-05,
        "recall": 0.000501,
        "f1": 0.000143,
        "accuracy": 0.000501,
        "main_score": 0.000143,
        "hf_subset": "ben_Beng-swa_Latn",
        "languages": [
          "ben-Beng",
          "swa-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "ben_Beng-swe_Latn",
        "languages": [
          "ben-Beng",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-tur_Latn",
        "languages": [
          "ben-Beng",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-vie_Latn",
        "languages": [
          "ben-Beng",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ben_Beng-zho_Hant",
        "languages": [
          "ben-Beng",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "ben_Beng-zul_Latn",
        "languages": [
          "ben-Beng",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.002626,
        "recall": 0.004507,
        "f1": 0.003076,
        "accuracy": 0.004507,
        "main_score": 0.003076,
        "hf_subset": "bod_Tibt-dzo_Tibt",
        "languages": [
          "bod-Tibt",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.001753,
        "recall": 0.002003,
        "f1": 0.001836,
        "accuracy": 0.002003,
        "main_score": 0.001836,
        "hf_subset": "bod_Tibt-eng_Latn",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001933,
        "recall": 0.004006,
        "f1": 0.002112,
        "accuracy": 0.004006,
        "main_score": 0.002112,
        "hf_subset": "bod_Tibt-khm_Khmr",
        "languages": [
          "bod-Tibt",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.001377,
        "recall": 0.002504,
        "f1": 0.001536,
        "accuracy": 0.002504,
        "main_score": 0.001536,
        "hf_subset": "bod_Tibt-lao_Laoo",
        "languages": [
          "bod-Tibt",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.000755,
        "recall": 0.001502,
        "f1": 0.000843,
        "accuracy": 0.001502,
        "main_score": 0.000843,
        "hf_subset": "bod_Tibt-mon_Mong",
        "languages": [
          "bod-Tibt",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.001003,
        "recall": 0.001502,
        "f1": 0.001004,
        "accuracy": 0.001502,
        "main_score": 0.001004,
        "hf_subset": "bod_Tibt-mya_Mymr",
        "languages": [
          "bod-Tibt",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.000513,
        "recall": 0.001502,
        "f1": 0.000526,
        "accuracy": 0.001502,
        "main_score": 0.000526,
        "hf_subset": "bod_Tibt-tha_Thai",
        "languages": [
          "bod-Tibt",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.001176,
        "recall": 0.004507,
        "f1": 0.001559,
        "accuracy": 0.004507,
        "main_score": 0.001559,
        "hf_subset": "bos_Latn-bel_Cyrl",
        "languages": [
          "bos-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.004795,
        "recall": 0.010516,
        "f1": 0.00595,
        "accuracy": 0.010516,
        "main_score": 0.00595,
        "hf_subset": "bos_Latn-bul_Cyrl",
        "languages": [
          "bos-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.037113,
        "recall": 0.047071,
        "f1": 0.039067,
        "accuracy": 0.047071,
        "main_score": 0.039067,
        "hf_subset": "bos_Latn-ces_Latn",
        "languages": [
          "bos-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.014477,
        "recall": 0.021532,
        "f1": 0.015401,
        "accuracy": 0.021532,
        "main_score": 0.015401,
        "hf_subset": "bos_Latn-eng_Latn",
        "languages": [
          "bos-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.62937,
        "recall": 0.71357,
        "f1": 0.654022,
        "accuracy": 0.71357,
        "main_score": 0.654022,
        "hf_subset": "bos_Latn-hrv_Latn",
        "languages": [
          "bos-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.003428,
        "recall": 0.007011,
        "f1": 0.003918,
        "accuracy": 0.007011,
        "main_score": 0.003918,
        "hf_subset": "bos_Latn-mkd_Cyrl",
        "languages": [
          "bos-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.017261,
        "recall": 0.025038,
        "f1": 0.018453,
        "accuracy": 0.025038,
        "main_score": 0.018453,
        "hf_subset": "bos_Latn-pol_Latn",
        "languages": [
          "bos-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001166,
        "recall": 0.004507,
        "f1": 0.001468,
        "accuracy": 0.004507,
        "main_score": 0.001468,
        "hf_subset": "bos_Latn-rus_Cyrl",
        "languages": [
          "bos-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.040001,
        "recall": 0.056084,
        "f1": 0.042295,
        "accuracy": 0.056084,
        "main_score": 0.042295,
        "hf_subset": "bos_Latn-slk_Latn",
        "languages": [
          "bos-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.110578,
        "recall": 0.150225,
        "f1": 0.118809,
        "accuracy": 0.150225,
        "main_score": 0.118809,
        "hf_subset": "bos_Latn-slv_Latn",
        "languages": [
          "bos-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.012565,
        "recall": 0.032048,
        "f1": 0.015164,
        "accuracy": 0.032048,
        "main_score": 0.015164,
        "hf_subset": "bos_Latn-srp_Cyrl",
        "languages": [
          "bos-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.62815,
        "recall": 0.712068,
        "f1": 0.652156,
        "accuracy": 0.712068,
        "main_score": 0.652156,
        "hf_subset": "bos_Latn-srp_Latn",
        "languages": [
          "bos-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.001667,
        "recall": 0.004507,
        "f1": 0.001947,
        "accuracy": 0.004507,
        "main_score": 0.001947,
        "hf_subset": "bos_Latn-ukr_Cyrl",
        "languages": [
          "bos-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.004058,
        "recall": 0.008513,
        "f1": 0.004349,
        "accuracy": 0.008513,
        "main_score": 0.004349,
        "hf_subset": "bul_Cyrl-bel_Cyrl",
        "languages": [
          "bul-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.001024,
        "recall": 0.002504,
        "f1": 0.001045,
        "accuracy": 0.002504,
        "main_score": 0.001045,
        "hf_subset": "bul_Cyrl-bos_Latn",
        "languages": [
          "bul-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.00051,
        "recall": 0.001002,
        "f1": 0.00052,
        "accuracy": 0.001002,
        "main_score": 0.00052,
        "hf_subset": "bul_Cyrl-ces_Latn",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.000669,
        "recall": 0.002003,
        "f1": 0.000754,
        "accuracy": 0.002003,
        "main_score": 0.000754,
        "hf_subset": "bul_Cyrl-eng_Latn",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000511,
        "recall": 0.002003,
        "f1": 0.000522,
        "accuracy": 0.002003,
        "main_score": 0.000522,
        "hf_subset": "bul_Cyrl-hrv_Latn",
        "languages": [
          "bul-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.068395,
        "recall": 0.110165,
        "f1": 0.07737,
        "accuracy": 0.110165,
        "main_score": 0.07737,
        "hf_subset": "bul_Cyrl-mkd_Cyrl",
        "languages": [
          "bul-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 3.6e-05,
        "recall": 0.001002,
        "f1": 6.8e-05,
        "accuracy": 0.001002,
        "main_score": 6.8e-05,
        "hf_subset": "bul_Cyrl-pol_Latn",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.024986,
        "recall": 0.045068,
        "f1": 0.028511,
        "accuracy": 0.045068,
        "main_score": 0.028511,
        "hf_subset": "bul_Cyrl-rus_Cyrl",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.001021,
        "recall": 0.002504,
        "f1": 0.001038,
        "accuracy": 0.002504,
        "main_score": 0.001038,
        "hf_subset": "bul_Cyrl-slk_Latn",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.00052,
        "recall": 0.001502,
        "f1": 0.000538,
        "accuracy": 0.001502,
        "main_score": 0.000538,
        "hf_subset": "bul_Cyrl-slv_Latn",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.01519,
        "recall": 0.025038,
        "f1": 0.016835,
        "accuracy": 0.025038,
        "main_score": 0.016835,
        "hf_subset": "bul_Cyrl-srp_Cyrl",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.000508,
        "recall": 0.001502,
        "f1": 0.000515,
        "accuracy": 0.001502,
        "main_score": 0.000515,
        "hf_subset": "bul_Cyrl-srp_Latn",
        "languages": [
          "bul-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.003779,
        "recall": 0.008012,
        "f1": 0.004355,
        "accuracy": 0.008012,
        "main_score": 0.004355,
        "hf_subset": "bul_Cyrl-ukr_Cyrl",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.046814,
        "recall": 0.071607,
        "f1": 0.050017,
        "accuracy": 0.071607,
        "main_score": 0.050017,
        "hf_subset": "cat_Latn-eng_Latn",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.084158,
        "recall": 0.123686,
        "f1": 0.092057,
        "accuracy": 0.123686,
        "main_score": 0.092057,
        "hf_subset": "cat_Latn-fra_Latn",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.208008,
        "recall": 0.269404,
        "f1": 0.221885,
        "accuracy": 0.269404,
        "main_score": 0.221885,
        "hf_subset": "cat_Latn-glg_Latn",
        "languages": [
          "cat-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.099871,
        "recall": 0.136204,
        "f1": 0.107785,
        "accuracy": 0.136204,
        "main_score": 0.107785,
        "hf_subset": "cat_Latn-ita_Latn",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.025173,
        "recall": 0.043065,
        "f1": 0.028531,
        "accuracy": 0.043065,
        "main_score": 0.028531,
        "hf_subset": "cat_Latn-mlt_Latn",
        "languages": [
          "cat-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.141666,
        "recall": 0.196294,
        "f1": 0.15422,
        "accuracy": 0.196294,
        "main_score": 0.15422,
        "hf_subset": "cat_Latn-por_Latn",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.053525,
        "recall": 0.082624,
        "f1": 0.059702,
        "accuracy": 0.082624,
        "main_score": 0.059702,
        "hf_subset": "cat_Latn-ron_Latn",
        "languages": [
          "cat-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.245305,
        "recall": 0.316475,
        "f1": 0.262361,
        "accuracy": 0.316475,
        "main_score": 0.262361,
        "hf_subset": "cat_Latn-spa_Latn",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.002542,
        "recall": 0.006009,
        "f1": 0.002922,
        "accuracy": 0.006009,
        "main_score": 0.002922,
        "hf_subset": "ces_Latn-bel_Cyrl",
        "languages": [
          "ces-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.047241,
        "recall": 0.062594,
        "f1": 0.050649,
        "accuracy": 0.062594,
        "main_score": 0.050649,
        "hf_subset": "ces_Latn-bos_Latn",
        "languages": [
          "ces-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.002734,
        "recall": 0.007011,
        "f1": 0.003602,
        "accuracy": 0.007011,
        "main_score": 0.003602,
        "hf_subset": "ces_Latn-bul_Cyrl",
        "languages": [
          "ces-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.019967,
        "recall": 0.031547,
        "f1": 0.021723,
        "accuracy": 0.031547,
        "main_score": 0.021723,
        "hf_subset": "ces_Latn-eng_Latn",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.044026,
        "recall": 0.064597,
        "f1": 0.048325,
        "accuracy": 0.064597,
        "main_score": 0.048325,
        "hf_subset": "ces_Latn-hrv_Latn",
        "languages": [
          "ces-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.00329,
        "recall": 0.010516,
        "f1": 0.004393,
        "accuracy": 0.010516,
        "main_score": 0.004393,
        "hf_subset": "ces_Latn-mkd_Cyrl",
        "languages": [
          "ces-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.03773,
        "recall": 0.054081,
        "f1": 0.040443,
        "accuracy": 0.054081,
        "main_score": 0.040443,
        "hf_subset": "ces_Latn-pol_Latn",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001901,
        "recall": 0.005508,
        "f1": 0.00218,
        "accuracy": 0.005508,
        "main_score": 0.00218,
        "hf_subset": "ces_Latn-rus_Cyrl",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.370131,
        "recall": 0.465198,
        "f1": 0.394269,
        "accuracy": 0.465198,
        "main_score": 0.394269,
        "hf_subset": "ces_Latn-slk_Latn",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.055268,
        "recall": 0.076615,
        "f1": 0.059922,
        "accuracy": 0.076615,
        "main_score": 0.059922,
        "hf_subset": "ces_Latn-slv_Latn",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.003489,
        "recall": 0.011017,
        "f1": 0.004283,
        "accuracy": 0.011017,
        "main_score": 0.004283,
        "hf_subset": "ces_Latn-srp_Cyrl",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.036235,
        "recall": 0.050075,
        "f1": 0.038928,
        "accuracy": 0.050075,
        "main_score": 0.038928,
        "hf_subset": "ces_Latn-srp_Latn",
        "languages": [
          "ces-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.003182,
        "recall": 0.00651,
        "f1": 0.003573,
        "accuracy": 0.00651,
        "main_score": 0.003573,
        "hf_subset": "ces_Latn-ukr_Cyrl",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.000104,
        "recall": 0.001502,
        "f1": 0.000182,
        "accuracy": 0.001502,
        "main_score": 0.000182,
        "hf_subset": "ckb_Arab-arb_Arab",
        "languages": [
          "ckb-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000506,
        "accuracy": 0.001502,
        "main_score": 0.000506,
        "hf_subset": "ckb_Arab-eng_Latn",
        "languages": [
          "ckb-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002317,
        "recall": 0.006009,
        "f1": 0.002749,
        "accuracy": 0.006009,
        "main_score": 0.002749,
        "hf_subset": "ckb_Arab-fas_Arab",
        "languages": [
          "ckb-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.00016,
        "recall": 0.001502,
        "f1": 0.000278,
        "accuracy": 0.001502,
        "main_score": 0.000278,
        "hf_subset": "ckb_Arab-heb_Hebr",
        "languages": [
          "ckb-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.001012,
        "recall": 0.001502,
        "f1": 0.001022,
        "accuracy": 0.001502,
        "main_score": 0.001022,
        "hf_subset": "ckb_Arab-kmr_Latn",
        "languages": [
          "ckb-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.00025,
        "recall": 0.000501,
        "f1": 0.000334,
        "accuracy": 0.000501,
        "main_score": 0.000334,
        "hf_subset": "ckb_Arab-mey_Arab",
        "languages": [
          "ckb-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.003422,
        "recall": 0.008513,
        "f1": 0.004129,
        "accuracy": 0.008513,
        "main_score": 0.004129,
        "hf_subset": "ckb_Arab-prs_Arab",
        "languages": [
          "ckb-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000157,
        "recall": 0.002504,
        "f1": 0.000294,
        "accuracy": 0.002504,
        "main_score": 0.000294,
        "hf_subset": "ckb_Arab-pus_Arab",
        "languages": [
          "ckb-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.000968,
        "recall": 0.003505,
        "f1": 0.001209,
        "accuracy": 0.003505,
        "main_score": 0.001209,
        "hf_subset": "ckb_Arab-shi_Arab",
        "languages": [
          "ckb-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.001018,
        "recall": 0.002504,
        "f1": 0.0012,
        "accuracy": 0.002504,
        "main_score": 0.0012,
        "hf_subset": "ckb_Arab-tgk_Cyrl",
        "languages": [
          "ckb-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.013341,
        "recall": 0.022033,
        "f1": 0.014098,
        "accuracy": 0.022033,
        "main_score": 0.014098,
        "hf_subset": "cym_Latn-eng_Latn",
        "languages": [
          "cym-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007265,
        "recall": 0.01352,
        "f1": 0.008282,
        "accuracy": 0.01352,
        "main_score": 0.008282,
        "hf_subset": "cym_Latn-gle_Latn",
        "languages": [
          "cym-Latn",
          "gle-Latn"
        ]
      },
      {
        "precision": 0.044086,
        "recall": 0.056585,
        "f1": 0.046462,
        "accuracy": 0.056585,
        "main_score": 0.046462,
        "hf_subset": "dan_Latn-afr_Latn",
        "languages": [
          "dan-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.042878,
        "recall": 0.05358,
        "f1": 0.045596,
        "accuracy": 0.05358,
        "main_score": 0.045596,
        "hf_subset": "dan_Latn-deu_Latn",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.035755,
        "recall": 0.055083,
        "f1": 0.038641,
        "accuracy": 0.055083,
        "main_score": 0.038641,
        "hf_subset": "dan_Latn-eng_Latn",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.044476,
        "recall": 0.06009,
        "f1": 0.047631,
        "accuracy": 0.06009,
        "main_score": 0.047631,
        "hf_subset": "dan_Latn-fao_Latn",
        "languages": [
          "dan-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.027135,
        "recall": 0.040561,
        "f1": 0.029544,
        "accuracy": 0.040561,
        "main_score": 0.029544,
        "hf_subset": "dan_Latn-isl_Latn",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.042623,
        "recall": 0.059089,
        "f1": 0.046008,
        "accuracy": 0.059089,
        "main_score": 0.046008,
        "hf_subset": "dan_Latn-ltz_Latn",
        "languages": [
          "dan-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.042376,
        "recall": 0.057086,
        "f1": 0.045696,
        "accuracy": 0.057086,
        "main_score": 0.045696,
        "hf_subset": "dan_Latn-nld_Latn",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.201176,
        "recall": 0.254382,
        "f1": 0.213433,
        "accuracy": 0.254382,
        "main_score": 0.213433,
        "hf_subset": "dan_Latn-nno_Latn",
        "languages": [
          "dan-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.404408,
        "recall": 0.47972,
        "f1": 0.423759,
        "accuracy": 0.47972,
        "main_score": 0.423759,
        "hf_subset": "dan_Latn-nob_Latn",
        "languages": [
          "dan-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.143357,
        "recall": 0.180771,
        "f1": 0.151362,
        "accuracy": 0.180771,
        "main_score": 0.151362,
        "hf_subset": "dan_Latn-swe_Latn",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.043622,
        "recall": 0.06009,
        "f1": 0.046725,
        "accuracy": 0.06009,
        "main_score": 0.046725,
        "hf_subset": "deu_Latn-afr_Latn",
        "languages": [
          "deu-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.000105,
        "recall": 0.001002,
        "f1": 0.000188,
        "accuracy": 0.001002,
        "main_score": 0.000188,
        "hf_subset": "deu_Latn-arb_Arab",
        "languages": [
          "deu-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 2.8e-05,
        "recall": 0.001502,
        "f1": 5.5e-05,
        "accuracy": 0.001502,
        "main_score": 5.5e-05,
        "hf_subset": "deu_Latn-ben_Beng",
        "languages": [
          "deu-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.040626,
        "recall": 0.05308,
        "f1": 0.042848,
        "accuracy": 0.05308,
        "main_score": 0.042848,
        "hf_subset": "deu_Latn-dan_Latn",
        "languages": [
          "deu-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.000679,
        "recall": 0.001502,
        "f1": 0.000773,
        "accuracy": 0.001502,
        "main_score": 0.000773,
        "hf_subset": "deu_Latn-ell_Grek",
        "languages": [
          "deu-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.026258,
        "recall": 0.043565,
        "f1": 0.028443,
        "accuracy": 0.043565,
        "main_score": 0.028443,
        "hf_subset": "deu_Latn-eng_Latn",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022689,
        "recall": 0.029544,
        "f1": 0.023891,
        "accuracy": 0.029544,
        "main_score": 0.023891,
        "hf_subset": "deu_Latn-fao_Latn",
        "languages": [
          "deu-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.001394,
        "recall": 0.005008,
        "f1": 0.001641,
        "accuracy": 0.005008,
        "main_score": 0.001641,
        "hf_subset": "deu_Latn-fas_Arab",
        "languages": [
          "deu-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.012419,
        "recall": 0.017026,
        "f1": 0.013157,
        "accuracy": 0.017026,
        "main_score": 0.013157,
        "hf_subset": "deu_Latn-fin_Latn",
        "languages": [
          "deu-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.024782,
        "recall": 0.041062,
        "f1": 0.027587,
        "accuracy": 0.041062,
        "main_score": 0.027587,
        "hf_subset": "deu_Latn-fra_Latn",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000585,
        "recall": 0.001502,
        "f1": 0.00065,
        "accuracy": 0.001502,
        "main_score": 0.00065,
        "hf_subset": "deu_Latn-heb_Hebr",
        "languages": [
          "deu-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000544,
        "recall": 0.002003,
        "f1": 0.000584,
        "accuracy": 0.002003,
        "main_score": 0.000584,
        "hf_subset": "deu_Latn-hin_Deva",
        "languages": [
          "deu-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.014396,
        "recall": 0.02003,
        "f1": 0.015344,
        "accuracy": 0.02003,
        "main_score": 0.015344,
        "hf_subset": "deu_Latn-hun_Latn",
        "languages": [
          "deu-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.015364,
        "recall": 0.024036,
        "f1": 0.016836,
        "accuracy": 0.024036,
        "main_score": 0.016836,
        "hf_subset": "deu_Latn-ind_Latn",
        "languages": [
          "deu-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.015115,
        "recall": 0.020531,
        "f1": 0.016053,
        "accuracy": 0.020531,
        "main_score": 0.016053,
        "hf_subset": "deu_Latn-isl_Latn",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.000809,
        "recall": 0.002504,
        "f1": 0.001108,
        "accuracy": 0.002504,
        "main_score": 0.001108,
        "hf_subset": "deu_Latn-jpn_Jpan",
        "languages": [
          "deu-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001544,
        "recall": 0.003505,
        "f1": 0.001809,
        "accuracy": 0.003505,
        "main_score": 0.001809,
        "hf_subset": "deu_Latn-kor_Hang",
        "languages": [
          "deu-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.010207,
        "recall": 0.018528,
        "f1": 0.011542,
        "accuracy": 0.018528,
        "main_score": 0.011542,
        "hf_subset": "deu_Latn-lit_Latn",
        "languages": [
          "deu-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.099977,
        "recall": 0.140711,
        "f1": 0.108455,
        "accuracy": 0.140711,
        "main_score": 0.108455,
        "hf_subset": "deu_Latn-ltz_Latn",
        "languages": [
          "deu-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.044095,
        "recall": 0.062594,
        "f1": 0.047889,
        "accuracy": 0.062594,
        "main_score": 0.047889,
        "hf_subset": "deu_Latn-nld_Latn",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.029734,
        "recall": 0.040561,
        "f1": 0.031832,
        "accuracy": 0.040561,
        "main_score": 0.031832,
        "hf_subset": "deu_Latn-nno_Latn",
        "languages": [
          "deu-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.032393,
        "recall": 0.044567,
        "f1": 0.034655,
        "accuracy": 0.044567,
        "main_score": 0.034655,
        "hf_subset": "deu_Latn-nob_Latn",
        "languages": [
          "deu-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.012125,
        "recall": 0.020531,
        "f1": 0.01334,
        "accuracy": 0.020531,
        "main_score": 0.01334,
        "hf_subset": "deu_Latn-pol_Latn",
        "languages": [
          "deu-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.02108,
        "recall": 0.030045,
        "f1": 0.022511,
        "accuracy": 0.030045,
        "main_score": 0.022511,
        "hf_subset": "deu_Latn-por_Latn",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.002003,
        "f1": 0.000757,
        "accuracy": 0.002003,
        "main_score": 0.000757,
        "hf_subset": "deu_Latn-rus_Cyrl",
        "languages": [
          "deu-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.022251,
        "recall": 0.031547,
        "f1": 0.023809,
        "accuracy": 0.031547,
        "main_score": 0.023809,
        "hf_subset": "deu_Latn-spa_Latn",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.007115,
        "recall": 0.012018,
        "f1": 0.008019,
        "accuracy": 0.012018,
        "main_score": 0.008019,
        "hf_subset": "deu_Latn-swa_Latn",
        "languages": [
          "deu-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.029289,
        "recall": 0.040561,
        "f1": 0.031209,
        "accuracy": 0.040561,
        "main_score": 0.031209,
        "hf_subset": "deu_Latn-swe_Latn",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001118,
        "recall": 0.002504,
        "f1": 0.001201,
        "accuracy": 0.002504,
        "main_score": 0.001201,
        "hf_subset": "deu_Latn-tam_Taml",
        "languages": [
          "deu-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.012865,
        "recall": 0.017526,
        "f1": 0.013749,
        "accuracy": 0.017526,
        "main_score": 0.013749,
        "hf_subset": "deu_Latn-tur_Latn",
        "languages": [
          "deu-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.008997,
        "recall": 0.016525,
        "f1": 0.010152,
        "accuracy": 0.016525,
        "main_score": 0.010152,
        "hf_subset": "deu_Latn-vie_Latn",
        "languages": [
          "deu-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.020984,
        "recall": 0.042564,
        "f1": 0.023495,
        "accuracy": 0.042564,
        "main_score": 0.023495,
        "hf_subset": "deu_Latn-zho_Hant",
        "languages": [
          "deu-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.012925,
        "recall": 0.021532,
        "f1": 0.014001,
        "accuracy": 0.021532,
        "main_score": 0.014001,
        "hf_subset": "deu_Latn-zul_Latn",
        "languages": [
          "deu-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 8.7e-05,
        "recall": 0.001502,
        "f1": 0.000151,
        "accuracy": 0.001502,
        "main_score": 0.000151,
        "hf_subset": "div_Thaa-ben_Beng",
        "languages": [
          "div-Thaa",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.00858,
        "recall": 0.019029,
        "f1": 0.010332,
        "accuracy": 0.019029,
        "main_score": 0.010332,
        "hf_subset": "div_Thaa-eng_Latn",
        "languages": [
          "div-Thaa",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001539,
        "recall": 0.004006,
        "f1": 0.001818,
        "accuracy": 0.004006,
        "main_score": 0.001818,
        "hf_subset": "div_Thaa-eus_Latn",
        "languages": [
          "div-Thaa",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.100365,
        "recall": 0.128192,
        "f1": 0.106876,
        "accuracy": 0.128192,
        "main_score": 0.106876,
        "hf_subset": "div_Thaa-guj_Gujr",
        "languages": [
          "div-Thaa",
          "guj-Gujr"
        ]
      },
      {
        "precision": 3.5e-05,
        "recall": 0.001502,
        "f1": 6.7e-05,
        "accuracy": 0.001502,
        "main_score": 6.7e-05,
        "hf_subset": "div_Thaa-hin_Deva",
        "languages": [
          "div-Thaa",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.094488,
        "recall": 0.124186,
        "f1": 0.101654,
        "accuracy": 0.124186,
        "main_score": 0.101654,
        "hf_subset": "div_Thaa-kan_Knda",
        "languages": [
          "div-Thaa",
          "kan-Knda"
        ]
      },
      {
        "precision": 8.5e-05,
        "recall": 0.002003,
        "f1": 0.00016,
        "accuracy": 0.002003,
        "main_score": 0.00016,
        "hf_subset": "div_Thaa-mar_Deva",
        "languages": [
          "div-Thaa",
          "mar-Deva"
        ]
      },
      {
        "precision": 5e-05,
        "recall": 0.000501,
        "f1": 9.1e-05,
        "accuracy": 0.000501,
        "main_score": 9.1e-05,
        "hf_subset": "div_Thaa-nep_Deva",
        "languages": [
          "div-Thaa",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.063749,
        "recall": 0.092639,
        "f1": 0.070558,
        "accuracy": 0.092639,
        "main_score": 0.070558,
        "hf_subset": "div_Thaa-pan_Guru",
        "languages": [
          "div-Thaa",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.045541,
        "recall": 0.075113,
        "f1": 0.052187,
        "accuracy": 0.075113,
        "main_score": 0.052187,
        "hf_subset": "div_Thaa-sin_Sinh",
        "languages": [
          "div-Thaa",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.002024,
        "recall": 0.00651,
        "f1": 0.002324,
        "accuracy": 0.00651,
        "main_score": 0.002324,
        "hf_subset": "div_Thaa-snd_Arab",
        "languages": [
          "div-Thaa",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.000166,
        "recall": 0.003505,
        "f1": 0.000304,
        "accuracy": 0.003505,
        "main_score": 0.000304,
        "hf_subset": "div_Thaa-tam_Taml",
        "languages": [
          "div-Thaa",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.089835,
        "recall": 0.117176,
        "f1": 0.096688,
        "accuracy": 0.117176,
        "main_score": 0.096688,
        "hf_subset": "div_Thaa-tel_Telu",
        "languages": [
          "div-Thaa",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000329,
        "recall": 0.002003,
        "f1": 0.000482,
        "accuracy": 0.002003,
        "main_score": 0.000482,
        "hf_subset": "div_Thaa-urd_Arab",
        "languages": [
          "div-Thaa",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.003589,
        "recall": 0.005008,
        "f1": 0.004006,
        "accuracy": 0.005008,
        "main_score": 0.004006,
        "hf_subset": "dzo_Tibt-bod_Tibt",
        "languages": [
          "dzo-Tibt",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "dzo_Tibt-eng_Latn",
        "languages": [
          "dzo-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "dzo_Tibt-khm_Khmr",
        "languages": [
          "dzo-Tibt",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "dzo_Tibt-lao_Laoo",
        "languages": [
          "dzo-Tibt",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "dzo_Tibt-mon_Mong",
        "languages": [
          "dzo-Tibt",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "dzo_Tibt-mya_Mymr",
        "languages": [
          "dzo-Tibt",
          "mya-Mymr"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 6e-06,
        "accuracy": 0.001002,
        "main_score": 6e-06,
        "hf_subset": "dzo_Tibt-tha_Thai",
        "languages": [
          "dzo-Tibt",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-arb_Arab",
        "languages": [
          "ell-Grek",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-ben_Beng",
        "languages": [
          "ell-Grek",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000336,
        "accuracy": 0.001002,
        "main_score": 0.000336,
        "hf_subset": "ell_Grek-deu_Latn",
        "languages": [
          "ell-Grek",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-eng_Latn",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000334,
        "accuracy": 0.001002,
        "main_score": 0.000334,
        "hf_subset": "ell_Grek-fas_Arab",
        "languages": [
          "ell-Grek",
          "fas-Arab"
        ]
      },
      {
        "precision": 2.8e-05,
        "recall": 0.000501,
        "f1": 5.3e-05,
        "accuracy": 0.000501,
        "main_score": 5.3e-05,
        "hf_subset": "ell_Grek-fin_Latn",
        "languages": [
          "ell-Grek",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "ell_Grek-fra_Latn",
        "languages": [
          "ell-Grek",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-heb_Hebr",
        "languages": [
          "ell-Grek",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-hin_Deva",
        "languages": [
          "ell-Grek",
          "hin-Deva"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.000501,
        "f1": 7e-06,
        "accuracy": 0.000501,
        "main_score": 7e-06,
        "hf_subset": "ell_Grek-hun_Latn",
        "languages": [
          "ell-Grek",
          "hun-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "ell_Grek-hye_Armn",
        "languages": [
          "ell-Grek",
          "hye-Armn"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.000501,
        "f1": 7e-06,
        "accuracy": 0.000501,
        "main_score": 7e-06,
        "hf_subset": "ell_Grek-ind_Latn",
        "languages": [
          "ell-Grek",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-jpn_Jpan",
        "languages": [
          "ell-Grek",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.000501,
        "f1": 8e-06,
        "accuracy": 0.000501,
        "main_score": 8e-06,
        "hf_subset": "ell_Grek-kat_Geor",
        "languages": [
          "ell-Grek",
          "kat-Geor"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 5e-06,
        "accuracy": 0.000501,
        "main_score": 5e-06,
        "hf_subset": "ell_Grek-kor_Hang",
        "languages": [
          "ell-Grek",
          "kor-Hang"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-lit_Latn",
        "languages": [
          "ell-Grek",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-nld_Latn",
        "languages": [
          "ell-Grek",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-pol_Latn",
        "languages": [
          "ell-Grek",
          "pol-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "ell_Grek-por_Latn",
        "languages": [
          "ell-Grek",
          "por-Latn"
        ]
      },
      {
        "precision": 2e-05,
        "recall": 0.001502,
        "f1": 3.9e-05,
        "accuracy": 0.001502,
        "main_score": 3.9e-05,
        "hf_subset": "ell_Grek-rus_Cyrl",
        "languages": [
          "ell-Grek",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-spa_Latn",
        "languages": [
          "ell-Grek",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.000175,
        "recall": 0.001502,
        "f1": 0.000267,
        "accuracy": 0.001502,
        "main_score": 0.000267,
        "hf_subset": "ell_Grek-sqi_Latn",
        "languages": [
          "ell-Grek",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "ell_Grek-swa_Latn",
        "languages": [
          "ell-Grek",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "ell_Grek-swe_Latn",
        "languages": [
          "ell-Grek",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-tam_Taml",
        "languages": [
          "ell-Grek",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-tur_Latn",
        "languages": [
          "ell-Grek",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000334,
        "accuracy": 0.001002,
        "main_score": 0.000334,
        "hf_subset": "ell_Grek-vie_Latn",
        "languages": [
          "ell-Grek",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ell_Grek-zho_Hant",
        "languages": [
          "ell-Grek",
          "zho-Hant"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "ell_Grek-zul_Latn",
        "languages": [
          "ell-Grek",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.046243,
        "recall": 0.084627,
        "f1": 0.053264,
        "accuracy": 0.084627,
        "main_score": 0.053264,
        "hf_subset": "eng_Latn-afr_Latn",
        "languages": [
          "eng-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.034066,
        "recall": 0.083625,
        "f1": 0.043305,
        "accuracy": 0.083625,
        "main_score": 0.043305,
        "hf_subset": "eng_Latn-amh_Ethi",
        "languages": [
          "eng-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.000884,
        "recall": 0.002504,
        "f1": 0.001094,
        "accuracy": 0.002504,
        "main_score": 0.001094,
        "hf_subset": "eng_Latn-arb_Arab",
        "languages": [
          "eng-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.00891,
        "recall": 0.021532,
        "f1": 0.010155,
        "accuracy": 0.021532,
        "main_score": 0.010155,
        "hf_subset": "eng_Latn-aze_Latn",
        "languages": [
          "eng-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.004268,
        "recall": 0.010015,
        "f1": 0.004734,
        "accuracy": 0.010015,
        "main_score": 0.004734,
        "hf_subset": "eng_Latn-bak_Cyrl",
        "languages": [
          "eng-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.00145,
        "recall": 0.005008,
        "f1": 0.001775,
        "accuracy": 0.005008,
        "main_score": 0.001775,
        "hf_subset": "eng_Latn-bel_Cyrl",
        "languages": [
          "eng-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.031808,
        "recall": 0.057086,
        "f1": 0.035858,
        "accuracy": 0.057086,
        "main_score": 0.035858,
        "hf_subset": "eng_Latn-bem_Latn",
        "languages": [
          "eng-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.000501,
        "f1": 1.9e-05,
        "accuracy": 0.000501,
        "main_score": 1.9e-05,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.007686,
        "recall": 0.017526,
        "f1": 0.008806,
        "accuracy": 0.017526,
        "main_score": 0.008806,
        "hf_subset": "eng_Latn-bod_Tibt",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.029707,
        "recall": 0.052579,
        "f1": 0.03319,
        "accuracy": 0.052579,
        "main_score": 0.03319,
        "hf_subset": "eng_Latn-bos_Latn",
        "languages": [
          "eng-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.002313,
        "recall": 0.008513,
        "f1": 0.002777,
        "accuracy": 0.008513,
        "main_score": 0.002777,
        "hf_subset": "eng_Latn-bul_Cyrl",
        "languages": [
          "eng-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.073807,
        "recall": 0.122684,
        "f1": 0.083518,
        "accuracy": 0.122684,
        "main_score": 0.083518,
        "hf_subset": "eng_Latn-cat_Latn",
        "languages": [
          "eng-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.035751,
        "recall": 0.068102,
        "f1": 0.04086,
        "accuracy": 0.068102,
        "main_score": 0.04086,
        "hf_subset": "eng_Latn-ces_Latn",
        "languages": [
          "eng-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.000656,
        "recall": 0.002504,
        "f1": 0.000773,
        "accuracy": 0.002504,
        "main_score": 0.000773,
        "hf_subset": "eng_Latn-ckb_Arab",
        "languages": [
          "eng-Latn",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.031115,
        "recall": 0.058588,
        "f1": 0.035621,
        "accuracy": 0.058588,
        "main_score": 0.035621,
        "hf_subset": "eng_Latn-cym_Latn",
        "languages": [
          "eng-Latn",
          "cym-Latn"
        ]
      },
      {
        "precision": 0.058843,
        "recall": 0.100651,
        "f1": 0.06669,
        "accuracy": 0.100651,
        "main_score": 0.06669,
        "hf_subset": "eng_Latn-dan_Latn",
        "languages": [
          "eng-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.046238,
        "recall": 0.081122,
        "f1": 0.052008,
        "accuracy": 0.081122,
        "main_score": 0.052008,
        "hf_subset": "eng_Latn-deu_Latn",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.007181,
        "recall": 0.018027,
        "f1": 0.009127,
        "accuracy": 0.018027,
        "main_score": 0.009127,
        "hf_subset": "eng_Latn-div_Thaa",
        "languages": [
          "eng-Latn",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.000189,
        "recall": 0.002003,
        "f1": 0.000335,
        "accuracy": 0.002003,
        "main_score": 0.000335,
        "hf_subset": "eng_Latn-dzo_Tibt",
        "languages": [
          "eng-Latn",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.000994,
        "recall": 0.004006,
        "f1": 0.001253,
        "accuracy": 0.004006,
        "main_score": 0.001253,
        "hf_subset": "eng_Latn-ell_Grek",
        "languages": [
          "eng-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.025321,
        "recall": 0.04657,
        "f1": 0.028334,
        "accuracy": 0.04657,
        "main_score": 0.028334,
        "hf_subset": "eng_Latn-eus_Latn",
        "languages": [
          "eng-Latn",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.032545,
        "recall": 0.065598,
        "f1": 0.03823,
        "accuracy": 0.065598,
        "main_score": 0.03823,
        "hf_subset": "eng_Latn-ewe_Latn",
        "languages": [
          "eng-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.030193,
        "recall": 0.057086,
        "f1": 0.03396,
        "accuracy": 0.057086,
        "main_score": 0.03396,
        "hf_subset": "eng_Latn-fao_Latn",
        "languages": [
          "eng-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.002711,
        "recall": 0.007011,
        "f1": 0.003072,
        "accuracy": 0.007011,
        "main_score": 0.003072,
        "hf_subset": "eng_Latn-fas_Arab",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.018201,
        "recall": 0.037056,
        "f1": 0.020799,
        "accuracy": 0.037056,
        "main_score": 0.020799,
        "hf_subset": "eng_Latn-fij_Latn",
        "languages": [
          "eng-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.058244,
        "recall": 0.099149,
        "f1": 0.064855,
        "accuracy": 0.099149,
        "main_score": 0.064855,
        "hf_subset": "eng_Latn-fil_Latn",
        "languages": [
          "eng-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.022665,
        "recall": 0.041562,
        "f1": 0.025615,
        "accuracy": 0.041562,
        "main_score": 0.025615,
        "hf_subset": "eng_Latn-fin_Latn",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.094585,
        "recall": 0.142213,
        "f1": 0.103269,
        "accuracy": 0.142213,
        "main_score": 0.103269,
        "hf_subset": "eng_Latn-fra_Latn",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.039919,
        "recall": 0.075613,
        "f1": 0.045463,
        "accuracy": 0.075613,
        "main_score": 0.045463,
        "hf_subset": "eng_Latn-fuc_Latn",
        "languages": [
          "eng-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.025506,
        "recall": 0.049074,
        "f1": 0.028895,
        "accuracy": 0.049074,
        "main_score": 0.028895,
        "hf_subset": "eng_Latn-gle_Latn",
        "languages": [
          "eng-Latn",
          "gle-Latn"
        ]
      },
      {
        "precision": 0.065077,
        "recall": 0.107661,
        "f1": 0.071996,
        "accuracy": 0.107661,
        "main_score": 0.071996,
        "hf_subset": "eng_Latn-glg_Latn",
        "languages": [
          "eng-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.012223,
        "recall": 0.032048,
        "f1": 0.015431,
        "accuracy": 0.032048,
        "main_score": 0.015431,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.035107,
        "recall": 0.062594,
        "f1": 0.039933,
        "accuracy": 0.062594,
        "main_score": 0.039933,
        "hf_subset": "eng_Latn-hau_Latn",
        "languages": [
          "eng-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.001738,
        "recall": 0.00651,
        "f1": 0.002133,
        "accuracy": 0.00651,
        "main_score": 0.002133,
        "hf_subset": "eng_Latn-heb_Hebr",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.002086,
        "recall": 0.00651,
        "f1": 0.002434,
        "accuracy": 0.00651,
        "main_score": 0.002434,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.018223,
        "recall": 0.044066,
        "f1": 0.021866,
        "accuracy": 0.044066,
        "main_score": 0.021866,
        "hf_subset": "eng_Latn-hmn_Latn",
        "languages": [
          "eng-Latn",
          "hmn-Latn"
        ]
      },
      {
        "precision": 0.026815,
        "recall": 0.054081,
        "f1": 0.031307,
        "accuracy": 0.054081,
        "main_score": 0.031307,
        "hf_subset": "eng_Latn-hrv_Latn",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.024545,
        "recall": 0.04657,
        "f1": 0.028041,
        "accuracy": 0.04657,
        "main_score": 0.028041,
        "hf_subset": "eng_Latn-hun_Latn",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.000198,
        "recall": 0.005008,
        "f1": 0.000362,
        "accuracy": 0.005008,
        "main_score": 0.000362,
        "hf_subset": "eng_Latn-hye_Armn",
        "languages": [
          "eng-Latn",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.045231,
        "recall": 0.079619,
        "f1": 0.050774,
        "accuracy": 0.079619,
        "main_score": 0.050774,
        "hf_subset": "eng_Latn-ibo_Latn",
        "languages": [
          "eng-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.036267,
        "recall": 0.068102,
        "f1": 0.041785,
        "accuracy": 0.068102,
        "main_score": 0.041785,
        "hf_subset": "eng_Latn-ind_Latn",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.01721,
        "recall": 0.041062,
        "f1": 0.020782,
        "accuracy": 0.041062,
        "main_score": 0.020782,
        "hf_subset": "eng_Latn-isl_Latn",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.057966,
        "recall": 0.092639,
        "f1": 0.064093,
        "accuracy": 0.092639,
        "main_score": 0.064093,
        "hf_subset": "eng_Latn-ita_Latn",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.00145,
        "recall": 0.00651,
        "f1": 0.001792,
        "accuracy": 0.00651,
        "main_score": 0.001792,
        "hf_subset": "eng_Latn-jpn_Jpan",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.015835,
        "recall": 0.037056,
        "f1": 0.019294,
        "accuracy": 0.037056,
        "main_score": 0.019294,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.003158,
        "recall": 0.010516,
        "f1": 0.003895,
        "accuracy": 0.010516,
        "main_score": 0.003895,
        "hf_subset": "eng_Latn-kat_Geor",
        "languages": [
          "eng-Latn",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.001974,
        "recall": 0.006009,
        "f1": 0.002508,
        "accuracy": 0.006009,
        "main_score": 0.002508,
        "hf_subset": "eng_Latn-kaz_Cyrl",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.235263,
        "recall": 0.313971,
        "f1": 0.254752,
        "accuracy": 0.313971,
        "main_score": 0.254752,
        "hf_subset": "eng_Latn-khm_Khmr",
        "languages": [
          "eng-Latn",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.022682,
        "recall": 0.04006,
        "f1": 0.025731,
        "accuracy": 0.04006,
        "main_score": 0.025731,
        "hf_subset": "eng_Latn-kin_Latn",
        "languages": [
          "eng-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.000897,
        "recall": 0.005008,
        "f1": 0.001193,
        "accuracy": 0.005008,
        "main_score": 0.001193,
        "hf_subset": "eng_Latn-kir_Cyrl",
        "languages": [
          "eng-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.029377,
        "recall": 0.059089,
        "f1": 0.033998,
        "accuracy": 0.059089,
        "main_score": 0.033998,
        "hf_subset": "eng_Latn-kmr_Latn",
        "languages": [
          "eng-Latn",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.002232,
        "recall": 0.006009,
        "f1": 0.002416,
        "accuracy": 0.006009,
        "main_score": 0.002416,
        "hf_subset": "eng_Latn-kor_Hang",
        "languages": [
          "eng-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.295393,
        "recall": 0.375563,
        "f1": 0.315206,
        "accuracy": 0.375563,
        "main_score": 0.315206,
        "hf_subset": "eng_Latn-lao_Laoo",
        "languages": [
          "eng-Latn",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.023583,
        "recall": 0.047071,
        "f1": 0.027666,
        "accuracy": 0.047071,
        "main_score": 0.027666,
        "hf_subset": "eng_Latn-lav_Latn",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.022935,
        "recall": 0.041562,
        "f1": 0.025934,
        "accuracy": 0.041562,
        "main_score": 0.025934,
        "hf_subset": "eng_Latn-lit_Latn",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.050256,
        "recall": 0.08663,
        "f1": 0.056765,
        "accuracy": 0.08663,
        "main_score": 0.056765,
        "hf_subset": "eng_Latn-ltz_Latn",
        "languages": [
          "eng-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.01069,
        "recall": 0.028543,
        "f1": 0.01357,
        "accuracy": 0.028543,
        "main_score": 0.01357,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.000476,
        "recall": 0.004006,
        "f1": 0.000738,
        "accuracy": 0.004006,
        "main_score": 0.000738,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 4.3e-05,
        "recall": 0.001002,
        "f1": 8e-05,
        "accuracy": 0.001002,
        "main_score": 8e-05,
        "hf_subset": "eng_Latn-mey_Arab",
        "languages": [
          "eng-Latn",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.001957,
        "recall": 0.007011,
        "f1": 0.002278,
        "accuracy": 0.007011,
        "main_score": 0.002278,
        "hf_subset": "eng_Latn-mkd_Cyrl",
        "languages": [
          "eng-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.024474,
        "recall": 0.054582,
        "f1": 0.029425,
        "accuracy": 0.054582,
        "main_score": 0.029425,
        "hf_subset": "eng_Latn-mlg_Latn",
        "languages": [
          "eng-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.038217,
        "recall": 0.0666,
        "f1": 0.043258,
        "accuracy": 0.0666,
        "main_score": 0.043258,
        "hf_subset": "eng_Latn-mlt_Latn",
        "languages": [
          "eng-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.000181,
        "recall": 0.003005,
        "f1": 0.00033,
        "accuracy": 0.003005,
        "main_score": 0.00033,
        "hf_subset": "eng_Latn-mon_Mong",
        "languages": [
          "eng-Latn",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.026853,
        "recall": 0.052078,
        "f1": 0.030689,
        "accuracy": 0.052078,
        "main_score": 0.030689,
        "hf_subset": "eng_Latn-mri_Latn",
        "languages": [
          "eng-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.036835,
        "recall": 0.068603,
        "f1": 0.042516,
        "accuracy": 0.068603,
        "main_score": 0.042516,
        "hf_subset": "eng_Latn-msa_Latn",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.097787,
        "recall": 0.167251,
        "f1": 0.112543,
        "accuracy": 0.167251,
        "main_score": 0.112543,
        "hf_subset": "eng_Latn-mya_Mymr",
        "languages": [
          "eng-Latn",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.009175,
        "recall": 0.023535,
        "f1": 0.010529,
        "accuracy": 0.023535,
        "main_score": 0.010529,
        "hf_subset": "eng_Latn-nde_Latn",
        "languages": [
          "eng-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.0022,
        "recall": 0.008012,
        "f1": 0.002908,
        "accuracy": 0.008012,
        "main_score": 0.002908,
        "hf_subset": "eng_Latn-nep_Deva",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.054369,
        "recall": 0.094141,
        "f1": 0.06127,
        "accuracy": 0.094141,
        "main_score": 0.06127,
        "hf_subset": "eng_Latn-nld_Latn",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.059934,
        "recall": 0.099649,
        "f1": 0.067068,
        "accuracy": 0.099649,
        "main_score": 0.067068,
        "hf_subset": "eng_Latn-nno_Latn",
        "languages": [
          "eng-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.055113,
        "recall": 0.099649,
        "f1": 0.062961,
        "accuracy": 0.099649,
        "main_score": 0.062961,
        "hf_subset": "eng_Latn-nob_Latn",
        "languages": [
          "eng-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.03397,
        "recall": 0.06009,
        "f1": 0.038309,
        "accuracy": 0.06009,
        "main_score": 0.038309,
        "hf_subset": "eng_Latn-nso_Latn",
        "languages": [
          "eng-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.024658,
        "recall": 0.051077,
        "f1": 0.028657,
        "accuracy": 0.051077,
        "main_score": 0.028657,
        "hf_subset": "eng_Latn-nya_Latn",
        "languages": [
          "eng-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.012821,
        "recall": 0.028042,
        "f1": 0.015165,
        "accuracy": 0.028042,
        "main_score": 0.015165,
        "hf_subset": "eng_Latn-orm_Ethi",
        "languages": [
          "eng-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.018969,
        "recall": 0.051077,
        "f1": 0.024634,
        "accuracy": 0.051077,
        "main_score": 0.024634,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.023434,
        "recall": 0.044567,
        "f1": 0.026536,
        "accuracy": 0.044567,
        "main_score": 0.026536,
        "hf_subset": "eng_Latn-pol_Latn",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.05821,
        "recall": 0.101152,
        "f1": 0.065287,
        "accuracy": 0.101152,
        "main_score": 0.065287,
        "hf_subset": "eng_Latn-por_Latn",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001005,
        "recall": 0.001502,
        "f1": 0.001008,
        "accuracy": 0.001502,
        "main_score": 0.001008,
        "hf_subset": "eng_Latn-prs_Arab",
        "languages": [
          "eng-Latn",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000771,
        "recall": 0.004507,
        "f1": 0.000949,
        "accuracy": 0.004507,
        "main_score": 0.000949,
        "hf_subset": "eng_Latn-pus_Arab",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.054298,
        "recall": 0.092639,
        "f1": 0.060955,
        "accuracy": 0.092639,
        "main_score": 0.060955,
        "hf_subset": "eng_Latn-ron_Latn",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.000849,
        "recall": 0.004006,
        "f1": 0.001072,
        "accuracy": 0.004006,
        "main_score": 0.001072,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.000526,
        "recall": 0.002003,
        "f1": 0.000549,
        "accuracy": 0.002003,
        "main_score": 0.000549,
        "hf_subset": "eng_Latn-shi_Arab",
        "languages": [
          "eng-Latn",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.010369,
        "recall": 0.035053,
        "f1": 0.013897,
        "accuracy": 0.035053,
        "main_score": 0.013897,
        "hf_subset": "eng_Latn-sin_Sinh",
        "languages": [
          "eng-Latn",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.028529,
        "recall": 0.054582,
        "f1": 0.03238,
        "accuracy": 0.054582,
        "main_score": 0.03238,
        "hf_subset": "eng_Latn-slk_Latn",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.025333,
        "recall": 0.051577,
        "f1": 0.02999,
        "accuracy": 0.051577,
        "main_score": 0.02999,
        "hf_subset": "eng_Latn-slv_Latn",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.032005,
        "recall": 0.054582,
        "f1": 0.03535,
        "accuracy": 0.054582,
        "main_score": 0.03535,
        "hf_subset": "eng_Latn-smo_Latn",
        "languages": [
          "eng-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.012347,
        "recall": 0.029044,
        "f1": 0.014736,
        "accuracy": 0.029044,
        "main_score": 0.014736,
        "hf_subset": "eng_Latn-sna_Latn",
        "languages": [
          "eng-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.000941,
        "recall": 0.004507,
        "f1": 0.001247,
        "accuracy": 0.004507,
        "main_score": 0.001247,
        "hf_subset": "eng_Latn-snd_Arab",
        "languages": [
          "eng-Latn",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.018602,
        "recall": 0.04006,
        "f1": 0.021849,
        "accuracy": 0.04006,
        "main_score": 0.021849,
        "hf_subset": "eng_Latn-som_Latn",
        "languages": [
          "eng-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.069489,
        "recall": 0.10666,
        "f1": 0.076727,
        "accuracy": 0.10666,
        "main_score": 0.076727,
        "hf_subset": "eng_Latn-spa_Latn",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.029533,
        "recall": 0.058087,
        "f1": 0.034385,
        "accuracy": 0.058087,
        "main_score": 0.034385,
        "hf_subset": "eng_Latn-sqi_Latn",
        "languages": [
          "eng-Latn",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.002348,
        "recall": 0.00651,
        "f1": 0.002743,
        "accuracy": 0.00651,
        "main_score": 0.002743,
        "hf_subset": "eng_Latn-srp_Cyrl",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.00907,
        "recall": 0.023035,
        "f1": 0.010741,
        "accuracy": 0.023035,
        "main_score": 0.010741,
        "hf_subset": "eng_Latn-srp_Latn",
        "languages": [
          "eng-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.021634,
        "recall": 0.047071,
        "f1": 0.025627,
        "accuracy": 0.047071,
        "main_score": 0.025627,
        "hf_subset": "eng_Latn-ssw_Latn",
        "languages": [
          "eng-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.022793,
        "recall": 0.044567,
        "f1": 0.026164,
        "accuracy": 0.044567,
        "main_score": 0.026164,
        "hf_subset": "eng_Latn-swa_Latn",
        "languages": [
          "eng-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.065454,
        "recall": 0.109664,
        "f1": 0.072792,
        "accuracy": 0.109664,
        "main_score": 0.072792,
        "hf_subset": "eng_Latn-swe_Latn",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.022504,
        "recall": 0.041062,
        "f1": 0.025327,
        "accuracy": 0.041062,
        "main_score": 0.025327,
        "hf_subset": "eng_Latn-tah_Latn",
        "languages": [
          "eng-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.001514,
        "recall": 0.007011,
        "f1": 0.001812,
        "accuracy": 0.007011,
        "main_score": 0.001812,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001597,
        "recall": 0.005008,
        "f1": 0.001908,
        "accuracy": 0.005008,
        "main_score": 0.001908,
        "hf_subset": "eng_Latn-tat_Cyrl",
        "languages": [
          "eng-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.017896,
        "recall": 0.045068,
        "f1": 0.022723,
        "accuracy": 0.045068,
        "main_score": 0.022723,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000674,
        "recall": 0.003505,
        "f1": 0.000809,
        "accuracy": 0.003505,
        "main_score": 0.000809,
        "hf_subset": "eng_Latn-tgk_Cyrl",
        "languages": [
          "eng-Latn",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.165635,
        "recall": 0.238858,
        "f1": 0.182621,
        "accuracy": 0.238858,
        "main_score": 0.182621,
        "hf_subset": "eng_Latn-tha_Thai",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.024058,
        "recall": 0.061092,
        "f1": 0.03062,
        "accuracy": 0.061092,
        "main_score": 0.03062,
        "hf_subset": "eng_Latn-tir_Ethi",
        "languages": [
          "eng-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.014316,
        "recall": 0.034552,
        "f1": 0.017261,
        "accuracy": 0.034552,
        "main_score": 0.017261,
        "hf_subset": "eng_Latn-ton_Latn",
        "languages": [
          "eng-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.026792,
        "recall": 0.05358,
        "f1": 0.030556,
        "accuracy": 0.05358,
        "main_score": 0.030556,
        "hf_subset": "eng_Latn-tsn_Latn",
        "languages": [
          "eng-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.018026,
        "recall": 0.036054,
        "f1": 0.020738,
        "accuracy": 0.036054,
        "main_score": 0.020738,
        "hf_subset": "eng_Latn-tuk_Latn",
        "languages": [
          "eng-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.020691,
        "recall": 0.04006,
        "f1": 0.023536,
        "accuracy": 0.04006,
        "main_score": 0.023536,
        "hf_subset": "eng_Latn-tur_Latn",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000296,
        "recall": 0.003505,
        "f1": 0.000423,
        "accuracy": 0.003505,
        "main_score": 0.000423,
        "hf_subset": "eng_Latn-uig_Arab",
        "languages": [
          "eng-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.001035,
        "recall": 0.004507,
        "f1": 0.001295,
        "accuracy": 0.004507,
        "main_score": 0.001295,
        "hf_subset": "eng_Latn-ukr_Cyrl",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.001411,
        "recall": 0.004006,
        "f1": 0.001688,
        "accuracy": 0.004006,
        "main_score": 0.001688,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.00662,
        "recall": 0.015023,
        "f1": 0.007287,
        "accuracy": 0.015023,
        "main_score": 0.007287,
        "hf_subset": "eng_Latn-uzb_Latn",
        "languages": [
          "eng-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.027799,
        "recall": 0.057586,
        "f1": 0.032641,
        "accuracy": 0.057586,
        "main_score": 0.032641,
        "hf_subset": "eng_Latn-ven_Latn",
        "languages": [
          "eng-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.035161,
        "recall": 0.062594,
        "f1": 0.040176,
        "accuracy": 0.062594,
        "main_score": 0.040176,
        "hf_subset": "eng_Latn-vie_Latn",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.030115,
        "recall": 0.05308,
        "f1": 0.033799,
        "accuracy": 0.05308,
        "main_score": 0.033799,
        "hf_subset": "eng_Latn-wol_Latn",
        "languages": [
          "eng-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.015551,
        "recall": 0.037056,
        "f1": 0.018248,
        "accuracy": 0.037056,
        "main_score": 0.018248,
        "hf_subset": "eng_Latn-xho_Latn",
        "languages": [
          "eng-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.022697,
        "recall": 0.049074,
        "f1": 0.026947,
        "accuracy": 0.049074,
        "main_score": 0.026947,
        "hf_subset": "eng_Latn-yor_Latn",
        "languages": [
          "eng-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.010467,
        "recall": 0.024036,
        "f1": 0.012567,
        "accuracy": 0.024036,
        "main_score": 0.012567,
        "hf_subset": "eng_Latn-yue_Hant",
        "languages": [
          "eng-Latn",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.038474,
        "recall": 0.072609,
        "f1": 0.044344,
        "accuracy": 0.072609,
        "main_score": 0.044344,
        "hf_subset": "eng_Latn-zho_Hans",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.100516,
        "recall": 0.157737,
        "f1": 0.111307,
        "accuracy": 0.157737,
        "main_score": 0.111307,
        "hf_subset": "eng_Latn-zho_Hant",
        "languages": [
          "eng-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.029317,
        "recall": 0.058588,
        "f1": 0.033556,
        "accuracy": 0.058588,
        "main_score": 0.033556,
        "hf_subset": "eng_Latn-zul_Latn",
        "languages": [
          "eng-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000511,
        "recall": 0.001002,
        "f1": 0.000521,
        "accuracy": 0.001002,
        "main_score": 0.000521,
        "hf_subset": "eus_Latn-ben_Beng",
        "languages": [
          "eus-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001002,
        "f1": 9e-06,
        "accuracy": 0.001002,
        "main_score": 9e-06,
        "hf_subset": "eus_Latn-div_Thaa",
        "languages": [
          "eus-Latn",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.009892,
        "recall": 0.022534,
        "f1": 0.011248,
        "accuracy": 0.022534,
        "main_score": 0.011248,
        "hf_subset": "eus_Latn-eng_Latn",
        "languages": [
          "eus-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001002,
        "f1": 1.2e-05,
        "accuracy": 0.001002,
        "main_score": 1.2e-05,
        "hf_subset": "eus_Latn-guj_Gujr",
        "languages": [
          "eus-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 7.5e-05,
        "recall": 0.001002,
        "f1": 0.000139,
        "accuracy": 0.001002,
        "main_score": 0.000139,
        "hf_subset": "eus_Latn-hin_Deva",
        "languages": [
          "eus-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001008,
        "recall": 0.002003,
        "f1": 0.001013,
        "accuracy": 0.002003,
        "main_score": 0.001013,
        "hf_subset": "eus_Latn-kan_Knda",
        "languages": [
          "eus-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000668,
        "recall": 0.001002,
        "f1": 0.000751,
        "accuracy": 0.001002,
        "main_score": 0.000751,
        "hf_subset": "eus_Latn-mar_Deva",
        "languages": [
          "eus-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001605,
        "recall": 0.004507,
        "f1": 0.001862,
        "accuracy": 0.004507,
        "main_score": 0.001862,
        "hf_subset": "eus_Latn-nep_Deva",
        "languages": [
          "eus-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.001257,
        "recall": 0.005508,
        "f1": 0.001834,
        "accuracy": 0.005508,
        "main_score": 0.001834,
        "hf_subset": "eus_Latn-pan_Guru",
        "languages": [
          "eus-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001644,
        "recall": 0.003005,
        "f1": 0.001735,
        "accuracy": 0.003005,
        "main_score": 0.001735,
        "hf_subset": "eus_Latn-sin_Sinh",
        "languages": [
          "eus-Latn",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "eus_Latn-snd_Arab",
        "languages": [
          "eus-Latn",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.000764,
        "recall": 0.003005,
        "f1": 0.000931,
        "accuracy": 0.003005,
        "main_score": 0.000931,
        "hf_subset": "eus_Latn-tam_Taml",
        "languages": [
          "eus-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001184,
        "recall": 0.003005,
        "f1": 0.001283,
        "accuracy": 0.003005,
        "main_score": 0.001283,
        "hf_subset": "eus_Latn-tel_Telu",
        "languages": [
          "eus-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000601,
        "recall": 0.001002,
        "f1": 0.000668,
        "accuracy": 0.001002,
        "main_score": 0.000668,
        "hf_subset": "eus_Latn-urd_Arab",
        "languages": [
          "eus-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.010259,
        "recall": 0.01352,
        "f1": 0.010968,
        "accuracy": 0.01352,
        "main_score": 0.010968,
        "hf_subset": "ewe_Latn-bem_Latn",
        "languages": [
          "ewe-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.022871,
        "recall": 0.030546,
        "f1": 0.024352,
        "accuracy": 0.030546,
        "main_score": 0.024352,
        "hf_subset": "ewe_Latn-eng_Latn",
        "languages": [
          "ewe-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012115,
        "recall": 0.014522,
        "f1": 0.012713,
        "accuracy": 0.014522,
        "main_score": 0.012713,
        "hf_subset": "ewe_Latn-fuc_Latn",
        "languages": [
          "ewe-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.005641,
        "recall": 0.011517,
        "f1": 0.006397,
        "accuracy": 0.011517,
        "main_score": 0.006397,
        "hf_subset": "ewe_Latn-kin_Latn",
        "languages": [
          "ewe-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.004382,
        "recall": 0.008513,
        "f1": 0.004824,
        "accuracy": 0.008513,
        "main_score": 0.004824,
        "hf_subset": "ewe_Latn-nde_Latn",
        "languages": [
          "ewe-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.00804,
        "recall": 0.011017,
        "f1": 0.008619,
        "accuracy": 0.011017,
        "main_score": 0.008619,
        "hf_subset": "ewe_Latn-nya_Latn",
        "languages": [
          "ewe-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.003703,
        "recall": 0.005008,
        "f1": 0.003981,
        "accuracy": 0.005008,
        "main_score": 0.003981,
        "hf_subset": "ewe_Latn-sna_Latn",
        "languages": [
          "ewe-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.008263,
        "recall": 0.011017,
        "f1": 0.008932,
        "accuracy": 0.011017,
        "main_score": 0.008932,
        "hf_subset": "ewe_Latn-ven_Latn",
        "languages": [
          "ewe-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.015494,
        "recall": 0.02003,
        "f1": 0.016153,
        "accuracy": 0.02003,
        "main_score": 0.016153,
        "hf_subset": "fao_Latn-afr_Latn",
        "languages": [
          "fao-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.035227,
        "recall": 0.046069,
        "f1": 0.036697,
        "accuracy": 0.046069,
        "main_score": 0.036697,
        "hf_subset": "fao_Latn-dan_Latn",
        "languages": [
          "fao-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.019399,
        "recall": 0.02654,
        "f1": 0.020672,
        "accuracy": 0.02654,
        "main_score": 0.020672,
        "hf_subset": "fao_Latn-deu_Latn",
        "languages": [
          "fao-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.022888,
        "recall": 0.036555,
        "f1": 0.024371,
        "accuracy": 0.036555,
        "main_score": 0.024371,
        "hf_subset": "fao_Latn-eng_Latn",
        "languages": [
          "fao-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.102879,
        "recall": 0.136204,
        "f1": 0.110522,
        "accuracy": 0.136204,
        "main_score": 0.110522,
        "hf_subset": "fao_Latn-isl_Latn",
        "languages": [
          "fao-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.015186,
        "recall": 0.019529,
        "f1": 0.015775,
        "accuracy": 0.019529,
        "main_score": 0.015775,
        "hf_subset": "fao_Latn-ltz_Latn",
        "languages": [
          "fao-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.013243,
        "recall": 0.021032,
        "f1": 0.01412,
        "accuracy": 0.021032,
        "main_score": 0.01412,
        "hf_subset": "fao_Latn-nld_Latn",
        "languages": [
          "fao-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.04908,
        "recall": 0.064096,
        "f1": 0.052114,
        "accuracy": 0.064096,
        "main_score": 0.052114,
        "hf_subset": "fao_Latn-nno_Latn",
        "languages": [
          "fao-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.043743,
        "recall": 0.057586,
        "f1": 0.046285,
        "accuracy": 0.057586,
        "main_score": 0.046285,
        "hf_subset": "fao_Latn-nob_Latn",
        "languages": [
          "fao-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.038285,
        "recall": 0.049574,
        "f1": 0.039972,
        "accuracy": 0.049574,
        "main_score": 0.039972,
        "hf_subset": "fao_Latn-swe_Latn",
        "languages": [
          "fao-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001415,
        "recall": 0.004507,
        "f1": 0.001625,
        "accuracy": 0.004507,
        "main_score": 0.001625,
        "hf_subset": "fas_Arab-arb_Arab",
        "languages": [
          "fas-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001002,
        "f1": 1.2e-05,
        "accuracy": 0.001002,
        "main_score": 1.2e-05,
        "hf_subset": "fas_Arab-ben_Beng",
        "languages": [
          "fas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000114,
        "recall": 0.002003,
        "f1": 0.000207,
        "accuracy": 0.002003,
        "main_score": 0.000207,
        "hf_subset": "fas_Arab-ckb_Arab",
        "languages": [
          "fas-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.000546,
        "recall": 0.002003,
        "f1": 0.000585,
        "accuracy": 0.002003,
        "main_score": 0.000585,
        "hf_subset": "fas_Arab-deu_Latn",
        "languages": [
          "fas-Arab",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "fas_Arab-ell_Grek",
        "languages": [
          "fas-Arab",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.001015,
        "recall": 0.002003,
        "f1": 0.001027,
        "accuracy": 0.002003,
        "main_score": 0.001027,
        "hf_subset": "fas_Arab-eng_Latn",
        "languages": [
          "fas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 3e-06,
        "accuracy": 0.000501,
        "main_score": 3e-06,
        "hf_subset": "fas_Arab-fin_Latn",
        "languages": [
          "fas-Arab",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "fas_Arab-fra_Latn",
        "languages": [
          "fas-Arab",
          "fra-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 3e-06,
        "accuracy": 0.000501,
        "main_score": 3e-06,
        "hf_subset": "fas_Arab-heb_Hebr",
        "languages": [
          "fas-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001502,
        "f1": 0.000507,
        "accuracy": 0.001502,
        "main_score": 0.000507,
        "hf_subset": "fas_Arab-hin_Deva",
        "languages": [
          "fas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.001002,
        "f1": 2e-05,
        "accuracy": 0.001002,
        "main_score": 2e-05,
        "hf_subset": "fas_Arab-hun_Latn",
        "languages": [
          "fas-Arab",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "fas_Arab-ind_Latn",
        "languages": [
          "fas-Arab",
          "ind-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "fas_Arab-jpn_Jpan",
        "languages": [
          "fas-Arab",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "fas_Arab-kmr_Latn",
        "languages": [
          "fas-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "fas_Arab-kor_Hang",
        "languages": [
          "fas-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001002,
        "f1": 1e-05,
        "accuracy": 0.001002,
        "main_score": 1e-05,
        "hf_subset": "fas_Arab-lit_Latn",
        "languages": [
          "fas-Arab",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.001133,
        "recall": 0.003005,
        "f1": 0.001424,
        "accuracy": 0.003005,
        "main_score": 0.001424,
        "hf_subset": "fas_Arab-mey_Arab",
        "languages": [
          "fas-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.000501,
        "f1": 1.8e-05,
        "accuracy": 0.000501,
        "main_score": 1.8e-05,
        "hf_subset": "fas_Arab-nld_Latn",
        "languages": [
          "fas-Arab",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "fas_Arab-pol_Latn",
        "languages": [
          "fas-Arab",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "fas_Arab-por_Latn",
        "languages": [
          "fas-Arab",
          "por-Latn"
        ]
      },
      {
        "precision": 0.150177,
        "recall": 0.205308,
        "f1": 0.164689,
        "accuracy": 0.205308,
        "main_score": 0.164689,
        "hf_subset": "fas_Arab-prs_Arab",
        "languages": [
          "fas-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.001806,
        "recall": 0.005008,
        "f1": 0.00201,
        "accuracy": 0.005008,
        "main_score": 0.00201,
        "hf_subset": "fas_Arab-pus_Arab",
        "languages": [
          "fas-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.001056,
        "recall": 0.002504,
        "f1": 0.001105,
        "accuracy": 0.002504,
        "main_score": 0.001105,
        "hf_subset": "fas_Arab-rus_Cyrl",
        "languages": [
          "fas-Arab",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.000518,
        "recall": 0.002003,
        "f1": 0.000535,
        "accuracy": 0.002003,
        "main_score": 0.000535,
        "hf_subset": "fas_Arab-shi_Arab",
        "languages": [
          "fas-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "fas_Arab-spa_Latn",
        "languages": [
          "fas-Arab",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000503,
        "accuracy": 0.001002,
        "main_score": 0.000503,
        "hf_subset": "fas_Arab-swa_Latn",
        "languages": [
          "fas-Arab",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "fas_Arab-swe_Latn",
        "languages": [
          "fas-Arab",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "fas_Arab-tam_Taml",
        "languages": [
          "fas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001859,
        "recall": 0.005508,
        "f1": 0.002036,
        "accuracy": 0.005508,
        "main_score": 0.002036,
        "hf_subset": "fas_Arab-tgk_Cyrl",
        "languages": [
          "fas-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.001025,
        "recall": 0.002504,
        "f1": 0.001047,
        "accuracy": 0.002504,
        "main_score": 0.001047,
        "hf_subset": "fas_Arab-tur_Latn",
        "languages": [
          "fas-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000651,
        "recall": 0.002003,
        "f1": 0.00076,
        "accuracy": 0.002003,
        "main_score": 0.00076,
        "hf_subset": "fas_Arab-vie_Latn",
        "languages": [
          "fas-Arab",
          "vie-Latn"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.000501,
        "f1": 7e-06,
        "accuracy": 0.000501,
        "main_score": 7e-06,
        "hf_subset": "fas_Arab-zho_Hant",
        "languages": [
          "fas-Arab",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "fas_Arab-zul_Latn",
        "languages": [
          "fas-Arab",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.01186,
        "recall": 0.018027,
        "f1": 0.012512,
        "accuracy": 0.018027,
        "main_score": 0.012512,
        "hf_subset": "fij_Latn-eng_Latn",
        "languages": [
          "fij-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004292,
        "recall": 0.008012,
        "f1": 0.004647,
        "accuracy": 0.008012,
        "main_score": 0.004647,
        "hf_subset": "fij_Latn-fil_Latn",
        "languages": [
          "fij-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.004502,
        "recall": 0.007511,
        "f1": 0.004932,
        "accuracy": 0.007511,
        "main_score": 0.004932,
        "hf_subset": "fij_Latn-ind_Latn",
        "languages": [
          "fij-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000512,
        "recall": 0.002003,
        "f1": 0.000523,
        "accuracy": 0.002003,
        "main_score": 0.000523,
        "hf_subset": "fij_Latn-mal_Mlym",
        "languages": [
          "fij-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.004209,
        "recall": 0.005508,
        "f1": 0.004326,
        "accuracy": 0.005508,
        "main_score": 0.004326,
        "hf_subset": "fij_Latn-mlg_Latn",
        "languages": [
          "fij-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.006566,
        "recall": 0.010015,
        "f1": 0.007063,
        "accuracy": 0.010015,
        "main_score": 0.007063,
        "hf_subset": "fij_Latn-mri_Latn",
        "languages": [
          "fij-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.004307,
        "recall": 0.005508,
        "f1": 0.004434,
        "accuracy": 0.005508,
        "main_score": 0.004434,
        "hf_subset": "fij_Latn-msa_Latn",
        "languages": [
          "fij-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.007626,
        "recall": 0.01302,
        "f1": 0.008361,
        "accuracy": 0.01302,
        "main_score": 0.008361,
        "hf_subset": "fij_Latn-smo_Latn",
        "languages": [
          "fij-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.005347,
        "recall": 0.008012,
        "f1": 0.005726,
        "accuracy": 0.008012,
        "main_score": 0.005726,
        "hf_subset": "fij_Latn-tah_Latn",
        "languages": [
          "fij-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.00461,
        "recall": 0.008012,
        "f1": 0.005112,
        "accuracy": 0.008012,
        "main_score": 0.005112,
        "hf_subset": "fij_Latn-ton_Latn",
        "languages": [
          "fij-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.036689,
        "recall": 0.049574,
        "f1": 0.037961,
        "accuracy": 0.049574,
        "main_score": 0.037961,
        "hf_subset": "fil_Latn-eng_Latn",
        "languages": [
          "fil-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00765,
        "recall": 0.012018,
        "f1": 0.008557,
        "accuracy": 0.012018,
        "main_score": 0.008557,
        "hf_subset": "fil_Latn-fij_Latn",
        "languages": [
          "fil-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.014957,
        "recall": 0.021532,
        "f1": 0.015893,
        "accuracy": 0.021532,
        "main_score": 0.015893,
        "hf_subset": "fil_Latn-ind_Latn",
        "languages": [
          "fil-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.001502,
        "f1": 2.9e-05,
        "accuracy": 0.001502,
        "main_score": 2.9e-05,
        "hf_subset": "fil_Latn-mal_Mlym",
        "languages": [
          "fil-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.012957,
        "recall": 0.017526,
        "f1": 0.013415,
        "accuracy": 0.017526,
        "main_score": 0.013415,
        "hf_subset": "fil_Latn-mlg_Latn",
        "languages": [
          "fil-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.009966,
        "recall": 0.016024,
        "f1": 0.010807,
        "accuracy": 0.016024,
        "main_score": 0.010807,
        "hf_subset": "fil_Latn-mri_Latn",
        "languages": [
          "fil-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.015842,
        "recall": 0.020531,
        "f1": 0.016428,
        "accuracy": 0.020531,
        "main_score": 0.016428,
        "hf_subset": "fil_Latn-msa_Latn",
        "languages": [
          "fil-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.010207,
        "recall": 0.019029,
        "f1": 0.011711,
        "accuracy": 0.019029,
        "main_score": 0.011711,
        "hf_subset": "fil_Latn-smo_Latn",
        "languages": [
          "fil-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.006558,
        "recall": 0.015023,
        "f1": 0.007817,
        "accuracy": 0.015023,
        "main_score": 0.007817,
        "hf_subset": "fil_Latn-tah_Latn",
        "languages": [
          "fil-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.004018,
        "recall": 0.009014,
        "f1": 0.004702,
        "accuracy": 0.009014,
        "main_score": 0.004702,
        "hf_subset": "fil_Latn-ton_Latn",
        "languages": [
          "fil-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.000336,
        "recall": 0.001502,
        "f1": 0.000482,
        "accuracy": 0.001502,
        "main_score": 0.000482,
        "hf_subset": "fin_Latn-arb_Arab",
        "languages": [
          "fin-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "fin_Latn-ben_Beng",
        "languages": [
          "fin-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.007043,
        "recall": 0.011017,
        "f1": 0.007572,
        "accuracy": 0.011017,
        "main_score": 0.007572,
        "hf_subset": "fin_Latn-deu_Latn",
        "languages": [
          "fin-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000255,
        "recall": 0.001502,
        "f1": 0.000343,
        "accuracy": 0.001502,
        "main_score": 0.000343,
        "hf_subset": "fin_Latn-ell_Grek",
        "languages": [
          "fin-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.010685,
        "recall": 0.019029,
        "f1": 0.011527,
        "accuracy": 0.019029,
        "main_score": 0.011527,
        "hf_subset": "fin_Latn-eng_Latn",
        "languages": [
          "fin-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000242,
        "recall": 0.002003,
        "f1": 0.000401,
        "accuracy": 0.002003,
        "main_score": 0.000401,
        "hf_subset": "fin_Latn-fas_Arab",
        "languages": [
          "fin-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.010125,
        "recall": 0.014522,
        "f1": 0.010802,
        "accuracy": 0.014522,
        "main_score": 0.010802,
        "hf_subset": "fin_Latn-fra_Latn",
        "languages": [
          "fin-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.0001,
        "recall": 0.000501,
        "f1": 0.000167,
        "accuracy": 0.000501,
        "main_score": 0.000167,
        "hf_subset": "fin_Latn-heb_Hebr",
        "languages": [
          "fin-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000535,
        "recall": 0.002504,
        "f1": 0.000811,
        "accuracy": 0.002504,
        "main_score": 0.000811,
        "hf_subset": "fin_Latn-hin_Deva",
        "languages": [
          "fin-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.009358,
        "recall": 0.01352,
        "f1": 0.010125,
        "accuracy": 0.01352,
        "main_score": 0.010125,
        "hf_subset": "fin_Latn-hun_Latn",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.005776,
        "recall": 0.008513,
        "f1": 0.00621,
        "accuracy": 0.008513,
        "main_score": 0.00621,
        "hf_subset": "fin_Latn-ind_Latn",
        "languages": [
          "fin-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000923,
        "recall": 0.003005,
        "f1": 0.001155,
        "accuracy": 0.003005,
        "main_score": 0.001155,
        "hf_subset": "fin_Latn-jpn_Jpan",
        "languages": [
          "fin-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.0005,
        "recall": 0.004006,
        "f1": 0.000769,
        "accuracy": 0.004006,
        "main_score": 0.000769,
        "hf_subset": "fin_Latn-kor_Hang",
        "languages": [
          "fin-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.004934,
        "recall": 0.007011,
        "f1": 0.005198,
        "accuracy": 0.007011,
        "main_score": 0.005198,
        "hf_subset": "fin_Latn-lav_Latn",
        "languages": [
          "fin-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.006133,
        "recall": 0.010516,
        "f1": 0.006683,
        "accuracy": 0.010516,
        "main_score": 0.006683,
        "hf_subset": "fin_Latn-lit_Latn",
        "languages": [
          "fin-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.012323,
        "recall": 0.018027,
        "f1": 0.013308,
        "accuracy": 0.018027,
        "main_score": 0.013308,
        "hf_subset": "fin_Latn-nld_Latn",
        "languages": [
          "fin-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.007121,
        "recall": 0.008513,
        "f1": 0.007374,
        "accuracy": 0.008513,
        "main_score": 0.007374,
        "hf_subset": "fin_Latn-pol_Latn",
        "languages": [
          "fin-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.007174,
        "recall": 0.011017,
        "f1": 0.008046,
        "accuracy": 0.011017,
        "main_score": 0.008046,
        "hf_subset": "fin_Latn-por_Latn",
        "languages": [
          "fin-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000535,
        "recall": 0.001502,
        "f1": 0.000567,
        "accuracy": 0.001502,
        "main_score": 0.000567,
        "hf_subset": "fin_Latn-rus_Cyrl",
        "languages": [
          "fin-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.011444,
        "recall": 0.015023,
        "f1": 0.011849,
        "accuracy": 0.015023,
        "main_score": 0.011849,
        "hf_subset": "fin_Latn-spa_Latn",
        "languages": [
          "fin-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.005336,
        "recall": 0.008513,
        "f1": 0.005905,
        "accuracy": 0.008513,
        "main_score": 0.005905,
        "hf_subset": "fin_Latn-swa_Latn",
        "languages": [
          "fin-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.01114,
        "recall": 0.018027,
        "f1": 0.012099,
        "accuracy": 0.018027,
        "main_score": 0.012099,
        "hf_subset": "fin_Latn-swe_Latn",
        "languages": [
          "fin-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000101,
        "recall": 0.002003,
        "f1": 0.000178,
        "accuracy": 0.002003,
        "main_score": 0.000178,
        "hf_subset": "fin_Latn-tam_Taml",
        "languages": [
          "fin-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.007626,
        "recall": 0.011017,
        "f1": 0.007984,
        "accuracy": 0.011017,
        "main_score": 0.007984,
        "hf_subset": "fin_Latn-tur_Latn",
        "languages": [
          "fin-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.005152,
        "recall": 0.011017,
        "f1": 0.0056,
        "accuracy": 0.011017,
        "main_score": 0.0056,
        "hf_subset": "fin_Latn-vie_Latn",
        "languages": [
          "fin-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.010984,
        "recall": 0.021532,
        "f1": 0.011974,
        "accuracy": 0.021532,
        "main_score": 0.011974,
        "hf_subset": "fin_Latn-zho_Hant",
        "languages": [
          "fin-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.006796,
        "recall": 0.010015,
        "f1": 0.007328,
        "accuracy": 0.010015,
        "main_score": 0.007328,
        "hf_subset": "fin_Latn-zul_Latn",
        "languages": [
          "fin-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000167,
        "recall": 0.001002,
        "f1": 0.000286,
        "accuracy": 0.001002,
        "main_score": 0.000286,
        "hf_subset": "fra_Latn-arb_Arab",
        "languages": [
          "fra-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000163,
        "recall": 0.001502,
        "f1": 0.000284,
        "accuracy": 0.001502,
        "main_score": 0.000284,
        "hf_subset": "fra_Latn-ben_Beng",
        "languages": [
          "fra-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.055897,
        "recall": 0.074111,
        "f1": 0.058891,
        "accuracy": 0.074111,
        "main_score": 0.058891,
        "hf_subset": "fra_Latn-cat_Latn",
        "languages": [
          "fra-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.027778,
        "recall": 0.035553,
        "f1": 0.029181,
        "accuracy": 0.035553,
        "main_score": 0.029181,
        "hf_subset": "fra_Latn-deu_Latn",
        "languages": [
          "fra-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.00011,
        "recall": 0.001502,
        "f1": 0.000186,
        "accuracy": 0.001502,
        "main_score": 0.000186,
        "hf_subset": "fra_Latn-ell_Grek",
        "languages": [
          "fra-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.050881,
        "recall": 0.062594,
        "f1": 0.052895,
        "accuracy": 0.062594,
        "main_score": 0.052895,
        "hf_subset": "fra_Latn-eng_Latn",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002859,
        "recall": 0.006009,
        "f1": 0.003242,
        "accuracy": 0.006009,
        "main_score": 0.003242,
        "hf_subset": "fra_Latn-fas_Arab",
        "languages": [
          "fra-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.015733,
        "recall": 0.02003,
        "f1": 0.016279,
        "accuracy": 0.02003,
        "main_score": 0.016279,
        "hf_subset": "fra_Latn-fin_Latn",
        "languages": [
          "fra-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.049023,
        "recall": 0.071107,
        "f1": 0.053192,
        "accuracy": 0.071107,
        "main_score": 0.053192,
        "hf_subset": "fra_Latn-glg_Latn",
        "languages": [
          "fra-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.001007,
        "recall": 0.003005,
        "f1": 0.001262,
        "accuracy": 0.003005,
        "main_score": 0.001262,
        "hf_subset": "fra_Latn-heb_Hebr",
        "languages": [
          "fra-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "fra_Latn-hin_Deva",
        "languages": [
          "fra-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016366,
        "recall": 0.021032,
        "f1": 0.017238,
        "accuracy": 0.021032,
        "main_score": 0.017238,
        "hf_subset": "fra_Latn-hun_Latn",
        "languages": [
          "fra-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.01428,
        "recall": 0.021532,
        "f1": 0.015301,
        "accuracy": 0.021532,
        "main_score": 0.015301,
        "hf_subset": "fra_Latn-ind_Latn",
        "languages": [
          "fra-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.041606,
        "recall": 0.055583,
        "f1": 0.044024,
        "accuracy": 0.055583,
        "main_score": 0.044024,
        "hf_subset": "fra_Latn-ita_Latn",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.00114,
        "recall": 0.002504,
        "f1": 0.001228,
        "accuracy": 0.002504,
        "main_score": 0.001228,
        "hf_subset": "fra_Latn-jpn_Jpan",
        "languages": [
          "fra-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001857,
        "recall": 0.004507,
        "f1": 0.002237,
        "accuracy": 0.004507,
        "main_score": 0.002237,
        "hf_subset": "fra_Latn-kor_Hang",
        "languages": [
          "fra-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.007727,
        "recall": 0.014522,
        "f1": 0.008995,
        "accuracy": 0.014522,
        "main_score": 0.008995,
        "hf_subset": "fra_Latn-lit_Latn",
        "languages": [
          "fra-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.016078,
        "recall": 0.023035,
        "f1": 0.017101,
        "accuracy": 0.023035,
        "main_score": 0.017101,
        "hf_subset": "fra_Latn-mlt_Latn",
        "languages": [
          "fra-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.025212,
        "recall": 0.039559,
        "f1": 0.027281,
        "accuracy": 0.039559,
        "main_score": 0.027281,
        "hf_subset": "fra_Latn-nld_Latn",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.015354,
        "recall": 0.021032,
        "f1": 0.016198,
        "accuracy": 0.021032,
        "main_score": 0.016198,
        "hf_subset": "fra_Latn-pol_Latn",
        "languages": [
          "fra-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.040254,
        "recall": 0.056084,
        "f1": 0.043306,
        "accuracy": 0.056084,
        "main_score": 0.043306,
        "hf_subset": "fra_Latn-por_Latn",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.035155,
        "recall": 0.047571,
        "f1": 0.037358,
        "accuracy": 0.047571,
        "main_score": 0.037358,
        "hf_subset": "fra_Latn-ron_Latn",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.000358,
        "recall": 0.002003,
        "f1": 0.000516,
        "accuracy": 0.002003,
        "main_score": 0.000516,
        "hf_subset": "fra_Latn-rus_Cyrl",
        "languages": [
          "fra-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.052149,
        "recall": 0.069604,
        "f1": 0.055121,
        "accuracy": 0.069604,
        "main_score": 0.055121,
        "hf_subset": "fra_Latn-spa_Latn",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.010001,
        "recall": 0.012519,
        "f1": 0.010245,
        "accuracy": 0.012519,
        "main_score": 0.010245,
        "hf_subset": "fra_Latn-swa_Latn",
        "languages": [
          "fra-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.018977,
        "recall": 0.028042,
        "f1": 0.0205,
        "accuracy": 0.028042,
        "main_score": 0.0205,
        "hf_subset": "fra_Latn-swe_Latn",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000354,
        "recall": 0.002003,
        "f1": 0.000519,
        "accuracy": 0.002003,
        "main_score": 0.000519,
        "hf_subset": "fra_Latn-tam_Taml",
        "languages": [
          "fra-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.013171,
        "recall": 0.015523,
        "f1": 0.013642,
        "accuracy": 0.015523,
        "main_score": 0.013642,
        "hf_subset": "fra_Latn-tur_Latn",
        "languages": [
          "fra-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.015591,
        "recall": 0.023535,
        "f1": 0.017072,
        "accuracy": 0.023535,
        "main_score": 0.017072,
        "hf_subset": "fra_Latn-vie_Latn",
        "languages": [
          "fra-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.026315,
        "recall": 0.039559,
        "f1": 0.028358,
        "accuracy": 0.039559,
        "main_score": 0.028358,
        "hf_subset": "fra_Latn-zho_Hant",
        "languages": [
          "fra-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.012083,
        "recall": 0.02003,
        "f1": 0.013122,
        "accuracy": 0.02003,
        "main_score": 0.013122,
        "hf_subset": "fra_Latn-zul_Latn",
        "languages": [
          "fra-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.011117,
        "recall": 0.017026,
        "f1": 0.012214,
        "accuracy": 0.017026,
        "main_score": 0.012214,
        "hf_subset": "fuc_Latn-bem_Latn",
        "languages": [
          "fuc-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.028144,
        "recall": 0.041562,
        "f1": 0.02984,
        "accuracy": 0.041562,
        "main_score": 0.02984,
        "hf_subset": "fuc_Latn-eng_Latn",
        "languages": [
          "fuc-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014087,
        "recall": 0.02003,
        "f1": 0.015169,
        "accuracy": 0.02003,
        "main_score": 0.015169,
        "hf_subset": "fuc_Latn-ewe_Latn",
        "languages": [
          "fuc-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.011683,
        "recall": 0.019029,
        "f1": 0.012841,
        "accuracy": 0.019029,
        "main_score": 0.012841,
        "hf_subset": "fuc_Latn-kin_Latn",
        "languages": [
          "fuc-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.006691,
        "recall": 0.010516,
        "f1": 0.00726,
        "accuracy": 0.010516,
        "main_score": 0.00726,
        "hf_subset": "fuc_Latn-nde_Latn",
        "languages": [
          "fuc-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.014868,
        "recall": 0.021532,
        "f1": 0.016086,
        "accuracy": 0.021532,
        "main_score": 0.016086,
        "hf_subset": "fuc_Latn-nya_Latn",
        "languages": [
          "fuc-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.006107,
        "recall": 0.008513,
        "f1": 0.006564,
        "accuracy": 0.008513,
        "main_score": 0.006564,
        "hf_subset": "fuc_Latn-sna_Latn",
        "languages": [
          "fuc-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.012771,
        "recall": 0.019029,
        "f1": 0.01401,
        "accuracy": 0.019029,
        "main_score": 0.01401,
        "hf_subset": "fuc_Latn-ven_Latn",
        "languages": [
          "fuc-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.007526,
        "recall": 0.011517,
        "f1": 0.007994,
        "accuracy": 0.011517,
        "main_score": 0.007994,
        "hf_subset": "gle_Latn-cym_Latn",
        "languages": [
          "gle-Latn",
          "cym-Latn"
        ]
      },
      {
        "precision": 0.012643,
        "recall": 0.022033,
        "f1": 0.013482,
        "accuracy": 0.022033,
        "main_score": 0.013482,
        "hf_subset": "gle_Latn-eng_Latn",
        "languages": [
          "gle-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.158231,
        "recall": 0.210816,
        "f1": 0.168158,
        "accuracy": 0.210816,
        "main_score": 0.168158,
        "hf_subset": "glg_Latn-cat_Latn",
        "languages": [
          "glg-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.037978,
        "recall": 0.057086,
        "f1": 0.040411,
        "accuracy": 0.057086,
        "main_score": 0.040411,
        "hf_subset": "glg_Latn-eng_Latn",
        "languages": [
          "glg-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.053206,
        "recall": 0.079119,
        "f1": 0.057822,
        "accuracy": 0.079119,
        "main_score": 0.057822,
        "hf_subset": "glg_Latn-fra_Latn",
        "languages": [
          "glg-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.065666,
        "recall": 0.09314,
        "f1": 0.070939,
        "accuracy": 0.09314,
        "main_score": 0.070939,
        "hf_subset": "glg_Latn-ita_Latn",
        "languages": [
          "glg-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.017916,
        "recall": 0.02654,
        "f1": 0.019783,
        "accuracy": 0.02654,
        "main_score": 0.019783,
        "hf_subset": "glg_Latn-mlt_Latn",
        "languages": [
          "glg-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.347792,
        "recall": 0.434652,
        "f1": 0.369747,
        "accuracy": 0.434652,
        "main_score": 0.369747,
        "hf_subset": "glg_Latn-por_Latn",
        "languages": [
          "glg-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.034561,
        "recall": 0.054582,
        "f1": 0.038384,
        "accuracy": 0.054582,
        "main_score": 0.038384,
        "hf_subset": "glg_Latn-ron_Latn",
        "languages": [
          "glg-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.373005,
        "recall": 0.455183,
        "f1": 0.393438,
        "accuracy": 0.455183,
        "main_score": 0.393438,
        "hf_subset": "glg_Latn-spa_Latn",
        "languages": [
          "glg-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.090115,
        "recall": 0.121182,
        "f1": 0.097684,
        "accuracy": 0.121182,
        "main_score": 0.097684,
        "hf_subset": "guj_Gujr-div_Thaa",
        "languages": [
          "guj-Gujr",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.013116,
        "recall": 0.024537,
        "f1": 0.015289,
        "accuracy": 0.024537,
        "main_score": 0.015289,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000853,
        "recall": 0.004006,
        "f1": 0.001111,
        "accuracy": 0.004006,
        "main_score": 0.001111,
        "hf_subset": "guj_Gujr-eus_Latn",
        "languages": [
          "guj-Gujr",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.000282,
        "recall": 0.002504,
        "f1": 0.000395,
        "accuracy": 0.002504,
        "main_score": 0.000395,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.100805,
        "recall": 0.131197,
        "f1": 0.10887,
        "accuracy": 0.131197,
        "main_score": 0.10887,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.00014,
        "recall": 0.002003,
        "f1": 0.00023,
        "accuracy": 0.002003,
        "main_score": 0.00023,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000118,
        "recall": 0.001502,
        "f1": 0.000201,
        "accuracy": 0.001502,
        "main_score": 0.000201,
        "hf_subset": "guj_Gujr-nep_Deva",
        "languages": [
          "guj-Gujr",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.08206,
        "recall": 0.116174,
        "f1": 0.089237,
        "accuracy": 0.116174,
        "main_score": 0.089237,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.054161,
        "recall": 0.090135,
        "f1": 0.061503,
        "accuracy": 0.090135,
        "main_score": 0.061503,
        "hf_subset": "guj_Gujr-sin_Sinh",
        "languages": [
          "guj-Gujr",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.001835,
        "recall": 0.00651,
        "f1": 0.002259,
        "accuracy": 0.00651,
        "main_score": 0.002259,
        "hf_subset": "guj_Gujr-snd_Arab",
        "languages": [
          "guj-Gujr",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.001219,
        "recall": 0.005008,
        "f1": 0.001387,
        "accuracy": 0.005008,
        "main_score": 0.001387,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.119017,
        "recall": 0.148723,
        "f1": 0.126385,
        "accuracy": 0.148723,
        "main_score": 0.126385,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000761,
        "recall": 0.001502,
        "f1": 0.000853,
        "accuracy": 0.001502,
        "main_score": 0.000853,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.003598,
        "recall": 0.008513,
        "f1": 0.004141,
        "accuracy": 0.008513,
        "main_score": 0.004141,
        "hf_subset": "hau_Latn-amh_Ethi",
        "languages": [
          "hau-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.017325,
        "recall": 0.028543,
        "f1": 0.018871,
        "accuracy": 0.028543,
        "main_score": 0.018871,
        "hf_subset": "hau_Latn-eng_Latn",
        "languages": [
          "hau-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014073,
        "recall": 0.020531,
        "f1": 0.014791,
        "accuracy": 0.020531,
        "main_score": 0.014791,
        "hf_subset": "hau_Latn-ibo_Latn",
        "languages": [
          "hau-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.00671,
        "recall": 0.011517,
        "f1": 0.007522,
        "accuracy": 0.011517,
        "main_score": 0.007522,
        "hf_subset": "hau_Latn-nso_Latn",
        "languages": [
          "hau-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.008284,
        "recall": 0.012018,
        "f1": 0.008869,
        "accuracy": 0.012018,
        "main_score": 0.008869,
        "hf_subset": "hau_Latn-orm_Ethi",
        "languages": [
          "hau-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.010268,
        "recall": 0.014021,
        "f1": 0.010869,
        "accuracy": 0.014021,
        "main_score": 0.010869,
        "hf_subset": "hau_Latn-som_Latn",
        "languages": [
          "hau-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.008348,
        "recall": 0.011517,
        "f1": 0.008759,
        "accuracy": 0.011517,
        "main_score": 0.008759,
        "hf_subset": "hau_Latn-ssw_Latn",
        "languages": [
          "hau-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.014532,
        "recall": 0.023035,
        "f1": 0.016256,
        "accuracy": 0.023035,
        "main_score": 0.016256,
        "hf_subset": "hau_Latn-swa_Latn",
        "languages": [
          "hau-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.003581,
        "recall": 0.008012,
        "f1": 0.003886,
        "accuracy": 0.008012,
        "main_score": 0.003886,
        "hf_subset": "hau_Latn-tir_Ethi",
        "languages": [
          "hau-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.007677,
        "recall": 0.012519,
        "f1": 0.008322,
        "accuracy": 0.012519,
        "main_score": 0.008322,
        "hf_subset": "hau_Latn-tsn_Latn",
        "languages": [
          "hau-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.009724,
        "recall": 0.015023,
        "f1": 0.010472,
        "accuracy": 0.015023,
        "main_score": 0.010472,
        "hf_subset": "hau_Latn-wol_Latn",
        "languages": [
          "hau-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.007143,
        "recall": 0.010015,
        "f1": 0.007516,
        "accuracy": 0.010015,
        "main_score": 0.007516,
        "hf_subset": "hau_Latn-xho_Latn",
        "languages": [
          "hau-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.009673,
        "recall": 0.01302,
        "f1": 0.010129,
        "accuracy": 0.01302,
        "main_score": 0.010129,
        "hf_subset": "hau_Latn-yor_Latn",
        "languages": [
          "hau-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.006641,
        "recall": 0.014522,
        "f1": 0.007696,
        "accuracy": 0.014522,
        "main_score": 0.007696,
        "hf_subset": "hau_Latn-zul_Latn",
        "languages": [
          "hau-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.001104,
        "recall": 0.002003,
        "f1": 0.001172,
        "accuracy": 0.002003,
        "main_score": 0.001172,
        "hf_subset": "heb_Hebr-arb_Arab",
        "languages": [
          "heb-Hebr",
          "arb-Arab"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001502,
        "f1": 9e-06,
        "accuracy": 0.001502,
        "main_score": 9e-06,
        "hf_subset": "heb_Hebr-ben_Beng",
        "languages": [
          "heb-Hebr",
          "ben-Beng"
        ]
      },
      {
        "precision": 4.8e-05,
        "recall": 0.001002,
        "f1": 8.8e-05,
        "accuracy": 0.001002,
        "main_score": 8.8e-05,
        "hf_subset": "heb_Hebr-ckb_Arab",
        "languages": [
          "heb-Hebr",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.000376,
        "recall": 0.001502,
        "f1": 0.000535,
        "accuracy": 0.001502,
        "main_score": 0.000535,
        "hf_subset": "heb_Hebr-deu_Latn",
        "languages": [
          "heb-Hebr",
          "deu-Latn"
        ]
      },
      {
        "precision": 3.3e-05,
        "recall": 0.001002,
        "f1": 6.4e-05,
        "accuracy": 0.001002,
        "main_score": 6.4e-05,
        "hf_subset": "heb_Hebr-ell_Grek",
        "languages": [
          "heb-Hebr",
          "ell-Grek"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 5e-06,
        "accuracy": 0.000501,
        "main_score": 5e-06,
        "hf_subset": "heb_Hebr-eng_Latn",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001002,
        "f1": 1e-05,
        "accuracy": 0.001002,
        "main_score": 1e-05,
        "hf_subset": "heb_Hebr-fas_Arab",
        "languages": [
          "heb-Hebr",
          "fas-Arab"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 5e-06,
        "accuracy": 0.001002,
        "main_score": 5e-06,
        "hf_subset": "heb_Hebr-fin_Latn",
        "languages": [
          "heb-Hebr",
          "fin-Latn"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001502,
        "f1": 9e-06,
        "accuracy": 0.001502,
        "main_score": 9e-06,
        "hf_subset": "heb_Hebr-fra_Latn",
        "languages": [
          "heb-Hebr",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001002,
        "f1": 0.001002,
        "accuracy": 0.001002,
        "main_score": 0.001002,
        "hf_subset": "heb_Hebr-hin_Deva",
        "languages": [
          "heb-Hebr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "heb_Hebr-hun_Latn",
        "languages": [
          "heb-Hebr",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "heb_Hebr-ind_Latn",
        "languages": [
          "heb-Hebr",
          "ind-Latn"
        ]
      },
      {
        "precision": 2.3e-05,
        "recall": 0.001502,
        "f1": 4.6e-05,
        "accuracy": 0.001502,
        "main_score": 4.6e-05,
        "hf_subset": "heb_Hebr-jpn_Jpan",
        "languages": [
          "heb-Hebr",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "heb_Hebr-kmr_Latn",
        "languages": [
          "heb-Hebr",
          "kmr-Latn"
        ]
      },
      {
        "precision": 4.5e-05,
        "recall": 0.001502,
        "f1": 8.6e-05,
        "accuracy": 0.001502,
        "main_score": 8.6e-05,
        "hf_subset": "heb_Hebr-kor_Hang",
        "languages": [
          "heb-Hebr",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "heb_Hebr-lit_Latn",
        "languages": [
          "heb-Hebr",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.000786,
        "recall": 0.002504,
        "f1": 0.000902,
        "accuracy": 0.002504,
        "main_score": 0.000902,
        "hf_subset": "heb_Hebr-mey_Arab",
        "languages": [
          "heb-Hebr",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "heb_Hebr-nld_Latn",
        "languages": [
          "heb-Hebr",
          "nld-Latn"
        ]
      },
      {
        "precision": 1.4e-05,
        "recall": 0.000501,
        "f1": 2.8e-05,
        "accuracy": 0.000501,
        "main_score": 2.8e-05,
        "hf_subset": "heb_Hebr-pol_Latn",
        "languages": [
          "heb-Hebr",
          "pol-Latn"
        ]
      },
      {
        "precision": 5.1e-05,
        "recall": 0.001002,
        "f1": 9.2e-05,
        "accuracy": 0.001002,
        "main_score": 9.2e-05,
        "hf_subset": "heb_Hebr-por_Latn",
        "languages": [
          "heb-Hebr",
          "por-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "heb_Hebr-prs_Arab",
        "languages": [
          "heb-Hebr",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "heb_Hebr-pus_Arab",
        "languages": [
          "heb-Hebr",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.000668,
        "recall": 0.001502,
        "f1": 0.000752,
        "accuracy": 0.001502,
        "main_score": 0.000752,
        "hf_subset": "heb_Hebr-rus_Cyrl",
        "languages": [
          "heb-Hebr",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 3e-06,
        "accuracy": 0.000501,
        "main_score": 3e-06,
        "hf_subset": "heb_Hebr-shi_Arab",
        "languages": [
          "heb-Hebr",
          "shi-Arab"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.001502,
        "f1": 2.1e-05,
        "accuracy": 0.001502,
        "main_score": 2.1e-05,
        "hf_subset": "heb_Hebr-spa_Latn",
        "languages": [
          "heb-Hebr",
          "spa-Latn"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001002,
        "f1": 1.2e-05,
        "accuracy": 0.001002,
        "main_score": 1.2e-05,
        "hf_subset": "heb_Hebr-swa_Latn",
        "languages": [
          "heb-Hebr",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "heb_Hebr-swe_Latn",
        "languages": [
          "heb-Hebr",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "heb_Hebr-tam_Taml",
        "languages": [
          "heb-Hebr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001522,
        "recall": 0.003005,
        "f1": 0.001707,
        "accuracy": 0.003005,
        "main_score": 0.001707,
        "hf_subset": "heb_Hebr-tgk_Cyrl",
        "languages": [
          "heb-Hebr",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.001255,
        "recall": 0.002504,
        "f1": 0.001341,
        "accuracy": 0.002504,
        "main_score": 0.001341,
        "hf_subset": "heb_Hebr-tur_Latn",
        "languages": [
          "heb-Hebr",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000126,
        "recall": 0.001002,
        "f1": 0.000201,
        "accuracy": 0.001002,
        "main_score": 0.000201,
        "hf_subset": "heb_Hebr-vie_Latn",
        "languages": [
          "heb-Hebr",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.000277,
        "recall": 0.002003,
        "f1": 0.000385,
        "accuracy": 0.002003,
        "main_score": 0.000385,
        "hf_subset": "heb_Hebr-zho_Hant",
        "languages": [
          "heb-Hebr",
          "zho-Hant"
        ]
      },
      {
        "precision": 2.6e-05,
        "recall": 0.001002,
        "f1": 4.9e-05,
        "accuracy": 0.001002,
        "main_score": 4.9e-05,
        "hf_subset": "heb_Hebr-zul_Latn",
        "languages": [
          "heb-Hebr",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "hin_Deva-arb_Arab",
        "languages": [
          "hin-Deva",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000227,
        "recall": 0.002003,
        "f1": 0.00037,
        "accuracy": 0.002003,
        "main_score": 0.00037,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "hin_Deva-deu_Latn",
        "languages": [
          "hin-Deva",
          "deu-Latn"
        ]
      },
      {
        "precision": 3.9e-05,
        "recall": 0.001002,
        "f1": 7.3e-05,
        "accuracy": 0.001002,
        "main_score": 7.3e-05,
        "hf_subset": "hin_Deva-div_Thaa",
        "languages": [
          "hin-Deva",
          "div-Thaa"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.000501,
        "f1": 5e-06,
        "accuracy": 0.000501,
        "main_score": 5e-06,
        "hf_subset": "hin_Deva-ell_Grek",
        "languages": [
          "hin-Deva",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000507,
        "recall": 0.002003,
        "f1": 0.000514,
        "accuracy": 0.002003,
        "main_score": 0.000514,
        "hf_subset": "hin_Deva-eus_Latn",
        "languages": [
          "hin-Deva",
          "eus-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 3e-06,
        "accuracy": 0.000501,
        "main_score": 3e-06,
        "hf_subset": "hin_Deva-fas_Arab",
        "languages": [
          "hin-Deva",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "hin_Deva-fin_Latn",
        "languages": [
          "hin-Deva",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.000516,
        "recall": 0.002003,
        "f1": 0.000531,
        "accuracy": 0.002003,
        "main_score": 0.000531,
        "hf_subset": "hin_Deva-fra_Latn",
        "languages": [
          "hin-Deva",
          "fra-Latn"
        ]
      },
      {
        "precision": 2.9e-05,
        "recall": 0.000501,
        "f1": 5.6e-05,
        "accuracy": 0.000501,
        "main_score": 5.6e-05,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000667,
        "recall": 0.003005,
        "f1": 0.00078,
        "accuracy": 0.003005,
        "main_score": 0.00078,
        "hf_subset": "hin_Deva-heb_Hebr",
        "languages": [
          "hin-Deva",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000503,
        "accuracy": 0.001502,
        "main_score": 0.000503,
        "hf_subset": "hin_Deva-hun_Latn",
        "languages": [
          "hin-Deva",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "hin_Deva-ind_Latn",
        "languages": [
          "hin-Deva",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000548,
        "recall": 0.001502,
        "f1": 0.000587,
        "accuracy": 0.001502,
        "main_score": 0.000587,
        "hf_subset": "hin_Deva-jpn_Jpan",
        "languages": [
          "hin-Deva",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.000501,
        "f1": 1e-05,
        "accuracy": 0.000501,
        "main_score": 1e-05,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000507,
        "recall": 0.001502,
        "f1": 0.000513,
        "accuracy": 0.001502,
        "main_score": 0.000513,
        "hf_subset": "hin_Deva-kor_Hang",
        "languages": [
          "hin-Deva",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.000126,
        "recall": 0.001002,
        "f1": 0.000202,
        "accuracy": 0.001002,
        "main_score": 0.000202,
        "hf_subset": "hin_Deva-lit_Latn",
        "languages": [
          "hin-Deva",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.019101,
        "recall": 0.030546,
        "f1": 0.021226,
        "accuracy": 0.030546,
        "main_score": 0.021226,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.018704,
        "recall": 0.034051,
        "f1": 0.02149,
        "accuracy": 0.034051,
        "main_score": 0.02149,
        "hf_subset": "hin_Deva-nep_Deva",
        "languages": [
          "hin-Deva",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.000507,
        "recall": 0.001002,
        "f1": 0.000512,
        "accuracy": 0.001002,
        "main_score": 0.000512,
        "hf_subset": "hin_Deva-nld_Latn",
        "languages": [
          "hin-Deva",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 4e-06,
        "accuracy": 0.000501,
        "main_score": 4e-06,
        "hf_subset": "hin_Deva-pol_Latn",
        "languages": [
          "hin-Deva",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.000592,
        "recall": 0.002003,
        "f1": 0.000659,
        "accuracy": 0.002003,
        "main_score": 0.000659,
        "hf_subset": "hin_Deva-por_Latn",
        "languages": [
          "hin-Deva",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "hin_Deva-rus_Cyrl",
        "languages": [
          "hin-Deva",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "hin_Deva-sin_Sinh",
        "languages": [
          "hin-Deva",
          "sin-Sinh"
        ]
      },
      {
        "precision": 1.4e-05,
        "recall": 0.001002,
        "f1": 2.7e-05,
        "accuracy": 0.001002,
        "main_score": 2.7e-05,
        "hf_subset": "hin_Deva-snd_Arab",
        "languages": [
          "hin-Deva",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.000519,
        "recall": 0.002003,
        "f1": 0.000535,
        "accuracy": 0.002003,
        "main_score": 0.000535,
        "hf_subset": "hin_Deva-spa_Latn",
        "languages": [
          "hin-Deva",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001002,
        "f1": 0.000507,
        "accuracy": 0.001002,
        "main_score": 0.000507,
        "hf_subset": "hin_Deva-swa_Latn",
        "languages": [
          "hin-Deva",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "hin_Deva-swe_Latn",
        "languages": [
          "hin-Deva",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001502,
        "f1": 0.000507,
        "accuracy": 0.001502,
        "main_score": 0.000507,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001002,
        "f1": 0.000507,
        "accuracy": 0.001002,
        "main_score": 0.000507,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "hin_Deva-tur_Latn",
        "languages": [
          "hin-Deva",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000761,
        "recall": 0.003505,
        "f1": 0.000925,
        "accuracy": 0.003505,
        "main_score": 0.000925,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "hin_Deva-vie_Latn",
        "languages": [
          "hin-Deva",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.000541,
        "recall": 0.001502,
        "f1": 0.000575,
        "accuracy": 0.001502,
        "main_score": 0.000575,
        "hf_subset": "hin_Deva-zho_Hant",
        "languages": [
          "hin-Deva",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.000253,
        "recall": 0.001502,
        "f1": 0.000338,
        "accuracy": 0.001502,
        "main_score": 0.000338,
        "hf_subset": "hin_Deva-zul_Latn",
        "languages": [
          "hin-Deva",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.014807,
        "recall": 0.021532,
        "f1": 0.015871,
        "accuracy": 0.021532,
        "main_score": 0.015871,
        "hf_subset": "hmn_Latn-eng_Latn",
        "languages": [
          "hmn-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003283,
        "recall": 0.006009,
        "f1": 0.003644,
        "accuracy": 0.006009,
        "main_score": 0.003644,
        "hf_subset": "hrv_Latn-bel_Cyrl",
        "languages": [
          "hrv-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.614512,
        "recall": 0.694041,
        "f1": 0.637151,
        "accuracy": 0.694041,
        "main_score": 0.637151,
        "hf_subset": "hrv_Latn-bos_Latn",
        "languages": [
          "hrv-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.00441,
        "recall": 0.009014,
        "f1": 0.005298,
        "accuracy": 0.009014,
        "main_score": 0.005298,
        "hf_subset": "hrv_Latn-bul_Cyrl",
        "languages": [
          "hrv-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.029874,
        "recall": 0.042063,
        "f1": 0.032029,
        "accuracy": 0.042063,
        "main_score": 0.032029,
        "hf_subset": "hrv_Latn-ces_Latn",
        "languages": [
          "hrv-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.012877,
        "recall": 0.019029,
        "f1": 0.013855,
        "accuracy": 0.019029,
        "main_score": 0.013855,
        "hf_subset": "hrv_Latn-eng_Latn",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004056,
        "recall": 0.009014,
        "f1": 0.004958,
        "accuracy": 0.009014,
        "main_score": 0.004958,
        "hf_subset": "hrv_Latn-mkd_Cyrl",
        "languages": [
          "hrv-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.016196,
        "recall": 0.024036,
        "f1": 0.01755,
        "accuracy": 0.024036,
        "main_score": 0.01755,
        "hf_subset": "hrv_Latn-pol_Latn",
        "languages": [
          "hrv-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.002106,
        "recall": 0.005508,
        "f1": 0.002599,
        "accuracy": 0.005508,
        "main_score": 0.002599,
        "hf_subset": "hrv_Latn-rus_Cyrl",
        "languages": [
          "hrv-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.041197,
        "recall": 0.056084,
        "f1": 0.043863,
        "accuracy": 0.056084,
        "main_score": 0.043863,
        "hf_subset": "hrv_Latn-slk_Latn",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.119654,
        "recall": 0.159239,
        "f1": 0.127881,
        "accuracy": 0.159239,
        "main_score": 0.127881,
        "hf_subset": "hrv_Latn-slv_Latn",
        "languages": [
          "hrv-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.00955,
        "recall": 0.025038,
        "f1": 0.01151,
        "accuracy": 0.025038,
        "main_score": 0.01151,
        "hf_subset": "hrv_Latn-srp_Cyrl",
        "languages": [
          "hrv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.403574,
        "recall": 0.491738,
        "f1": 0.425844,
        "accuracy": 0.491738,
        "main_score": 0.425844,
        "hf_subset": "hrv_Latn-srp_Latn",
        "languages": [
          "hrv-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.003253,
        "recall": 0.006009,
        "f1": 0.003575,
        "accuracy": 0.006009,
        "main_score": 0.003575,
        "hf_subset": "hrv_Latn-ukr_Cyrl",
        "languages": [
          "hrv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.000505,
        "recall": 0.001002,
        "f1": 0.00051,
        "accuracy": 0.001002,
        "main_score": 0.00051,
        "hf_subset": "hun_Latn-arb_Arab",
        "languages": [
          "hun-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000318,
        "recall": 0.002003,
        "f1": 0.00046,
        "accuracy": 0.002003,
        "main_score": 0.00046,
        "hf_subset": "hun_Latn-ben_Beng",
        "languages": [
          "hun-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.011753,
        "recall": 0.017026,
        "f1": 0.012658,
        "accuracy": 0.017026,
        "main_score": 0.012658,
        "hf_subset": "hun_Latn-deu_Latn",
        "languages": [
          "hun-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000322,
        "recall": 0.001502,
        "f1": 0.000463,
        "accuracy": 0.001502,
        "main_score": 0.000463,
        "hf_subset": "hun_Latn-ell_Grek",
        "languages": [
          "hun-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.013532,
        "recall": 0.023035,
        "f1": 0.01454,
        "accuracy": 0.023035,
        "main_score": 0.01454,
        "hf_subset": "hun_Latn-eng_Latn",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00081,
        "recall": 0.003505,
        "f1": 0.00111,
        "accuracy": 0.003505,
        "main_score": 0.00111,
        "hf_subset": "hun_Latn-fas_Arab",
        "languages": [
          "hun-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.009389,
        "recall": 0.011017,
        "f1": 0.009729,
        "accuracy": 0.011017,
        "main_score": 0.009729,
        "hf_subset": "hun_Latn-fin_Latn",
        "languages": [
          "hun-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.012814,
        "recall": 0.022033,
        "f1": 0.014277,
        "accuracy": 0.022033,
        "main_score": 0.014277,
        "hf_subset": "hun_Latn-fra_Latn",
        "languages": [
          "hun-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000768,
        "recall": 0.002003,
        "f1": 0.000867,
        "accuracy": 0.002003,
        "main_score": 0.000867,
        "hf_subset": "hun_Latn-heb_Hebr",
        "languages": [
          "hun-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 5.5e-05,
        "recall": 0.001502,
        "f1": 0.000102,
        "accuracy": 0.001502,
        "main_score": 0.000102,
        "hf_subset": "hun_Latn-hin_Deva",
        "languages": [
          "hun-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00794,
        "recall": 0.014522,
        "f1": 0.008891,
        "accuracy": 0.014522,
        "main_score": 0.008891,
        "hf_subset": "hun_Latn-ind_Latn",
        "languages": [
          "hun-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000351,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "hun_Latn-jpn_Jpan",
        "languages": [
          "hun-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.00023,
        "recall": 0.001502,
        "f1": 0.000389,
        "accuracy": 0.001502,
        "main_score": 0.000389,
        "hf_subset": "hun_Latn-kor_Hang",
        "languages": [
          "hun-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.006592,
        "recall": 0.010516,
        "f1": 0.007309,
        "accuracy": 0.010516,
        "main_score": 0.007309,
        "hf_subset": "hun_Latn-lav_Latn",
        "languages": [
          "hun-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.003776,
        "recall": 0.008513,
        "f1": 0.004393,
        "accuracy": 0.008513,
        "main_score": 0.004393,
        "hf_subset": "hun_Latn-lit_Latn",
        "languages": [
          "hun-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.011006,
        "recall": 0.015023,
        "f1": 0.011603,
        "accuracy": 0.015023,
        "main_score": 0.011603,
        "hf_subset": "hun_Latn-nld_Latn",
        "languages": [
          "hun-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.00698,
        "recall": 0.012018,
        "f1": 0.00766,
        "accuracy": 0.012018,
        "main_score": 0.00766,
        "hf_subset": "hun_Latn-pol_Latn",
        "languages": [
          "hun-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.01162,
        "recall": 0.02003,
        "f1": 0.01316,
        "accuracy": 0.02003,
        "main_score": 0.01316,
        "hf_subset": "hun_Latn-por_Latn",
        "languages": [
          "hun-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001073,
        "recall": 0.001502,
        "f1": 0.001127,
        "accuracy": 0.001502,
        "main_score": 0.001127,
        "hf_subset": "hun_Latn-rus_Cyrl",
        "languages": [
          "hun-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.01208,
        "recall": 0.018528,
        "f1": 0.013249,
        "accuracy": 0.018528,
        "main_score": 0.013249,
        "hf_subset": "hun_Latn-spa_Latn",
        "languages": [
          "hun-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.004913,
        "recall": 0.007511,
        "f1": 0.005359,
        "accuracy": 0.007511,
        "main_score": 0.005359,
        "hf_subset": "hun_Latn-swa_Latn",
        "languages": [
          "hun-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.013098,
        "recall": 0.02003,
        "f1": 0.013992,
        "accuracy": 0.02003,
        "main_score": 0.013992,
        "hf_subset": "hun_Latn-swe_Latn",
        "languages": [
          "hun-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 1.4e-05,
        "recall": 0.001502,
        "f1": 2.7e-05,
        "accuracy": 0.001502,
        "main_score": 2.7e-05,
        "hf_subset": "hun_Latn-tam_Taml",
        "languages": [
          "hun-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.007262,
        "recall": 0.009514,
        "f1": 0.007601,
        "accuracy": 0.009514,
        "main_score": 0.007601,
        "hf_subset": "hun_Latn-tur_Latn",
        "languages": [
          "hun-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.005648,
        "recall": 0.011017,
        "f1": 0.00627,
        "accuracy": 0.011017,
        "main_score": 0.00627,
        "hf_subset": "hun_Latn-vie_Latn",
        "languages": [
          "hun-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.01353,
        "recall": 0.026039,
        "f1": 0.01542,
        "accuracy": 0.026039,
        "main_score": 0.01542,
        "hf_subset": "hun_Latn-zho_Hant",
        "languages": [
          "hun-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.008099,
        "recall": 0.011017,
        "f1": 0.008753,
        "accuracy": 0.011017,
        "main_score": 0.008753,
        "hf_subset": "hun_Latn-zul_Latn",
        "languages": [
          "hun-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 3e-06,
        "accuracy": 0.000501,
        "main_score": 3e-06,
        "hf_subset": "hye_Armn-ell_Grek",
        "languages": [
          "hye-Armn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.003009,
        "recall": 0.004006,
        "f1": 0.003014,
        "accuracy": 0.004006,
        "main_score": 0.003014,
        "hf_subset": "hye_Armn-eng_Latn",
        "languages": [
          "hye-Armn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002504,
        "f1": 0.00167,
        "accuracy": 0.002504,
        "main_score": 0.00167,
        "hf_subset": "hye_Armn-kat_Geor",
        "languages": [
          "hye-Armn",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.001502,
        "recall": 0.001502,
        "f1": 0.001502,
        "accuracy": 0.001502,
        "main_score": 0.001502,
        "hf_subset": "hye_Armn-sqi_Latn",
        "languages": [
          "hye-Armn",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.006833,
        "recall": 0.010015,
        "f1": 0.007285,
        "accuracy": 0.010015,
        "main_score": 0.007285,
        "hf_subset": "ibo_Latn-amh_Ethi",
        "languages": [
          "ibo-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.027015,
        "recall": 0.038057,
        "f1": 0.028716,
        "accuracy": 0.038057,
        "main_score": 0.028716,
        "hf_subset": "ibo_Latn-eng_Latn",
        "languages": [
          "ibo-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015593,
        "recall": 0.024537,
        "f1": 0.017271,
        "accuracy": 0.024537,
        "main_score": 0.017271,
        "hf_subset": "ibo_Latn-hau_Latn",
        "languages": [
          "ibo-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.014177,
        "recall": 0.019529,
        "f1": 0.015106,
        "accuracy": 0.019529,
        "main_score": 0.015106,
        "hf_subset": "ibo_Latn-nso_Latn",
        "languages": [
          "ibo-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.007733,
        "recall": 0.010516,
        "f1": 0.008252,
        "accuracy": 0.010516,
        "main_score": 0.008252,
        "hf_subset": "ibo_Latn-orm_Ethi",
        "languages": [
          "ibo-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.009628,
        "recall": 0.012519,
        "f1": 0.010159,
        "accuracy": 0.012519,
        "main_score": 0.010159,
        "hf_subset": "ibo_Latn-som_Latn",
        "languages": [
          "ibo-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.012808,
        "recall": 0.017526,
        "f1": 0.013632,
        "accuracy": 0.017526,
        "main_score": 0.013632,
        "hf_subset": "ibo_Latn-ssw_Latn",
        "languages": [
          "ibo-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.011344,
        "recall": 0.015523,
        "f1": 0.012025,
        "accuracy": 0.015523,
        "main_score": 0.012025,
        "hf_subset": "ibo_Latn-swa_Latn",
        "languages": [
          "ibo-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.004274,
        "recall": 0.007011,
        "f1": 0.00465,
        "accuracy": 0.007011,
        "main_score": 0.00465,
        "hf_subset": "ibo_Latn-tir_Ethi",
        "languages": [
          "ibo-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.013056,
        "recall": 0.018027,
        "f1": 0.013675,
        "accuracy": 0.018027,
        "main_score": 0.013675,
        "hf_subset": "ibo_Latn-tsn_Latn",
        "languages": [
          "ibo-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.009726,
        "recall": 0.01352,
        "f1": 0.010131,
        "accuracy": 0.01352,
        "main_score": 0.010131,
        "hf_subset": "ibo_Latn-wol_Latn",
        "languages": [
          "ibo-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.008003,
        "recall": 0.011017,
        "f1": 0.008471,
        "accuracy": 0.011017,
        "main_score": 0.008471,
        "hf_subset": "ibo_Latn-xho_Latn",
        "languages": [
          "ibo-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.01302,
        "recall": 0.016024,
        "f1": 0.013594,
        "accuracy": 0.016024,
        "main_score": 0.013594,
        "hf_subset": "ibo_Latn-yor_Latn",
        "languages": [
          "ibo-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.012893,
        "recall": 0.017526,
        "f1": 0.013646,
        "accuracy": 0.017526,
        "main_score": 0.013646,
        "hf_subset": "ibo_Latn-zul_Latn",
        "languages": [
          "ibo-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000844,
        "recall": 0.002003,
        "f1": 0.000995,
        "accuracy": 0.002003,
        "main_score": 0.000995,
        "hf_subset": "ind_Latn-arb_Arab",
        "languages": [
          "ind-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "ind_Latn-ben_Beng",
        "languages": [
          "ind-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.013362,
        "recall": 0.019029,
        "f1": 0.014495,
        "accuracy": 0.019029,
        "main_score": 0.014495,
        "hf_subset": "ind_Latn-deu_Latn",
        "languages": [
          "ind-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 8e-06,
        "recall": 0.000501,
        "f1": 1.6e-05,
        "accuracy": 0.000501,
        "main_score": 1.6e-05,
        "hf_subset": "ind_Latn-ell_Grek",
        "languages": [
          "ind-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.018992,
        "recall": 0.031047,
        "f1": 0.020524,
        "accuracy": 0.031047,
        "main_score": 0.020524,
        "hf_subset": "ind_Latn-eng_Latn",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001639,
        "recall": 0.005508,
        "f1": 0.001994,
        "accuracy": 0.005508,
        "main_score": 0.001994,
        "hf_subset": "ind_Latn-fas_Arab",
        "languages": [
          "ind-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.007991,
        "recall": 0.014021,
        "f1": 0.008736,
        "accuracy": 0.014021,
        "main_score": 0.008736,
        "hf_subset": "ind_Latn-fij_Latn",
        "languages": [
          "ind-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.014729,
        "recall": 0.018528,
        "f1": 0.01533,
        "accuracy": 0.018528,
        "main_score": 0.01533,
        "hf_subset": "ind_Latn-fil_Latn",
        "languages": [
          "ind-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.011701,
        "recall": 0.016024,
        "f1": 0.012498,
        "accuracy": 0.016024,
        "main_score": 0.012498,
        "hf_subset": "ind_Latn-fin_Latn",
        "languages": [
          "ind-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.012342,
        "recall": 0.021032,
        "f1": 0.01344,
        "accuracy": 0.021032,
        "main_score": 0.01344,
        "hf_subset": "ind_Latn-fra_Latn",
        "languages": [
          "ind-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000997,
        "recall": 0.002504,
        "f1": 0.00128,
        "accuracy": 0.002504,
        "main_score": 0.00128,
        "hf_subset": "ind_Latn-heb_Hebr",
        "languages": [
          "ind-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.00108,
        "recall": 0.002003,
        "f1": 0.001144,
        "accuracy": 0.002003,
        "main_score": 0.001144,
        "hf_subset": "ind_Latn-hin_Deva",
        "languages": [
          "ind-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.011138,
        "recall": 0.015523,
        "f1": 0.011755,
        "accuracy": 0.015523,
        "main_score": 0.011755,
        "hf_subset": "ind_Latn-hun_Latn",
        "languages": [
          "ind-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.001098,
        "recall": 0.002003,
        "f1": 0.00117,
        "accuracy": 0.002003,
        "main_score": 0.00117,
        "hf_subset": "ind_Latn-jpn_Jpan",
        "languages": [
          "ind-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000972,
        "recall": 0.004507,
        "f1": 0.001483,
        "accuracy": 0.004507,
        "main_score": 0.001483,
        "hf_subset": "ind_Latn-kor_Hang",
        "languages": [
          "ind-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.005593,
        "recall": 0.008513,
        "f1": 0.006075,
        "accuracy": 0.008513,
        "main_score": 0.006075,
        "hf_subset": "ind_Latn-lit_Latn",
        "languages": [
          "ind-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.000545,
        "recall": 0.002504,
        "f1": 0.000587,
        "accuracy": 0.002504,
        "main_score": 0.000587,
        "hf_subset": "ind_Latn-mal_Mlym",
        "languages": [
          "ind-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.009325,
        "recall": 0.01352,
        "f1": 0.010052,
        "accuracy": 0.01352,
        "main_score": 0.010052,
        "hf_subset": "ind_Latn-mlg_Latn",
        "languages": [
          "ind-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.016998,
        "recall": 0.023535,
        "f1": 0.018289,
        "accuracy": 0.023535,
        "main_score": 0.018289,
        "hf_subset": "ind_Latn-mri_Latn",
        "languages": [
          "ind-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.315766,
        "recall": 0.4001,
        "f1": 0.337063,
        "accuracy": 0.4001,
        "main_score": 0.337063,
        "hf_subset": "ind_Latn-msa_Latn",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.01486,
        "recall": 0.019529,
        "f1": 0.015475,
        "accuracy": 0.019529,
        "main_score": 0.015475,
        "hf_subset": "ind_Latn-nld_Latn",
        "languages": [
          "ind-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.009947,
        "recall": 0.017026,
        "f1": 0.010673,
        "accuracy": 0.017026,
        "main_score": 0.010673,
        "hf_subset": "ind_Latn-pol_Latn",
        "languages": [
          "ind-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.016469,
        "recall": 0.021532,
        "f1": 0.017119,
        "accuracy": 0.021532,
        "main_score": 0.017119,
        "hf_subset": "ind_Latn-por_Latn",
        "languages": [
          "ind-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001261,
        "recall": 0.002504,
        "f1": 0.001353,
        "accuracy": 0.002504,
        "main_score": 0.001353,
        "hf_subset": "ind_Latn-rus_Cyrl",
        "languages": [
          "ind-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.011897,
        "recall": 0.018528,
        "f1": 0.013139,
        "accuracy": 0.018528,
        "main_score": 0.013139,
        "hf_subset": "ind_Latn-smo_Latn",
        "languages": [
          "ind-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.018078,
        "recall": 0.02654,
        "f1": 0.019171,
        "accuracy": 0.02654,
        "main_score": 0.019171,
        "hf_subset": "ind_Latn-spa_Latn",
        "languages": [
          "ind-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.011999,
        "recall": 0.017526,
        "f1": 0.012877,
        "accuracy": 0.017526,
        "main_score": 0.012877,
        "hf_subset": "ind_Latn-swa_Latn",
        "languages": [
          "ind-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.015129,
        "recall": 0.020531,
        "f1": 0.015918,
        "accuracy": 0.020531,
        "main_score": 0.015918,
        "hf_subset": "ind_Latn-swe_Latn",
        "languages": [
          "ind-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.008549,
        "recall": 0.020531,
        "f1": 0.010394,
        "accuracy": 0.020531,
        "main_score": 0.010394,
        "hf_subset": "ind_Latn-tah_Latn",
        "languages": [
          "ind-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.000796,
        "recall": 0.002504,
        "f1": 0.000973,
        "accuracy": 0.002504,
        "main_score": 0.000973,
        "hf_subset": "ind_Latn-tam_Taml",
        "languages": [
          "ind-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.007024,
        "recall": 0.012519,
        "f1": 0.00773,
        "accuracy": 0.012519,
        "main_score": 0.00773,
        "hf_subset": "ind_Latn-ton_Latn",
        "languages": [
          "ind-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.01413,
        "recall": 0.02003,
        "f1": 0.015119,
        "accuracy": 0.02003,
        "main_score": 0.015119,
        "hf_subset": "ind_Latn-tur_Latn",
        "languages": [
          "ind-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.010669,
        "recall": 0.018528,
        "f1": 0.011611,
        "accuracy": 0.018528,
        "main_score": 0.011611,
        "hf_subset": "ind_Latn-vie_Latn",
        "languages": [
          "ind-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.017119,
        "recall": 0.027041,
        "f1": 0.018273,
        "accuracy": 0.027041,
        "main_score": 0.018273,
        "hf_subset": "ind_Latn-zho_Hant",
        "languages": [
          "ind-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.010217,
        "recall": 0.017026,
        "f1": 0.011039,
        "accuracy": 0.017026,
        "main_score": 0.011039,
        "hf_subset": "ind_Latn-zul_Latn",
        "languages": [
          "ind-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.008134,
        "recall": 0.012519,
        "f1": 0.008573,
        "accuracy": 0.012519,
        "main_score": 0.008573,
        "hf_subset": "isl_Latn-afr_Latn",
        "languages": [
          "isl-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.019686,
        "recall": 0.02654,
        "f1": 0.020872,
        "accuracy": 0.02654,
        "main_score": 0.020872,
        "hf_subset": "isl_Latn-dan_Latn",
        "languages": [
          "isl-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.008519,
        "recall": 0.012519,
        "f1": 0.008769,
        "accuracy": 0.012519,
        "main_score": 0.008769,
        "hf_subset": "isl_Latn-deu_Latn",
        "languages": [
          "isl-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.009132,
        "recall": 0.02003,
        "f1": 0.010358,
        "accuracy": 0.02003,
        "main_score": 0.010358,
        "hf_subset": "isl_Latn-eng_Latn",
        "languages": [
          "isl-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.071092,
        "recall": 0.095643,
        "f1": 0.075357,
        "accuracy": 0.095643,
        "main_score": 0.075357,
        "hf_subset": "isl_Latn-fao_Latn",
        "languages": [
          "isl-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.009161,
        "recall": 0.01302,
        "f1": 0.009663,
        "accuracy": 0.01302,
        "main_score": 0.009663,
        "hf_subset": "isl_Latn-ltz_Latn",
        "languages": [
          "isl-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.007825,
        "recall": 0.011517,
        "f1": 0.008273,
        "accuracy": 0.011517,
        "main_score": 0.008273,
        "hf_subset": "isl_Latn-nld_Latn",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.018681,
        "recall": 0.025038,
        "f1": 0.019716,
        "accuracy": 0.025038,
        "main_score": 0.019716,
        "hf_subset": "isl_Latn-nno_Latn",
        "languages": [
          "isl-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.016399,
        "recall": 0.022534,
        "f1": 0.017452,
        "accuracy": 0.022534,
        "main_score": 0.017452,
        "hf_subset": "isl_Latn-nob_Latn",
        "languages": [
          "isl-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.01512,
        "recall": 0.020531,
        "f1": 0.016063,
        "accuracy": 0.020531,
        "main_score": 0.016063,
        "hf_subset": "isl_Latn-swe_Latn",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.066361,
        "recall": 0.096645,
        "f1": 0.071303,
        "accuracy": 0.096645,
        "main_score": 0.071303,
        "hf_subset": "ita_Latn-cat_Latn",
        "languages": [
          "ita-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.03423,
        "recall": 0.052078,
        "f1": 0.036762,
        "accuracy": 0.052078,
        "main_score": 0.036762,
        "hf_subset": "ita_Latn-eng_Latn",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.04531,
        "recall": 0.0666,
        "f1": 0.048602,
        "accuracy": 0.0666,
        "main_score": 0.048602,
        "hf_subset": "ita_Latn-fra_Latn",
        "languages": [
          "ita-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.070442,
        "recall": 0.095143,
        "f1": 0.075233,
        "accuracy": 0.095143,
        "main_score": 0.075233,
        "hf_subset": "ita_Latn-glg_Latn",
        "languages": [
          "ita-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.032226,
        "recall": 0.045568,
        "f1": 0.034402,
        "accuracy": 0.045568,
        "main_score": 0.034402,
        "hf_subset": "ita_Latn-mlt_Latn",
        "languages": [
          "ita-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.064126,
        "recall": 0.092639,
        "f1": 0.06978,
        "accuracy": 0.092639,
        "main_score": 0.06978,
        "hf_subset": "ita_Latn-por_Latn",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.046164,
        "recall": 0.069104,
        "f1": 0.050143,
        "accuracy": 0.069104,
        "main_score": 0.050143,
        "hf_subset": "ita_Latn-ron_Latn",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.07408,
        "recall": 0.104156,
        "f1": 0.079726,
        "accuracy": 0.104156,
        "main_score": 0.079726,
        "hf_subset": "ita_Latn-spa_Latn",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.000501,
        "f1": 2.1e-05,
        "accuracy": 0.000501,
        "main_score": 2.1e-05,
        "hf_subset": "jpn_Jpan-arb_Arab",
        "languages": [
          "jpn-Jpan",
          "arb-Arab"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.001002,
        "f1": 2e-05,
        "accuracy": 0.001002,
        "main_score": 2e-05,
        "hf_subset": "jpn_Jpan-ben_Beng",
        "languages": [
          "jpn-Jpan",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001002,
        "f1": 0.001002,
        "accuracy": 0.001002,
        "main_score": 0.001002,
        "hf_subset": "jpn_Jpan-deu_Latn",
        "languages": [
          "jpn-Jpan",
          "deu-Latn"
        ]
      },
      {
        "precision": 8.6e-05,
        "recall": 0.001002,
        "f1": 0.000154,
        "accuracy": 0.001002,
        "main_score": 0.000154,
        "hf_subset": "jpn_Jpan-ell_Grek",
        "languages": [
          "jpn-Jpan",
          "ell-Grek"
        ]
      },
      {
        "precision": 8e-05,
        "recall": 0.002003,
        "f1": 0.000143,
        "accuracy": 0.002003,
        "main_score": 0.000143,
        "hf_subset": "jpn_Jpan-eng_Latn",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.000501,
        "f1": 2.2e-05,
        "accuracy": 0.000501,
        "main_score": 2.2e-05,
        "hf_subset": "jpn_Jpan-fas_Arab",
        "languages": [
          "jpn-Jpan",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "jpn_Jpan-fin_Latn",
        "languages": [
          "jpn-Jpan",
          "fin-Latn"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 6e-06,
        "accuracy": 0.001002,
        "main_score": 6e-06,
        "hf_subset": "jpn_Jpan-fra_Latn",
        "languages": [
          "jpn-Jpan",
          "fra-Latn"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.001002,
        "f1": 1e-05,
        "accuracy": 0.001002,
        "main_score": 1e-05,
        "hf_subset": "jpn_Jpan-heb_Hebr",
        "languages": [
          "jpn-Jpan",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000503,
        "accuracy": 0.001002,
        "main_score": 0.000503,
        "hf_subset": "jpn_Jpan-hin_Deva",
        "languages": [
          "jpn-Jpan",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000518,
        "recall": 0.002003,
        "f1": 0.000534,
        "accuracy": 0.002003,
        "main_score": 0.000534,
        "hf_subset": "jpn_Jpan-hun_Latn",
        "languages": [
          "jpn-Jpan",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.000603,
        "recall": 0.001502,
        "f1": 0.000671,
        "accuracy": 0.001502,
        "main_score": 0.000671,
        "hf_subset": "jpn_Jpan-ind_Latn",
        "languages": [
          "jpn-Jpan",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001015,
        "recall": 0.002504,
        "f1": 0.001028,
        "accuracy": 0.002504,
        "main_score": 0.001028,
        "hf_subset": "jpn_Jpan-kor_Hang",
        "languages": [
          "jpn-Jpan",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.000759,
        "recall": 0.002504,
        "f1": 0.00085,
        "accuracy": 0.002504,
        "main_score": 0.00085,
        "hf_subset": "jpn_Jpan-lit_Latn",
        "languages": [
          "jpn-Jpan",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.000508,
        "recall": 0.001502,
        "f1": 0.000515,
        "accuracy": 0.001502,
        "main_score": 0.000515,
        "hf_subset": "jpn_Jpan-nld_Latn",
        "languages": [
          "jpn-Jpan",
          "nld-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 3e-06,
        "accuracy": 0.000501,
        "main_score": 3e-06,
        "hf_subset": "jpn_Jpan-pol_Latn",
        "languages": [
          "jpn-Jpan",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.00151,
        "recall": 0.002504,
        "f1": 0.001517,
        "accuracy": 0.002504,
        "main_score": 0.001517,
        "hf_subset": "jpn_Jpan-por_Latn",
        "languages": [
          "jpn-Jpan",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000838,
        "recall": 0.002003,
        "f1": 0.001008,
        "accuracy": 0.002003,
        "main_score": 0.001008,
        "hf_subset": "jpn_Jpan-rus_Cyrl",
        "languages": [
          "jpn-Jpan",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000505,
        "accuracy": 0.001502,
        "main_score": 0.000505,
        "hf_subset": "jpn_Jpan-spa_Latn",
        "languages": [
          "jpn-Jpan",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.000675,
        "recall": 0.001502,
        "f1": 0.000766,
        "accuracy": 0.001502,
        "main_score": 0.000766,
        "hf_subset": "jpn_Jpan-swa_Latn",
        "languages": [
          "jpn-Jpan",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "jpn_Jpan-swe_Latn",
        "languages": [
          "jpn-Jpan",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "jpn_Jpan-tam_Taml",
        "languages": [
          "jpn-Jpan",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001169,
        "recall": 0.002003,
        "f1": 0.001253,
        "accuracy": 0.002003,
        "main_score": 0.001253,
        "hf_subset": "jpn_Jpan-tur_Latn",
        "languages": [
          "jpn-Jpan",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000519,
        "recall": 0.001502,
        "f1": 0.000537,
        "accuracy": 0.001502,
        "main_score": 0.000537,
        "hf_subset": "jpn_Jpan-vie_Latn",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.000572,
        "recall": 0.002003,
        "f1": 0.000634,
        "accuracy": 0.002003,
        "main_score": 0.000634,
        "hf_subset": "jpn_Jpan-yue_Hant",
        "languages": [
          "jpn-Jpan",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.000199,
        "recall": 0.001502,
        "f1": 0.000311,
        "accuracy": 0.001502,
        "main_score": 0.000311,
        "hf_subset": "jpn_Jpan-zho_Hans",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.000776,
        "recall": 0.002504,
        "f1": 0.000942,
        "accuracy": 0.002504,
        "main_score": 0.000942,
        "hf_subset": "jpn_Jpan-zho_Hant",
        "languages": [
          "jpn-Jpan",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.000584,
        "recall": 0.001502,
        "f1": 0.000649,
        "accuracy": 0.001502,
        "main_score": 0.000649,
        "hf_subset": "jpn_Jpan-zul_Latn",
        "languages": [
          "jpn-Jpan",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.087907,
        "recall": 0.121683,
        "f1": 0.096295,
        "accuracy": 0.121683,
        "main_score": 0.096295,
        "hf_subset": "kan_Knda-div_Thaa",
        "languages": [
          "kan-Knda",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.014741,
        "recall": 0.027541,
        "f1": 0.017272,
        "accuracy": 0.027541,
        "main_score": 0.017272,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00156,
        "recall": 0.006009,
        "f1": 0.00197,
        "accuracy": 0.006009,
        "main_score": 0.00197,
        "hf_subset": "kan_Knda-eus_Latn",
        "languages": [
          "kan-Knda",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.105037,
        "recall": 0.136204,
        "f1": 0.112826,
        "accuracy": 0.136204,
        "main_score": 0.112826,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.001083,
        "recall": 0.003005,
        "f1": 0.001153,
        "accuracy": 0.003005,
        "main_score": 0.001153,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000354,
        "recall": 0.002504,
        "f1": 0.000517,
        "accuracy": 0.002504,
        "main_score": 0.000517,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000281,
        "recall": 0.002003,
        "f1": 0.000471,
        "accuracy": 0.002003,
        "main_score": 0.000471,
        "hf_subset": "kan_Knda-nep_Deva",
        "languages": [
          "kan-Knda",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.07397,
        "recall": 0.107661,
        "f1": 0.081431,
        "accuracy": 0.107661,
        "main_score": 0.081431,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.056535,
        "recall": 0.10015,
        "f1": 0.065407,
        "accuracy": 0.10015,
        "main_score": 0.065407,
        "hf_subset": "kan_Knda-sin_Sinh",
        "languages": [
          "kan-Knda",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.001646,
        "recall": 0.005008,
        "f1": 0.001933,
        "accuracy": 0.005008,
        "main_score": 0.001933,
        "hf_subset": "kan_Knda-snd_Arab",
        "languages": [
          "kan-Knda",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.001318,
        "recall": 0.008012,
        "f1": 0.001758,
        "accuracy": 0.008012,
        "main_score": 0.001758,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.119015,
        "recall": 0.151728,
        "f1": 0.126942,
        "accuracy": 0.151728,
        "main_score": 0.126942,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.000501,
        "f1": 1.3e-05,
        "accuracy": 0.000501,
        "main_score": 1.3e-05,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000659,
        "recall": 0.002003,
        "f1": 0.000763,
        "accuracy": 0.002003,
        "main_score": 0.000763,
        "hf_subset": "kat_Geor-ell_Grek",
        "languages": [
          "kat-Geor",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.002004,
        "recall": 0.003005,
        "f1": 0.002006,
        "accuracy": 0.003005,
        "main_score": 0.002006,
        "hf_subset": "kat_Geor-eng_Latn",
        "languages": [
          "kat-Geor",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000263,
        "recall": 0.001502,
        "f1": 0.000359,
        "accuracy": 0.001502,
        "main_score": 0.000359,
        "hf_subset": "kat_Geor-hye_Armn",
        "languages": [
          "kat-Geor",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.001142,
        "recall": 0.003005,
        "f1": 0.001231,
        "accuracy": 0.003005,
        "main_score": 0.001231,
        "hf_subset": "kat_Geor-sqi_Latn",
        "languages": [
          "kat-Geor",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.000711,
        "recall": 0.002003,
        "f1": 0.000831,
        "accuracy": 0.002003,
        "main_score": 0.000831,
        "hf_subset": "kaz_Cyrl-aze_Latn",
        "languages": [
          "kaz-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.020239,
        "recall": 0.038558,
        "f1": 0.0233,
        "accuracy": 0.038558,
        "main_score": 0.0233,
        "hf_subset": "kaz_Cyrl-bak_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.002275,
        "recall": 0.004006,
        "f1": 0.002379,
        "accuracy": 0.004006,
        "main_score": 0.002379,
        "hf_subset": "kaz_Cyrl-eng_Latn",
        "languages": [
          "kaz-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023527,
        "recall": 0.038558,
        "f1": 0.026704,
        "accuracy": 0.038558,
        "main_score": 0.026704,
        "hf_subset": "kaz_Cyrl-kir_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.023795,
        "recall": 0.041062,
        "f1": 0.027221,
        "accuracy": 0.041062,
        "main_score": 0.027221,
        "hf_subset": "kaz_Cyrl-tat_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001002,
        "f1": 7e-06,
        "accuracy": 0.001002,
        "main_score": 7e-06,
        "hf_subset": "kaz_Cyrl-tuk_Latn",
        "languages": [
          "kaz-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 4e-06,
        "accuracy": 0.000501,
        "main_score": 4e-06,
        "hf_subset": "kaz_Cyrl-tur_Latn",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.001173,
        "recall": 0.003505,
        "f1": 0.001292,
        "accuracy": 0.003505,
        "main_score": 0.001292,
        "hf_subset": "kaz_Cyrl-uig_Arab",
        "languages": [
          "kaz-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000503,
        "accuracy": 0.001002,
        "main_score": 0.000503,
        "hf_subset": "kaz_Cyrl-uzb_Latn",
        "languages": [
          "kaz-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.009482,
        "recall": 0.022534,
        "f1": 0.01162,
        "accuracy": 0.022534,
        "main_score": 0.01162,
        "hf_subset": "khm_Khmr-bod_Tibt",
        "languages": [
          "khm-Khmr",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.000267,
        "recall": 0.001002,
        "f1": 0.000417,
        "accuracy": 0.001002,
        "main_score": 0.000417,
        "hf_subset": "khm_Khmr-dzo_Tibt",
        "languages": [
          "khm-Khmr",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.225901,
        "recall": 0.27992,
        "f1": 0.240555,
        "accuracy": 0.27992,
        "main_score": 0.240555,
        "hf_subset": "khm_Khmr-eng_Latn",
        "languages": [
          "khm-Khmr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.364331,
        "recall": 0.403105,
        "f1": 0.375322,
        "accuracy": 0.403105,
        "main_score": 0.375322,
        "hf_subset": "khm_Khmr-lao_Laoo",
        "languages": [
          "khm-Khmr",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.001383,
        "recall": 0.005008,
        "f1": 0.001671,
        "accuracy": 0.005008,
        "main_score": 0.001671,
        "hf_subset": "khm_Khmr-mon_Mong",
        "languages": [
          "khm-Khmr",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.11814,
        "recall": 0.182774,
        "f1": 0.134534,
        "accuracy": 0.182774,
        "main_score": 0.134534,
        "hf_subset": "khm_Khmr-mya_Mymr",
        "languages": [
          "khm-Khmr",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.212993,
        "recall": 0.27341,
        "f1": 0.22946,
        "accuracy": 0.27341,
        "main_score": 0.22946,
        "hf_subset": "khm_Khmr-tha_Thai",
        "languages": [
          "khm-Khmr",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.010479,
        "recall": 0.015523,
        "f1": 0.01118,
        "accuracy": 0.015523,
        "main_score": 0.01118,
        "hf_subset": "kin_Latn-bem_Latn",
        "languages": [
          "kin-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.006828,
        "recall": 0.01352,
        "f1": 0.007481,
        "accuracy": 0.01352,
        "main_score": 0.007481,
        "hf_subset": "kin_Latn-eng_Latn",
        "languages": [
          "kin-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002189,
        "recall": 0.004006,
        "f1": 0.002457,
        "accuracy": 0.004006,
        "main_score": 0.002457,
        "hf_subset": "kin_Latn-ewe_Latn",
        "languages": [
          "kin-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.005881,
        "recall": 0.007511,
        "f1": 0.006061,
        "accuracy": 0.007511,
        "main_score": 0.006061,
        "hf_subset": "kin_Latn-fuc_Latn",
        "languages": [
          "kin-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.00267,
        "recall": 0.005508,
        "f1": 0.002997,
        "accuracy": 0.005508,
        "main_score": 0.002997,
        "hf_subset": "kin_Latn-nde_Latn",
        "languages": [
          "kin-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.008206,
        "recall": 0.010516,
        "f1": 0.008549,
        "accuracy": 0.010516,
        "main_score": 0.008549,
        "hf_subset": "kin_Latn-nya_Latn",
        "languages": [
          "kin-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.004817,
        "recall": 0.007011,
        "f1": 0.005178,
        "accuracy": 0.007011,
        "main_score": 0.005178,
        "hf_subset": "kin_Latn-sna_Latn",
        "languages": [
          "kin-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.008234,
        "recall": 0.01302,
        "f1": 0.008864,
        "accuracy": 0.01302,
        "main_score": 0.008864,
        "hf_subset": "kin_Latn-ven_Latn",
        "languages": [
          "kin-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.000263,
        "recall": 0.002003,
        "f1": 0.000358,
        "accuracy": 0.002003,
        "main_score": 0.000358,
        "hf_subset": "kir_Cyrl-aze_Latn",
        "languages": [
          "kir-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.0133,
        "recall": 0.024537,
        "f1": 0.014804,
        "accuracy": 0.024537,
        "main_score": 0.014804,
        "hf_subset": "kir_Cyrl-bak_Cyrl",
        "languages": [
          "kir-Cyrl",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.000513,
        "recall": 0.002003,
        "f1": 0.000525,
        "accuracy": 0.002003,
        "main_score": 0.000525,
        "hf_subset": "kir_Cyrl-eng_Latn",
        "languages": [
          "kir-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012039,
        "recall": 0.028543,
        "f1": 0.014525,
        "accuracy": 0.028543,
        "main_score": 0.014525,
        "hf_subset": "kir_Cyrl-kaz_Cyrl",
        "languages": [
          "kir-Cyrl",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.025514,
        "recall": 0.043065,
        "f1": 0.029114,
        "accuracy": 0.043065,
        "main_score": 0.029114,
        "hf_subset": "kir_Cyrl-tat_Cyrl",
        "languages": [
          "kir-Cyrl",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.00051,
        "recall": 0.001002,
        "f1": 0.000519,
        "accuracy": 0.001002,
        "main_score": 0.000519,
        "hf_subset": "kir_Cyrl-tuk_Latn",
        "languages": [
          "kir-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.000601,
        "recall": 0.001002,
        "f1": 0.000668,
        "accuracy": 0.001002,
        "main_score": 0.000668,
        "hf_subset": "kir_Cyrl-tur_Latn",
        "languages": [
          "kir-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000484,
        "recall": 0.002504,
        "f1": 0.000704,
        "accuracy": 0.002504,
        "main_score": 0.000704,
        "hf_subset": "kir_Cyrl-uig_Arab",
        "languages": [
          "kir-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.000513,
        "recall": 0.002003,
        "f1": 0.000525,
        "accuracy": 0.002003,
        "main_score": 0.000525,
        "hf_subset": "kir_Cyrl-uzb_Latn",
        "languages": [
          "kir-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.000515,
        "recall": 0.001502,
        "f1": 0.000529,
        "accuracy": 0.001502,
        "main_score": 0.000529,
        "hf_subset": "kmr_Latn-arb_Arab",
        "languages": [
          "kmr-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.00067,
        "recall": 0.002504,
        "f1": 0.000989,
        "accuracy": 0.002504,
        "main_score": 0.000989,
        "hf_subset": "kmr_Latn-ckb_Arab",
        "languages": [
          "kmr-Latn",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.016789,
        "recall": 0.028042,
        "f1": 0.018197,
        "accuracy": 0.028042,
        "main_score": 0.018197,
        "hf_subset": "kmr_Latn-eng_Latn",
        "languages": [
          "kmr-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00143,
        "recall": 0.005008,
        "f1": 0.001662,
        "accuracy": 0.005008,
        "main_score": 0.001662,
        "hf_subset": "kmr_Latn-fas_Arab",
        "languages": [
          "kmr-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.00124,
        "recall": 0.003505,
        "f1": 0.00155,
        "accuracy": 0.003505,
        "main_score": 0.00155,
        "hf_subset": "kmr_Latn-heb_Hebr",
        "languages": [
          "kmr-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.00042,
        "recall": 0.001502,
        "f1": 0.000589,
        "accuracy": 0.001502,
        "main_score": 0.000589,
        "hf_subset": "kmr_Latn-mey_Arab",
        "languages": [
          "kmr-Latn",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.000381,
        "recall": 0.002504,
        "f1": 0.000627,
        "accuracy": 0.002504,
        "main_score": 0.000627,
        "hf_subset": "kmr_Latn-prs_Arab",
        "languages": [
          "kmr-Latn",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.001023,
        "recall": 0.001502,
        "f1": 0.001043,
        "accuracy": 0.001502,
        "main_score": 0.001043,
        "hf_subset": "kmr_Latn-pus_Arab",
        "languages": [
          "kmr-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.000543,
        "recall": 0.002003,
        "f1": 0.000583,
        "accuracy": 0.002003,
        "main_score": 0.000583,
        "hf_subset": "kmr_Latn-shi_Arab",
        "languages": [
          "kmr-Latn",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.001942,
        "recall": 0.005508,
        "f1": 0.002409,
        "accuracy": 0.005508,
        "main_score": 0.002409,
        "hf_subset": "kmr_Latn-tgk_Cyrl",
        "languages": [
          "kmr-Latn",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.000501,
        "f1": 7e-06,
        "accuracy": 0.000501,
        "main_score": 7e-06,
        "hf_subset": "kor_Hang-arb_Arab",
        "languages": [
          "kor-Hang",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "kor_Hang-ben_Beng",
        "languages": [
          "kor-Hang",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "kor_Hang-deu_Latn",
        "languages": [
          "kor-Hang",
          "deu-Latn"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.001002,
        "f1": 3.2e-05,
        "accuracy": 0.001002,
        "main_score": 3.2e-05,
        "hf_subset": "kor_Hang-ell_Grek",
        "languages": [
          "kor-Hang",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.002005,
        "recall": 0.003005,
        "f1": 0.002006,
        "accuracy": 0.003005,
        "main_score": 0.002006,
        "hf_subset": "kor_Hang-eng_Latn",
        "languages": [
          "kor-Hang",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000289,
        "recall": 0.002003,
        "f1": 0.000409,
        "accuracy": 0.002003,
        "main_score": 0.000409,
        "hf_subset": "kor_Hang-fas_Arab",
        "languages": [
          "kor-Hang",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "kor_Hang-fin_Latn",
        "languages": [
          "kor-Hang",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002003,
        "f1": 0.001006,
        "accuracy": 0.002003,
        "main_score": 0.001006,
        "hf_subset": "kor_Hang-fra_Latn",
        "languages": [
          "kor-Hang",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000505,
        "accuracy": 0.001502,
        "main_score": 0.000505,
        "hf_subset": "kor_Hang-heb_Hebr",
        "languages": [
          "kor-Hang",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000668,
        "recall": 0.001002,
        "f1": 0.000751,
        "accuracy": 0.001002,
        "main_score": 0.000751,
        "hf_subset": "kor_Hang-hin_Deva",
        "languages": [
          "kor-Hang",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "kor_Hang-hun_Latn",
        "languages": [
          "kor-Hang",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002003,
        "f1": 0.001503,
        "accuracy": 0.002003,
        "main_score": 0.001503,
        "hf_subset": "kor_Hang-ind_Latn",
        "languages": [
          "kor-Hang",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001002,
        "f1": 0.001002,
        "accuracy": 0.001002,
        "main_score": 0.001002,
        "hf_subset": "kor_Hang-jpn_Jpan",
        "languages": [
          "kor-Hang",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "kor_Hang-lit_Latn",
        "languages": [
          "kor-Hang",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000503,
        "accuracy": 0.001002,
        "main_score": 0.000503,
        "hf_subset": "kor_Hang-nld_Latn",
        "languages": [
          "kor-Hang",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000503,
        "accuracy": 0.001002,
        "main_score": 0.000503,
        "hf_subset": "kor_Hang-pol_Latn",
        "languages": [
          "kor-Hang",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001002,
        "f1": 0.001002,
        "accuracy": 0.001002,
        "main_score": 0.001002,
        "hf_subset": "kor_Hang-por_Latn",
        "languages": [
          "kor-Hang",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "kor_Hang-rus_Cyrl",
        "languages": [
          "kor-Hang",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "kor_Hang-spa_Latn",
        "languages": [
          "kor-Hang",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001003,
        "accuracy": 0.001502,
        "main_score": 0.001003,
        "hf_subset": "kor_Hang-swa_Latn",
        "languages": [
          "kor-Hang",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002003,
        "f1": 0.001006,
        "accuracy": 0.002003,
        "main_score": 0.001006,
        "hf_subset": "kor_Hang-swe_Latn",
        "languages": [
          "kor-Hang",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001002,
        "f1": 0.001002,
        "accuracy": 0.001002,
        "main_score": 0.001002,
        "hf_subset": "kor_Hang-tam_Taml",
        "languages": [
          "kor-Hang",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001011,
        "recall": 0.002003,
        "f1": 0.00102,
        "accuracy": 0.002003,
        "main_score": 0.00102,
        "hf_subset": "kor_Hang-tur_Latn",
        "languages": [
          "kor-Hang",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000752,
        "recall": 0.001502,
        "f1": 0.000837,
        "accuracy": 0.001502,
        "main_score": 0.000837,
        "hf_subset": "kor_Hang-vie_Latn",
        "languages": [
          "kor-Hang",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "kor_Hang-yue_Hant",
        "languages": [
          "kor-Hang",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.002003,
        "recall": 0.002003,
        "f1": 0.002003,
        "accuracy": 0.002003,
        "main_score": 0.002003,
        "hf_subset": "kor_Hang-zho_Hans",
        "languages": [
          "kor-Hang",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002003,
        "f1": 0.001504,
        "accuracy": 0.002003,
        "main_score": 0.001504,
        "hf_subset": "kor_Hang-zho_Hant",
        "languages": [
          "kor-Hang",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "kor_Hang-zul_Latn",
        "languages": [
          "kor-Hang",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.009377,
        "recall": 0.02654,
        "f1": 0.011856,
        "accuracy": 0.02654,
        "main_score": 0.011856,
        "hf_subset": "lao_Laoo-bod_Tibt",
        "languages": [
          "lao-Laoo",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.001426,
        "recall": 0.004006,
        "f1": 0.001647,
        "accuracy": 0.004006,
        "main_score": 0.001647,
        "hf_subset": "lao_Laoo-dzo_Tibt",
        "languages": [
          "lao-Laoo",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.272746,
        "recall": 0.349024,
        "f1": 0.292731,
        "accuracy": 0.349024,
        "main_score": 0.292731,
        "hf_subset": "lao_Laoo-eng_Latn",
        "languages": [
          "lao-Laoo",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.332704,
        "recall": 0.406109,
        "f1": 0.352892,
        "accuracy": 0.406109,
        "main_score": 0.352892,
        "hf_subset": "lao_Laoo-khm_Khmr",
        "languages": [
          "lao-Laoo",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.002057,
        "recall": 0.007011,
        "f1": 0.002598,
        "accuracy": 0.007011,
        "main_score": 0.002598,
        "hf_subset": "lao_Laoo-mon_Mong",
        "languages": [
          "lao-Laoo",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.140117,
        "recall": 0.221332,
        "f1": 0.159733,
        "accuracy": 0.221332,
        "main_score": 0.159733,
        "hf_subset": "lao_Laoo-mya_Mymr",
        "languages": [
          "lao-Laoo",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.254119,
        "recall": 0.337506,
        "f1": 0.276747,
        "accuracy": 0.337506,
        "main_score": 0.276747,
        "hf_subset": "lao_Laoo-tha_Thai",
        "languages": [
          "lao-Laoo",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.010555,
        "recall": 0.02003,
        "f1": 0.011424,
        "accuracy": 0.02003,
        "main_score": 0.011424,
        "hf_subset": "lav_Latn-eng_Latn",
        "languages": [
          "lav-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010155,
        "recall": 0.011517,
        "f1": 0.01041,
        "accuracy": 0.011517,
        "main_score": 0.01041,
        "hf_subset": "lav_Latn-fin_Latn",
        "languages": [
          "lav-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.005433,
        "recall": 0.011517,
        "f1": 0.00624,
        "accuracy": 0.011517,
        "main_score": 0.00624,
        "hf_subset": "lav_Latn-hun_Latn",
        "languages": [
          "lav-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.024936,
        "recall": 0.039559,
        "f1": 0.027579,
        "accuracy": 0.039559,
        "main_score": 0.027579,
        "hf_subset": "lav_Latn-lit_Latn",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.000252,
        "recall": 0.001002,
        "f1": 0.000336,
        "accuracy": 0.001002,
        "main_score": 0.000336,
        "hf_subset": "lit_Latn-arb_Arab",
        "languages": [
          "lit-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 3.3e-05,
        "recall": 0.001002,
        "f1": 6.2e-05,
        "accuracy": 0.001002,
        "main_score": 6.2e-05,
        "hf_subset": "lit_Latn-ben_Beng",
        "languages": [
          "lit-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.006134,
        "recall": 0.011017,
        "f1": 0.006704,
        "accuracy": 0.011017,
        "main_score": 0.006704,
        "hf_subset": "lit_Latn-deu_Latn",
        "languages": [
          "lit-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000145,
        "recall": 0.002003,
        "f1": 0.000239,
        "accuracy": 0.002003,
        "main_score": 0.000239,
        "hf_subset": "lit_Latn-ell_Grek",
        "languages": [
          "lit-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.008659,
        "recall": 0.017026,
        "f1": 0.009648,
        "accuracy": 0.017026,
        "main_score": 0.009648,
        "hf_subset": "lit_Latn-eng_Latn",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000426,
        "recall": 0.003505,
        "f1": 0.000703,
        "accuracy": 0.003505,
        "main_score": 0.000703,
        "hf_subset": "lit_Latn-fas_Arab",
        "languages": [
          "lit-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.002834,
        "recall": 0.005008,
        "f1": 0.003042,
        "accuracy": 0.005008,
        "main_score": 0.003042,
        "hf_subset": "lit_Latn-fin_Latn",
        "languages": [
          "lit-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.004874,
        "recall": 0.009014,
        "f1": 0.005323,
        "accuracy": 0.009014,
        "main_score": 0.005323,
        "hf_subset": "lit_Latn-fra_Latn",
        "languages": [
          "lit-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 7.6e-05,
        "recall": 0.002003,
        "f1": 0.00014,
        "accuracy": 0.002003,
        "main_score": 0.00014,
        "hf_subset": "lit_Latn-heb_Hebr",
        "languages": [
          "lit-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 1.3e-05,
        "recall": 0.000501,
        "f1": 2.5e-05,
        "accuracy": 0.000501,
        "main_score": 2.5e-05,
        "hf_subset": "lit_Latn-hin_Deva",
        "languages": [
          "lit-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.005335,
        "recall": 0.010516,
        "f1": 0.005913,
        "accuracy": 0.010516,
        "main_score": 0.005913,
        "hf_subset": "lit_Latn-hun_Latn",
        "languages": [
          "lit-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.006326,
        "recall": 0.008012,
        "f1": 0.006634,
        "accuracy": 0.008012,
        "main_score": 0.006634,
        "hf_subset": "lit_Latn-ind_Latn",
        "languages": [
          "lit-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.000501,
        "f1": 1.1e-05,
        "accuracy": 0.000501,
        "main_score": 1.1e-05,
        "hf_subset": "lit_Latn-jpn_Jpan",
        "languages": [
          "lit-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.00058,
        "recall": 0.002003,
        "f1": 0.000646,
        "accuracy": 0.002003,
        "main_score": 0.000646,
        "hf_subset": "lit_Latn-kor_Hang",
        "languages": [
          "lit-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.01827,
        "recall": 0.027541,
        "f1": 0.019858,
        "accuracy": 0.027541,
        "main_score": 0.019858,
        "hf_subset": "lit_Latn-lav_Latn",
        "languages": [
          "lit-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.004811,
        "recall": 0.008513,
        "f1": 0.005219,
        "accuracy": 0.008513,
        "main_score": 0.005219,
        "hf_subset": "lit_Latn-nld_Latn",
        "languages": [
          "lit-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.006512,
        "recall": 0.011017,
        "f1": 0.007339,
        "accuracy": 0.011017,
        "main_score": 0.007339,
        "hf_subset": "lit_Latn-pol_Latn",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.005395,
        "recall": 0.008012,
        "f1": 0.005799,
        "accuracy": 0.008012,
        "main_score": 0.005799,
        "hf_subset": "lit_Latn-por_Latn",
        "languages": [
          "lit-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001277,
        "recall": 0.005008,
        "f1": 0.001676,
        "accuracy": 0.005008,
        "main_score": 0.001676,
        "hf_subset": "lit_Latn-rus_Cyrl",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.004775,
        "recall": 0.008012,
        "f1": 0.005188,
        "accuracy": 0.008012,
        "main_score": 0.005188,
        "hf_subset": "lit_Latn-spa_Latn",
        "languages": [
          "lit-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.00558,
        "recall": 0.00651,
        "f1": 0.0058,
        "accuracy": 0.00651,
        "main_score": 0.0058,
        "hf_subset": "lit_Latn-swa_Latn",
        "languages": [
          "lit-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.008461,
        "recall": 0.014021,
        "f1": 0.009188,
        "accuracy": 0.014021,
        "main_score": 0.009188,
        "hf_subset": "lit_Latn-swe_Latn",
        "languages": [
          "lit-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000106,
        "recall": 0.002504,
        "f1": 0.000199,
        "accuracy": 0.002504,
        "main_score": 0.000199,
        "hf_subset": "lit_Latn-tam_Taml",
        "languages": [
          "lit-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.005039,
        "recall": 0.008513,
        "f1": 0.005703,
        "accuracy": 0.008513,
        "main_score": 0.005703,
        "hf_subset": "lit_Latn-tur_Latn",
        "languages": [
          "lit-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.003832,
        "recall": 0.00651,
        "f1": 0.004049,
        "accuracy": 0.00651,
        "main_score": 0.004049,
        "hf_subset": "lit_Latn-vie_Latn",
        "languages": [
          "lit-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.006615,
        "recall": 0.01352,
        "f1": 0.00752,
        "accuracy": 0.01352,
        "main_score": 0.00752,
        "hf_subset": "lit_Latn-zho_Hant",
        "languages": [
          "lit-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.004229,
        "recall": 0.007011,
        "f1": 0.004401,
        "accuracy": 0.007011,
        "main_score": 0.004401,
        "hf_subset": "lit_Latn-zul_Latn",
        "languages": [
          "lit-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.050543,
        "recall": 0.066099,
        "f1": 0.053642,
        "accuracy": 0.066099,
        "main_score": 0.053642,
        "hf_subset": "ltz_Latn-afr_Latn",
        "languages": [
          "ltz-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.036378,
        "recall": 0.052078,
        "f1": 0.039383,
        "accuracy": 0.052078,
        "main_score": 0.039383,
        "hf_subset": "ltz_Latn-dan_Latn",
        "languages": [
          "ltz-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.104446,
        "recall": 0.138207,
        "f1": 0.112023,
        "accuracy": 0.138207,
        "main_score": 0.112023,
        "hf_subset": "ltz_Latn-deu_Latn",
        "languages": [
          "ltz-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.038314,
        "recall": 0.054081,
        "f1": 0.040166,
        "accuracy": 0.054081,
        "main_score": 0.040166,
        "hf_subset": "ltz_Latn-eng_Latn",
        "languages": [
          "ltz-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022726,
        "recall": 0.03305,
        "f1": 0.024581,
        "accuracy": 0.03305,
        "main_score": 0.024581,
        "hf_subset": "ltz_Latn-fao_Latn",
        "languages": [
          "ltz-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.019136,
        "recall": 0.028543,
        "f1": 0.020553,
        "accuracy": 0.028543,
        "main_score": 0.020553,
        "hf_subset": "ltz_Latn-isl_Latn",
        "languages": [
          "ltz-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.050751,
        "recall": 0.064096,
        "f1": 0.052895,
        "accuracy": 0.064096,
        "main_score": 0.052895,
        "hf_subset": "ltz_Latn-nld_Latn",
        "languages": [
          "ltz-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.035726,
        "recall": 0.049074,
        "f1": 0.038533,
        "accuracy": 0.049074,
        "main_score": 0.038533,
        "hf_subset": "ltz_Latn-nno_Latn",
        "languages": [
          "ltz-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.035503,
        "recall": 0.047571,
        "f1": 0.037727,
        "accuracy": 0.047571,
        "main_score": 0.037727,
        "hf_subset": "ltz_Latn-nob_Latn",
        "languages": [
          "ltz-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.03119,
        "recall": 0.048573,
        "f1": 0.033882,
        "accuracy": 0.048573,
        "main_score": 0.033882,
        "hf_subset": "ltz_Latn-swe_Latn",
        "languages": [
          "ltz-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.011617,
        "recall": 0.022534,
        "f1": 0.013659,
        "accuracy": 0.022534,
        "main_score": 0.013659,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000295,
        "recall": 0.002003,
        "f1": 0.000417,
        "accuracy": 0.002003,
        "main_score": 0.000417,
        "hf_subset": "mal_Mlym-fij_Latn",
        "languages": [
          "mal-Mlym",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.00299,
        "recall": 0.005508,
        "f1": 0.003255,
        "accuracy": 0.005508,
        "main_score": 0.003255,
        "hf_subset": "mal_Mlym-fil_Latn",
        "languages": [
          "mal-Mlym",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.00256,
        "recall": 0.004507,
        "f1": 0.00294,
        "accuracy": 0.004507,
        "main_score": 0.00294,
        "hf_subset": "mal_Mlym-ind_Latn",
        "languages": [
          "mal-Mlym",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001009,
        "recall": 0.004507,
        "f1": 0.001338,
        "accuracy": 0.004507,
        "main_score": 0.001338,
        "hf_subset": "mal_Mlym-mlg_Latn",
        "languages": [
          "mal-Mlym",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.003016,
        "recall": 0.005508,
        "f1": 0.003328,
        "accuracy": 0.005508,
        "main_score": 0.003328,
        "hf_subset": "mal_Mlym-mri_Latn",
        "languages": [
          "mal-Mlym",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.001801,
        "recall": 0.005008,
        "f1": 0.002239,
        "accuracy": 0.005008,
        "main_score": 0.002239,
        "hf_subset": "mal_Mlym-msa_Latn",
        "languages": [
          "mal-Mlym",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.001952,
        "recall": 0.004507,
        "f1": 0.002397,
        "accuracy": 0.004507,
        "main_score": 0.002397,
        "hf_subset": "mal_Mlym-smo_Latn",
        "languages": [
          "mal-Mlym",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.002086,
        "recall": 0.003505,
        "f1": 0.002504,
        "accuracy": 0.003505,
        "main_score": 0.002504,
        "hf_subset": "mal_Mlym-tah_Latn",
        "languages": [
          "mal-Mlym",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.001717,
        "recall": 0.003505,
        "f1": 0.001865,
        "accuracy": 0.003505,
        "main_score": 0.001865,
        "hf_subset": "mal_Mlym-ton_Latn",
        "languages": [
          "mal-Mlym",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.000418,
        "recall": 0.001502,
        "f1": 0.000585,
        "accuracy": 0.001502,
        "main_score": 0.000585,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "mar_Deva-div_Thaa",
        "languages": [
          "mar-Deva",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 1.3e-05,
        "recall": 0.001002,
        "f1": 2.5e-05,
        "accuracy": 0.001002,
        "main_score": 2.5e-05,
        "hf_subset": "mar_Deva-eus_Latn",
        "languages": [
          "mar-Deva",
          "eus-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.014003,
        "recall": 0.026039,
        "f1": 0.015804,
        "accuracy": 0.026039,
        "main_score": 0.015804,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.008508,
        "recall": 0.015023,
        "f1": 0.00964,
        "accuracy": 0.015023,
        "main_score": 0.00964,
        "hf_subset": "mar_Deva-nep_Deva",
        "languages": [
          "mar-Deva",
          "nep-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 6e-05,
        "recall": 0.001502,
        "f1": 0.000108,
        "accuracy": 0.001502,
        "main_score": 0.000108,
        "hf_subset": "mar_Deva-sin_Sinh",
        "languages": [
          "mar-Deva",
          "sin-Sinh"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.001502,
        "f1": 3e-05,
        "accuracy": 0.001502,
        "main_score": 3e-05,
        "hf_subset": "mar_Deva-snd_Arab",
        "languages": [
          "mar-Deva",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000334,
        "accuracy": 0.001002,
        "main_score": 0.000334,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 5.5e-05,
        "recall": 0.001502,
        "f1": 0.000102,
        "accuracy": 0.001502,
        "main_score": 0.000102,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.124514,
        "recall": 0.185278,
        "f1": 0.139514,
        "accuracy": 0.185278,
        "main_score": 0.139514,
        "hf_subset": "mey_Arab-arb_Arab",
        "languages": [
          "mey-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 5e-06,
        "accuracy": 0.001002,
        "main_score": 5e-06,
        "hf_subset": "mey_Arab-ckb_Arab",
        "languages": [
          "mey-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "mey_Arab-eng_Latn",
        "languages": [
          "mey-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001406,
        "recall": 0.004006,
        "f1": 0.001593,
        "accuracy": 0.004006,
        "main_score": 0.001593,
        "hf_subset": "mey_Arab-fas_Arab",
        "languages": [
          "mey-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "mey_Arab-heb_Hebr",
        "languages": [
          "mey-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "mey_Arab-kmr_Latn",
        "languages": [
          "mey-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000366,
        "recall": 0.002504,
        "f1": 0.000588,
        "accuracy": 0.002504,
        "main_score": 0.000588,
        "hf_subset": "mey_Arab-prs_Arab",
        "languages": [
          "mey-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000753,
        "recall": 0.001502,
        "f1": 0.000839,
        "accuracy": 0.001502,
        "main_score": 0.000839,
        "hf_subset": "mey_Arab-pus_Arab",
        "languages": [
          "mey-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.017761,
        "recall": 0.034051,
        "f1": 0.020537,
        "accuracy": 0.034051,
        "main_score": 0.020537,
        "hf_subset": "mey_Arab-shi_Arab",
        "languages": [
          "mey-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.00064,
        "recall": 0.001502,
        "f1": 0.000744,
        "accuracy": 0.001502,
        "main_score": 0.000744,
        "hf_subset": "mey_Arab-tgk_Cyrl",
        "languages": [
          "mey-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.003094,
        "recall": 0.007011,
        "f1": 0.003594,
        "accuracy": 0.007011,
        "main_score": 0.003594,
        "hf_subset": "mkd_Cyrl-bel_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 5.6e-05,
        "recall": 0.001002,
        "f1": 0.000107,
        "accuracy": 0.001002,
        "main_score": 0.000107,
        "hf_subset": "mkd_Cyrl-bos_Latn",
        "languages": [
          "mkd-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.068933,
        "recall": 0.106159,
        "f1": 0.076663,
        "accuracy": 0.106159,
        "main_score": 0.076663,
        "hf_subset": "mkd_Cyrl-bul_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 7.3e-05,
        "recall": 0.001502,
        "f1": 0.000128,
        "accuracy": 0.001502,
        "main_score": 0.000128,
        "hf_subset": "mkd_Cyrl-ces_Latn",
        "languages": [
          "mkd-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "mkd_Cyrl-eng_Latn",
        "languages": [
          "mkd-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 4.8e-05,
        "recall": 0.001502,
        "f1": 8.8e-05,
        "accuracy": 0.001502,
        "main_score": 8.8e-05,
        "hf_subset": "mkd_Cyrl-hrv_Latn",
        "languages": [
          "mkd-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 2.6e-05,
        "recall": 0.001502,
        "f1": 5.1e-05,
        "accuracy": 0.001502,
        "main_score": 5.1e-05,
        "hf_subset": "mkd_Cyrl-pol_Latn",
        "languages": [
          "mkd-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.015279,
        "recall": 0.029044,
        "f1": 0.017452,
        "accuracy": 0.029044,
        "main_score": 0.017452,
        "hf_subset": "mkd_Cyrl-rus_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "mkd_Cyrl-slk_Latn",
        "languages": [
          "mkd-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "mkd_Cyrl-slv_Latn",
        "languages": [
          "mkd-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.042267,
        "recall": 0.069104,
        "f1": 0.046806,
        "accuracy": 0.069104,
        "main_score": 0.046806,
        "hf_subset": "mkd_Cyrl-srp_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.000507,
        "recall": 0.002003,
        "f1": 0.000514,
        "accuracy": 0.002003,
        "main_score": 0.000514,
        "hf_subset": "mkd_Cyrl-srp_Latn",
        "languages": [
          "mkd-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.001146,
        "recall": 0.006009,
        "f1": 0.00151,
        "accuracy": 0.006009,
        "main_score": 0.00151,
        "hf_subset": "mkd_Cyrl-ukr_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.008687,
        "recall": 0.016024,
        "f1": 0.009329,
        "accuracy": 0.016024,
        "main_score": 0.009329,
        "hf_subset": "mlg_Latn-eng_Latn",
        "languages": [
          "mlg-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005828,
        "recall": 0.008513,
        "f1": 0.006223,
        "accuracy": 0.008513,
        "main_score": 0.006223,
        "hf_subset": "mlg_Latn-fij_Latn",
        "languages": [
          "mlg-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.007042,
        "recall": 0.011517,
        "f1": 0.007746,
        "accuracy": 0.011517,
        "main_score": 0.007746,
        "hf_subset": "mlg_Latn-fil_Latn",
        "languages": [
          "mlg-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.006281,
        "recall": 0.010516,
        "f1": 0.00668,
        "accuracy": 0.010516,
        "main_score": 0.00668,
        "hf_subset": "mlg_Latn-ind_Latn",
        "languages": [
          "mlg-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.001502,
        "f1": 1.3e-05,
        "accuracy": 0.001502,
        "main_score": 1.3e-05,
        "hf_subset": "mlg_Latn-mal_Mlym",
        "languages": [
          "mlg-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.008221,
        "recall": 0.01352,
        "f1": 0.008631,
        "accuracy": 0.01352,
        "main_score": 0.008631,
        "hf_subset": "mlg_Latn-mri_Latn",
        "languages": [
          "mlg-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.008401,
        "recall": 0.014021,
        "f1": 0.009282,
        "accuracy": 0.014021,
        "main_score": 0.009282,
        "hf_subset": "mlg_Latn-msa_Latn",
        "languages": [
          "mlg-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.007719,
        "recall": 0.014522,
        "f1": 0.008366,
        "accuracy": 0.014522,
        "main_score": 0.008366,
        "hf_subset": "mlg_Latn-smo_Latn",
        "languages": [
          "mlg-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.004942,
        "recall": 0.009014,
        "f1": 0.00539,
        "accuracy": 0.009014,
        "main_score": 0.00539,
        "hf_subset": "mlg_Latn-tah_Latn",
        "languages": [
          "mlg-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.00528,
        "recall": 0.008513,
        "f1": 0.005639,
        "accuracy": 0.008513,
        "main_score": 0.005639,
        "hf_subset": "mlg_Latn-ton_Latn",
        "languages": [
          "mlg-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.01863,
        "recall": 0.027541,
        "f1": 0.019966,
        "accuracy": 0.027541,
        "main_score": 0.019966,
        "hf_subset": "mlt_Latn-cat_Latn",
        "languages": [
          "mlt-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.019513,
        "recall": 0.032048,
        "f1": 0.021183,
        "accuracy": 0.032048,
        "main_score": 0.021183,
        "hf_subset": "mlt_Latn-eng_Latn",
        "languages": [
          "mlt-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012851,
        "recall": 0.023035,
        "f1": 0.014344,
        "accuracy": 0.023035,
        "main_score": 0.014344,
        "hf_subset": "mlt_Latn-fra_Latn",
        "languages": [
          "mlt-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.017293,
        "recall": 0.030045,
        "f1": 0.01898,
        "accuracy": 0.030045,
        "main_score": 0.01898,
        "hf_subset": "mlt_Latn-glg_Latn",
        "languages": [
          "mlt-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.024366,
        "recall": 0.036555,
        "f1": 0.026275,
        "accuracy": 0.036555,
        "main_score": 0.026275,
        "hf_subset": "mlt_Latn-ita_Latn",
        "languages": [
          "mlt-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.022128,
        "recall": 0.03355,
        "f1": 0.023879,
        "accuracy": 0.03355,
        "main_score": 0.023879,
        "hf_subset": "mlt_Latn-por_Latn",
        "languages": [
          "mlt-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.016981,
        "recall": 0.022033,
        "f1": 0.017702,
        "accuracy": 0.022033,
        "main_score": 0.017702,
        "hf_subset": "mlt_Latn-ron_Latn",
        "languages": [
          "mlt-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.017098,
        "recall": 0.027041,
        "f1": 0.018333,
        "accuracy": 0.027041,
        "main_score": 0.018333,
        "hf_subset": "mlt_Latn-spa_Latn",
        "languages": [
          "mlt-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001002,
        "f1": 3e-06,
        "accuracy": 0.001002,
        "main_score": 3e-06,
        "hf_subset": "mon_Mong-bod_Tibt",
        "languages": [
          "mon-Mong",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "mon_Mong-dzo_Tibt",
        "languages": [
          "mon-Mong",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 1e-05,
        "recall": 0.002003,
        "f1": 1.9e-05,
        "accuracy": 0.002003,
        "main_score": 1.9e-05,
        "hf_subset": "mon_Mong-eng_Latn",
        "languages": [
          "mon-Mong",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "mon_Mong-khm_Khmr",
        "languages": [
          "mon-Mong",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mon_Mong-lao_Laoo",
        "languages": [
          "mon-Mong",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mon_Mong-mya_Mymr",
        "languages": [
          "mon-Mong",
          "mya-Mymr"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "mon_Mong-tha_Thai",
        "languages": [
          "mon-Mong",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.017434,
        "recall": 0.026039,
        "f1": 0.018207,
        "accuracy": 0.026039,
        "main_score": 0.018207,
        "hf_subset": "mri_Latn-eng_Latn",
        "languages": [
          "mri-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007184,
        "recall": 0.010015,
        "f1": 0.007677,
        "accuracy": 0.010015,
        "main_score": 0.007677,
        "hf_subset": "mri_Latn-fij_Latn",
        "languages": [
          "mri-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.008276,
        "recall": 0.011517,
        "f1": 0.008633,
        "accuracy": 0.011517,
        "main_score": 0.008633,
        "hf_subset": "mri_Latn-fil_Latn",
        "languages": [
          "mri-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.009226,
        "recall": 0.012018,
        "f1": 0.009395,
        "accuracy": 0.012018,
        "main_score": 0.009395,
        "hf_subset": "mri_Latn-ind_Latn",
        "languages": [
          "mri-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000513,
        "recall": 0.002003,
        "f1": 0.000525,
        "accuracy": 0.002003,
        "main_score": 0.000525,
        "hf_subset": "mri_Latn-mal_Mlym",
        "languages": [
          "mri-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.007666,
        "recall": 0.009514,
        "f1": 0.008006,
        "accuracy": 0.009514,
        "main_score": 0.008006,
        "hf_subset": "mri_Latn-mlg_Latn",
        "languages": [
          "mri-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.007123,
        "recall": 0.008513,
        "f1": 0.007213,
        "accuracy": 0.008513,
        "main_score": 0.007213,
        "hf_subset": "mri_Latn-msa_Latn",
        "languages": [
          "mri-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.011548,
        "recall": 0.015023,
        "f1": 0.012199,
        "accuracy": 0.015023,
        "main_score": 0.012199,
        "hf_subset": "mri_Latn-smo_Latn",
        "languages": [
          "mri-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.019533,
        "recall": 0.028543,
        "f1": 0.021053,
        "accuracy": 0.028543,
        "main_score": 0.021053,
        "hf_subset": "mri_Latn-tah_Latn",
        "languages": [
          "mri-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.005467,
        "recall": 0.012018,
        "f1": 0.006272,
        "accuracy": 0.012018,
        "main_score": 0.006272,
        "hf_subset": "mri_Latn-ton_Latn",
        "languages": [
          "mri-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.019637,
        "recall": 0.032048,
        "f1": 0.021241,
        "accuracy": 0.032048,
        "main_score": 0.021241,
        "hf_subset": "msa_Latn-eng_Latn",
        "languages": [
          "msa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007657,
        "recall": 0.012519,
        "f1": 0.00812,
        "accuracy": 0.012519,
        "main_score": 0.00812,
        "hf_subset": "msa_Latn-fij_Latn",
        "languages": [
          "msa-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.014173,
        "recall": 0.019029,
        "f1": 0.015042,
        "accuracy": 0.019029,
        "main_score": 0.015042,
        "hf_subset": "msa_Latn-fil_Latn",
        "languages": [
          "msa-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.329043,
        "recall": 0.414121,
        "f1": 0.351008,
        "accuracy": 0.414121,
        "main_score": 0.351008,
        "hf_subset": "msa_Latn-ind_Latn",
        "languages": [
          "msa-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000642,
        "recall": 0.002003,
        "f1": 0.000733,
        "accuracy": 0.002003,
        "main_score": 0.000733,
        "hf_subset": "msa_Latn-mal_Mlym",
        "languages": [
          "msa-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.012546,
        "recall": 0.017026,
        "f1": 0.013144,
        "accuracy": 0.017026,
        "main_score": 0.013144,
        "hf_subset": "msa_Latn-mlg_Latn",
        "languages": [
          "msa-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.01458,
        "recall": 0.021032,
        "f1": 0.015808,
        "accuracy": 0.021032,
        "main_score": 0.015808,
        "hf_subset": "msa_Latn-mri_Latn",
        "languages": [
          "msa-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.013935,
        "recall": 0.021532,
        "f1": 0.015056,
        "accuracy": 0.021532,
        "main_score": 0.015056,
        "hf_subset": "msa_Latn-smo_Latn",
        "languages": [
          "msa-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.012191,
        "recall": 0.022033,
        "f1": 0.013706,
        "accuracy": 0.022033,
        "main_score": 0.013706,
        "hf_subset": "msa_Latn-tah_Latn",
        "languages": [
          "msa-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.005217,
        "recall": 0.012018,
        "f1": 0.006392,
        "accuracy": 0.012018,
        "main_score": 0.006392,
        "hf_subset": "msa_Latn-ton_Latn",
        "languages": [
          "msa-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.005285,
        "recall": 0.010516,
        "f1": 0.006275,
        "accuracy": 0.010516,
        "main_score": 0.006275,
        "hf_subset": "mya_Mymr-bod_Tibt",
        "languages": [
          "mya-Mymr",
          "bod-Tibt"
        ]
      },
      {
        "precision": 1.4e-05,
        "recall": 0.001002,
        "f1": 2.7e-05,
        "accuracy": 0.001002,
        "main_score": 2.7e-05,
        "hf_subset": "mya_Mymr-dzo_Tibt",
        "languages": [
          "mya-Mymr",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.120279,
        "recall": 0.149725,
        "f1": 0.128166,
        "accuracy": 0.149725,
        "main_score": 0.128166,
        "hf_subset": "mya_Mymr-eng_Latn",
        "languages": [
          "mya-Mymr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.145457,
        "recall": 0.178267,
        "f1": 0.154109,
        "accuracy": 0.178267,
        "main_score": 0.154109,
        "hf_subset": "mya_Mymr-khm_Khmr",
        "languages": [
          "mya-Mymr",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.180674,
        "recall": 0.206309,
        "f1": 0.187989,
        "accuracy": 0.206309,
        "main_score": 0.187989,
        "hf_subset": "mya_Mymr-lao_Laoo",
        "languages": [
          "mya-Mymr",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.001088,
        "recall": 0.002504,
        "f1": 0.00116,
        "accuracy": 0.002504,
        "main_score": 0.00116,
        "hf_subset": "mya_Mymr-mon_Mong",
        "languages": [
          "mya-Mymr",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.134063,
        "recall": 0.166249,
        "f1": 0.142615,
        "accuracy": 0.166249,
        "main_score": 0.142615,
        "hf_subset": "mya_Mymr-tha_Thai",
        "languages": [
          "mya-Mymr",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.003579,
        "recall": 0.005508,
        "f1": 0.003812,
        "accuracy": 0.005508,
        "main_score": 0.003812,
        "hf_subset": "nde_Latn-bem_Latn",
        "languages": [
          "nde-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.005619,
        "recall": 0.012018,
        "f1": 0.006178,
        "accuracy": 0.012018,
        "main_score": 0.006178,
        "hf_subset": "nde_Latn-eng_Latn",
        "languages": [
          "nde-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005159,
        "recall": 0.008012,
        "f1": 0.005485,
        "accuracy": 0.008012,
        "main_score": 0.005485,
        "hf_subset": "nde_Latn-ewe_Latn",
        "languages": [
          "nde-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.003409,
        "recall": 0.006009,
        "f1": 0.003762,
        "accuracy": 0.006009,
        "main_score": 0.003762,
        "hf_subset": "nde_Latn-fuc_Latn",
        "languages": [
          "nde-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.003772,
        "recall": 0.007011,
        "f1": 0.003983,
        "accuracy": 0.007011,
        "main_score": 0.003983,
        "hf_subset": "nde_Latn-kin_Latn",
        "languages": [
          "nde-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.003193,
        "recall": 0.004006,
        "f1": 0.003297,
        "accuracy": 0.004006,
        "main_score": 0.003297,
        "hf_subset": "nde_Latn-nya_Latn",
        "languages": [
          "nde-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.006011,
        "recall": 0.007011,
        "f1": 0.00618,
        "accuracy": 0.007011,
        "main_score": 0.00618,
        "hf_subset": "nde_Latn-sna_Latn",
        "languages": [
          "nde-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.00328,
        "recall": 0.006009,
        "f1": 0.003501,
        "accuracy": 0.006009,
        "main_score": 0.003501,
        "hf_subset": "nde_Latn-ven_Latn",
        "languages": [
          "nde-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 4.3e-05,
        "recall": 0.001502,
        "f1": 8e-05,
        "accuracy": 0.001502,
        "main_score": 8e-05,
        "hf_subset": "nep_Deva-ben_Beng",
        "languages": [
          "nep-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.001002,
        "f1": 2.8e-05,
        "accuracy": 0.001002,
        "main_score": 2.8e-05,
        "hf_subset": "nep_Deva-div_Thaa",
        "languages": [
          "nep-Deva",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.000544,
        "recall": 0.002003,
        "f1": 0.00058,
        "accuracy": 0.002003,
        "main_score": 0.00058,
        "hf_subset": "nep_Deva-eng_Latn",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001002,
        "f1": 1.1e-05,
        "accuracy": 0.001002,
        "main_score": 1.1e-05,
        "hf_subset": "nep_Deva-eus_Latn",
        "languages": [
          "nep-Deva",
          "eus-Latn"
        ]
      },
      {
        "precision": 1.2e-05,
        "recall": 0.000501,
        "f1": 2.4e-05,
        "accuracy": 0.000501,
        "main_score": 2.4e-05,
        "hf_subset": "nep_Deva-guj_Gujr",
        "languages": [
          "nep-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.021965,
        "recall": 0.037556,
        "f1": 0.025247,
        "accuracy": 0.037556,
        "main_score": 0.025247,
        "hf_subset": "nep_Deva-hin_Deva",
        "languages": [
          "nep-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 8e-06,
        "recall": 0.001002,
        "f1": 1.6e-05,
        "accuracy": 0.001002,
        "main_score": 1.6e-05,
        "hf_subset": "nep_Deva-kan_Knda",
        "languages": [
          "nep-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.009267,
        "recall": 0.021032,
        "f1": 0.011061,
        "accuracy": 0.021032,
        "main_score": 0.011061,
        "hf_subset": "nep_Deva-mar_Deva",
        "languages": [
          "nep-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 7.2e-05,
        "recall": 0.001002,
        "f1": 0.000126,
        "accuracy": 0.001002,
        "main_score": 0.000126,
        "hf_subset": "nep_Deva-pan_Guru",
        "languages": [
          "nep-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.000501,
        "f1": 2.1e-05,
        "accuracy": 0.000501,
        "main_score": 2.1e-05,
        "hf_subset": "nep_Deva-sin_Sinh",
        "languages": [
          "nep-Deva",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000507,
        "recall": 0.001502,
        "f1": 0.000514,
        "accuracy": 0.001502,
        "main_score": 0.000514,
        "hf_subset": "nep_Deva-snd_Arab",
        "languages": [
          "nep-Deva",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "nep_Deva-tam_Taml",
        "languages": [
          "nep-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.001002,
        "f1": 3e-05,
        "accuracy": 0.001002,
        "main_score": 3e-05,
        "hf_subset": "nep_Deva-tel_Telu",
        "languages": [
          "nep-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001002,
        "f1": 7e-06,
        "accuracy": 0.001002,
        "main_score": 7e-06,
        "hf_subset": "nep_Deva-urd_Arab",
        "languages": [
          "nep-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.165005,
        "recall": 0.22033,
        "f1": 0.176928,
        "accuracy": 0.22033,
        "main_score": 0.176928,
        "hf_subset": "nld_Latn-afr_Latn",
        "languages": [
          "nld-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001002,
        "f1": 0.000505,
        "accuracy": 0.001002,
        "main_score": 0.000505,
        "hf_subset": "nld_Latn-arb_Arab",
        "languages": [
          "nld-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 3.9e-05,
        "recall": 0.000501,
        "f1": 7.2e-05,
        "accuracy": 0.000501,
        "main_score": 7.2e-05,
        "hf_subset": "nld_Latn-ben_Beng",
        "languages": [
          "nld-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.03567,
        "recall": 0.049574,
        "f1": 0.037922,
        "accuracy": 0.049574,
        "main_score": 0.037922,
        "hf_subset": "nld_Latn-dan_Latn",
        "languages": [
          "nld-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.03873,
        "recall": 0.058087,
        "f1": 0.041859,
        "accuracy": 0.058087,
        "main_score": 0.041859,
        "hf_subset": "nld_Latn-deu_Latn",
        "languages": [
          "nld-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.001272,
        "recall": 0.003005,
        "f1": 0.001457,
        "accuracy": 0.003005,
        "main_score": 0.001457,
        "hf_subset": "nld_Latn-ell_Grek",
        "languages": [
          "nld-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.033172,
        "recall": 0.048573,
        "f1": 0.035038,
        "accuracy": 0.048573,
        "main_score": 0.035038,
        "hf_subset": "nld_Latn-eng_Latn",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01424,
        "recall": 0.022534,
        "f1": 0.015307,
        "accuracy": 0.022534,
        "main_score": 0.015307,
        "hf_subset": "nld_Latn-fao_Latn",
        "languages": [
          "nld-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.001666,
        "recall": 0.005508,
        "f1": 0.001805,
        "accuracy": 0.005508,
        "main_score": 0.001805,
        "hf_subset": "nld_Latn-fas_Arab",
        "languages": [
          "nld-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.01121,
        "recall": 0.014522,
        "f1": 0.011754,
        "accuracy": 0.014522,
        "main_score": 0.011754,
        "hf_subset": "nld_Latn-fin_Latn",
        "languages": [
          "nld-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.020227,
        "recall": 0.03355,
        "f1": 0.022327,
        "accuracy": 0.03355,
        "main_score": 0.022327,
        "hf_subset": "nld_Latn-fra_Latn",
        "languages": [
          "nld-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 3.2e-05,
        "recall": 0.001502,
        "f1": 6.3e-05,
        "accuracy": 0.001502,
        "main_score": 6.3e-05,
        "hf_subset": "nld_Latn-heb_Hebr",
        "languages": [
          "nld-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000266,
        "recall": 0.001502,
        "f1": 0.000365,
        "accuracy": 0.001502,
        "main_score": 0.000365,
        "hf_subset": "nld_Latn-hin_Deva",
        "languages": [
          "nld-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.010388,
        "recall": 0.015023,
        "f1": 0.011368,
        "accuracy": 0.015023,
        "main_score": 0.011368,
        "hf_subset": "nld_Latn-hun_Latn",
        "languages": [
          "nld-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.014192,
        "recall": 0.02003,
        "f1": 0.01509,
        "accuracy": 0.02003,
        "main_score": 0.01509,
        "hf_subset": "nld_Latn-ind_Latn",
        "languages": [
          "nld-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.011738,
        "recall": 0.019029,
        "f1": 0.012808,
        "accuracy": 0.019029,
        "main_score": 0.012808,
        "hf_subset": "nld_Latn-isl_Latn",
        "languages": [
          "nld-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.001182,
        "recall": 0.002003,
        "f1": 0.001279,
        "accuracy": 0.002003,
        "main_score": 0.001279,
        "hf_subset": "nld_Latn-jpn_Jpan",
        "languages": [
          "nld-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000828,
        "recall": 0.003505,
        "f1": 0.00121,
        "accuracy": 0.003505,
        "main_score": 0.00121,
        "hf_subset": "nld_Latn-kor_Hang",
        "languages": [
          "nld-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.006224,
        "recall": 0.01302,
        "f1": 0.007047,
        "accuracy": 0.01302,
        "main_score": 0.007047,
        "hf_subset": "nld_Latn-lit_Latn",
        "languages": [
          "nld-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.046914,
        "recall": 0.067601,
        "f1": 0.050417,
        "accuracy": 0.067601,
        "main_score": 0.050417,
        "hf_subset": "nld_Latn-ltz_Latn",
        "languages": [
          "nld-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.025713,
        "recall": 0.035553,
        "f1": 0.02737,
        "accuracy": 0.035553,
        "main_score": 0.02737,
        "hf_subset": "nld_Latn-nno_Latn",
        "languages": [
          "nld-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.026596,
        "recall": 0.038057,
        "f1": 0.028709,
        "accuracy": 0.038057,
        "main_score": 0.028709,
        "hf_subset": "nld_Latn-nob_Latn",
        "languages": [
          "nld-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.010196,
        "recall": 0.018528,
        "f1": 0.011323,
        "accuracy": 0.018528,
        "main_score": 0.011323,
        "hf_subset": "nld_Latn-pol_Latn",
        "languages": [
          "nld-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.019745,
        "recall": 0.028042,
        "f1": 0.021226,
        "accuracy": 0.028042,
        "main_score": 0.021226,
        "hf_subset": "nld_Latn-por_Latn",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001502,
        "recall": 0.003005,
        "f1": 0.001796,
        "accuracy": 0.003005,
        "main_score": 0.001796,
        "hf_subset": "nld_Latn-rus_Cyrl",
        "languages": [
          "nld-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.020468,
        "recall": 0.02654,
        "f1": 0.021686,
        "accuracy": 0.02654,
        "main_score": 0.021686,
        "hf_subset": "nld_Latn-spa_Latn",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.006602,
        "recall": 0.011017,
        "f1": 0.007302,
        "accuracy": 0.011017,
        "main_score": 0.007302,
        "hf_subset": "nld_Latn-swa_Latn",
        "languages": [
          "nld-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.026733,
        "recall": 0.036054,
        "f1": 0.028395,
        "accuracy": 0.036054,
        "main_score": 0.028395,
        "hf_subset": "nld_Latn-swe_Latn",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000103,
        "recall": 0.001502,
        "f1": 0.000191,
        "accuracy": 0.001502,
        "main_score": 0.000191,
        "hf_subset": "nld_Latn-tam_Taml",
        "languages": [
          "nld-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.010824,
        "recall": 0.016525,
        "f1": 0.011793,
        "accuracy": 0.016525,
        "main_score": 0.011793,
        "hf_subset": "nld_Latn-tur_Latn",
        "languages": [
          "nld-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.008166,
        "recall": 0.015523,
        "f1": 0.009364,
        "accuracy": 0.015523,
        "main_score": 0.009364,
        "hf_subset": "nld_Latn-vie_Latn",
        "languages": [
          "nld-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.019028,
        "recall": 0.03305,
        "f1": 0.0213,
        "accuracy": 0.03305,
        "main_score": 0.0213,
        "hf_subset": "nld_Latn-zho_Hant",
        "languages": [
          "nld-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.011358,
        "recall": 0.018027,
        "f1": 0.01225,
        "accuracy": 0.018027,
        "main_score": 0.01225,
        "hf_subset": "nld_Latn-zul_Latn",
        "languages": [
          "nld-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.042632,
        "recall": 0.065098,
        "f1": 0.047578,
        "accuracy": 0.065098,
        "main_score": 0.047578,
        "hf_subset": "nno_Latn-afr_Latn",
        "languages": [
          "nno-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.250854,
        "recall": 0.329995,
        "f1": 0.270888,
        "accuracy": 0.329995,
        "main_score": 0.270888,
        "hf_subset": "nno_Latn-dan_Latn",
        "languages": [
          "nno-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.032699,
        "recall": 0.051577,
        "f1": 0.036843,
        "accuracy": 0.051577,
        "main_score": 0.036843,
        "hf_subset": "nno_Latn-deu_Latn",
        "languages": [
          "nno-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.040369,
        "recall": 0.065098,
        "f1": 0.04395,
        "accuracy": 0.065098,
        "main_score": 0.04395,
        "hf_subset": "nno_Latn-eng_Latn",
        "languages": [
          "nno-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.07424,
        "recall": 0.104156,
        "f1": 0.080422,
        "accuracy": 0.104156,
        "main_score": 0.080422,
        "hf_subset": "nno_Latn-fao_Latn",
        "languages": [
          "nno-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.032135,
        "recall": 0.051577,
        "f1": 0.035756,
        "accuracy": 0.051577,
        "main_score": 0.035756,
        "hf_subset": "nno_Latn-isl_Latn",
        "languages": [
          "nno-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.042481,
        "recall": 0.063595,
        "f1": 0.046954,
        "accuracy": 0.063595,
        "main_score": 0.046954,
        "hf_subset": "nno_Latn-ltz_Latn",
        "languages": [
          "nno-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.044725,
        "recall": 0.064597,
        "f1": 0.048812,
        "accuracy": 0.064597,
        "main_score": 0.048812,
        "hf_subset": "nno_Latn-nld_Latn",
        "languages": [
          "nno-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.491576,
        "recall": 0.583876,
        "f1": 0.516946,
        "accuracy": 0.583876,
        "main_score": 0.516946,
        "hf_subset": "nno_Latn-nob_Latn",
        "languages": [
          "nno-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.20757,
        "recall": 0.269905,
        "f1": 0.222159,
        "accuracy": 0.269905,
        "main_score": 0.222159,
        "hf_subset": "nno_Latn-swe_Latn",
        "languages": [
          "nno-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.046692,
        "recall": 0.062594,
        "f1": 0.050153,
        "accuracy": 0.062594,
        "main_score": 0.050153,
        "hf_subset": "nob_Latn-afr_Latn",
        "languages": [
          "nob-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.429597,
        "recall": 0.512769,
        "f1": 0.451759,
        "accuracy": 0.512769,
        "main_score": 0.451759,
        "hf_subset": "nob_Latn-dan_Latn",
        "languages": [
          "nob-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.045411,
        "recall": 0.063095,
        "f1": 0.048814,
        "accuracy": 0.063095,
        "main_score": 0.048814,
        "hf_subset": "nob_Latn-deu_Latn",
        "languages": [
          "nob-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.035147,
        "recall": 0.058588,
        "f1": 0.038259,
        "accuracy": 0.058588,
        "main_score": 0.038259,
        "hf_subset": "nob_Latn-eng_Latn",
        "languages": [
          "nob-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.064054,
        "recall": 0.085628,
        "f1": 0.06835,
        "accuracy": 0.085628,
        "main_score": 0.06835,
        "hf_subset": "nob_Latn-fao_Latn",
        "languages": [
          "nob-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.028965,
        "recall": 0.044567,
        "f1": 0.031876,
        "accuracy": 0.044567,
        "main_score": 0.031876,
        "hf_subset": "nob_Latn-isl_Latn",
        "languages": [
          "nob-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.039802,
        "recall": 0.05358,
        "f1": 0.042639,
        "accuracy": 0.05358,
        "main_score": 0.042639,
        "hf_subset": "nob_Latn-ltz_Latn",
        "languages": [
          "nob-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.042091,
        "recall": 0.058588,
        "f1": 0.045323,
        "accuracy": 0.058588,
        "main_score": 0.045323,
        "hf_subset": "nob_Latn-nld_Latn",
        "languages": [
          "nob-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.445563,
        "recall": 0.522283,
        "f1": 0.46504,
        "accuracy": 0.522283,
        "main_score": 0.46504,
        "hf_subset": "nob_Latn-nno_Latn",
        "languages": [
          "nob-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.192541,
        "recall": 0.245869,
        "f1": 0.203401,
        "accuracy": 0.245869,
        "main_score": 0.203401,
        "hf_subset": "nob_Latn-swe_Latn",
        "languages": [
          "nob-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.00387,
        "recall": 0.008513,
        "f1": 0.004289,
        "accuracy": 0.008513,
        "main_score": 0.004289,
        "hf_subset": "nso_Latn-amh_Ethi",
        "languages": [
          "nso-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.017389,
        "recall": 0.027541,
        "f1": 0.018592,
        "accuracy": 0.027541,
        "main_score": 0.018592,
        "hf_subset": "nso_Latn-eng_Latn",
        "languages": [
          "nso-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00722,
        "recall": 0.011017,
        "f1": 0.007755,
        "accuracy": 0.011017,
        "main_score": 0.007755,
        "hf_subset": "nso_Latn-hau_Latn",
        "languages": [
          "nso-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.010248,
        "recall": 0.01302,
        "f1": 0.010785,
        "accuracy": 0.01302,
        "main_score": 0.010785,
        "hf_subset": "nso_Latn-ibo_Latn",
        "languages": [
          "nso-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.004371,
        "recall": 0.007511,
        "f1": 0.004716,
        "accuracy": 0.007511,
        "main_score": 0.004716,
        "hf_subset": "nso_Latn-orm_Ethi",
        "languages": [
          "nso-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.007739,
        "recall": 0.012018,
        "f1": 0.008414,
        "accuracy": 0.012018,
        "main_score": 0.008414,
        "hf_subset": "nso_Latn-som_Latn",
        "languages": [
          "nso-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.010679,
        "recall": 0.015023,
        "f1": 0.011285,
        "accuracy": 0.015023,
        "main_score": 0.011285,
        "hf_subset": "nso_Latn-ssw_Latn",
        "languages": [
          "nso-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.007823,
        "recall": 0.010516,
        "f1": 0.008191,
        "accuracy": 0.010516,
        "main_score": 0.008191,
        "hf_subset": "nso_Latn-swa_Latn",
        "languages": [
          "nso-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.002441,
        "recall": 0.005008,
        "f1": 0.002656,
        "accuracy": 0.005008,
        "main_score": 0.002656,
        "hf_subset": "nso_Latn-tir_Ethi",
        "languages": [
          "nso-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.082233,
        "recall": 0.114171,
        "f1": 0.088797,
        "accuracy": 0.114171,
        "main_score": 0.088797,
        "hf_subset": "nso_Latn-tsn_Latn",
        "languages": [
          "nso-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.005979,
        "recall": 0.008513,
        "f1": 0.0064,
        "accuracy": 0.008513,
        "main_score": 0.0064,
        "hf_subset": "nso_Latn-wol_Latn",
        "languages": [
          "nso-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.006853,
        "recall": 0.010516,
        "f1": 0.007274,
        "accuracy": 0.010516,
        "main_score": 0.007274,
        "hf_subset": "nso_Latn-xho_Latn",
        "languages": [
          "nso-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.006567,
        "recall": 0.009014,
        "f1": 0.006849,
        "accuracy": 0.009014,
        "main_score": 0.006849,
        "hf_subset": "nso_Latn-yor_Latn",
        "languages": [
          "nso-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.014431,
        "recall": 0.019529,
        "f1": 0.015279,
        "accuracy": 0.019529,
        "main_score": 0.015279,
        "hf_subset": "nso_Latn-zul_Latn",
        "languages": [
          "nso-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.009964,
        "recall": 0.015523,
        "f1": 0.010772,
        "accuracy": 0.015523,
        "main_score": 0.010772,
        "hf_subset": "nya_Latn-bem_Latn",
        "languages": [
          "nya-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.01018,
        "recall": 0.018528,
        "f1": 0.011211,
        "accuracy": 0.018528,
        "main_score": 0.011211,
        "hf_subset": "nya_Latn-eng_Latn",
        "languages": [
          "nya-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003362,
        "recall": 0.007011,
        "f1": 0.003817,
        "accuracy": 0.007011,
        "main_score": 0.003817,
        "hf_subset": "nya_Latn-ewe_Latn",
        "languages": [
          "nya-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.005404,
        "recall": 0.008012,
        "f1": 0.005616,
        "accuracy": 0.008012,
        "main_score": 0.005616,
        "hf_subset": "nya_Latn-fuc_Latn",
        "languages": [
          "nya-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.007257,
        "recall": 0.011517,
        "f1": 0.008017,
        "accuracy": 0.011517,
        "main_score": 0.008017,
        "hf_subset": "nya_Latn-kin_Latn",
        "languages": [
          "nya-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.002481,
        "recall": 0.007011,
        "f1": 0.002993,
        "accuracy": 0.007011,
        "main_score": 0.002993,
        "hf_subset": "nya_Latn-nde_Latn",
        "languages": [
          "nya-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.012897,
        "recall": 0.021532,
        "f1": 0.014242,
        "accuracy": 0.021532,
        "main_score": 0.014242,
        "hf_subset": "nya_Latn-sna_Latn",
        "languages": [
          "nya-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.008262,
        "recall": 0.011517,
        "f1": 0.008826,
        "accuracy": 0.011517,
        "main_score": 0.008826,
        "hf_subset": "nya_Latn-ven_Latn",
        "languages": [
          "nya-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.001447,
        "recall": 0.005508,
        "f1": 0.001684,
        "accuracy": 0.005508,
        "main_score": 0.001684,
        "hf_subset": "orm_Ethi-amh_Ethi",
        "languages": [
          "orm-Ethi",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.005231,
        "recall": 0.009014,
        "f1": 0.005566,
        "accuracy": 0.009014,
        "main_score": 0.005566,
        "hf_subset": "orm_Ethi-eng_Latn",
        "languages": [
          "orm-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004966,
        "recall": 0.006009,
        "f1": 0.005184,
        "accuracy": 0.006009,
        "main_score": 0.005184,
        "hf_subset": "orm_Ethi-hau_Latn",
        "languages": [
          "orm-Ethi",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.006752,
        "recall": 0.009014,
        "f1": 0.00725,
        "accuracy": 0.009014,
        "main_score": 0.00725,
        "hf_subset": "orm_Ethi-ibo_Latn",
        "languages": [
          "orm-Ethi",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.004791,
        "recall": 0.006009,
        "f1": 0.004904,
        "accuracy": 0.006009,
        "main_score": 0.004904,
        "hf_subset": "orm_Ethi-nso_Latn",
        "languages": [
          "orm-Ethi",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.005314,
        "recall": 0.007011,
        "f1": 0.005615,
        "accuracy": 0.007011,
        "main_score": 0.005615,
        "hf_subset": "orm_Ethi-som_Latn",
        "languages": [
          "orm-Ethi",
          "som-Latn"
        ]
      },
      {
        "precision": 0.003394,
        "recall": 0.004507,
        "f1": 0.003605,
        "accuracy": 0.004507,
        "main_score": 0.003605,
        "hf_subset": "orm_Ethi-ssw_Latn",
        "languages": [
          "orm-Ethi",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.005151,
        "recall": 0.00651,
        "f1": 0.005425,
        "accuracy": 0.00651,
        "main_score": 0.005425,
        "hf_subset": "orm_Ethi-swa_Latn",
        "languages": [
          "orm-Ethi",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001571,
        "recall": 0.003005,
        "f1": 0.00163,
        "accuracy": 0.003005,
        "main_score": 0.00163,
        "hf_subset": "orm_Ethi-tir_Ethi",
        "languages": [
          "orm-Ethi",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.003341,
        "recall": 0.005008,
        "f1": 0.0035,
        "accuracy": 0.005008,
        "main_score": 0.0035,
        "hf_subset": "orm_Ethi-tsn_Latn",
        "languages": [
          "orm-Ethi",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.004847,
        "recall": 0.007011,
        "f1": 0.005217,
        "accuracy": 0.007011,
        "main_score": 0.005217,
        "hf_subset": "orm_Ethi-wol_Latn",
        "languages": [
          "orm-Ethi",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.002929,
        "recall": 0.004507,
        "f1": 0.003103,
        "accuracy": 0.004507,
        "main_score": 0.003103,
        "hf_subset": "orm_Ethi-xho_Latn",
        "languages": [
          "orm-Ethi",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.005976,
        "recall": 0.008513,
        "f1": 0.00643,
        "accuracy": 0.008513,
        "main_score": 0.00643,
        "hf_subset": "orm_Ethi-yor_Latn",
        "languages": [
          "orm-Ethi",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.006968,
        "recall": 0.010015,
        "f1": 0.007223,
        "accuracy": 0.010015,
        "main_score": 0.007223,
        "hf_subset": "orm_Ethi-zul_Latn",
        "languages": [
          "orm-Ethi",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.066392,
        "recall": 0.095643,
        "f1": 0.073201,
        "accuracy": 0.095643,
        "main_score": 0.073201,
        "hf_subset": "pan_Guru-div_Thaa",
        "languages": [
          "pan-Guru",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.031678,
        "recall": 0.042063,
        "f1": 0.034088,
        "accuracy": 0.042063,
        "main_score": 0.034088,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005969,
        "recall": 0.009514,
        "f1": 0.006428,
        "accuracy": 0.009514,
        "main_score": 0.006428,
        "hf_subset": "pan_Guru-eus_Latn",
        "languages": [
          "pan-Guru",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.089754,
        "recall": 0.119179,
        "f1": 0.096936,
        "accuracy": 0.119179,
        "main_score": 0.096936,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000711,
        "recall": 0.002504,
        "f1": 0.000834,
        "accuracy": 0.002504,
        "main_score": 0.000834,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.079559,
        "recall": 0.108162,
        "f1": 0.086585,
        "accuracy": 0.108162,
        "main_score": 0.086585,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000146,
        "recall": 0.002504,
        "f1": 0.000241,
        "accuracy": 0.002504,
        "main_score": 0.000241,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00025,
        "recall": 0.000501,
        "f1": 0.000334,
        "accuracy": 0.000501,
        "main_score": 0.000334,
        "hf_subset": "pan_Guru-nep_Deva",
        "languages": [
          "pan-Guru",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.041782,
        "recall": 0.076114,
        "f1": 0.049344,
        "accuracy": 0.076114,
        "main_score": 0.049344,
        "hf_subset": "pan_Guru-sin_Sinh",
        "languages": [
          "pan-Guru",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.00152,
        "recall": 0.005508,
        "f1": 0.00185,
        "accuracy": 0.005508,
        "main_score": 0.00185,
        "hf_subset": "pan_Guru-snd_Arab",
        "languages": [
          "pan-Guru",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.001554,
        "recall": 0.00651,
        "f1": 0.001916,
        "accuracy": 0.00651,
        "main_score": 0.001916,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.075468,
        "recall": 0.102654,
        "f1": 0.082485,
        "accuracy": 0.102654,
        "main_score": 0.082485,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000351,
        "recall": 0.001502,
        "f1": 0.000509,
        "accuracy": 0.001502,
        "main_score": 0.000509,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 5e-06,
        "accuracy": 0.000501,
        "main_score": 5e-06,
        "hf_subset": "pol_Latn-arb_Arab",
        "languages": [
          "pol-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001177,
        "recall": 0.003505,
        "f1": 0.00171,
        "accuracy": 0.003505,
        "main_score": 0.00171,
        "hf_subset": "pol_Latn-bel_Cyrl",
        "languages": [
          "pol-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.000521,
        "recall": 0.001502,
        "f1": 0.000539,
        "accuracy": 0.001502,
        "main_score": 0.000539,
        "hf_subset": "pol_Latn-ben_Beng",
        "languages": [
          "pol-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.021184,
        "recall": 0.028042,
        "f1": 0.022285,
        "accuracy": 0.028042,
        "main_score": 0.022285,
        "hf_subset": "pol_Latn-bos_Latn",
        "languages": [
          "pol-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.002732,
        "recall": 0.005508,
        "f1": 0.003065,
        "accuracy": 0.005508,
        "main_score": 0.003065,
        "hf_subset": "pol_Latn-bul_Cyrl",
        "languages": [
          "pol-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.021969,
        "recall": 0.030045,
        "f1": 0.0229,
        "accuracy": 0.030045,
        "main_score": 0.0229,
        "hf_subset": "pol_Latn-ces_Latn",
        "languages": [
          "pol-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.007739,
        "recall": 0.014522,
        "f1": 0.008721,
        "accuracy": 0.014522,
        "main_score": 0.008721,
        "hf_subset": "pol_Latn-deu_Latn",
        "languages": [
          "pol-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000272,
        "recall": 0.002003,
        "f1": 0.000456,
        "accuracy": 0.002003,
        "main_score": 0.000456,
        "hf_subset": "pol_Latn-ell_Grek",
        "languages": [
          "pol-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.014184,
        "recall": 0.021032,
        "f1": 0.015099,
        "accuracy": 0.021032,
        "main_score": 0.015099,
        "hf_subset": "pol_Latn-eng_Latn",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000518,
        "recall": 0.002003,
        "f1": 0.000767,
        "accuracy": 0.002003,
        "main_score": 0.000767,
        "hf_subset": "pol_Latn-fas_Arab",
        "languages": [
          "pol-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.006714,
        "recall": 0.011517,
        "f1": 0.007319,
        "accuracy": 0.011517,
        "main_score": 0.007319,
        "hf_subset": "pol_Latn-fin_Latn",
        "languages": [
          "pol-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.010081,
        "recall": 0.015023,
        "f1": 0.010996,
        "accuracy": 0.015023,
        "main_score": 0.010996,
        "hf_subset": "pol_Latn-fra_Latn",
        "languages": [
          "pol-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.001042,
        "recall": 0.002003,
        "f1": 0.001078,
        "accuracy": 0.002003,
        "main_score": 0.001078,
        "hf_subset": "pol_Latn-heb_Hebr",
        "languages": [
          "pol-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.000501,
        "f1": 1.2e-05,
        "accuracy": 0.000501,
        "main_score": 1.2e-05,
        "hf_subset": "pol_Latn-hin_Deva",
        "languages": [
          "pol-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.020158,
        "recall": 0.027541,
        "f1": 0.021592,
        "accuracy": 0.027541,
        "main_score": 0.021592,
        "hf_subset": "pol_Latn-hrv_Latn",
        "languages": [
          "pol-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.007003,
        "recall": 0.012018,
        "f1": 0.00756,
        "accuracy": 0.012018,
        "main_score": 0.00756,
        "hf_subset": "pol_Latn-hun_Latn",
        "languages": [
          "pol-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.00836,
        "recall": 0.012519,
        "f1": 0.008954,
        "accuracy": 0.012519,
        "main_score": 0.008954,
        "hf_subset": "pol_Latn-ind_Latn",
        "languages": [
          "pol-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.00103,
        "recall": 0.003005,
        "f1": 0.001057,
        "accuracy": 0.003005,
        "main_score": 0.001057,
        "hf_subset": "pol_Latn-jpn_Jpan",
        "languages": [
          "pol-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001525,
        "recall": 0.003005,
        "f1": 0.00188,
        "accuracy": 0.003005,
        "main_score": 0.00188,
        "hf_subset": "pol_Latn-kor_Hang",
        "languages": [
          "pol-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.004202,
        "recall": 0.008012,
        "f1": 0.004756,
        "accuracy": 0.008012,
        "main_score": 0.004756,
        "hf_subset": "pol_Latn-lit_Latn",
        "languages": [
          "pol-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.002754,
        "recall": 0.005508,
        "f1": 0.003137,
        "accuracy": 0.005508,
        "main_score": 0.003137,
        "hf_subset": "pol_Latn-mkd_Cyrl",
        "languages": [
          "pol-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.008914,
        "recall": 0.01352,
        "f1": 0.00933,
        "accuracy": 0.01352,
        "main_score": 0.00933,
        "hf_subset": "pol_Latn-nld_Latn",
        "languages": [
          "pol-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.011606,
        "recall": 0.016525,
        "f1": 0.01225,
        "accuracy": 0.016525,
        "main_score": 0.01225,
        "hf_subset": "pol_Latn-por_Latn",
        "languages": [
          "pol-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.001332,
        "recall": 0.003505,
        "f1": 0.001571,
        "accuracy": 0.003505,
        "main_score": 0.001571,
        "hf_subset": "pol_Latn-rus_Cyrl",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.025799,
        "recall": 0.035053,
        "f1": 0.027131,
        "accuracy": 0.035053,
        "main_score": 0.027131,
        "hf_subset": "pol_Latn-slk_Latn",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.01498,
        "recall": 0.022033,
        "f1": 0.015998,
        "accuracy": 0.022033,
        "main_score": 0.015998,
        "hf_subset": "pol_Latn-slv_Latn",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.009398,
        "recall": 0.015023,
        "f1": 0.01024,
        "accuracy": 0.015023,
        "main_score": 0.01024,
        "hf_subset": "pol_Latn-spa_Latn",
        "languages": [
          "pol-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.003109,
        "recall": 0.008012,
        "f1": 0.003459,
        "accuracy": 0.008012,
        "main_score": 0.003459,
        "hf_subset": "pol_Latn-srp_Cyrl",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.011661,
        "recall": 0.017026,
        "f1": 0.012581,
        "accuracy": 0.017026,
        "main_score": 0.012581,
        "hf_subset": "pol_Latn-srp_Latn",
        "languages": [
          "pol-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.005369,
        "recall": 0.009014,
        "f1": 0.005977,
        "accuracy": 0.009014,
        "main_score": 0.005977,
        "hf_subset": "pol_Latn-swa_Latn",
        "languages": [
          "pol-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.010528,
        "recall": 0.014021,
        "f1": 0.011157,
        "accuracy": 0.014021,
        "main_score": 0.011157,
        "hf_subset": "pol_Latn-swe_Latn",
        "languages": [
          "pol-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000524,
        "recall": 0.001502,
        "f1": 0.000546,
        "accuracy": 0.001502,
        "main_score": 0.000546,
        "hf_subset": "pol_Latn-tam_Taml",
        "languages": [
          "pol-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.004214,
        "recall": 0.007511,
        "f1": 0.004546,
        "accuracy": 0.007511,
        "main_score": 0.004546,
        "hf_subset": "pol_Latn-tur_Latn",
        "languages": [
          "pol-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.001746,
        "recall": 0.006009,
        "f1": 0.002134,
        "accuracy": 0.006009,
        "main_score": 0.002134,
        "hf_subset": "pol_Latn-ukr_Cyrl",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.005439,
        "recall": 0.009514,
        "f1": 0.00586,
        "accuracy": 0.009514,
        "main_score": 0.00586,
        "hf_subset": "pol_Latn-vie_Latn",
        "languages": [
          "pol-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.007852,
        "recall": 0.01352,
        "f1": 0.008642,
        "accuracy": 0.01352,
        "main_score": 0.008642,
        "hf_subset": "pol_Latn-zho_Hant",
        "languages": [
          "pol-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.005873,
        "recall": 0.008012,
        "f1": 0.00605,
        "accuracy": 0.008012,
        "main_score": 0.00605,
        "hf_subset": "pol_Latn-zul_Latn",
        "languages": [
          "pol-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 1.3e-05,
        "recall": 0.001002,
        "f1": 2.5e-05,
        "accuracy": 0.001002,
        "main_score": 2.5e-05,
        "hf_subset": "por_Latn-arb_Arab",
        "languages": [
          "por-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000512,
        "recall": 0.001002,
        "f1": 0.000524,
        "accuracy": 0.001002,
        "main_score": 0.000524,
        "hf_subset": "por_Latn-ben_Beng",
        "languages": [
          "por-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.119081,
        "recall": 0.163746,
        "f1": 0.127398,
        "accuracy": 0.163746,
        "main_score": 0.127398,
        "hf_subset": "por_Latn-cat_Latn",
        "languages": [
          "por-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.022413,
        "recall": 0.03355,
        "f1": 0.024118,
        "accuracy": 0.03355,
        "main_score": 0.024118,
        "hf_subset": "por_Latn-deu_Latn",
        "languages": [
          "por-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000252,
        "recall": 0.001002,
        "f1": 0.000338,
        "accuracy": 0.001002,
        "main_score": 0.000338,
        "hf_subset": "por_Latn-ell_Grek",
        "languages": [
          "por-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.034991,
        "recall": 0.051077,
        "f1": 0.037013,
        "accuracy": 0.051077,
        "main_score": 0.037013,
        "hf_subset": "por_Latn-eng_Latn",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000978,
        "recall": 0.004006,
        "f1": 0.001232,
        "accuracy": 0.004006,
        "main_score": 0.001232,
        "hf_subset": "por_Latn-fas_Arab",
        "languages": [
          "por-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.013109,
        "recall": 0.017526,
        "f1": 0.013845,
        "accuracy": 0.017526,
        "main_score": 0.013845,
        "hf_subset": "por_Latn-fin_Latn",
        "languages": [
          "por-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.052807,
        "recall": 0.075113,
        "f1": 0.056399,
        "accuracy": 0.075113,
        "main_score": 0.056399,
        "hf_subset": "por_Latn-fra_Latn",
        "languages": [
          "por-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.332653,
        "recall": 0.418127,
        "f1": 0.353851,
        "accuracy": 0.418127,
        "main_score": 0.353851,
        "hf_subset": "por_Latn-glg_Latn",
        "languages": [
          "por-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.002697,
        "recall": 0.004507,
        "f1": 0.002973,
        "accuracy": 0.004507,
        "main_score": 0.002973,
        "hf_subset": "por_Latn-heb_Hebr",
        "languages": [
          "por-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000515,
        "recall": 0.002003,
        "f1": 0.000529,
        "accuracy": 0.002003,
        "main_score": 0.000529,
        "hf_subset": "por_Latn-hin_Deva",
        "languages": [
          "por-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.01279,
        "recall": 0.018528,
        "f1": 0.01404,
        "accuracy": 0.018528,
        "main_score": 0.01404,
        "hf_subset": "por_Latn-hun_Latn",
        "languages": [
          "por-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.012435,
        "recall": 0.024036,
        "f1": 0.014263,
        "accuracy": 0.024036,
        "main_score": 0.014263,
        "hf_subset": "por_Latn-ind_Latn",
        "languages": [
          "por-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.066362,
        "recall": 0.09364,
        "f1": 0.071568,
        "accuracy": 0.09364,
        "main_score": 0.071568,
        "hf_subset": "por_Latn-ita_Latn",
        "languages": [
          "por-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.001233,
        "recall": 0.003505,
        "f1": 0.001536,
        "accuracy": 0.003505,
        "main_score": 0.001536,
        "hf_subset": "por_Latn-jpn_Jpan",
        "languages": [
          "por-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001408,
        "recall": 0.003505,
        "f1": 0.00168,
        "accuracy": 0.003505,
        "main_score": 0.00168,
        "hf_subset": "por_Latn-kor_Hang",
        "languages": [
          "por-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.01071,
        "recall": 0.018027,
        "f1": 0.011521,
        "accuracy": 0.018027,
        "main_score": 0.011521,
        "hf_subset": "por_Latn-lit_Latn",
        "languages": [
          "por-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.021507,
        "recall": 0.029544,
        "f1": 0.023435,
        "accuracy": 0.029544,
        "main_score": 0.023435,
        "hf_subset": "por_Latn-mlt_Latn",
        "languages": [
          "por-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.021874,
        "recall": 0.031547,
        "f1": 0.023546,
        "accuracy": 0.031547,
        "main_score": 0.023546,
        "hf_subset": "por_Latn-nld_Latn",
        "languages": [
          "por-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.010092,
        "recall": 0.019529,
        "f1": 0.011801,
        "accuracy": 0.019529,
        "main_score": 0.011801,
        "hf_subset": "por_Latn-pol_Latn",
        "languages": [
          "por-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.035189,
        "recall": 0.052579,
        "f1": 0.038104,
        "accuracy": 0.052579,
        "main_score": 0.038104,
        "hf_subset": "por_Latn-ron_Latn",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.001043,
        "recall": 0.002003,
        "f1": 0.001079,
        "accuracy": 0.002003,
        "main_score": 0.001079,
        "hf_subset": "por_Latn-rus_Cyrl",
        "languages": [
          "por-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.192776,
        "recall": 0.243866,
        "f1": 0.203916,
        "accuracy": 0.243866,
        "main_score": 0.203916,
        "hf_subset": "por_Latn-spa_Latn",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.009054,
        "recall": 0.01352,
        "f1": 0.00982,
        "accuracy": 0.01352,
        "main_score": 0.00982,
        "hf_subset": "por_Latn-swa_Latn",
        "languages": [
          "por-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.020671,
        "recall": 0.030045,
        "f1": 0.02211,
        "accuracy": 0.030045,
        "main_score": 0.02211,
        "hf_subset": "por_Latn-swe_Latn",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000532,
        "recall": 0.002003,
        "f1": 0.000561,
        "accuracy": 0.002003,
        "main_score": 0.000561,
        "hf_subset": "por_Latn-tam_Taml",
        "languages": [
          "por-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.009575,
        "recall": 0.01302,
        "f1": 0.010025,
        "accuracy": 0.01302,
        "main_score": 0.010025,
        "hf_subset": "por_Latn-tur_Latn",
        "languages": [
          "por-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.010609,
        "recall": 0.018027,
        "f1": 0.011572,
        "accuracy": 0.018027,
        "main_score": 0.011572,
        "hf_subset": "por_Latn-vie_Latn",
        "languages": [
          "por-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.018356,
        "recall": 0.032549,
        "f1": 0.020278,
        "accuracy": 0.032549,
        "main_score": 0.020278,
        "hf_subset": "por_Latn-zho_Hant",
        "languages": [
          "por-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.00923,
        "recall": 0.01302,
        "f1": 0.009757,
        "accuracy": 0.01302,
        "main_score": 0.009757,
        "hf_subset": "por_Latn-zul_Latn",
        "languages": [
          "por-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000932,
        "recall": 0.004006,
        "f1": 0.001163,
        "accuracy": 0.004006,
        "main_score": 0.001163,
        "hf_subset": "prs_Arab-arb_Arab",
        "languages": [
          "prs-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000807,
        "recall": 0.002003,
        "f1": 0.000938,
        "accuracy": 0.002003,
        "main_score": 0.000938,
        "hf_subset": "prs_Arab-ckb_Arab",
        "languages": [
          "prs-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 8.3e-05,
        "recall": 0.001502,
        "f1": 0.000148,
        "accuracy": 0.001502,
        "main_score": 0.000148,
        "hf_subset": "prs_Arab-eng_Latn",
        "languages": [
          "prs-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.146529,
        "recall": 0.202804,
        "f1": 0.160288,
        "accuracy": 0.202804,
        "main_score": 0.160288,
        "hf_subset": "prs_Arab-fas_Arab",
        "languages": [
          "prs-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000536,
        "recall": 0.001502,
        "f1": 0.000568,
        "accuracy": 0.001502,
        "main_score": 0.000568,
        "hf_subset": "prs_Arab-heb_Hebr",
        "languages": [
          "prs-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "prs_Arab-kmr_Latn",
        "languages": [
          "prs-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.001088,
        "recall": 0.002504,
        "f1": 0.001318,
        "accuracy": 0.002504,
        "main_score": 0.001318,
        "hf_subset": "prs_Arab-mey_Arab",
        "languages": [
          "prs-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.003861,
        "recall": 0.009514,
        "f1": 0.004528,
        "accuracy": 0.009514,
        "main_score": 0.004528,
        "hf_subset": "prs_Arab-pus_Arab",
        "languages": [
          "prs-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.000997,
        "recall": 0.003005,
        "f1": 0.001249,
        "accuracy": 0.003005,
        "main_score": 0.001249,
        "hf_subset": "prs_Arab-shi_Arab",
        "languages": [
          "prs-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.002394,
        "recall": 0.004507,
        "f1": 0.002588,
        "accuracy": 0.004507,
        "main_score": 0.002588,
        "hf_subset": "prs_Arab-tgk_Cyrl",
        "languages": [
          "prs-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 8.6e-05,
        "recall": 0.002504,
        "f1": 0.000164,
        "accuracy": 0.002504,
        "main_score": 0.000164,
        "hf_subset": "pus_Arab-arb_Arab",
        "languages": [
          "pus-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000167,
        "recall": 0.000501,
        "f1": 0.00025,
        "accuracy": 0.000501,
        "main_score": 0.00025,
        "hf_subset": "pus_Arab-ckb_Arab",
        "languages": [
          "pus-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "pus_Arab-eng_Latn",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005646,
        "recall": 0.010015,
        "f1": 0.006299,
        "accuracy": 0.010015,
        "main_score": 0.006299,
        "hf_subset": "pus_Arab-fas_Arab",
        "languages": [
          "pus-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.000501,
        "f1": 6e-06,
        "accuracy": 0.000501,
        "main_score": 6e-06,
        "hf_subset": "pus_Arab-heb_Hebr",
        "languages": [
          "pus-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 1.3e-05,
        "recall": 0.000501,
        "f1": 2.4e-05,
        "accuracy": 0.000501,
        "main_score": 2.4e-05,
        "hf_subset": "pus_Arab-kmr_Latn",
        "languages": [
          "pus-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.001029,
        "recall": 0.002504,
        "f1": 0.001055,
        "accuracy": 0.002504,
        "main_score": 0.001055,
        "hf_subset": "pus_Arab-mey_Arab",
        "languages": [
          "pus-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.004936,
        "recall": 0.012519,
        "f1": 0.006056,
        "accuracy": 0.012519,
        "main_score": 0.006056,
        "hf_subset": "pus_Arab-prs_Arab",
        "languages": [
          "pus-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000685,
        "recall": 0.001502,
        "f1": 0.000785,
        "accuracy": 0.001502,
        "main_score": 0.000785,
        "hf_subset": "pus_Arab-shi_Arab",
        "languages": [
          "pus-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "pus_Arab-tgk_Cyrl",
        "languages": [
          "pus-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.033828,
        "recall": 0.045068,
        "f1": 0.035402,
        "accuracy": 0.045068,
        "main_score": 0.035402,
        "hf_subset": "ron_Latn-cat_Latn",
        "languages": [
          "ron-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.026089,
        "recall": 0.038057,
        "f1": 0.027729,
        "accuracy": 0.038057,
        "main_score": 0.027729,
        "hf_subset": "ron_Latn-eng_Latn",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.023398,
        "recall": 0.03355,
        "f1": 0.025247,
        "accuracy": 0.03355,
        "main_score": 0.025247,
        "hf_subset": "ron_Latn-fra_Latn",
        "languages": [
          "ron-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.034143,
        "recall": 0.04657,
        "f1": 0.036327,
        "accuracy": 0.04657,
        "main_score": 0.036327,
        "hf_subset": "ron_Latn-glg_Latn",
        "languages": [
          "ron-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.038305,
        "recall": 0.050075,
        "f1": 0.040234,
        "accuracy": 0.050075,
        "main_score": 0.040234,
        "hf_subset": "ron_Latn-ita_Latn",
        "languages": [
          "ron-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.019241,
        "recall": 0.029544,
        "f1": 0.020887,
        "accuracy": 0.029544,
        "main_score": 0.020887,
        "hf_subset": "ron_Latn-mlt_Latn",
        "languages": [
          "ron-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.032613,
        "recall": 0.043565,
        "f1": 0.034346,
        "accuracy": 0.043565,
        "main_score": 0.034346,
        "hf_subset": "ron_Latn-por_Latn",
        "languages": [
          "ron-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.035095,
        "recall": 0.046069,
        "f1": 0.036886,
        "accuracy": 0.046069,
        "main_score": 0.036886,
        "hf_subset": "ron_Latn-spa_Latn",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.000501,
        "f1": 1.8e-05,
        "accuracy": 0.000501,
        "main_score": 1.8e-05,
        "hf_subset": "rus_Cyrl-arb_Arab",
        "languages": [
          "rus-Cyrl",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.015542,
        "recall": 0.031047,
        "f1": 0.01766,
        "accuracy": 0.031047,
        "main_score": 0.01766,
        "hf_subset": "rus_Cyrl-bel_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.002003,
        "f1": 3.5e-05,
        "accuracy": 0.002003,
        "main_score": 3.5e-05,
        "hf_subset": "rus_Cyrl-ben_Beng",
        "languages": [
          "rus-Cyrl",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000509,
        "recall": 0.002003,
        "f1": 0.000517,
        "accuracy": 0.002003,
        "main_score": 0.000517,
        "hf_subset": "rus_Cyrl-bos_Latn",
        "languages": [
          "rus-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.020982,
        "recall": 0.037556,
        "f1": 0.023777,
        "accuracy": 0.037556,
        "main_score": 0.023777,
        "hf_subset": "rus_Cyrl-bul_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "rus_Cyrl-ces_Latn",
        "languages": [
          "rus-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.001006,
        "recall": 0.002003,
        "f1": 0.001011,
        "accuracy": 0.002003,
        "main_score": 0.001011,
        "hf_subset": "rus_Cyrl-deu_Latn",
        "languages": [
          "rus-Cyrl",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "rus_Cyrl-ell_Grek",
        "languages": [
          "rus-Cyrl",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "rus_Cyrl-fas_Arab",
        "languages": [
          "rus-Cyrl",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "rus_Cyrl-fin_Latn",
        "languages": [
          "rus-Cyrl",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.000531,
        "recall": 0.001502,
        "f1": 0.000558,
        "accuracy": 0.001502,
        "main_score": 0.000558,
        "hf_subset": "rus_Cyrl-fra_Latn",
        "languages": [
          "rus-Cyrl",
          "fra-Latn"
        ]
      },
      {
        "precision": 6.3e-05,
        "recall": 0.001002,
        "f1": 0.000112,
        "accuracy": 0.001002,
        "main_score": 0.000112,
        "hf_subset": "rus_Cyrl-heb_Hebr",
        "languages": [
          "rus-Cyrl",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000584,
        "recall": 0.002003,
        "f1": 0.000652,
        "accuracy": 0.002003,
        "main_score": 0.000652,
        "hf_subset": "rus_Cyrl-hin_Deva",
        "languages": [
          "rus-Cyrl",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "rus_Cyrl-hrv_Latn",
        "languages": [
          "rus-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "rus_Cyrl-hun_Latn",
        "languages": [
          "rus-Cyrl",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "rus_Cyrl-ind_Latn",
        "languages": [
          "rus-Cyrl",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001002,
        "f1": 0.000505,
        "accuracy": 0.001002,
        "main_score": 0.000505,
        "hf_subset": "rus_Cyrl-jpn_Jpan",
        "languages": [
          "rus-Cyrl",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000515,
        "recall": 0.002003,
        "f1": 0.000528,
        "accuracy": 0.002003,
        "main_score": 0.000528,
        "hf_subset": "rus_Cyrl-kor_Hang",
        "languages": [
          "rus-Cyrl",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "rus_Cyrl-lit_Latn",
        "languages": [
          "rus-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.017654,
        "recall": 0.03305,
        "f1": 0.020089,
        "accuracy": 0.03305,
        "main_score": 0.020089,
        "hf_subset": "rus_Cyrl-mkd_Cyrl",
        "languages": [
          "rus-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000503,
        "accuracy": 0.001502,
        "main_score": 0.000503,
        "hf_subset": "rus_Cyrl-nld_Latn",
        "languages": [
          "rus-Cyrl",
          "nld-Latn"
        ]
      },
      {
        "precision": 3.8e-05,
        "recall": 0.001502,
        "f1": 7.3e-05,
        "accuracy": 0.001502,
        "main_score": 7.3e-05,
        "hf_subset": "rus_Cyrl-pol_Latn",
        "languages": [
          "rus-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000503,
        "accuracy": 0.001002,
        "main_score": 0.000503,
        "hf_subset": "rus_Cyrl-por_Latn",
        "languages": [
          "rus-Cyrl",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "rus_Cyrl-slk_Latn",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "rus_Cyrl-slv_Latn",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000506,
        "accuracy": 0.001502,
        "main_score": 0.000506,
        "hf_subset": "rus_Cyrl-spa_Latn",
        "languages": [
          "rus-Cyrl",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.00915,
        "recall": 0.019029,
        "f1": 0.010496,
        "accuracy": 0.019029,
        "main_score": 0.010496,
        "hf_subset": "rus_Cyrl-srp_Cyrl",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.000509,
        "recall": 0.002504,
        "f1": 0.000518,
        "accuracy": 0.002504,
        "main_score": 0.000518,
        "hf_subset": "rus_Cyrl-srp_Latn",
        "languages": [
          "rus-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.00051,
        "recall": 0.001502,
        "f1": 0.00052,
        "accuracy": 0.001502,
        "main_score": 0.00052,
        "hf_subset": "rus_Cyrl-swa_Latn",
        "languages": [
          "rus-Cyrl",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "rus_Cyrl-swe_Latn",
        "languages": [
          "rus-Cyrl",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "rus_Cyrl-tam_Taml",
        "languages": [
          "rus-Cyrl",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "rus_Cyrl-tur_Latn",
        "languages": [
          "rus-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.016311,
        "recall": 0.029544,
        "f1": 0.018381,
        "accuracy": 0.029544,
        "main_score": 0.018381,
        "hf_subset": "rus_Cyrl-ukr_Cyrl",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "rus_Cyrl-vie_Latn",
        "languages": [
          "rus-Cyrl",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "rus_Cyrl-zho_Hant",
        "languages": [
          "rus-Cyrl",
          "zho-Hant"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "rus_Cyrl-zul_Latn",
        "languages": [
          "rus-Cyrl",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.012452,
        "recall": 0.025038,
        "f1": 0.014187,
        "accuracy": 0.025038,
        "main_score": 0.014187,
        "hf_subset": "shi_Arab-arb_Arab",
        "languages": [
          "shi-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "shi_Arab-ckb_Arab",
        "languages": [
          "shi-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "shi_Arab-eng_Latn",
        "languages": [
          "shi-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000554,
        "recall": 0.003005,
        "f1": 0.000604,
        "accuracy": 0.003005,
        "main_score": 0.000604,
        "hf_subset": "shi_Arab-fas_Arab",
        "languages": [
          "shi-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "shi_Arab-heb_Hebr",
        "languages": [
          "shi-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "shi_Arab-kmr_Latn",
        "languages": [
          "shi-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.016234,
        "recall": 0.029044,
        "f1": 0.018464,
        "accuracy": 0.029044,
        "main_score": 0.018464,
        "hf_subset": "shi_Arab-mey_Arab",
        "languages": [
          "shi-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.000563,
        "recall": 0.001002,
        "f1": 0.000612,
        "accuracy": 0.001002,
        "main_score": 0.000612,
        "hf_subset": "shi_Arab-prs_Arab",
        "languages": [
          "shi-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.000124,
        "recall": 0.002504,
        "f1": 0.000225,
        "accuracy": 0.002504,
        "main_score": 0.000225,
        "hf_subset": "shi_Arab-pus_Arab",
        "languages": [
          "shi-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 2.4e-05,
        "recall": 0.001502,
        "f1": 4.7e-05,
        "accuracy": 0.001502,
        "main_score": 4.7e-05,
        "hf_subset": "shi_Arab-tgk_Cyrl",
        "languages": [
          "shi-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 4e-06,
        "accuracy": 0.000501,
        "main_score": 4e-06,
        "hf_subset": "sin_Sinh-ben_Beng",
        "languages": [
          "sin-Sinh",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.063191,
        "recall": 0.085128,
        "f1": 0.068517,
        "accuracy": 0.085128,
        "main_score": 0.068517,
        "hf_subset": "sin_Sinh-div_Thaa",
        "languages": [
          "sin-Sinh",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.017634,
        "recall": 0.02654,
        "f1": 0.019432,
        "accuracy": 0.02654,
        "main_score": 0.019432,
        "hf_subset": "sin_Sinh-eng_Latn",
        "languages": [
          "sin-Sinh",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002907,
        "recall": 0.006009,
        "f1": 0.003342,
        "accuracy": 0.006009,
        "main_score": 0.003342,
        "hf_subset": "sin_Sinh-eus_Latn",
        "languages": [
          "sin-Sinh",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.074322,
        "recall": 0.091137,
        "f1": 0.078348,
        "accuracy": 0.091137,
        "main_score": 0.078348,
        "hf_subset": "sin_Sinh-guj_Gujr",
        "languages": [
          "sin-Sinh",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000832,
        "recall": 0.004006,
        "f1": 0.001051,
        "accuracy": 0.004006,
        "main_score": 0.001051,
        "hf_subset": "sin_Sinh-hin_Deva",
        "languages": [
          "sin-Sinh",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.074807,
        "recall": 0.09364,
        "f1": 0.079308,
        "accuracy": 0.09364,
        "main_score": 0.079308,
        "hf_subset": "sin_Sinh-kan_Knda",
        "languages": [
          "sin-Sinh",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000854,
        "recall": 0.002504,
        "f1": 0.001015,
        "accuracy": 0.002504,
        "main_score": 0.001015,
        "hf_subset": "sin_Sinh-mar_Deva",
        "languages": [
          "sin-Sinh",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000677,
        "recall": 0.002003,
        "f1": 0.000795,
        "accuracy": 0.002003,
        "main_score": 0.000795,
        "hf_subset": "sin_Sinh-nep_Deva",
        "languages": [
          "sin-Sinh",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.05572,
        "recall": 0.075113,
        "f1": 0.060044,
        "accuracy": 0.075113,
        "main_score": 0.060044,
        "hf_subset": "sin_Sinh-pan_Guru",
        "languages": [
          "sin-Sinh",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001785,
        "recall": 0.00651,
        "f1": 0.002249,
        "accuracy": 0.00651,
        "main_score": 0.002249,
        "hf_subset": "sin_Sinh-snd_Arab",
        "languages": [
          "sin-Sinh",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.003468,
        "recall": 0.009014,
        "f1": 0.003982,
        "accuracy": 0.009014,
        "main_score": 0.003982,
        "hf_subset": "sin_Sinh-tam_Taml",
        "languages": [
          "sin-Sinh",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.073433,
        "recall": 0.094642,
        "f1": 0.078821,
        "accuracy": 0.094642,
        "main_score": 0.078821,
        "hf_subset": "sin_Sinh-tel_Telu",
        "languages": [
          "sin-Sinh",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000182,
        "recall": 0.001502,
        "f1": 0.000279,
        "accuracy": 0.001502,
        "main_score": 0.000279,
        "hf_subset": "sin_Sinh-urd_Arab",
        "languages": [
          "sin-Sinh",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001551,
        "recall": 0.005508,
        "f1": 0.002104,
        "accuracy": 0.005508,
        "main_score": 0.002104,
        "hf_subset": "slk_Latn-bel_Cyrl",
        "languages": [
          "slk-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.053304,
        "recall": 0.074111,
        "f1": 0.057321,
        "accuracy": 0.074111,
        "main_score": 0.057321,
        "hf_subset": "slk_Latn-bos_Latn",
        "languages": [
          "slk-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.003962,
        "recall": 0.009014,
        "f1": 0.004963,
        "accuracy": 0.009014,
        "main_score": 0.004963,
        "hf_subset": "slk_Latn-bul_Cyrl",
        "languages": [
          "slk-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.355489,
        "recall": 0.44667,
        "f1": 0.378743,
        "accuracy": 0.44667,
        "main_score": 0.378743,
        "hf_subset": "slk_Latn-ces_Latn",
        "languages": [
          "slk-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.018549,
        "recall": 0.029544,
        "f1": 0.019993,
        "accuracy": 0.029544,
        "main_score": 0.019993,
        "hf_subset": "slk_Latn-eng_Latn",
        "languages": [
          "slk-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.050303,
        "recall": 0.070105,
        "f1": 0.053938,
        "accuracy": 0.070105,
        "main_score": 0.053938,
        "hf_subset": "slk_Latn-hrv_Latn",
        "languages": [
          "slk-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.002146,
        "recall": 0.008012,
        "f1": 0.002918,
        "accuracy": 0.008012,
        "main_score": 0.002918,
        "hf_subset": "slk_Latn-mkd_Cyrl",
        "languages": [
          "slk-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.046968,
        "recall": 0.067101,
        "f1": 0.051107,
        "accuracy": 0.067101,
        "main_score": 0.051107,
        "hf_subset": "slk_Latn-pol_Latn",
        "languages": [
          "slk-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001937,
        "recall": 0.005008,
        "f1": 0.002178,
        "accuracy": 0.005008,
        "main_score": 0.002178,
        "hf_subset": "slk_Latn-rus_Cyrl",
        "languages": [
          "slk-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.049747,
        "recall": 0.070105,
        "f1": 0.053735,
        "accuracy": 0.070105,
        "main_score": 0.053735,
        "hf_subset": "slk_Latn-slv_Latn",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.004391,
        "recall": 0.009514,
        "f1": 0.005077,
        "accuracy": 0.009514,
        "main_score": 0.005077,
        "hf_subset": "slk_Latn-srp_Cyrl",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.032106,
        "recall": 0.04657,
        "f1": 0.034997,
        "accuracy": 0.04657,
        "main_score": 0.034997,
        "hf_subset": "slk_Latn-srp_Latn",
        "languages": [
          "slk-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.00248,
        "recall": 0.00651,
        "f1": 0.003016,
        "accuracy": 0.00651,
        "main_score": 0.003016,
        "hf_subset": "slk_Latn-ukr_Cyrl",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.001678,
        "recall": 0.004006,
        "f1": 0.002037,
        "accuracy": 0.004006,
        "main_score": 0.002037,
        "hf_subset": "slv_Latn-bel_Cyrl",
        "languages": [
          "slv-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.118742,
        "recall": 0.167251,
        "f1": 0.129901,
        "accuracy": 0.167251,
        "main_score": 0.129901,
        "hf_subset": "slv_Latn-bos_Latn",
        "languages": [
          "slv-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.001939,
        "recall": 0.006009,
        "f1": 0.002612,
        "accuracy": 0.006009,
        "main_score": 0.002612,
        "hf_subset": "slv_Latn-bul_Cyrl",
        "languages": [
          "slv-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.037354,
        "recall": 0.05308,
        "f1": 0.040182,
        "accuracy": 0.05308,
        "main_score": 0.040182,
        "hf_subset": "slv_Latn-ces_Latn",
        "languages": [
          "slv-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.011943,
        "recall": 0.02003,
        "f1": 0.013111,
        "accuracy": 0.02003,
        "main_score": 0.013111,
        "hf_subset": "slv_Latn-eng_Latn",
        "languages": [
          "slv-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.127512,
        "recall": 0.175764,
        "f1": 0.138817,
        "accuracy": 0.175764,
        "main_score": 0.138817,
        "hf_subset": "slv_Latn-hrv_Latn",
        "languages": [
          "slv-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.00333,
        "recall": 0.009514,
        "f1": 0.003982,
        "accuracy": 0.009514,
        "main_score": 0.003982,
        "hf_subset": "slv_Latn-mkd_Cyrl",
        "languages": [
          "slv-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.015236,
        "recall": 0.024537,
        "f1": 0.016665,
        "accuracy": 0.024537,
        "main_score": 0.016665,
        "hf_subset": "slv_Latn-pol_Latn",
        "languages": [
          "slv-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.002034,
        "recall": 0.00651,
        "f1": 0.002511,
        "accuracy": 0.00651,
        "main_score": 0.002511,
        "hf_subset": "slv_Latn-rus_Cyrl",
        "languages": [
          "slv-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.039775,
        "recall": 0.059589,
        "f1": 0.043265,
        "accuracy": 0.059589,
        "main_score": 0.043265,
        "hf_subset": "slv_Latn-slk_Latn",
        "languages": [
          "slv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.003231,
        "recall": 0.009014,
        "f1": 0.003643,
        "accuracy": 0.009014,
        "main_score": 0.003643,
        "hf_subset": "slv_Latn-srp_Cyrl",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.076078,
        "recall": 0.108663,
        "f1": 0.083514,
        "accuracy": 0.108663,
        "main_score": 0.083514,
        "hf_subset": "slv_Latn-srp_Latn",
        "languages": [
          "slv-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.000809,
        "recall": 0.002504,
        "f1": 0.001109,
        "accuracy": 0.002504,
        "main_score": 0.001109,
        "hf_subset": "slv_Latn-ukr_Cyrl",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.018817,
        "recall": 0.023035,
        "f1": 0.019424,
        "accuracy": 0.023035,
        "main_score": 0.019424,
        "hf_subset": "smo_Latn-eng_Latn",
        "languages": [
          "smo-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005839,
        "recall": 0.009014,
        "f1": 0.006087,
        "accuracy": 0.009014,
        "main_score": 0.006087,
        "hf_subset": "smo_Latn-fij_Latn",
        "languages": [
          "smo-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.008474,
        "recall": 0.012519,
        "f1": 0.00925,
        "accuracy": 0.012519,
        "main_score": 0.00925,
        "hf_subset": "smo_Latn-fil_Latn",
        "languages": [
          "smo-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.011026,
        "recall": 0.015023,
        "f1": 0.011631,
        "accuracy": 0.015023,
        "main_score": 0.011631,
        "hf_subset": "smo_Latn-ind_Latn",
        "languages": [
          "smo-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000602,
        "recall": 0.002003,
        "f1": 0.000684,
        "accuracy": 0.002003,
        "main_score": 0.000684,
        "hf_subset": "smo_Latn-mal_Mlym",
        "languages": [
          "smo-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.00475,
        "recall": 0.007511,
        "f1": 0.005084,
        "accuracy": 0.007511,
        "main_score": 0.005084,
        "hf_subset": "smo_Latn-mlg_Latn",
        "languages": [
          "smo-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.013043,
        "recall": 0.019029,
        "f1": 0.01409,
        "accuracy": 0.019029,
        "main_score": 0.01409,
        "hf_subset": "smo_Latn-mri_Latn",
        "languages": [
          "smo-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.007213,
        "recall": 0.010015,
        "f1": 0.007715,
        "accuracy": 0.010015,
        "main_score": 0.007715,
        "hf_subset": "smo_Latn-msa_Latn",
        "languages": [
          "smo-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.011148,
        "recall": 0.016525,
        "f1": 0.01207,
        "accuracy": 0.016525,
        "main_score": 0.01207,
        "hf_subset": "smo_Latn-tah_Latn",
        "languages": [
          "smo-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.011234,
        "recall": 0.022033,
        "f1": 0.012636,
        "accuracy": 0.022033,
        "main_score": 0.012636,
        "hf_subset": "smo_Latn-ton_Latn",
        "languages": [
          "smo-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.00825,
        "recall": 0.01352,
        "f1": 0.009156,
        "accuracy": 0.01352,
        "main_score": 0.009156,
        "hf_subset": "sna_Latn-bem_Latn",
        "languages": [
          "sna-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.008203,
        "recall": 0.012018,
        "f1": 0.008693,
        "accuracy": 0.012018,
        "main_score": 0.008693,
        "hf_subset": "sna_Latn-eng_Latn",
        "languages": [
          "sna-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005296,
        "recall": 0.00651,
        "f1": 0.005414,
        "accuracy": 0.00651,
        "main_score": 0.005414,
        "hf_subset": "sna_Latn-ewe_Latn",
        "languages": [
          "sna-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.004588,
        "recall": 0.006009,
        "f1": 0.004656,
        "accuracy": 0.006009,
        "main_score": 0.004656,
        "hf_subset": "sna_Latn-fuc_Latn",
        "languages": [
          "sna-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.004848,
        "recall": 0.007511,
        "f1": 0.005382,
        "accuracy": 0.007511,
        "main_score": 0.005382,
        "hf_subset": "sna_Latn-kin_Latn",
        "languages": [
          "sna-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.007009,
        "recall": 0.012018,
        "f1": 0.007545,
        "accuracy": 0.012018,
        "main_score": 0.007545,
        "hf_subset": "sna_Latn-nde_Latn",
        "languages": [
          "sna-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.010013,
        "recall": 0.014522,
        "f1": 0.010572,
        "accuracy": 0.014522,
        "main_score": 0.010572,
        "hf_subset": "sna_Latn-nya_Latn",
        "languages": [
          "sna-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.007611,
        "recall": 0.012018,
        "f1": 0.008303,
        "accuracy": 0.012018,
        "main_score": 0.008303,
        "hf_subset": "sna_Latn-ven_Latn",
        "languages": [
          "sna-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 4.1e-05,
        "recall": 0.001502,
        "f1": 7.6e-05,
        "accuracy": 0.001502,
        "main_score": 7.6e-05,
        "hf_subset": "snd_Arab-ben_Beng",
        "languages": [
          "snd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "snd_Arab-div_Thaa",
        "languages": [
          "snd-Arab",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "snd_Arab-eng_Latn",
        "languages": [
          "snd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "snd_Arab-eus_Latn",
        "languages": [
          "snd-Arab",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "snd_Arab-guj_Gujr",
        "languages": [
          "snd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.00095,
        "recall": 0.005008,
        "f1": 0.00122,
        "accuracy": 0.005008,
        "main_score": 0.00122,
        "hf_subset": "snd_Arab-hin_Deva",
        "languages": [
          "snd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "snd_Arab-kan_Knda",
        "languages": [
          "snd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 5e-05,
        "recall": 0.001002,
        "f1": 9.3e-05,
        "accuracy": 0.001002,
        "main_score": 9.3e-05,
        "hf_subset": "snd_Arab-mar_Deva",
        "languages": [
          "snd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.3e-05,
        "recall": 0.001502,
        "f1": 2.7e-05,
        "accuracy": 0.001502,
        "main_score": 2.7e-05,
        "hf_subset": "snd_Arab-nep_Deva",
        "languages": [
          "snd-Arab",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "snd_Arab-pan_Guru",
        "languages": [
          "snd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "snd_Arab-sin_Sinh",
        "languages": [
          "snd-Arab",
          "sin-Sinh"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.000501,
        "f1": 1.9e-05,
        "accuracy": 0.000501,
        "main_score": 1.9e-05,
        "hf_subset": "snd_Arab-tam_Taml",
        "languages": [
          "snd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "snd_Arab-tel_Telu",
        "languages": [
          "snd-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.00393,
        "recall": 0.010015,
        "f1": 0.004665,
        "accuracy": 0.010015,
        "main_score": 0.004665,
        "hf_subset": "snd_Arab-urd_Arab",
        "languages": [
          "snd-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.004534,
        "recall": 0.007511,
        "f1": 0.004827,
        "accuracy": 0.007511,
        "main_score": 0.004827,
        "hf_subset": "som_Latn-amh_Ethi",
        "languages": [
          "som-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.010962,
        "recall": 0.017526,
        "f1": 0.01166,
        "accuracy": 0.017526,
        "main_score": 0.01166,
        "hf_subset": "som_Latn-eng_Latn",
        "languages": [
          "som-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009216,
        "recall": 0.011017,
        "f1": 0.009557,
        "accuracy": 0.011017,
        "main_score": 0.009557,
        "hf_subset": "som_Latn-hau_Latn",
        "languages": [
          "som-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.00921,
        "recall": 0.012018,
        "f1": 0.009684,
        "accuracy": 0.012018,
        "main_score": 0.009684,
        "hf_subset": "som_Latn-ibo_Latn",
        "languages": [
          "som-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.008495,
        "recall": 0.01302,
        "f1": 0.009009,
        "accuracy": 0.01302,
        "main_score": 0.009009,
        "hf_subset": "som_Latn-nso_Latn",
        "languages": [
          "som-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.004107,
        "recall": 0.005508,
        "f1": 0.004356,
        "accuracy": 0.005508,
        "main_score": 0.004356,
        "hf_subset": "som_Latn-orm_Ethi",
        "languages": [
          "som-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.007424,
        "recall": 0.012018,
        "f1": 0.007893,
        "accuracy": 0.012018,
        "main_score": 0.007893,
        "hf_subset": "som_Latn-ssw_Latn",
        "languages": [
          "som-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.008736,
        "recall": 0.011517,
        "f1": 0.009371,
        "accuracy": 0.011517,
        "main_score": 0.009371,
        "hf_subset": "som_Latn-swa_Latn",
        "languages": [
          "som-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.002382,
        "recall": 0.005008,
        "f1": 0.002787,
        "accuracy": 0.005008,
        "main_score": 0.002787,
        "hf_subset": "som_Latn-tir_Ethi",
        "languages": [
          "som-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.004489,
        "recall": 0.008012,
        "f1": 0.004946,
        "accuracy": 0.008012,
        "main_score": 0.004946,
        "hf_subset": "som_Latn-tsn_Latn",
        "languages": [
          "som-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.00693,
        "recall": 0.008513,
        "f1": 0.007128,
        "accuracy": 0.008513,
        "main_score": 0.007128,
        "hf_subset": "som_Latn-wol_Latn",
        "languages": [
          "som-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.006054,
        "recall": 0.008513,
        "f1": 0.006325,
        "accuracy": 0.008513,
        "main_score": 0.006325,
        "hf_subset": "som_Latn-xho_Latn",
        "languages": [
          "som-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.003758,
        "recall": 0.006009,
        "f1": 0.004142,
        "accuracy": 0.006009,
        "main_score": 0.004142,
        "hf_subset": "som_Latn-yor_Latn",
        "languages": [
          "som-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.005941,
        "recall": 0.009514,
        "f1": 0.006583,
        "accuracy": 0.009514,
        "main_score": 0.006583,
        "hf_subset": "som_Latn-zul_Latn",
        "languages": [
          "som-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "spa_Latn-arb_Arab",
        "languages": [
          "spa-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000668,
        "recall": 0.001002,
        "f1": 0.000751,
        "accuracy": 0.001002,
        "main_score": 0.000751,
        "hf_subset": "spa_Latn-ben_Beng",
        "languages": [
          "spa-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.194462,
        "recall": 0.254882,
        "f1": 0.206788,
        "accuracy": 0.254882,
        "main_score": 0.206788,
        "hf_subset": "spa_Latn-cat_Latn",
        "languages": [
          "spa-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.023901,
        "recall": 0.035053,
        "f1": 0.025788,
        "accuracy": 0.035053,
        "main_score": 0.025788,
        "hf_subset": "spa_Latn-deu_Latn",
        "languages": [
          "spa-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "spa_Latn-ell_Grek",
        "languages": [
          "spa-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.034894,
        "recall": 0.054081,
        "f1": 0.037631,
        "accuracy": 0.054081,
        "main_score": 0.037631,
        "hf_subset": "spa_Latn-eng_Latn",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001037,
        "recall": 0.006009,
        "f1": 0.001313,
        "accuracy": 0.006009,
        "main_score": 0.001313,
        "hf_subset": "spa_Latn-fas_Arab",
        "languages": [
          "spa-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.009312,
        "recall": 0.015023,
        "f1": 0.010504,
        "accuracy": 0.015023,
        "main_score": 0.010504,
        "hf_subset": "spa_Latn-fin_Latn",
        "languages": [
          "spa-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.066793,
        "recall": 0.096144,
        "f1": 0.072091,
        "accuracy": 0.096144,
        "main_score": 0.072091,
        "hf_subset": "spa_Latn-fra_Latn",
        "languages": [
          "spa-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.395924,
        "recall": 0.490235,
        "f1": 0.419501,
        "accuracy": 0.490235,
        "main_score": 0.419501,
        "hf_subset": "spa_Latn-glg_Latn",
        "languages": [
          "spa-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.000943,
        "recall": 0.002504,
        "f1": 0.001134,
        "accuracy": 0.002504,
        "main_score": 0.001134,
        "hf_subset": "spa_Latn-heb_Hebr",
        "languages": [
          "spa-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000506,
        "recall": 0.001502,
        "f1": 0.000512,
        "accuracy": 0.001502,
        "main_score": 0.000512,
        "hf_subset": "spa_Latn-hin_Deva",
        "languages": [
          "spa-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016248,
        "recall": 0.024036,
        "f1": 0.017401,
        "accuracy": 0.024036,
        "main_score": 0.017401,
        "hf_subset": "spa_Latn-hun_Latn",
        "languages": [
          "spa-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.0159,
        "recall": 0.026039,
        "f1": 0.01779,
        "accuracy": 0.026039,
        "main_score": 0.01779,
        "hf_subset": "spa_Latn-ind_Latn",
        "languages": [
          "spa-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.079548,
        "recall": 0.109664,
        "f1": 0.085544,
        "accuracy": 0.109664,
        "main_score": 0.085544,
        "hf_subset": "spa_Latn-ita_Latn",
        "languages": [
          "spa-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.001743,
        "recall": 0.004006,
        "f1": 0.001889,
        "accuracy": 0.004006,
        "main_score": 0.001889,
        "hf_subset": "spa_Latn-jpn_Jpan",
        "languages": [
          "spa-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000474,
        "recall": 0.003505,
        "f1": 0.000766,
        "accuracy": 0.003505,
        "main_score": 0.000766,
        "hf_subset": "spa_Latn-kor_Hang",
        "languages": [
          "spa-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.005802,
        "recall": 0.012519,
        "f1": 0.006836,
        "accuracy": 0.012519,
        "main_score": 0.006836,
        "hf_subset": "spa_Latn-lit_Latn",
        "languages": [
          "spa-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.019705,
        "recall": 0.031547,
        "f1": 0.021466,
        "accuracy": 0.031547,
        "main_score": 0.021466,
        "hf_subset": "spa_Latn-mlt_Latn",
        "languages": [
          "spa-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.023482,
        "recall": 0.035553,
        "f1": 0.025429,
        "accuracy": 0.035553,
        "main_score": 0.025429,
        "hf_subset": "spa_Latn-nld_Latn",
        "languages": [
          "spa-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.015121,
        "recall": 0.023035,
        "f1": 0.016583,
        "accuracy": 0.023035,
        "main_score": 0.016583,
        "hf_subset": "spa_Latn-pol_Latn",
        "languages": [
          "spa-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.201426,
        "recall": 0.272909,
        "f1": 0.218008,
        "accuracy": 0.272909,
        "main_score": 0.218008,
        "hf_subset": "spa_Latn-por_Latn",
        "languages": [
          "spa-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.03911,
        "recall": 0.056084,
        "f1": 0.041947,
        "accuracy": 0.056084,
        "main_score": 0.041947,
        "hf_subset": "spa_Latn-ron_Latn",
        "languages": [
          "spa-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.00058,
        "recall": 0.003005,
        "f1": 0.000885,
        "accuracy": 0.003005,
        "main_score": 0.000885,
        "hf_subset": "spa_Latn-rus_Cyrl",
        "languages": [
          "spa-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.008677,
        "recall": 0.014522,
        "f1": 0.009798,
        "accuracy": 0.014522,
        "main_score": 0.009798,
        "hf_subset": "spa_Latn-swa_Latn",
        "languages": [
          "spa-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.024235,
        "recall": 0.034051,
        "f1": 0.025585,
        "accuracy": 0.034051,
        "main_score": 0.025585,
        "hf_subset": "spa_Latn-swe_Latn",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000674,
        "recall": 0.002003,
        "f1": 0.000796,
        "accuracy": 0.002003,
        "main_score": 0.000796,
        "hf_subset": "spa_Latn-tam_Taml",
        "languages": [
          "spa-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.008787,
        "recall": 0.015023,
        "f1": 0.009586,
        "accuracy": 0.015023,
        "main_score": 0.009586,
        "hf_subset": "spa_Latn-tur_Latn",
        "languages": [
          "spa-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.007691,
        "recall": 0.01352,
        "f1": 0.00841,
        "accuracy": 0.01352,
        "main_score": 0.00841,
        "hf_subset": "spa_Latn-vie_Latn",
        "languages": [
          "spa-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.022205,
        "recall": 0.034552,
        "f1": 0.023764,
        "accuracy": 0.034552,
        "main_score": 0.023764,
        "hf_subset": "spa_Latn-zho_Hant",
        "languages": [
          "spa-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.012461,
        "recall": 0.019529,
        "f1": 0.013417,
        "accuracy": 0.019529,
        "main_score": 0.013417,
        "hf_subset": "spa_Latn-zul_Latn",
        "languages": [
          "spa-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001002,
        "f1": 1.3e-05,
        "accuracy": 0.001002,
        "main_score": 1.3e-05,
        "hf_subset": "sqi_Latn-ell_Grek",
        "languages": [
          "sqi-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.016744,
        "recall": 0.029544,
        "f1": 0.018186,
        "accuracy": 0.029544,
        "main_score": 0.018186,
        "hf_subset": "sqi_Latn-eng_Latn",
        "languages": [
          "sqi-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001055,
        "recall": 0.004006,
        "f1": 0.001271,
        "accuracy": 0.004006,
        "main_score": 0.001271,
        "hf_subset": "sqi_Latn-hye_Armn",
        "languages": [
          "sqi-Latn",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.001091,
        "recall": 0.003005,
        "f1": 0.001167,
        "accuracy": 0.003005,
        "main_score": 0.001167,
        "hf_subset": "sqi_Latn-kat_Geor",
        "languages": [
          "sqi-Latn",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.004379,
        "recall": 0.010516,
        "f1": 0.005071,
        "accuracy": 0.010516,
        "main_score": 0.005071,
        "hf_subset": "srp_Cyrl-bel_Cyrl",
        "languages": [
          "srp-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.001589,
        "recall": 0.004006,
        "f1": 0.001666,
        "accuracy": 0.004006,
        "main_score": 0.001666,
        "hf_subset": "srp_Cyrl-bos_Latn",
        "languages": [
          "srp-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.017919,
        "recall": 0.028543,
        "f1": 0.019963,
        "accuracy": 0.028543,
        "main_score": 0.019963,
        "hf_subset": "srp_Cyrl-bul_Cyrl",
        "languages": [
          "srp-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.001534,
        "recall": 0.003005,
        "f1": 0.001565,
        "accuracy": 0.003005,
        "main_score": 0.001565,
        "hf_subset": "srp_Cyrl-ces_Latn",
        "languages": [
          "srp-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.001013,
        "recall": 0.002003,
        "f1": 0.001024,
        "accuracy": 0.002003,
        "main_score": 0.001024,
        "hf_subset": "srp_Cyrl-eng_Latn",
        "languages": [
          "srp-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001615,
        "recall": 0.004507,
        "f1": 0.001708,
        "accuracy": 0.004507,
        "main_score": 0.001708,
        "hf_subset": "srp_Cyrl-hrv_Latn",
        "languages": [
          "srp-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.051468,
        "recall": 0.082624,
        "f1": 0.057886,
        "accuracy": 0.082624,
        "main_score": 0.057886,
        "hf_subset": "srp_Cyrl-mkd_Cyrl",
        "languages": [
          "srp-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.000518,
        "recall": 0.002003,
        "f1": 0.000534,
        "accuracy": 0.002003,
        "main_score": 0.000534,
        "hf_subset": "srp_Cyrl-pol_Latn",
        "languages": [
          "srp-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.014081,
        "recall": 0.028543,
        "f1": 0.016517,
        "accuracy": 0.028543,
        "main_score": 0.016517,
        "hf_subset": "srp_Cyrl-rus_Cyrl",
        "languages": [
          "srp-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.002025,
        "recall": 0.002504,
        "f1": 0.002045,
        "accuracy": 0.002504,
        "main_score": 0.002045,
        "hf_subset": "srp_Cyrl-slk_Latn",
        "languages": [
          "srp-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.001011,
        "recall": 0.002003,
        "f1": 0.00102,
        "accuracy": 0.002003,
        "main_score": 0.00102,
        "hf_subset": "srp_Cyrl-slv_Latn",
        "languages": [
          "srp-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.002236,
        "recall": 0.004507,
        "f1": 0.002551,
        "accuracy": 0.004507,
        "main_score": 0.002551,
        "hf_subset": "srp_Cyrl-srp_Latn",
        "languages": [
          "srp-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.005273,
        "recall": 0.01352,
        "f1": 0.006044,
        "accuracy": 0.01352,
        "main_score": 0.006044,
        "hf_subset": "srp_Cyrl-ukr_Cyrl",
        "languages": [
          "srp-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.002336,
        "recall": 0.005508,
        "f1": 0.002763,
        "accuracy": 0.005508,
        "main_score": 0.002763,
        "hf_subset": "srp_Latn-bel_Cyrl",
        "languages": [
          "srp-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.606671,
        "recall": 0.696545,
        "f1": 0.632556,
        "accuracy": 0.696545,
        "main_score": 0.632556,
        "hf_subset": "srp_Latn-bos_Latn",
        "languages": [
          "srp-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.003314,
        "recall": 0.008513,
        "f1": 0.003989,
        "accuracy": 0.008513,
        "main_score": 0.003989,
        "hf_subset": "srp_Latn-bul_Cyrl",
        "languages": [
          "srp-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.022936,
        "recall": 0.03305,
        "f1": 0.02498,
        "accuracy": 0.03305,
        "main_score": 0.02498,
        "hf_subset": "srp_Latn-ces_Latn",
        "languages": [
          "srp-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.004059,
        "recall": 0.007511,
        "f1": 0.004359,
        "accuracy": 0.007511,
        "main_score": 0.004359,
        "hf_subset": "srp_Latn-eng_Latn",
        "languages": [
          "srp-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.426017,
        "recall": 0.52028,
        "f1": 0.450969,
        "accuracy": 0.52028,
        "main_score": 0.450969,
        "hf_subset": "srp_Latn-hrv_Latn",
        "languages": [
          "srp-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.004093,
        "recall": 0.009514,
        "f1": 0.004827,
        "accuracy": 0.009514,
        "main_score": 0.004827,
        "hf_subset": "srp_Latn-mkd_Cyrl",
        "languages": [
          "srp-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.009076,
        "recall": 0.015023,
        "f1": 0.009844,
        "accuracy": 0.015023,
        "main_score": 0.009844,
        "hf_subset": "srp_Latn-pol_Latn",
        "languages": [
          "srp-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.0018,
        "recall": 0.007011,
        "f1": 0.002215,
        "accuracy": 0.007011,
        "main_score": 0.002215,
        "hf_subset": "srp_Latn-rus_Cyrl",
        "languages": [
          "srp-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.02586,
        "recall": 0.036054,
        "f1": 0.027618,
        "accuracy": 0.036054,
        "main_score": 0.027618,
        "hf_subset": "srp_Latn-slk_Latn",
        "languages": [
          "srp-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.078054,
        "recall": 0.117176,
        "f1": 0.086065,
        "accuracy": 0.117176,
        "main_score": 0.086065,
        "hf_subset": "srp_Latn-slv_Latn",
        "languages": [
          "srp-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.030558,
        "recall": 0.069104,
        "f1": 0.03617,
        "accuracy": 0.069104,
        "main_score": 0.03617,
        "hf_subset": "srp_Latn-srp_Cyrl",
        "languages": [
          "srp-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.002485,
        "recall": 0.006009,
        "f1": 0.002779,
        "accuracy": 0.006009,
        "main_score": 0.002779,
        "hf_subset": "srp_Latn-ukr_Cyrl",
        "languages": [
          "srp-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.00167,
        "recall": 0.006009,
        "f1": 0.002211,
        "accuracy": 0.006009,
        "main_score": 0.002211,
        "hf_subset": "ssw_Latn-amh_Ethi",
        "languages": [
          "ssw-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.011783,
        "recall": 0.021532,
        "f1": 0.012965,
        "accuracy": 0.021532,
        "main_score": 0.012965,
        "hf_subset": "ssw_Latn-eng_Latn",
        "languages": [
          "ssw-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006525,
        "recall": 0.009014,
        "f1": 0.006873,
        "accuracy": 0.009014,
        "main_score": 0.006873,
        "hf_subset": "ssw_Latn-hau_Latn",
        "languages": [
          "ssw-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.0099,
        "recall": 0.01352,
        "f1": 0.010336,
        "accuracy": 0.01352,
        "main_score": 0.010336,
        "hf_subset": "ssw_Latn-ibo_Latn",
        "languages": [
          "ssw-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.011985,
        "recall": 0.018528,
        "f1": 0.012943,
        "accuracy": 0.018528,
        "main_score": 0.012943,
        "hf_subset": "ssw_Latn-nso_Latn",
        "languages": [
          "ssw-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.005234,
        "recall": 0.008513,
        "f1": 0.005951,
        "accuracy": 0.008513,
        "main_score": 0.005951,
        "hf_subset": "ssw_Latn-orm_Ethi",
        "languages": [
          "ssw-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.008094,
        "recall": 0.010516,
        "f1": 0.008336,
        "accuracy": 0.010516,
        "main_score": 0.008336,
        "hf_subset": "ssw_Latn-som_Latn",
        "languages": [
          "ssw-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.010141,
        "recall": 0.012519,
        "f1": 0.010452,
        "accuracy": 0.012519,
        "main_score": 0.010452,
        "hf_subset": "ssw_Latn-swa_Latn",
        "languages": [
          "ssw-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001237,
        "recall": 0.003005,
        "f1": 0.001376,
        "accuracy": 0.003005,
        "main_score": 0.001376,
        "hf_subset": "ssw_Latn-tir_Ethi",
        "languages": [
          "ssw-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.007185,
        "recall": 0.010015,
        "f1": 0.007546,
        "accuracy": 0.010015,
        "main_score": 0.007546,
        "hf_subset": "ssw_Latn-tsn_Latn",
        "languages": [
          "ssw-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.004604,
        "recall": 0.007511,
        "f1": 0.00493,
        "accuracy": 0.007511,
        "main_score": 0.00493,
        "hf_subset": "ssw_Latn-wol_Latn",
        "languages": [
          "ssw-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.032918,
        "recall": 0.049574,
        "f1": 0.036278,
        "accuracy": 0.049574,
        "main_score": 0.036278,
        "hf_subset": "ssw_Latn-xho_Latn",
        "languages": [
          "ssw-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.0073,
        "recall": 0.010015,
        "f1": 0.007679,
        "accuracy": 0.010015,
        "main_score": 0.007679,
        "hf_subset": "ssw_Latn-yor_Latn",
        "languages": [
          "ssw-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.083895,
        "recall": 0.120681,
        "f1": 0.091452,
        "accuracy": 0.120681,
        "main_score": 0.091452,
        "hf_subset": "ssw_Latn-zul_Latn",
        "languages": [
          "ssw-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.002418,
        "recall": 0.006009,
        "f1": 0.00266,
        "accuracy": 0.006009,
        "main_score": 0.00266,
        "hf_subset": "swa_Latn-amh_Ethi",
        "languages": [
          "swa-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "swa_Latn-arb_Arab",
        "languages": [
          "swa-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "swa_Latn-ben_Beng",
        "languages": [
          "swa-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.005565,
        "recall": 0.008012,
        "f1": 0.005782,
        "accuracy": 0.008012,
        "main_score": 0.005782,
        "hf_subset": "swa_Latn-deu_Latn",
        "languages": [
          "swa-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.001002,
        "f1": 3.4e-05,
        "accuracy": 0.001002,
        "main_score": 3.4e-05,
        "hf_subset": "swa_Latn-ell_Grek",
        "languages": [
          "swa-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.0065,
        "recall": 0.01302,
        "f1": 0.007219,
        "accuracy": 0.01302,
        "main_score": 0.007219,
        "hf_subset": "swa_Latn-eng_Latn",
        "languages": [
          "swa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001594,
        "recall": 0.005008,
        "f1": 0.001977,
        "accuracy": 0.005008,
        "main_score": 0.001977,
        "hf_subset": "swa_Latn-fas_Arab",
        "languages": [
          "swa-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.005719,
        "recall": 0.008012,
        "f1": 0.006087,
        "accuracy": 0.008012,
        "main_score": 0.006087,
        "hf_subset": "swa_Latn-fin_Latn",
        "languages": [
          "swa-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.007718,
        "recall": 0.011017,
        "f1": 0.008044,
        "accuracy": 0.011017,
        "main_score": 0.008044,
        "hf_subset": "swa_Latn-fra_Latn",
        "languages": [
          "swa-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.007782,
        "recall": 0.009514,
        "f1": 0.008117,
        "accuracy": 0.009514,
        "main_score": 0.008117,
        "hf_subset": "swa_Latn-hau_Latn",
        "languages": [
          "swa-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.00079,
        "recall": 0.001502,
        "f1": 0.000906,
        "accuracy": 0.001502,
        "main_score": 0.000906,
        "hf_subset": "swa_Latn-heb_Hebr",
        "languages": [
          "swa-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000563,
        "recall": 0.001502,
        "f1": 0.000779,
        "accuracy": 0.001502,
        "main_score": 0.000779,
        "hf_subset": "swa_Latn-hin_Deva",
        "languages": [
          "swa-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.005329,
        "recall": 0.006009,
        "f1": 0.005467,
        "accuracy": 0.006009,
        "main_score": 0.005467,
        "hf_subset": "swa_Latn-hun_Latn",
        "languages": [
          "swa-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.004215,
        "recall": 0.006009,
        "f1": 0.004576,
        "accuracy": 0.006009,
        "main_score": 0.004576,
        "hf_subset": "swa_Latn-ibo_Latn",
        "languages": [
          "swa-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.003884,
        "recall": 0.006009,
        "f1": 0.004062,
        "accuracy": 0.006009,
        "main_score": 0.004062,
        "hf_subset": "swa_Latn-ind_Latn",
        "languages": [
          "swa-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000189,
        "recall": 0.001502,
        "f1": 0.000315,
        "accuracy": 0.001502,
        "main_score": 0.000315,
        "hf_subset": "swa_Latn-jpn_Jpan",
        "languages": [
          "swa-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.000687,
        "recall": 0.004507,
        "f1": 0.000847,
        "accuracy": 0.004507,
        "main_score": 0.000847,
        "hf_subset": "swa_Latn-kor_Hang",
        "languages": [
          "swa-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.001758,
        "recall": 0.003005,
        "f1": 0.001906,
        "accuracy": 0.003005,
        "main_score": 0.001906,
        "hf_subset": "swa_Latn-lit_Latn",
        "languages": [
          "swa-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.002234,
        "recall": 0.005008,
        "f1": 0.002404,
        "accuracy": 0.005008,
        "main_score": 0.002404,
        "hf_subset": "swa_Latn-nld_Latn",
        "languages": [
          "swa-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.006315,
        "recall": 0.012018,
        "f1": 0.007098,
        "accuracy": 0.012018,
        "main_score": 0.007098,
        "hf_subset": "swa_Latn-nso_Latn",
        "languages": [
          "swa-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.003183,
        "recall": 0.005008,
        "f1": 0.003527,
        "accuracy": 0.005008,
        "main_score": 0.003527,
        "hf_subset": "swa_Latn-orm_Ethi",
        "languages": [
          "swa-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.003331,
        "recall": 0.005508,
        "f1": 0.003529,
        "accuracy": 0.005508,
        "main_score": 0.003529,
        "hf_subset": "swa_Latn-pol_Latn",
        "languages": [
          "swa-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.008147,
        "recall": 0.011517,
        "f1": 0.008799,
        "accuracy": 0.011517,
        "main_score": 0.008799,
        "hf_subset": "swa_Latn-por_Latn",
        "languages": [
          "swa-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000145,
        "recall": 0.001502,
        "f1": 0.000254,
        "accuracy": 0.001502,
        "main_score": 0.000254,
        "hf_subset": "swa_Latn-rus_Cyrl",
        "languages": [
          "swa-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.003749,
        "recall": 0.005508,
        "f1": 0.003922,
        "accuracy": 0.005508,
        "main_score": 0.003922,
        "hf_subset": "swa_Latn-som_Latn",
        "languages": [
          "swa-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.008343,
        "recall": 0.012018,
        "f1": 0.008751,
        "accuracy": 0.012018,
        "main_score": 0.008751,
        "hf_subset": "swa_Latn-spa_Latn",
        "languages": [
          "swa-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.00734,
        "recall": 0.012018,
        "f1": 0.007783,
        "accuracy": 0.012018,
        "main_score": 0.007783,
        "hf_subset": "swa_Latn-ssw_Latn",
        "languages": [
          "swa-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.004058,
        "recall": 0.00651,
        "f1": 0.004337,
        "accuracy": 0.00651,
        "main_score": 0.004337,
        "hf_subset": "swa_Latn-swe_Latn",
        "languages": [
          "swa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.00014,
        "recall": 0.003005,
        "f1": 0.000244,
        "accuracy": 0.003005,
        "main_score": 0.000244,
        "hf_subset": "swa_Latn-tam_Taml",
        "languages": [
          "swa-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001098,
        "recall": 0.005008,
        "f1": 0.001187,
        "accuracy": 0.005008,
        "main_score": 0.001187,
        "hf_subset": "swa_Latn-tir_Ethi",
        "languages": [
          "swa-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.004608,
        "recall": 0.007011,
        "f1": 0.004911,
        "accuracy": 0.007011,
        "main_score": 0.004911,
        "hf_subset": "swa_Latn-tsn_Latn",
        "languages": [
          "swa-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.005135,
        "recall": 0.007511,
        "f1": 0.005408,
        "accuracy": 0.007511,
        "main_score": 0.005408,
        "hf_subset": "swa_Latn-tur_Latn",
        "languages": [
          "swa-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.00469,
        "recall": 0.007511,
        "f1": 0.004836,
        "accuracy": 0.007511,
        "main_score": 0.004836,
        "hf_subset": "swa_Latn-vie_Latn",
        "languages": [
          "swa-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.002073,
        "recall": 0.003505,
        "f1": 0.00213,
        "accuracy": 0.003505,
        "main_score": 0.00213,
        "hf_subset": "swa_Latn-wol_Latn",
        "languages": [
          "swa-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.004211,
        "recall": 0.005508,
        "f1": 0.004495,
        "accuracy": 0.005508,
        "main_score": 0.004495,
        "hf_subset": "swa_Latn-xho_Latn",
        "languages": [
          "swa-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.004207,
        "recall": 0.00651,
        "f1": 0.004517,
        "accuracy": 0.00651,
        "main_score": 0.004517,
        "hf_subset": "swa_Latn-yor_Latn",
        "languages": [
          "swa-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.00529,
        "recall": 0.012018,
        "f1": 0.005976,
        "accuracy": 0.012018,
        "main_score": 0.005976,
        "hf_subset": "swa_Latn-zho_Hant",
        "languages": [
          "swa-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.006808,
        "recall": 0.009014,
        "f1": 0.006936,
        "accuracy": 0.009014,
        "main_score": 0.006936,
        "hf_subset": "swa_Latn-zul_Latn",
        "languages": [
          "swa-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.043159,
        "recall": 0.065098,
        "f1": 0.047502,
        "accuracy": 0.065098,
        "main_score": 0.047502,
        "hf_subset": "swe_Latn-afr_Latn",
        "languages": [
          "swe-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.000125,
        "recall": 0.000501,
        "f1": 0.0002,
        "accuracy": 0.000501,
        "main_score": 0.0002,
        "hf_subset": "swe_Latn-arb_Arab",
        "languages": [
          "swe-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 4.3e-05,
        "recall": 0.001002,
        "f1": 8.2e-05,
        "accuracy": 0.001002,
        "main_score": 8.2e-05,
        "hf_subset": "swe_Latn-ben_Beng",
        "languages": [
          "swe-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.160275,
        "recall": 0.225338,
        "f1": 0.173706,
        "accuracy": 0.225338,
        "main_score": 0.173706,
        "hf_subset": "swe_Latn-dan_Latn",
        "languages": [
          "swe-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.039003,
        "recall": 0.058087,
        "f1": 0.042601,
        "accuracy": 0.058087,
        "main_score": 0.042601,
        "hf_subset": "swe_Latn-deu_Latn",
        "languages": [
          "swe-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000169,
        "recall": 0.001002,
        "f1": 0.000254,
        "accuracy": 0.001002,
        "main_score": 0.000254,
        "hf_subset": "swe_Latn-ell_Grek",
        "languages": [
          "swe-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.041907,
        "recall": 0.065098,
        "f1": 0.044927,
        "accuracy": 0.065098,
        "main_score": 0.044927,
        "hf_subset": "swe_Latn-eng_Latn",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.058266,
        "recall": 0.083125,
        "f1": 0.062814,
        "accuracy": 0.083125,
        "main_score": 0.062814,
        "hf_subset": "swe_Latn-fao_Latn",
        "languages": [
          "swe-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.002117,
        "recall": 0.004507,
        "f1": 0.002364,
        "accuracy": 0.004507,
        "main_score": 0.002364,
        "hf_subset": "swe_Latn-fas_Arab",
        "languages": [
          "swe-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.02269,
        "recall": 0.034051,
        "f1": 0.024833,
        "accuracy": 0.034051,
        "main_score": 0.024833,
        "hf_subset": "swe_Latn-fin_Latn",
        "languages": [
          "swe-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.027903,
        "recall": 0.044567,
        "f1": 0.030716,
        "accuracy": 0.044567,
        "main_score": 0.030716,
        "hf_subset": "swe_Latn-fra_Latn",
        "languages": [
          "swe-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000507,
        "recall": 0.002504,
        "f1": 0.000777,
        "accuracy": 0.002504,
        "main_score": 0.000777,
        "hf_subset": "swe_Latn-heb_Hebr",
        "languages": [
          "swe-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.00078,
        "recall": 0.002504,
        "f1": 0.000891,
        "accuracy": 0.002504,
        "main_score": 0.000891,
        "hf_subset": "swe_Latn-hin_Deva",
        "languages": [
          "swe-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.021193,
        "recall": 0.031547,
        "f1": 0.023217,
        "accuracy": 0.031547,
        "main_score": 0.023217,
        "hf_subset": "swe_Latn-hun_Latn",
        "languages": [
          "swe-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.024736,
        "recall": 0.042063,
        "f1": 0.027633,
        "accuracy": 0.042063,
        "main_score": 0.027633,
        "hf_subset": "swe_Latn-ind_Latn",
        "languages": [
          "swe-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.034248,
        "recall": 0.051077,
        "f1": 0.037495,
        "accuracy": 0.051077,
        "main_score": 0.037495,
        "hf_subset": "swe_Latn-isl_Latn",
        "languages": [
          "swe-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.001799,
        "recall": 0.004006,
        "f1": 0.001992,
        "accuracy": 0.004006,
        "main_score": 0.001992,
        "hf_subset": "swe_Latn-jpn_Jpan",
        "languages": [
          "swe-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001268,
        "recall": 0.005008,
        "f1": 0.001669,
        "accuracy": 0.005008,
        "main_score": 0.001669,
        "hf_subset": "swe_Latn-kor_Hang",
        "languages": [
          "swe-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.014914,
        "recall": 0.026039,
        "f1": 0.016791,
        "accuracy": 0.026039,
        "main_score": 0.016791,
        "hf_subset": "swe_Latn-lit_Latn",
        "languages": [
          "swe-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.041829,
        "recall": 0.062093,
        "f1": 0.045776,
        "accuracy": 0.062093,
        "main_score": 0.045776,
        "hf_subset": "swe_Latn-ltz_Latn",
        "languages": [
          "swe-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.041804,
        "recall": 0.063095,
        "f1": 0.046419,
        "accuracy": 0.063095,
        "main_score": 0.046419,
        "hf_subset": "swe_Latn-nld_Latn",
        "languages": [
          "swe-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.201662,
        "recall": 0.275413,
        "f1": 0.218311,
        "accuracy": 0.275413,
        "main_score": 0.218311,
        "hf_subset": "swe_Latn-nno_Latn",
        "languages": [
          "swe-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.212849,
        "recall": 0.288433,
        "f1": 0.229592,
        "accuracy": 0.288433,
        "main_score": 0.229592,
        "hf_subset": "swe_Latn-nob_Latn",
        "languages": [
          "swe-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.018066,
        "recall": 0.029544,
        "f1": 0.019971,
        "accuracy": 0.029544,
        "main_score": 0.019971,
        "hf_subset": "swe_Latn-pol_Latn",
        "languages": [
          "swe-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.02661,
        "recall": 0.039559,
        "f1": 0.029249,
        "accuracy": 0.039559,
        "main_score": 0.029249,
        "hf_subset": "swe_Latn-por_Latn",
        "languages": [
          "swe-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.00088,
        "recall": 0.002504,
        "f1": 0.001042,
        "accuracy": 0.002504,
        "main_score": 0.001042,
        "hf_subset": "swe_Latn-rus_Cyrl",
        "languages": [
          "swe-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.027159,
        "recall": 0.043565,
        "f1": 0.03011,
        "accuracy": 0.043565,
        "main_score": 0.03011,
        "hf_subset": "swe_Latn-spa_Latn",
        "languages": [
          "swe-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.008974,
        "recall": 0.019029,
        "f1": 0.010423,
        "accuracy": 0.019029,
        "main_score": 0.010423,
        "hf_subset": "swe_Latn-swa_Latn",
        "languages": [
          "swe-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000659,
        "recall": 0.004006,
        "f1": 0.000795,
        "accuracy": 0.004006,
        "main_score": 0.000795,
        "hf_subset": "swe_Latn-tam_Taml",
        "languages": [
          "swe-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.015247,
        "recall": 0.025038,
        "f1": 0.016957,
        "accuracy": 0.025038,
        "main_score": 0.016957,
        "hf_subset": "swe_Latn-tur_Latn",
        "languages": [
          "swe-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.01285,
        "recall": 0.020531,
        "f1": 0.01405,
        "accuracy": 0.020531,
        "main_score": 0.01405,
        "hf_subset": "swe_Latn-vie_Latn",
        "languages": [
          "swe-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.023424,
        "recall": 0.048072,
        "f1": 0.026759,
        "accuracy": 0.048072,
        "main_score": 0.026759,
        "hf_subset": "swe_Latn-zho_Hant",
        "languages": [
          "swe-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.013094,
        "recall": 0.022534,
        "f1": 0.014434,
        "accuracy": 0.022534,
        "main_score": 0.014434,
        "hf_subset": "swe_Latn-zul_Latn",
        "languages": [
          "swe-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.017199,
        "recall": 0.024036,
        "f1": 0.018143,
        "accuracy": 0.024036,
        "main_score": 0.018143,
        "hf_subset": "tah_Latn-eng_Latn",
        "languages": [
          "tah-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005192,
        "recall": 0.007511,
        "f1": 0.005322,
        "accuracy": 0.007511,
        "main_score": 0.005322,
        "hf_subset": "tah_Latn-fij_Latn",
        "languages": [
          "tah-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.003578,
        "recall": 0.006009,
        "f1": 0.003807,
        "accuracy": 0.006009,
        "main_score": 0.003807,
        "hf_subset": "tah_Latn-fil_Latn",
        "languages": [
          "tah-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.006215,
        "recall": 0.009014,
        "f1": 0.006547,
        "accuracy": 0.009014,
        "main_score": 0.006547,
        "hf_subset": "tah_Latn-ind_Latn",
        "languages": [
          "tah-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.00103,
        "recall": 0.002504,
        "f1": 0.001057,
        "accuracy": 0.002504,
        "main_score": 0.001057,
        "hf_subset": "tah_Latn-mal_Mlym",
        "languages": [
          "tah-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.005875,
        "recall": 0.007511,
        "f1": 0.006239,
        "accuracy": 0.007511,
        "main_score": 0.006239,
        "hf_subset": "tah_Latn-mlg_Latn",
        "languages": [
          "tah-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.008937,
        "recall": 0.014021,
        "f1": 0.009669,
        "accuracy": 0.014021,
        "main_score": 0.009669,
        "hf_subset": "tah_Latn-mri_Latn",
        "languages": [
          "tah-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.003857,
        "recall": 0.006009,
        "f1": 0.00403,
        "accuracy": 0.006009,
        "main_score": 0.00403,
        "hf_subset": "tah_Latn-msa_Latn",
        "languages": [
          "tah-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.007263,
        "recall": 0.008513,
        "f1": 0.007348,
        "accuracy": 0.008513,
        "main_score": 0.007348,
        "hf_subset": "tah_Latn-smo_Latn",
        "languages": [
          "tah-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.007844,
        "recall": 0.012519,
        "f1": 0.008418,
        "accuracy": 0.012519,
        "main_score": 0.008418,
        "hf_subset": "tah_Latn-ton_Latn",
        "languages": [
          "tah-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 3e-06,
        "accuracy": 0.000501,
        "main_score": 3e-06,
        "hf_subset": "tam_Taml-arb_Arab",
        "languages": [
          "tam-Taml",
          "arb-Arab"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 5e-06,
        "accuracy": 0.001002,
        "main_score": 5e-06,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000802,
        "recall": 0.003005,
        "f1": 0.00093,
        "accuracy": 0.003005,
        "main_score": 0.00093,
        "hf_subset": "tam_Taml-deu_Latn",
        "languages": [
          "tam-Taml",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.001016,
        "recall": 0.002003,
        "f1": 0.001029,
        "accuracy": 0.002003,
        "main_score": 0.001029,
        "hf_subset": "tam_Taml-div_Thaa",
        "languages": [
          "tam-Taml",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "tam_Taml-ell_Grek",
        "languages": [
          "tam-Taml",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.002005,
        "recall": 0.003005,
        "f1": 0.002006,
        "accuracy": 0.003005,
        "main_score": 0.002006,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000668,
        "accuracy": 0.001002,
        "main_score": 0.000668,
        "hf_subset": "tam_Taml-eus_Latn",
        "languages": [
          "tam-Taml",
          "eus-Latn"
        ]
      },
      {
        "precision": 1.4e-05,
        "recall": 0.001002,
        "f1": 2.8e-05,
        "accuracy": 0.001002,
        "main_score": 2.8e-05,
        "hf_subset": "tam_Taml-fas_Arab",
        "languages": [
          "tam-Taml",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.001151,
        "recall": 0.002504,
        "f1": 0.001248,
        "accuracy": 0.002504,
        "main_score": 0.001248,
        "hf_subset": "tam_Taml-fin_Latn",
        "languages": [
          "tam-Taml",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.001502,
        "recall": 0.001502,
        "f1": 0.001502,
        "accuracy": 0.001502,
        "main_score": 0.001502,
        "hf_subset": "tam_Taml-fra_Latn",
        "languages": [
          "tam-Taml",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.00151,
        "recall": 0.003005,
        "f1": 0.001517,
        "accuracy": 0.003005,
        "main_score": 0.001517,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 5.3e-05,
        "recall": 0.001002,
        "f1": 9.6e-05,
        "accuracy": 0.001002,
        "main_score": 9.6e-05,
        "hf_subset": "tam_Taml-heb_Hebr",
        "languages": [
          "tam-Taml",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.001047,
        "recall": 0.002003,
        "f1": 0.001089,
        "accuracy": 0.002003,
        "main_score": 0.001089,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.000838,
        "recall": 0.003005,
        "f1": 0.001064,
        "accuracy": 0.003005,
        "main_score": 0.001064,
        "hf_subset": "tam_Taml-hun_Latn",
        "languages": [
          "tam-Taml",
          "hun-Latn"
        ]
      },
      {
        "precision": 8.6e-05,
        "recall": 0.001502,
        "f1": 0.000159,
        "accuracy": 0.001502,
        "main_score": 0.000159,
        "hf_subset": "tam_Taml-ind_Latn",
        "languages": [
          "tam-Taml",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000587,
        "recall": 0.002003,
        "f1": 0.00065,
        "accuracy": 0.002003,
        "main_score": 0.00065,
        "hf_subset": "tam_Taml-jpn_Jpan",
        "languages": [
          "tam-Taml",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.002504,
        "recall": 0.003005,
        "f1": 0.002505,
        "accuracy": 0.003005,
        "main_score": 0.002505,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001048,
        "recall": 0.003005,
        "f1": 0.00109,
        "accuracy": 0.003005,
        "main_score": 0.00109,
        "hf_subset": "tam_Taml-kor_Hang",
        "languages": [
          "tam-Taml",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.000323,
        "recall": 0.002504,
        "f1": 0.000522,
        "accuracy": 0.002504,
        "main_score": 0.000522,
        "hf_subset": "tam_Taml-lit_Latn",
        "languages": [
          "tam-Taml",
          "lit-Latn"
        ]
      },
      {
        "precision": 3.9e-05,
        "recall": 0.001002,
        "f1": 7.3e-05,
        "accuracy": 0.001002,
        "main_score": 7.3e-05,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.001002,
        "f1": 2.1e-05,
        "accuracy": 0.001002,
        "main_score": 2.1e-05,
        "hf_subset": "tam_Taml-nep_Deva",
        "languages": [
          "tam-Taml",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.002506,
        "recall": 0.003005,
        "f1": 0.002508,
        "accuracy": 0.003005,
        "main_score": 0.002508,
        "hf_subset": "tam_Taml-nld_Latn",
        "languages": [
          "tam-Taml",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002003,
        "f1": 0.001503,
        "accuracy": 0.002003,
        "main_score": 0.001503,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.001502,
        "f1": 3.3e-05,
        "accuracy": 0.001502,
        "main_score": 3.3e-05,
        "hf_subset": "tam_Taml-pol_Latn",
        "languages": [
          "tam-Taml",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.001753,
        "recall": 0.002504,
        "f1": 0.001837,
        "accuracy": 0.002504,
        "main_score": 0.001837,
        "hf_subset": "tam_Taml-por_Latn",
        "languages": [
          "tam-Taml",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000252,
        "recall": 0.001002,
        "f1": 0.000337,
        "accuracy": 0.001002,
        "main_score": 0.000337,
        "hf_subset": "tam_Taml-rus_Cyrl",
        "languages": [
          "tam-Taml",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.002008,
        "recall": 0.003005,
        "f1": 0.002012,
        "accuracy": 0.003005,
        "main_score": 0.002012,
        "hf_subset": "tam_Taml-sin_Sinh",
        "languages": [
          "tam-Taml",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000185,
        "recall": 0.002504,
        "f1": 0.000312,
        "accuracy": 0.002504,
        "main_score": 0.000312,
        "hf_subset": "tam_Taml-snd_Arab",
        "languages": [
          "tam-Taml",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002003,
        "f1": 0.001007,
        "accuracy": 0.002003,
        "main_score": 0.001007,
        "hf_subset": "tam_Taml-spa_Latn",
        "languages": [
          "tam-Taml",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001052,
        "recall": 0.002003,
        "f1": 0.001094,
        "accuracy": 0.002003,
        "main_score": 0.001094,
        "hf_subset": "tam_Taml-swa_Latn",
        "languages": [
          "tam-Taml",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001252,
        "recall": 0.001502,
        "f1": 0.001335,
        "accuracy": 0.001502,
        "main_score": 0.001335,
        "hf_subset": "tam_Taml-swe_Latn",
        "languages": [
          "tam-Taml",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.002506,
        "recall": 0.003505,
        "f1": 0.002509,
        "accuracy": 0.003505,
        "main_score": 0.002509,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000309,
        "recall": 0.002003,
        "f1": 0.00044,
        "accuracy": 0.002003,
        "main_score": 0.00044,
        "hf_subset": "tam_Taml-tur_Latn",
        "languages": [
          "tam-Taml",
          "tur-Latn"
        ]
      },
      {
        "precision": 4.6e-05,
        "recall": 0.000501,
        "f1": 8.3e-05,
        "accuracy": 0.000501,
        "main_score": 8.3e-05,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 1.6e-05,
        "recall": 0.001502,
        "f1": 3.1e-05,
        "accuracy": 0.001502,
        "main_score": 3.1e-05,
        "hf_subset": "tam_Taml-vie_Latn",
        "languages": [
          "tam-Taml",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.00167,
        "recall": 0.002504,
        "f1": 0.001755,
        "accuracy": 0.002504,
        "main_score": 0.001755,
        "hf_subset": "tam_Taml-zho_Hant",
        "languages": [
          "tam-Taml",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.00025,
        "recall": 0.001002,
        "f1": 0.000401,
        "accuracy": 0.001002,
        "main_score": 0.000401,
        "hf_subset": "tam_Taml-zul_Latn",
        "languages": [
          "tam-Taml",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.00082,
        "recall": 0.003505,
        "f1": 0.001004,
        "accuracy": 0.003505,
        "main_score": 0.001004,
        "hf_subset": "tat_Cyrl-aze_Latn",
        "languages": [
          "tat-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.052193,
        "recall": 0.083125,
        "f1": 0.058593,
        "accuracy": 0.083125,
        "main_score": 0.058593,
        "hf_subset": "tat_Cyrl-bak_Cyrl",
        "languages": [
          "tat-Cyrl",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.000518,
        "recall": 0.002504,
        "f1": 0.000535,
        "accuracy": 0.002504,
        "main_score": 0.000535,
        "hf_subset": "tat_Cyrl-eng_Latn",
        "languages": [
          "tat-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017513,
        "recall": 0.034552,
        "f1": 0.020597,
        "accuracy": 0.034552,
        "main_score": 0.020597,
        "hf_subset": "tat_Cyrl-kaz_Cyrl",
        "languages": [
          "tat-Cyrl",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.036647,
        "recall": 0.055583,
        "f1": 0.041228,
        "accuracy": 0.055583,
        "main_score": 0.041228,
        "hf_subset": "tat_Cyrl-kir_Cyrl",
        "languages": [
          "tat-Cyrl",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "tat_Cyrl-tuk_Latn",
        "languages": [
          "tat-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 5.3e-05,
        "recall": 0.001002,
        "f1": 9.9e-05,
        "accuracy": 0.001002,
        "main_score": 9.9e-05,
        "hf_subset": "tat_Cyrl-tur_Latn",
        "languages": [
          "tat-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000471,
        "recall": 0.002003,
        "f1": 0.000684,
        "accuracy": 0.002003,
        "main_score": 0.000684,
        "hf_subset": "tat_Cyrl-uig_Arab",
        "languages": [
          "tat-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 4.8e-05,
        "recall": 0.002003,
        "f1": 9.1e-05,
        "accuracy": 0.002003,
        "main_score": 9.1e-05,
        "hf_subset": "tat_Cyrl-uzb_Latn",
        "languages": [
          "tat-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.081677,
        "recall": 0.116174,
        "f1": 0.089805,
        "accuracy": 0.116174,
        "main_score": 0.089805,
        "hf_subset": "tel_Telu-div_Thaa",
        "languages": [
          "tel-Telu",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.024185,
        "recall": 0.038057,
        "f1": 0.02688,
        "accuracy": 0.038057,
        "main_score": 0.02688,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002324,
        "recall": 0.00651,
        "f1": 0.002742,
        "accuracy": 0.00651,
        "main_score": 0.002742,
        "hf_subset": "tel_Telu-eus_Latn",
        "languages": [
          "tel-Telu",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.116106,
        "recall": 0.149725,
        "f1": 0.124372,
        "accuracy": 0.149725,
        "main_score": 0.124372,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000861,
        "recall": 0.003005,
        "f1": 0.001029,
        "accuracy": 0.003005,
        "main_score": 0.001029,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.112679,
        "recall": 0.150225,
        "f1": 0.121709,
        "accuracy": 0.150225,
        "main_score": 0.121709,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000445,
        "recall": 0.003005,
        "f1": 0.000639,
        "accuracy": 0.003005,
        "main_score": 0.000639,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00031,
        "recall": 0.002003,
        "f1": 0.000513,
        "accuracy": 0.002003,
        "main_score": 0.000513,
        "hf_subset": "tel_Telu-nep_Deva",
        "languages": [
          "tel-Telu",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.066073,
        "recall": 0.098147,
        "f1": 0.073445,
        "accuracy": 0.098147,
        "main_score": 0.073445,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.04835,
        "recall": 0.091137,
        "f1": 0.05688,
        "accuracy": 0.091137,
        "main_score": 0.05688,
        "hf_subset": "tel_Telu-sin_Sinh",
        "languages": [
          "tel-Telu",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.001867,
        "recall": 0.00651,
        "f1": 0.002314,
        "accuracy": 0.00651,
        "main_score": 0.002314,
        "hf_subset": "tel_Telu-snd_Arab",
        "languages": [
          "tel-Telu",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.002109,
        "recall": 0.009514,
        "f1": 0.002495,
        "accuracy": 0.009514,
        "main_score": 0.002495,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000511,
        "recall": 0.002003,
        "f1": 0.000521,
        "accuracy": 0.002003,
        "main_score": 0.000521,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000501,
        "f1": 3e-06,
        "accuracy": 0.000501,
        "main_score": 3e-06,
        "hf_subset": "tgk_Cyrl-arb_Arab",
        "languages": [
          "tgk-Cyrl",
          "arb-Arab"
        ]
      },
      {
        "precision": 4.6e-05,
        "recall": 0.001002,
        "f1": 8.5e-05,
        "accuracy": 0.001002,
        "main_score": 8.5e-05,
        "hf_subset": "tgk_Cyrl-ckb_Arab",
        "languages": [
          "tgk-Cyrl",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.002003,
        "f1": 0.000507,
        "accuracy": 0.002003,
        "main_score": 0.000507,
        "hf_subset": "tgk_Cyrl-eng_Latn",
        "languages": [
          "tgk-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001108,
        "recall": 0.003005,
        "f1": 0.001195,
        "accuracy": 0.003005,
        "main_score": 0.001195,
        "hf_subset": "tgk_Cyrl-fas_Arab",
        "languages": [
          "tgk-Cyrl",
          "fas-Arab"
        ]
      },
      {
        "precision": 1.8e-05,
        "recall": 0.001002,
        "f1": 3.5e-05,
        "accuracy": 0.001002,
        "main_score": 3.5e-05,
        "hf_subset": "tgk_Cyrl-heb_Hebr",
        "languages": [
          "tgk-Cyrl",
          "heb-Hebr"
        ]
      },
      {
        "precision": 8e-06,
        "recall": 0.001502,
        "f1": 1.6e-05,
        "accuracy": 0.001502,
        "main_score": 1.6e-05,
        "hf_subset": "tgk_Cyrl-kmr_Latn",
        "languages": [
          "tgk-Cyrl",
          "kmr-Latn"
        ]
      },
      {
        "precision": 3.6e-05,
        "recall": 0.001502,
        "f1": 6.9e-05,
        "accuracy": 0.001502,
        "main_score": 6.9e-05,
        "hf_subset": "tgk_Cyrl-mey_Arab",
        "languages": [
          "tgk-Cyrl",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.000505,
        "recall": 0.002003,
        "f1": 0.00051,
        "accuracy": 0.002003,
        "main_score": 0.00051,
        "hf_subset": "tgk_Cyrl-prs_Arab",
        "languages": [
          "tgk-Cyrl",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.001024,
        "recall": 0.002504,
        "f1": 0.001045,
        "accuracy": 0.002504,
        "main_score": 0.001045,
        "hf_subset": "tgk_Cyrl-pus_Arab",
        "languages": [
          "tgk-Cyrl",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "tgk_Cyrl-shi_Arab",
        "languages": [
          "tgk-Cyrl",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.004712,
        "recall": 0.012519,
        "f1": 0.005657,
        "accuracy": 0.012519,
        "main_score": 0.005657,
        "hf_subset": "tha_Thai-bod_Tibt",
        "languages": [
          "tha-Thai",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.000862,
        "recall": 0.002003,
        "f1": 0.001054,
        "accuracy": 0.002003,
        "main_score": 0.001054,
        "hf_subset": "tha_Thai-dzo_Tibt",
        "languages": [
          "tha-Thai",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.177019,
        "recall": 0.224837,
        "f1": 0.189228,
        "accuracy": 0.224837,
        "main_score": 0.189228,
        "hf_subset": "tha_Thai-eng_Latn",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.224055,
        "recall": 0.270406,
        "f1": 0.236385,
        "accuracy": 0.270406,
        "main_score": 0.236385,
        "hf_subset": "tha_Thai-khm_Khmr",
        "languages": [
          "tha-Thai",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.299457,
        "recall": 0.338007,
        "f1": 0.309557,
        "accuracy": 0.338007,
        "main_score": 0.309557,
        "hf_subset": "tha_Thai-lao_Laoo",
        "languages": [
          "tha-Thai",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.001323,
        "recall": 0.003005,
        "f1": 0.001525,
        "accuracy": 0.003005,
        "main_score": 0.001525,
        "hf_subset": "tha_Thai-mon_Mong",
        "languages": [
          "tha-Thai",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.122853,
        "recall": 0.177266,
        "f1": 0.135661,
        "accuracy": 0.177266,
        "main_score": 0.135661,
        "hf_subset": "tha_Thai-mya_Mymr",
        "languages": [
          "tha-Thai",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.056133,
        "recall": 0.094141,
        "f1": 0.064906,
        "accuracy": 0.094141,
        "main_score": 0.064906,
        "hf_subset": "tir_Ethi-amh_Ethi",
        "languages": [
          "tir-Ethi",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.03152,
        "recall": 0.047071,
        "f1": 0.034461,
        "accuracy": 0.047071,
        "main_score": 0.034461,
        "hf_subset": "tir_Ethi-eng_Latn",
        "languages": [
          "tir-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005911,
        "recall": 0.01352,
        "f1": 0.006863,
        "accuracy": 0.01352,
        "main_score": 0.006863,
        "hf_subset": "tir_Ethi-hau_Latn",
        "languages": [
          "tir-Ethi",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.0057,
        "recall": 0.014522,
        "f1": 0.006822,
        "accuracy": 0.014522,
        "main_score": 0.006822,
        "hf_subset": "tir_Ethi-ibo_Latn",
        "languages": [
          "tir-Ethi",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.005074,
        "recall": 0.009514,
        "f1": 0.005616,
        "accuracy": 0.009514,
        "main_score": 0.005616,
        "hf_subset": "tir_Ethi-nso_Latn",
        "languages": [
          "tir-Ethi",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.002561,
        "recall": 0.008012,
        "f1": 0.003114,
        "accuracy": 0.008012,
        "main_score": 0.003114,
        "hf_subset": "tir_Ethi-orm_Ethi",
        "languages": [
          "tir-Ethi",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.0047,
        "recall": 0.011517,
        "f1": 0.005492,
        "accuracy": 0.011517,
        "main_score": 0.005492,
        "hf_subset": "tir_Ethi-som_Latn",
        "languages": [
          "tir-Ethi",
          "som-Latn"
        ]
      },
      {
        "precision": 0.003381,
        "recall": 0.009014,
        "f1": 0.004238,
        "accuracy": 0.009014,
        "main_score": 0.004238,
        "hf_subset": "tir_Ethi-ssw_Latn",
        "languages": [
          "tir-Ethi",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.002077,
        "recall": 0.006009,
        "f1": 0.002602,
        "accuracy": 0.006009,
        "main_score": 0.002602,
        "hf_subset": "tir_Ethi-swa_Latn",
        "languages": [
          "tir-Ethi",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.003219,
        "recall": 0.009014,
        "f1": 0.003671,
        "accuracy": 0.009014,
        "main_score": 0.003671,
        "hf_subset": "tir_Ethi-tsn_Latn",
        "languages": [
          "tir-Ethi",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.003019,
        "recall": 0.007011,
        "f1": 0.003533,
        "accuracy": 0.007011,
        "main_score": 0.003533,
        "hf_subset": "tir_Ethi-wol_Latn",
        "languages": [
          "tir-Ethi",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.002964,
        "recall": 0.007011,
        "f1": 0.003433,
        "accuracy": 0.007011,
        "main_score": 0.003433,
        "hf_subset": "tir_Ethi-xho_Latn",
        "languages": [
          "tir-Ethi",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.003269,
        "recall": 0.008012,
        "f1": 0.003937,
        "accuracy": 0.008012,
        "main_score": 0.003937,
        "hf_subset": "tir_Ethi-yor_Latn",
        "languages": [
          "tir-Ethi",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.005721,
        "recall": 0.011517,
        "f1": 0.006524,
        "accuracy": 0.011517,
        "main_score": 0.006524,
        "hf_subset": "tir_Ethi-zul_Latn",
        "languages": [
          "tir-Ethi",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.004083,
        "recall": 0.007011,
        "f1": 0.004547,
        "accuracy": 0.007011,
        "main_score": 0.004547,
        "hf_subset": "ton_Latn-eng_Latn",
        "languages": [
          "ton-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002108,
        "recall": 0.004006,
        "f1": 0.002194,
        "accuracy": 0.004006,
        "main_score": 0.002194,
        "hf_subset": "ton_Latn-fij_Latn",
        "languages": [
          "ton-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.002425,
        "recall": 0.004507,
        "f1": 0.002664,
        "accuracy": 0.004507,
        "main_score": 0.002664,
        "hf_subset": "ton_Latn-fil_Latn",
        "languages": [
          "ton-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.000532,
        "recall": 0.001002,
        "f1": 0.00056,
        "accuracy": 0.001002,
        "main_score": 0.00056,
        "hf_subset": "ton_Latn-ind_Latn",
        "languages": [
          "ton-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ton_Latn-mal_Mlym",
        "languages": [
          "ton-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001526,
        "recall": 0.003005,
        "f1": 0.00155,
        "accuracy": 0.003005,
        "main_score": 0.00155,
        "hf_subset": "ton_Latn-mlg_Latn",
        "languages": [
          "ton-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.002841,
        "recall": 0.004507,
        "f1": 0.003179,
        "accuracy": 0.004507,
        "main_score": 0.003179,
        "hf_subset": "ton_Latn-mri_Latn",
        "languages": [
          "ton-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.001756,
        "recall": 0.002504,
        "f1": 0.001842,
        "accuracy": 0.002504,
        "main_score": 0.001842,
        "hf_subset": "ton_Latn-msa_Latn",
        "languages": [
          "ton-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.006429,
        "recall": 0.010516,
        "f1": 0.006813,
        "accuracy": 0.010516,
        "main_score": 0.006813,
        "hf_subset": "ton_Latn-smo_Latn",
        "languages": [
          "ton-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.003081,
        "recall": 0.005508,
        "f1": 0.003314,
        "accuracy": 0.005508,
        "main_score": 0.003314,
        "hf_subset": "ton_Latn-tah_Latn",
        "languages": [
          "ton-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.002914,
        "recall": 0.00651,
        "f1": 0.003123,
        "accuracy": 0.00651,
        "main_score": 0.003123,
        "hf_subset": "tsn_Latn-amh_Ethi",
        "languages": [
          "tsn-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.015287,
        "recall": 0.025038,
        "f1": 0.016343,
        "accuracy": 0.025038,
        "main_score": 0.016343,
        "hf_subset": "tsn_Latn-eng_Latn",
        "languages": [
          "tsn-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005097,
        "recall": 0.008012,
        "f1": 0.005668,
        "accuracy": 0.008012,
        "main_score": 0.005668,
        "hf_subset": "tsn_Latn-hau_Latn",
        "languages": [
          "tsn-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.011063,
        "recall": 0.014021,
        "f1": 0.011713,
        "accuracy": 0.014021,
        "main_score": 0.011713,
        "hf_subset": "tsn_Latn-ibo_Latn",
        "languages": [
          "tsn-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.065938,
        "recall": 0.091637,
        "f1": 0.07113,
        "accuracy": 0.091637,
        "main_score": 0.07113,
        "hf_subset": "tsn_Latn-nso_Latn",
        "languages": [
          "tsn-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.002751,
        "recall": 0.00651,
        "f1": 0.003075,
        "accuracy": 0.00651,
        "main_score": 0.003075,
        "hf_subset": "tsn_Latn-orm_Ethi",
        "languages": [
          "tsn-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.006677,
        "recall": 0.008012,
        "f1": 0.007094,
        "accuracy": 0.008012,
        "main_score": 0.007094,
        "hf_subset": "tsn_Latn-som_Latn",
        "languages": [
          "tsn-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.008349,
        "recall": 0.012018,
        "f1": 0.008765,
        "accuracy": 0.012018,
        "main_score": 0.008765,
        "hf_subset": "tsn_Latn-ssw_Latn",
        "languages": [
          "tsn-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.006392,
        "recall": 0.009514,
        "f1": 0.006789,
        "accuracy": 0.009514,
        "main_score": 0.006789,
        "hf_subset": "tsn_Latn-swa_Latn",
        "languages": [
          "tsn-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001696,
        "recall": 0.005008,
        "f1": 0.002005,
        "accuracy": 0.005008,
        "main_score": 0.002005,
        "hf_subset": "tsn_Latn-tir_Ethi",
        "languages": [
          "tsn-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.006254,
        "recall": 0.008513,
        "f1": 0.006735,
        "accuracy": 0.008513,
        "main_score": 0.006735,
        "hf_subset": "tsn_Latn-wol_Latn",
        "languages": [
          "tsn-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.005747,
        "recall": 0.009014,
        "f1": 0.006105,
        "accuracy": 0.009014,
        "main_score": 0.006105,
        "hf_subset": "tsn_Latn-xho_Latn",
        "languages": [
          "tsn-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.004994,
        "recall": 0.007511,
        "f1": 0.00524,
        "accuracy": 0.007511,
        "main_score": 0.00524,
        "hf_subset": "tsn_Latn-yor_Latn",
        "languages": [
          "tsn-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.009905,
        "recall": 0.014522,
        "f1": 0.010442,
        "accuracy": 0.014522,
        "main_score": 0.010442,
        "hf_subset": "tsn_Latn-zul_Latn",
        "languages": [
          "tsn-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.009417,
        "recall": 0.022534,
        "f1": 0.010709,
        "accuracy": 0.022534,
        "main_score": 0.010709,
        "hf_subset": "tuk_Latn-aze_Latn",
        "languages": [
          "tuk-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.00152,
        "recall": 0.003005,
        "f1": 0.001538,
        "accuracy": 0.003005,
        "main_score": 0.001538,
        "hf_subset": "tuk_Latn-bak_Cyrl",
        "languages": [
          "tuk-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.01055,
        "recall": 0.017026,
        "f1": 0.011208,
        "accuracy": 0.017026,
        "main_score": 0.011208,
        "hf_subset": "tuk_Latn-eng_Latn",
        "languages": [
          "tuk-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001898,
        "recall": 0.006009,
        "f1": 0.002212,
        "accuracy": 0.006009,
        "main_score": 0.002212,
        "hf_subset": "tuk_Latn-kaz_Cyrl",
        "languages": [
          "tuk-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.002024,
        "recall": 0.00651,
        "f1": 0.00255,
        "accuracy": 0.00651,
        "main_score": 0.00255,
        "hf_subset": "tuk_Latn-kir_Cyrl",
        "languages": [
          "tuk-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.001851,
        "recall": 0.003505,
        "f1": 0.002013,
        "accuracy": 0.003505,
        "main_score": 0.002013,
        "hf_subset": "tuk_Latn-tat_Cyrl",
        "languages": [
          "tuk-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.023495,
        "recall": 0.03305,
        "f1": 0.025014,
        "accuracy": 0.03305,
        "main_score": 0.025014,
        "hf_subset": "tuk_Latn-tur_Latn",
        "languages": [
          "tuk-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 5.6e-05,
        "recall": 0.000501,
        "f1": 0.0001,
        "accuracy": 0.000501,
        "main_score": 0.0001,
        "hf_subset": "tuk_Latn-uig_Arab",
        "languages": [
          "tuk-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.013982,
        "recall": 0.024036,
        "f1": 0.01548,
        "accuracy": 0.024036,
        "main_score": 0.01548,
        "hf_subset": "tuk_Latn-uzb_Latn",
        "languages": [
          "tuk-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000503,
        "accuracy": 0.001002,
        "main_score": 0.000503,
        "hf_subset": "tur_Latn-arb_Arab",
        "languages": [
          "tur-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.015739,
        "recall": 0.031547,
        "f1": 0.017805,
        "accuracy": 0.031547,
        "main_score": 0.017805,
        "hf_subset": "tur_Latn-aze_Latn",
        "languages": [
          "tur-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.000447,
        "recall": 0.001502,
        "f1": 0.00064,
        "accuracy": 0.001502,
        "main_score": 0.00064,
        "hf_subset": "tur_Latn-bak_Cyrl",
        "languages": [
          "tur-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 1.4e-05,
        "recall": 0.001002,
        "f1": 2.6e-05,
        "accuracy": 0.001002,
        "main_score": 2.6e-05,
        "hf_subset": "tur_Latn-ben_Beng",
        "languages": [
          "tur-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.008204,
        "recall": 0.012018,
        "f1": 0.008786,
        "accuracy": 0.012018,
        "main_score": 0.008786,
        "hf_subset": "tur_Latn-deu_Latn",
        "languages": [
          "tur-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000171,
        "recall": 0.001502,
        "f1": 0.000258,
        "accuracy": 0.001502,
        "main_score": 0.000258,
        "hf_subset": "tur_Latn-ell_Grek",
        "languages": [
          "tur-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.007865,
        "recall": 0.016024,
        "f1": 0.008863,
        "accuracy": 0.016024,
        "main_score": 0.008863,
        "hf_subset": "tur_Latn-eng_Latn",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000569,
        "recall": 0.003505,
        "f1": 0.000631,
        "accuracy": 0.003505,
        "main_score": 0.000631,
        "hf_subset": "tur_Latn-fas_Arab",
        "languages": [
          "tur-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.006851,
        "recall": 0.011517,
        "f1": 0.007121,
        "accuracy": 0.011517,
        "main_score": 0.007121,
        "hf_subset": "tur_Latn-fin_Latn",
        "languages": [
          "tur-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.008329,
        "recall": 0.01352,
        "f1": 0.009062,
        "accuracy": 0.01352,
        "main_score": 0.009062,
        "hf_subset": "tur_Latn-fra_Latn",
        "languages": [
          "tur-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000709,
        "recall": 0.003005,
        "f1": 0.001035,
        "accuracy": 0.003005,
        "main_score": 0.001035,
        "hf_subset": "tur_Latn-heb_Hebr",
        "languages": [
          "tur-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.001064,
        "recall": 0.001502,
        "f1": 0.001113,
        "accuracy": 0.001502,
        "main_score": 0.001113,
        "hf_subset": "tur_Latn-hin_Deva",
        "languages": [
          "tur-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00767,
        "recall": 0.011017,
        "f1": 0.008179,
        "accuracy": 0.011017,
        "main_score": 0.008179,
        "hf_subset": "tur_Latn-hun_Latn",
        "languages": [
          "tur-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.007345,
        "recall": 0.010015,
        "f1": 0.007744,
        "accuracy": 0.010015,
        "main_score": 0.007744,
        "hf_subset": "tur_Latn-ind_Latn",
        "languages": [
          "tur-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000407,
        "recall": 0.002003,
        "f1": 0.000603,
        "accuracy": 0.002003,
        "main_score": 0.000603,
        "hf_subset": "tur_Latn-jpn_Jpan",
        "languages": [
          "tur-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001463,
        "recall": 0.003505,
        "f1": 0.001757,
        "accuracy": 0.003505,
        "main_score": 0.001757,
        "hf_subset": "tur_Latn-kaz_Cyrl",
        "languages": [
          "tur-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.003753,
        "recall": 0.008012,
        "f1": 0.004362,
        "accuracy": 0.008012,
        "main_score": 0.004362,
        "hf_subset": "tur_Latn-kir_Cyrl",
        "languages": [
          "tur-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.000312,
        "recall": 0.002504,
        "f1": 0.00045,
        "accuracy": 0.002504,
        "main_score": 0.00045,
        "hf_subset": "tur_Latn-kor_Hang",
        "languages": [
          "tur-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.004848,
        "recall": 0.00651,
        "f1": 0.005062,
        "accuracy": 0.00651,
        "main_score": 0.005062,
        "hf_subset": "tur_Latn-lit_Latn",
        "languages": [
          "tur-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.008045,
        "recall": 0.011017,
        "f1": 0.008338,
        "accuracy": 0.011017,
        "main_score": 0.008338,
        "hf_subset": "tur_Latn-nld_Latn",
        "languages": [
          "tur-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.006589,
        "recall": 0.011017,
        "f1": 0.007098,
        "accuracy": 0.011017,
        "main_score": 0.007098,
        "hf_subset": "tur_Latn-pol_Latn",
        "languages": [
          "tur-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.008586,
        "recall": 0.014522,
        "f1": 0.009082,
        "accuracy": 0.014522,
        "main_score": 0.009082,
        "hf_subset": "tur_Latn-por_Latn",
        "languages": [
          "tur-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000835,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "tur_Latn-rus_Cyrl",
        "languages": [
          "tur-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.007739,
        "recall": 0.009514,
        "f1": 0.008043,
        "accuracy": 0.009514,
        "main_score": 0.008043,
        "hf_subset": "tur_Latn-spa_Latn",
        "languages": [
          "tur-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.006656,
        "recall": 0.011017,
        "f1": 0.007184,
        "accuracy": 0.011017,
        "main_score": 0.007184,
        "hf_subset": "tur_Latn-swa_Latn",
        "languages": [
          "tur-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.007353,
        "recall": 0.011517,
        "f1": 0.007939,
        "accuracy": 0.011517,
        "main_score": 0.007939,
        "hf_subset": "tur_Latn-swe_Latn",
        "languages": [
          "tur-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000884,
        "recall": 0.002504,
        "f1": 0.001109,
        "accuracy": 0.002504,
        "main_score": 0.001109,
        "hf_subset": "tur_Latn-tam_Taml",
        "languages": [
          "tur-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.00101,
        "recall": 0.002504,
        "f1": 0.001271,
        "accuracy": 0.002504,
        "main_score": 0.001271,
        "hf_subset": "tur_Latn-tat_Cyrl",
        "languages": [
          "tur-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.011966,
        "recall": 0.020531,
        "f1": 0.013232,
        "accuracy": 0.020531,
        "main_score": 0.013232,
        "hf_subset": "tur_Latn-tuk_Latn",
        "languages": [
          "tur-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.000708,
        "recall": 0.002003,
        "f1": 0.000851,
        "accuracy": 0.002003,
        "main_score": 0.000851,
        "hf_subset": "tur_Latn-uig_Arab",
        "languages": [
          "tur-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.005725,
        "recall": 0.011017,
        "f1": 0.006482,
        "accuracy": 0.011017,
        "main_score": 0.006482,
        "hf_subset": "tur_Latn-uzb_Latn",
        "languages": [
          "tur-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.002199,
        "recall": 0.006009,
        "f1": 0.002682,
        "accuracy": 0.006009,
        "main_score": 0.002682,
        "hf_subset": "tur_Latn-vie_Latn",
        "languages": [
          "tur-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.010378,
        "recall": 0.021532,
        "f1": 0.011846,
        "accuracy": 0.021532,
        "main_score": 0.011846,
        "hf_subset": "tur_Latn-zho_Hant",
        "languages": [
          "tur-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.006478,
        "recall": 0.008513,
        "f1": 0.006718,
        "accuracy": 0.008513,
        "main_score": 0.006718,
        "hf_subset": "tur_Latn-zul_Latn",
        "languages": [
          "tur-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 9.5e-05,
        "recall": 0.001502,
        "f1": 0.000166,
        "accuracy": 0.001502,
        "main_score": 0.000166,
        "hf_subset": "uig_Arab-aze_Latn",
        "languages": [
          "uig-Arab",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.000507,
        "recall": 0.001002,
        "f1": 0.000513,
        "accuracy": 0.001002,
        "main_score": 0.000513,
        "hf_subset": "uig_Arab-bak_Cyrl",
        "languages": [
          "uig-Arab",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.001127,
        "recall": 0.002003,
        "f1": 0.001202,
        "accuracy": 0.002003,
        "main_score": 0.001202,
        "hf_subset": "uig_Arab-eng_Latn",
        "languages": [
          "uig-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000896,
        "recall": 0.003505,
        "f1": 0.001154,
        "accuracy": 0.003505,
        "main_score": 0.001154,
        "hf_subset": "uig_Arab-kaz_Cyrl",
        "languages": [
          "uig-Arab",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.000589,
        "recall": 0.003005,
        "f1": 0.000669,
        "accuracy": 0.003005,
        "main_score": 0.000669,
        "hf_subset": "uig_Arab-kir_Cyrl",
        "languages": [
          "uig-Arab",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "uig_Arab-tat_Cyrl",
        "languages": [
          "uig-Arab",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "uig_Arab-tuk_Latn",
        "languages": [
          "uig-Arab",
          "tuk-Latn"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.001002,
        "f1": 1.8e-05,
        "accuracy": 0.001002,
        "main_score": 1.8e-05,
        "hf_subset": "uig_Arab-tur_Latn",
        "languages": [
          "uig-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 2.8e-05,
        "recall": 0.001502,
        "f1": 5.3e-05,
        "accuracy": 0.001502,
        "main_score": 5.3e-05,
        "hf_subset": "uig_Arab-uzb_Latn",
        "languages": [
          "uig-Arab",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.039713,
        "recall": 0.063095,
        "f1": 0.043328,
        "accuracy": 0.063095,
        "main_score": 0.043328,
        "hf_subset": "ukr_Cyrl-bel_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.000513,
        "recall": 0.002504,
        "f1": 0.000526,
        "accuracy": 0.002504,
        "main_score": 0.000526,
        "hf_subset": "ukr_Cyrl-bos_Latn",
        "languages": [
          "ukr-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.011451,
        "recall": 0.021032,
        "f1": 0.012905,
        "accuracy": 0.021032,
        "main_score": 0.012905,
        "hf_subset": "ukr_Cyrl-bul_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001002,
        "f1": 0.001002,
        "accuracy": 0.001002,
        "main_score": 0.001002,
        "hf_subset": "ukr_Cyrl-ces_Latn",
        "languages": [
          "ukr-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.001003,
        "recall": 0.002003,
        "f1": 0.001004,
        "accuracy": 0.002003,
        "main_score": 0.001004,
        "hf_subset": "ukr_Cyrl-eng_Latn",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000677,
        "recall": 0.002003,
        "f1": 0.00077,
        "accuracy": 0.002003,
        "main_score": 0.00077,
        "hf_subset": "ukr_Cyrl-hrv_Latn",
        "languages": [
          "ukr-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.011129,
        "recall": 0.019029,
        "f1": 0.012302,
        "accuracy": 0.019029,
        "main_score": 0.012302,
        "hf_subset": "ukr_Cyrl-mkd_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001502,
        "f1": 1.1e-05,
        "accuracy": 0.001502,
        "main_score": 1.1e-05,
        "hf_subset": "ukr_Cyrl-pol_Latn",
        "languages": [
          "ukr-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.037484,
        "recall": 0.056585,
        "f1": 0.041173,
        "accuracy": 0.056585,
        "main_score": 0.041173,
        "hf_subset": "ukr_Cyrl-rus_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.000526,
        "recall": 0.002003,
        "f1": 0.000549,
        "accuracy": 0.002003,
        "main_score": 0.000549,
        "hf_subset": "ukr_Cyrl-slk_Latn",
        "languages": [
          "ukr-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "ukr_Cyrl-slv_Latn",
        "languages": [
          "ukr-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.007235,
        "recall": 0.01352,
        "f1": 0.008227,
        "accuracy": 0.01352,
        "main_score": 0.008227,
        "hf_subset": "ukr_Cyrl-srp_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.000521,
        "recall": 0.003005,
        "f1": 0.000541,
        "accuracy": 0.003005,
        "main_score": 0.000541,
        "hf_subset": "ukr_Cyrl-srp_Latn",
        "languages": [
          "ukr-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001002,
        "f1": 1.2e-05,
        "accuracy": 0.001002,
        "main_score": 1.2e-05,
        "hf_subset": "urd_Arab-div_Thaa",
        "languages": [
          "urd-Arab",
          "div-Thaa"
        ]
      },
      {
        "precision": 7.9e-05,
        "recall": 0.002504,
        "f1": 0.00014,
        "accuracy": 0.002504,
        "main_score": 0.00014,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "urd_Arab-eus_Latn",
        "languages": [
          "urd-Arab",
          "eus-Latn"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.000501,
        "f1": 5e-06,
        "accuracy": 0.000501,
        "main_score": 5e-06,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000619,
        "recall": 0.003505,
        "f1": 0.000722,
        "accuracy": 0.003505,
        "main_score": 0.000722,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 2.2e-05,
        "recall": 0.001502,
        "f1": 4.3e-05,
        "accuracy": 0.001502,
        "main_score": 4.3e-05,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001002,
        "f1": 9e-06,
        "accuracy": 0.001002,
        "main_score": 9e-06,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00025,
        "recall": 0.000501,
        "f1": 0.000334,
        "accuracy": 0.000501,
        "main_score": 0.000334,
        "hf_subset": "urd_Arab-nep_Deva",
        "languages": [
          "urd-Arab",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.000501,
        "f1": 1.4e-05,
        "accuracy": 0.000501,
        "main_score": 1.4e-05,
        "hf_subset": "urd_Arab-sin_Sinh",
        "languages": [
          "urd-Arab",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.001795,
        "recall": 0.004507,
        "f1": 0.002149,
        "accuracy": 0.004507,
        "main_score": 0.002149,
        "hf_subset": "urd_Arab-snd_Arab",
        "languages": [
          "urd-Arab",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.000513,
        "recall": 0.001502,
        "f1": 0.000525,
        "accuracy": 0.001502,
        "main_score": 0.000525,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.009228,
        "recall": 0.018027,
        "f1": 0.011012,
        "accuracy": 0.018027,
        "main_score": 0.011012,
        "hf_subset": "uzb_Latn-aze_Latn",
        "languages": [
          "uzb-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.001523,
        "recall": 0.002003,
        "f1": 0.001542,
        "accuracy": 0.002003,
        "main_score": 0.001542,
        "hf_subset": "uzb_Latn-bak_Cyrl",
        "languages": [
          "uzb-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.003449,
        "recall": 0.007011,
        "f1": 0.003734,
        "accuracy": 0.007011,
        "main_score": 0.003734,
        "hf_subset": "uzb_Latn-eng_Latn",
        "languages": [
          "uzb-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001587,
        "recall": 0.003005,
        "f1": 0.001825,
        "accuracy": 0.003005,
        "main_score": 0.001825,
        "hf_subset": "uzb_Latn-kaz_Cyrl",
        "languages": [
          "uzb-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.002071,
        "recall": 0.005508,
        "f1": 0.002406,
        "accuracy": 0.005508,
        "main_score": 0.002406,
        "hf_subset": "uzb_Latn-kir_Cyrl",
        "languages": [
          "uzb-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.002042,
        "recall": 0.005008,
        "f1": 0.002493,
        "accuracy": 0.005008,
        "main_score": 0.002493,
        "hf_subset": "uzb_Latn-tat_Cyrl",
        "languages": [
          "uzb-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.013113,
        "recall": 0.022534,
        "f1": 0.014575,
        "accuracy": 0.022534,
        "main_score": 0.014575,
        "hf_subset": "uzb_Latn-tuk_Latn",
        "languages": [
          "uzb-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.00732,
        "recall": 0.012018,
        "f1": 0.00796,
        "accuracy": 0.012018,
        "main_score": 0.00796,
        "hf_subset": "uzb_Latn-tur_Latn",
        "languages": [
          "uzb-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.001588,
        "recall": 0.002504,
        "f1": 0.001657,
        "accuracy": 0.002504,
        "main_score": 0.001657,
        "hf_subset": "uzb_Latn-uig_Arab",
        "languages": [
          "uzb-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.009967,
        "recall": 0.015523,
        "f1": 0.010607,
        "accuracy": 0.015523,
        "main_score": 0.010607,
        "hf_subset": "ven_Latn-bem_Latn",
        "languages": [
          "ven-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.018021,
        "recall": 0.024036,
        "f1": 0.018885,
        "accuracy": 0.024036,
        "main_score": 0.018885,
        "hf_subset": "ven_Latn-eng_Latn",
        "languages": [
          "ven-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0065,
        "recall": 0.009514,
        "f1": 0.007106,
        "accuracy": 0.009514,
        "main_score": 0.007106,
        "hf_subset": "ven_Latn-ewe_Latn",
        "languages": [
          "ven-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.009901,
        "recall": 0.015023,
        "f1": 0.010779,
        "accuracy": 0.015023,
        "main_score": 0.010779,
        "hf_subset": "ven_Latn-fuc_Latn",
        "languages": [
          "ven-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.010444,
        "recall": 0.017026,
        "f1": 0.011538,
        "accuracy": 0.017026,
        "main_score": 0.011538,
        "hf_subset": "ven_Latn-kin_Latn",
        "languages": [
          "ven-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.005572,
        "recall": 0.009014,
        "f1": 0.005907,
        "accuracy": 0.009014,
        "main_score": 0.005907,
        "hf_subset": "ven_Latn-nde_Latn",
        "languages": [
          "ven-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.012688,
        "recall": 0.019029,
        "f1": 0.013569,
        "accuracy": 0.019029,
        "main_score": 0.013569,
        "hf_subset": "ven_Latn-nya_Latn",
        "languages": [
          "ven-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.007493,
        "recall": 0.011017,
        "f1": 0.007976,
        "accuracy": 0.011017,
        "main_score": 0.007976,
        "hf_subset": "ven_Latn-sna_Latn",
        "languages": [
          "ven-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 7.2e-05,
        "recall": 0.000501,
        "f1": 0.000125,
        "accuracy": 0.000501,
        "main_score": 0.000125,
        "hf_subset": "vie_Latn-arb_Arab",
        "languages": [
          "vie-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000504,
        "accuracy": 0.001002,
        "main_score": 0.000504,
        "hf_subset": "vie_Latn-ben_Beng",
        "languages": [
          "vie-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.008791,
        "recall": 0.012018,
        "f1": 0.009372,
        "accuracy": 0.012018,
        "main_score": 0.009372,
        "hf_subset": "vie_Latn-deu_Latn",
        "languages": [
          "vie-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 2.3e-05,
        "recall": 0.001502,
        "f1": 4.5e-05,
        "accuracy": 0.001502,
        "main_score": 4.5e-05,
        "hf_subset": "vie_Latn-ell_Grek",
        "languages": [
          "vie-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.012938,
        "recall": 0.019529,
        "f1": 0.01401,
        "accuracy": 0.019529,
        "main_score": 0.01401,
        "hf_subset": "vie_Latn-eng_Latn",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001835,
        "recall": 0.003505,
        "f1": 0.002041,
        "accuracy": 0.003505,
        "main_score": 0.002041,
        "hf_subset": "vie_Latn-fas_Arab",
        "languages": [
          "vie-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.007518,
        "recall": 0.011517,
        "f1": 0.007933,
        "accuracy": 0.011517,
        "main_score": 0.007933,
        "hf_subset": "vie_Latn-fin_Latn",
        "languages": [
          "vie-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.011705,
        "recall": 0.020531,
        "f1": 0.013047,
        "accuracy": 0.020531,
        "main_score": 0.013047,
        "hf_subset": "vie_Latn-fra_Latn",
        "languages": [
          "vie-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.000417,
        "recall": 0.001002,
        "f1": 0.000584,
        "accuracy": 0.001002,
        "main_score": 0.000584,
        "hf_subset": "vie_Latn-heb_Hebr",
        "languages": [
          "vie-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "vie_Latn-hin_Deva",
        "languages": [
          "vie-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00453,
        "recall": 0.00651,
        "f1": 0.004769,
        "accuracy": 0.00651,
        "main_score": 0.004769,
        "hf_subset": "vie_Latn-hun_Latn",
        "languages": [
          "vie-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.007907,
        "recall": 0.011017,
        "f1": 0.00843,
        "accuracy": 0.011017,
        "main_score": 0.00843,
        "hf_subset": "vie_Latn-ind_Latn",
        "languages": [
          "vie-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "vie_Latn-jpn_Jpan",
        "languages": [
          "vie-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.002012,
        "recall": 0.003505,
        "f1": 0.002253,
        "accuracy": 0.003505,
        "main_score": 0.002253,
        "hf_subset": "vie_Latn-kor_Hang",
        "languages": [
          "vie-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.003178,
        "recall": 0.00651,
        "f1": 0.003507,
        "accuracy": 0.00651,
        "main_score": 0.003507,
        "hf_subset": "vie_Latn-lit_Latn",
        "languages": [
          "vie-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.009763,
        "recall": 0.014522,
        "f1": 0.010257,
        "accuracy": 0.014522,
        "main_score": 0.010257,
        "hf_subset": "vie_Latn-nld_Latn",
        "languages": [
          "vie-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.003478,
        "recall": 0.006009,
        "f1": 0.00371,
        "accuracy": 0.006009,
        "main_score": 0.00371,
        "hf_subset": "vie_Latn-pol_Latn",
        "languages": [
          "vie-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.009032,
        "recall": 0.010516,
        "f1": 0.009267,
        "accuracy": 0.010516,
        "main_score": 0.009267,
        "hf_subset": "vie_Latn-por_Latn",
        "languages": [
          "vie-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 5.6e-05,
        "recall": 0.000501,
        "f1": 0.0001,
        "accuracy": 0.000501,
        "main_score": 0.0001,
        "hf_subset": "vie_Latn-rus_Cyrl",
        "languages": [
          "vie-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.009484,
        "recall": 0.014021,
        "f1": 0.009915,
        "accuracy": 0.014021,
        "main_score": 0.009915,
        "hf_subset": "vie_Latn-spa_Latn",
        "languages": [
          "vie-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.007907,
        "recall": 0.011017,
        "f1": 0.008273,
        "accuracy": 0.011017,
        "main_score": 0.008273,
        "hf_subset": "vie_Latn-swa_Latn",
        "languages": [
          "vie-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.007364,
        "recall": 0.011517,
        "f1": 0.00793,
        "accuracy": 0.011517,
        "main_score": 0.00793,
        "hf_subset": "vie_Latn-swe_Latn",
        "languages": [
          "vie-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "vie_Latn-tam_Taml",
        "languages": [
          "vie-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.008111,
        "recall": 0.011017,
        "f1": 0.008853,
        "accuracy": 0.011017,
        "main_score": 0.008853,
        "hf_subset": "vie_Latn-tur_Latn",
        "languages": [
          "vie-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.001141,
        "recall": 0.002504,
        "f1": 0.001249,
        "accuracy": 0.002504,
        "main_score": 0.001249,
        "hf_subset": "vie_Latn-yue_Hant",
        "languages": [
          "vie-Latn",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.00706,
        "recall": 0.014021,
        "f1": 0.007798,
        "accuracy": 0.014021,
        "main_score": 0.007798,
        "hf_subset": "vie_Latn-zho_Hans",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.016775,
        "recall": 0.027541,
        "f1": 0.018107,
        "accuracy": 0.027541,
        "main_score": 0.018107,
        "hf_subset": "vie_Latn-zho_Hant",
        "languages": [
          "vie-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.007893,
        "recall": 0.010516,
        "f1": 0.008557,
        "accuracy": 0.010516,
        "main_score": 0.008557,
        "hf_subset": "vie_Latn-zul_Latn",
        "languages": [
          "vie-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.003793,
        "recall": 0.006009,
        "f1": 0.004137,
        "accuracy": 0.006009,
        "main_score": 0.004137,
        "hf_subset": "wol_Latn-amh_Ethi",
        "languages": [
          "wol-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.018875,
        "recall": 0.027041,
        "f1": 0.019974,
        "accuracy": 0.027041,
        "main_score": 0.019974,
        "hf_subset": "wol_Latn-eng_Latn",
        "languages": [
          "wol-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012866,
        "recall": 0.015523,
        "f1": 0.013418,
        "accuracy": 0.015523,
        "main_score": 0.013418,
        "hf_subset": "wol_Latn-hau_Latn",
        "languages": [
          "wol-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.010795,
        "recall": 0.015023,
        "f1": 0.011475,
        "accuracy": 0.015023,
        "main_score": 0.011475,
        "hf_subset": "wol_Latn-ibo_Latn",
        "languages": [
          "wol-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.008084,
        "recall": 0.014522,
        "f1": 0.008839,
        "accuracy": 0.014522,
        "main_score": 0.008839,
        "hf_subset": "wol_Latn-nso_Latn",
        "languages": [
          "wol-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.003975,
        "recall": 0.00651,
        "f1": 0.00444,
        "accuracy": 0.00651,
        "main_score": 0.00444,
        "hf_subset": "wol_Latn-orm_Ethi",
        "languages": [
          "wol-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.011214,
        "recall": 0.015023,
        "f1": 0.011699,
        "accuracy": 0.015023,
        "main_score": 0.011699,
        "hf_subset": "wol_Latn-som_Latn",
        "languages": [
          "wol-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.003954,
        "recall": 0.008012,
        "f1": 0.004634,
        "accuracy": 0.008012,
        "main_score": 0.004634,
        "hf_subset": "wol_Latn-ssw_Latn",
        "languages": [
          "wol-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.007187,
        "recall": 0.01302,
        "f1": 0.008388,
        "accuracy": 0.01302,
        "main_score": 0.008388,
        "hf_subset": "wol_Latn-swa_Latn",
        "languages": [
          "wol-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001656,
        "recall": 0.005008,
        "f1": 0.001782,
        "accuracy": 0.005008,
        "main_score": 0.001782,
        "hf_subset": "wol_Latn-tir_Ethi",
        "languages": [
          "wol-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.009069,
        "recall": 0.014522,
        "f1": 0.009681,
        "accuracy": 0.014522,
        "main_score": 0.009681,
        "hf_subset": "wol_Latn-tsn_Latn",
        "languages": [
          "wol-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.007113,
        "recall": 0.011017,
        "f1": 0.007436,
        "accuracy": 0.011017,
        "main_score": 0.007436,
        "hf_subset": "wol_Latn-xho_Latn",
        "languages": [
          "wol-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.009337,
        "recall": 0.017026,
        "f1": 0.010684,
        "accuracy": 0.017026,
        "main_score": 0.010684,
        "hf_subset": "wol_Latn-yor_Latn",
        "languages": [
          "wol-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.01055,
        "recall": 0.017526,
        "f1": 0.011507,
        "accuracy": 0.017526,
        "main_score": 0.011507,
        "hf_subset": "wol_Latn-zul_Latn",
        "languages": [
          "wol-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.001614,
        "recall": 0.005008,
        "f1": 0.001961,
        "accuracy": 0.005008,
        "main_score": 0.001961,
        "hf_subset": "xho_Latn-amh_Ethi",
        "languages": [
          "xho-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.009305,
        "recall": 0.016024,
        "f1": 0.009799,
        "accuracy": 0.016024,
        "main_score": 0.009799,
        "hf_subset": "xho_Latn-eng_Latn",
        "languages": [
          "xho-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005016,
        "recall": 0.009014,
        "f1": 0.005591,
        "accuracy": 0.009014,
        "main_score": 0.005591,
        "hf_subset": "xho_Latn-hau_Latn",
        "languages": [
          "xho-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.007148,
        "recall": 0.009014,
        "f1": 0.007262,
        "accuracy": 0.009014,
        "main_score": 0.007262,
        "hf_subset": "xho_Latn-ibo_Latn",
        "languages": [
          "xho-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.007401,
        "recall": 0.010516,
        "f1": 0.007927,
        "accuracy": 0.010516,
        "main_score": 0.007927,
        "hf_subset": "xho_Latn-nso_Latn",
        "languages": [
          "xho-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.003505,
        "recall": 0.004006,
        "f1": 0.003672,
        "accuracy": 0.004006,
        "main_score": 0.003672,
        "hf_subset": "xho_Latn-orm_Ethi",
        "languages": [
          "xho-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.004928,
        "recall": 0.007511,
        "f1": 0.00515,
        "accuracy": 0.007511,
        "main_score": 0.00515,
        "hf_subset": "xho_Latn-som_Latn",
        "languages": [
          "xho-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.040588,
        "recall": 0.057586,
        "f1": 0.044118,
        "accuracy": 0.057586,
        "main_score": 0.044118,
        "hf_subset": "xho_Latn-ssw_Latn",
        "languages": [
          "xho-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.007195,
        "recall": 0.009514,
        "f1": 0.00753,
        "accuracy": 0.009514,
        "main_score": 0.00753,
        "hf_subset": "xho_Latn-swa_Latn",
        "languages": [
          "xho-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001095,
        "recall": 0.003005,
        "f1": 0.001174,
        "accuracy": 0.003005,
        "main_score": 0.001174,
        "hf_subset": "xho_Latn-tir_Ethi",
        "languages": [
          "xho-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.005562,
        "recall": 0.007011,
        "f1": 0.005815,
        "accuracy": 0.007011,
        "main_score": 0.005815,
        "hf_subset": "xho_Latn-tsn_Latn",
        "languages": [
          "xho-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.004194,
        "recall": 0.005008,
        "f1": 0.004318,
        "accuracy": 0.005008,
        "main_score": 0.004318,
        "hf_subset": "xho_Latn-wol_Latn",
        "languages": [
          "xho-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.004582,
        "recall": 0.007511,
        "f1": 0.004903,
        "accuracy": 0.007511,
        "main_score": 0.004903,
        "hf_subset": "xho_Latn-yor_Latn",
        "languages": [
          "xho-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.085003,
        "recall": 0.117677,
        "f1": 0.092187,
        "accuracy": 0.117677,
        "main_score": 0.092187,
        "hf_subset": "xho_Latn-zul_Latn",
        "languages": [
          "xho-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.004616,
        "recall": 0.008513,
        "f1": 0.004966,
        "accuracy": 0.008513,
        "main_score": 0.004966,
        "hf_subset": "yor_Latn-amh_Ethi",
        "languages": [
          "yor-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.013522,
        "recall": 0.022534,
        "f1": 0.014876,
        "accuracy": 0.022534,
        "main_score": 0.014876,
        "hf_subset": "yor_Latn-eng_Latn",
        "languages": [
          "yor-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008988,
        "recall": 0.011517,
        "f1": 0.009531,
        "accuracy": 0.011517,
        "main_score": 0.009531,
        "hf_subset": "yor_Latn-hau_Latn",
        "languages": [
          "yor-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.00958,
        "recall": 0.011517,
        "f1": 0.00964,
        "accuracy": 0.011517,
        "main_score": 0.00964,
        "hf_subset": "yor_Latn-ibo_Latn",
        "languages": [
          "yor-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.007204,
        "recall": 0.01302,
        "f1": 0.008061,
        "accuracy": 0.01302,
        "main_score": 0.008061,
        "hf_subset": "yor_Latn-nso_Latn",
        "languages": [
          "yor-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.002969,
        "recall": 0.006009,
        "f1": 0.003399,
        "accuracy": 0.006009,
        "main_score": 0.003399,
        "hf_subset": "yor_Latn-orm_Ethi",
        "languages": [
          "yor-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.007687,
        "recall": 0.010516,
        "f1": 0.008042,
        "accuracy": 0.010516,
        "main_score": 0.008042,
        "hf_subset": "yor_Latn-som_Latn",
        "languages": [
          "yor-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.005942,
        "recall": 0.010516,
        "f1": 0.006607,
        "accuracy": 0.010516,
        "main_score": 0.006607,
        "hf_subset": "yor_Latn-ssw_Latn",
        "languages": [
          "yor-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.010237,
        "recall": 0.01352,
        "f1": 0.010924,
        "accuracy": 0.01352,
        "main_score": 0.010924,
        "hf_subset": "yor_Latn-swa_Latn",
        "languages": [
          "yor-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001323,
        "recall": 0.003505,
        "f1": 0.00147,
        "accuracy": 0.003505,
        "main_score": 0.00147,
        "hf_subset": "yor_Latn-tir_Ethi",
        "languages": [
          "yor-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.007052,
        "recall": 0.011517,
        "f1": 0.007532,
        "accuracy": 0.011517,
        "main_score": 0.007532,
        "hf_subset": "yor_Latn-tsn_Latn",
        "languages": [
          "yor-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.006916,
        "recall": 0.009014,
        "f1": 0.007445,
        "accuracy": 0.009014,
        "main_score": 0.007445,
        "hf_subset": "yor_Latn-wol_Latn",
        "languages": [
          "yor-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.004667,
        "recall": 0.008012,
        "f1": 0.004968,
        "accuracy": 0.008012,
        "main_score": 0.004968,
        "hf_subset": "yor_Latn-xho_Latn",
        "languages": [
          "yor-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.006121,
        "recall": 0.011017,
        "f1": 0.006854,
        "accuracy": 0.011017,
        "main_score": 0.006854,
        "hf_subset": "yor_Latn-zul_Latn",
        "languages": [
          "yor-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.007455,
        "recall": 0.012519,
        "f1": 0.007948,
        "accuracy": 0.012519,
        "main_score": 0.007948,
        "hf_subset": "yue_Hant-eng_Latn",
        "languages": [
          "yue-Hant",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006695,
        "recall": 0.018528,
        "f1": 0.008295,
        "accuracy": 0.018528,
        "main_score": 0.008295,
        "hf_subset": "yue_Hant-jpn_Jpan",
        "languages": [
          "yue-Hant",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 3.1e-05,
        "recall": 0.001502,
        "f1": 6.1e-05,
        "accuracy": 0.001502,
        "main_score": 6.1e-05,
        "hf_subset": "yue_Hant-kor_Hang",
        "languages": [
          "yue-Hant",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.002125,
        "recall": 0.004507,
        "f1": 0.002386,
        "accuracy": 0.004507,
        "main_score": 0.002386,
        "hf_subset": "yue_Hant-vie_Latn",
        "languages": [
          "yue-Hant",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.283259,
        "recall": 0.370055,
        "f1": 0.304686,
        "accuracy": 0.370055,
        "main_score": 0.304686,
        "hf_subset": "yue_Hant-zho_Hans",
        "languages": [
          "yue-Hant",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.255275,
        "recall": 0.344517,
        "f1": 0.276507,
        "accuracy": 0.344517,
        "main_score": 0.276507,
        "hf_subset": "yue_Hant-zho_Hant",
        "languages": [
          "yue-Hant",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.029524,
        "recall": 0.038558,
        "f1": 0.03119,
        "accuracy": 0.038558,
        "main_score": 0.03119,
        "hf_subset": "zho_Hans-eng_Latn",
        "languages": [
          "zho-Hans",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006696,
        "recall": 0.018027,
        "f1": 0.007888,
        "accuracy": 0.018027,
        "main_score": 0.007888,
        "hf_subset": "zho_Hans-jpn_Jpan",
        "languages": [
          "zho-Hans",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.001365,
        "recall": 0.005008,
        "f1": 0.001628,
        "accuracy": 0.005008,
        "main_score": 0.001628,
        "hf_subset": "zho_Hans-kor_Hang",
        "languages": [
          "zho-Hans",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.009436,
        "recall": 0.012519,
        "f1": 0.010038,
        "accuracy": 0.012519,
        "main_score": 0.010038,
        "hf_subset": "zho_Hans-vie_Latn",
        "languages": [
          "zho-Hans",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.284199,
        "recall": 0.348022,
        "f1": 0.300235,
        "accuracy": 0.348022,
        "main_score": 0.300235,
        "hf_subset": "zho_Hans-yue_Hant",
        "languages": [
          "zho-Hans",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.315044,
        "recall": 0.392589,
        "f1": 0.335635,
        "accuracy": 0.392589,
        "main_score": 0.335635,
        "hf_subset": "zho_Hans-zho_Hant",
        "languages": [
          "zho-Hans",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001002,
        "f1": 0.000835,
        "accuracy": 0.001002,
        "main_score": 0.000835,
        "hf_subset": "zho_Hant-arb_Arab",
        "languages": [
          "zho-Hant",
          "arb-Arab"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.000501,
        "f1": 8e-06,
        "accuracy": 0.000501,
        "main_score": 8e-06,
        "hf_subset": "zho_Hant-ben_Beng",
        "languages": [
          "zho-Hant",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.030847,
        "recall": 0.042564,
        "f1": 0.03298,
        "accuracy": 0.042564,
        "main_score": 0.03298,
        "hf_subset": "zho_Hant-deu_Latn",
        "languages": [
          "zho-Hant",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.00106,
        "recall": 0.002504,
        "f1": 0.001318,
        "accuracy": 0.002504,
        "main_score": 0.001318,
        "hf_subset": "zho_Hant-ell_Grek",
        "languages": [
          "zho-Hant",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.07083,
        "recall": 0.086129,
        "f1": 0.073907,
        "accuracy": 0.086129,
        "main_score": 0.073907,
        "hf_subset": "zho_Hant-eng_Latn",
        "languages": [
          "zho-Hant",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003591,
        "recall": 0.008012,
        "f1": 0.004246,
        "accuracy": 0.008012,
        "main_score": 0.004246,
        "hf_subset": "zho_Hant-fas_Arab",
        "languages": [
          "zho-Hant",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.020193,
        "recall": 0.025538,
        "f1": 0.021368,
        "accuracy": 0.025538,
        "main_score": 0.021368,
        "hf_subset": "zho_Hant-fin_Latn",
        "languages": [
          "zho-Hant",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.030775,
        "recall": 0.046069,
        "f1": 0.033424,
        "accuracy": 0.046069,
        "main_score": 0.033424,
        "hf_subset": "zho_Hant-fra_Latn",
        "languages": [
          "zho-Hant",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.001538,
        "recall": 0.004507,
        "f1": 0.001824,
        "accuracy": 0.004507,
        "main_score": 0.001824,
        "hf_subset": "zho_Hant-heb_Hebr",
        "languages": [
          "zho-Hant",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000904,
        "recall": 0.003005,
        "f1": 0.001099,
        "accuracy": 0.003005,
        "main_score": 0.001099,
        "hf_subset": "zho_Hant-hin_Deva",
        "languages": [
          "zho-Hant",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.020898,
        "recall": 0.029044,
        "f1": 0.022126,
        "accuracy": 0.029044,
        "main_score": 0.022126,
        "hf_subset": "zho_Hant-hun_Latn",
        "languages": [
          "zho-Hant",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.024833,
        "recall": 0.03355,
        "f1": 0.026462,
        "accuracy": 0.03355,
        "main_score": 0.026462,
        "hf_subset": "zho_Hant-ind_Latn",
        "languages": [
          "zho-Hant",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.011028,
        "recall": 0.024036,
        "f1": 0.012515,
        "accuracy": 0.024036,
        "main_score": 0.012515,
        "hf_subset": "zho_Hant-jpn_Jpan",
        "languages": [
          "zho-Hant",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.003917,
        "recall": 0.008513,
        "f1": 0.004579,
        "accuracy": 0.008513,
        "main_score": 0.004579,
        "hf_subset": "zho_Hant-kor_Hang",
        "languages": [
          "zho-Hant",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.012479,
        "recall": 0.025538,
        "f1": 0.01465,
        "accuracy": 0.025538,
        "main_score": 0.01465,
        "hf_subset": "zho_Hant-lit_Latn",
        "languages": [
          "zho-Hant",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.026402,
        "recall": 0.039559,
        "f1": 0.028758,
        "accuracy": 0.039559,
        "main_score": 0.028758,
        "hf_subset": "zho_Hant-nld_Latn",
        "languages": [
          "zho-Hant",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.015049,
        "recall": 0.021532,
        "f1": 0.016394,
        "accuracy": 0.021532,
        "main_score": 0.016394,
        "hf_subset": "zho_Hant-pol_Latn",
        "languages": [
          "zho-Hant",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.033374,
        "recall": 0.046069,
        "f1": 0.035723,
        "accuracy": 0.046069,
        "main_score": 0.035723,
        "hf_subset": "zho_Hant-por_Latn",
        "languages": [
          "zho-Hant",
          "por-Latn"
        ]
      },
      {
        "precision": 0.002481,
        "recall": 0.004006,
        "f1": 0.002721,
        "accuracy": 0.004006,
        "main_score": 0.002721,
        "hf_subset": "zho_Hant-rus_Cyrl",
        "languages": [
          "zho-Hant",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.032478,
        "recall": 0.044567,
        "f1": 0.034944,
        "accuracy": 0.044567,
        "main_score": 0.034944,
        "hf_subset": "zho_Hant-spa_Latn",
        "languages": [
          "zho-Hant",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.015366,
        "recall": 0.022534,
        "f1": 0.016942,
        "accuracy": 0.022534,
        "main_score": 0.016942,
        "hf_subset": "zho_Hant-swa_Latn",
        "languages": [
          "zho-Hant",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.029506,
        "recall": 0.042564,
        "f1": 0.032064,
        "accuracy": 0.042564,
        "main_score": 0.032064,
        "hf_subset": "zho_Hant-swe_Latn",
        "languages": [
          "zho-Hant",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001339,
        "recall": 0.004507,
        "f1": 0.00154,
        "accuracy": 0.004507,
        "main_score": 0.00154,
        "hf_subset": "zho_Hant-tam_Taml",
        "languages": [
          "zho-Hant",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.021844,
        "recall": 0.031547,
        "f1": 0.023601,
        "accuracy": 0.031547,
        "main_score": 0.023601,
        "hf_subset": "zho_Hant-tur_Latn",
        "languages": [
          "zho-Hant",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.023415,
        "recall": 0.032048,
        "f1": 0.025386,
        "accuracy": 0.032048,
        "main_score": 0.025386,
        "hf_subset": "zho_Hant-vie_Latn",
        "languages": [
          "zho-Hant",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.274745,
        "recall": 0.340511,
        "f1": 0.291407,
        "accuracy": 0.340511,
        "main_score": 0.291407,
        "hf_subset": "zho_Hant-yue_Hant",
        "languages": [
          "zho-Hant",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.305831,
        "recall": 0.387581,
        "f1": 0.328563,
        "accuracy": 0.387581,
        "main_score": 0.328563,
        "hf_subset": "zho_Hant-zho_Hans",
        "languages": [
          "zho-Hant",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.023684,
        "recall": 0.035553,
        "f1": 0.026067,
        "accuracy": 0.035553,
        "main_score": 0.026067,
        "hf_subset": "zho_Hant-zul_Latn",
        "languages": [
          "zho-Hant",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.005992,
        "recall": 0.010015,
        "f1": 0.006328,
        "accuracy": 0.010015,
        "main_score": 0.006328,
        "hf_subset": "zul_Latn-amh_Ethi",
        "languages": [
          "zul-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 5.1e-05,
        "recall": 0.001002,
        "f1": 9.6e-05,
        "accuracy": 0.001002,
        "main_score": 9.6e-05,
        "hf_subset": "zul_Latn-arb_Arab",
        "languages": [
          "zul-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000335,
        "accuracy": 0.001002,
        "main_score": 0.000335,
        "hf_subset": "zul_Latn-ben_Beng",
        "languages": [
          "zul-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.012948,
        "recall": 0.018027,
        "f1": 0.013684,
        "accuracy": 0.018027,
        "main_score": 0.013684,
        "hf_subset": "zul_Latn-deu_Latn",
        "languages": [
          "zul-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.000169,
        "recall": 0.003005,
        "f1": 0.000311,
        "accuracy": 0.003005,
        "main_score": 0.000311,
        "hf_subset": "zul_Latn-ell_Grek",
        "languages": [
          "zul-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.023568,
        "recall": 0.03355,
        "f1": 0.024751,
        "accuracy": 0.03355,
        "main_score": 0.024751,
        "hf_subset": "zul_Latn-eng_Latn",
        "languages": [
          "zul-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000436,
        "recall": 0.003005,
        "f1": 0.00065,
        "accuracy": 0.003005,
        "main_score": 0.00065,
        "hf_subset": "zul_Latn-fas_Arab",
        "languages": [
          "zul-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.010706,
        "recall": 0.015523,
        "f1": 0.011467,
        "accuracy": 0.015523,
        "main_score": 0.011467,
        "hf_subset": "zul_Latn-fin_Latn",
        "languages": [
          "zul-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.013393,
        "recall": 0.019529,
        "f1": 0.014404,
        "accuracy": 0.019529,
        "main_score": 0.014404,
        "hf_subset": "zul_Latn-fra_Latn",
        "languages": [
          "zul-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.007765,
        "recall": 0.009514,
        "f1": 0.008186,
        "accuracy": 0.009514,
        "main_score": 0.008186,
        "hf_subset": "zul_Latn-hau_Latn",
        "languages": [
          "zul-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.000252,
        "recall": 0.001502,
        "f1": 0.000426,
        "accuracy": 0.001502,
        "main_score": 0.000426,
        "hf_subset": "zul_Latn-heb_Hebr",
        "languages": [
          "zul-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.00018,
        "recall": 0.002003,
        "f1": 0.000276,
        "accuracy": 0.002003,
        "main_score": 0.000276,
        "hf_subset": "zul_Latn-hin_Deva",
        "languages": [
          "zul-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.009765,
        "recall": 0.014522,
        "f1": 0.010607,
        "accuracy": 0.014522,
        "main_score": 0.010607,
        "hf_subset": "zul_Latn-hun_Latn",
        "languages": [
          "zul-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.015147,
        "recall": 0.018528,
        "f1": 0.015677,
        "accuracy": 0.018528,
        "main_score": 0.015677,
        "hf_subset": "zul_Latn-ibo_Latn",
        "languages": [
          "zul-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.009449,
        "recall": 0.014522,
        "f1": 0.010066,
        "accuracy": 0.014522,
        "main_score": 0.010066,
        "hf_subset": "zul_Latn-ind_Latn",
        "languages": [
          "zul-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001291,
        "recall": 0.002504,
        "f1": 0.001409,
        "accuracy": 0.002504,
        "main_score": 0.001409,
        "hf_subset": "zul_Latn-jpn_Jpan",
        "languages": [
          "zul-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.00048,
        "recall": 0.001502,
        "f1": 0.000695,
        "accuracy": 0.001502,
        "main_score": 0.000695,
        "hf_subset": "zul_Latn-kor_Hang",
        "languages": [
          "zul-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.004057,
        "recall": 0.00651,
        "f1": 0.00456,
        "accuracy": 0.00651,
        "main_score": 0.00456,
        "hf_subset": "zul_Latn-lit_Latn",
        "languages": [
          "zul-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.011037,
        "recall": 0.01302,
        "f1": 0.01145,
        "accuracy": 0.01302,
        "main_score": 0.01145,
        "hf_subset": "zul_Latn-nld_Latn",
        "languages": [
          "zul-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.013912,
        "recall": 0.019529,
        "f1": 0.014739,
        "accuracy": 0.019529,
        "main_score": 0.014739,
        "hf_subset": "zul_Latn-nso_Latn",
        "languages": [
          "zul-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.005369,
        "recall": 0.009014,
        "f1": 0.0058,
        "accuracy": 0.009014,
        "main_score": 0.0058,
        "hf_subset": "zul_Latn-orm_Ethi",
        "languages": [
          "zul-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.009227,
        "recall": 0.012018,
        "f1": 0.009739,
        "accuracy": 0.012018,
        "main_score": 0.009739,
        "hf_subset": "zul_Latn-pol_Latn",
        "languages": [
          "zul-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.01058,
        "recall": 0.015023,
        "f1": 0.011463,
        "accuracy": 0.015023,
        "main_score": 0.011463,
        "hf_subset": "zul_Latn-por_Latn",
        "languages": [
          "zul-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.000306,
        "recall": 0.001502,
        "f1": 0.000494,
        "accuracy": 0.001502,
        "main_score": 0.000494,
        "hf_subset": "zul_Latn-rus_Cyrl",
        "languages": [
          "zul-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.007201,
        "recall": 0.011517,
        "f1": 0.007757,
        "accuracy": 0.011517,
        "main_score": 0.007757,
        "hf_subset": "zul_Latn-som_Latn",
        "languages": [
          "zul-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.014727,
        "recall": 0.02003,
        "f1": 0.015643,
        "accuracy": 0.02003,
        "main_score": 0.015643,
        "hf_subset": "zul_Latn-spa_Latn",
        "languages": [
          "zul-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.093974,
        "recall": 0.132198,
        "f1": 0.102557,
        "accuracy": 0.132198,
        "main_score": 0.102557,
        "hf_subset": "zul_Latn-ssw_Latn",
        "languages": [
          "zul-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.009254,
        "recall": 0.014021,
        "f1": 0.010024,
        "accuracy": 0.014021,
        "main_score": 0.010024,
        "hf_subset": "zul_Latn-swa_Latn",
        "languages": [
          "zul-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.010821,
        "recall": 0.016525,
        "f1": 0.011749,
        "accuracy": 0.016525,
        "main_score": 0.011749,
        "hf_subset": "zul_Latn-swe_Latn",
        "languages": [
          "zul-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000644,
        "recall": 0.003005,
        "f1": 0.000765,
        "accuracy": 0.003005,
        "main_score": 0.000765,
        "hf_subset": "zul_Latn-tam_Taml",
        "languages": [
          "zul-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.002639,
        "recall": 0.005508,
        "f1": 0.002983,
        "accuracy": 0.005508,
        "main_score": 0.002983,
        "hf_subset": "zul_Latn-tir_Ethi",
        "languages": [
          "zul-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.011215,
        "recall": 0.016525,
        "f1": 0.01178,
        "accuracy": 0.016525,
        "main_score": 0.01178,
        "hf_subset": "zul_Latn-tsn_Latn",
        "languages": [
          "zul-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.007581,
        "recall": 0.011017,
        "f1": 0.008135,
        "accuracy": 0.011017,
        "main_score": 0.008135,
        "hf_subset": "zul_Latn-tur_Latn",
        "languages": [
          "zul-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.00731,
        "recall": 0.011517,
        "f1": 0.007925,
        "accuracy": 0.011517,
        "main_score": 0.007925,
        "hf_subset": "zul_Latn-vie_Latn",
        "languages": [
          "zul-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.010136,
        "recall": 0.01352,
        "f1": 0.010737,
        "accuracy": 0.01352,
        "main_score": 0.010737,
        "hf_subset": "zul_Latn-wol_Latn",
        "languages": [
          "zul-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.091562,
        "recall": 0.131698,
        "f1": 0.101616,
        "accuracy": 0.131698,
        "main_score": 0.101616,
        "hf_subset": "zul_Latn-xho_Latn",
        "languages": [
          "zul-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.014811,
        "recall": 0.02003,
        "f1": 0.015596,
        "accuracy": 0.02003,
        "main_score": 0.015596,
        "hf_subset": "zul_Latn-yor_Latn",
        "languages": [
          "zul-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.014686,
        "recall": 0.02654,
        "f1": 0.016062,
        "accuracy": 0.02654,
        "main_score": 0.016062,
        "hf_subset": "zul_Latn-zho_Hant",
        "languages": [
          "zul-Latn",
          "zho-Hant"
        ]
      }
    ]
  },
  "evaluation_time": 38.12569713592529,
  "kg_co2_emissions": 0.0008639016671402559
}