{
  "dataset_revision": "3e0319203c7162b9c9f8015b594441f979c199bc",
  "task_name": "ToxicChatClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "accuracy": 0.714003,
        "f1": 0.598444,
        "f1_weighted": 0.758164,
        "ap": 0.225257,
        "ap_weighted": 0.225257,
        "scores_per_experiment": [
          {
            "accuracy": 0.668385,
            "f1": 0.563781,
            "f1_weighted": 0.723807,
            "ap": 0.201445,
            "ap_weighted": 0.201445
          },
          {
            "accuracy": 0.749141,
            "f1": 0.625951,
            "f1_weighted": 0.786762,
            "ap": 0.241401,
            "ap_weighted": 0.241401
          },
          {
            "accuracy": 0.646048,
            "f1": 0.561957,
            "f1_weighted": 0.705736,
            "ap": 0.218881,
            "ap_weighted": 0.218881
          },
          {
            "accuracy": 0.809278,
            "f1": 0.671396,
            "f1_weighted": 0.830857,
            "ap": 0.273918,
            "ap_weighted": 0.273918
          },
          {
            "accuracy": 0.755155,
            "f1": 0.62659,
            "f1_weighted": 0.790731,
            "ap": 0.237598,
            "ap_weighted": 0.237598
          },
          {
            "accuracy": 0.684708,
            "f1": 0.591938,
            "f1_weighted": 0.737695,
            "ap": 0.238067,
            "ap_weighted": 0.238067
          },
          {
            "accuracy": 0.786082,
            "f1": 0.614152,
            "f1_weighted": 0.807104,
            "ap": 0.201461,
            "ap_weighted": 0.201461
          },
          {
            "accuracy": 0.647766,
            "f1": 0.555641,
            "f1_weighted": 0.707213,
            "ap": 0.205271,
            "ap_weighted": 0.205271
          },
          {
            "accuracy": 0.722509,
            "f1": 0.596204,
            "f1_weighted": 0.765386,
            "ap": 0.212248,
            "ap_weighted": 0.212248
          },
          {
            "accuracy": 0.670962,
            "f1": 0.576826,
            "f1_weighted": 0.726347,
            "ap": 0.222286,
            "ap_weighted": 0.222286
          }
        ],
        "main_score": 0.714003,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 7.162917375564575,
  "kg_co2_emissions": 0.0001621708487575911
}