{
  "dataset_revision": "bd27d0058bea2ad52470d9072a3b5da6b97c1ac3",
  "task_name": "VaccinChatNLClassification",
  "mteb_version": "2.1.17",
  "scores": {
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.196581,
            "f1": 0.194033,
            "f1_weighted": 0.176383,
            "precision": 0.223772,
            "precision_weighted": 0.357196,
            "recall": 0.342756,
            "recall_weighted": 0.196581,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.213675,
            "f1": 0.201839,
            "f1_weighted": 0.185397,
            "precision": 0.220741,
            "precision_weighted": 0.338869,
            "recall": 0.366031,
            "recall_weighted": 0.213675,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.233333,
            "f1": 0.221126,
            "f1_weighted": 0.207839,
            "precision": 0.252201,
            "precision_weighted": 0.398878,
            "recall": 0.381899,
            "recall_weighted": 0.233333,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.218803,
            "f1": 0.193203,
            "f1_weighted": 0.209892,
            "precision": 0.238371,
            "precision_weighted": 0.447931,
            "recall": 0.322063,
            "recall_weighted": 0.218803,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.222222,
            "f1": 0.199293,
            "f1_weighted": 0.196057,
            "precision": 0.235182,
            "precision_weighted": 0.377334,
            "recall": 0.352714,
            "recall_weighted": 0.222222,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.212821,
            "f1": 0.197653,
            "f1_weighted": 0.189335,
            "precision": 0.227249,
            "precision_weighted": 0.390046,
            "recall": 0.354114,
            "recall_weighted": 0.212821,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.211111,
            "f1": 0.198454,
            "f1_weighted": 0.188958,
            "precision": 0.24246,
            "precision_weighted": 0.37308,
            "recall": 0.335694,
            "recall_weighted": 0.211111,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.211111,
            "f1": 0.174237,
            "f1_weighted": 0.182527,
            "precision": 0.200441,
            "precision_weighted": 0.344905,
            "recall": 0.330691,
            "recall_weighted": 0.211111,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.211111,
            "f1": 0.209806,
            "f1_weighted": 0.177384,
            "precision": 0.208206,
            "precision_weighted": 0.276881,
            "recall": 0.376971,
            "recall_weighted": 0.211111,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.242735,
            "f1": 0.212894,
            "f1_weighted": 0.226737,
            "precision": 0.2354,
            "precision_weighted": 0.417815,
            "recall": 0.35129,
            "recall_weighted": 0.242735,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.21735,
        "f1": 0.200254,
        "f1_weighted": 0.194051,
        "precision": 0.228402,
        "precision_weighted": 0.372294,
        "recall": 0.351422,
        "recall_weighted": 0.21735,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.200254,
        "hf_subset": "default",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 9.411653518676758,
  "kg_co2_emissions": null
}