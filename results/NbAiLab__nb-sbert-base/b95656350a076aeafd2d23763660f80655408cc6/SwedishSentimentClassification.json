{
  "dataset_revision": "105ba6b3cb99b9fd64880215be469d60ebf44a1b",
  "task_name": "SwedishSentimentClassification",
  "mteb_version": "1.36.7",
  "scores": {
    "validation": [
      {
        "accuracy": 0.8729,
        "f1": 0.872594,
        "f1_weighted": 0.872598,
        "ap": 0.824954,
        "ap_weighted": 0.824954,
        "scores_per_experiment": [
          {
            "accuracy": 0.861816,
            "f1": 0.861766,
            "f1_weighted": 0.861774,
            "ap": 0.808407,
            "ap_weighted": 0.808407
          },
          {
            "accuracy": 0.846191,
            "f1": 0.846181,
            "f1_weighted": 0.846185,
            "ap": 0.792424,
            "ap_weighted": 0.792424
          },
          {
            "accuracy": 0.907227,
            "f1": 0.907207,
            "f1_weighted": 0.907203,
            "ap": 0.875996,
            "ap_weighted": 0.875996
          },
          {
            "accuracy": 0.866699,
            "f1": 0.866028,
            "f1_weighted": 0.866,
            "ap": 0.841829,
            "ap_weighted": 0.841829
          },
          {
            "accuracy": 0.865723,
            "f1": 0.865268,
            "f1_weighted": 0.865291,
            "ap": 0.803927,
            "ap_weighted": 0.803927
          },
          {
            "accuracy": 0.881348,
            "f1": 0.880904,
            "f1_weighted": 0.880925,
            "ap": 0.821498,
            "ap_weighted": 0.821498
          },
          {
            "accuracy": 0.860352,
            "f1": 0.85945,
            "f1_weighted": 0.859483,
            "ap": 0.793265,
            "ap_weighted": 0.793265
          },
          {
            "accuracy": 0.895996,
            "f1": 0.895993,
            "f1_weighted": 0.895995,
            "ap": 0.854591,
            "ap_weighted": 0.854591
          },
          {
            "accuracy": 0.852051,
            "f1": 0.851646,
            "f1_weighted": 0.851623,
            "ap": 0.816143,
            "ap_weighted": 0.816143
          },
          {
            "accuracy": 0.891602,
            "f1": 0.891496,
            "f1_weighted": 0.891506,
            "ap": 0.841465,
            "ap_weighted": 0.841465
          }
        ],
        "main_score": 0.8729,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.869336,
        "f1": 0.869021,
        "f1_weighted": 0.869022,
        "ap": 0.821192,
        "ap_weighted": 0.821192,
        "scores_per_experiment": [
          {
            "accuracy": 0.859863,
            "f1": 0.859846,
            "f1_weighted": 0.859849,
            "ap": 0.807536,
            "ap_weighted": 0.807536
          },
          {
            "accuracy": 0.850586,
            "f1": 0.850586,
            "f1_weighted": 0.850586,
            "ap": 0.79894,
            "ap_weighted": 0.79894
          },
          {
            "accuracy": 0.903809,
            "f1": 0.903758,
            "f1_weighted": 0.903754,
            "ap": 0.873866,
            "ap_weighted": 0.873866
          },
          {
            "accuracy": 0.854492,
            "f1": 0.853334,
            "f1_weighted": 0.853308,
            "ap": 0.831354,
            "ap_weighted": 0.831354
          },
          {
            "accuracy": 0.869141,
            "f1": 0.868815,
            "f1_weighted": 0.868828,
            "ap": 0.809335,
            "ap_weighted": 0.809335
          },
          {
            "accuracy": 0.865723,
            "f1": 0.865046,
            "f1_weighted": 0.865065,
            "ap": 0.800817,
            "ap_weighted": 0.800817
          },
          {
            "accuracy": 0.866211,
            "f1": 0.865601,
            "f1_weighted": 0.865618,
            "ap": 0.80209,
            "ap_weighted": 0.80209
          },
          {
            "accuracy": 0.893555,
            "f1": 0.893554,
            "f1_weighted": 0.893554,
            "ap": 0.851731,
            "ap_weighted": 0.851731
          },
          {
            "accuracy": 0.84668,
            "f1": 0.846457,
            "f1_weighted": 0.846446,
            "ap": 0.80453,
            "ap_weighted": 0.80453
          },
          {
            "accuracy": 0.883301,
            "f1": 0.88321,
            "f1_weighted": 0.883217,
            "ap": 0.831721,
            "ap_weighted": 0.831721
          }
        ],
        "main_score": 0.869336,
        "hf_subset": "default",
        "languages": [
          "swe-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 10.77375078201294,
  "kg_co2_emissions": null
}