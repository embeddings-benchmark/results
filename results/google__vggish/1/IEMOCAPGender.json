{
  "dataset_revision": "6d4225271da423e791e16770d335cfa351cdf88e",
  "task_name": "IEMOCAPGender",
  "mteb_version": "2.4.2",
  "scores": {
    "train": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.937251,
            "f1": 0.937166,
            "f1_weighted": 0.937286,
            "precision": 0.936893,
            "precision_weighted": 0.937739,
            "recall": 0.937858,
            "recall_weighted": 0.937251,
            "ap": 0.921653,
            "ap_weighted": 0.921653
          },
          {
            "accuracy": 0.869024,
            "f1": 0.868969,
            "f1_weighted": 0.869132,
            "precision": 0.869776,
            "precision_weighted": 0.872069,
            "recall": 0.870999,
            "recall_weighted": 0.869024,
            "ap": 0.846611,
            "ap_weighted": 0.846611
          },
          {
            "accuracy": 0.926295,
            "f1": 0.92548,
            "f1_weighted": 0.925961,
            "precision": 0.931111,
            "precision_weighted": 0.929094,
            "recall": 0.923358,
            "recall_weighted": 0.926295,
            "ap": 0.887749,
            "ap_weighted": 0.887749
          },
          {
            "accuracy": 0.914841,
            "f1": 0.914665,
            "f1_weighted": 0.914723,
            "precision": 0.916663,
            "precision_weighted": 0.916303,
            "recall": 0.914368,
            "recall_weighted": 0.914841,
            "ap": 0.888163,
            "ap_weighted": 0.888163
          },
          {
            "accuracy": 0.929746,
            "f1": 0.929382,
            "f1_weighted": 0.929683,
            "precision": 0.930301,
            "precision_weighted": 0.92991,
            "recall": 0.928757,
            "recall_weighted": 0.929746,
            "ap": 0.902212,
            "ap_weighted": 0.902212
          }
        ],
        "accuracy": 0.915431,
        "f1": 0.915132,
        "f1_weighted": 0.915357,
        "precision": 0.916949,
        "precision_weighted": 0.917023,
        "recall": 0.915068,
        "recall_weighted": 0.915431,
        "ap": 0.889277,
        "ap_weighted": 0.889277,
        "main_score": 0.915431,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 1322.6932153701782,
  "kg_co2_emissions": null
}