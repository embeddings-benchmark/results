{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "task_name": "ToxicConversationsClassification",
  "mteb_version": "1.36.5",
  "scores": {
    "test": [
      {
        "accuracy": 0.901611,
        "f1": 0.771807,
        "f1_weighted": 0.916602,
        "ap": 0.416544,
        "ap_weighted": 0.416544,
        "scores_per_experiment": [
          {
            "accuracy": 0.905273,
            "f1": 0.773542,
            "f1_weighted": 0.918936,
            "ap": 0.413924,
            "ap_weighted": 0.413924
          },
          {
            "accuracy": 0.914062,
            "f1": 0.78771,
            "f1_weighted": 0.925578,
            "ap": 0.437813,
            "ap_weighted": 0.437813
          },
          {
            "accuracy": 0.902344,
            "f1": 0.770609,
            "f1_weighted": 0.916943,
            "ap": 0.411656,
            "ap_weighted": 0.411656
          },
          {
            "accuracy": 0.883301,
            "f1": 0.745498,
            "f1_weighted": 0.903144,
            "ap": 0.376735,
            "ap_weighted": 0.376735
          },
          {
            "accuracy": 0.921875,
            "f1": 0.801055,
            "f1_weighted": 0.931565,
            "ap": 0.461537,
            "ap_weighted": 0.461537
          },
          {
            "accuracy": 0.869141,
            "f1": 0.727709,
            "f1_weighted": 0.892904,
            "ap": 0.35273,
            "ap_weighted": 0.35273
          },
          {
            "accuracy": 0.925293,
            "f1": 0.807137,
            "f1_weighted": 0.934212,
            "ap": 0.47276,
            "ap_weighted": 0.47276
          },
          {
            "accuracy": 0.858887,
            "f1": 0.715073,
            "f1_weighted": 0.885475,
            "ap": 0.335781,
            "ap_weighted": 0.335781
          },
          {
            "accuracy": 0.92334,
            "f1": 0.802872,
            "f1_weighted": 0.932595,
            "ap": 0.463683,
            "ap_weighted": 0.463683
          },
          {
            "accuracy": 0.912598,
            "f1": 0.786862,
            "f1_weighted": 0.924668,
            "ap": 0.438816,
            "ap_weighted": 0.438816
          }
        ],
        "main_score": 0.901611,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 10.300183534622192,
  "kg_co2_emissions": null
}