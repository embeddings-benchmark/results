{
  "dataset_revision": "fad2c6e8459f9e1c45d9315f4953d921437d70f8",
  "task_name": "MassiveScenarioClassification",
  "mteb_version": "2.3.0",
  "scores": {
    "validation": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.751599,
            "f1": 0.744985,
            "f1_weighted": 0.753904,
            "precision": 0.727531,
            "precision_weighted": 0.785164,
            "recall": 0.79941,
            "recall_weighted": 0.751599,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.697983,
            "f1": 0.690097,
            "f1_weighted": 0.700138,
            "precision": 0.683234,
            "precision_weighted": 0.76636,
            "recall": 0.772532,
            "recall_weighted": 0.697983,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.699459,
            "f1": 0.685281,
            "f1_weighted": 0.697255,
            "precision": 0.67661,
            "precision_weighted": 0.760407,
            "recall": 0.770006,
            "recall_weighted": 0.699459,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.694048,
            "f1": 0.677738,
            "f1_weighted": 0.698594,
            "precision": 0.669869,
            "precision_weighted": 0.74771,
            "recall": 0.746461,
            "recall_weighted": 0.694048,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.697491,
            "f1": 0.686979,
            "f1_weighted": 0.691305,
            "precision": 0.681578,
            "precision_weighted": 0.756091,
            "recall": 0.765041,
            "recall_weighted": 0.697491,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.676832,
            "f1": 0.66764,
            "f1_weighted": 0.668992,
            "precision": 0.660002,
            "precision_weighted": 0.73747,
            "recall": 0.744513,
            "recall_weighted": 0.676832,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.68667,
            "f1": 0.674274,
            "f1_weighted": 0.681332,
            "precision": 0.671386,
            "precision_weighted": 0.746257,
            "recall": 0.753634,
            "recall_weighted": 0.68667,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.694048,
            "f1": 0.696082,
            "f1_weighted": 0.701332,
            "precision": 0.689347,
            "precision_weighted": 0.758166,
            "recall": 0.75279,
            "recall_weighted": 0.694048,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.740777,
            "f1": 0.740101,
            "f1_weighted": 0.743823,
            "precision": 0.721053,
            "precision_weighted": 0.776871,
            "recall": 0.79373,
            "recall_weighted": 0.740777,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.70487,
            "f1": 0.698258,
            "f1_weighted": 0.705911,
            "precision": 0.690858,
            "precision_weighted": 0.752222,
            "recall": 0.769469,
            "recall_weighted": 0.70487,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.704378,
        "f1": 0.696144,
        "f1_weighted": 0.704258,
        "precision": 0.687147,
        "precision_weighted": 0.758672,
        "recall": 0.766759,
        "recall_weighted": 0.704378,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.704378,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      }
    ],
    "test": [
      {
        "scores_per_experiment": [
          {
            "accuracy": 0.752186,
            "f1": 0.746133,
            "f1_weighted": 0.753653,
            "precision": 0.729335,
            "precision_weighted": 0.780471,
            "recall": 0.793359,
            "recall_weighted": 0.752186,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.704775,
            "f1": 0.70183,
            "f1_weighted": 0.703087,
            "precision": 0.690571,
            "precision_weighted": 0.764065,
            "recall": 0.781092,
            "recall_weighted": 0.704775,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.703093,
            "f1": 0.689415,
            "f1_weighted": 0.702045,
            "precision": 0.680016,
            "precision_weighted": 0.758419,
            "recall": 0.763787,
            "recall_weighted": 0.703093,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.718561,
            "f1": 0.709126,
            "f1_weighted": 0.721714,
            "precision": 0.699039,
            "precision_weighted": 0.769708,
            "recall": 0.772707,
            "recall_weighted": 0.718561,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.702757,
            "f1": 0.694923,
            "f1_weighted": 0.694757,
            "precision": 0.690711,
            "precision_weighted": 0.758924,
            "recall": 0.768414,
            "recall_weighted": 0.702757,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.688971,
            "f1": 0.681767,
            "f1_weighted": 0.681124,
            "precision": 0.674978,
            "precision_weighted": 0.741027,
            "recall": 0.749113,
            "recall_weighted": 0.688971,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.686954,
            "f1": 0.680655,
            "f1_weighted": 0.682654,
            "precision": 0.670806,
            "precision_weighted": 0.741505,
            "recall": 0.757011,
            "recall_weighted": 0.686954,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.7115,
            "f1": 0.715763,
            "f1_weighted": 0.717218,
            "precision": 0.704544,
            "precision_weighted": 0.766384,
            "recall": 0.769057,
            "recall_weighted": 0.7115,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.737054,
            "f1": 0.735052,
            "f1_weighted": 0.739218,
            "precision": 0.719477,
            "precision_weighted": 0.776094,
            "recall": 0.790118,
            "recall_weighted": 0.737054,
            "ap": null,
            "ap_weighted": null
          },
          {
            "accuracy": 0.713181,
            "f1": 0.710322,
            "f1_weighted": 0.714623,
            "precision": 0.702761,
            "precision_weighted": 0.758587,
            "recall": 0.774025,
            "recall_weighted": 0.713181,
            "ap": null,
            "ap_weighted": null
          }
        ],
        "accuracy": 0.711903,
        "f1": 0.706499,
        "f1_weighted": 0.711009,
        "precision": 0.696224,
        "precision_weighted": 0.761518,
        "recall": 0.771868,
        "recall_weighted": 0.711903,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.711903,
        "hf_subset": "nl",
        "languages": [
          "nld-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 47.28494095802307,
  "kg_co2_emissions": null
}