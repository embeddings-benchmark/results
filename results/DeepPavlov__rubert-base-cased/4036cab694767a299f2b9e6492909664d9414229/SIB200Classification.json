{
  "dataset_revision": "a74d7350ea12af010cfb1c21e34f1f81fd2e615b",
  "evaluation_time": 8.576018571853638,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.89",
  "scores": {
    "test": [
      {
        "accuracy": 0.6328431372549019,
        "f1": 0.6268517072255697,
        "f1_weighted": 0.6365635608774032,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.6328431372549019,
        "scores_per_experiment": [
          {
            "accuracy": 0.6519607843137255,
            "f1": 0.635521916302971,
            "f1_weighted": 0.6541701677916769
          },
          {
            "accuracy": 0.6078431372549019,
            "f1": 0.6053762474861907,
            "f1_weighted": 0.6074991459675249
          },
          {
            "accuracy": 0.5686274509803921,
            "f1": 0.5651418876517367,
            "f1_weighted": 0.5643537151910925
          },
          {
            "accuracy": 0.6127450980392157,
            "f1": 0.6038546574350857,
            "f1_weighted": 0.6165443614979164
          },
          {
            "accuracy": 0.7009803921568627,
            "f1": 0.6903933304926119,
            "f1_weighted": 0.7047981991110756
          },
          {
            "accuracy": 0.6127450980392157,
            "f1": 0.6041273760416194,
            "f1_weighted": 0.6231427251550812
          },
          {
            "accuracy": 0.6274509803921569,
            "f1": 0.6373328988049245,
            "f1_weighted": 0.644426817914066
          },
          {
            "accuracy": 0.6323529411764706,
            "f1": 0.6246751887568214,
            "f1_weighted": 0.6359945516668205
          },
          {
            "accuracy": 0.6323529411764706,
            "f1": 0.6219722382880278,
            "f1_weighted": 0.6264324839247439
          },
          {
            "accuracy": 0.6813725490196079,
            "f1": 0.6801213309957073,
            "f1_weighted": 0.688273440554035
          }
        ]
      }
    ],
    "train": [
      {
        "accuracy": 0.6532097004279601,
        "f1": 0.6482421154701679,
        "f1_weighted": 0.6537761845785336,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.6532097004279601,
        "scores_per_experiment": [
          {
            "accuracy": 0.6590584878744651,
            "f1": 0.649895604395394,
            "f1_weighted": 0.6576159079606452
          },
          {
            "accuracy": 0.6348074179743224,
            "f1": 0.6295819722879445,
            "f1_weighted": 0.6347097253912325
          },
          {
            "accuracy": 0.6419400855920114,
            "f1": 0.6419709274121173,
            "f1_weighted": 0.6371882368335631
          },
          {
            "accuracy": 0.6504992867332382,
            "f1": 0.6445831166627966,
            "f1_weighted": 0.6526866727506001
          },
          {
            "accuracy": 0.6947218259629101,
            "f1": 0.6922781753117756,
            "f1_weighted": 0.6962296015903493
          },
          {
            "accuracy": 0.6362339514978602,
            "f1": 0.6317582729117424,
            "f1_weighted": 0.6426396768147563
          },
          {
            "accuracy": 0.6319543509272468,
            "f1": 0.6297709449615232,
            "f1_weighted": 0.6355728343969377
          },
          {
            "accuracy": 0.6476462196861626,
            "f1": 0.6388742458232798,
            "f1_weighted": 0.6485803844616497
          },
          {
            "accuracy": 0.6291012838801712,
            "f1": 0.6228485802827394,
            "f1_weighted": 0.6257672842469265
          },
          {
            "accuracy": 0.7061340941512125,
            "f1": 0.700859314652366,
            "f1_weighted": 0.7067715213386759
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.611111111111111,
        "f1": 0.5978106891394375,
        "f1_weighted": 0.615017454567285,
        "hf_subset": "rus_Cyrl",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.611111111111111,
        "scores_per_experiment": [
          {
            "accuracy": 0.6262626262626263,
            "f1": 0.6181970468555835,
            "f1_weighted": 0.6314418705216932
          },
          {
            "accuracy": 0.6161616161616161,
            "f1": 0.6239160011830819,
            "f1_weighted": 0.6211502185415229
          },
          {
            "accuracy": 0.5353535353535354,
            "f1": 0.5363568684577088,
            "f1_weighted": 0.5265106418047595
          },
          {
            "accuracy": 0.6767676767676768,
            "f1": 0.6585337576179168,
            "f1_weighted": 0.672745074359632
          },
          {
            "accuracy": 0.5858585858585859,
            "f1": 0.5804208391431107,
            "f1_weighted": 0.5900944175064258
          },
          {
            "accuracy": 0.5454545454545454,
            "f1": 0.5378327492613206,
            "f1_weighted": 0.5623022917972412
          },
          {
            "accuracy": 0.5555555555555556,
            "f1": 0.5411304784577997,
            "f1_weighted": 0.5664026424715091
          },
          {
            "accuracy": 0.6565656565656566,
            "f1": 0.6229891573854422,
            "f1_weighted": 0.6533237431070248
          },
          {
            "accuracy": 0.6363636363636364,
            "f1": 0.6125801045055704,
            "f1_weighted": 0.6422199914953539
          },
          {
            "accuracy": 0.6767676767676768,
            "f1": 0.6461498885268393,
            "f1_weighted": 0.6839836540676878
          }
        ]
      }
    ]
  },
  "task_name": "SIB200Classification"
}