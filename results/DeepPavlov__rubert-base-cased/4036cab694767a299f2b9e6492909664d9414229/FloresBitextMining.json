{
  "dataset_revision": "e6b647fcb6299a2f686f742f4d4c023e553ea67e",
  "evaluation_time": 408.5949146747589,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.89",
  "scores": {
    "devtest": [
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.00012628494543590665,
        "hf_subset": "ace_Arab-rus_Cyrl",
        "languages": [
          "ace-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.00012628494543590665,
        "precision": 6.489971327227926e-05,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.003332527195820369,
        "hf_subset": "bam_Latn-rus_Cyrl",
        "languages": [
          "bam-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003332527195820369,
        "precision": 0.002983890394076289,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 1.8908895720489926e-05,
        "hf_subset": "dzo_Tibt-rus_Cyrl",
        "languages": [
          "dzo-Tibt",
          "rus-Cyrl"
        ],
        "main_score": 1.8908895720489926e-05,
        "precision": 9.525153446321633e-06,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0029681769430965044,
        "hf_subset": "hin_Deva-rus_Cyrl",
        "languages": [
          "hin-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0029681769430965044,
        "precision": 0.0029663054749845957,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.044466403162055336,
        "f1": 0.02855445952593035,
        "hf_subset": "khm_Khmr-rus_Cyrl",
        "languages": [
          "khm-Khmr",
          "rus-Cyrl"
        ],
        "main_score": 0.02855445952593035,
        "precision": 0.025825522597348917,
        "recall": 0.044466403162055336
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0016726071144148968,
        "hf_subset": "mag_Deva-rus_Cyrl",
        "languages": [
          "mag-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0016726071144148968,
        "precision": 0.00149519435376386,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.009363202986302688,
        "hf_subset": "pap_Latn-rus_Cyrl",
        "languages": [
          "pap-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.009363202986302688,
        "precision": 0.008232617625905967,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.003132015037535884,
        "hf_subset": "sot_Latn-rus_Cyrl",
        "languages": [
          "sot-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003132015037535884,
        "precision": 0.002801187511970887,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.0052494342615863705,
        "hf_subset": "tur_Latn-rus_Cyrl",
        "languages": [
          "tur-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0052494342615863705,
        "precision": 0.004208050649104309,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.005601635227741212,
        "hf_subset": "ace_Latn-rus_Cyrl",
        "languages": [
          "ace-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.005601635227741212,
        "precision": 0.005435864911316124,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.00461333707857654,
        "hf_subset": "ban_Latn-rus_Cyrl",
        "languages": [
          "ban-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.00461333707857654,
        "precision": 0.0044476445258523735,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 2.0104624465719603e-06,
        "hf_subset": "ell_Grek-rus_Cyrl",
        "languages": [
          "ell-Grek",
          "rus-Cyrl"
        ],
        "main_score": 2.0104624465719603e-06,
        "precision": 1.0062548803361696e-06,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0019829387418320225,
        "hf_subset": "hne_Deva-rus_Cyrl",
        "languages": [
          "hne-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0019829387418320225,
        "precision": 0.001979622903535947,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.006132283721417591,
        "hf_subset": "kik_Latn-rus_Cyrl",
        "languages": [
          "kik-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.006132283721417591,
        "precision": 0.0060362274107959215,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0032974074314060056,
        "hf_subset": "mai_Deva-rus_Cyrl",
        "languages": [
          "mai-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0032974074314060056,
        "precision": 0.0029662300568362135,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.001895166334869367,
        "hf_subset": "pbt_Arab-rus_Cyrl",
        "languages": [
          "pbt-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.001895166334869367,
        "precision": 0.0016122856606659765,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.041501976284584984,
        "f1": 0.0277916743474569,
        "hf_subset": "spa_Latn-rus_Cyrl",
        "languages": [
          "spa-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0277916743474569,
        "precision": 0.026123889641937164,
        "recall": 0.041501976284584984
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0033868294524678102,
        "hf_subset": "twi_Latn-rus_Cyrl",
        "languages": [
          "twi-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0033868294524678102,
        "precision": 0.002914249516849385,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.002235776192228194,
        "hf_subset": "acm_Arab-rus_Cyrl",
        "languages": [
          "acm-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.002235776192228194,
        "precision": 0.0021177250054769657,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.09881422924901186,
        "f1": 0.07374745380382383,
        "hf_subset": "bel_Cyrl-rus_Cyrl",
        "languages": [
          "bel-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.07374745380382383,
        "precision": 0.0702969899599947,
        "recall": 0.09881422924901186
      },
      {
        "accuracy": 0.24011857707509882,
        "f1": 0.21363978351635785,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.21363978351635785,
        "precision": 0.206238491613993,
        "recall": 0.24011857707509882
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.014367680284333764,
        "hf_subset": "hrv_Latn-rus_Cyrl",
        "languages": [
          "hrv-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.014367680284333764,
        "precision": 0.01277635982162246,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0023281094530955533,
        "hf_subset": "kin_Latn-rus_Cyrl",
        "languages": [
          "kin-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0023281094530955533,
        "precision": 0.0021852333992612187,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0029644268774703555,
        "hf_subset": "mal_Mlym-rus_Cyrl",
        "languages": [
          "mal-Mlym",
          "rus-Cyrl"
        ],
        "main_score": 0.0029644268774703555,
        "precision": 0.0024703557312252965,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010379698836282905,
        "hf_subset": "pes_Arab-rus_Cyrl",
        "languages": [
          "pes-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0010379698836282905,
        "precision": 0.0010136070238372027,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.012596743690356535,
        "hf_subset": "srd_Latn-rus_Cyrl",
        "languages": [
          "srd-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.012596743690356535,
        "precision": 0.011489619359682842,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.004679730841649883,
        "hf_subset": "tzm_Tfng-rus_Cyrl",
        "languages": [
          "tzm-Tfng",
          "rus-Cyrl"
        ],
        "main_score": 0.004679730841649883,
        "precision": 0.004200868352152685,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.002202188767024253,
        "hf_subset": "acq_Arab-rus_Cyrl",
        "languages": [
          "acq-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.002202188767024253,
        "precision": 0.0020985768494556417,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0020752143159163136,
        "hf_subset": "bem_Latn-rus_Cyrl",
        "languages": [
          "bem-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0020752143159163136,
        "precision": 0.002027731981521798,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.0142032744621068,
        "hf_subset": "epo_Latn-rus_Cyrl",
        "languages": [
          "epo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0142032744621068,
        "precision": 0.012974552390510449,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0027847507386118717,
        "hf_subset": "hun_Latn-rus_Cyrl",
        "languages": [
          "hun-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0027847507386118717,
        "precision": 0.0025506471266737523,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.020277852647473824,
        "hf_subset": "kir_Cyrl-rus_Cyrl",
        "languages": [
          "kir-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.020277852647473824,
        "precision": 0.018029062940882558,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 0.0009881422924901185,
        "hf_subset": "mar_Deva-rus_Cyrl",
        "languages": [
          "mar-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0009881422924901185,
        "precision": 0.0009881422924901185,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.004185784016578527,
        "hf_subset": "plt_Latn-rus_Cyrl",
        "languages": [
          "plt-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.004185784016578527,
        "precision": 0.004076746031556028,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.13339920948616601,
        "f1": 0.10399776450723361,
        "hf_subset": "srp_Cyrl-rus_Cyrl",
        "languages": [
          "srp-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.10399776450723361,
        "precision": 0.09751158676798152,
        "recall": 0.13339920948616601
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.0076631022962544695,
        "hf_subset": "uig_Arab-rus_Cyrl",
        "languages": [
          "uig-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0076631022962544695,
        "precision": 0.006961743854326974,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.001827079888208498,
        "hf_subset": "aeb_Arab-rus_Cyrl",
        "languages": [
          "aeb-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.001827079888208498,
        "precision": 0.0015779605712593833,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0029644268774703555,
        "hf_subset": "ben_Beng-rus_Cyrl",
        "languages": [
          "ben-Beng",
          "rus-Cyrl"
        ],
        "main_score": 0.0029644268774703555,
        "precision": 0.0029644268774703555,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.005247078972807128,
        "hf_subset": "est_Latn-rus_Cyrl",
        "languages": [
          "est-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.005247078972807128,
        "precision": 0.0039904831969819555,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0033809438256078577,
        "hf_subset": "hye_Armn-rus_Cyrl",
        "languages": [
          "hye-Armn",
          "rus-Cyrl"
        ],
        "main_score": 0.0033809438256078577,
        "precision": 0.003222177629454949,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0014928258162326062,
        "hf_subset": "kmb_Latn-rus_Cyrl",
        "languages": [
          "kmb-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0014928258162326062,
        "precision": 0.0013228469759909531,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0010532325847876982,
        "hf_subset": "min_Arab-rus_Cyrl",
        "languages": [
          "min-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0010532325847876982,
        "precision": 0.0010214468414828626,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.008888439515488891,
        "hf_subset": "pol_Latn-rus_Cyrl",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.008888439515488891,
        "precision": 0.007931125784063133,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001978969754253308,
        "hf_subset": "ssw_Latn-rus_Cyrl",
        "languages": [
          "ssw-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001978969754253308,
        "precision": 0.0019776289962625364,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.6768774703557312,
        "f1": 0.6287591345766048,
        "hf_subset": "ukr_Cyrl-rus_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.6287591345766048,
        "precision": 0.61382638414506,
        "recall": 0.6768774703557312
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.019954185869422537,
        "hf_subset": "afr_Latn-rus_Cyrl",
        "languages": [
          "afr-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.019954185869422537,
        "precision": 0.01836958615129827,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0013273351746557003,
        "hf_subset": "bho_Deva-rus_Cyrl",
        "languages": [
          "bho-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0013273351746557003,
        "precision": 0.000993060581442686,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.006945536618458747,
        "hf_subset": "eus_Latn-rus_Cyrl",
        "languages": [
          "eus-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.006945536618458747,
        "precision": 0.0060020797337696045,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.004173715426781786,
        "hf_subset": "ibo_Latn-rus_Cyrl",
        "languages": [
          "ibo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.004173715426781786,
        "precision": 0.004068639088730485,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.002516401624599392,
        "hf_subset": "kmr_Latn-rus_Cyrl",
        "languages": [
          "kmr-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002516401624599392,
        "precision": 0.0022875308201395156,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.006655587177971797,
        "hf_subset": "min_Latn-rus_Cyrl",
        "languages": [
          "min-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.006655587177971797,
        "precision": 0.006176938311388602,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.02196160501245493,
        "hf_subset": "por_Latn-rus_Cyrl",
        "languages": [
          "por-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.02196160501245493,
        "precision": 0.01991414913192393,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0020442129544120603,
        "hf_subset": "sun_Latn-rus_Cyrl",
        "languages": [
          "sun-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0020442129544120603,
        "precision": 0.0017302761867979259,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0033598128648154126,
        "hf_subset": "umb_Latn-rus_Cyrl",
        "languages": [
          "umb-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0033598128648154126,
        "precision": 0.0029262227398323816,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0009327458466887129,
        "hf_subset": "ajp_Arab-rus_Cyrl",
        "languages": [
          "ajp-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0009327458466887129,
        "precision": 0.0006426234304764488,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.00013240484856038128,
        "hf_subset": "bjn_Arab-rus_Cyrl",
        "languages": [
          "bjn-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.00013240484856038128,
        "precision": 6.860449920025833e-05,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.002742483247298076,
        "hf_subset": "ewe_Latn-rus_Cyrl",
        "languages": [
          "ewe-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002742483247298076,
        "precision": 0.0022443031492275253,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.005963878721098316,
        "hf_subset": "ilo_Latn-rus_Cyrl",
        "languages": [
          "ilo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.005963878721098316,
        "precision": 0.005380930362546319,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010165489549183644,
        "hf_subset": "knc_Arab-rus_Cyrl",
        "languages": [
          "knc-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0010165489549183644,
        "precision": 0.0010024990959741926,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.15118577075098813,
        "f1": 0.12212315748895633,
        "hf_subset": "mkd_Cyrl-rus_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.12212315748895633,
        "precision": 0.11650874657775781,
        "recall": 0.15118577075098813
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0010985102333386355,
        "hf_subset": "prs_Arab-rus_Cyrl",
        "languages": [
          "prs-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0010985102333386355,
        "precision": 0.001044542046985824,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.013974072123281302,
        "hf_subset": "swe_Latn-rus_Cyrl",
        "languages": [
          "swe-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.013974072123281302,
        "precision": 0.012509182294602083,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0001362730001522101,
        "hf_subset": "urd_Arab-rus_Cyrl",
        "languages": [
          "urd-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0001362730001522101,
        "precision": 7.227924879153612e-05,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.005512734759140968,
        "hf_subset": "aka_Latn-rus_Cyrl",
        "languages": [
          "aka-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.005512734759140968,
        "precision": 0.005244667686587914,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001978280832035773,
        "hf_subset": "bjn_Latn-rus_Cyrl",
        "languages": [
          "bjn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001978280832035773,
        "precision": 0.001977283717733008,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.007086183313701674,
        "hf_subset": "fao_Latn-rus_Cyrl",
        "languages": [
          "fao-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.007086183313701674,
        "precision": 0.005847796641681718,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0036252491822152248,
        "hf_subset": "ind_Latn-rus_Cyrl",
        "languages": [
          "ind-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0036252491822152248,
        "precision": 0.0031301487233229086,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0026442635809767624,
        "hf_subset": "knc_Latn-rus_Cyrl",
        "languages": [
          "knc-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0026442635809767624,
        "precision": 0.0023948526878734494,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.005230921842441201,
        "hf_subset": "mlt_Latn-rus_Cyrl",
        "languages": [
          "mlt-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.005230921842441201,
        "precision": 0.004288727773724914,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001649051956235321,
        "hf_subset": "quy_Latn-rus_Cyrl",
        "languages": [
          "quy-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001649051956235321,
        "precision": 0.001483288675179672,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.00120214731190604,
        "hf_subset": "swh_Latn-rus_Cyrl",
        "languages": [
          "swh-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.00120214731190604,
        "precision": 0.001106165307181682,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001978284873021715,
        "hf_subset": "uzn_Latn-rus_Cyrl",
        "languages": [
          "uzn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001978284873021715,
        "precision": 0.00197728574231812,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.00536314290638862,
        "hf_subset": "als_Latn-rus_Cyrl",
        "languages": [
          "als-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.00536314290638862,
        "precision": 0.004989042441237476,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009906890509759178,
        "hf_subset": "bod_Tibt-rus_Cyrl",
        "languages": [
          "bod-Tibt",
          "rus-Cyrl"
        ],
        "main_score": 0.0009906890509759178,
        "precision": 0.000989417314803009,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.005071156130887432,
        "hf_subset": "fij_Latn-rus_Cyrl",
        "languages": [
          "fij-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.005071156130887432,
        "precision": 0.005007531400569123,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.008675462817275516,
        "hf_subset": "isl_Latn-rus_Cyrl",
        "languages": [
          "isl-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.008675462817275516,
        "precision": 0.007670821564593733,
        "recall": 0.019762845849802372
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.004049554647618061,
        "hf_subset": "kon_Latn-rus_Cyrl",
        "languages": [
          "kon-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.004049554647618061,
        "precision": 0.004003416725244587,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.005599472990777338,
        "hf_subset": "mni_Beng-rus_Cyrl",
        "languages": [
          "mni-Beng",
          "rus-Cyrl"
        ],
        "main_score": 0.005599472990777338,
        "precision": 0.005434782608695652,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0266798418972332,
        "f1": 0.016142457020337352,
        "hf_subset": "ron_Latn-rus_Cyrl",
        "languages": [
          "ron-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.016142457020337352,
        "precision": 0.014154870878676232,
        "recall": 0.0266798418972332
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.009663447722422308,
        "hf_subset": "szl_Latn-rus_Cyrl",
        "languages": [
          "szl-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.009663447722422308,
        "precision": 0.00913435167317155,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.01597145558997491,
        "hf_subset": "vec_Latn-rus_Cyrl",
        "languages": [
          "vec-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01597145558997491,
        "precision": 0.014752270468162522,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.004349985960819888,
        "hf_subset": "amh_Ethi-rus_Cyrl",
        "languages": [
          "amh-Ethi",
          "rus-Cyrl"
        ],
        "main_score": 0.004349985960819888,
        "precision": 0.003904243173817905,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.013097095801747527,
        "hf_subset": "bos_Latn-rus_Cyrl",
        "languages": [
          "bos-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.013097095801747527,
        "precision": 0.011747183286631206,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.004496331037443508,
        "hf_subset": "fin_Latn-rus_Cyrl",
        "languages": [
          "fin-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.004496331037443508,
        "precision": 0.0043070468639776404,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.043478260869565216,
        "f1": 0.03170585279289744,
        "hf_subset": "ita_Latn-rus_Cyrl",
        "languages": [
          "ita-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.03170585279289744,
        "precision": 0.029898406909353168,
        "recall": 0.043478260869565216
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.006099980207940779,
        "hf_subset": "kor_Hang-rus_Cyrl",
        "languages": [
          "kor-Hang",
          "rus-Cyrl"
        ],
        "main_score": 0.006099980207940779,
        "precision": 0.005712697803061685,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0018490438155867356,
        "hf_subset": "mos_Latn-rus_Cyrl",
        "languages": [
          "mos-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0018490438155867356,
        "precision": 0.0015909449259113508,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0029872115651932165,
        "hf_subset": "run_Latn-rus_Cyrl",
        "languages": [
          "run-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0029872115651932165,
        "precision": 0.0029759213474991673,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.005173549588841943,
        "hf_subset": "tam_Taml-rus_Cyrl",
        "languages": [
          "tam-Taml",
          "rus-Cyrl"
        ],
        "main_score": 0.005173549588841943,
        "precision": 0.004811311876529267,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.005610048407920039,
        "hf_subset": "vie_Latn-rus_Cyrl",
        "languages": [
          "vie-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.005610048407920039,
        "precision": 0.005440084625833972,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0018947737888163833,
        "hf_subset": "apc_Arab-rus_Cyrl",
        "languages": [
          "apc-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0018947737888163833,
        "precision": 0.0016175606422841908,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0019785933286542794,
        "hf_subset": "bug_Latn-rus_Cyrl",
        "languages": [
          "bug-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0019785933286542794,
        "precision": 0.0016809976192127222,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 6.505265652551515e-05,
        "hf_subset": "fon_Latn-rus_Cyrl",
        "languages": [
          "fon-Latn",
          "rus-Cyrl"
        ],
        "main_score": 6.505265652551515e-05,
        "precision": 3.3285437554401786e-05,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0033617640940295404,
        "hf_subset": "jav_Latn-rus_Cyrl",
        "languages": [
          "jav-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0033617640940295404,
        "precision": 0.0028831229322593232,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.046442687747035576,
        "f1": 0.030784277203469292,
        "hf_subset": "lao_Laoo-rus_Cyrl",
        "languages": [
          "lao-Laoo",
          "rus-Cyrl"
        ],
        "main_score": 0.030784277203469292,
        "precision": 0.02838856251449766,
        "recall": 0.046442687747035576
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0022881538388369797,
        "hf_subset": "mri_Latn-rus_Cyrl",
        "languages": [
          "mri-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0022881538388369797,
        "precision": 0.0021444542198585585,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.00012610116510372265,
        "hf_subset": "rus_Cyrl-ace_Arab",
        "languages": [
          "rus-Cyrl",
          "ace-Arab"
        ],
        "main_score": 0.00012610116510372265,
        "precision": 6.716953279666687e-05,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.0266798418972332,
        "f1": 0.008797944232382839,
        "hf_subset": "rus_Cyrl-bam_Latn",
        "languages": [
          "rus-Cyrl",
          "bam-Latn"
        ],
        "main_score": 0.008797944232382839,
        "precision": 0.0060446703532966144,
        "recall": 0.0266798418972332
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 2.3930497663396054e-05,
        "hf_subset": "rus_Cyrl-dzo_Tibt",
        "languages": [
          "rus-Cyrl",
          "dzo-Tibt"
        ],
        "main_score": 2.3930497663396054e-05,
        "precision": 1.2087141644560245e-05,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.0066707056685590465,
        "hf_subset": "rus_Cyrl-hin_Deva",
        "languages": [
          "rus-Cyrl",
          "hin-Deva"
        ],
        "main_score": 0.0066707056685590465,
        "precision": 0.005816062636064767,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.05731225296442688,
        "f1": 0.029768006012877792,
        "hf_subset": "rus_Cyrl-khm_Khmr",
        "languages": [
          "rus-Cyrl",
          "khm-Khmr"
        ],
        "main_score": 0.029768006012877792,
        "precision": 0.02456932366012541,
        "recall": 0.05731225296442688
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0030810662046680272,
        "hf_subset": "rus_Cyrl-mag_Deva",
        "languages": [
          "rus-Cyrl",
          "mag-Deva"
        ],
        "main_score": 0.0030810662046680272,
        "precision": 0.0024387527118325753,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.05533596837944664,
        "f1": 0.029403468174323828,
        "hf_subset": "rus_Cyrl-pap_Latn",
        "languages": [
          "rus-Cyrl",
          "pap-Latn"
        ],
        "main_score": 0.029403468174323828,
        "precision": 0.025208856018362945,
        "recall": 0.05533596837944664
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.015710067935257442,
        "hf_subset": "rus_Cyrl-sot_Latn",
        "languages": [
          "rus-Cyrl",
          "sot-Latn"
        ],
        "main_score": 0.015710067935257442,
        "precision": 0.012499729196536217,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.025691699604743084,
        "f1": 0.010979296766582696,
        "hf_subset": "rus_Cyrl-tur_Latn",
        "languages": [
          "rus-Cyrl",
          "tur-Latn"
        ],
        "main_score": 0.010979296766582696,
        "precision": 0.009621341589788843,
        "recall": 0.025691699604743084
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.018199596014004643,
        "hf_subset": "rus_Cyrl-ace_Latn",
        "languages": [
          "rus-Cyrl",
          "ace-Latn"
        ],
        "main_score": 0.018199596014004643,
        "precision": 0.01510021918534702,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.0266798418972332,
        "f1": 0.013635642216700527,
        "hf_subset": "rus_Cyrl-ban_Latn",
        "languages": [
          "rus-Cyrl",
          "ban-Latn"
        ],
        "main_score": 0.013635642216700527,
        "precision": 0.011166273591035475,
        "recall": 0.0266798418972332
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0018489501129351586,
        "hf_subset": "rus_Cyrl-ell_Grek",
        "languages": [
          "rus-Cyrl",
          "ell-Grek"
        ],
        "main_score": 0.0018489501129351586,
        "precision": 0.0015204966226672317,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0011831034965189811,
        "hf_subset": "rus_Cyrl-hne_Deva",
        "languages": [
          "rus-Cyrl",
          "hne-Deva"
        ],
        "main_score": 0.0011831034965189811,
        "precision": 0.0006884901881357457,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.036561264822134384,
        "f1": 0.01452885527803666,
        "hf_subset": "rus_Cyrl-kik_Latn",
        "languages": [
          "rus-Cyrl",
          "kik-Latn"
        ],
        "main_score": 0.01452885527803666,
        "precision": 0.011265727646063982,
        "recall": 0.036561264822134384
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.00488325513980337,
        "hf_subset": "rus_Cyrl-mai_Deva",
        "languages": [
          "rus-Cyrl",
          "mai-Deva"
        ],
        "main_score": 0.00488325513980337,
        "precision": 0.003855260165306203,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.0032884228457280285,
        "hf_subset": "rus_Cyrl-pbt_Arab",
        "languages": [
          "rus-Cyrl",
          "pbt-Arab"
        ],
        "main_score": 0.0032884228457280285,
        "precision": 0.0028273411953725906,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.11561264822134387,
        "f1": 0.07130289032376606,
        "hf_subset": "rus_Cyrl-spa_Latn",
        "languages": [
          "rus-Cyrl",
          "spa-Latn"
        ],
        "main_score": 0.07130289032376606,
        "precision": 0.06367852252500461,
        "recall": 0.11561264822134387
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.013735608808258333,
        "hf_subset": "rus_Cyrl-twi_Latn",
        "languages": [
          "rus-Cyrl",
          "twi-Latn"
        ],
        "main_score": 0.013735608808258333,
        "precision": 0.011523423426587616,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0005317927967534898,
        "hf_subset": "rus_Cyrl-acm_Arab",
        "languages": [
          "rus-Cyrl",
          "acm-Arab"
        ],
        "main_score": 0.0005317927967534898,
        "precision": 0.00034856391166872286,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.08596837944664032,
        "f1": 0.05670645805528606,
        "hf_subset": "rus_Cyrl-bel_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bel-Cyrl"
        ],
        "main_score": 0.05670645805528606,
        "precision": 0.0518182594285571,
        "recall": 0.08596837944664032
      },
      {
        "accuracy": 0.3132411067193676,
        "f1": 0.24666811393745677,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ],
        "main_score": 0.24666811393745677,
        "precision": 0.2296388048874313,
        "recall": 0.3132411067193676
      },
      {
        "accuracy": 0.03557312252964427,
        "f1": 0.021327034137736567,
        "hf_subset": "rus_Cyrl-hrv_Latn",
        "languages": [
          "rus-Cyrl",
          "hrv-Latn"
        ],
        "main_score": 0.021327034137736567,
        "precision": 0.01876516560535904,
        "recall": 0.03557312252964427
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.00811765848945156,
        "hf_subset": "rus_Cyrl-kin_Latn",
        "languages": [
          "rus-Cyrl",
          "kin-Latn"
        ],
        "main_score": 0.00811765848945156,
        "precision": 0.006930998607476829,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.004275090415151852,
        "hf_subset": "rus_Cyrl-mal_Mlym",
        "languages": [
          "rus-Cyrl",
          "mal-Mlym"
        ],
        "main_score": 0.004275090415151852,
        "precision": 0.00370131127366879,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.000503403936687536,
        "hf_subset": "rus_Cyrl-pes_Arab",
        "languages": [
          "rus-Cyrl",
          "pes-Arab"
        ],
        "main_score": 0.000503403936687536,
        "precision": 0.00033405863162800953,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.07015810276679842,
        "f1": 0.041035611971525415,
        "hf_subset": "rus_Cyrl-srd_Latn",
        "languages": [
          "rus-Cyrl",
          "srd-Latn"
        ],
        "main_score": 0.041035611971525415,
        "precision": 0.03601137786642355,
        "recall": 0.07015810276679842
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0019047155908580781,
        "hf_subset": "rus_Cyrl-tzm_Tfng",
        "languages": [
          "rus-Cyrl",
          "tzm-Tfng"
        ],
        "main_score": 0.0019047155908580781,
        "precision": 0.0012337509982211913,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 5.580569324121277e-05,
        "hf_subset": "rus_Cyrl-acq_Arab",
        "languages": [
          "rus-Cyrl",
          "acq-Arab"
        ],
        "main_score": 5.580569324121277e-05,
        "precision": 2.864614524693576e-05,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.01649993637293152,
        "hf_subset": "rus_Cyrl-bem_Latn",
        "languages": [
          "rus-Cyrl",
          "bem-Latn"
        ],
        "main_score": 0.01649993637293152,
        "precision": 0.013460531604688512,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.05039525691699605,
        "f1": 0.02514774805782711,
        "hf_subset": "rus_Cyrl-epo_Latn",
        "languages": [
          "rus-Cyrl",
          "epo-Latn"
        ],
        "main_score": 0.02514774805782711,
        "precision": 0.021556526945337762,
        "recall": 0.05039525691699605
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.008207445951112906,
        "hf_subset": "rus_Cyrl-hun_Latn",
        "languages": [
          "rus-Cyrl",
          "hun-Latn"
        ],
        "main_score": 0.008207445951112906,
        "precision": 0.007095505946406248,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.05928853754940711,
        "f1": 0.03208324933343244,
        "hf_subset": "rus_Cyrl-kir_Cyrl",
        "languages": [
          "rus-Cyrl",
          "kir-Cyrl"
        ],
        "main_score": 0.03208324933343244,
        "precision": 0.028470021093924693,
        "recall": 0.05928853754940711
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.00393939393939394,
        "hf_subset": "rus_Cyrl-mar_Deva",
        "languages": [
          "rus-Cyrl",
          "mar-Deva"
        ],
        "main_score": 0.00393939393939394,
        "precision": 0.0033183954574675387,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.008350499725046825,
        "hf_subset": "rus_Cyrl-plt_Latn",
        "languages": [
          "rus-Cyrl",
          "plt-Latn"
        ],
        "main_score": 0.008350499725046825,
        "precision": 0.006532571085836967,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.18379446640316205,
        "f1": 0.1333930092464318,
        "hf_subset": "rus_Cyrl-srp_Cyrl",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ],
        "main_score": 0.1333930092464318,
        "precision": 0.1220025836062441,
        "recall": 0.18379446640316205
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0031663081965209346,
        "hf_subset": "rus_Cyrl-uig_Arab",
        "languages": [
          "rus-Cyrl",
          "uig-Arab"
        ],
        "main_score": 0.0031663081965209346,
        "precision": 0.0027509821085575582,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 3.495165288162595e-05,
        "hf_subset": "rus_Cyrl-aeb_Arab",
        "languages": [
          "rus-Cyrl",
          "aeb-Arab"
        ],
        "main_score": 3.495165288162595e-05,
        "precision": 1.7610546601043825e-05,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0030893574967165377,
        "hf_subset": "rus_Cyrl-ben_Beng",
        "languages": [
          "rus-Cyrl",
          "ben-Beng"
        ],
        "main_score": 0.0030893574967165377,
        "precision": 0.0026232412537785794,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.006260867028646968,
        "hf_subset": "rus_Cyrl-est_Latn",
        "languages": [
          "rus-Cyrl",
          "est-Latn"
        ],
        "main_score": 0.006260867028646968,
        "precision": 0.005071652609211061,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.0033144166035822117,
        "hf_subset": "rus_Cyrl-hye_Armn",
        "languages": [
          "rus-Cyrl",
          "hye-Armn"
        ],
        "main_score": 0.0033144166035822117,
        "precision": 0.002385408515609544,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.009920795543441361,
        "hf_subset": "rus_Cyrl-kmb_Latn",
        "languages": [
          "rus-Cyrl",
          "kmb-Latn"
        ],
        "main_score": 0.009920795543441361,
        "precision": 0.00756988120317472,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.00022982886821161887,
        "hf_subset": "rus_Cyrl-min_Arab",
        "languages": [
          "rus-Cyrl",
          "min-Arab"
        ],
        "main_score": 0.00022982886821161887,
        "precision": 0.00012010886318656079,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.05731225296442688,
        "f1": 0.031145363286967036,
        "hf_subset": "rus_Cyrl-pol_Latn",
        "languages": [
          "rus-Cyrl",
          "pol-Latn"
        ],
        "main_score": 0.031145363286967036,
        "precision": 0.026389183627539014,
        "recall": 0.05731225296442688
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.01063835066515331,
        "hf_subset": "rus_Cyrl-ssw_Latn",
        "languages": [
          "rus-Cyrl",
          "ssw-Latn"
        ],
        "main_score": 0.01063835066515331,
        "precision": 0.008391198930670283,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.8517786561264822,
        "f1": 0.8125682288725766,
        "hf_subset": "rus_Cyrl-ukr_Cyrl",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ],
        "main_score": 0.8125682288725766,
        "precision": 0.7962560386473431,
        "recall": 0.8517786561264822
      },
      {
        "accuracy": 0.06620553359683795,
        "f1": 0.02890096559859879,
        "hf_subset": "rus_Cyrl-afr_Latn",
        "languages": [
          "rus-Cyrl",
          "afr-Latn"
        ],
        "main_score": 0.02890096559859879,
        "precision": 0.021807083125015687,
        "recall": 0.06620553359683795
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.002996636836049089,
        "hf_subset": "rus_Cyrl-bho_Deva",
        "languages": [
          "rus-Cyrl",
          "bho-Deva"
        ],
        "main_score": 0.002996636836049089,
        "precision": 0.002387865878919038,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.011409560129719592,
        "hf_subset": "rus_Cyrl-eus_Latn",
        "languages": [
          "rus-Cyrl",
          "eus-Latn"
        ],
        "main_score": 0.011409560129719592,
        "precision": 0.009468758290881927,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.025691699604743084,
        "f1": 0.010255863545959712,
        "hf_subset": "rus_Cyrl-ibo_Latn",
        "languages": [
          "rus-Cyrl",
          "ibo-Latn"
        ],
        "main_score": 0.010255863545959712,
        "precision": 0.008451656659390074,
        "recall": 0.025691699604743084
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.006575576756739463,
        "hf_subset": "rus_Cyrl-kmr_Latn",
        "languages": [
          "rus-Cyrl",
          "kmr-Latn"
        ],
        "main_score": 0.006575576756739463,
        "precision": 0.006094616484741453,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.014117537167111935,
        "hf_subset": "rus_Cyrl-min_Latn",
        "languages": [
          "rus-Cyrl",
          "min-Latn"
        ],
        "main_score": 0.014117537167111935,
        "precision": 0.012008168196710727,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.11067193675889328,
        "f1": 0.06468114212264615,
        "hf_subset": "rus_Cyrl-por_Latn",
        "languages": [
          "rus-Cyrl",
          "por-Latn"
        ],
        "main_score": 0.06468114212264615,
        "precision": 0.05511846220595671,
        "recall": 0.11067193675889328
      },
      {
        "accuracy": 0.041501976284584984,
        "f1": 0.014229145906043928,
        "hf_subset": "rus_Cyrl-sun_Latn",
        "languages": [
          "rus-Cyrl",
          "sun-Latn"
        ],
        "main_score": 0.014229145906043928,
        "precision": 0.010441466935141037,
        "recall": 0.041501976284584984
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.008616303979173451,
        "hf_subset": "rus_Cyrl-umb_Latn",
        "languages": [
          "rus-Cyrl",
          "umb-Latn"
        ],
        "main_score": 0.008616303979173451,
        "precision": 0.007181241881072281,
        "recall": 0.022727272727272728
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.001155359892711166,
        "hf_subset": "rus_Cyrl-ajp_Arab",
        "languages": [
          "rus-Cyrl",
          "ajp-Arab"
        ],
        "main_score": 0.001155359892711166,
        "precision": 0.0008247171374154617,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 9.055664862001286e-05,
        "hf_subset": "rus_Cyrl-bjn_Arab",
        "languages": [
          "rus-Cyrl",
          "bjn-Arab"
        ],
        "main_score": 9.055664862001286e-05,
        "precision": 4.633907350629895e-05,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.006272448939384453,
        "hf_subset": "rus_Cyrl-ewe_Latn",
        "languages": [
          "rus-Cyrl",
          "ewe-Latn"
        ],
        "main_score": 0.006272448939384453,
        "precision": 0.004480024066307053,
        "recall": 0.019762845849802372
      },
      {
        "accuracy": 0.038537549407114624,
        "f1": 0.017615618925991228,
        "hf_subset": "rus_Cyrl-ilo_Latn",
        "languages": [
          "rus-Cyrl",
          "ilo-Latn"
        ],
        "main_score": 0.017615618925991228,
        "precision": 0.014933395307368867,
        "recall": 0.038537549407114624
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 2.49216215003813e-06,
        "hf_subset": "rus_Cyrl-knc_Arab",
        "languages": [
          "rus-Cyrl",
          "knc-Arab"
        ],
        "main_score": 2.49216215003813e-06,
        "precision": 1.2476544097097459e-06,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.17193675889328064,
        "f1": 0.12122670083946831,
        "hf_subset": "rus_Cyrl-mkd_Cyrl",
        "languages": [
          "rus-Cyrl",
          "mkd-Cyrl"
        ],
        "main_score": 0.12122670083946831,
        "precision": 0.10949833208268726,
        "recall": 0.17193675889328064
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 3.699943863765617e-05,
        "hf_subset": "rus_Cyrl-prs_Arab",
        "languages": [
          "rus-Cyrl",
          "prs-Arab"
        ],
        "main_score": 3.699943863765617e-05,
        "precision": 1.8810660217551112e-05,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.04743083003952569,
        "f1": 0.02720373022786188,
        "hf_subset": "rus_Cyrl-swe_Latn",
        "languages": [
          "rus-Cyrl",
          "swe-Latn"
        ],
        "main_score": 0.02720373022786188,
        "precision": 0.02458958187018134,
        "recall": 0.04743083003952569
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0024614947720035824,
        "hf_subset": "rus_Cyrl-urd_Arab",
        "languages": [
          "rus-Cyrl",
          "urd-Arab"
        ],
        "main_score": 0.0024614947720035824,
        "precision": 0.0019334189097340874,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.03557312252964427,
        "f1": 0.011897454861631287,
        "hf_subset": "rus_Cyrl-aka_Latn",
        "languages": [
          "rus-Cyrl",
          "aka-Latn"
        ],
        "main_score": 0.011897454861631287,
        "precision": 0.00862103240723604,
        "recall": 0.03557312252964427
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.017561647558238795,
        "hf_subset": "rus_Cyrl-bjn_Latn",
        "languages": [
          "rus-Cyrl",
          "bjn-Latn"
        ],
        "main_score": 0.017561647558238795,
        "precision": 0.01548960384292478,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.011126095174129876,
        "hf_subset": "rus_Cyrl-fao_Latn",
        "languages": [
          "rus-Cyrl",
          "fao-Latn"
        ],
        "main_score": 0.011126095174129876,
        "precision": 0.009005537447974329,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.016832211166134196,
        "hf_subset": "rus_Cyrl-ind_Latn",
        "languages": [
          "rus-Cyrl",
          "ind-Latn"
        ],
        "main_score": 0.016832211166134196,
        "precision": 0.014878643056639893,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.016478304142049944,
        "hf_subset": "rus_Cyrl-knc_Latn",
        "languages": [
          "rus-Cyrl",
          "knc-Latn"
        ],
        "main_score": 0.016478304142049944,
        "precision": 0.013848248221581632,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.041501976284584984,
        "f1": 0.020392822740823206,
        "hf_subset": "rus_Cyrl-mlt_Latn",
        "languages": [
          "rus-Cyrl",
          "mlt-Latn"
        ],
        "main_score": 0.020392822740823206,
        "precision": 0.01785254900039287,
        "recall": 0.041501976284584984
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.006987306640188831,
        "hf_subset": "rus_Cyrl-quy_Latn",
        "languages": [
          "rus-Cyrl",
          "quy-Latn"
        ],
        "main_score": 0.006987306640188831,
        "precision": 0.005166199948539149,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.011292547554627781,
        "hf_subset": "rus_Cyrl-swh_Latn",
        "languages": [
          "rus-Cyrl",
          "swh-Latn"
        ],
        "main_score": 0.011292547554627781,
        "precision": 0.009087930702181389,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.007119037560705668,
        "hf_subset": "rus_Cyrl-uzn_Latn",
        "languages": [
          "rus-Cyrl",
          "uzn-Latn"
        ],
        "main_score": 0.007119037560705668,
        "precision": 0.005557328969137945,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.0266798418972332,
        "f1": 0.011307899410270017,
        "hf_subset": "rus_Cyrl-als_Latn",
        "languages": [
          "rus-Cyrl",
          "als-Latn"
        ],
        "main_score": 0.011307899410270017,
        "precision": 0.009338237701847033,
        "recall": 0.0266798418972332
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0032962657070379326,
        "hf_subset": "rus_Cyrl-bod_Tibt",
        "languages": [
          "rus-Cyrl",
          "bod-Tibt"
        ],
        "main_score": 0.0032962657070379326,
        "precision": 0.0029656574407237683,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.007604554791743641,
        "hf_subset": "rus_Cyrl-fij_Latn",
        "languages": [
          "rus-Cyrl",
          "fij-Latn"
        ],
        "main_score": 0.007604554791743641,
        "precision": 0.005748661735091206,
        "recall": 0.019762845849802372
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.006353591278821826,
        "hf_subset": "rus_Cyrl-isl_Latn",
        "languages": [
          "rus-Cyrl",
          "isl-Latn"
        ],
        "main_score": 0.006353591278821826,
        "precision": 0.004908041019026893,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.029644268774703556,
        "f1": 0.01380798557242742,
        "hf_subset": "rus_Cyrl-kon_Latn",
        "languages": [
          "rus-Cyrl",
          "kon-Latn"
        ],
        "main_score": 0.01380798557242742,
        "precision": 0.011061911281066945,
        "recall": 0.029644268774703556
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.003731196183545907,
        "hf_subset": "rus_Cyrl-mni_Beng",
        "languages": [
          "rus-Cyrl",
          "mni-Beng"
        ],
        "main_score": 0.003731196183545907,
        "precision": 0.003201126347757023,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.05138339920948617,
        "f1": 0.024033761976322156,
        "hf_subset": "rus_Cyrl-ron_Latn",
        "languages": [
          "rus-Cyrl",
          "ron-Latn"
        ],
        "main_score": 0.024033761976322156,
        "precision": 0.02004202750148025,
        "recall": 0.05138339920948617
      },
      {
        "accuracy": 0.05138339920948617,
        "f1": 0.024654094999984187,
        "hf_subset": "rus_Cyrl-szl_Latn",
        "languages": [
          "rus-Cyrl",
          "szl-Latn"
        ],
        "main_score": 0.024654094999984187,
        "precision": 0.02066173358674567,
        "recall": 0.05138339920948617
      },
      {
        "accuracy": 0.07114624505928854,
        "f1": 0.03827700774111118,
        "hf_subset": "rus_Cyrl-vec_Latn",
        "languages": [
          "rus-Cyrl",
          "vec-Latn"
        ],
        "main_score": 0.03827700774111118,
        "precision": 0.032205181458864106,
        "recall": 0.07114624505928854
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.00502993356780131,
        "hf_subset": "rus_Cyrl-amh_Ethi",
        "languages": [
          "rus-Cyrl",
          "amh-Ethi"
        ],
        "main_score": 0.00502993356780131,
        "precision": 0.0039294601946400845,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.040513833992094864,
        "f1": 0.022806895053026025,
        "hf_subset": "rus_Cyrl-bos_Latn",
        "languages": [
          "rus-Cyrl",
          "bos-Latn"
        ],
        "main_score": 0.022806895053026025,
        "precision": 0.01924712239941121,
        "recall": 0.040513833992094864
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.007953368765771232,
        "hf_subset": "rus_Cyrl-fin_Latn",
        "languages": [
          "rus-Cyrl",
          "fin-Latn"
        ],
        "main_score": 0.007953368765771232,
        "precision": 0.006822643608717368,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.11561264822134387,
        "f1": 0.06987650959673045,
        "hf_subset": "rus_Cyrl-ita_Latn",
        "languages": [
          "rus-Cyrl",
          "ita-Latn"
        ],
        "main_score": 0.06987650959673045,
        "precision": 0.06172516237918057,
        "recall": 0.11561264822134387
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.0018740447379588334,
        "hf_subset": "rus_Cyrl-kor_Hang",
        "languages": [
          "rus-Cyrl",
          "kor-Hang"
        ],
        "main_score": 0.0018740447379588334,
        "precision": 0.0012954059164743137,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.010439585816764853,
        "hf_subset": "rus_Cyrl-mos_Latn",
        "languages": [
          "rus-Cyrl",
          "mos-Latn"
        ],
        "main_score": 0.010439585816764853,
        "precision": 0.009206613977301905,
        "recall": 0.019762845849802372
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.008364935641137314,
        "hf_subset": "rus_Cyrl-run_Latn",
        "languages": [
          "rus-Cyrl",
          "run-Latn"
        ],
        "main_score": 0.008364935641137314,
        "precision": 0.0067861320434756366,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.003700904844962351,
        "hf_subset": "rus_Cyrl-tam_Taml",
        "languages": [
          "rus-Cyrl",
          "tam-Taml"
        ],
        "main_score": 0.003700904844962351,
        "precision": 0.0025479670854735743,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.039525691699604744,
        "f1": 0.012302600169903059,
        "hf_subset": "rus_Cyrl-vie_Latn",
        "languages": [
          "rus-Cyrl",
          "vie-Latn"
        ],
        "main_score": 0.012302600169903059,
        "precision": 0.009178510869517556,
        "recall": 0.039525691699604744
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0006271939337095843,
        "hf_subset": "rus_Cyrl-apc_Arab",
        "languages": [
          "rus-Cyrl",
          "apc-Arab"
        ],
        "main_score": 0.0006271939337095843,
        "precision": 0.00039869751895130743,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.01499537758518868,
        "hf_subset": "rus_Cyrl-bug_Latn",
        "languages": [
          "rus-Cyrl",
          "bug-Latn"
        ],
        "main_score": 0.01499537758518868,
        "precision": 0.011733989013522987,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.0055960270587402695,
        "hf_subset": "rus_Cyrl-fon_Latn",
        "languages": [
          "rus-Cyrl",
          "fon-Latn"
        ],
        "main_score": 0.0055960270587402695,
        "precision": 0.004738753006973745,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.03557312252964427,
        "f1": 0.020210785296662318,
        "hf_subset": "rus_Cyrl-jav_Latn",
        "languages": [
          "rus-Cyrl",
          "jav-Latn"
        ],
        "main_score": 0.020210785296662318,
        "precision": 0.01765665767914729,
        "recall": 0.03557312252964427
      },
      {
        "accuracy": 0.04743083003952569,
        "f1": 0.027889214404246795,
        "hf_subset": "rus_Cyrl-lao_Laoo",
        "languages": [
          "rus-Cyrl",
          "lao-Laoo"
        ],
        "main_score": 0.027889214404246795,
        "precision": 0.02500211169321674,
        "recall": 0.04743083003952569
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.004869124617566176,
        "hf_subset": "rus_Cyrl-mri_Latn",
        "languages": [
          "rus-Cyrl",
          "mri-Latn"
        ],
        "main_score": 0.004869124617566176,
        "precision": 0.00404992925465383,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.011529582325779445,
        "hf_subset": "rus_Cyrl-taq_Latn",
        "languages": [
          "rus-Cyrl",
          "taq-Latn"
        ],
        "main_score": 0.011529582325779445,
        "precision": 0.00924245594364357,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.044466403162055336,
        "f1": 0.023179939318421397,
        "hf_subset": "rus_Cyrl-war_Latn",
        "languages": [
          "rus-Cyrl",
          "war-Latn"
        ],
        "main_score": 0.023179939318421397,
        "precision": 0.01978019819688901,
        "recall": 0.044466403162055336
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0002926259621917526,
        "hf_subset": "rus_Cyrl-arb_Arab",
        "languages": [
          "rus-Cyrl",
          "arb-Arab"
        ],
        "main_score": 0.0002926259621917526,
        "precision": 0.00016985621931236302,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.233201581027668,
        "f1": 0.17688821643476127,
        "hf_subset": "rus_Cyrl-bul_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bul-Cyrl"
        ],
        "main_score": 0.17688821643476127,
        "precision": 0.16338021352314613,
        "recall": 0.233201581027668
      },
      {
        "accuracy": 0.13339920948616601,
        "f1": 0.08655209080870171,
        "hf_subset": "rus_Cyrl-fra_Latn",
        "languages": [
          "rus-Cyrl",
          "fra-Latn"
        ],
        "main_score": 0.08655209080870171,
        "precision": 0.07750154954810734,
        "recall": 0.13339920948616601
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.007824801568173783,
        "hf_subset": "rus_Cyrl-jpn_Jpan",
        "languages": [
          "rus-Cyrl",
          "jpn-Jpan"
        ],
        "main_score": 0.007824801568173783,
        "precision": 0.00755323560954062,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.05632411067193676,
        "f1": 0.026601824309635102,
        "hf_subset": "rus_Cyrl-lij_Latn",
        "languages": [
          "rus-Cyrl",
          "lij-Latn"
        ],
        "main_score": 0.026601824309635102,
        "precision": 0.022656610738776204,
        "recall": 0.05632411067193676
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.004542535883931399,
        "hf_subset": "rus_Cyrl-mya_Mymr",
        "languages": [
          "rus-Cyrl",
          "mya-Mymr"
        ],
        "main_score": 0.004542535883931399,
        "precision": 0.0031407637028346407,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.029644268774703556,
        "f1": 0.01138778036927635,
        "hf_subset": "rus_Cyrl-sag_Latn",
        "languages": [
          "rus-Cyrl",
          "sag-Latn"
        ],
        "main_score": 0.01138778036927635,
        "precision": 0.009490970053051774,
        "recall": 0.029644268774703556
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.001497812577434418,
        "hf_subset": "rus_Cyrl-taq_Tfng",
        "languages": [
          "rus-Cyrl",
          "taq-Tfng"
        ],
        "main_score": 0.001497812577434418,
        "precision": 0.0009464513756127395,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.01502147884982623,
        "hf_subset": "rus_Cyrl-wol_Latn",
        "languages": [
          "rus-Cyrl",
          "wol-Latn"
        ],
        "main_score": 0.01502147884982623,
        "precision": 0.012647745983742924,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.008174773513458331,
        "hf_subset": "rus_Cyrl-arb_Latn",
        "languages": [
          "rus-Cyrl",
          "arb-Latn"
        ],
        "main_score": 0.008174773513458331,
        "precision": 0.0066692810995693215,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.09683794466403162,
        "f1": 0.06811405482633967,
        "hf_subset": "rus_Cyrl-cat_Latn",
        "languages": [
          "rus-Cyrl",
          "cat-Latn"
        ],
        "main_score": 0.06811405482633967,
        "precision": 0.062343460142243165,
        "recall": 0.09683794466403162
      },
      {
        "accuracy": 0.038537549407114624,
        "f1": 0.020378851073357927,
        "hf_subset": "rus_Cyrl-fur_Latn",
        "languages": [
          "rus-Cyrl",
          "fur-Latn"
        ],
        "main_score": 0.020378851073357927,
        "precision": 0.017498982582734735,
        "recall": 0.038537549407114624
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.0043359457959650976,
        "hf_subset": "rus_Cyrl-kab_Latn",
        "languages": [
          "rus-Cyrl",
          "kab-Latn"
        ],
        "main_score": 0.0043359457959650976,
        "precision": 0.003439090473945034,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.04743083003952569,
        "f1": 0.026896261212105286,
        "hf_subset": "rus_Cyrl-lim_Latn",
        "languages": [
          "rus-Cyrl",
          "lim-Latn"
        ],
        "main_score": 0.026896261212105286,
        "precision": 0.02371546414244068,
        "recall": 0.04743083003952569
      },
      {
        "accuracy": 0.046442687747035576,
        "f1": 0.023638483137363532,
        "hf_subset": "rus_Cyrl-nld_Latn",
        "languages": [
          "rus-Cyrl",
          "nld-Latn"
        ],
        "main_score": 0.023638483137363532,
        "precision": 0.019277263161554304,
        "recall": 0.046442687747035576
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.005736821222192419,
        "hf_subset": "rus_Cyrl-san_Deva",
        "languages": [
          "rus-Cyrl",
          "san-Deva"
        ],
        "main_score": 0.005736821222192419,
        "precision": 0.00452660576454923,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.06521739130434782,
        "f1": 0.03200226845467202,
        "hf_subset": "rus_Cyrl-tat_Cyrl",
        "languages": [
          "rus-Cyrl",
          "tat-Cyrl"
        ],
        "main_score": 0.03200226845467202,
        "precision": 0.026974345552195328,
        "recall": 0.06521739130434782
      },
      {
        "accuracy": 0.03359683794466403,
        "f1": 0.011894461847754658,
        "hf_subset": "rus_Cyrl-xho_Latn",
        "languages": [
          "rus-Cyrl",
          "xho-Latn"
        ],
        "main_score": 0.011894461847754658,
        "precision": 0.009156081923236834,
        "recall": 0.03359683794466403
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.00029266231144007426,
        "hf_subset": "rus_Cyrl-ars_Arab",
        "languages": [
          "rus-Cyrl",
          "ars-Arab"
        ],
        "main_score": 0.00029266231144007426,
        "precision": 0.00016987451148458565,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.036561264822134384,
        "f1": 0.016679883107707058,
        "hf_subset": "rus_Cyrl-ceb_Latn",
        "languages": [
          "rus-Cyrl",
          "ceb-Latn"
        ],
        "main_score": 0.016679883107707058,
        "precision": 0.014070246836588935,
        "recall": 0.036561264822134384
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.012138003596343105,
        "hf_subset": "rus_Cyrl-fuv_Latn",
        "languages": [
          "rus-Cyrl",
          "fuv-Latn"
        ],
        "main_score": 0.012138003596343105,
        "precision": 0.010482407288086143,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.0266798418972332,
        "f1": 0.01053946276215231,
        "hf_subset": "rus_Cyrl-kac_Latn",
        "languages": [
          "rus-Cyrl",
          "kac-Latn"
        ],
        "main_score": 0.01053946276215231,
        "precision": 0.008465439580206513,
        "recall": 0.0266798418972332
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.012383499384364704,
        "hf_subset": "rus_Cyrl-lin_Latn",
        "languages": [
          "rus-Cyrl",
          "lin-Latn"
        ],
        "main_score": 0.012383499384364704,
        "precision": 0.010251753367382438,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.08399209486166008,
        "f1": 0.04745854197928531,
        "hf_subset": "rus_Cyrl-nno_Latn",
        "languages": [
          "rus-Cyrl",
          "nno-Latn"
        ],
        "main_score": 0.04745854197928531,
        "precision": 0.041842120826681206,
        "recall": 0.08399209486166008
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.001984428628889472,
        "hf_subset": "rus_Cyrl-sat_Olck",
        "languages": [
          "rus-Cyrl",
          "sat-Olck"
        ],
        "main_score": 0.001984428628889472,
        "precision": 0.0012788137962571478,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.00719067602260714,
        "hf_subset": "rus_Cyrl-tel_Telu",
        "languages": [
          "rus-Cyrl",
          "tel-Telu"
        ],
        "main_score": 0.00719067602260714,
        "precision": 0.00596045001006092,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 2.204741033017325e-05,
        "hf_subset": "rus_Cyrl-ydd_Hebr",
        "languages": [
          "rus-Cyrl",
          "ydd-Hebr"
        ],
        "main_score": 2.204741033017325e-05,
        "precision": 1.1067160793451636e-05,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 9.84308787475894e-06,
        "hf_subset": "rus_Cyrl-ary_Arab",
        "languages": [
          "rus-Cyrl",
          "ary-Arab"
        ],
        "main_score": 9.84308787475894e-06,
        "precision": 4.9348191410881e-06,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.0533596837944664,
        "f1": 0.02945746018991929,
        "hf_subset": "rus_Cyrl-ces_Latn",
        "languages": [
          "rus-Cyrl",
          "ces-Latn"
        ],
        "main_score": 0.02945746018991929,
        "precision": 0.025003288583628002,
        "recall": 0.0533596837944664
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.005449246836401009,
        "hf_subset": "rus_Cyrl-gaz_Latn",
        "languages": [
          "rus-Cyrl",
          "gaz-Latn"
        ],
        "main_score": 0.005449246836401009,
        "precision": 0.004278581975472577,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.011644870384510593,
        "hf_subset": "rus_Cyrl-kam_Latn",
        "languages": [
          "rus-Cyrl",
          "kam-Latn"
        ],
        "main_score": 0.011644870384510593,
        "precision": 0.009745105645104538,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.009799728997039686,
        "hf_subset": "rus_Cyrl-lit_Latn",
        "languages": [
          "rus-Cyrl",
          "lit-Latn"
        ],
        "main_score": 0.009799728997039686,
        "precision": 0.008520334428132978,
        "recall": 0.019762845849802372
      },
      {
        "accuracy": 0.06818181818181818,
        "f1": 0.04085251031283748,
        "hf_subset": "rus_Cyrl-nob_Latn",
        "languages": [
          "rus-Cyrl",
          "nob-Latn"
        ],
        "main_score": 0.04085251031283748,
        "precision": 0.0357088872307788,
        "recall": 0.06818181818181818
      },
      {
        "accuracy": 0.04940711462450593,
        "f1": 0.026492757618490015,
        "hf_subset": "rus_Cyrl-scn_Latn",
        "languages": [
          "rus-Cyrl",
          "scn-Latn"
        ],
        "main_score": 0.026492757618490015,
        "precision": 0.02273966785355497,
        "recall": 0.04940711462450593
      },
      {
        "accuracy": 0.03359683794466403,
        "f1": 0.014511660890831696,
        "hf_subset": "rus_Cyrl-tgk_Cyrl",
        "languages": [
          "rus-Cyrl",
          "tgk-Cyrl"
        ],
        "main_score": 0.014511660890831696,
        "precision": 0.012460272373377086,
        "recall": 0.03359683794466403
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.007748140248737706,
        "hf_subset": "rus_Cyrl-yor_Latn",
        "languages": [
          "rus-Cyrl",
          "yor-Latn"
        ],
        "main_score": 0.007748140248737706,
        "precision": 0.006075925242831677,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0005855092136413129,
        "hf_subset": "rus_Cyrl-arz_Arab",
        "languages": [
          "rus-Cyrl",
          "arz-Arab"
        ],
        "main_score": 0.0005855092136413129,
        "precision": 0.0003759316309043842,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.024703557312252964,
        "f1": 0.010371762657568843,
        "hf_subset": "rus_Cyrl-cjk_Latn",
        "languages": [
          "rus-Cyrl",
          "cjk-Latn"
        ],
        "main_score": 0.010371762657568843,
        "precision": 0.008272766398497413,
        "recall": 0.024703557312252964
      },
      {
        "accuracy": 0.025691699604743084,
        "f1": 0.007309532186391824,
        "hf_subset": "rus_Cyrl-gla_Latn",
        "languages": [
          "rus-Cyrl",
          "gla-Latn"
        ],
        "main_score": 0.007309532186391824,
        "precision": 0.005075520514008765,
        "recall": 0.025691699604743084
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.003681199642466796,
        "hf_subset": "rus_Cyrl-kan_Knda",
        "languages": [
          "rus-Cyrl",
          "kan-Knda"
        ],
        "main_score": 0.003681199642466796,
        "precision": 0.0027414034724700634,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.06324110671936758,
        "f1": 0.0309198875336923,
        "hf_subset": "rus_Cyrl-lmo_Latn",
        "languages": [
          "rus-Cyrl",
          "lmo-Latn"
        ],
        "main_score": 0.0309198875336923,
        "precision": 0.026163322875842335,
        "recall": 0.06324110671936758
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.004612419027049572,
        "hf_subset": "rus_Cyrl-npi_Deva",
        "languages": [
          "rus-Cyrl",
          "npi-Deva"
        ],
        "main_score": 0.004612419027049572,
        "precision": 0.003994768746321541,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.06620553359683795,
        "f1": 0.037824856976012164,
        "hf_subset": "rus_Cyrl-shn_Mymr",
        "languages": [
          "rus-Cyrl",
          "shn-Mymr"
        ],
        "main_score": 0.037824856976012164,
        "precision": 0.03228713703240744,
        "recall": 0.06620553359683795
      },
      {
        "accuracy": 0.030632411067193676,
        "f1": 0.013165612792542048,
        "hf_subset": "rus_Cyrl-tgl_Latn",
        "languages": [
          "rus-Cyrl",
          "tgl-Latn"
        ],
        "main_score": 0.013165612792542048,
        "precision": 0.011514478033842987,
        "recall": 0.030632411067193676
      },
      {
        "accuracy": 0.04841897233201581,
        "f1": 0.029535289331911928,
        "hf_subset": "rus_Cyrl-yue_Hant",
        "languages": [
          "rus-Cyrl",
          "yue-Hant"
        ],
        "main_score": 0.029535289331911928,
        "precision": 0.026834830483448896,
        "recall": 0.04841897233201581
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.004655554883254728,
        "hf_subset": "rus_Cyrl-asm_Beng",
        "languages": [
          "rus-Cyrl",
          "asm-Beng"
        ],
        "main_score": 0.004655554883254728,
        "precision": 0.004365052448888846,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0006947559400812198,
        "hf_subset": "rus_Cyrl-ckb_Arab",
        "languages": [
          "rus-Cyrl",
          "ckb-Arab"
        ],
        "main_score": 0.0006947559400812198,
        "precision": 0.0003749485178935548,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.008219757743207285,
        "hf_subset": "rus_Cyrl-gle_Latn",
        "languages": [
          "rus-Cyrl",
          "gle-Latn"
        ],
        "main_score": 0.008219757743207285,
        "precision": 0.006625012578333652,
        "recall": 0.022727272727272728
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.00029150591079641643,
        "hf_subset": "rus_Cyrl-kas_Arab",
        "languages": [
          "rus-Cyrl",
          "kas-Arab"
        ],
        "main_score": 0.00029150591079641643,
        "precision": 0.00015796635475388732,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.025691699604743084,
        "f1": 0.0141721150681981,
        "hf_subset": "rus_Cyrl-ltg_Latn",
        "languages": [
          "rus-Cyrl",
          "ltg-Latn"
        ],
        "main_score": 0.0141721150681981,
        "precision": 0.01228788218827888,
        "recall": 0.025691699604743084
      },
      {
        "accuracy": 0.024703557312252964,
        "f1": 0.009443538967991074,
        "hf_subset": "rus_Cyrl-nso_Latn",
        "languages": [
          "rus-Cyrl",
          "nso-Latn"
        ],
        "main_score": 0.009443538967991074,
        "precision": 0.007247749404812893,
        "recall": 0.024703557312252964
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.003923886649803103,
        "hf_subset": "rus_Cyrl-sin_Sinh",
        "languages": [
          "rus-Cyrl",
          "sin-Sinh"
        ],
        "main_score": 0.003923886649803103,
        "precision": 0.0026788884084253672,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.03557312252964427,
        "f1": 0.021305251754742748,
        "hf_subset": "rus_Cyrl-tha_Thai",
        "languages": [
          "rus-Cyrl",
          "tha-Thai"
        ],
        "main_score": 0.021305251754742748,
        "precision": 0.018685033365498063,
        "recall": 0.03557312252964427
      },
      {
        "accuracy": 0.06620553359683795,
        "f1": 0.03762366155631733,
        "hf_subset": "rus_Cyrl-zho_Hans",
        "languages": [
          "rus-Cyrl",
          "zho-Hans"
        ],
        "main_score": 0.03762366155631733,
        "precision": 0.03322354255653129,
        "recall": 0.06620553359683795
      },
      {
        "accuracy": 0.08992094861660078,
        "f1": 0.05432744487486874,
        "hf_subset": "rus_Cyrl-ast_Latn",
        "languages": [
          "rus-Cyrl",
          "ast-Latn"
        ],
        "main_score": 0.05432744487486874,
        "precision": 0.048953796695536796,
        "recall": 0.08992094861660078
      },
      {
        "accuracy": 0.03260869565217391,
        "f1": 0.010099852289835105,
        "hf_subset": "rus_Cyrl-crh_Latn",
        "languages": [
          "rus-Cyrl",
          "crh-Latn"
        ],
        "main_score": 0.010099852289835105,
        "precision": 0.007804384814268085,
        "recall": 0.03260869565217391
      },
      {
        "accuracy": 0.07509881422924901,
        "f1": 0.04829177172921879,
        "hf_subset": "rus_Cyrl-glg_Latn",
        "languages": [
          "rus-Cyrl",
          "glg-Latn"
        ],
        "main_score": 0.04829177172921879,
        "precision": 0.042930321629581616,
        "recall": 0.07509881422924901
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.004623943470961676,
        "hf_subset": "rus_Cyrl-kas_Deva",
        "languages": [
          "rus-Cyrl",
          "kas-Deva"
        ],
        "main_score": 0.004623943470961676,
        "precision": 0.0041235930258221145,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.039525691699604744,
        "f1": 0.022715141979457006,
        "hf_subset": "rus_Cyrl-ltz_Latn",
        "languages": [
          "rus-Cyrl",
          "ltz-Latn"
        ],
        "main_score": 0.022715141979457006,
        "precision": 0.020054955488068255,
        "recall": 0.039525691699604744
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.0019401151930209671,
        "hf_subset": "rus_Cyrl-nus_Latn",
        "languages": [
          "rus-Cyrl",
          "nus-Latn"
        ],
        "main_score": 0.0019401151930209671,
        "precision": 0.0012111925128654747,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.05039525691699605,
        "f1": 0.026488307357659,
        "hf_subset": "rus_Cyrl-slk_Latn",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ],
        "main_score": 0.026488307357659,
        "precision": 0.023091317005197926,
        "recall": 0.05039525691699605
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0005915239363949553,
        "hf_subset": "rus_Cyrl-tir_Ethi",
        "languages": [
          "rus-Cyrl",
          "tir-Ethi"
        ],
        "main_score": 0.0005915239363949553,
        "precision": 0.00031265868952531033,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.06719367588932806,
        "f1": 0.03837629640027368,
        "hf_subset": "rus_Cyrl-zho_Hant",
        "languages": [
          "rus-Cyrl",
          "zho-Hant"
        ],
        "main_score": 0.03837629640027368,
        "precision": 0.033090456091093186,
        "recall": 0.06719367588932806
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0030507645626222705,
        "hf_subset": "rus_Cyrl-awa_Deva",
        "languages": [
          "rus-Cyrl",
          "awa-Deva"
        ],
        "main_score": 0.0030507645626222705,
        "precision": 0.0026343381652855066,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.0086237574290972,
        "hf_subset": "rus_Cyrl-cym_Latn",
        "languages": [
          "rus-Cyrl",
          "cym-Latn"
        ],
        "main_score": 0.0086237574290972,
        "precision": 0.0072937112796304425,
        "recall": 0.022727272727272728
      },
      {
        "accuracy": 0.036561264822134384,
        "f1": 0.01349012402404034,
        "hf_subset": "rus_Cyrl-grn_Latn",
        "languages": [
          "rus-Cyrl",
          "grn-Latn"
        ],
        "main_score": 0.01349012402404034,
        "precision": 0.010911489081216615,
        "recall": 0.036561264822134384
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.004767159624950189,
        "hf_subset": "rus_Cyrl-kat_Geor",
        "languages": [
          "rus-Cyrl",
          "kat-Geor"
        ],
        "main_score": 0.004767159624950189,
        "precision": 0.003794327064610258,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.024703557312252964,
        "f1": 0.010458240489597634,
        "hf_subset": "rus_Cyrl-lua_Latn",
        "languages": [
          "rus-Cyrl",
          "lua-Latn"
        ],
        "main_score": 0.010458240489597634,
        "precision": 0.008662957038569135,
        "recall": 0.024703557312252964
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.010176882282852493,
        "hf_subset": "rus_Cyrl-nya_Latn",
        "languages": [
          "rus-Cyrl",
          "nya-Latn"
        ],
        "main_score": 0.010176882282852493,
        "precision": 0.007951433382804348,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.046442687747035576,
        "f1": 0.022567953655872188,
        "hf_subset": "rus_Cyrl-slv_Latn",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ],
        "main_score": 0.022567953655872188,
        "precision": 0.0186554286553105,
        "recall": 0.046442687747035576
      },
      {
        "accuracy": 0.046442687747035576,
        "f1": 0.023015975069025578,
        "hf_subset": "rus_Cyrl-tpi_Latn",
        "languages": [
          "rus-Cyrl",
          "tpi-Latn"
        ],
        "main_score": 0.023015975069025578,
        "precision": 0.018917513516094497,
        "recall": 0.046442687747035576
      },
      {
        "accuracy": 0.03557312252964427,
        "f1": 0.02155399104923255,
        "hf_subset": "rus_Cyrl-zsm_Latn",
        "languages": [
          "rus-Cyrl",
          "zsm-Latn"
        ],
        "main_score": 0.02155399104923255,
        "precision": 0.019053885443954064,
        "recall": 0.03557312252964427
      },
      {
        "accuracy": 0.022727272727272728,
        "f1": 0.007440201816184444,
        "hf_subset": "rus_Cyrl-ayr_Latn",
        "languages": [
          "rus-Cyrl",
          "ayr-Latn"
        ],
        "main_score": 0.007440201816184444,
        "precision": 0.005663344321606451,
        "recall": 0.022727272727272728
      },
      {
        "accuracy": 0.07806324110671936,
        "f1": 0.043533423235161794,
        "hf_subset": "rus_Cyrl-dan_Latn",
        "languages": [
          "rus-Cyrl",
          "dan-Latn"
        ],
        "main_score": 0.043533423235161794,
        "precision": 0.03822279904698018,
        "recall": 0.07806324110671936
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.002856311945052403,
        "hf_subset": "rus_Cyrl-guj_Gujr",
        "languages": [
          "rus-Cyrl",
          "guj-Gujr"
        ],
        "main_score": 0.002856311945052403,
        "precision": 0.0021881694214516212,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.06126482213438735,
        "f1": 0.029339784372316453,
        "hf_subset": "rus_Cyrl-kaz_Cyrl",
        "languages": [
          "rus-Cyrl",
          "kaz-Cyrl"
        ],
        "main_score": 0.029339784372316453,
        "precision": 0.02494123839261543,
        "recall": 0.06126482213438735
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.007010421526315611,
        "hf_subset": "rus_Cyrl-lug_Latn",
        "languages": [
          "rus-Cyrl",
          "lug-Latn"
        ],
        "main_score": 0.007010421526315611,
        "precision": 0.0051729425061756654,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.10177865612648221,
        "f1": 0.05768216575982549,
        "hf_subset": "rus_Cyrl-oci_Latn",
        "languages": [
          "rus-Cyrl",
          "oci-Latn"
        ],
        "main_score": 0.05768216575982549,
        "precision": 0.04910723998630702,
        "recall": 0.10177865612648221
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.012865865049660061,
        "hf_subset": "rus_Cyrl-smo_Latn",
        "languages": [
          "rus-Cyrl",
          "smo-Latn"
        ],
        "main_score": 0.012865865049660061,
        "precision": 0.01037352947403867,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.006459824780634852,
        "hf_subset": "rus_Cyrl-tsn_Latn",
        "languages": [
          "rus-Cyrl",
          "tsn-Latn"
        ],
        "main_score": 0.006459824780634852,
        "precision": 0.005091842636467228,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.025691699604743084,
        "f1": 0.007945928648460145,
        "hf_subset": "rus_Cyrl-zul_Latn",
        "languages": [
          "rus-Cyrl",
          "zul-Latn"
        ],
        "main_score": 0.007945928648460145,
        "precision": 0.005872470232452155,
        "recall": 0.025691699604743084
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0006637774790500458,
        "hf_subset": "rus_Cyrl-azb_Arab",
        "languages": [
          "rus-Cyrl",
          "azb-Arab"
        ],
        "main_score": 0.0006637774790500458,
        "precision": 0.0004965855032234056,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.10375494071146245,
        "f1": 0.067385416379775,
        "hf_subset": "rus_Cyrl-deu_Latn",
        "languages": [
          "rus-Cyrl",
          "deu-Latn"
        ],
        "main_score": 0.067385416379775,
        "precision": 0.061800034013261514,
        "recall": 0.10375494071146245
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.005559373105529886,
        "hf_subset": "rus_Cyrl-hat_Latn",
        "languages": [
          "rus-Cyrl",
          "hat-Latn"
        ],
        "main_score": 0.005559373105529886,
        "precision": 0.004300217172490868,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.006473901450809796,
        "hf_subset": "rus_Cyrl-kbp_Latn",
        "languages": [
          "rus-Cyrl",
          "kbp-Latn"
        ],
        "main_score": 0.006473901450809796,
        "precision": 0.004463613335314829,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.03557312252964427,
        "f1": 0.016431733895399623,
        "hf_subset": "rus_Cyrl-luo_Latn",
        "languages": [
          "rus-Cyrl",
          "luo-Latn"
        ],
        "main_score": 0.016431733895399623,
        "precision": 0.013590577456117092,
        "recall": 0.03557312252964427
      },
      {
        "accuracy": 0.01383399209486166,
        "f1": 0.004882981386942211,
        "hf_subset": "rus_Cyrl-ory_Orya",
        "languages": [
          "rus-Cyrl",
          "ory-Orya"
        ],
        "main_score": 0.004882981386942211,
        "precision": 0.0038171230825183667,
        "recall": 0.01383399209486166
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.011099591985868948,
        "hf_subset": "rus_Cyrl-sna_Latn",
        "languages": [
          "rus-Cyrl",
          "sna-Latn"
        ],
        "main_score": 0.011099591985868948,
        "precision": 0.009280814573223987,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.029644268774703556,
        "f1": 0.014069991916926013,
        "hf_subset": "rus_Cyrl-tso_Latn",
        "languages": [
          "rus-Cyrl",
          "tso-Latn"
        ],
        "main_score": 0.014069991916926013,
        "precision": 0.012239501685083469,
        "recall": 0.029644268774703556
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.010670986424482115,
        "hf_subset": "rus_Cyrl-azj_Latn",
        "languages": [
          "rus-Cyrl",
          "azj-Latn"
        ],
        "main_score": 0.010670986424482115,
        "precision": 0.008190184121468776,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.010332161869225372,
        "hf_subset": "rus_Cyrl-dik_Latn",
        "languages": [
          "rus-Cyrl",
          "dik-Latn"
        ],
        "main_score": 0.010332161869225372,
        "precision": 0.007959206842837954,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.007586336347765691,
        "hf_subset": "rus_Cyrl-hau_Latn",
        "languages": [
          "rus-Cyrl",
          "hau-Latn"
        ],
        "main_score": 0.007586336347765691,
        "precision": 0.00565232834371,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.045454545454545456,
        "f1": 0.02448865543951826,
        "hf_subset": "rus_Cyrl-kea_Latn",
        "languages": [
          "rus-Cyrl",
          "kea-Latn"
        ],
        "main_score": 0.02448865543951826,
        "precision": 0.02125973268965474,
        "recall": 0.045454545454545456
      },
      {
        "accuracy": 0.042490118577075096,
        "f1": 0.022658533535899875,
        "hf_subset": "rus_Cyrl-lus_Latn",
        "languages": [
          "rus-Cyrl",
          "lus-Latn"
        ],
        "main_score": 0.022658533535899875,
        "precision": 0.01918148747668854,
        "recall": 0.042490118577075096
      },
      {
        "accuracy": 0.06027667984189723,
        "f1": 0.03492843299809736,
        "hf_subset": "rus_Cyrl-pag_Latn",
        "languages": [
          "rus-Cyrl",
          "pag-Latn"
        ],
        "main_score": 0.03492843299809736,
        "precision": 0.030546675419828175,
        "recall": 0.06027667984189723
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0011550784525092826,
        "hf_subset": "rus_Cyrl-snd_Arab",
        "languages": [
          "rus-Cyrl",
          "snd-Arab"
        ],
        "main_score": 0.0011550784525092826,
        "precision": 0.0010790975764198118,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.006820135907326768,
        "hf_subset": "rus_Cyrl-tuk_Latn",
        "languages": [
          "rus-Cyrl",
          "tuk-Latn"
        ],
        "main_score": 0.006820135907326768,
        "precision": 0.005771768520984399,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.06818181818181818,
        "f1": 0.03689176423484456,
        "hf_subset": "rus_Cyrl-bak_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bak-Cyrl"
        ],
        "main_score": 0.03689176423484456,
        "precision": 0.032171406651455715,
        "recall": 0.06818181818181818
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.006797723991542231,
        "hf_subset": "rus_Cyrl-dyu_Latn",
        "languages": [
          "rus-Cyrl",
          "dyu-Latn"
        ],
        "main_score": 0.006797723991542231,
        "precision": 0.006073420703721963,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.00035016900448673406,
        "hf_subset": "rus_Cyrl-heb_Hebr",
        "languages": [
          "rus-Cyrl",
          "heb-Hebr"
        ],
        "main_score": 0.00035016900448673406,
        "precision": 0.00018673447787468476,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.013098115098830517,
        "hf_subset": "rus_Cyrl-khk_Cyrl",
        "languages": [
          "rus-Cyrl",
          "khk-Cyrl"
        ],
        "main_score": 0.013098115098830517,
        "precision": 0.011216937130516072,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.020750988142292492,
        "f1": 0.010701963538361545,
        "hf_subset": "rus_Cyrl-lvs_Latn",
        "languages": [
          "rus-Cyrl",
          "lvs-Latn"
        ],
        "main_score": 0.010701963538361545,
        "precision": 0.009483584010161118,
        "recall": 0.020750988142292492
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.003718357314336005,
        "hf_subset": "rus_Cyrl-pan_Guru",
        "languages": [
          "rus-Cyrl",
          "pan-Guru"
        ],
        "main_score": 0.003718357314336005,
        "precision": 0.003039569139298778,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.029644268774703556,
        "f1": 0.011353750941399423,
        "hf_subset": "rus_Cyrl-som_Latn",
        "languages": [
          "rus-Cyrl",
          "som-Latn"
        ],
        "main_score": 0.011353750941399423,
        "precision": 0.008931499032276543,
        "recall": 0.029644268774703556
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.010745620137412934,
        "hf_subset": "rus_Cyrl-tum_Latn",
        "languages": [
          "rus-Cyrl",
          "tum-Latn"
        ],
        "main_score": 0.010745620137412934,
        "precision": 0.0091855446721813,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.005120747993771708,
        "hf_subset": "taq_Latn-rus_Cyrl",
        "languages": [
          "taq-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.005120747993771708,
        "precision": 0.00478373526896471,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0046133209143848835,
        "hf_subset": "war_Latn-rus_Cyrl",
        "languages": [
          "war-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0046133209143848835,
        "precision": 0.004447636427387479,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0021785297831893612,
        "hf_subset": "arb_Arab-rus_Cyrl",
        "languages": [
          "arb-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0021785297831893612,
        "precision": 0.0020851039816370777,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.25592885375494073,
        "f1": 0.20621376290674356,
        "hf_subset": "bul_Cyrl-rus_Cyrl",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.20621376290674356,
        "precision": 0.19545019854958764,
        "recall": 0.25592885375494073
      },
      {
        "accuracy": 0.036561264822134384,
        "f1": 0.029952943611289227,
        "hf_subset": "fra_Latn-rus_Cyrl",
        "languages": [
          "fra-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.029952943611289227,
        "precision": 0.028683630168656157,
        "recall": 0.036561264822134384
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.006273976609598272,
        "hf_subset": "jpn_Jpan-rus_Cyrl",
        "languages": [
          "jpn-Jpan",
          "rus-Cyrl"
        ],
        "main_score": 0.006273976609598272,
        "precision": 0.005432668340277036,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.021739130434782608,
        "f1": 0.015773407424996368,
        "hf_subset": "lij_Latn-rus_Cyrl",
        "languages": [
          "lij-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.015773407424996368,
        "precision": 0.014606596366570438,
        "recall": 0.021739130434782608
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.0049935571674702105,
        "hf_subset": "mya_Mymr-rus_Cyrl",
        "languages": [
          "mya-Mymr",
          "rus-Cyrl"
        ],
        "main_score": 0.0049935571674702105,
        "precision": 0.0046622755343436115,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.003091027791309281,
        "hf_subset": "sag_Latn-rus_Cyrl",
        "languages": [
          "sag-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003091027791309281,
        "precision": 0.003031847002635046,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 6.476815863342046e-05,
        "hf_subset": "taq_Tfng-rus_Cyrl",
        "languages": [
          "taq-Tfng",
          "rus-Cyrl"
        ],
        "main_score": 6.476815863342046e-05,
        "precision": 3.282896837438712e-05,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0014383935521770858,
        "hf_subset": "wol_Latn-rus_Cyrl",
        "languages": [
          "wol-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0014383935521770858,
        "precision": 0.0009897621978876433,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.0009881422924901185,
        "f1": 1.9902160976638844e-06,
        "hf_subset": "arb_Latn-rus_Cyrl",
        "languages": [
          "arb-Latn",
          "rus-Cyrl"
        ],
        "main_score": 1.9902160976638844e-06,
        "precision": 9.96111181945684e-07,
        "recall": 0.0009881422924901185
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.015632493253092315,
        "hf_subset": "cat_Latn-rus_Cyrl",
        "languages": [
          "cat-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.015632493253092315,
        "precision": 0.014651467831276233,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.013737101021583778,
        "hf_subset": "fur_Latn-rus_Cyrl",
        "languages": [
          "fur-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.013737101021583778,
        "precision": 0.012900986221075618,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0014120659218859058,
        "hf_subset": "kab_Latn-rus_Cyrl",
        "languages": [
          "kab-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0014120659218859058,
        "precision": 0.0012495980579097891,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.024703557312252964,
        "f1": 0.014873845254909653,
        "hf_subset": "lim_Latn-rus_Cyrl",
        "languages": [
          "lim-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.014873845254909653,
        "precision": 0.013381419084904062,
        "recall": 0.024703557312252964
      },
      {
        "accuracy": 0.029644268774703556,
        "f1": 0.019823530736202195,
        "hf_subset": "nld_Latn-rus_Cyrl",
        "languages": [
          "nld-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.019823530736202195,
        "precision": 0.018623616322678747,
        "recall": 0.029644268774703556
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.004920748991895236,
        "hf_subset": "san_Deva-rus_Cyrl",
        "languages": [
          "san-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.004920748991895236,
        "precision": 0.00461721249764728,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.05632411067193676,
        "f1": 0.03917818334078058,
        "hf_subset": "tat_Cyrl-rus_Cyrl",
        "languages": [
          "tat-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.03917818334078058,
        "precision": 0.0361723955823989,
        "recall": 0.05632411067193676
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0019015883799683962,
        "hf_subset": "xho_Latn-rus_Cyrl",
        "languages": [
          "xho-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0019015883799683962,
        "precision": 0.001338576889038144,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0011888655380307485,
        "hf_subset": "ars_Arab-rus_Cyrl",
        "languages": [
          "ars-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0011888655380307485,
        "precision": 0.001096179825544838,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.003625184652852637,
        "hf_subset": "ceb_Latn-rus_Cyrl",
        "languages": [
          "ceb-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003625184652852637,
        "precision": 0.0034594971564681854,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0033262259721124066,
        "hf_subset": "fuv_Latn-rus_Cyrl",
        "languages": [
          "fuv-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0033262259721124066,
        "precision": 0.0029808557839984557,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0012372983426351591,
        "hf_subset": "kac_Latn-rus_Cyrl",
        "languages": [
          "kac-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0012372983426351591,
        "precision": 0.0011303668544596953,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.003811426355758327,
        "hf_subset": "lin_Latn-rus_Cyrl",
        "languages": [
          "lin-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003811426355758327,
        "precision": 0.0035569420470705996,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.02865612648221344,
        "f1": 0.02144049347178255,
        "hf_subset": "nno_Latn-rus_Cyrl",
        "languages": [
          "nno-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.02144049347178255,
        "precision": 0.02031888982268153,
        "recall": 0.02865612648221344
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009912693250612899,
        "hf_subset": "sat_Olck-rus_Cyrl",
        "languages": [
          "sat-Olck",
          "rus-Cyrl"
        ],
        "main_score": 0.0009912693250612899,
        "precision": 0.0009897082866145086,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.00848155467720685,
        "hf_subset": "tel_Telu-rus_Cyrl",
        "languages": [
          "tel-Telu",
          "rus-Cyrl"
        ],
        "main_score": 0.00848155467720685,
        "precision": 0.008046301524562394,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0006851119894598155,
        "hf_subset": "ydd_Hebr-rus_Cyrl",
        "languages": [
          "ydd-Hebr",
          "rus-Cyrl"
        ],
        "main_score": 0.0006851119894598155,
        "precision": 0.0005074244204678987,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0005042199860496371,
        "hf_subset": "ary_Arab-rus_Cyrl",
        "languages": [
          "ary-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0005042199860496371,
        "precision": 0.00033446865655279936,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.023715415019762844,
        "f1": 0.01310662235506143,
        "hf_subset": "ces_Latn-rus_Cyrl",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01310662235506143,
        "precision": 0.011515224143217578,
        "recall": 0.023715415019762844
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.001978402789251384,
        "hf_subset": "gaz_Latn-rus_Cyrl",
        "languages": [
          "gaz-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001978402789251384,
        "precision": 0.001680902135744457,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.004046666485708134,
        "hf_subset": "kam_Latn-rus_Cyrl",
        "languages": [
          "kam-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.004046666485708134,
        "precision": 0.00400071559363359,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.017786561264822136,
        "f1": 0.009133370829968183,
        "hf_subset": "lit_Latn-rus_Cyrl",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.009133370829968183,
        "precision": 0.008165314525339635,
        "recall": 0.017786561264822136
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.01975503045582955,
        "hf_subset": "nob_Latn-rus_Cyrl",
        "languages": [
          "nob-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01975503045582955,
        "precision": 0.018196827344083233,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.008591015778047262,
        "hf_subset": "scn_Latn-rus_Cyrl",
        "languages": [
          "scn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.008591015778047262,
        "precision": 0.007641983235144927,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.010324599665919951,
        "hf_subset": "tgk_Cyrl-rus_Cyrl",
        "languages": [
          "tgk-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.010324599665919951,
        "precision": 0.009486714904273228,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.010869565217391304,
        "f1": 0.006824144446784442,
        "hf_subset": "yor_Latn-rus_Cyrl",
        "languages": [
          "yor-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.006824144446784442,
        "precision": 0.006550501329897347,
        "recall": 0.010869565217391304
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.00028749167280903143,
        "hf_subset": "arz_Arab-rus_Cyrl",
        "languages": [
          "arz-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.00028749167280903143,
        "precision": 0.0001583634947430203,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.002379874666745777,
        "hf_subset": "cjk_Latn-rus_Cyrl",
        "languages": [
          "cjk-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.002379874666745777,
        "precision": 0.002227495556108047,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0021435415704190407,
        "hf_subset": "gla_Latn-rus_Cyrl",
        "languages": [
          "gla-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0021435415704190407,
        "precision": 0.0018128791733699294,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.004183135704874835,
        "hf_subset": "kan_Knda-rus_Cyrl",
        "languages": [
          "kan-Knda",
          "rus-Cyrl"
        ],
        "main_score": 0.004183135704874835,
        "precision": 0.003540843214756258,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.009749056630366633,
        "hf_subset": "lmo_Latn-rus_Cyrl",
        "languages": [
          "lmo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.009749056630366633,
        "precision": 0.008670118515300118,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.006274301873453517,
        "hf_subset": "npi_Deva-rus_Cyrl",
        "languages": [
          "npi-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.006274301873453517,
        "precision": 0.005936953281928335,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.044466403162055336,
        "f1": 0.03022892565597601,
        "hf_subset": "shn_Mymr-rus_Cyrl",
        "languages": [
          "shn-Mymr",
          "rus-Cyrl"
        ],
        "main_score": 0.03022892565597601,
        "precision": 0.028210124109917977,
        "recall": 0.044466403162055336
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.003295791863104592,
        "hf_subset": "tgl_Latn-rus_Cyrl",
        "languages": [
          "tgl-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003295791863104592,
        "precision": 0.002965419985302004,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.041501976284584984,
        "f1": 0.02478597978630155,
        "hf_subset": "yue_Hant-rus_Cyrl",
        "languages": [
          "yue-Hant",
          "rus-Cyrl"
        ],
        "main_score": 0.02478597978630155,
        "precision": 0.022503983644621684,
        "recall": 0.041501976284584984
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0011009702637475253,
        "hf_subset": "asm_Beng-rus_Cyrl",
        "languages": [
          "asm-Beng",
          "rus-Cyrl"
        ],
        "main_score": 0.0011009702637475253,
        "precision": 0.0010474555501030591,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.003588877909530083,
        "hf_subset": "ckb_Arab-rus_Cyrl",
        "languages": [
          "ckb-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.003588877909530083,
        "precision": 0.003324207257273619,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.005052154124159623,
        "hf_subset": "gle_Latn-rus_Cyrl",
        "languages": [
          "gle-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.005052154124159623,
        "precision": 0.004716938224739074,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0032341908191421942,
        "hf_subset": "kas_Arab-rus_Cyrl",
        "languages": [
          "kas-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0032341908191421942,
        "precision": 0.0031059343422294157,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.011857707509881422,
        "f1": 0.00653152610018413,
        "hf_subset": "ltg_Latn-rus_Cyrl",
        "languages": [
          "ltg-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.00653152610018413,
        "precision": 0.006283026393724942,
        "recall": 0.011857707509881422
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.003965302174780925,
        "hf_subset": "nso_Latn-rus_Cyrl",
        "languages": [
          "nso-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003965302174780925,
        "precision": 0.0034648852396708977,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.004943172588957418,
        "hf_subset": "sin_Sinh-rus_Cyrl",
        "languages": [
          "sin-Sinh",
          "rus-Cyrl"
        ],
        "main_score": 0.004943172588957418,
        "precision": 0.004612562795908778,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.03557312252964427,
        "f1": 0.02485215448573482,
        "hf_subset": "tha_Thai-rus_Cyrl",
        "languages": [
          "tha-Thai",
          "rus-Cyrl"
        ],
        "main_score": 0.02485215448573482,
        "precision": 0.023227877670994834,
        "recall": 0.03557312252964427
      },
      {
        "accuracy": 0.0266798418972332,
        "f1": 0.018508590622660793,
        "hf_subset": "zho_Hans-rus_Cyrl",
        "languages": [
          "zho-Hans",
          "rus-Cyrl"
        ],
        "main_score": 0.018508590622660793,
        "precision": 0.017340486344180155,
        "recall": 0.0266798418972332
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.02111962384319334,
        "hf_subset": "ast_Latn-rus_Cyrl",
        "languages": [
          "ast-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.02111962384319334,
        "precision": 0.018896150518004064,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0022638152487893257,
        "hf_subset": "crh_Latn-rus_Cyrl",
        "languages": [
          "crh-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0022638152487893257,
        "precision": 0.0018511730692583029,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.036561264822134384,
        "f1": 0.025737949747024754,
        "hf_subset": "glg_Latn-rus_Cyrl",
        "languages": [
          "glg-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.025737949747024754,
        "precision": 0.024134613931515756,
        "recall": 0.036561264822134384
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.009550289678511967,
        "hf_subset": "kas_Deva-rus_Cyrl",
        "languages": [
          "kas-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.009550289678511967,
        "precision": 0.008669962233191506,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.0266798418972332,
        "f1": 0.016618354026847804,
        "hf_subset": "ltz_Latn-rus_Cyrl",
        "languages": [
          "ltz-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.016618354026847804,
        "precision": 0.015510479203431422,
        "recall": 0.0266798418972332
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.001542973058387819,
        "hf_subset": "nus_Latn-rus_Cyrl",
        "languages": [
          "nus-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001542973058387819,
        "precision": 0.0013484579661583304,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.00889582185182982,
        "hf_subset": "slk_Latn-rus_Cyrl",
        "languages": [
          "slk-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.00889582185182982,
        "precision": 0.008183659367067582,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.003098308800145382,
        "hf_subset": "tir_Ethi-rus_Cyrl",
        "languages": [
          "tir-Ethi",
          "rus-Cyrl"
        ],
        "main_score": 0.003098308800145382,
        "precision": 0.003036074426956656,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.03458498023715415,
        "f1": 0.01997510132975295,
        "hf_subset": "zho_Hant-rus_Cyrl",
        "languages": [
          "zho-Hant",
          "rus-Cyrl"
        ],
        "main_score": 0.01997510132975295,
        "precision": 0.017912731217631563,
        "recall": 0.03458498023715415
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010041342223074702,
        "hf_subset": "awa_Deva-rus_Cyrl",
        "languages": [
          "awa-Deva",
          "rus-Cyrl"
        ],
        "main_score": 0.0010041342223074702,
        "precision": 0.0009961794701777652,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.008157487227056977,
        "hf_subset": "cym_Latn-rus_Cyrl",
        "languages": [
          "cym-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.008157487227056977,
        "precision": 0.007441351572247145,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0034816106386594894,
        "hf_subset": "grn_Latn-rus_Cyrl",
        "languages": [
          "grn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0034816106386594894,
        "precision": 0.0033054192829539007,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0011485573490194697,
        "hf_subset": "kat_Geor-rus_Cyrl",
        "languages": [
          "kat-Geor",
          "rus-Cyrl"
        ],
        "main_score": 0.0011485573490194697,
        "precision": 0.0010711174476116239,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.001448254617559526,
        "hf_subset": "lua_Latn-rus_Cyrl",
        "languages": [
          "lua-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.001448254617559526,
        "precision": 0.0012684449012028717,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0002909084767834652,
        "hf_subset": "nya_Latn-rus_Cyrl",
        "languages": [
          "nya-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0002909084767834652,
        "precision": 0.0001689913991303067,
        "recall": 0.0029644268774703555
      },
      {
        "accuracy": 0.016798418972332016,
        "f1": 0.010635211504540765,
        "hf_subset": "slv_Latn-rus_Cyrl",
        "languages": [
          "slv-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.010635211504540765,
        "precision": 0.009828549422668123,
        "recall": 0.016798418972332016
      },
      {
        "accuracy": 0.018774703557312252,
        "f1": 0.01340922607039094,
        "hf_subset": "tpi_Latn-rus_Cyrl",
        "languages": [
          "tpi-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01340922607039094,
        "precision": 0.012875656268577578,
        "recall": 0.018774703557312252
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0006607760895754513,
        "hf_subset": "zsm_Latn-rus_Cyrl",
        "languages": [
          "zsm-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0006607760895754513,
        "precision": 0.0004950794547067839,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.003952569169960474,
        "f1": 0.0016574652556419738,
        "hf_subset": "ayr_Latn-rus_Cyrl",
        "languages": [
          "ayr-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0016574652556419738,
        "precision": 0.0014875118174676053,
        "recall": 0.003952569169960474
      },
      {
        "accuracy": 0.037549407114624504,
        "f1": 0.026322566342519782,
        "hf_subset": "dan_Latn-rus_Cyrl",
        "languages": [
          "dan-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.026322566342519782,
        "precision": 0.02433982378860174,
        "recall": 0.037549407114624504
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0036256837146165207,
        "hf_subset": "guj_Gujr-rus_Cyrl",
        "languages": [
          "guj-Gujr",
          "rus-Cyrl"
        ],
        "main_score": 0.0036256837146165207,
        "precision": 0.0034597472554379056,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.038537549407114624,
        "f1": 0.027845900504073033,
        "hf_subset": "kaz_Cyrl-rus_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.027845900504073033,
        "precision": 0.025819862965150053,
        "recall": 0.038537549407114624
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0030275862834824173,
        "hf_subset": "lug_Latn-rus_Cyrl",
        "languages": [
          "lug-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0030275862834824173,
        "precision": 0.002996945034380142,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.02766798418972332,
        "f1": 0.019430656648762253,
        "hf_subset": "oci_Latn-rus_Cyrl",
        "languages": [
          "oci-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.019430656648762253,
        "precision": 0.01828061967620928,
        "recall": 0.02766798418972332
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.003204142127559884,
        "hf_subset": "smo_Latn-rus_Cyrl",
        "languages": [
          "smo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003204142127559884,
        "precision": 0.0028378261728455234,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.0029000556639820797,
        "hf_subset": "tsn_Latn-rus_Cyrl",
        "languages": [
          "tsn-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0029000556639820797,
        "precision": 0.0025700689672057643,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0022924271826561503,
        "hf_subset": "zul_Latn-rus_Cyrl",
        "languages": [
          "zul-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0022924271826561503,
        "precision": 0.0018927658194405575,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 9.43029575851947e-05,
        "hf_subset": "azb_Arab-rus_Cyrl",
        "languages": [
          "azb-Arab",
          "rus-Cyrl"
        ],
        "main_score": 9.43029575851947e-05,
        "precision": 4.771046920031447e-05,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.058300395256917,
        "f1": 0.04051371924319676,
        "hf_subset": "deu_Latn-rus_Cyrl",
        "languages": [
          "deu-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.04051371924319676,
        "precision": 0.03711133507802933,
        "recall": 0.058300395256917
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.009067682132968222,
        "hf_subset": "hat_Latn-rus_Cyrl",
        "languages": [
          "hat-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.009067682132968222,
        "precision": 0.008437015943809424,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.007905138339920948,
        "f1": 0.0031605204308922485,
        "hf_subset": "kbp_Latn-rus_Cyrl",
        "languages": [
          "kbp-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0031605204308922485,
        "precision": 0.0027150265240867997,
        "recall": 0.007905138339920948
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.005108579150939,
        "hf_subset": "luo_Latn-rus_Cyrl",
        "languages": [
          "luo-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.005108579150939,
        "precision": 0.004777612291789985,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.009881422924901186,
        "f1": 0.008402449296961058,
        "hf_subset": "ory_Orya-rus_Cyrl",
        "languages": [
          "ory-Orya",
          "rus-Cyrl"
        ],
        "main_score": 0.008402449296961058,
        "precision": 0.008236141669425028,
        "recall": 0.009881422924901186
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.003032630809555068,
        "hf_subset": "sna_Latn-rus_Cyrl",
        "languages": [
          "sna-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003032630809555068,
        "precision": 0.0027185565664851964,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.003588176349424143,
        "hf_subset": "tso_Latn-rus_Cyrl",
        "languages": [
          "tso-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.003588176349424143,
        "precision": 0.0033394439235439693,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0015091392022145698,
        "hf_subset": "azj_Latn-rus_Cyrl",
        "languages": [
          "azj-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0015091392022145698,
        "precision": 0.0012833195469056753,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.008893280632411068,
        "f1": 0.00497673345178036,
        "hf_subset": "dik_Latn-rus_Cyrl",
        "languages": [
          "dik-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.00497673345178036,
        "precision": 0.004662405831586001,
        "recall": 0.008893280632411068
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.0016989649450961167,
        "hf_subset": "hau_Latn-rus_Cyrl",
        "languages": [
          "hau-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0016989649450961167,
        "precision": 0.0014327372232510573,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.011225292548237748,
        "hf_subset": "kea_Latn-rus_Cyrl",
        "languages": [
          "kea-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.011225292548237748,
        "precision": 0.00984664006082225,
        "recall": 0.019762845849802372
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0036589052991725774,
        "hf_subset": "lus_Latn-rus_Cyrl",
        "languages": [
          "lus-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0036589052991725774,
        "precision": 0.0034766464809317396,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.019762845849802372,
        "f1": 0.01637249557039662,
        "hf_subset": "pag_Latn-rus_Cyrl",
        "languages": [
          "pag-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.01637249557039662,
        "precision": 0.01584670457875541,
        "recall": 0.019762845849802372
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0003120875134256333,
        "hf_subset": "snd_Arab-rus_Cyrl",
        "languages": [
          "snd-Arab",
          "rus-Cyrl"
        ],
        "main_score": 0.0003120875134256333,
        "precision": 0.00016820539945644881,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.012845849802371542,
        "f1": 0.0064399414599025095,
        "hf_subset": "tuk_Latn-rus_Cyrl",
        "languages": [
          "tuk-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0064399414599025095,
        "precision": 0.00584136449022023,
        "recall": 0.012845849802371542
      },
      {
        "accuracy": 0.03359683794466403,
        "f1": 0.027163386217012395,
        "hf_subset": "bak_Cyrl-rus_Cyrl",
        "languages": [
          "bak-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.027163386217012395,
        "precision": 0.025585123794964488,
        "recall": 0.03359683794466403
      },
      {
        "accuracy": 0.005928853754940711,
        "f1": 0.0020842330048679433,
        "hf_subset": "dyu_Latn-rus_Cyrl",
        "languages": [
          "dyu-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0020842330048679433,
        "precision": 0.0017505600807891048,
        "recall": 0.005928853754940711
      },
      {
        "accuracy": 0.004940711462450593,
        "f1": 0.00019295732693057287,
        "hf_subset": "heb_Hebr-rus_Cyrl",
        "languages": [
          "heb-Hebr",
          "rus-Cyrl"
        ],
        "main_score": 0.00019295732693057287,
        "precision": 0.00010111109526070994,
        "recall": 0.004940711462450593
      },
      {
        "accuracy": 0.015810276679841896,
        "f1": 0.005862014381767968,
        "hf_subset": "khk_Cyrl-rus_Cyrl",
        "languages": [
          "khk-Cyrl",
          "rus-Cyrl"
        ],
        "main_score": 0.005862014381767968,
        "precision": 0.005439021423774433,
        "recall": 0.015810276679841896
      },
      {
        "accuracy": 0.014822134387351778,
        "f1": 0.007911068490078112,
        "hf_subset": "lvs_Latn-rus_Cyrl",
        "languages": [
          "lvs-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.007911068490078112,
        "precision": 0.007281713611583893,
        "recall": 0.014822134387351778
      },
      {
        "accuracy": 0.00691699604743083,
        "f1": 0.00560242707834831,
        "hf_subset": "pan_Guru-rus_Cyrl",
        "languages": [
          "pan-Guru",
          "rus-Cyrl"
        ],
        "main_score": 0.00560242707834831,
        "precision": 0.00543626186362453,
        "recall": 0.00691699604743083
      },
      {
        "accuracy": 0.001976284584980237,
        "f1": 0.0009902204045668592,
        "hf_subset": "som_Latn-rus_Cyrl",
        "languages": [
          "som-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0009902204045668592,
        "precision": 0.000989182442271687,
        "recall": 0.001976284584980237
      },
      {
        "accuracy": 0.0029644268774703555,
        "f1": 0.0010612097773705649,
        "hf_subset": "tum_Latn-rus_Cyrl",
        "languages": [
          "tum-Latn",
          "rus-Cyrl"
        ],
        "main_score": 0.0010612097773705649,
        "precision": 0.0010259846668783257,
        "recall": 0.0029644268774703555
      }
    ]
  },
  "task_name": "FloresBitextMining"
}