{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "task_name": "EmotionClassification",
  "mteb_version": "1.18.0",
  "scores": {
    "validation": [
      {
        "accuracy": 0.2052,
        "f1": 0.186758,
        "f1_weighted": 0.220385,
        "scores_per_experiment": [
          {
            "accuracy": 0.2125,
            "f1": 0.195081,
            "f1_weighted": 0.226401
          },
          {
            "accuracy": 0.1805,
            "f1": 0.160972,
            "f1_weighted": 0.199444
          },
          {
            "accuracy": 0.21,
            "f1": 0.189276,
            "f1_weighted": 0.232113
          },
          {
            "accuracy": 0.1955,
            "f1": 0.174524,
            "f1_weighted": 0.21332
          },
          {
            "accuracy": 0.2125,
            "f1": 0.19257,
            "f1_weighted": 0.226937
          },
          {
            "accuracy": 0.223,
            "f1": 0.198594,
            "f1_weighted": 0.239547
          },
          {
            "accuracy": 0.212,
            "f1": 0.194768,
            "f1_weighted": 0.225399
          },
          {
            "accuracy": 0.1965,
            "f1": 0.186269,
            "f1_weighted": 0.20902
          },
          {
            "accuracy": 0.207,
            "f1": 0.186691,
            "f1_weighted": 0.21974
          },
          {
            "accuracy": 0.2025,
            "f1": 0.188839,
            "f1_weighted": 0.211926
          }
        ],
        "main_score": 0.2052,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.2001,
        "f1": 0.178882,
        "f1_weighted": 0.218233,
        "scores_per_experiment": [
          {
            "accuracy": 0.197,
            "f1": 0.176213,
            "f1_weighted": 0.215057
          },
          {
            "accuracy": 0.18,
            "f1": 0.160893,
            "f1_weighted": 0.199224
          },
          {
            "accuracy": 0.199,
            "f1": 0.184843,
            "f1_weighted": 0.214344
          },
          {
            "accuracy": 0.2025,
            "f1": 0.177316,
            "f1_weighted": 0.221402
          },
          {
            "accuracy": 0.2295,
            "f1": 0.205465,
            "f1_weighted": 0.249252
          },
          {
            "accuracy": 0.209,
            "f1": 0.186347,
            "f1_weighted": 0.225935
          },
          {
            "accuracy": 0.192,
            "f1": 0.172383,
            "f1_weighted": 0.207451
          },
          {
            "accuracy": 0.1955,
            "f1": 0.179334,
            "f1_weighted": 0.214115
          },
          {
            "accuracy": 0.196,
            "f1": 0.164667,
            "f1_weighted": 0.21878
          },
          {
            "accuracy": 0.2005,
            "f1": 0.181356,
            "f1_weighted": 0.21677
          }
        ],
        "main_score": 0.2001,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 16.989490509033203,
  "kg_co2_emissions": 0.0005617882864401998
}