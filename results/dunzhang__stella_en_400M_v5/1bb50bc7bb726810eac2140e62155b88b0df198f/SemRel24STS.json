{
  "dataset_revision": "ef5c383d1b87eb8feccde3dfb7f95e42b1b050dd",
  "evaluation_time": 49.62835240364075,
  "kg_co2_emissions": 0.002587696910957434,
  "mteb_version": "1.18.0",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.7415728362813779,
        "cosine_spearman": 0.7383662648136349,
        "euclidean_pearson": 0.726514472025021,
        "euclidean_spearman": 0.7383662648136349,
        "hf_subset": "afr",
        "languages": [
          "afr-Latn"
        ],
        "main_score": 0.7383662648136349,
        "manhattan_pearson": 0.723800342098618,
        "manhattan_spearman": 0.7336895872900437,
        "pearson": 0.7415728362813779,
        "spearman": 0.7383662648136349
      },
      {
        "cosine_pearson": 0.007547143743369289,
        "cosine_spearman": 0.018362178894987504,
        "euclidean_pearson": 0.03724184499345544,
        "euclidean_spearman": 0.018396567376365414,
        "hf_subset": "amh",
        "languages": [
          "amh-Ethi"
        ],
        "main_score": 0.018362178894987504,
        "manhattan_pearson": 0.03700421460977563,
        "manhattan_spearman": 0.020538736311401965,
        "pearson": 0.007547143743369289,
        "spearman": 0.018362178894987504
      },
      {
        "cosine_pearson": 0.23161069405994994,
        "cosine_spearman": 0.24715054986659088,
        "euclidean_pearson": 0.2534043220874743,
        "euclidean_spearman": 0.24715054986659088,
        "hf_subset": "arb",
        "languages": [
          "arb-Arab"
        ],
        "main_score": 0.24715054986659088,
        "manhattan_pearson": 0.2514562990805624,
        "manhattan_spearman": 0.24540045884300854,
        "pearson": 0.23161069405994994,
        "spearman": 0.24715054986659088
      },
      {
        "cosine_pearson": 0.3660383840088223,
        "cosine_spearman": 0.3579651998840836,
        "euclidean_pearson": 0.3803419608748532,
        "euclidean_spearman": 0.3579651998840836,
        "hf_subset": "arq",
        "languages": [
          "arq-Arab"
        ],
        "main_score": 0.3579651998840836,
        "manhattan_pearson": 0.38256097626770375,
        "manhattan_spearman": 0.35939635503640904,
        "pearson": 0.3660383840088223,
        "spearman": 0.3579651998840836
      },
      {
        "cosine_pearson": 0.102445654107451,
        "cosine_spearman": 0.10415500107887053,
        "euclidean_pearson": 0.13688568643689758,
        "euclidean_spearman": 0.10415500107887053,
        "hf_subset": "ary",
        "languages": [
          "ary-Arab"
        ],
        "main_score": 0.10415500107887053,
        "manhattan_pearson": 0.13649918150966267,
        "manhattan_spearman": 0.10397443524073675,
        "pearson": 0.102445654107451,
        "spearman": 0.10415500107887053
      },
      {
        "cosine_pearson": 0.8253052341387213,
        "cosine_spearman": 0.8105701484043522,
        "euclidean_pearson": 0.8216103628796723,
        "euclidean_spearman": 0.8105698720260176,
        "hf_subset": "eng",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8105701484043522,
        "manhattan_pearson": 0.8206128574700994,
        "manhattan_spearman": 0.8086097523054301,
        "pearson": 0.8253052341387213,
        "spearman": 0.8105701484043522
      },
      {
        "cosine_pearson": 0.40375226511563345,
        "cosine_spearman": 0.3837221530707676,
        "euclidean_pearson": 0.40992306583797133,
        "euclidean_spearman": 0.3837221530707676,
        "hf_subset": "hau",
        "languages": [
          "hau-Latn"
        ],
        "main_score": 0.3837221530707676,
        "manhattan_pearson": 0.4066080075864834,
        "manhattan_spearman": 0.3789372924304588,
        "pearson": 0.40375226511563345,
        "spearman": 0.3837221530707676
      },
      {
        "cosine_pearson": 0.47550466517325857,
        "cosine_spearman": 0.4706403693531936,
        "euclidean_pearson": 0.5036327830810391,
        "euclidean_spearman": 0.4706403693531936,
        "hf_subset": "hin",
        "languages": [
          "hin-Deva"
        ],
        "main_score": 0.4706403693531936,
        "manhattan_pearson": 0.5038132527701099,
        "manhattan_spearman": 0.47145539825638827,
        "pearson": 0.47550466517325857,
        "spearman": 0.4706403693531936
      },
      {
        "cosine_pearson": 0.37561478618956934,
        "cosine_spearman": 0.3801851362640013,
        "euclidean_pearson": 0.4114910097073084,
        "euclidean_spearman": 0.3801851362640013,
        "hf_subset": "ind",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.3801851362640013,
        "manhattan_pearson": 0.408896844332912,
        "manhattan_spearman": 0.37754588562161173,
        "pearson": 0.37561478618956934,
        "spearman": 0.3801851362640013
      },
      {
        "cosine_pearson": 0.4612875526601016,
        "cosine_spearman": 0.43748815978188293,
        "euclidean_pearson": 0.4633331271213939,
        "euclidean_spearman": 0.43748815978188293,
        "hf_subset": "kin",
        "languages": [
          "kin-Latn"
        ],
        "main_score": 0.43748815978188293,
        "manhattan_pearson": 0.46255150951059415,
        "manhattan_spearman": 0.43921907346806155,
        "pearson": 0.4612875526601016,
        "spearman": 0.43748815978188293
      },
      {
        "cosine_pearson": 0.5487698675520067,
        "cosine_spearman": 0.5432735894980035,
        "euclidean_pearson": 0.5741267062025668,
        "euclidean_spearman": 0.5432735894980035,
        "hf_subset": "mar",
        "languages": [
          "mar-Deva"
        ],
        "main_score": 0.5432735894980035,
        "manhattan_pearson": 0.578240391679042,
        "manhattan_spearman": 0.5475346824614774,
        "pearson": 0.5487698675520067,
        "spearman": 0.5432735894980035
      },
      {
        "cosine_pearson": 0.2154972894547361,
        "cosine_spearman": 0.3310738764925261,
        "euclidean_pearson": 0.2890766031394811,
        "euclidean_spearman": 0.33205170822111424,
        "hf_subset": "tel",
        "languages": [
          "tel-Telu"
        ],
        "main_score": 0.3310738764925261,
        "manhattan_pearson": 0.2896625605923465,
        "manhattan_spearman": 0.33117636359791514,
        "pearson": 0.2154972894547361,
        "spearman": 0.3310738764925261
      }
    ]
  },
  "task_name": "SemRel24STS"
}